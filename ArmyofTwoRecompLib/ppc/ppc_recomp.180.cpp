#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82D4F330"))) PPC_WEAK_FUNC(sub_82D4F330);
PPC_FUNC_IMPL(__imp__sub_82D4F330) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1520
	ctx.r5.s64 = ctx.r11.s64 + -1520;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-3352
	ctx.r4.s64 = ctx.r11.s64 + -3352;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D4F348"))) PPC_WEAK_FUNC(sub_82D4F348);
PPC_FUNC_IMPL(__imp__sub_82D4F348) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D4F350;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D4F358;
	__savefpr_14(ctx, base);
	// stwu r1,-656(r1)
	ea = -656 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d50b58
	if (!ctx.cr6.lt) goto loc_82D50B58;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// stw r10,300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 300, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f31,-8004(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8004);
	ctx.f31.f64 = double(temp.f32);
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lfs f1,-8000(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8000);
	ctx.f1.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f2,-8012(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -8012);
	ctx.f2.f64 = double(temp.f32);
	// lfs f11,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f11.f64 = double(temp.f32);
	// stw r10,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f3,-8008(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8008);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,136(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f10.f64 = double(temp.f32);
	// stw r29,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, ctx.r29.u32);
	// lfs f12,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
loc_82D4F3C0:
	// lfs f0,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f30,f0,f9
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f7,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f0,f8
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f9,f7
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f8,f6
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f29,f5,f7
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmuls f28,f4,f6
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f13,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f26,f4,f7
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// fmuls f27,f5,f6
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f20,f0,f5
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f16,f13,f4
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmadds f30,f13,f8,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f30.f64));
	// stfs f30,48(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmuls f19,f0,f6
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// fmuls f15,f13,f7
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmsubs f30,f13,f9,f25
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f25.f64));
	// stfs f30,140(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmuls f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f16,f20
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f22,204(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fadds f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f22,120(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f23,f9,f6
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f18,f0,f4
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fmuls f22,f13,f5
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmuls f17,f0,f7
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fsubs f25,f21,f23
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fsubs f21,f22,f18
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f21,184(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmuls f21,f13,f6
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fsubs f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f22,188(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f19,f13,f27
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// fmuls f18,f0,f27
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fmuls f15,f25,f0
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fsubs f22,f17,f21
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fsubs f22,f20,f16
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f22,64(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmuls f16,f26,f0
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fadds f14,f21,f17
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f14,f24,f0
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f22,f0,f30
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f21,f13,f30
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fmuls f20,f0,f29
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// fmuls f17,f13,f28
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmadds f16,f25,f13,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f16,100(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmsubs f16,f26,f13,f15
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmadds f16,f23,f13,f14
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f16,136(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f16,f19,f22
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f16,196(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f22,f21,f18
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f22,192(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fadds f22,f18,f21
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f22,212(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f21,f0,f28
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// rlwinm r10,r6,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// fmuls f22,f13,f29
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// fmuls f18,f8,f5
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f19,f9,f4
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f16,f9,f30
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f15,f8,f27
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f17,f8,f4
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmuls f14,f8,f30
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fadds f20,f21,f22
	ctx.f20.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f20,224(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,208(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmuls f22,f9,f27
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f21,f18,f19
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f18,f23,f0
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f20,f9,f5
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmsubs f18,f24,f13,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f18,128(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fsubs f18,f16,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f18,160(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,36(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f18,112(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fmuls f16,f8,f28
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f18,52(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,176(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f17,f9,f29
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmuls f14,f19,f0
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,164(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f16,f9,f28
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f17,f8,f29
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,172(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,152(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f15,f20,f0
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmsubs f20,f20,f13,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f20,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f22,f0
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f21,f0
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// lfs f20,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmadds f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f19,96(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfsx f19,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f19,f18,f0
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmadds f17,f21,f13,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmsubs f17,f22,f13,f16
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmadds f20,f18,f13,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f20,28(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f20,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmsubs f20,f20,f13,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f19.f64));
	// stfs f20,76(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f20,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f18,f19,f0
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f19,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f17,f19,f13,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f17,168(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// mulli r8,r6,96
	ctx.r8.s64 = ctx.r6.s64 * 96;
	// fmadds f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f17,116(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f17,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r21,r6,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f17,88(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f17,f13,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f20.f64));
	// stfs f20,60(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f20,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f20.f64 = double(temp.f32);
	// mulli r20,r6,100
	ctx.r20.s64 = ctx.r6.s64 * 100;
	// fmadds f20,f20,f13,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f20,f17
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f17.f64));
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f20,f18
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f18.f64));
	// lfs f20,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// add r18,r21,r3
	ctx.r18.u64 = ctx.r21.u64 + ctx.r3.u64;
	// rlwinm r9,r6,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r19,r6,68
	ctx.r19.s64 = ctx.r6.s64 * 68;
	// fmadds f18,f20,f18,f16
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 + ctx.f16.f64));
	// fmsubs f17,f20,f17,f15
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f20,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// add r7,r20,r3
	ctx.r7.u64 = ctx.r20.u64 + ctx.r3.u64;
	// add r5,r19,r3
	ctx.r5.u64 = ctx.r19.u64 + ctx.r3.u64;
	// fadds f16,f18,f20
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfsx f16,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// stw r7,340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 340, ctx.r7.u32);
	// lfs f16,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// stw r5,324(r1)
	PPC_STORE_U32(ctx.r1.u32 + 324, ctx.r5.u32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f20,124(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f20,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f16,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f20,f17
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfsx f16,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f20,144(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f16,108(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f20,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f16,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,180(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f16,f20,f26
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// fmuls f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// lfsx f17,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// stfs f18,148(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// fmadds f25,f18,f25,f16
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f16.f64));
	// fmsubs f20,f18,f26,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 - ctx.f20.f64));
	// lfs f26,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f6
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// lfs f26,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f26,f18,f15
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f26,f26,f15,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f15.f64 - ctx.f17.f64));
	// stfs f26,28(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f7.f64));
	// lfs f17,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f26,f17
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f17,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f17.f64 = double(temp.f32);
	// mulli r7,r6,124
	ctx.r7.s64 = ctx.r6.s64 * 124;
	// fmuls f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// stfs f26,16(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// mulli r17,r6,36
	ctx.r17.s64 = ctx.r6.s64 * 36;
	// fmr f26,f17
	ctx.f26.f64 = ctx.f17.f64;
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f6,f26,f6,f14
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f14.f64));
	// stfs f6,76(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f6,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f7,f26,f7,f16
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 - ctx.f16.f64));
	// fmuls f14,f6,f17
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f17,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f26.f64 = double(temp.f32);
	// mulli r5,r6,92
	ctx.r5.s64 = ctx.r6.s64 * 92;
	// fmadds f26,f17,f26,f15
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f15.f64));
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// mulli r31,r6,60
	ctx.r31.s64 = ctx.r6.s64 * 60;
	// add r29,r17,r3
	ctx.r29.u64 = ctx.r17.u64 + ctx.r3.u64;
	// mulli r30,r6,28
	ctx.r30.s64 = ctx.r6.s64 * 28;
	// stw r29,348(r1)
	PPC_STORE_U32(ctx.r1.u32 + 348, ctx.r29.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f18,f25
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fsubs f18,f20,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f15,196(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f15,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f25
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfs f15,216(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f15,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f15,292(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f15,204(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f6,f6,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// stfs f6,16(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f20,268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f20,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f6,f20,f15,f14
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f20,f15,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f6,f14
	ctx.f15.f64 = double(float(ctx.f6.f64 + ctx.f14.f64));
	// fsubs f6,f14,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 - ctx.f6.f64));
	// stfs f6,144(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fadds f6,f20,f7
	ctx.f6.f64 = double(float(ctx.f20.f64 + ctx.f7.f64));
	// stfs f6,236(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fsubs f7,f7,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f20.f64));
	// lfsx f20,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,108(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f20,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,76(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f20,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,180(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfsx f6,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f20,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f6,16(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f20,128(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfsx f6,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f20,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f7,228(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f7,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// stfs f6,28(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// stfs f20,232(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfsx f20,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f7,f8
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// stfs f20,124(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f20,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r28,r6,48
	ctx.r28.s64 = ctx.r6.s64 * 48;
	// stfs f20,220(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f20,f7,f9
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f7,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f6,f7
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f7.f64 = double(temp.f32);
	// mulli r27,r6,80
	ctx.r27.s64 = ctx.r6.s64 * 80;
	// fmsubs f9,f7,f9,f14
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 - ctx.f14.f64));
	// stfs f9,136(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f9,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f9.f64 = double(temp.f32);
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f8,f7,f8,f20
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f20.f64));
	// stfs f8,16(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f8,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f7,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f9,f7
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f9,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f8,f9,f8,f6
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,148(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f8,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f9,f9,f8,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 - ctx.f20.f64));
	// stfs f9,28(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f9,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f9,f8
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f20,f9,f8
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f8,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f8,f9,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f7.f64));
	// lfs f7,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f8,f8,f7,f14
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f14.f64));
	// stfs f8,104(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f14,f8,f19
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f7,f8,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f6.f64));
	// lfs f6,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f7,f7,f6,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 - ctx.f20.f64));
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fadds f6,f20,f26
	ctx.f6.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// lfs f20,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,24(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f17,f6,f15
	ctx.f17.f64 = double(float(ctx.f6.f64 + ctx.f15.f64));
	// fsubs f6,f15,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 - ctx.f6.f64));
	// stfs f6,256(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f6,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f6.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 - ctx.f15.f64));
	// stfs f15,344(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f6,f15,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 + ctx.f6.f64));
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f15,296(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f20,136(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f20,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f20,f26
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// stfs f15,328(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fadds f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// stfs f26,144(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f26,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f26.f64 = double(temp.f32);
	// lfs f20,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f26
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f20,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f26,f20,f26,f14
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f26.f64 + ctx.f14.f64));
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f15.f64));
	// fadds f15,f7,f14
	ctx.f15.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f7,f14,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 - ctx.f7.f64));
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f8,f19
	ctx.f19.f64 = double(float(ctx.f8.f64 + ctx.f19.f64));
	// mulli r26,r6,112
	ctx.r26.s64 = ctx.r6.s64 * 112;
	// fsubs f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// fadds f14,f26,f9
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f9.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f9,f26,f9
	ctx.f9.f64 = double(float(ctx.f26.f64 - ctx.f9.f64));
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// lfsx f20,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f20,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,76(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f20,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,28(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f20,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,108(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f20,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,84(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfsx f20,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,104(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f20,124(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// fsubs f19,f15,f14
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f19,260(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fadds f19,f14,f15
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f19,148(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f19,f7,f9
	ctx.f19.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// stfs f19,352(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fadds f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// stfs f9,212(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfsx f9,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,128(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fadds f9,f26,f8
	ctx.f9.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// stfs f9,236(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfsx f9,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,24(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f9,f8,f26
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f26.f64));
	// stfs f9,208(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f9,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f26,f9,f28
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f7,f9,f29
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// lfs f9,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f19,f9,f22
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f22.f64));
	// lfs f8,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f9,f21
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// lfs f9,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f14,f8,f9
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// stfs f9,16(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f8,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f9,f8,f28,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 + ctx.f7.f64));
	// lfs f28,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f8,f8,f29,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f29.f64 - ctx.f26.f64));
	// lfs f29,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f7,f28,f21,f19
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f21.f64 + ctx.f19.f64));
	// lfs f19,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f19.f64 = double(temp.f32);
	// lfs f26,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f29
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmuls f29,f19,f29
	ctx.f29.f64 = double(float(ctx.f19.f64 * ctx.f29.f64));
	// stfs f29,120(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmsubs f29,f28,f22,f15
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 - ctx.f15.f64));
	// lfs f28,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f28.f64 = double(temp.f32);
	// stfs f26,116(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmr f26,f28
	ctx.f26.f64 = ctx.f28.f64;
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f28,f28,f26,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f26.f64 + ctx.f14.f64));
	// fmsubs f26,f22,f26,f15
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f26.f64 - ctx.f15.f64));
	// lfs f21,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f21.f64 = double(temp.f32);
	// rlwinm r16,r6,3,0,28
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// mulli r15,r6,104
	ctx.r15.s64 = ctx.r6.s64 * 104;
	// fmadds f22,f19,f21,f15
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 + ctx.f15.f64));
	// lfs f19,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f21,f19,f21,f15
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 - ctx.f15.f64));
	// fadds f15,f26,f8
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// fadds f19,f28,f9
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f9.f64));
	// fsubs f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f26.f64));
	// fsubs f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f28.f64));
	// add r23,r16,r4
	ctx.r23.u64 = ctx.r16.u64 + ctx.r4.u64;
	// add r22,r15,r4
	ctx.r22.u64 = ctx.r15.u64 + ctx.r4.u64;
	// mulli r25,r6,40
	ctx.r25.s64 = ctx.r6.s64 * 40;
	// fadds f14,f22,f7
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f7.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f7,f22,f7
	ctx.f7.f64 = double(float(ctx.f22.f64 - ctx.f7.f64));
	// fadds f14,f21,f29
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f29,f21,f29
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// stw r22,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r22.u32);
	// lfsx f26,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stw r25,320(r1)
	PPC_STORE_U32(ctx.r1.u32 + 320, ctx.r25.u32);
	// stfs f26,116(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stw r23,308(r1)
	PPC_STORE_U32(ctx.r1.u32 + 308, ctx.r23.u32);
	// fadds f28,f8,f9
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// mulli r24,r6,120
	ctx.r24.s64 = ctx.r6.s64 * 120;
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfsx f26,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stw r24,336(r1)
	PPC_STORE_U32(ctx.r1.u32 + 336, ctx.r24.u32);
	// fsubs f8,f7,f29
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// stfs f8,220(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fadds f8,f29,f7
	ctx.f8.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// lfs f7,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,72(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// mulli r14,r6,72
	ctx.r14.s64 = ctx.r6.s64 * 72;
	// stfs f8,228(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfsx f8,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f26,28(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f26,f8,f30
	ctx.f26.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f22,f8,f27
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// lfsx f7,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f21,f7,f8
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f29,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// add r22,r14,r4
	ctx.r22.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r22,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r22.u32);
	// add r22,r25,r4
	ctx.r22.u64 = ctx.r25.u64 + ctx.r4.u64;
	// stw r22,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r22.u32);
	// add r22,r24,r4
	ctx.r22.u64 = ctx.r24.u64 + ctx.r4.u64;
	// stw r22,332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 332, ctx.r22.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,168(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lwz r25,180(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fmuls f14,f7,f8
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f8,f29,f8
	ctx.f8.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fmuls f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f7.f64));
	// stfs f7,120(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f29,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f29.f64 = double(temp.f32);
	// fmr f7,f29
	ctx.f7.f64 = ctx.f29.f64;
	// stfs f8,72(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f29,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f8,f7,f27,f26
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f27.f64 + ctx.f26.f64));
	// fmsubs f7,f7,f30,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f22.f64));
	// lfs f30,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f29,f30,f29,f21
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 + ctx.f21.f64));
	// stfs f29,16(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f29,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f26,f29,f24
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// lwz r25,224(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// fmuls f21,f29,f23
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f23.f64));
	// lfs f29,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f29.f64 = double(temp.f32);
	// mulli r24,r6,56
	ctx.r24.s64 = ctx.r6.s64 * 56;
	// fmsubs f30,f30,f29,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 - ctx.f14.f64));
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// lfs f29,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f29.f64 = double(temp.f32);
	// mulli r23,r6,24
	ctx.r23.s64 = ctx.r6.s64 * 24;
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// lfs f27,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lwz r25,128(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fmadds f29,f27,f29,f22
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f22.f64));
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f27,f27,f22,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64 - ctx.f14.f64));
	// stw r24,288(r1)
	PPC_STORE_U32(ctx.r1.u32 + 288, ctx.r24.u32);
	// lfs f22,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f26,f22,f23,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f26.f64));
	// fmsubs f24,f22,f24,f21
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f21.f64));
	// stw r23,284(r1)
	PPC_STORE_U32(ctx.r1.u32 + 284, ctx.r23.u32);
	// fadds f23,f29,f8
	ctx.f23.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// mulli r25,r6,88
	ctx.r25.s64 = ctx.r6.s64 * 88;
	// fadds f22,f27,f7
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// lfs f27,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f8,f8,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f29.f64));
	// fadds f29,f26,f27
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// stw r25,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r25.u32);
	// fadds f26,f24,f30
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fsubs f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// fadds f24,f29,f23
	ctx.f24.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// fsubs f23,f22,f26
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fadds f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// fadds f22,f30,f8
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f8.f64));
	// fsubs f8,f8,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f30.f64));
	// stfs f8,188(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f8,f7,f27
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// stfs f8,244(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fadds f8,f27,f7
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// stfs f8,132(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f8,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// mulli r22,r6,20
	ctx.r22.s64 = ctx.r6.s64 * 20;
	// lfs f30,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f30.f64 = double(temp.f32);
	// lfs f7,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f21,f30,f7
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// fmuls f27,f8,f7
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f7.f64 = double(temp.f32);
	// stw r22,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r22.u32);
	// mulli r22,r6,84
	ctx.r22.s64 = ctx.r6.s64 * 84;
	// stw r22,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r22.u32);
	// fmsubs f8,f8,f7,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f21.f64));
	// stfs f8,116(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmadds f30,f30,f7,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f27.f64));
	// add r22,r25,r4
	ctx.r22.u64 = ctx.r25.u64 + ctx.r4.u64;
	// lfsx f8,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f30,48(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f30,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,68(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f7,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// stw r22,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r22.u32);
	// add r22,r24,r4
	ctx.r22.u64 = ctx.r24.u64 + ctx.r4.u64;
	// stw r22,76(r1)
	PPC_STORE_U32(ctx.r1.u32 + 76, ctx.r22.u32);
	// add r22,r23,r4
	ctx.r22.u64 = ctx.r23.u64 + ctx.r4.u64;
	// stw r22,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r22.u32);
	// lwz r22,112(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// add r22,r22,r3
	ctx.r22.u64 = ctx.r22.u64 + ctx.r3.u64;
	// stw r22,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r22.u32);
	// lwz r22,184(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// add r22,r22,r3
	ctx.r22.u64 = ctx.r22.u64 + ctx.r3.u64;
	// stw r22,316(r1)
	PPC_STORE_U32(ctx.r1.u32 + 316, ctx.r22.u32);
	// lwz r25,28(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lfs f27,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lwz r25,112(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stfs f27,64(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f30,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lwz r25,184(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// stfs f30,72(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f30,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,120(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f30,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f30,f8,f30
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f7,f14
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f14.f64));
	// lwz r25,76(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	// fmuls f21,f7,f21
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// lfs f7,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f7.f64 = double(temp.f32);
	// lwz r24,16(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fmadds f8,f8,f7,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 + ctx.f27.f64));
	// stfs f8,32(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f8,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f8,f8,f7,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f30.f64));
	// stfs f8,140(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f8,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f30,f8,f7
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f8,f7
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f8.f64 = double(temp.f32);
	// lwz r25,108(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// fmadds f8,f7,f8,f21
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f21.f64));
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f7,f7,f21,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 - ctx.f14.f64));
	// stfs f7,56(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f21,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// lfs f7,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f21,f7,f21
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// lfs f7,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f30,f7,f14,f30
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f14.f64 + ctx.f30.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f30,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f14.f64));
	// lfs f30,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f7,f7,f30,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f27.f64));
	// lfs f27,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f27,f30,f21
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f27,f27,f21,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f21.f64 - ctx.f14.f64));
	// lfs f21,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f8,f21
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f21,88(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// stfs f8,64(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f8,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f8.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f8
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f8.f64));
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f7,f14
	ctx.f14.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f14.f64));
	// stfs f7,68(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f7,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f7.f64));
	// stfs f14,192(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f14.f64));
	// stfs f7,304(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f7,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f7.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f7.f64));
	// stfs f14,276(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// stfs f7,84(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// mulli r25,r6,52
	ctx.r25.s64 = ctx.r6.s64 * 52;
	// fsubs f7,f21,f8
	ctx.f7.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// fadds f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f8,48(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// stfs f7,252(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// mulli r23,r6,116
	ctx.r23.s64 = ctx.r6.s64 * 116;
	// lfs f7,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f8.f64 = double(temp.f32);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r25.u32);
	// fadds f21,f7,f8
	ctx.f21.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfs f8,60(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f8,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f8,f7
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// stfs f8,20(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stfs f21,200(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// stw r23,312(r1)
	PPC_STORE_U32(ctx.r1.u32 + 312, ctx.r23.u32);
	// add r22,r23,r3
	ctx.r22.u64 = ctx.r23.u64 + ctx.r3.u64;
	// mulli r25,r6,12
	ctx.r25.s64 = ctx.r6.s64 * 12;
	// fmadds f8,f21,f7,f14
	ctx.f8.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f14.f64));
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// stw r22,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, ctx.r22.u32);
	// mulli r24,r6,76
	ctx.r24.s64 = ctx.r6.s64 * 76;
	// lwz r22,176(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// add r22,r22,r3
	ctx.r22.u64 = ctx.r22.u64 + ctx.r3.u64;
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f7,f21,f7,f14
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 - ctx.f14.f64));
	// stw r22,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r22.u32);
	// fsubs f21,f30,f8
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f8.f64));
	// fadds f8,f8,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f30.f64));
	// lfsx f30,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f8,36(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f8,f27,f7
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f7.f64));
	// lwz r22,232(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	// fadds f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f27.f64));
	// stfs f7,64(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f7,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lwz r23,152(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lfs f27,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lwz r23,176(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lfsx f14,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f14,f8,f21
	ctx.f14.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fsubs f8,f21,f8
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,96(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f8,72(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f8,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,32(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f8,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,40(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f8,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,56(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f7,f7,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// lfs f21,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f21,f27,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fmuls f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f8,f30,f14,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f14.f64 + ctx.f8.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f7,f30,f14,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f14.f64 - ctx.f7.f64));
	// stfs f7,88(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f30,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f30.f64 = double(temp.f32);
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f7,f5
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// lfs f7,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f30,f7,f30,f21
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 + ctx.f21.f64));
	// stfs f30,20(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f30,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f30,f4
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// lfs f30,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f7,f7,f30,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f27.f64));
	// lfs f30,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f30.f64 = double(temp.f32);
	// mulli r23,r6,108
	ctx.r23.s64 = ctx.r6.s64 * 108;
	// lfs f27,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f27.f64 = double(temp.f32);
	// mulli r22,r6,44
	ctx.r22.s64 = ctx.r6.s64 * 44;
	// fmuls f27,f30,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f4,f30,f4,f14
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f4.f64 + ctx.f14.f64));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f5,f30,f5,f21
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f5.f64 - ctx.f21.f64));
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// lfs f30,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f21,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f21.f64 + ctx.f27.f64));
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f8,f21
	ctx.f27.f64 = double(float(ctx.f8.f64 - ctx.f21.f64));
	// fadds f8,f21,f8
	ctx.f8.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// fsubs f21,f14,f7
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f7.f64));
	// fadds f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// stfs f14,140(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fsubs f14,f21,f27
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// fadds f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f8,f21,f8
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// stfs f8,264(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f8,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f21,f7,f8
	ctx.f21.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// stfs f21,240(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fadds f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// stfs f8,24(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f8,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f8.f64 = double(temp.f32);
	// fadds f21,f14,f8
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f8.f64));
	// fsubs f7,f8,f14
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f14.f64));
	// lfs f8,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f14,f27,f8
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f8.f64));
	// fadds f8,f8,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f27.f64));
	// stfs f8,20(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f8,f7,f12
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f7,f21,f12
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f27,f14,f12
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// stfs f21,92(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f14.f64));
	// fadds f14,f30,f4
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f30,20(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f30,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// stfs f30,44(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f30,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// stfs f30,80(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f14,f30,f21
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f30.f64 - ctx.f21.f64));
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,96(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f14,f30,f5
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// lfs f30,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// lfsx f21,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,20(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f14,f4,f5
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfs f30,44(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfsx f30,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// stfs f5,72(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmuls f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfsx f21,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f5,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f5.f64 = double(temp.f32);
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fmuls f14,f21,f5
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f5,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f5,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f0,f5,f0,f30
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f30.f64));
	// lfs f30,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f13,f5,f13,f4
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f4.f64));
	// lfs f4,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f4,f5,f14
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 + ctx.f14.f64));
	// fmsubs f4,f4,f30,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 - ctx.f21.f64));
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// fadds f30,f5,f13
	ctx.f30.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// fsubs f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f5.f64));
	// fadds f5,f4,f0
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f0.f64));
	// fsubs f0,f0,f4
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f4.f64));
	// fadds f4,f30,f21
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// fsubs f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 - ctx.f30.f64));
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f21,f5
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// stfs f30,160(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f30,f0,f13
	ctx.f30.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// stfs f14,248(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fsubs f13,f5,f21
	ctx.f13.f64 = double(float(ctx.f5.f64 - ctx.f21.f64));
	// lfs f5,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f5.f64 = double(temp.f32);
	// stfs f13,156(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f13,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f4,f13
	ctx.f13.f64 = double(float(ctx.f4.f64 + ctx.f13.f64));
	// fadds f5,f14,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 + ctx.f5.f64));
	// stfs f5,20(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f5,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f21,f30,f5
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// fadds f30,f5,f30
	ctx.f30.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// lfs f5,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f14,f5,f0
	ctx.f14.f64 = double(float(ctx.f5.f64 - ctx.f0.f64));
	// fadds f0,f0,f5
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f5.f64));
	// fmuls f5,f21,f12
	ctx.f5.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// stfs f5,172(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f21,f30,f12
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// stfs f21,32(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f5,f14,f12
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f5,164(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// stfs f0,52(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f0,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
	// fadds f5,f0,f17
	ctx.f5.f64 = double(float(ctx.f0.f64 + ctx.f17.f64));
	// fadds f0,f13,f5
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f5.f64));
	// fsubs f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f5.f64));
	// lfs f5,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f6
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfs f30,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f14,f30,f5
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfs f5,100(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f5,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f30,f5,f0
	ctx.f30.f64 = double(float(ctx.f5.f64 - ctx.f0.f64));
	// stfsx f30,r31,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f30.f64 = double(temp.f32);
	// fadds f0,f0,f5
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f5.f64));
	// fsubs f14,f13,f30
	ctx.f14.f64 = double(float(ctx.f13.f64 - ctx.f30.f64));
	// stfsx f14,r8,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f30.f64));
	// stfsx f13,r5,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// stfs f0,0(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f0,r9,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// stfsx f0,r10,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// stfs f0,40(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f0,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f0,f7
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f7.f64));
	// stfs f0,20(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f0,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f0,f21
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f21.f64));
	// stfs f0,36(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f13,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f0,56(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f0,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f0.f64 = double(temp.f32);
	// fadds f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f9.f64));
	// lfs f13,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f5,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f5.f64 = double(temp.f32);
	// lfs f30,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fsubs f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// lfs f21,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f11
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f11.f64));
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f0,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f0,f11,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64 + ctx.f13.f64));
	// lfs f13,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f13,f13,f10,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 - ctx.f5.f64));
	// fmuls f5,f30,f12
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// stfs f5,64(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f5,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f5,f5,f11,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 - ctx.f21.f64));
	// stfs f5,72(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f5,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f5,f10,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f14.f64));
	// stfs f5,68(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f30,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f30.f64 = double(temp.f32);
	// lfs f5,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfs f5,60(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f5,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f5.f64 = double(temp.f32);
	// lfs f30,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f30.f64 = double(temp.f32);
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfs f5,52(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f5,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f5.f64 = double(temp.f32);
	// lfs f30,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f30.f64 = double(temp.f32);
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfs f5,48(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f5,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f5.f64 = double(temp.f32);
	// fadds f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// stfs f7,92(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f5,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f5.f64 = double(temp.f32);
	// lfs f7,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f7.f64 = double(temp.f32);
	// fadds f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// stfsx f7,r7,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f5,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f5.f64 = double(temp.f32);
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fadds f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// stfsx f7,r30,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f7,f31
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f21,f7,f1
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// lfs f7,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f7,f31
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfs f7,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f7.f64 = double(temp.f32);
	// lfs f30,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f31
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fmadds f7,f7,f1,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 + ctx.f5.f64));
	// lfs f5,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f5,f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 - ctx.f30.f64));
	// lfs f30,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f31,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f31.f64 - ctx.f21.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f30,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f1,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 + ctx.f14.f64));
	// stfs f30,36(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f30,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f21,f18,f30
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f30.f64));
	// stfs f21,80(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f18.f64));
	// stfs f30,132(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f30,f13,f0
	ctx.f30.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f30,96(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f30,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f30,f21
	ctx.f18.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// stfs f0,56(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// lfs f13,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f0.f64 = double(temp.f32);
	// stfs f30,20(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f30,f13,f0
	ctx.f30.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// stfs f18,100(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f30,44(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f30,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f2
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f2
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// lfs f13,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f13,f13,f3,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f30.f64));
	// lfs f30,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f3,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f3.f64 + ctx.f21.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f2,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 + ctx.f18.f64));
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f2,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64 - ctx.f14.f64));
	// stfs f18,92(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f18,f5,f7
	ctx.f18.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// stfs f18,216(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,52(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,60(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f18,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfsx f14,r28,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfsx f18,r25,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f6,f6,f17
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f17.f64));
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f4,f17,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 - ctx.f4.f64));
	// stfsx f14,r24,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f17,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// fsubs f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f5,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f14.f64));
	// stfs f5,100(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f14.f64));
	// stfs f5,248(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// lfs f5,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f14.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f0.f64));
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f14,f21,f13
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f13.f64));
	// fsubs f13,f13,f21
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f21.f64));
	// stfs f13,32(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f13,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f13.f64));
	// stfs f21,20(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// stfs f21,88(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f13,f13,f21
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f21.f64));
	// lfs f21,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f21.f64 = double(temp.f32);
	// fadds f0,f0,f21
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f21.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f30,64(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f21,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// lfs f30,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f21,44(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f21,f6,f18
	ctx.f21.f64 = double(float(ctx.f6.f64 + ctx.f18.f64));
	// stfsx f30,r26,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f18,f6
	ctx.f6.f64 = double(float(ctx.f18.f64 - ctx.f6.f64));
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f4,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 - ctx.f18.f64));
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// fadds f4,f18,f4
	ctx.f4.f64 = double(float(ctx.f18.f64 + ctx.f4.f64));
	// lfs f30,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f18,f17,f26
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// fadds f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// fsubs f17,f15,f24
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// fadds f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// fsubs f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 - ctx.f15.f64));
	// stfsx f15,r23,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fadds f7,f15,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 + ctx.f7.f64));
	// stfsx f7,r27,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f15,f7,f5
	ctx.f15.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// stfsx f15,r22,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// stfsx f7,r29,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f5,f7,f14
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f14.f64));
	// stfsx f5,r9,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f7,f14,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 + ctx.f7.f64));
	// stfsx f7,r30,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f7,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f7.f64 = double(temp.f32);
	// lfs f5,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f15,f7,f5
	ctx.f15.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// stfsx f15,r7,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f5,f7,f13
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f13.f64));
	// stfsx f5,r5,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f7.f64));
	// stfsx f13,r8,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f7,f0,f13
	ctx.f7.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f7,r31,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f0,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f7,f4,f6
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fadds f13,f0,f21
	ctx.f13.f64 = double(float(ctx.f0.f64 + ctx.f21.f64));
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f4,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f5,f0,f21
	ctx.f5.f64 = double(float(ctx.f0.f64 - ctx.f21.f64));
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f0,f13,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f13,f7,f12
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f7,f6,f12
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fmuls f6,f5,f12
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fsubs f5,f18,f0
	ctx.f5.f64 = double(float(ctx.f18.f64 - ctx.f0.f64));
	// stfsx f5,r22,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// fadds f0,f0,f18
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f18.f64));
	// stfsx f0,r29,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f0,f13,f17
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f17.f64));
	// stfsx f0,r27,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f13,f17
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f17.f64));
	// stfsx f0,r23,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f26,f7
	ctx.f0.f64 = double(float(ctx.f26.f64 - ctx.f7.f64));
	// stfsx f0,r28,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f7,f26
	ctx.f0.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// stfsx f0,r25,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f6,f24
	ctx.f0.f64 = double(float(ctx.f6.f64 - ctx.f24.f64));
	// stfsx f0,r26,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f6,f24
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f24.f64));
	// stfsx f0,r24,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fadds f0,f23,f29
	ctx.f0.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// lfs f24,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// lfs f18,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f18.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f26,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f7,f18,f15
	ctx.f7.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// lfs f5,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f13,f26,f17
	ctx.f13.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// lfs f23,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f23.f64 = double(temp.f32);
	// fadds f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// fsubs f5,f20,f5
	ctx.f5.f64 = double(float(ctx.f20.f64 - ctx.f5.f64));
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// fadds f20,f15,f18
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f18,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f19,264(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f6,f21,f14
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,168(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// fmuls f18,f7,f10
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f15,f7,f11
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fsubs f16,f26,f29
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fmuls f17,f4,f10
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmuls f14,f5,f10
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fadds f19,f13,f0
	ctx.f19.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// stfs f29,240(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fmuls f7,f24,f10
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// stfs f7,260(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f26,f20,f10
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// stfs f26,256(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmadds f29,f6,f11,f18
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f11.f64 + ctx.f18.f64));
	// fmsubs f6,f6,f10,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 - ctx.f15.f64));
	// fmuls f26,f16,f12
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmsubs f5,f5,f11,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 - ctx.f17.f64));
	// fmadds f4,f4,f11,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f14.f64));
	// fmuls f7,f19,f12
	ctx.f7.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fmsubs f0,f21,f11,f17
	ctx.f0.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 - ctx.f17.f64));
	// lfs f19,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// lfs f17,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// fmadds f19,f23,f11,f19
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f19.f64));
	// lfs f18,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmsubs f24,f23,f10,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 - ctx.f24.f64));
	// fmadds f23,f20,f11,f21
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f21.f64));
	// fadds f21,f7,f30
	ctx.f21.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// fsubs f7,f30,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// fadds f30,f5,f29
	ctx.f30.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fsubs f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f29.f64));
	// fsubs f29,f4,f6
	ctx.f29.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fadds f20,f26,f17
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f4,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f4.f64 = double(temp.f32);
	// fadds f17,f0,f19
	ctx.f17.f64 = double(float(ctx.f0.f64 + ctx.f19.f64));
	// fadds f4,f18,f4
	ctx.f4.f64 = double(float(ctx.f18.f64 + ctx.f4.f64));
	// fsubs f0,f19,f0
	ctx.f0.f64 = double(float(ctx.f19.f64 - ctx.f0.f64));
	// fsubs f16,f21,f30
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f30.f64));
	// stfsx f16,r10,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	// fadds f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// stfsx f30,r16,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fsubs f30,f29,f20
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f20.f64));
	// stfsx f30,r14,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f20,f29
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f29.f64));
	// lfs f29,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f29.f64 = double(temp.f32);
	// lfs f16,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,184(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// fsubs f30,f5,f26
	ctx.f30.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// stfsx f30,r15,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// lfs f26,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f30,f29,f27
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// lfs f27,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f27.f64 = double(temp.f32);
	// stfsx f5,r10,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,320(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	// fsubs f5,f7,f6
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fadds f21,f27,f28
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f28,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f28.f64 = double(temp.f32);
	// fadds f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfs f27,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f20,f28,f9
	ctx.f20.f64 = double(float(ctx.f28.f64 - ctx.f9.f64));
	// lfs f28,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f5,r10,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// fmuls f14,f28,f11
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// lfs f9,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f9.f64 = double(temp.f32);
	// lfs f5,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f28,f28,f10
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// stfs f28,244(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fadds f28,f13,f27
	ctx.f28.f64 = double(float(ctx.f13.f64 + ctx.f27.f64));
	// fsubs f6,f4,f17
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f17.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,288(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	// lfs f7,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f9,f11
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// fadds f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fsubs f5,f26,f8
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f8.f64));
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// stfs f9,252(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// stfsx f6,r10,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f13,f27,f13
	ctx.f13.f64 = double(float(ctx.f27.f64 - ctx.f13.f64));
	// lfs f6,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f6.f64 = double(temp.f32);
	// fadds f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// lfs f27,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f9,f24,f23
	ctx.f9.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fadds f6,f6,f16
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f16.f64));
	// fsubs f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// fmuls f24,f21,f12
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmsubs f21,f22,f10,f15
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f15.f64));
	// lfs f15,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f22,f11,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f15.f64));
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f23,f20,f12
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmadds f20,f19,f10,f14
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f14.f64));
	// lfs f18,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f19,f11,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f15.f64));
	// lwz r10,336(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	// fmuls f14,f30,f1
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// lwz r9,300(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// fmuls f15,f30,f31
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fmuls f30,f29,f3
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// stfs f30,200(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f4,f17,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 + ctx.f4.f64));
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfsx f4,r21,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// fmuls f17,f6,f3
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f4,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f16,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// fmuls f16,f7,f3
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// fmuls f29,f29,f2
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f2.f64));
	// fmsubs f30,f5,f1,f15
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 - ctx.f15.f64));
	// fmadds f5,f5,f31,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 + ctx.f14.f64));
	// fmsubs f7,f7,f2,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f2.f64 - ctx.f17.f64));
	// fmadds f6,f6,f2,f16
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// stfs f29,200(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmadds f29,f8,f2,f17
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 + ctx.f17.f64));
	// fsubs f17,f9,f28
	ctx.f17.f64 = double(float(ctx.f9.f64 - ctx.f28.f64));
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,280(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// fadds f9,f28,f9
	ctx.f9.f64 = double(float(ctx.f28.f64 + ctx.f9.f64));
	// stfsx f9,r19,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f0,f13
	ctx.f9.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f13,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f28,f25,f23
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,284(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stfsx f0,r20,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f27,f26
	ctx.f0.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// stfsx f0,r17,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// fadds f0,f26,f27
	ctx.f0.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fadds f27,f20,f21
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// subf r4,r9,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r9.s64;
	// fsubs f26,f20,f21
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfsx f0,r10,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f0,f13,f24
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f24.f64));
	// fadds f13,f24,f13
	ctx.f13.f64 = double(float(ctx.f24.f64 + ctx.f13.f64));
	// lwz r10,272(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// fsubs f24,f22,f19
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fadds f9,f23,f25
	ctx.f9.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fmuls f21,f18,f1
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fadds f25,f19,f22
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fmuls f19,f4,f1
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stw r10,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r10.u32);
	// fadds f23,f27,f0
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f0.f64));
	// fsubs f0,f0,f27
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f27.f64));
	// fadds f22,f24,f28
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// fmadds f4,f4,f31,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64 + ctx.f21.f64));
	// fadds f27,f25,f13
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f13.f64));
	// fadds f24,f29,f7
	ctx.f24.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fadds f20,f26,f9
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f9.f64));
	// fsubs f7,f7,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// fmsubs f19,f18,f31,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f31.f64 - ctx.f19.f64));
	// fsubs f9,f9,f26
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f26.f64));
	// fsubs f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f25.f64));
	// fsubs f29,f27,f24
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f8,f8,f3,f17
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 - ctx.f17.f64));
	// fsubs f21,f6,f8
	ctx.f21.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// fadds f6,f4,f30
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// fsubs f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// lwz r10,152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// fsubs f24,f7,f9
	ctx.f24.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fadds f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fsubs f7,f13,f8
	ctx.f7.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// fadds f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fsubs f8,f23,f6
	ctx.f8.f64 = double(float(ctx.f23.f64 - ctx.f6.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,308(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// fsubs f30,f19,f5
	ctx.f30.f64 = double(float(ctx.f19.f64 - ctx.f5.f64));
	// fadds f8,f6,f23
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f23.f64));
	// fadds f5,f19,f5
	ctx.f5.f64 = double(float(ctx.f19.f64 + ctx.f5.f64));
	// fsubs f26,f21,f20
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f25,f20,f21
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,232(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	// fsubs f8,f4,f28
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// fsubs f6,f30,f22
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// stfs f6,0(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,224(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// fadds f6,f22,f30
	ctx.f6.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// stfs f6,0(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,180(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// fadds f8,f28,f4
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fsubs f8,f0,f5
	ctx.f8.f64 = double(float(ctx.f0.f64 - ctx.f5.f64));
	// fadds f0,f5,f0
	ctx.f0.f64 = double(float(ctx.f5.f64 + ctx.f0.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,108(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,76(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// stfs f27,0(r18)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// stfs f26,0(r10)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,332(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// stfs f25,0(r10)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,340(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// stfs f24,0(r10)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,28(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// stfs f9,0(r10)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,348(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// stfs f7,0(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,16(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f13,0(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,356(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d4f3c0
	if (!ctx.cr0.eq) goto loc_82D4F3C0;
loc_82D50B58:
	// addi r1,r1,656
	ctx.r1.s64 = ctx.r1.s64 + 656;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D50B64;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D50B68"))) PPC_WEAK_FUNC(sub_82D50B68);
PPC_FUNC_IMPL(__imp__sub_82D50B68) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1448
	ctx.r5.s64 = ctx.r11.s64 + -1448;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,-3256
	ctx.r4.s64 = ctx.r11.s64 + -3256;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D50B80"))) PPC_WEAK_FUNC(sub_82D50B80);
PPC_FUNC_IMPL(__imp__sub_82D50B80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D50B88;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D50B90;
	__savefpr_14(ctx, base);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d513c0
	if (!ctx.cr6.lt) goto loc_82D513C0;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r25,r7,r8
	ctx.r25.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// stw r10,-312(r1)
	PPC_STORE_U32(ctx.r1.u32 + -312, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f8,136(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
loc_82D50BC8:
	// lfs f0,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r6,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r9,r6,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r7,r6,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f13,f12
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f2,f0,f11
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f31,f13,f11
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f0,f12
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f7,f12
	ctx.f28.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f27,f7,f11
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f5,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f6,f11
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f30,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f6,f12
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f29,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f24,f0,f7
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f13,f6
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// lfsx f15,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f23,f0,f6
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfsx f16,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f1,f2
	ctx.f14.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmuls f21,f13,f7
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// mulli r5,r6,40
	ctx.r5.s64 = ctx.r6.s64 * 40;
	// fsubs f14,f3,f31
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f3,-340(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfs f3,-352(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fsubs f3,f28,f26
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fadds f2,f25,f27
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f1,f25,f27
	ctx.f1.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f31,f26,f28
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f28,f24,f22
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f25,f22,f24
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f27,f21,f23
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f26,f21,f23
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fmuls f20,f5,f12
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f19,f5,f11
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f23,f13,f2
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f22,f0,f1
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmadds f20,f4,f11,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f20.f64));
	// fmsubs f19,f4,f12,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 - ctx.f19.f64));
	// lfs f24,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f21,f18,f24
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// fmuls f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// fmuls f24,f0,f3
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmadds f21,f17,f14,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f17,f14,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 - ctx.f18.f64));
	// fsubs f17,f24,f23
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-336(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fmuls f23,f0,f2
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f24,f13,f3
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fadds f14,f23,f24
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f14,-328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f24,-332(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f23,f13,f1
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmuls f24,f0,f31
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-376(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f24,f13,f31
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fadds f23,f22,f24
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f21,f30
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f22,-344(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fsubs f22,f29,f18
	ctx.f22.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// fmuls f21,f15,f3
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// mulli r8,r6,48
	ctx.r8.s64 = ctx.r6.s64 * 48;
	// fmuls f18,f15,f2
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// add r23,r7,r4
	ctx.r23.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmadds f2,f16,f2,f21
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f21.f64));
	// lfsx f15,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-384(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfsx f15,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// add r24,r7,r3
	ctx.r24.u64 = ctx.r7.u64 + ctx.r3.u64;
	// stfs f15,-356(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// add r28,r5,r4
	ctx.r28.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmsubs f3,f16,f3,f18
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f18.f64));
	// add r29,r5,r3
	ctx.r29.u64 = ctx.r5.u64 + ctx.r3.u64;
	// stfs f3,-364(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// mulli r31,r6,56
	ctx.r31.s64 = ctx.r6.s64 * 56;
	// lfs f21,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-348(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// lfs f3,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f1
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f1,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f1.f64 = double(temp.f32);
	// lfs f16,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f16,f1
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// fmuls f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// stfs f1,-340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// add r22,r31,r3
	ctx.r22.u64 = ctx.r31.u64 + ctx.r3.u64;
	// mulli r30,r6,24
	ctx.r30.s64 = ctx.r6.s64 * 24;
	// fmadds f21,f3,f31,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f21.f64));
	// add r19,r30,r4
	ctx.r19.u64 = ctx.r30.u64 + ctx.r4.u64;
	// add r20,r30,r3
	ctx.r20.u64 = ctx.r30.u64 + ctx.r3.u64;
	// add r21,r31,r4
	ctx.r21.u64 = ctx.r31.u64 + ctx.r4.u64;
	// mulli r7,r6,60
	ctx.r7.s64 = ctx.r6.s64 * 60;
	// lfs f18,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f27
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f3,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f3.f64 = double(temp.f32);
	// stfs f18,-348(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fmsubs f3,f3,f31,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 - ctx.f15.f64));
	// stfs f3,-360(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f3,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f31,f3,f25
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f3,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f3.f64 = double(temp.f32);
	// fmr f1,f3
	ctx.f1.f64 = ctx.f3.f64;
	// lfs f3,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f18,f3,f1,f16
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f1.f64 + ctx.f16.f64));
	// lfs f16,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f16.f64 = double(temp.f32);
	// lfs f3,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f3,f1,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f1.f64 - ctx.f16.f64));
	// stfs f3,-340(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f1,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f3,f20
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// lfs f15,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f25,f1,f25,f15
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f25.f64 + ctx.f15.f64));
	// fmuls f15,f3,f19
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// fmsubs f3,f1,f27,f31
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 - ctx.f31.f64));
	// stfs f3,-384(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f31,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f27,f31,f28
	ctx.f27.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// lfs f1,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f3,f1,f28
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f3,-348(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f3,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f28,f3,f19,f16
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f19,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f3,f3,f20,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f20.f64 - ctx.f15.f64));
	// fmadds f1,f1,f26,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f21,f18
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// lfs f18,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fadds f18,f25,f2
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fsubs f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// lfs f25,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f25,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfs f16,-364(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// fadds f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f25.f64));
	// fsubs f16,f27,f20
	ctx.f16.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// lfs f15,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f15.f64 = double(temp.f32);
	// mulli r31,r6,28
	ctx.r31.s64 = ctx.r6.s64 * 28;
	// fmsubs f31,f31,f26,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f26.f64 - ctx.f15.f64));
	// lfsx f20,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f26,f28,f1
	ctx.f26.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// stfs f20,-340(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fadds f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// mulli r30,r6,12
	ctx.r30.s64 = ctx.r6.s64 * 12;
	// fsubs f28,f3,f31
	ctx.f28.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// lfsx f31,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// mulli r5,r6,44
	ctx.r5.s64 = ctx.r6.s64 * 44;
	// fadds f15,f28,f26
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// stfs f15,-368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfs f28,-372(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfsx f28,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f31,f4
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// stfs f28,-348(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// rlwinm r27,r6,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f28,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,-384(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// add r18,r27,r3
	ctx.r18.u64 = ctx.r27.u64 + ctx.r3.u64;
	// lfsx f28,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// add r17,r27,r4
	ctx.r17.u64 = ctx.r27.u64 + ctx.r4.u64;
	// stfs f28,-360(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// mulli r27,r6,52
	ctx.r27.s64 = ctx.r6.s64 * 52;
	// lfsx f28,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,-380(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fmuls f28,f31,f5
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f5.f64));
	// lfs f31,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f20,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f15,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f20,-352(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fmuls f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64));
	// stfs f15,-356(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// lfs f31,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f4,f31,f4,f28
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f4.f64 + ctx.f28.f64));
	// fmsubs f31,f31,f5,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f5.f64 - ctx.f26.f64));
	// lfs f28,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f28.f64 = double(temp.f32);
	// lfs f5,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// stfs f5,-340(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fmr f5,f28
	ctx.f5.f64 = ctx.f28.f64;
	// lfs f28,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f28,f28,f24,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f24.f64 + ctx.f15.f64));
	// fmsubs f26,f26,f24,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 - ctx.f20.f64));
	// lfs f24,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f20,f24,f7
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// fmuls f15,f24,f6
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// lfs f24,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f5,f23,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 + ctx.f24.f64));
	// lfs f5,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f5,f5,f23,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f14.f64));
	// stfs f5,-340(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f5,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f5,f12
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f23,-348(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fmr f23,f14
	ctx.f23.f64 = ctx.f14.f64;
	// fmadds f6,f23,f6,f20
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f20.f64));
	// fmsubs f7,f23,f7,f15
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 - ctx.f15.f64));
	// fsubs f23,f4,f24
	ctx.f23.f64 = double(float(ctx.f4.f64 - ctx.f24.f64));
	// fadds f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// fsubs f24,f6,f28
	ctx.f24.f64 = double(float(ctx.f6.f64 - ctx.f28.f64));
	// fadds f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f28.f64));
	// fsubs f28,f7,f26
	ctx.f28.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// fadds f26,f7,f26
	ctx.f26.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// fsubs f14,f4,f6
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// lfs f15,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f31,f15
	ctx.f20.f64 = double(float(ctx.f31.f64 - ctx.f15.f64));
	// fadds f31,f15,f31
	ctx.f31.f64 = double(float(ctx.f15.f64 + ctx.f31.f64));
	// fadds f15,f24,f20
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// fsubs f7,f31,f26
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// stfs f7,-308(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fsubs f20,f23,f28
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f28.f64));
	// fadds f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f23.f64));
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f7,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// add r15,r27,r3
	ctx.r15.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fmadds f11,f7,f11,f23
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f23.f64));
	// stfs f11,-324(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f11,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f11.f64 = double(temp.f32);
	// add r27,r27,r4
	ctx.r27.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fadds f23,f11,f16
	ctx.f23.f64 = double(float(ctx.f11.f64 + ctx.f16.f64));
	// lfs f11,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f27,f11
	ctx.f11.f64 = double(float(ctx.f27.f64 - ctx.f11.f64));
	// stfs f11,-340(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// mulli r16,r6,20
	ctx.r16.s64 = ctx.r6.s64 * 20;
	// fadds f11,f2,f22
	ctx.f11.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// fmsubs f12,f7,f12,f5
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 - ctx.f5.f64));
	// stfs f12,-320(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fmuls f12,f15,f8
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// stfs f12,-348(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f7,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f12,f30,f7
	ctx.f12.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// add r14,r16,r3
	ctx.r14.u64 = ctx.r16.u64 + ctx.r3.u64;
	// fmuls f7,f23,f10
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// add r16,r16,r4
	ctx.r16.u64 = ctx.r16.u64 + ctx.r4.u64;
	// mulli r26,r6,36
	ctx.r26.s64 = ctx.r6.s64 * 36;
	// stw r16,-380(r1)
	PPC_STORE_U32(ctx.r1.u32 + -380, ctx.r16.u32);
	// lfs f5,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f5.f64 = double(temp.f32);
	// stw r27,-340(r1)
	PPC_STORE_U32(ctx.r1.u32 + -340, ctx.r27.u32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// add r27,r26,r3
	ctx.r27.u64 = ctx.r26.u64 + ctx.r3.u64;
	// add r26,r26,r4
	ctx.r26.u64 = ctx.r26.u64 + ctx.r4.u64;
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f20,f9,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 + ctx.f23.f64));
	// stfs f23,-376(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fadds f23,f7,f12
	ctx.f23.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// stfs f23,-316(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// stfs f12,-348(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f7,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fadds f12,f11,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// stfs f12,-352(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fsubs f12,f11,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// lfs f5,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f23,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f0,f7,f0
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f7.f64 = double(temp.f32);
	// stfs f0,-332(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmr f0,f7
	ctx.f0.f64 = ctx.f7.f64;
	// stfs f12,-360(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f12,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lwz r16,-340(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	// lfs f11,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lwz r16,-380(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	// stfs f11,-356(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fmuls f11,f11,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// fmuls f23,f12,f23
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fmadds f12,f12,f0,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f11.f64));
	// stfs f12,-336(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f11,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f11,f11,f13,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f5,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f13,f7,f13,f5
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 - ctx.f5.f64));
	// lfs f7,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f0,f12,f0,f23
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f23.f64));
	// lfs f12,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f23,f12,f17
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f0,-384(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f0,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f17,f0,f17
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// fmadds f0,f0,f7,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 + ctx.f23.f64));
	// lfs f23,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f12,f12,f7,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 - ctx.f17.f64));
	// lfs f17,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f5,f17,f13
	ctx.f5.f64 = double(float(ctx.f17.f64 - ctx.f13.f64));
	// fadds f13,f13,f17
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f17.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f7,f23,f11
	ctx.f7.f64 = double(float(ctx.f23.f64 - ctx.f11.f64));
	// fadds f11,f11,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f23.f64));
	// fsubs f23,f0,f17
	ctx.f23.f64 = double(float(ctx.f0.f64 - ctx.f17.f64));
	// fadds f0,f0,f17
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f17.f64));
	// lfs f17,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f12,f17
	ctx.f17.f64 = double(float(ctx.f12.f64 - ctx.f17.f64));
	// stfs f17,-380(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f17,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// fadds f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f17.f64));
	// fadds f17,f23,f5
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// stfs f17,-384(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// stfs f5,-356(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fadds f31,f26,f31
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// lfs f26,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f26.f64 = double(temp.f32);
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfs f26,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// fsubs f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f2.f64));
	// fsubs f17,f11,f0
	ctx.f17.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfs f17,-328(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fadds f11,f6,f4
	ctx.f11.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// fadds f4,f25,f29
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fadds f6,f3,f19
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fmuls f26,f26,f10
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f17,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f7,f17
	ctx.f17.f64 = double(float(ctx.f7.f64 - ctx.f17.f64));
	// stfs f17,-320(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f17,f13,f12
	ctx.f17.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// stfs f17,-324(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f5,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f5.f64 = double(temp.f32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fmuls f23,f5,f8
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f17,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f17.f64 = double(temp.f32);
	// fadds f7,f17,f7
	ctx.f7.f64 = double(float(ctx.f17.f64 + ctx.f7.f64));
	// fmsubs f12,f20,f8,f15
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 - ctx.f15.f64));
	// lfs f20,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f20,f8
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f20,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f20.f64 = double(temp.f32);
	// fadds f30,f20,f30
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// lfs f20,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f24,f8
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// lfs f5,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f5,f8
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// fmsubs f5,f5,f9,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 - ctx.f23.f64));
	// lfs f23,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// stfs f23,-380(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f23,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 - ctx.f5.f64));
	// lfs f23,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f9,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64 + ctx.f17.f64));
	// fadds f17,f1,f21
	ctx.f17.f64 = double(float(ctx.f1.f64 + ctx.f21.f64));
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfsx f22,r31,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfsx f22,r5,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmadds f22,f7,f9,f16
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 + ctx.f16.f64));
	// lfs f16,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f16.f64 = double(temp.f32);
	// fadds f5,f5,f16
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f16.f64));
	// stfsx f5,r8,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f5,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f20
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f20.f64));
	// lfs f20,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f9
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// stfs f5,0(r4)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmsubs f5,f28,f9,f15
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 - ctx.f15.f64));
	// fadds f15,f12,f23
	ctx.f15.f64 = double(float(ctx.f12.f64 + ctx.f23.f64));
	// fsubs f12,f12,f23
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f23.f64));
	// fmsubs f7,f7,f8,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 - ctx.f20.f64));
	// lfs f20,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f18,f20
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fadds f20,f17,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fadds f16,f11,f0
	ctx.f16.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// fsubs f11,f4,f6
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f4,f31,f13
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f13.f64));
	// fadds f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f31.f64));
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// fadds f31,f27,f30
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fadds f27,f2,f26
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// fsubs f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// fadds f26,f5,f22
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// fsubs f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// fsubs f23,f20,f16
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// fadds f22,f16,f20
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// lfs f16,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfsx f16,r9,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f16,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f0,f11
	ctx.f20.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// fsubs f16,f12,f16
	ctx.f16.f64 = double(float(ctx.f12.f64 - ctx.f16.f64));
	// stfsx f16,r7,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f16.f64 = double(temp.f32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fadds f12,f12,f16
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f16.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f28,f28,f8
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fadds f12,f15,f12
	ctx.f12.f64 = double(float(ctx.f15.f64 + ctx.f12.f64));
	// stfsx f12,r30,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// stfsx f23,r31,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f17,f4
	ctx.f11.f64 = double(float(ctx.f17.f64 - ctx.f4.f64));
	// stfsx f20,r8,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fsubs f12,f13,f6
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f6.f64));
	// stfsx f0,r5,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fadds f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f6.f64));
	// stfs f22,0(r3)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f0,f4,f17
	ctx.f0.f64 = double(float(ctx.f4.f64 + ctx.f17.f64));
	// stfsx f11,r9,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f4,f3,f19
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f19.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f3,f21,f1
	ctx.f3.f64 = double(float(ctx.f21.f64 - ctx.f1.f64));
	// stfsx f13,r7,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f1,f29,f25
	ctx.f1.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// lfs f6,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f29,f31,f26
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// lfs f12,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f12.f64 = double(temp.f32);
	// lwz r10,-312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	// stfsx f0,r30,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f0,f6,f12
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// lfs f11,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f6.f64));
	// lfs f6,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f13,f14,f11
	ctx.f13.f64 = double(float(ctx.f14.f64 - ctx.f11.f64));
	// stfs f29,0(r19)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fsubs f6,f6,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f18.f64));
	// fmadds f29,f24,f9,f28
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f28.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fadds f11,f11,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f14.f64));
	// subf r4,r10,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r10.s64;
	// fsubs f28,f5,f2
	ctx.f28.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// stfs f28,0(r15)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// fadds f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// stfs f5,0(r28)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f5,f26,f31
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// stfs f5,0(r18)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fsubs f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// fadds f5,f13,f0
	ctx.f5.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// fsubs f0,f6,f4
	ctx.f0.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f13,f4,f6
	ctx.f13.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fadds f6,f29,f7
	ctx.f6.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fsubs f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 - ctx.f7.f64));
	// fsubs f31,f11,f12
	ctx.f31.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fadds f28,f11,f12
	ctx.f28.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// fsubs f12,f1,f3
	ctx.f12.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// fadds f11,f1,f3
	ctx.f11.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fmuls f4,f2,f10
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fsubs f1,f30,f6
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// stfs f1,0(r14)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fsubs f1,f7,f27
	ctx.f1.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// stfs f1,0(r27)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fmuls f3,f31,f10
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// fmuls f2,f28,f10
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// fadds f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f27.f64));
	// stfs f7,0(r21)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// lwz r10,-340(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	// fadds f7,f6,f30
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// stfs f7,0(r23)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fsubs f7,f0,f5
	ctx.f7.f64 = double(float(ctx.f0.f64 - ctx.f5.f64));
	// stfs f7,0(r16)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fsubs f7,f3,f12
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f12.f64));
	// stfs f7,0(r29)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f12,f3,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 + ctx.f12.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fadds f0,f5,f0
	ctx.f0.f64 = double(float(ctx.f5.f64 + ctx.f0.f64));
	// stfs f0,0(r24)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fsubs f0,f13,f2
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// stfs f0,0(r20)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fsubs f0,f4,f11
	ctx.f0.f64 = double(float(ctx.f4.f64 - ctx.f11.f64));
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// stfs f0,0(r22)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fadds f0,f4,f11
	ctx.f0.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// stfs f0,0(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fadds f0,f2,f13
	ctx.f0.f64 = double(float(ctx.f2.f64 + ctx.f13.f64));
	// stfs f0,0(r17)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d50bc8
	if (!ctx.cr0.eq) goto loc_82D50BC8;
loc_82D513C0:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D513C8;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D513D0"))) PPC_WEAK_FUNC(sub_82D513D0);
PPC_FUNC_IMPL(__imp__sub_82D513D0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1376
	ctx.r5.s64 = ctx.r11.s64 + -1376;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,2944
	ctx.r4.s64 = ctx.r11.s64 + 2944;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D513E8"))) PPC_WEAK_FUNC(sub_82D513E8);
PPC_FUNC_IMPL(__imp__sub_82D513E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D513F0;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28ef0
	ctx.lr = 0x82D513F8;
	__savefpr_18(ctx, base);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d516a4
	if (!ctx.cr6.lt) goto loc_82D516A4;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r23,r9,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f6,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f6.f64 = double(temp.f32);
loc_82D51420:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r9,r6,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// mulli r8,r6,28
	ctx.r8.s64 = ctx.r6.s64 * 28;
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f10,f0
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f3,f9,f13
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f9,f0
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f10,f13
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f5,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f4,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// add r31,r9,r3
	ctx.r31.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmuls f31,f12,f13
	ctx.f31.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// add r29,r8,r3
	ctx.r29.u64 = ctx.r8.u64 + ctx.r3.u64;
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// fsubs f26,f8,f3
	ctx.f26.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// lfs f30,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fadds f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// lfs f28,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f2,f7
	ctx.f25.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// lfsx f3,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f28,f12
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// add r30,r9,r4
	ctx.r30.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fmuls f28,f28,f11
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmuls f22,f3,f10
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// add r28,r8,r4
	ctx.r28.u64 = ctx.r8.u64 + ctx.r4.u64;
	// fsubs f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f21,f3,f9
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// rlwinm r5,r6,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r6,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f1,f11,f13,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f1.f64));
	// add r27,r5,r3
	ctx.r27.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fmsubs f31,f11,f0,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f31.f64));
	// fmuls f24,f30,f26
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// lfs f29,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfs f27,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmuls f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// mulli r8,r6,20
	ctx.r8.s64 = ctx.r6.s64 * 20;
	// fmsubs f28,f27,f12,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 - ctx.f28.f64));
	// fmadds f9,f2,f9,f22
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f22.f64));
	// add r25,r26,r3
	ctx.r25.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fmadds f3,f29,f25,f24
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f25.f64 + ctx.f24.f64));
	// mulli r9,r6,24
	ctx.r9.s64 = ctx.r6.s64 * 24;
	// lfsx f25,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f30,f29,f26,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f26.f64 - ctx.f30.f64));
	// fmadds f29,f27,f11,f23
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f23.f64));
	// fmuls f26,f12,f7
	ctx.f26.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// fmuls f27,f12,f8
	ctx.f27.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmsubs f12,f2,f10,f21
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 - ctx.f21.f64));
	// lfsx f22,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f21,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// add r26,r26,r4
	ctx.r26.u64 = ctx.r26.u64 + ctx.r4.u64;
	// add r24,r8,r3
	ctx.r24.u64 = ctx.r8.u64 + ctx.r3.u64;
	// fadds f2,f3,f5
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fsubs f3,f4,f30
	ctx.f3.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// fadds f30,f9,f29
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// lfs f24,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f9,f29,f9
	ctx.f9.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// lfs f23,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fadds f29,f12,f28
	ctx.f29.f64 = double(float(ctx.f12.f64 + ctx.f28.f64));
	// fsubs f12,f28,f12
	ctx.f12.f64 = double(float(ctx.f28.f64 - ctx.f12.f64));
	// lfs f28,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f28,f8
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmuls f19,f28,f7
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// lfs f28,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f10,f11,f8,f26
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f26.f64));
	// lfs f26,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f11,f11,f7,f27
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f27.f64));
	// fadds f27,f12,f9
	ctx.f27.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// fmadds f7,f28,f7,f20
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f7.f64 + ctx.f20.f64));
	// fmsubs f8,f28,f8,f19
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f8.f64 - ctx.f19.f64));
	// fmuls f28,f26,f0
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f20,f25,f10
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// fmuls f19,f23,f10
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fmuls f18,f22,f1
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmadds f13,f24,f13,f28
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f28.f64));
	// fmuls f28,f22,f31
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// fmsubs f0,f24,f0,f26
	ctx.f0.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 - ctx.f26.f64));
	// fsubs f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// fmadds f10,f23,f11,f20
	ctx.f10.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f20.f64));
	// fmsubs f11,f25,f11,f19
	ctx.f11.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f19.f64));
	// fmadds f31,f21,f31,f18
	ctx.f31.f64 = double(float(ctx.f21.f64 * ctx.f31.f64 + ctx.f18.f64));
	// fmsubs f1,f21,f1,f28
	ctx.f1.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 - ctx.f28.f64));
	// fsubs f28,f13,f10
	ctx.f28.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// fadds f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// fsubs f10,f0,f11
	ctx.f10.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// fadds f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fadds f11,f31,f7
	ctx.f11.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// fadds f31,f1,f8
	ctx.f31.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// fsubs f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// fadds f1,f13,f30
	ctx.f1.f64 = double(float(ctx.f13.f64 + ctx.f30.f64));
	// fsubs f26,f28,f10
	ctx.f26.f64 = double(float(ctx.f28.f64 - ctx.f10.f64));
	// fsubs f13,f30,f13
	ctx.f13.f64 = double(float(ctx.f30.f64 - ctx.f13.f64));
	// fadds f30,f11,f2
	ctx.f30.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fsubs f25,f3,f7
	ctx.f25.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// fsubs f24,f4,f31
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// fsubs f23,f5,f8
	ctx.f23.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// fadds f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f28.f64));
	// fadds f9,f0,f29
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// fsubs f0,f29,f0
	ctx.f0.f64 = double(float(ctx.f29.f64 - ctx.f0.f64));
	// fadds f22,f27,f26
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fsubs f26,f30,f1
	ctx.f26.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// stfs f1,0(r3)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f1,f13,f24
	ctx.f1.f64 = double(float(ctx.f13.f64 - ctx.f24.f64));
	// stfsx f1,r9,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f24,f13
	ctx.f13.f64 = double(float(ctx.f24.f64 + ctx.f13.f64));
	// stfsx f13,r8,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f2,f11
	ctx.f11.f64 = double(float(ctx.f2.f64 - ctx.f11.f64));
	// fadds f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fadds f7,f7,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fmuls f13,f22,f6
	ctx.f13.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// fmuls f1,f27,f6
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fsubs f30,f23,f13
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f13.f64));
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f1,f25
	ctx.f30.f64 = double(float(ctx.f1.f64 + ctx.f25.f64));
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f23.f64));
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f13,f1,f25
	ctx.f13.f64 = double(float(ctx.f1.f64 - ctx.f25.f64));
	// stfs f13,0(r24)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fadds f13,f12,f10
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// add r3,r23,r3
	ctx.r3.u64 = ctx.r23.u64 + ctx.r3.u64;
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// subf r4,r23,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r23.s64;
	// fsubs f10,f9,f4
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// stfs f10,0(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f10,f4,f9
	ctx.f10.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// stfs f10,0(r28)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fsubs f10,f11,f0
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfs f10,0(r27)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// stfs f0,0(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fmuls f0,f13,f6
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmuls f13,f12,f6
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// fsubs f12,f8,f0
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f0.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f12,f13,f7
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f7.f64));
	// stfs f12,0(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fadds f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f8.f64));
	// stfs f0,0(r25)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f0,f13,f7
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// lwz r10,3532(r22)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r22.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d51420
	if (!ctx.cr0.eq) goto loc_82D51420;
loc_82D516A4:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28f3c
	ctx.lr = 0x82D516AC;
	__restfpr_18(ctx, base);
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D516B0"))) PPC_WEAK_FUNC(sub_82D516B0);
PPC_FUNC_IMPL(__imp__sub_82D516B0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1312
	ctx.r5.s64 = ctx.r11.s64 + -1312;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,5096
	ctx.r4.s64 = ctx.r11.s64 + 5096;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D516C8"))) PPC_WEAK_FUNC(sub_82D516C8);
PPC_FUNC_IMPL(__imp__sub_82D516C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D516D0;
	__savegprlr_28(ctx, base);
	// stfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f29.u64);
	// stfd f30,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-16
	ctx.r11.s64 = ctx.r11.s64 + -16;
	// bge cr6,0x82d51800
	if (!ctx.cr6.lt) goto loc_82D51800;
	// rlwinm r29,r9,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
loc_82D516FC:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f8,f12,f0
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// mulli r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 * 12;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f3,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f1,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// add r5,r10,r3
	ctx.r5.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fmadds f8,f11,f13,f8
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f8.f64));
	// add r31,r9,r3
	ctx.r31.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r30,r8,r3
	ctx.r30.u64 = ctx.r8.u64 + ctx.r3.u64;
	// fmsubs f7,f11,f0,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f7.f64));
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// lfs f6,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f30,f4,f0
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f29,f2,f12
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmuls f31,f6,f8
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f6,f6,f7
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmadds f13,f3,f13,f30
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f30.f64));
	// fmadds f11,f1,f11,f29
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f29.f64));
	// fmsubs f12,f1,f12,f2
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 - ctx.f2.f64));
	// fmadds f7,f5,f7,f31
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f31.f64));
	// fmsubs f0,f3,f0,f4
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f4.f64));
	// fmsubs f8,f5,f8,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 - ctx.f6.f64));
	// fadds f6,f7,f10
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fsubs f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f7,f11,f13
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fsubs f11,f0,f12
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fadds f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f12,f8,f9
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fsubs f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f7,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// stfs f8,0(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f8,f10,f11
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// stfs f11,0(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fsubs f11,f0,f12
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// stfs f11,0(r5)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// stfsx f0,r8,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f13,f9
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fadds f0,f9,f13
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfsx f0,r10,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,3532(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// subf r4,r29,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r29.s64;
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d516fc
	if (!ctx.cr0.eq) goto loc_82D516FC;
loc_82D51800:
	// lfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f30,-56(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D51810"))) PPC_WEAK_FUNC(sub_82D51810);
PPC_FUNC_IMPL(__imp__sub_82D51810) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1248
	ctx.r5.s64 = ctx.r11.s64 + -1248;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,5832
	ctx.r4.s64 = ctx.r11.s64 + 5832;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D51828"))) PPC_WEAK_FUNC(sub_82D51828);
PPC_FUNC_IMPL(__imp__sub_82D51828) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D51830;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D51838;
	__savefpr_14(ctx, base);
	// stwu r1,-960(r1)
	ea = -960 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r7,504
	ctx.r11.s64 = ctx.r7.s64 * 504;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-504
	ctx.r11.s64 = ctx.r11.s64 + -504;
	// bge cr6,0x82d55050
	if (!ctx.cr6.lt) goto loc_82D55050;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// stw r10,620(r1)
	PPC_STORE_U32(ctx.r1.u32 + 620, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f31,-5448(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -5448);
	ctx.f31.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f1,-5444(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -5444);
	ctx.f1.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f2,-5436(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -5436);
	ctx.f2.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f3,-5440(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -5440);
	ctx.f3.f64 = double(temp.f32);
	// stw r10,576(r1)
	PPC_STORE_U32(ctx.r1.u32 + 576, ctx.r10.u32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f8,-8004(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -8004);
	ctx.f8.f64 = double(temp.f32);
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lfs f9,-8000(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8000);
	ctx.f9.f64 = double(temp.f32);
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f4,-5424(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -5424);
	ctx.f4.f64 = double(temp.f32);
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lfs f5,-5420(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -5420);
	ctx.f5.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lfs f6,-5428(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -5428);
	ctx.f6.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f7,-5432(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -5432);
	ctx.f7.f64 = double(temp.f32);
	// lfs f10,-8008(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -8008);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-8012(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8012);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D518D8:
	// mulli r8,r6,192
	ctx.r8.s64 = ctx.r6.s64 * 192;
	// lfs f30,248(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r7,r6,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f29,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,376(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 376);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f16,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f25,380(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 380);
	ctx.f25.f64 = double(temp.f32);
	// rlwinm r9,r6,6,0,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f22,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// mulli r5,r6,160
	ctx.r5.s64 = ctx.r6.s64 * 160;
	// lfs f21,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f16,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f17,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r10,r6,7,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 7) & 0xFFFFFF80;
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f16,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r31,r6,224
	ctx.r31.s64 = ctx.r6.s64 * 224;
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f18,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f28,f18
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfsx f17,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f20,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f16,f30,f20
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// lfsx f19,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f29,f20
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f20.f64));
	// fmuls f14,f26,f17
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// add r28,r29,r4
	ctx.r28.u64 = ctx.r29.u64 + ctx.r4.u64;
	// mulli r30,r6,96
	ctx.r30.s64 = ctx.r6.s64 * 96;
	// stw r28,624(r1)
	PPC_STORE_U32(ctx.r1.u32 + 624, ctx.r28.u32);
	// fmadds f29,f29,f19,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64 + ctx.f16.f64));
	// fmsubs f30,f30,f19,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f19.f64 - ctx.f20.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// fmadds f27,f27,f20,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 + ctx.f15.f64));
	// fmsubs f28,f28,f20,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f20.f64 - ctx.f18.f64));
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f25,f25,f20,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f20.f64 + ctx.f14.f64));
	// lfs f18,444(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 444);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f26,f26,f20,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 - ctx.f17.f64));
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f21,f21,f20,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f16.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f29,f24
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// fadds f24,f25,f27
	ctx.f24.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fsubs f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fsubs f19,f23,f30
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// fadds f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f23.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fadds f26,f24,f20
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// fsubs f20,f29,f25
	ctx.f20.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fadds f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fadds f23,f19,f27
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f27.f64));
	// fadds f25,f30,f28
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f30,520(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// lfs f30,312(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 312);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// lfs f28,316(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 316);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f30,f16
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f16.f64));
	// fmuls f14,f28,f16
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,440(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 440);
	ctx.f19.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f16,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f30,f30,f16,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f30,52(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmadds f28,f28,f16,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 + ctx.f15.f64));
	// stfs f28,36(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f30,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f19,f30
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// fmuls f15,f18,f30
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfs f30,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f14,f17,f28
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// lfs f28,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// fmr f30,f28
	ctx.f30.f64 = ctx.f28.f64;
	// lfs f28,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f18,f18,f30,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f16.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f30,f19,f30,f15
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 - ctx.f15.f64));
	// stfs f30,20(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f30,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f30,f28
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f28,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f19,f28,f16,f14
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f28,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f28.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f17,f17,f16,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f28,f16
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f21,f16
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f22,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f22,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f15.f64));
	// fmsubs f30,f30,f22,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 - ctx.f14.f64));
	// fsubs f22,f18,f19
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// fsubs f18,f15,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f19,f21
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f14,296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fadds f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f21,496(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fsubs f21,f17,f16
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f21,456(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// fadds f21,f16,f17
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fadds f17,f22,f15
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fadds f18,f14,f19
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f18,588(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f19,384(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// mulli r29,r6,144
	ctx.r29.s64 = ctx.r6.s64 * 144;
	// fmuls f19,f17,f0
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// add r25,r29,r4
	ctx.r25.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,480(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// stfs f19,376(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f22,280(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f18,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// mulli r28,r6,80
	ctx.r28.s64 = ctx.r6.s64 * 80;
	// lfs f19,284(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 284);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// stw r25,632(r1)
	PPC_STORE_U32(ctx.r1.u32 + 632, ctx.r25.u32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f17,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r27,r6,208
	ctx.r27.s64 = ctx.r6.s64 * 208;
	// fmuls f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// fmuls f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// fmuls f18,f19,f18
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// add r24,r28,r4
	ctx.r24.u64 = ctx.r28.u64 + ctx.r4.u64;
	// add r23,r27,r4
	ctx.r23.u64 = ctx.r27.u64 + ctx.r4.u64;
	// mulli r26,r6,240
	ctx.r26.s64 = ctx.r6.s64 * 240;
	// stw r24,640(r1)
	PPC_STORE_U32(ctx.r1.u32 + 640, ctx.r24.u32);
	// stw r23,648(r1)
	PPC_STORE_U32(ctx.r1.u32 + 648, ctx.r23.u32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmr f18,f17
	ctx.f18.f64 = ctx.f17.f64;
	// lfs f17,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f14.f64));
	// stfs f19,32(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f22,f22,f18,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f22,408(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 408);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,412(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 412);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f22,f19
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// fmuls f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f19,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f17,f17,f19,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 - ctx.f15.f64));
	// fmadds f18,f18,f19,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f19,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,412(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 412);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f19,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f19.f64 + ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f22,f22,f19,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f28,f14
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// fadds f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 + ctx.f30.f64));
	// fsubs f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// fadds f17,f14,f15
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fsubs f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// fsubs f16,f28,f18
	ctx.f16.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f16,f30,f22
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// stfs f30,340(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f28,348(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmuls f18,f15,f12
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmuls f28,f17,f12
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmuls f22,f14,f12
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// fadds f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// stfs f16,452(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// mulli r29,r6,112
	ctx.r29.s64 = ctx.r6.s64 * 112;
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// mulli r28,r6,48
	ctx.r28.s64 = ctx.r6.s64 * 48;
	// fsubs f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// stfs f30,548(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// fmsubs f30,f14,f13,f28
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f28.f64));
	// stfs f30,592(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// fmadds f30,f17,f13,f22
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f22.f64));
	// stfs f30,560(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// fmadds f30,f19,f13,f18
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f30,528(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// fmsubs f30,f19,f12,f15
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 - ctx.f15.f64));
	// stfs f30,412(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfsx f30,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,476(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 476);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f28,f30
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// fmuls f14,f22,f30
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// lfs f19,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// add r26,r26,r4
	ctx.r26.u64 = ctx.r26.u64 + ctx.r4.u64;
	// mulli r27,r6,176
	ctx.r27.s64 = ctx.r6.s64 * 176;
	// lfs f30,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// stw r26,636(r1)
	PPC_STORE_U32(ctx.r1.u32 + 636, ctx.r26.u32);
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f30,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,20(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// add r25,r29,r4
	ctx.r25.u64 = ctx.r29.u64 + ctx.r4.u64;
	// lfsx f30,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// add r24,r28,r4
	ctx.r24.u64 = ctx.r28.u64 + ctx.r4.u64;
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// add r23,r27,r4
	ctx.r23.u64 = ctx.r27.u64 + ctx.r4.u64;
	// lfsx f30,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,44(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// stw r25,628(r1)
	PPC_STORE_U32(ctx.r1.u32 + 628, ctx.r25.u32);
	// stw r24,652(r1)
	PPC_STORE_U32(ctx.r1.u32 + 652, ctx.r24.u32);
	// stw r23,644(r1)
	PPC_STORE_U32(ctx.r1.u32 + 644, ctx.r23.u32);
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f22,f22,f30,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 + ctx.f15.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmsubs f30,f28,f30,f14
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f30.f64 - ctx.f14.f64));
	// stfs f30,64(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f30,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f19,f30
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// fmuls f22,f18,f30
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f17,f30
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fmuls f14,f16,f30
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f30,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f28,f18,f30,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f28.f64));
	// stfs f28,32(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmsubs f30,f19,f30,f22
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 - ctx.f22.f64));
	// stfs f30,24(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f30,344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 344);
	ctx.f30.f64 = double(temp.f32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f28,f30,f22
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f28,348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 348);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f28,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f22,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f19,f16,f22,f15
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f15.f64));
	// fmsubs f18,f17,f22,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f22,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f28,f28,f22,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f30,f30,f22,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 - ctx.f15.f64));
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f16,f14
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f14,f19,f28
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// fadds f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// rlwinm r29,r6,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f19,f18,f30
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f30.f64));
	// mulli r28,r6,136
	ctx.r28.s64 = ctx.r6.s64 * 136;
	// fadds f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f18.f64));
	// fadds f18,f14,f17
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// mulli r27,r6,72
	ctx.r27.s64 = ctx.r6.s64 * 72;
	// fadds f18,f28,f16
	ctx.f18.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// stfs f18,288(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fsubs f18,f22,f19
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f28,f16,f28
	ctx.f28.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// fadds f19,f30,f15
	ctx.f19.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// fsubs f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f30.f64));
	// mulli r26,r6,200
	ctx.r26.s64 = ctx.r6.s64 * 200;
	// fmuls f15,f22,f12
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// mulli r25,r6,40
	ctx.r25.s64 = ctx.r6.s64 * 40;
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f12
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// fmadds f14,f18,f13,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f14,472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// fmsubs f18,f18,f12,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f17.f64));
	// lfs f17,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f17,f12
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f14,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// stfs f18,464(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// lfs f18,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f22,f13,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f22,616(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// fmadds f22,f17,f13,f15
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f22,404(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fsubs f22,f28,f30
	ctx.f22.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfs f22,444(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// lfsx f28,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,20(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f22,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f17,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f17,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f17,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f17,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f30,540(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f30,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f17,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f18,f30
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmuls f17,f14,f30
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// lfsx f28,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f22,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f30,f28
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f30,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f30,f28
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f30,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f30,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// stfs f30,20(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmr f30,f28
	ctx.f30.f64 = ctx.f28.f64;
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f18,f30,f17
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f17.f64));
	// stfs f28,192(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f30,f28,f30,f16
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f30.f64 - ctx.f16.f64));
	// stfs f30,68(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f30,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f22,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 + ctx.f15.f64));
	// stfs f30,44(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// mulli r23,r6,232
	ctx.r23.s64 = ctx.r6.s64 * 232;
	// lfs f30,392(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 392);
	ctx.f30.f64 = double(temp.f32);
	// mulli r22,r6,104
	ctx.r22.s64 = ctx.r6.s64 * 104;
	// lfs f28,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f28.f64 = double(temp.f32);
	// lfs f18,396(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 396);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f30,f28
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// stfs f28,32(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f28,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f22,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f17,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f16.f64));
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,396(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 396);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f17.f64 + ctx.f15.f64));
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// mulli r24,r6,168
	ctx.r24.s64 = ctx.r6.s64 * 168;
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f30,f17,f15
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f14,f15
	ctx.f30.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f30,88(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f30,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,36(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f30,f16,f22
	ctx.f30.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f30,f17,f18
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f30,24(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f30,328(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 328);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f30,80(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f30,456(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 456);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,48(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f30,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f30,f16
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,180(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f17,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// fsubs f17,f16,f18
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f17,564(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,368(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 + ctx.f16.f64));
	// lfsx f16,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f16,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmsubs f30,f30,f18,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfsx f16,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// stfs f30,56(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f30,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f18,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f16,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f30
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f16,332(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 332);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f30,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f30,f17
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f17.f64));
	// lfs f30,460(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 460);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f17,f30,f17
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f17.f64));
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f18,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 + ctx.f15.f64));
	// stfs f30,24(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f30,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f18,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 - ctx.f16.f64));
	// stfs f30,52(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// lfs f30,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f30,f18
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// lfs f30,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f30,460(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 460);
	ctx.f30.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f30,f30,f18,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 + ctx.f14.f64));
	// fmsubs f18,f15,f18,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fsubs f14,f30,f17
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f17.f64));
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// fsubs f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f18,f30
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f30.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f18.f64));
	// stfs f30,96(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,200(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,228(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fadds f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f16,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// stfs f30,324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f30,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f30.f64 = double(temp.f32);
	// lfs f16,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// stfs f30,332(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// fadds f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// stfs f30,300(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fadds f30,f17,f14
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f18,572(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// mulli r19,r6,56
	ctx.r19.s64 = ctx.r6.s64 * 56;
	// mulli r18,r6,184
	ctx.r18.s64 = ctx.r6.s64 * 184;
	// fsubs f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fadds f30,f18,f16
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// lfs f18,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f18.f64 = double(temp.f32);
	// mulli r21,r6,248
	ctx.r21.s64 = ctx.r6.s64 * 248;
	// mulli r20,r6,120
	ctx.r20.s64 = ctx.r6.s64 * 120;
	// mulli r17,r6,24
	ctx.r17.s64 = ctx.r6.s64 * 24;
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f15,584(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f15,f30
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// fsubs f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f15,380(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfsx f16,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f16,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f16,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,488(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f30,600(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// lfsx f30,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f16,f30
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f17,328(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fadds f17,f22,f28
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f16,492(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,512(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// fmuls f28,f14,f0
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfsx f22,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f16,f30
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f30,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f30.f64 = double(temp.f32);
	// stfs f28,408(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// fmuls f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// lfsx f28,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64));
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// stfs f17,580(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// lfsx f17,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f30,f16,f28,f15
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f28.f64 + ctx.f15.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmsubs f28,f16,f28,f14
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f28.f64 - ctx.f14.f64));
	// stfs f28,72(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f28,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f28,f16
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// lfs f22,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f28,f18,f17,f14
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// lfs f18,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f14.f64));
	// stfs f18,124(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// mulli r16,r6,152
	ctx.r16.s64 = ctx.r6.s64 * 152;
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// mulli r15,r6,216
	ctx.r15.s64 = ctx.r6.s64 * 216;
	// lfs f18,360(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 360);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f18,364(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 364);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f22,f17,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f17.f64 + ctx.f15.f64));
	// fmsubs f18,f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f16.f64));
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,364(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 364);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,360(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 360);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f14.f64));
	// mulli r14,r6,88
	ctx.r14.s64 = ctx.r6.s64 * 88;
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f28,f30
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f15,f17,f22
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f28,296(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 296);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,24(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fadds f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfsx f14,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f16,f28,f15
	ctx.f16.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fadds f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// lfs f16,424(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 424);
	ctx.f16.f64 = double(temp.f32);
	// stfs f28,172(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// stfs f28,316(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f14,f28
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f28.f64));
	// fmuls f16,f16,f28
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// fsubs f28,f30,f18
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfs f28,604(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// fadds f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// lfsx f18,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f18,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f18,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// stfs f30,360(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfsx f30,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmadds f18,f14,f30,f16
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f30.f64 + ctx.f16.f64));
	// stfs f18,52(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f18,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f30,f18,f30,f15
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 - ctx.f15.f64));
	// stfs f30,48(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f28,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f30,f28
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f30,300(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 300);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f30,f28
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f28,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f28,f18
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f28,428(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 428);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f28,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,124
	ctx.r14.s64 = ctx.r6.s64 * 124;
	// fmadds f30,f30,f28,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f28.f64 + ctx.f16.f64));
	// stfs f30,80(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f30,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f28,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f28.f64 - ctx.f15.f64));
	// stfs f30,24(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f30.f64 = double(temp.f32);
	// stw r14,396(r1)
	PPC_STORE_U32(ctx.r1.u32 + 396, ctx.r14.u32);
	// fmuls f16,f30,f28
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f30,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f28,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,428(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 428);
	ctx.f30.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f30,f30,f28,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f28.f64 + ctx.f14.f64));
	// fmsubs f28,f15,f28,f18
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f28.f64 - ctx.f18.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,68(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f14,f18,f30
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// fsubs f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// fadds f18,f16,f28
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f28.f64));
	// fsubs f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,304(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,352(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f18,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f18,236(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f16,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,372(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,248(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f16,f28,f30
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f18,496(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// lfs f30,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,252
	ctx.r14.s64 = ctx.r6.s64 * 252;
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f30,24(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f30,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f14.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfs f28,28(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f28,f22,f17
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f22,f28
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// fsubs f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f14,f28,f16
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// fsubs f28,f16,f28
	ctx.f28.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// stfs f16,176(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fadds f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// stfs f30,260(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f30,f17,f0
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f30,416(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f30,f22,f0
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f30,364(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fmuls f30,f14,f0
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f30,424(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fmuls f30,f28,f0
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// stfs f30,400(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// lfs f28,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f30.f64 = double(temp.f32);
	// fadds f22,f28,f30
	ctx.f22.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f22,536(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f30,428(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// lfsx f30,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f28,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,396(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// fmuls f16,f18,f30
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfsx f22,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,60
	ctx.r14.s64 = ctx.r6.s64 * 60;
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,188
	ctx.r14.s64 = ctx.r6.s64 * 188;
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f17,500(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// lfs f30,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f30,f22
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// lfs f30,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f30,f22,f28,f16
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f16.f64));
	// fmsubs f28,f18,f28,f17
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 - ctx.f17.f64));
	// stfs f28,124(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f18,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f14.f64));
	// stfs f28,88(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f15,f22
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f22.f64));
	// fmuls f16,f28,f22
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f22,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f22,f22,f18,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f18,368(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 368);
	ctx.f18.f64 = double(temp.f32);
	// stfs f22,196(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// mulli r14,r6,28
	ctx.r14.s64 = ctx.r6.s64 * 28;
	// fmuls f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f22.f64));
	// lfs f18,372(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 372);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fmr f22,f18
	ctx.f22.f64 = ctx.f18.f64;
	// lfs f18,372(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 372);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f16,f15,f22,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f22.f64 - ctx.f16.f64));
	// stfs f16,92(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmadds f28,f28,f22,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f17.f64));
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f17,f18,f22,f14
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 + ctx.f14.f64));
	// lfs f18,368(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 368);
	ctx.f18.f64 = double(temp.f32);
	// stfs f17,108(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f18,f22,f14
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f22,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// lfs f18,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// stfs f15,192(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f14,304(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f18,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,432(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// stfs f16,140(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f14,308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 308);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f17,f22
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f22,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r14,r6,156
	ctx.r14.s64 = ctx.r6.s64 * 156;
	// fmuls f15,f18,f22
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f22.f64));
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,220
	ctx.r14.s64 = ctx.r6.s64 * 220;
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,92
	ctx.r14.s64 = ctx.r6.s64 * 92;
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f22.f64));
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmr f22,f14
	ctx.f22.f64 = ctx.f14.f64;
	// fmadds f18,f18,f22,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 + ctx.f16.f64));
	// stfs f18,80(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f18,f22,f15
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f22,436(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 436);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f18
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f22,308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,132
	ctx.r14.s64 = ctx.r6.s64 * 132;
	// fmadds f22,f22,f18,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f14.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f18,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 - ctx.f17.f64));
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f22,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,436(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 436);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f22,f22,f18,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f16.f64));
	// fmsubs f18,f17,f18,f15
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r14.u32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f17,f16,f18
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f16,240(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,420(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,132(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f16,f18,f22
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// lfs f18,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfs f17,436(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f17,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r14,r6,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,52(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f28,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f28,160(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fadds f14,f15,f28
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// fsubs f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// fadds f15,f22,f16
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f30,f16
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// stfs f16,568(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// stfs f30,532(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f16,f18,f30
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f30.f64));
	// stfs f16,164(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f18.f64));
	// stfs f30,252(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmuls f30,f14,f0
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f30,488(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f30,f28,f0
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// stfs f30,312(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fmuls f30,f15,f0
	ctx.f30.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f30,608(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// fmuls f30,f22,f0
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f30,524(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f28,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f30.f64 = double(temp.f32);
	// fadds f22,f28,f30
	ctx.f22.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f22,504(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f30,344(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfsx f30,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f28,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,24(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// fmuls f15,f17,f30
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// lfsx f22,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,68
	ctx.r14.s64 = ctx.r6.s64 * 68;
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,196
	ctx.r14.s64 = ctx.r6.s64 * 196;
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,92(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f30,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f30,f22
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// lfs f30,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// stfs f30,44(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f30,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f30,f22,f28,f15
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f15.f64));
	// lfs f22,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f18
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f28,f17,f28,f16
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 - ctx.f16.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,36
	ctx.r14.s64 = ctx.r6.s64 * 36;
	// lfs f22,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f16,f18,f17,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f16.f64));
	// fmadds f22,f22,f17,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// stfs f18,124(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f18,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmsubs f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f15.f64));
	// stfs f18,196(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f17,384(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f16,f28
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f28.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f17,324(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 324);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f17,448(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 448);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f17,452(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 452);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f17,388(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 388);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,88(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f16,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f15,f17,f16,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f17,384(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f15,92(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f18,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f17,f17,f16,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f16,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,192(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,164
	ctx.r14.s64 = ctx.r6.s64 * 164;
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,228
	ctx.r14.s64 = ctx.r6.s64 * 228;
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f16,f22,f30
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f18,f17
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,108(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,52(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,100
	ctx.r14.s64 = ctx.r6.s64 * 100;
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f16,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// lfs f17,320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 320);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f16.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,148
	ctx.r14.s64 = ctx.r6.s64 * 148;
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f18,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f15.f64));
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f18,f17
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f18,320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 320);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f16.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f18,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f18,f17
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f16.f64 = double(temp.f32);
	// stw r14,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r14.u32);
	// fmadds f16,f16,f18,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f18.f64 + ctx.f15.f64));
	// stfs f16,52(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f18,f16,f18,f14
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f14,f16,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f16.f64 + ctx.f17.f64));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f14,f16,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// fadds f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f16,184(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,292(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f18,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// mulli r14,r6,52
	ctx.r14.s64 = ctx.r6.s64 * 52;
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, ctx.r14.u32);
	// mulli r14,r6,180
	ctx.r14.s64 = ctx.r6.s64 * 180;
	// stw r14,36(r1)
	PPC_STORE_U32(ctx.r1.u32 + 36, ctx.r14.u32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// lfs f28,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,28(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f28,f22,f30
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// lfs f15,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// stfs f30,272(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f30,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,92(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f28,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// stfs f28,192(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f28,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f30,140(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f30.f64 = double(temp.f32);
	// fadds f22,f28,f30
	ctx.f22.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fsubs f15,f30,f28
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f14,f30,f16
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// fsubs f16,f30,f16
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f30,f28
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f28,60(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f28,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,136(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f30,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f28,f17,f30
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// stfs f28,320(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fadds f30,f30,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// stfs f30,116(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f30,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f28.f64 = double(temp.f32);
	// fadds f17,f28,f30
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f17,612(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f30,500(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fmuls f30,f22,f0
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f30,448(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// fmuls f30,f15,f0
	ctx.f30.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f30,468(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fmuls f30,f14,f0
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f30,432(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fmuls f30,f16,f0
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f30,492(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// lfs f30,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f22,f30,f28
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f22,100(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,276(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f30,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f22,f30,f28
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f22,596(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,460(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// mulli r14,r6,20
	ctx.r14.s64 = ctx.r6.s64 * 20;
	// lfsx f30,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f28,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,80(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// fmuls f15,f18,f30
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfsx f22,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,356(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,84
	ctx.r14.s64 = ctx.r6.s64 * 84;
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f30,288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 288);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f30,f22
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// lfs f30,292(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 292);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// stw r14,52(r1)
	PPC_STORE_U32(ctx.r1.u32 + 52, ctx.r14.u32);
	// lwz r14,36(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f30,f22,f28,f15
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f15.f64));
	// fmsubs f28,f18,f28,f16
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 - ctx.f16.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f22,292(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 292);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f22,f17,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f17.f64 + ctx.f14.f64));
	// fmuls f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f18,288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 288);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f22,f30
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// stfs f15,124(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// stfs f30,72(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f30,f18,f28
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f30,196(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fsubs f30,f28,f18
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,52(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	// stfs f30,68(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f30,352(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 352);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 356);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,212
	ctx.r14.s64 = ctx.r6.s64 * 212;
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,244
	ctx.r14.s64 = ctx.r6.s64 * 244;
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,116
	ctx.r14.s64 = ctx.r6.s64 * 116;
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f14,f30,f18
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// fmuls f18,f28,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// fmadds f28,f28,f15,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f15.f64 + ctx.f14.f64));
	// fmsubs f30,f30,f15,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f15.f64 - ctx.f18.f64));
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// stfs f30,76(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// mulli r14,r6,12
	ctx.r14.s64 = ctx.r6.s64 * 12;
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f22,f30
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmuls f18,f28,f30
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,416(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 416);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f30,f28
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f30,420(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 420);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f30,f22,f28,f18
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f18.f64));
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f28,f22,f28,f15
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,20(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f28,f22
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,420(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 420);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f22,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f14.f64));
	// stfs f28,40(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// lfs f28,484(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f15
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f15.f64));
	// lfs f28,416(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 416);
	ctx.f28.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f28,f28,f22,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 - ctx.f14.f64));
	// stfs f28,48(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f22
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f28,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,484(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f28,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f18.f64));
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f28,f22,f28,f15
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 - ctx.f15.f64));
	// lfs f18,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f22,f22,f18,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f14.f64));
	// fadds f18,f15,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f30
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f30,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f30.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f30
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// stfs f30,48(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// stw r14,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r14.u32);
	// lfs f30,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f30.f64 = double(temp.f32);
	// mulli r14,r6,140
	ctx.r14.s64 = ctx.r6.s64 * 140;
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f30,f30,f15,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f22
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stw r14,76(r1)
	PPC_STORE_U32(ctx.r1.u32 + 76, ctx.r14.u32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,88(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,204(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,44(r1)
	PPC_STORE_U32(ctx.r1.u32 + 44, ctx.r14.u32);
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,76(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,64(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r14.u32);
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// fsubs f14,f28,f30
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// stfs f30,20(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f30,f15,f16
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f30,56(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fadds f30,f16,f15
	ctx.f30.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f30,72(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// fadds f28,f18,f30
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// stfs f28,148(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f28,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f12
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// lfs f30,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f12
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lwz r14,44(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f15,220(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f30,f15,f13,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f30.f64));
	// stfs f30,544(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// lfs f30,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// stfs f30,212(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f30,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f13,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f28.f64));
	// stfs f30,336(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f30,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f30.f64 = double(temp.f32);
	// fadds f28,f17,f14
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// fmadds f30,f30,f13,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f30,476(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfs f30,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f13,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f30,508(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// lfs f30,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// lwz r14,88(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stfs f28,192(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,108(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f22,f14,f17
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,76(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,104(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f17,f12
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f12
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,144(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,268(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f17,f28,f12
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// lfs f28,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f30
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f28,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmr f30,f28
	ctx.f30.f64 = ctx.f28.f64;
	// stw r14,68(r1)
	PPC_STORE_U32(ctx.r1.u32 + 68, ctx.r14.u32);
	// stfs f22,140(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// mulli r14,r6,172
	ctx.r14.s64 = ctx.r6.s64 * 172;
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f28,f18,f30
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f30.f64));
	// stfs f28,208(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmr f28,f18
	ctx.f28.f64 = ctx.f18.f64;
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// stfs f30,224(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f30,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f30.f64 = double(temp.f32);
	// lfs f18,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f30
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfs f28,168(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f28,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f30,f28
	ctx.f28.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// lfs f30,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f13,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f30,440(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// lfs f30,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f13,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f30,552(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// stw r14,72(r1)
	PPC_STORE_U32(ctx.r1.u32 + 72, ctx.r14.u32);
	// mulli r14,r6,76
	ctx.r14.s64 = ctx.r6.s64 * 76;
	// fmsubs f30,f30,f13,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f22.f64));
	// stfs f30,484(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// lfs f16,276(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// stw r14,48(r1)
	PPC_STORE_U32(ctx.r1.u32 + 48, ctx.r14.u32);
	// lfs f30,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f13,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f30,516(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// mulli r14,r6,204
	ctx.r14.s64 = ctx.r6.s64 * 204;
	// lfs f30,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f22,f30,f18,f14
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 + ctx.f14.f64));
	// lfs f30,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f18,f30,f18,f17
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,272(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	ctx.f17.f64 = double(temp.f32);
	// stw r14,56(r1)
	PPC_STORE_U32(ctx.r1.u32 + 56, ctx.r14.u32);
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r14.u32);
	// lwz r14,32(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfs f30,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f17,f30
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fmuls f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lwz r14,72(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,64(r1)
	PPC_STORE_U32(ctx.r1.u32 + 64, ctx.r14.u32);
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lwz r14,48(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmadds f30,f16,f15,f14
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r14.u32);
	// lwz r14,56(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// fmsubs f17,f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 - ctx.f14.f64));
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r14.u32);
	// lwz r14,192(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,72(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,48(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// stfs f14,140(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f14,f30,f22
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fsubs f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// stfs f30,84(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f30,f18,f17
	ctx.f30.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f30,152(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfsx f30,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lwz r14,56(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// stfs f30,272(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f22,336(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 336);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,108(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f30,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lwz r14,64(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// stfs f30,388(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f30,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f18,f30,f16
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f16.f64));
	// stfs f30,92(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f30,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,28(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f17,f30,f16
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f16.f64));
	// lfs f30,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f22,f30
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// lfs f22,340(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 340);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// stfs f30,28(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmadds f22,f22,f15,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64 + ctx.f18.f64));
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f22,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f15,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64 - ctx.f17.f64));
	// stfs f22,148(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f22,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f30,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fmuls f18,f22,f30
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// lfs f22,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f22,f30
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// lfs f30,340(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 340);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f22,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 + ctx.f16.f64));
	// stfs f30,204(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f30,f30,f22,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 - ctx.f16.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f22,400(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 400);
	ctx.f22.f64 = double(temp.f32);
	// lfs f30,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f22,f30
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// lfs f22,404(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 404);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// stfs f30,28(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f22.f64 = double(temp.f32);
	// lfs f30,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f22,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f22.f64 + ctx.f18.f64));
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f18,f22,f17
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f17.f64));
	// lfs f16,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,404(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 404);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f16,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,236
	ctx.r14.s64 = ctx.r6.s64 * 236;
	// lfs f17,400(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 400);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,280(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// stw r14,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r14.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,108
	ctx.r14.s64 = ctx.r6.s64 * 108;
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,188(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,308(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stw r14,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r14.u32);
	// fadds f15,f18,f30
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f15,f17,f22
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,112(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfs f30,128(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,464(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f22,468(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 468);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,124(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r14.u32);
	// lwz r14,196(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f18,f17
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stw r14,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r14.u32);
	// fsubs f17,f14,f15
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f15,f30,f12
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fsubs f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f14,556(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 556, temp.u32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f18,216(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lwz r14,92(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lfs f18,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,124(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,196(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// stfs f17,108(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// stfs f14,272(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fmsubs f30,f30,f13,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f30,140(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f30,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f13,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f30,388(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f30,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f22,f18
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// fmuls f17,f30,f18
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// lfs f18,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// lfs f30,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f18,f30
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfs f18,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfs f18,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f18.f64 = double(temp.f32);
	// stfs f30,108(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmadds f30,f22,f18,f17
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f17.f64));
	// lfs f22,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f18,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f15,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f17,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f17,f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 - ctx.f14.f64));
	// fsubs f15,f30,f18
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// fadds f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// fsubs f18,f22,f17
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,104(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f16,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f22,f15
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f16,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f30,f16
	ctx.f18.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// fsubs f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// stfs f30,120(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f30,f22,f15
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f30,308(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fmuls f22,f17,f12
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f30,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f30,f12
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfs f30,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f30,f12
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfs f30,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f30,f12
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfs f30,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// stfs f30,188(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f30,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfs f30,280(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// lfs f18,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f30,f18
	ctx.f18.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfs f18,204(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f18,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f18.f64 = double(temp.f32);
	// fadds f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// fmadds f18,f17,f13,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f18,f13,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f22.f64));
	// stfs f22,272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f18,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f18,f22
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f17,148(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmsubs f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f13,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f17,308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// lfs f17,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfs f16,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// lfs f14,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,172(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,180(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 + ctx.f30.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfs f28,116(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfs f28,128(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// fadds f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fsubs f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,240(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f17,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,200(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,184(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f17,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,84(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,160(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f16,f21,f25
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f17,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,172(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,152(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f17,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f16,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f30
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,396(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// fsubs f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// stfs f30,116(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f30,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f28,f12
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f30,f30,f12
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmadds f30,f28,f13,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 + ctx.f30.f64));
	// stfs f30,316(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f30,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f30.f64 = double(temp.f32);
	// fadds f28,f18,f14
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// fmsubs f30,f30,f13,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f30,352(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f30,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// fsubs f15,f30,f22
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// lfs f30,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f30.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f30.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f14.f64));
	// stfs f30,128(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 + ctx.f30.f64));
	// stfs f30,200(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f30,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f30.f64));
	// stfs f14,144(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f28,180(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f28,f18,f0
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f28,172(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f28,f15,f0
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// stfs f28,112(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f14.f64));
	// lfs f18,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f28,84(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f28,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f28.f64 = double(temp.f32);
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f18,f28
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfsx f15,r14,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f28,0(r3)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f28,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,252
	ctx.r14.s64 = ctx.r6.s64 * 252;
	// lfs f18,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f18,f28
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// fadds f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// lfs f28,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// stfsx f28,r14,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// mulli r14,r6,188
	ctx.r14.s64 = ctx.r6.s64 * 188;
	// fsubs f28,f16,f30
	ctx.f28.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// stfsx f28,r8,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// lfs f28,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f30,r14,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f17.f64));
	// mulli r14,r6,60
	ctx.r14.s64 = ctx.r6.s64 * 60;
	// stfsx f15,r9,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f18,r14,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// mulli r14,r6,92
	ctx.r14.s64 = ctx.r6.s64 * 92;
	// fsubs f16,f30,f28
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f18,f28,f30
	ctx.f18.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lfs f30,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f16,r14,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// fsubs f16,f28,f30
	ctx.f16.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfsx f18,r7,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// mulli r14,r6,156
	ctx.r14.s64 = ctx.r6.s64 * 156;
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f16,r31,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// lfs f18,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f30,r14,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// mulli r14,r6,220
	ctx.r14.s64 = ctx.r6.s64 * 220;
	// stfsx f28,r5,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// lfs f28,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// lfs f18,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f16,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,160(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f16,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f15,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f14,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f14,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f14,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f15,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,180(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f15,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,172(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f17,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f17,184(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f15,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,200(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f15,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f17,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fadds f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// stfs f22,304(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// stfs f17,392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmuls f15,f28,f10
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfsx f22,r14,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f18,f16
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f22,232(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f17,f30,f10
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fadds f22,f16,f18
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f22,284(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f28,f28,f11,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 + ctx.f17.f64));
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f30,f30,f11,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64 - ctx.f15.f64));
	// fsubs f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f16,188(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,240(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// mulli r14,r6,28
	ctx.r14.s64 = ctx.r6.s64 * 28;
	// fmuls f18,f22,f11
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f11
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,144(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,244(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,128(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f28,96(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f30,120(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f30,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f10,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 - ctx.f18.f64));
	// stfs f30,84(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f28,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f28.f64 = double(temp.f32);
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f30,f28,f18
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f30,116(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f30,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f10,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 + ctx.f16.f64));
	// stfs f30,112(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f17,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f17.f64 = double(temp.f32);
	// lfs f30,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f16,f30,f17
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f17.f64));
	// stfsx f16,r30,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// stfsx f30,r14,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// fadds f30,f18,f28
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f30,180(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f28,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f30.f64 = double(temp.f32);
	// fadds f18,f28,f30
	ctx.f18.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f18,304(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfs f30,172(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfs f28,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f28,f4
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// fmuls f15,f28,f5
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// lfs f30,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f17,f30,f6
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// lfs f30,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f30,f6
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fmadds f30,f30,f7,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f17.f64));
	// lfs f17,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f17.f64 = double(temp.f32);
	// lfs f28,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f18,f17,f5,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f18.f64));
	// stfs f18,200(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f14,f28,f7
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// lfs f18,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f22,f4
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// stfs f28,232(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmr f28,f18
	ctx.f28.f64 = ctx.f18.f64;
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f18,160(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f28,184(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f28,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f28.f64 = double(temp.f32);
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f18,152(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmsubs f17,f17,f4,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 - ctx.f15.f64));
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f17,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f6,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 - ctx.f14.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f7,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 - ctx.f16.f64));
	// lfs f17,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f17,f4
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// fmsubs f16,f17,f5,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 - ctx.f16.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,244(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fmadds f22,f22,f5,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 + ctx.f15.f64));
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// stfs f17,232(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f17,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,240(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,284(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f16,f14,f7,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f7.f64 + ctx.f16.f64));
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,188(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f28,f15
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// stfs f15,160(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,152(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// stfs f26,296(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f26,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// lfs f14,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// stfs f25,288(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f21,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// lfs f25,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// stfs f25,184(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f21,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f21.f64 = double(temp.f32);
	// lfs f25,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f25.f64 = double(temp.f32);
	// stfs f19,112(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fsubs f19,f25,f21
	ctx.f19.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// stfsx f19,r30,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfsx f25,r14,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// mulli r30,r6,156
	ctx.r30.s64 = ctx.r6.s64 * 156;
	// lfs f25,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f21,f30,f25
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// fadds f19,f25,f30
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// lfs f30,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f25,f30,f18
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfs f25,348(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fadds f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f18.f64));
	// stfs f30,244(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f30,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f18,f17,f13
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// fadds f25,f22,f30
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// stfs f25,232(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fsubs f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// stfs f30,284(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f17,f12
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fadds f17,f30,f16
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// lfs f25,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// lfs f30,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f14,f30,f25
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// fadds f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// stfs f30,96(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fsubs f25,f28,f15
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f25,120(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// lfs f28,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfs f28,84(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f28,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f28.f64 = double(temp.f32);
	// fadds f30,f26,f28
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f26,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f28,f26,f13,f22
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 + ctx.f22.f64));
	// fmsubs f26,f26,f12,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 - ctx.f18.f64));
	// stfs f26,340(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f25,f17,f0
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f22,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f26.f64 = double(temp.f32);
	// fadds f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f22,296(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f22,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fmuls f22,f16,f0
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f22,288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f22,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f22
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfsx f18,r30,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f18.f64 = double(temp.f32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfsx f22,r31,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// mulli r31,r6,220
	ctx.r31.s64 = ctx.r6.s64 * 220;
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f21,r31,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfsx f19,r5,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// mulli r5,r6,92
	ctx.r5.s64 = ctx.r6.s64 * 92;
	// lfs f21,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f22,f21
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f19,f21,f22
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f18,r5,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fsubs f18,f22,f21
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfsx f19,r7,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lwz r7,396(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// fadds f19,f21,f22
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f18,r7,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// mulli r7,r6,252
	ctx.r7.s64 = ctx.r6.s64 * 252;
	// stfs f19,0(r4)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f21,f22
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f17,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f14,r7,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfsx f19,r10,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,188
	ctx.r10.s64 = ctx.r6.s64 * 188;
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f18,r10,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f18.f64 = double(temp.f32);
	// mulli r10,r6,60
	ctx.r10.s64 = ctx.r6.s64 * 60;
	// stfsx f22,r8,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// stfsx f19,r9,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f18,f17
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f16,f21,f19
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f16,168(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f19,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f18,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,268(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f21,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f21,280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f19,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// lfs f19,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// fmuls f15,f18,f13
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f17,f18,f12
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f25,f18
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f18.f64));
	// stfs f14,232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fsubs f25,f18,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 - ctx.f25.f64));
	// stfs f25,284(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f18,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f18.f64 = double(temp.f32);
	// lfs f25,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f25.f64 = double(temp.f32);
	// fadds f14,f18,f25
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// stfs f14,96(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// stfs f25,120(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f14,f19,f21
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f18,f19,f21
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// fmadds f17,f22,f13,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f17,244(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fmsubs f22,f22,f12,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f17,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f12
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f19,292(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f21,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// stfs f21,168(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f25,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f21,f18,f0
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f25,f25,f12
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f18,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f19,f18,f13,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f16.f64));
	// fmuls f18,f14,f0
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmsubs f25,f17,f13,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f25.f64));
	// lfs f17,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f16.f64));
	// lfs f16,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f13,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f15.f64));
	// fadds f15,f25,f14
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// lwz r10,196(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// fadds f14,f21,f26
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfs f14,168(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f14,f19,f22
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fsubs f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fadds f19,f17,f28
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// stfs f19,292(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fadds f21,f18,f30
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// lfs f19,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// lfs f18,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfsx f16,r10,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// mulli r10,r6,144
	ctx.r10.s64 = ctx.r6.s64 * 144;
	// lfs f17,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f14,f17
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfsx f16,r10,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,124(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,208
	ctx.r10.s64 = ctx.r6.s64 * 208;
	// fsubs f17,f25,f26
	ctx.f17.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,72(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,80
	ctx.r10.s64 = ctx.r6.s64 * 80;
	// lfs f26,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f26,f22
	ctx.f25.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// lfs f22,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,68(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,112
	ctx.r10.s64 = ctx.r6.s64 * 112;
	// lfs f26,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f21,f26
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// fadds f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// lfs f21,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,240
	ctx.r10.s64 = ctx.r6.s64 * 240;
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f19,f26
	ctx.f25.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// fadds f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// lfs f19,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,76(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,176
	ctx.r10.s64 = ctx.r6.s64 * 176;
	// lfs f26,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f26,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,56(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// lfs f25,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,48(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// fsubs f28,f30,f18
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// lfs f26,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f25,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// lfs f22,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f21,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmuls f17,f21,f12
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f21,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f21.f64 = double(temp.f32);
	// stfs f19,168(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f16,f21,f13
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f19,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// lfs f15,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// mulli r10,r6,48
	ctx.r10.s64 = ctx.r6.s64 * 48;
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fadds f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// lfs f18,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f21,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f24
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmadds f17,f19,f13,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f17,300(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f17,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// fmuls f15,f19,f12
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f13
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmsubs f16,f19,f12,f16
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 - ctx.f16.f64));
	// stfs f16,248(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f16,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f30,f18,f28
	ctx.f30.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// lfs f19,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f19.f64 = double(temp.f32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// lfs f16,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmsubs f16,f16,f13,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f15,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f15,f15,f12,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f14.f64));
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f14,f26
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// fadds f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// lfs f14,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfs f14,252(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f14,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// stfs f25,276(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fsubs f25,f14,f22
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,260(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f22,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f22,320(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f22,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f14,328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,168(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fadds f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f22,268(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fsubs f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f22,300(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fadds f22,f15,f16
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f22,264(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fsubs f22,f15,f16
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f22,248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f22,f28,f11
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmuls f21,f18,f8
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmuls f16,f25,f8
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fmuls f14,f25,f9
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// fmuls f19,f30,f8
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// fmuls f17,f26,f11
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f25,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f15,f15,f10
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// fmsubs f30,f30,f9,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 - ctx.f21.f64));
	// fmadds f26,f26,f10,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f22.f64));
	// stfs f25,256(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmadds f25,f18,f9,f19
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 + ctx.f19.f64));
	// lfs f19,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f28,f28,f10,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f17.f64));
	// lfs f21,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f19,f19,f11,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f15.f64));
	// fmadds f22,f21,f9,f16
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f16.f64));
	// stfs f19,372(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f19,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f21,f21,f8,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 - ctx.f14.f64));
	// stfs f21,136(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f18,332(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f18,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fsubs f21,f25,f21
	ctx.f21.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// stfs f21,260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f21,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f11,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f17.f64));
	// stfs f18,276(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fadds f18,f22,f30
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// stfs f18,252(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// lfs f18,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f18.f64 = double(temp.f32);
	// stfs f30,324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fsubs f30,f21,f18
	ctx.f30.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f30,248(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f17,f18,f21
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// lfs f30,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f30.f64 = double(temp.f32);
	// lfs f22,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f22.f64 = double(temp.f32);
	// fadds f21,f30,f22
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// lfs f30,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f30.f64 = double(temp.f32);
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f30,f13
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// stfs f17,256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f14,f22,f12
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f17,f22,f13
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f22,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f30,f12
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfs f30,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// lfs f22,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f22.f64 = double(temp.f32);
	// stfs f30,176(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f30,f19,f22
	ctx.f30.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// lfs f22,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f22.f64 = double(temp.f32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f25,228(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f22,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// lfs f19,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f22,136(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,300(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f28,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f22,168(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f22,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f26,f22
	ctx.f22.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f22,292(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f22,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// stfs f28,244(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f22,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f22,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f22.f64 = double(temp.f32);
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// lfs f22,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fmuls f22,f21,f0
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// lfs f21,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f12,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 - ctx.f18.f64));
	// fmuls f18,f16,f0
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f18,232(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmadds f19,f19,f12,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f17.f64));
	// lfs f17,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f18.f64 = double(temp.f32);
	// mulli r10,r6,100
	ctx.r10.s64 = ctx.r6.s64 * 100;
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfs f17,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f15,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmsubs f16,f16,f13,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f15,176(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f15,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f15.f64 = double(temp.f32);
	// mulli r30,r6,228
	ctx.r30.s64 = ctx.r6.s64 * 228;
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// lwz r9,24(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r10,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r17,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r16,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r30,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// mulli r31,r6,164
	ctx.r31.s64 = ctx.r6.s64 * 164;
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r15,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r31,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// mulli r10,r6,88
	ctx.r10.s64 = ctx.r6.s64 * 88;
	// fsubs f14,f30,f15
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// fadds f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// mulli r5,r6,36
	ctx.r5.s64 = ctx.r6.s64 * 36;
	// stfsx f30,r5,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f30.f64 = double(temp.f32);
	// mulli r8,r6,68
	ctx.r8.s64 = ctx.r6.s64 * 68;
	// fsubs f15,f25,f30
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fadds f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// lfs f25,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f15,r8,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r19,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f30.f64 = double(temp.f32);
	// mulli r7,r6,196
	ctx.r7.s64 = ctx.r6.s64 * 196;
	// fsubs f15,f30,f25
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// stfsx f15,r21,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f25.f64 = double(temp.f32);
	// lfs f30,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f15,f30,f25
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// stfsx f15,r18,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// stfsx f30,r7,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f28,f26
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfsx f30,r20,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f30,f26,f28
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fadds f28,f22,f24
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fadds f26,f19,f21
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f25,f19,f21
	ctx.f25.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// fadds f21,f16,f17
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f24,f22
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// lfs f22,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fadds f24,f18,f22
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// fsubs f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,164(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fmuls f14,f18,f8
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,212(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f17,224(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f17,208(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// stfs f18,164(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmr f18,f17
	ctx.f18.f64 = ctx.f17.f64;
	// fmuls f16,f18,f10
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// fmuls f15,f18,f11
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fadds f18,f26,f30
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// stfs f18,236(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fadds f18,f19,f22
	ctx.f18.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,252(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// lfs f22,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// stfs f22,220(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f22,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f22,f18
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f18,216(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// stfs f30,256(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f26,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f30.f64 = double(temp.f32);
	// lfs f18,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// fadds f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// stfs f26,60(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f26,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// lfs f19,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f26,176(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// stfs f22,100(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmadds f17,f30,f9,f14
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f14.f64));
	// stfs f17,228(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f26,f26,f11
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// stfs f26,132(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f17,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// lfs f19,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f8
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// fmsubs f26,f17,f9,f19
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 - ctx.f19.f64));
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmsubs f30,f30,f8,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f17.f64));
	// lfs f19,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f22,f19,f9,f18
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 + ctx.f18.f64));
	// fmsubs f19,f17,f11,f16
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f16.f64));
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f17,f17,f10,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f15.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f18,f18,f10,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 + ctx.f16.f64));
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f16,f10,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 - ctx.f15.f64));
	// fadds f15,f26,f14
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// fsubs f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// fsubs f14,f30,f22
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// fadds f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// mulli r14,r6,20
	ctx.r14.s64 = ctx.r6.s64 * 20;
	// fadds f22,f18,f19
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfsx f18,r22,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfsx f18,r14,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// lwz r14,80(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f14,f18
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfsx f15,r23,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// lfs f14,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f18,r14,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// mulli r14,r6,212
	ctx.r14.s64 = ctx.r6.s64 * 212;
	// lfs f18,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f26,f18
	ctx.f15.f64 = double(float(ctx.f26.f64 - ctx.f18.f64));
	// stfsx f15,r24,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f26,f18,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// lfs f15,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f26,r14,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// lwz r14,52(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	// lfs f26,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f18,f26,f30
	ctx.f18.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfsx f18,r14,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// mulli r14,r6,116
	ctx.r14.s64 = ctx.r6.s64 * 116;
	// stfsx f30,r25,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f21,f28
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f28.f64));
	// lfs f18,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f26,f30,f22
	ctx.f26.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// stfsx f26,r14,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// fadds f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// stfsx f30,r29,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f26,f17,f16
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// mulli r14,r6,244
	ctx.r14.s64 = ctx.r6.s64 * 244;
	// fadds f30,f24,f25
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f22,f26,f30
	ctx.f22.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// stfsx f22,r28,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfsx f30,r14,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// lfs f22,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// lfs f22,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// lfs f15,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,132(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f14,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,164(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f14,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,212(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f14,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,224(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f15,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,208(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// lwz r14,36(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// fadds f24,f16,f17
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f24,176(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f28,f28,f21
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f21.f64));
	// lfs f21,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f30,f8
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// fadds f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// stfs f24,228(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f21,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfs f24,136(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f21,f30,f9
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// lfs f24,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f24.f64 = double(temp.f32);
	// lfs f30,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f16,f30,f24
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// stfs f16,60(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fadds f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// stfs f30,220(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f30,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f30.f64 = double(temp.f32);
	// lfs f24,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f16,f30,f24
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// stfs f16,236(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmuls f16,f18,f9
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// lfs f14,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f30,380(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fmadds f21,f26,f8,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 + ctx.f21.f64));
	// lfs f24,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f26,f26,f9,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 - ctx.f17.f64));
	// stfs f26,216(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f17,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f22,f9
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// lfs f26,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// lfs f30,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f17,f19,f25
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f25.f64));
	// stfsx f17,r26,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// stfsx f25,r14,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// lwz r14,356(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// fmsubs f25,f22,f8,f16
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f8.f64 - ctx.f16.f64));
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// lfs f24,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// lfs f19,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f22,f28,f19
	ctx.f22.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// stfsx f22,r27,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// stfsx f28,r14,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f22,f18,f8,f14
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f14.f64));
	// fsubs f19,f29,f28
	ctx.f19.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// lfs f18,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f24,f2
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fsubs f28,f19,f18
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f19,224(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f19,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f27,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f19,f18
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f17,132(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f19,212(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f19,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f19,100(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f19,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f19,f2
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// lfs f17,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f19,f3
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f19,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f31
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f31.f64));
	// lfs f19,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64));
	// fmadds f19,f19,f3,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f18.f64));
	// lfs f18,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f1,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f1.f64 + ctx.f17.f64));
	// fadds f17,f25,f21
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// fsubs f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// lfs f21,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f22,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f21,356(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f21,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f2,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 - ctx.f16.f64));
	// stfs f21,220(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f21,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f30,f2
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// fmsubs f21,f21,f1,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 - ctx.f15.f64));
	// stfs f21,236(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmsubs f21,f30,f3,f14
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f3.f64 - ctx.f14.f64));
	// stfs f21,60(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f30,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f30,f31
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fmuls f14,f30,f1
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f1.f64));
	// fadds f30,f17,f28
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// stfs f30,208(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fsubs f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// lfs f17,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// fmadds f24,f24,f3,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f16.f64));
	// lfs f16,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f16.f64 = double(temp.f32);
	// fadds f30,f21,f19
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f30,100(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f21,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f21.f64 = double(temp.f32);
	// lfs f30,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f21,216(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f19,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,368(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f16,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// fmadds f16,f26,f1,f15
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f15.f64));
	// fmsubs f26,f26,f31,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f31.f64 - ctx.f14.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f25,f14
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// fsubs f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f14,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f14.f64 = double(temp.f32);
	// fadds f29,f14,f29
	ctx.f29.f64 = double(float(ctx.f14.f64 + ctx.f29.f64));
	// stfs f29,376(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f14,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f14.f64 = double(temp.f32);
	// lfs f29,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// stfs f29,60(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f14,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f14.f64 = double(temp.f32);
	// lfs f29,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// lfs f14,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 + ctx.f27.f64));
	// stfs f27,384(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f14,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f14.f64 = double(temp.f32);
	// lfs f27,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// stfs f27,364(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfs f14,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f14.f64 = double(temp.f32);
	// lfs f27,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// stfs f27,136(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f27,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f27.f64 = double(temp.f32);
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f27
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f27.f64));
	// stfsx f14,r22,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// mulli r22,r6,20
	ctx.r22.s64 = ctx.r6.s64 * 20;
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// fadds f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// stfsx f27,r22,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// lfs f27,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f27.f64 = double(temp.f32);
	// lwz r22,80(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// fsubs f14,f27,f21
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// lfs f27,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfs f27,100(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f27,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// lfs f24,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// lfs f21,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfs f21,132(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f21,f26,f18
	ctx.f21.f64 = double(float(ctx.f26.f64 - ctx.f18.f64));
	// stfs f21,164(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// stfs f26,228(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f26,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f26,f11
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f26.f64 = double(temp.f32);
	// stfs f24,60(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f21,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// lfs f16,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f26
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f26.f64));
	// stfs f16,360(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f16,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f16.f64 = double(temp.f32);
	// fadds f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// lfs f16,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f16.f64 = double(temp.f32);
	// stfs f21,176(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f21,f19,f11
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fadds f16,f16,f29
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f29.f64));
	// stfs f16,248(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f16,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f29,f16,f29
	ctx.f29.f64 = double(float(ctx.f16.f64 - ctx.f29.f64));
	// stfs f29,256(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f29,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f24,f19,f10,f18
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f18.f64));
	// lfs f16,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f29,f29,f11
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f11.f64));
	// stfs f29,252(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmsubs f29,f16,f10,f21
	ctx.f29.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 - ctx.f21.f64));
	// lfs f21,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f19,f21,f30
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f30.f64));
	// stfsx f19,r22,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// stfsx f30,r23,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// mulli r23,r6,212
	ctx.r23.s64 = ctx.r6.s64 * 212;
	// fsubs f30,f28,f27
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// stfsx f14,r23,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f14,r24,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lwz r24,52(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	// stfsx f30,r24,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// stfsx f28,r25,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// mulli r25,r6,116
	ctx.r25.s64 = ctx.r6.s64 * 116;
	// lfs f30,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f27,f17,f30
	ctx.f27.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// fadds f28,f30,f17
	ctx.f28.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// lfs f30,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f27,r25,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fsubs f27,f30,f15
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// stfsx f28,r29,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fadds f28,f15,f30
	ctx.f28.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// mulli r29,r6,244
	ctx.r29.s64 = ctx.r6.s64 * 244;
	// lfs f30,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f27,r29,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lwz r29,36(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// stfsx f28,r28,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f27,f30,f25
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// fadds f28,f25,f30
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// lfs f30,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f27,r29,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f27,f22,f30
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// stfsx f28,r26,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fadds f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// stfsx f27,r27,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r14,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f28.f64 = double(temp.f32);
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// lfs f27,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// lfs f25,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// lfs f22,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// lfs f21,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f19,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// lfs f18,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f10
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f16,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f17,f16,f10,f14
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f14.f64));
	// fmsubs f16,f16,f11,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f15.f64));
	// fsubs f15,f30,f28
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fsubs f28,f27,f25
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f25,f22,f21
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f21,f19,f18
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fadds f18,f17,f29
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// fsubs f29,f17,f29
	ctx.f29.f64 = double(float(ctx.f17.f64 - ctx.f29.f64));
	// stfs f29,312(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fsubs f29,f24,f16
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// stfs f29,60(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fadds f29,f16,f24
	ctx.f29.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f29,344(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fmuls f24,f15,f7
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// fmuls f29,f27,f4
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// stfs f29,100(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f17,f28,f7
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// fmuls f14,f21,f7
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f7.f64));
	// fmuls f16,f21,f6
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// lfs f21,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,132(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f21,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f21.f64 = double(temp.f32);
	// fadds f29,f18,f21
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fmadds f28,f28,f6,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f6.f64 + ctx.f24.f64));
	// fmsubs f24,f15,f6,f17
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f30,f4
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// fmsubs f21,f25,f7,f16
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 - ctx.f16.f64));
	// fmadds f25,f25,f6,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f14.f64));
	// fmuls f14,f19,f5
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// fmadds f27,f27,f5,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f15.f64));
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fmuls f16,f19,f4
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f30,f30,f5,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f5.f64 - ctx.f19.f64));
	// fmadds f19,f22,f5,f16
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 + ctx.f16.f64));
	// fadds f16,f21,f28
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f28.f64));
	// fsubs f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// fsubs f21,f25,f24
	ctx.f21.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f22,f22,f4,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 - ctx.f14.f64));
	// fsubs f15,f24,f16
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfsx f24,r5,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fsubs f24,f28,f18
	ctx.f24.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfsx f24,r30,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfsx f28,r16,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,100
	ctx.r10.s64 = ctx.r6.s64 * 100;
	// fsubs f28,f21,f17
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfsx f28,r31,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f17,f21
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfsx f28,r15,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f29,f25
	ctx.f28.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fadds f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// lfs f25,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f28,r10,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f29,r17,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f28.f64 = double(temp.f32);
	// lfs f29,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// lfs f28,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f25,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// lfs f21,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f21.f64));
	// lfs f18,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f17,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f16,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f15,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// stfs f15,336(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// fadds f15,f22,f27
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f15,f19,f30
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// stfs f15,132(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f27.f64));
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// lfs f22,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f19,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// lfs f14,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,164(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f14,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,228(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f19,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f28,f9
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f9.f64));
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfs f23,176(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f19,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f19.f64 = double(temp.f32);
	// lfs f23,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfs f23,136(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f23,f29,f9
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// stfs f23,60(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fsubs f23,f21,f18
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fsubs f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fmsubs f29,f29,f8,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 - ctx.f14.f64));
	// fmuls f17,f24,f9
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fmuls f16,f24,f8
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// lfs f24,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f28,f28,f8,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f8.f64 + ctx.f14.f64));
	// lfs f14,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f14.f64 = double(temp.f32);
	// lwz r10,24(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// fsubs f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfsx f14,r20,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f14.f64 = double(temp.f32);
	// addi r11,r11,504
	ctx.r11.s64 = ctx.r11.s64 + 504;
	// fadds f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfsx f24,r9,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// lwz r9,620(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	// fsubs f14,f24,f15
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// stfsx f24,r21,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// fsubs f24,f27,f22
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// stfsx f24,r7,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// stfsx f27,r18,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fmadds f24,f25,f8,f17
	ctx.f24.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 + ctx.f17.f64));
	// lfs f22,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f27,f25,f9,f16
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 - ctx.f16.f64));
	// lwz r10,576(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	// fsubs f25,f26,f30
	ctx.f25.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// stfsx f25,r8,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// lfs f26,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f30,r19,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f20,f26
	ctx.f30.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// fadds f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// lfs f20,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f20.f64 = double(temp.f32);
	// fadds f25,f20,f22
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmuls f16,f19,f2
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// subf r4,r9,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r9.s64;
	// fmuls f20,f19,f3
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmuls f17,f18,f1
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmuls f15,f18,f31
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// stw r10,576(r1)
	PPC_STORE_U32(ctx.r1.u32 + 576, ctx.r10.u32);
	// fadds f18,f24,f29
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// fsubs f24,f28,f27
	ctx.f24.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fmsubs f27,f23,f3,f16
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 - ctx.f16.f64));
	// lfs f16,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f20,f23,f2,f20
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f20.f64));
	// fmsubs f19,f21,f31,f17
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f31.f64 - ctx.f17.f64));
	// lfs f17,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f21,f1,f15
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f15.f64));
	// lfs f21,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// lfs f17,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f24,f22
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fsubs f15,f30,f18
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// fadds f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// fadds f18,f29,f25
	ctx.f18.f64 = double(float(ctx.f29.f64 + ctx.f25.f64));
	// fsubs f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// lfs f25,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f22,f28,f26
	ctx.f22.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// fsubs f26,f25,f21
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// fadds f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfs f25,100(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f21,f17,f16
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f21,60(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,132(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f16,f26,f3
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmuls f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmuls f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64));
	// fmsubs f26,f26,f2,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f21.f64));
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// stfs f25,60(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmadds f25,f21,f2,f16
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f21,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f21.f64 = double(temp.f32);
	// lwz r10,640(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	// fmsubs f21,f21,f1,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 - ctx.f17.f64));
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f1,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 + ctx.f16.f64));
	// fadds f16,f26,f20
	ctx.f16.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// fsubs f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f20.f64));
	// fsubs f20,f25,f27
	ctx.f20.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fadds f25,f21,f23
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f25,60(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fsubs f25,f17,f19
	ctx.f25.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// fadds f21,f17,f19
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f15,f16
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f19,0(r10)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,192(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// fadds f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f19,0(r10)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fsubs f19,f26,f14
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// fadds f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// stfs f19,0(r10)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,632(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	// stfs f26,0(r10)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,64(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// fsubs f26,f20,f24
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stfs f26,0(r10)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,648(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	// fadds f26,f24,f20
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// stfs f26,0(r10)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,28(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// fsubs f26,f30,f27
	ctx.f26.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f26,0(r10)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,624(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,628(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	// lfs f30,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f27,f22,f30
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// stfs f27,0(r10)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,44(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// fadds f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,32(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// fsubs f30,f25,f18
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,636(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	// fadds f30,f18,f25
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,20(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fsubs f30,f23,f29
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,644(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	// fadds f30,f29,f23
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,16(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fsubs f30,f28,f21
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f21.f64));
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,652(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	// fadds f30,f21,f28
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f28.f64));
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d518d8
	if (!ctx.cr0.eq) goto loc_82D518D8;
loc_82D55050:
	// addi r1,r1,960
	ctx.r1.s64 = ctx.r1.s64 + 960;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D5505C;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D55060"))) PPC_WEAK_FUNC(sub_82D55060);
PPC_FUNC_IMPL(__imp__sub_82D55060) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1192
	ctx.r5.s64 = ctx.r11.s64 + -1192;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,6184
	ctx.r4.s64 = ctx.r11.s64 + 6184;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D55078"))) PPC_WEAK_FUNC(sub_82D55078);
PPC_FUNC_IMPL(__imp__sub_82D55078) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D55080;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D55088;
	__savefpr_14(ctx, base);
	// stwu r1,-640(r1)
	ea = -640 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r7,248
	ctx.r11.s64 = ctx.r7.s64 * 248;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-248
	ctx.r11.s64 = ctx.r11.s64 + -248;
	// bge cr6,0x82d565b0
	if (!ctx.cr6.lt) goto loc_82D565B0;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// stw r10,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f8,-8004(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8004);
	ctx.f8.f64 = double(temp.f32);
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lfs f9,-8000(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8000);
	ctx.f9.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f10,-8012(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -8012);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// stw r10,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f11,-8008(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8008);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// stw r29,332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 332, ctx.r29.u32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D550F0:
	// rlwinm r10,r6,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f7,120(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// rlwinm r9,r6,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f6,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f6.f64 = double(temp.f32);
	// mulli r8,r6,96
	ctx.r8.s64 = ctx.r6.s64 * 96;
	// lfs f5,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f28,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f19,f7,f28
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfsx f26,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f28,f6,f28
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfsx f24,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f5,f26
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f2,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r21,r6,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f17,f3,f24
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fmuls f26,f4,f26
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// lfsx f27,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// lfs f30,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// add r7,r21,r3
	ctx.r7.u64 = ctx.r21.u64 + ctx.r3.u64;
	// lfsx f25,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f23,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r20,r6,100
	ctx.r20.s64 = ctx.r6.s64 * 100;
	// lfs f29,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f21,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f6,f6,f27,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f27.f64 + ctx.f19.f64));
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfs f22,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f7,f7,f27,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64 - ctx.f28.f64));
	// fmuls f28,f30,f22
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// lfs f31,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f4,f4,f25,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64 + ctx.f18.f64));
	// stw r7,300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 300, ctx.r7.u32);
	// fmadds f2,f2,f23,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64 + ctx.f17.f64));
	// add r5,r20,r3
	ctx.r5.u64 = ctx.r20.u64 + ctx.r3.u64;
	// fmsubs f5,f5,f25,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 - ctx.f26.f64));
	// mulli r19,r6,68
	ctx.r19.s64 = ctx.r6.s64 * 68;
	// fmsubs f3,f3,f23,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 - ctx.f24.f64));
	// lfs f26,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f29,f22
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// lfs f25,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// stw r5,316(r1)
	PPC_STORE_U32(ctx.r1.u32 + 316, ctx.r5.u32);
	// lfs f22,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f29,f29,f21,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f21.f64 + ctx.f28.f64));
	// lfs f19,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fadds f28,f6,f1
	ctx.f28.f64 = double(float(ctx.f6.f64 + ctx.f1.f64));
	// mulli r18,r6,36
	ctx.r18.s64 = ctx.r6.s64 * 36;
	// fsubs f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// lfs f18,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f18.f64 = double(temp.f32);
	// fadds f1,f2,f4
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fsubs f2,f5,f3
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fmsubs f30,f30,f21,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f21.f64 - ctx.f27.f64));
	// lfs f21,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f31,f7
	ctx.f27.f64 = double(float(ctx.f31.f64 - ctx.f7.f64));
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fadds f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// add r31,r19,r3
	ctx.r31.u64 = ctx.r19.u64 + ctx.r3.u64;
	// add r30,r18,r3
	ctx.r30.u64 = ctx.r18.u64 + ctx.r3.u64;
	// mulli r7,r6,124
	ctx.r7.s64 = ctx.r6.s64 * 124;
	// fadds f3,f1,f28
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// fsubs f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fadds f28,f2,f6
	ctx.f28.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// stw r31,308(r1)
	PPC_STORE_U32(ctx.r1.u32 + 308, ctx.r31.u32);
	// fsubs f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// stw r30,324(r1)
	PPC_STORE_U32(ctx.r1.u32 + 324, ctx.r30.u32);
	// fadds f31,f27,f4
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// fsubs f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 - ctx.f4.f64));
	// lfs f27,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f27.f64 = double(temp.f32);
	// fadds f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// mulli r5,r6,92
	ctx.r5.s64 = ctx.r6.s64 * 92;
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// lfs f5,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f5,f20
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmuls f14,f27,f20
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// lfsx f20,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f16,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f5,f5,f20,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f20.f64 - ctx.f14.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmadds f27,f27,f20,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 + ctx.f15.f64));
	// lfsx f16,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// mulli r28,r6,48
	ctx.r28.s64 = ctx.r6.s64 * 48;
	// lfsx f16,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,52(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// stfs f5,96(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f5,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f14,f24,f5
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// lfsx f16,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f15,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r30,r6,28
	ctx.r30.s64 = ctx.r6.s64 * 28;
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f17,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f26,f17
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfsx f16,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// mulli r31,r6,60
	ctx.r31.s64 = ctx.r6.s64 * 60;
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// stfs f5,20(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmsubs f26,f26,f20,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 - ctx.f17.f64));
	// fmadds f5,f25,f20,f15
	ctx.f5.f64 = double(float(ctx.f25.f64 * ctx.f20.f64 + ctx.f15.f64));
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f25,f23,f20,f14
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f20.f64 + ctx.f14.f64));
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f22,f17
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmuls f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f24,f24,f20,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f20.f64 - ctx.f14.f64));
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f23,f21,f20,f15
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f15.f64));
	// fadds f21,f5,f29
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fmuls f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// fsubs f5,f29,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// fadds f29,f25,f27
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fmuls f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// lfs f25,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f22,f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f20.f64 - ctx.f17.f64));
	// lfs f17,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f26,f30
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// fadds f26,f24,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fmadds f19,f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f15.f64));
	// stfs f19,96(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f24,f29,f21
	ctx.f24.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// fmsubs f19,f18,f16,f14
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f29,f21,f29
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,52(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f20,f26
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// lfsx f16,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f25,f5
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// stfs f19,72(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fsubs f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f25,f30,f27
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// lfsx f19,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// lfsx f16,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f27,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f17,f19
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f19.f64));
	// lfsx f18,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f27,f19
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f18,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f18
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f19,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmr f19,f18
	ctx.f19.f64 = ctx.f18.f64;
	// mulli r27,r6,80
	ctx.r27.s64 = ctx.r6.s64 * 80;
	// fmsubs f27,f27,f19,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f19.f64 - ctx.f15.f64));
	// stfs f27,36(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fmadds f18,f17,f19,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 + ctx.f16.f64));
	// stfs f18,120(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f14.f64));
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// lfs f27,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f27,f18
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f15,f19,f18
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f14.f64));
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f27,f17,f15
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f27,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fmadds f16,f27,f16,f14
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,56(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f23,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f23,52(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f23,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,140(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,208(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,240(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f22,f15
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f14,264(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f22,152(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f23,f22
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfs f15,312(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f15,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfs f23,136(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// mulli r26,r6,112
	ctx.r26.s64 = ctx.r6.s64 * 112;
	// fmuls f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// lfs f22,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// rlwinm r17,r6,3,0,28
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f22,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// mulli r16,r6,104
	ctx.r16.s64 = ctx.r6.s64 * 104;
	// fmsubs f27,f18,f22,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f27.f64));
	// lfsx f22,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f18,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,96(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfsx f18,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r15,r6,72
	ctx.r15.s64 = ctx.r6.s64 * 72;
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f18,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f27,160(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stfs f18,72(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f27,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f22,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f18,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f22.f64));
	// stfs f18,112(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fmuls f18,f15,f27
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f27.f64));
	// fmuls f15,f23,f27
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// add r25,r17,r4
	ctx.r25.u64 = ctx.r17.u64 + ctx.r4.u64;
	// add r24,r16,r4
	ctx.r24.u64 = ctx.r16.u64 + ctx.r4.u64;
	// stw r25,268(r1)
	PPC_STORE_U32(ctx.r1.u32 + 268, ctx.r25.u32);
	// stw r24,284(r1)
	PPC_STORE_U32(ctx.r1.u32 + 284, ctx.r24.u32);
	// lfs f27,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// stfs f27,20(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// fmr f27,f22
	ctx.f27.f64 = ctx.f22.f64;
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f23,f27,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f18.f64));
	// stfs f23,16(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f23,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f27,f23,f27,f15
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 - ctx.f15.f64));
	// stfs f27,48(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// lfs f27,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f27,f23
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// lfs f27,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f22,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64 + ctx.f14.f64));
	// stfs f27,28(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f27,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f23
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// lfs f23,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f23,f23,f22,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 - ctx.f14.f64));
	// stfs f23,36(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f22
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f23,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// stfs f23,20(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f23,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f22,f27,f23,f18
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f18.f64));
	// lfs f27,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f23,f27,f23,f15
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 - ctx.f15.f64));
	// lfs f27,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lfs f18,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f18,f18,f27,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f14.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f15,f27,f14
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f27.f64 - ctx.f14.f64));
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// add r25,r15,r4
	ctx.r25.u64 = ctx.r15.u64 + ctx.r4.u64;
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f16,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,40
	ctx.r14.s64 = ctx.r6.s64 * 40;
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// stw r25,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r25.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// fadds f14,f17,f19
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f14,248(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,228(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// add r22,r14,r4
	ctx.r22.u64 = ctx.r14.u64 + ctx.r4.u64;
	// mulli r25,r6,120
	ctx.r25.s64 = ctx.r6.s64 * 120;
	// stw r22,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r22.u32);
	// stw r25,320(r1)
	PPC_STORE_U32(ctx.r1.u32 + 320, ctx.r25.u32);
	// mulli r24,r6,88
	ctx.r24.s64 = ctx.r6.s64 * 88;
	// stw r24,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r24.u32);
	// mulli r23,r6,56
	ctx.r23.s64 = ctx.r6.s64 * 56;
	// stw r23,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r23.u32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f19,f15
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f17,216(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,200(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f17,f19
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lwz r22,160(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,220(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f19,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f19,f16
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f17,224(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// lfs f16,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f19,236(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f16,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f15,f19,f16
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// fmuls f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// add r22,r25,r4
	ctx.r22.u64 = ctx.r25.u64 + ctx.r4.u64;
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f16,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f16,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stw r22,56(r1)
	PPC_STORE_U32(ctx.r1.u32 + 56, ctx.r22.u32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// add r22,r24,r4
	ctx.r22.u64 = ctx.r24.u64 + ctx.r4.u64;
	// stw r22,52(r1)
	PPC_STORE_U32(ctx.r1.u32 + 52, ctx.r22.u32);
	// add r22,r23,r4
	ctx.r22.u64 = ctx.r23.u64 + ctx.r4.u64;
	// stw r22,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r22.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f19,f19,f16,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f19,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f17,f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// stfs f19,32(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f19,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f17
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// lwz r25,96(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mulli r24,r6,20
	ctx.r24.s64 = ctx.r6.s64 * 20;
	// mulli r23,r6,84
	ctx.r23.s64 = ctx.r6.s64 * 84;
	// lfs f17,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lwz r25,56(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// fmadds f19,f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f16.f64));
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// stw r24,304(r1)
	PPC_STORE_U32(ctx.r1.u32 + 304, ctx.r24.u32);
	// fmsubs f19,f19,f17,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 - ctx.f15.f64));
	// stfs f19,72(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f19,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// stw r23,328(r1)
	PPC_STORE_U32(ctx.r1.u32 + 328, ctx.r23.u32);
	// fadds f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// stfs f17,112(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f23,108(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f23,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f22,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lwz r25,52(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	// lfs f17,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f19,f22,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f14.f64));
	// fmsubs f17,f17,f22,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 - ctx.f16.f64));
	// lfs f22,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// mulli r25,r6,24
	ctx.r25.s64 = ctx.r6.s64 * 24;
	// fmadds f16,f23,f22,f15
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f15.f64));
	// lfs f23,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f23.f64 = double(temp.f32);
	// stw r25,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r25.u32);
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f15,f23,f22,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 - ctx.f15.f64));
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f22,f18
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fadds f18,f14,f27
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f27.f64));
	// fsubs f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 - ctx.f27.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f14,192(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f23,212(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f23,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f14,f23,f18
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f14,196(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f23,204(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f23,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f23.f64 = double(temp.f32);
	// fadds f18,f27,f23
	ctx.f18.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// stfs f18,172(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// stfs f27,128(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f27,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f23,f27,f22
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// stfs f23,112(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// stfs f27,88(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f23.f64 = double(temp.f32);
	// lfs f27,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f23,f22
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// fmuls f14,f27,f22
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// lfs f22,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f27,f27,f22,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64 + ctx.f18.f64));
	// fmsubs f23,f23,f22,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 - ctx.f14.f64));
	// mulli r22,r6,116
	ctx.r22.s64 = ctx.r6.s64 * 116;
	// fadds f22,f27,f19
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// stfs f27,116(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f27,f23,f17
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// stfs f27,24(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f27,f17,f23
	ctx.f27.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// stfs f27,48(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f27,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// stw r22,36(r1)
	PPC_STORE_U32(ctx.r1.u32 + 36, ctx.r22.u32);
	// add r22,r25,r4
	ctx.r22.u64 = ctx.r25.u64 + ctx.r4.u64;
	// lfsx f18,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,76(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f18,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// stw r22,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r22.u32);
	// add r22,r24,r3
	ctx.r22.u64 = ctx.r24.u64 + ctx.r3.u64;
	// stw r22,40(r1)
	PPC_STORE_U32(ctx.r1.u32 + 40, ctx.r22.u32);
	// add r22,r23,r3
	ctx.r22.u64 = ctx.r23.u64 + ctx.r3.u64;
	// stw r22,72(r1)
	PPC_STORE_U32(ctx.r1.u32 + 72, ctx.r22.u32);
	// lwz r22,36(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// add r22,r22,r3
	ctx.r22.u64 = ctx.r22.u64 + ctx.r3.u64;
	// stw r22,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, ctx.r22.u32);
	// lwz r25,20(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// lfs f23,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lwz r25,40(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lfs f19,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lwz r25,36(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// lfsx f18,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r25,72(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f18,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f18,f27
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f18,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f27
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f27,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,32(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// stfs f27,108(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f27,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f18,f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f23.f64 + ctx.f17.f64));
	// stfs f18,104(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f18,f27,f19
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// lfs f19,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f23,f19,f23,f14
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,16(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f23,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f19,f23
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfs f19,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f23
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfs f23,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f27,f27,f23,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f19.f64));
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f23,f19,f23,f18
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f23.f64 - ctx.f18.f64));
	// stfs f23,28(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f19,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfs f23,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// stfs f23,76(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f23,f18,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f18.f64 + ctx.f17.f64));
	// fmsubs f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f16
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,108(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// mulli r25,r6,52
	ctx.r25.s64 = ctx.r6.s64 * 52;
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// mulli r24,r6,76
	ctx.r24.s64 = ctx.r6.s64 * 76;
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,180(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// stw r25,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r25.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,132(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f15,f17
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f16,288(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f17,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f19
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f17,f27,f23
	ctx.f17.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// mulli r25,r6,12
	ctx.r25.s64 = ctx.r6.s64 * 12;
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfs f27,24(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f27,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f27.f64));
	// stfs f27,60(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f23,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f23.f64 = double(temp.f32);
	// lfs f27,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f27.f64 = double(temp.f32);
	// mulli r23,r6,108
	ctx.r23.s64 = ctx.r6.s64 * 108;
	// fmsubs f27,f27,f23,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 - ctx.f15.f64));
	// stfs f27,68(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f23,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f23.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,124(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lwz r22,120(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// add r22,r22,r3
	ctx.r22.u64 = ctx.r22.u64 + ctx.r3.u64;
	// lfs f19,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// stw r22,260(r1)
	PPC_STORE_U32(ctx.r1.u32 + 260, ctx.r22.u32);
	// lwz r22,120(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// fmuls f15,f23,f19
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfsx f17,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f27,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,32(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f27,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,116(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f27,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,104(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfsx f27,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,156(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfsx f27,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,28(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f27,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,92(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f27,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f27,f19
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f23,f19,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 + ctx.f16.f64));
	// stfs f23,80(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmsubs f27,f27,f19,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f19.f64 - ctx.f15.f64));
	// lfs f23,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// stfs f27,64(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmuls f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f27,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f27,f19
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// lfs f27,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f27.f64 = double(temp.f32);
	// mulli r22,r6,44
	ctx.r22.s64 = ctx.r6.s64 * 44;
	// fmuls f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// stfs f27,32(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f19,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f19.f64 = double(temp.f32);
	// fmr f27,f19
	ctx.f27.f64 = ctx.f19.f64;
	// fmadds f19,f23,f27,f17
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f17.f64));
	// lfs f23,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f17,f23,f27,f16
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 - ctx.f16.f64));
	// lfs f23,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f23.f64 = double(temp.f32);
	// lfs f27,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f23,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 + ctx.f15.f64));
	// stfs f27,44(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f27,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f27,f27,f23,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f23.f64 - ctx.f16.f64));
	// stfs f27,16(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f27,f18,f23
	ctx.f27.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// fsubs f18,f16,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f15,f18,f27
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// fadds f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f23,296(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f23,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f16,f23
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// stfs f18,184(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fadds f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// stfs f23,116(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f23,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f23,f15
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// fadds f16,f15,f23
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// lfs f23,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f15,f27,f23
	ctx.f15.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fmuls f23,f18,f0
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f23,272(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fmuls f23,f16,f0
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f23,68(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fmuls f23,f15,f0
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f23,168(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// lfs f23,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// stfs f27,60(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f15,f23,f18
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f27,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// stfs f18,84(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// fmadds f27,f27,f16,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f23,f23,f16,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 - ctx.f15.f64));
	// stfs f23,124(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f23,f16
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfs f23,24(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f23,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// lfs f16,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,92(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f23,84(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f23,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// fadds f16,f16,f23
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// stfs f23,144(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f23,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f16,f17,f23
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// stfs f23,100(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f23,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f17,f6,f23
	ctx.f17.f64 = double(float(ctx.f6.f64 - ctx.f23.f64));
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// stfs f6,32(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f6,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f17,f6
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f17,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f6,f17,f6
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// stfs f6,84(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfsx f23,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f6,f17,f23,f16
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 + ctx.f16.f64));
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f23,f17,f23,f16
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 - ctx.f16.f64));
	// lfs f16,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f6,f27
	ctx.f17.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// fadds f27,f23,f16
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// fadds f16,f17,f19
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// fadds f17,f18,f27
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f27.f64));
	// stfs f17,104(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fadds f17,f23,f6
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// fsubs f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// stfs f27,124(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f6.f64));
	// lfs f23,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f23.f64 = double(temp.f32);
	// lfs f27,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// stfs f27,92(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f27,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f23,f17,f27
	ctx.f23.f64 = double(float(ctx.f17.f64 - ctx.f27.f64));
	// fadds f18,f27,f17
	ctx.f18.f64 = double(float(ctx.f27.f64 + ctx.f17.f64));
	// lfs f27,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f17,f27,f6
	ctx.f17.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// fadds f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fmuls f27,f23,f0
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f27,252(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmuls f27,f18,f0
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f27,24(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f27,f17,f0
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f27,164(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f6,28(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f6,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f6.f64 = double(temp.f32);
	// fadds f27,f6,f24
	ctx.f27.f64 = double(float(ctx.f6.f64 + ctx.f24.f64));
	// lfs f6,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f6.f64 = double(temp.f32);
	// fadds f23,f16,f6
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f6.f64));
	// fadds f6,f23,f27
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// lfs f23,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f23.f64 = double(temp.f32);
	// fadds f18,f23,f26
	ctx.f18.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f17,f18
	ctx.f23.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f6.f64));
	// stfsx f17,r31,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f27,f17
	ctx.f17.f64 = double(float(ctx.f27.f64 - ctx.f17.f64));
	// stfsx f17,r8,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fadds f27,f27,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f17.f64));
	// stfsx f27,r5,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f27,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fadds f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// stfs f6,0(r3)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f6,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f27,f6,f23
	ctx.f27.f64 = double(float(ctx.f6.f64 - ctx.f23.f64));
	// stfsx f27,r9,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f27,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f27.f64 = double(temp.f32);
	// fadds f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// fsubs f17,f18,f27
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f27,f18,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 + ctx.f27.f64));
	// stfsx f27,r7,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// stfsx f6,r30,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f6.f64));
	// stfs f6,16(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f6,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f6,f30,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// stfs f6,100(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f6,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f6.f64 = double(temp.f32);
	// lfs f27,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// stfs f6,44(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f6,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f6.f64 = double(temp.f32);
	// lfs f27,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// stfs f6,80(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f6,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f12
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f6,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f18,f6,f13
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// stfs f6,88(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f17,f27,f12
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmadds f6,f27,f13,f23
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 + ctx.f23.f64));
	// lfs f23,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f12,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 - ctx.f18.f64));
	// lfs f18,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f27,f15,f0
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmsubs f18,f18,f13,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f18,132(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f13,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f18,88(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,152(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f18,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f18.f64 = double(temp.f32);
	// fadds f5,f18,f5
	ctx.f5.f64 = double(float(ctx.f18.f64 + ctx.f5.f64));
	// stfs f5,60(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f5,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfs f5,68(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f5,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f30,f5,f8
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmuls f17,f5,f9
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f5,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f5,f8
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f5,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f5,f9,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f30.f64));
	// lfs f30,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f9,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 - ctx.f18.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f8,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 - ctx.f17.f64));
	// fsubs f17,f31,f27
	ctx.f17.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// stfs f17,100(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fadds f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fmadds f17,f17,f9,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f15.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f17,f23,f6
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// stfs f17,128(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f23.f64));
	// stfs f31,144(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f6,16(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f31,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f31.f64 = double(temp.f32);
	// lfs f6,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f27,f31,f6
	ctx.f27.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// stfs f27,80(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f27,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f27.f64 = double(temp.f32);
	// fadds f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f23,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f31,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f31,f31,f11,f27
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f11.f64 - ctx.f27.f64));
	// lfs f27,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f11,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f23.f64));
	// lfs f23,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f10,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f17.f64));
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f10,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f15.f64));
	// fadds f15,f30,f5
	ctx.f15.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// fsubs f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfs f5,88(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f30,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f30.f64 = double(temp.f32);
	// lfs f5,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfs f5,68(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f5,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f5.f64 = double(temp.f32);
	// lfs f30,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f5
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfs f30,60(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f30,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// lfs f30,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// stfsx f30,r28,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// stfsx f30,r25,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// stfsx f15,r24,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// stfsx f30,r26,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f15,f30,f5
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfsx f15,r23,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// lfs f30,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f5,r27,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// lfs f5,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f5.f64 = double(temp.f32);
	// lfs f26,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f5,f24,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 - ctx.f5.f64));
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// lfs f24,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// lfs f16,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f16.f64));
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f15.f64));
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f6.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f14,f23,f31
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fsubs f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// stfs f31,132(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f31,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f31.f64 = double(temp.f32);
	// lfs f23,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f31
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// stfs f23,100(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f23,f27,f17
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f17.f64));
	// stfs f23,144(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f23,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// fadds f27,f17,f27
	ctx.f27.f64 = double(float(ctx.f17.f64 + ctx.f27.f64));
	// fsubs f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// stfs f31,92(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f23,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f23.f64 = double(temp.f32);
	// lfs f31,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// stfs f31,84(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f23,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f23.f64 = double(temp.f32);
	// lfs f31,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f31.f64 = double(temp.f32);
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f17,f17,f7
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f7.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f23.f64));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f7,f7,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f17.f64));
	// lfs f17,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f1,f23
	ctx.f23.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// fadds f1,f17,f1
	ctx.f1.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// lfs f17,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f17,148(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f17,f30,f5
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// fsubs f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// fsubs f30,f26,f24
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fsubs f24,f3,f22
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// fadds f3,f22,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// fsubs f22,f2,f16
	ctx.f22.f64 = double(float(ctx.f2.f64 - ctx.f16.f64));
	// fadds f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// fsubs f16,f15,f18
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfsx f16,r22,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfsx f18,r29,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f18,f14
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfsx f16,r9,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfsx f18,r30,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfsx f15,r7,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfsx f18,r10,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfsx f15,r5,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfsx f18,r8,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// fadds f16,f31,f18
	ctx.f16.f64 = double(float(ctx.f31.f64 + ctx.f18.f64));
	// fsubs f31,f18,f31
	ctx.f31.f64 = double(float(ctx.f18.f64 - ctx.f31.f64));
	// fsubs f18,f6,f27
	ctx.f18.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// stfsx f18,r31,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// stfs f6,0(r4)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f6,f16,f0
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f27,f30,f17
	ctx.f27.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// fsubs f18,f26,f5
	ctx.f18.f64 = double(float(ctx.f26.f64 - ctx.f5.f64));
	// fadds f26,f26,f5
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// fsubs f17,f30,f17
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f17.f64));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f5,f27,f0
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f30,f18,f0
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f27,f26,f0
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f26,f17,f0
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f24,f5
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f5.f64));
	// stfsx f18,r22,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// fadds f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// stfsx f5,r29,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f5,f30,f22
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// stfsx f5,r27,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f30,f22
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// stfsx f5,r23,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f3,f27
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f27.f64));
	// stfsx f5,r28,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f27,f3
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// stfsx f5,r25,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f26,f2
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f2.f64));
	// stfsx f5,r26,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f26,f2
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// lfs f26,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f30.f64 = double(temp.f32);
	// lfs f27,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f19.f64));
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// lfs f19,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f19.f64 = double(temp.f32);
	// lfs f26,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f2,f24,f17
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// fadds f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// lfs f22,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f3,f29,f18
	ctx.f3.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfsx f5,r24,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f21,f22
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f21,f13
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fadds f21,f6,f23
	ctx.f21.f64 = double(float(ctx.f6.f64 + ctx.f23.f64));
	// fsubs f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f6.f64));
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// fsubs f17,f26,f27
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfs f27,140(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmuls f14,f24,f13
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmuls f23,f3,f13
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f16,f5,f13
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f26,f22,f12
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f26,184(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f18,f30,f12
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f15,f2,f12
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmsubs f24,f24,f12,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 - ctx.f19.f64));
	// fmuls f27,f17,f0
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmadds f5,f5,f12,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f23.f64));
	// lfs f23,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f26,f23,f12,f14
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f14.f64));
	// fmsubs f3,f3,f12,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f16.f64));
	// fmsubs f2,f2,f13,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 - ctx.f18.f64));
	// fmadds f30,f30,f13,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f23,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f23.f64 = double(temp.f32);
	// stfs f22,140(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f29,f13,f18
	ctx.f22.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 - ctx.f18.f64));
	// fadds f18,f27,f7
	ctx.f18.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fadds f27,f22,f26
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// lfs f19,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f29,f29,f12,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 + ctx.f19.f64));
	// fadds f19,f2,f5
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fsubs f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// fsubs f2,f30,f3
	ctx.f2.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// fadds f3,f30,f3
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fadds f30,f23,f1
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// fsubs f16,f21,f19
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f24,f29
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// lfs f15,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// stfsx f16,r10,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,36(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// stfsx f21,r17,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fsubs f21,f2,f18
	ctx.f21.f64 = double(float(ctx.f2.f64 - ctx.f18.f64));
	// stfsx f21,r15,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f18,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 + ctx.f2.f64));
	// lfs f18,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f18.f64 = double(temp.f32);
	// fadds f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// lfs f21,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f2,r10,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,328(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	// fsubs f2,f5,f7
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfsx f2,r16,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f5,f20,f18
	ctx.f5.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,304(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// fsubs f7,f6,f3
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// stfsx f7,r14,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f3,f6
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,280(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// fsubs f7,f30,f27
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfsx f7,r10,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f27,f30
	ctx.f7.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfsx f7,r21,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,320(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	// lfs f7,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f7,f31,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// lfs f30,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f2,f25,f30
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fadds f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// fadds f25,f18,f20
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfs f18,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f31,f22,f31
	ctx.f31.f64 = double(float(ctx.f22.f64 - ctx.f31.f64));
	// fsubs f6,f17,f7
	ctx.f6.f64 = double(float(ctx.f17.f64 - ctx.f7.f64));
	// stfsx f6,r10,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f7,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f17.f64));
	// stfsx f7,r19,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f6.f64 = double(temp.f32);
	// fadds f3,f7,f6
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// lfs f7,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f7.f64 = double(temp.f32);
	// lfs f17,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f27,f7,f13
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f7,f17,f12
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f7,164(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f7,f14,f19
	ctx.f7.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// fadds f6,f15,f21
	ctx.f6.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// lfs f15,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f12
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmsubs f27,f16,f12,f27
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f27.f64));
	// fmuls f24,f15,f0
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmadds f23,f16,f13,f14
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f20,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f18,f13,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f20.f64));
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fmsubs f22,f17,f13,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f22,180(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f18,f28,f3
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f3.f64));
	// stfs f18,168(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f22,f6,f11
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f18,f7,f11
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fmuls f17,f2,f8
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lwz r10,188(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// fmuls f16,f2,f9
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fadds f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f28.f64));
	// addi r11,r11,248
	ctx.r11.s64 = ctx.r11.s64 + 248;
	// fsubs f28,f26,f31
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f31.f64));
	// fadds f2,f20,f27
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// stfs f2,172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f2,f19,f9
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// stfsx f28,r10,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// stfs f2,176(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f15,f30,f11
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fmuls f14,f30,f10
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fmuls f30,f21,f9
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// stfs f30,188(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fadds f31,f31,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f26.f64));
	// stfsx f31,r20,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f7,f7,f10,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64 - ctx.f22.f64));
	// fsubs f31,f1,f29
	ctx.f31.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfsx f31,r18,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f31,f5,f9,f17
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 - ctx.f17.f64));
	// fadds f1,f29,f1
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// lfs f29,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f29.f64 = double(temp.f32);
	// stfsx f1,r10,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f24,f4
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// fadds f30,f29,f23
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// lwz r10,244(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// fsubs f1,f20,f27
	ctx.f1.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f4,f4,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f24.f64));
	// addic. r9,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r9.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// lwz r10,256(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	// fmsubs f27,f25,f11,f14
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f14.f64));
	// fmadds f28,f25,f10,f15
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f15.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fmadds f5,f5,f8,f16
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 + ctx.f16.f64));
	// subf r4,r10,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r10.s64;
	// lwz r10,260(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// fmadds f6,f6,f10,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 + ctx.f18.f64));
	// stw r9,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r9.u32);
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f26,f21,f8,f22
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 + ctx.f22.f64));
	// lfs f22,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f22.f64 = double(temp.f32);
	// fadds f21,f29,f4
	ctx.f21.f64 = double(float(ctx.f29.f64 + ctx.f4.f64));
	// fmsubs f25,f19,f8,f22
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 - ctx.f22.f64));
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fadds f24,f19,f20
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f29.f64));
	// fsubs f29,f20,f19
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f19,f1,f2
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fsubs f20,f6,f27
	ctx.f20.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fadds f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// fadds f23,f26,f31
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// fsubs f31,f26,f31
	ctx.f31.f64 = double(float(ctx.f26.f64 - ctx.f31.f64));
	// fsubs f22,f25,f5
	ctx.f22.f64 = double(float(ctx.f25.f64 - ctx.f5.f64));
	// fadds f5,f25,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// fadds f26,f30,f3
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fadds f25,f28,f7
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// fsubs f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// fsubs f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fsubs f1,f24,f23
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,268(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// fadds f1,f23,f24
	ctx.f1.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,276(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// fsubs f1,f22,f21
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,160(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// fadds f1,f21,f22
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,72(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// fsubs f1,f31,f4
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f4.f64));
	// fadds f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,284(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stfs f4,0(r10)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// fsubs f4,f29,f5
	ctx.f4.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// stfs f4,0(r10)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,40(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// fadds f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// stfs f5,0(r10)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,292(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// fsubs f5,f26,f25
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f5,0(r10)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,300(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// fadds f5,f25,f26
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f5,0(r10)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,308(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// fsubs f5,f20,f19
	ctx.f5.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f5,0(r10)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,56(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// fadds f5,f19,f20
	ctx.f5.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f5,0(r10)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// fsubs f5,f7,f2
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fadds f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// stfs f5,0(r10)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,52(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	// stfs f7,0(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// fsubs f7,f3,f6
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// stfs f7,0(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,20(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fadds f7,f6,f3
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// stfs f7,0(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,332(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d550f0
	if (!ctx.cr0.eq) goto loc_82D550F0;
loc_82D565B0:
	// addi r1,r1,640
	ctx.r1.s64 = ctx.r1.s64 + 640;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D565BC;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D565C0"))) PPC_WEAK_FUNC(sub_82D565C0);
PPC_FUNC_IMPL(__imp__sub_82D565C0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1136
	ctx.r5.s64 = ctx.r11.s64 + -1136;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,20600
	ctx.r4.s64 = ctx.r11.s64 + 20600;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D565D8"))) PPC_WEAK_FUNC(sub_82D565D8);
PPC_FUNC_IMPL(__imp__sub_82D565D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D565E0;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D565E8;
	__savefpr_14(ctx, base);
	// mulli r11,r7,120
	ctx.r11.s64 = ctx.r7.s64 * 120;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-120
	ctx.r11.s64 = ctx.r11.s64 + -120;
	// bge cr6,0x82d56cd0
	if (!ctx.cr6.lt) goto loc_82D56CD0;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r21,r7,r8
	ctx.r21.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// stw r10,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f12,136(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D56620:
	// rlwinm r10,r6,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f11,56(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r9,r6,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r29,r6,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f8,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// mulli r28,r6,40
	ctx.r28.s64 = ctx.r6.s64 * 40;
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f30,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f28,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f11,f30
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f19,f9,f28
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// lfsx f29,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f10,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfsx f27,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f28,f8,f28
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f3,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f3.f64 = double(temp.f32);
	// add r20,r29,r3
	ctx.r20.u64 = ctx.r29.u64 + ctx.r3.u64;
	// lfs f2,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f2.f64 = double(temp.f32);
	// add r19,r28,r3
	ctx.r19.u64 = ctx.r28.u64 + ctx.r3.u64;
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// mulli r8,r6,48
	ctx.r8.s64 = ctx.r6.s64 * 48;
	// lfs f7,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f23,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f21,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f10,f10,f29,f20
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64 + ctx.f20.f64));
	// lfs f22,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f8,f8,f27,f19
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 + ctx.f19.f64));
	// fmsubs f11,f11,f29,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 - ctx.f30.f64));
	// lfsx f26,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f9,f9,f27,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f28.f64));
	// lfsx f25,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f28,f3,f22
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// mulli r27,r6,56
	ctx.r27.s64 = ctx.r6.s64 * 56;
	// fmuls f30,f5,f24
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f29,f4,f24
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// lfs f31,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// lfs f27,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f7,f26
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// fmuls f26,f6,f26
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// mulli r26,r6,24
	ctx.r26.s64 = ctx.r6.s64 * 24;
	// fmadds f4,f4,f23,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 + ctx.f30.f64));
	// fmadds f30,f2,f21,f28
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f21.f64 + ctx.f28.f64));
	// lfs f2,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f5,f5,f23,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f29.f64));
	// lfs f23,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f3,f3,f21,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f21.f64 - ctx.f22.f64));
	// lfsx f19,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f6,f6,f25,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f18.f64));
	// lfsx f21,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f7,f7,f25,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 - ctx.f26.f64));
	// add r18,r27,r3
	ctx.r18.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fadds f29,f10,f1
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f1.f64));
	// add r17,r26,r3
	ctx.r17.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fsubs f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// lfs f26,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f28,f31,f11
	ctx.f28.f64 = double(float(ctx.f31.f64 - ctx.f11.f64));
	// lfs f25,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f25.f64 = double(temp.f32);
	// fadds f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f31.f64));
	// lfs f31,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f31.f64 = double(temp.f32);
	// mulli r7,r6,60
	ctx.r7.s64 = ctx.r6.s64 * 60;
	// fsubs f24,f4,f30
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// lfs f20,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f5,f3
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// lfs f30,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fadds f1,f6,f8
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// lfs f7,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f7.f64 = double(temp.f32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfs f3,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// mulli r5,r6,44
	ctx.r5.s64 = ctx.r6.s64 * 44;
	// fsubs f18,f24,f22
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// mulli r31,r6,28
	ctx.r31.s64 = ctx.r6.s64 * 28;
	// lfsx f15,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f31,f3
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// stfs f15,-368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// lfsx f15,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r25,r6,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f15,-372(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// mulli r24,r6,52
	ctx.r24.s64 = ctx.r6.s64 * 52;
	// lfsx f15,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-376(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f15,f7,f3
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// fmuls f3,f27,f20
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// stfs f3,-364(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fmuls f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// lfsx f22,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f16,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f17,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f7,f7,f21,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 - ctx.f14.f64));
	// mulli r30,r6,12
	ctx.r30.s64 = ctx.r6.s64 * 12;
	// fmadds f3,f31,f21,f15
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f21.f64 + ctx.f15.f64));
	// fmuls f21,f2,f22
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// fmsubs f27,f27,f19,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f19.f64 - ctx.f20.f64));
	// fmuls f20,f23,f16
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// mulli r23,r6,36
	ctx.r23.s64 = ctx.r6.s64 * 36;
	// fmuls f22,f25,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f22.f64));
	// add r22,r23,r4
	ctx.r22.u64 = ctx.r23.u64 + ctx.r4.u64;
	// add r16,r25,r4
	ctx.r16.u64 = ctx.r25.u64 + ctx.r4.u64;
	// add r15,r24,r4
	ctx.r15.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fmsubs f2,f2,f17,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64 - ctx.f22.f64));
	// lfs f22,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// stw r22,-312(r1)
	PPC_STORE_U32(ctx.r1.u32 + -312, ctx.r22.u32);
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f31,f26,f19,f15
	ctx.f31.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 + ctx.f15.f64));
	// fmuls f19,f30,f16
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f16.f64));
	// lfs f16,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f25,f17,f21
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f17.f64 + ctx.f21.f64));
	// lfs f25,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f30,f30,f25,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 + ctx.f20.f64));
	// lfs f21,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f22,f16
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f20,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f25,f23,f25,f19
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f25.f64 - ctx.f19.f64));
	// lfs f19,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f23,f3,f31
	ctx.f23.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f31,f7,f27
	ctx.f31.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fadds f7,f27,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fadds f27,f31,f23
	ctx.f27.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// fsubs f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// lfs f23,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f16
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f16,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f23,f23,f16,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-364(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfsx f14,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-376(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmadds f22,f22,f16,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfsx f16,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f15,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f26,f22
	ctx.f14.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f14,-356(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f26,-372(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fsubs f26,f2,f23
	ctx.f26.f64 = double(float(ctx.f2.f64 - ctx.f23.f64));
	// stfs f26,-384(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmuls f26,f21,f16
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfsx f22,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// stfs f2,-368(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fmuls f23,f20,f16
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// stfs f22,-352(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fmadds f26,f20,f15,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 + ctx.f26.f64));
	// stfs f26,-380(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f2,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f19,f2
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// fmuls f20,f17,f2
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmsubs f2,f21,f15,f23
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f15.f64 - ctx.f23.f64));
	// stfs f2,-360(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f2,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f2.f64 = double(temp.f32);
	// lfs f23,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f2,f23
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// fmuls f14,f26,f23
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f23,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// stfs f22,-364(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f22,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f21,f17,f22,f16
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 + ctx.f16.f64));
	// fmsubs f20,f19,f22,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 - ctx.f20.f64));
	// lfs f22,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f19,f26,f22,f15
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 + ctx.f15.f64));
	// lfs f26,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f22,f2,f22,f14
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f2,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f2.f64 = double(temp.f32);
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// mulli r22,r6,20
	ctx.r22.s64 = ctx.r6.s64 * 20;
	// lfs f14,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r22,r4
	ctx.r14.u64 = ctx.r22.u64 + ctx.r4.u64;
	// lfs f16,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f2,f26,f16
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f26.f64 + ctx.f16.f64));
	// fsubs f16,f15,f30
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f30.f64));
	// fadds f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// fsubs f15,f14,f25
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// fadds f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// stfs f14,-324(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,-344(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f16,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f25
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// stfs f16,-320(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f16,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,-340(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f16,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f24,f31
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f31.f64));
	// fmuls f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// fsubs f16,f21,f17
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfs f16,-376(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fadds f16,f27,f18
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// fadds f17,f1,f29
	ctx.f17.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// fmsubs f2,f23,f26,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 - ctx.f2.f64));
	// fmuls f23,f16,f0
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f23,-356(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fmuls f16,f14,f0
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f26,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f26,-352(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f10,f6
	ctx.f26.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f23,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f13,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f15,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f12,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f14.f64));
	// fsubs f14,f20,f2
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f2.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fadds f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// stfs f2,-364(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f2,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f2.f64 = double(temp.f32);
	// fadds f20,f2,f26
	ctx.f20.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// stfs f20,-356(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fsubs f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 - ctx.f2.f64));
	// stfs f2,-360(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fadds f2,f8,f28
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fsubs f26,f2,f16
	ctx.f26.f64 = double(float(ctx.f2.f64 - ctx.f16.f64));
	// stfs f26,-384(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fadds f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// stfs f2,-348(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f2,f3,f4
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fadds f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f17.f64));
	// stfs f2,-332(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// lfsx f20,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// lfs f2,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f2.f64 = double(temp.f32);
	// lfs f26,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f2,f20
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// fmuls f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lfs f27,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// fadds f27,f7,f5
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fmadds f26,f26,f16,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f2,f2,f16,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f16.f64 - ctx.f20.f64));
	// fsubs f20,f26,f19
	ctx.f20.f64 = double(float(ctx.f26.f64 - ctx.f19.f64));
	// fadds f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// fsubs f19,f2,f22
	ctx.f19.f64 = double(float(ctx.f2.f64 - ctx.f22.f64));
	// fadds f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fsubs f16,f21,f26
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// fsubs f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f14,-352(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f14,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f2.f64));
	// stfs f14,-328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f14,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,-336(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f19,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f20,-376(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f19,f22,f12
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f20,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f12
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmsubs f20,f20,f13,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f19.f64));
	// fmadds f22,f22,f13,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f14.f64));
	// fadds f19,f23,f20
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f20,f15,f22
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f15,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f19
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfsx f14,r31,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfsx f14,r5,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfsx f23,r8,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f23,f19,f15
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f23,0(r4)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f23,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f19,f23,f20
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfsx f19,r9,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f19,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f19.f64 = double(temp.f32);
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// fsubs f15,f22,f19
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfsx f15,r7,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfsx f22,r10,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f22,f31,f24
	ctx.f22.f64 = double(float(ctx.f31.f64 + ctx.f24.f64));
	// lfs f24,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f19,f24,f12
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// stfsx f23,r30,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f31,f26,f21
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// lfs f21,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f21.f64 = double(temp.f32);
	// fadds f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// lfs f21,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f24,f13
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fadds f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f21.f64));
	// lfs f21,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f24,f23,f12
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stfs f24,-336(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fmuls f15,f20,f12
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fadds f26,f9,f11
	ctx.f26.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fmuls f6,f22,f0
	ctx.f6.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmadds f24,f21,f13,f19
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f19.f64));
	// fsubs f8,f28,f8
	ctx.f8.f64 = double(float(ctx.f28.f64 - ctx.f8.f64));
	// lfs f19,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f28,f21,f12,f14
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 - ctx.f14.f64));
	// addic. r21,r21,-1
	ctx.xer.ca = ctx.r21.u32 > 0;
	ctx.r21.s64 = ctx.r21.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r21.s32, 0, ctx.xer);
	// fmadds f21,f20,f13,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f19.f64));
	// addi r11,r11,120
	ctx.r11.s64 = ctx.r11.s64 + 120;
	// fadds f20,f3,f4
	ctx.f20.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fmsubs f23,f23,f13,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f15.f64));
	// fsubs f1,f29,f1
	ctx.f1.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fadds f9,f30,f31
	ctx.f9.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fsubs f5,f4,f3
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fsubs f3,f26,f27
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fsubs f4,f30,f31
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f31.f64));
	// fadds f29,f6,f10
	ctx.f29.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f31,f26,f27
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fadds f6,f23,f24
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f30,f25,f2
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f2.f64));
	// fsubs f27,f23,f24
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fmuls f22,f18,f0
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// fsubs f24,f1,f7
	ctx.f24.f64 = double(float(ctx.f1.f64 - ctx.f7.f64));
	// fadds f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f25.f64));
	// fadds f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// lfs f1,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f23,f1,f9
	ctx.f23.f64 = double(float(ctx.f1.f64 - ctx.f9.f64));
	// stfsx f23,r31,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fsubs f1,f4,f3
	ctx.f1.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfsx f1,r8,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// stfsx f4,r5,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// stfs f9,0(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f25,f21,f28
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f28.f64));
	// fsubs f26,f8,f22
	ctx.f26.f64 = double(float(ctx.f8.f64 - ctx.f22.f64));
	// lfs f4,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f9,f20,f30
	ctx.f9.f64 = double(float(ctx.f20.f64 - ctx.f30.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f22.f64));
	// fsubs f9,f2,f31
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f2,f31
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// stfsx f9,r7,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f30,f20
	ctx.f9.f64 = double(float(ctx.f30.f64 + ctx.f20.f64));
	// stfsx f9,r30,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// lwz r10,-316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// fsubs f9,f29,f6
	ctx.f9.f64 = double(float(ctx.f29.f64 - ctx.f6.f64));
	// stfsx f9,r26,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f6,f29
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fsubs f6,f27,f26
	ctx.f6.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// stfsx f6,r24,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f27,f26
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// stfsx f6,r28,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// stfsx f9,r25,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fsubs f9,f10,f25
	ctx.f9.f64 = double(float(ctx.f10.f64 - ctx.f25.f64));
	// stfsx f9,r22,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f25,f10
	ctx.f10.f64 = double(float(ctx.f25.f64 + ctx.f10.f64));
	// lfs f6,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f9,f28,f8
	ctx.f9.f64 = double(float(ctx.f28.f64 - ctx.f8.f64));
	// stfsx f9,r23,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f28,f8
	ctx.f9.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// lfs f8,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f8.f64 = double(temp.f32);
	// stfsx f9,r27,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f6,f4
	ctx.f9.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// stfsx f10,r29,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fadds f10,f8,f16
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f16.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f4,f11,f5
	ctx.f4.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// subf r4,r10,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r10.s64;
	// fadds f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fsubs f8,f16,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 - ctx.f8.f64));
	// fadds f5,f9,f10
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fsubs f3,f6,f8
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// fadds f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fmuls f10,f5,f0
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f8,f3,f0
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lwz r10,-312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fsubs f5,f24,f10
	ctx.f5.f64 = double(float(ctx.f24.f64 - ctx.f10.f64));
	// stfs f5,0(r14)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fadds f10,f10,f24
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f24.f64));
	// fsubs f5,f8,f4
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// stfs f5,0(r19)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fadds f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// stfs f8,0(r15)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// stfs f10,0(r20)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fsubs f10,f7,f6
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// stfs f10,0(r17)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// fsubs f10,f9,f11
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfs f10,0(r18)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// fadds f11,f6,f7
	ctx.f11.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfs f11,0(r16)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d56620
	if (!ctx.cr0.eq) goto loc_82D56620;
loc_82D56CD0:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D56CD8;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D56CE0"))) PPC_WEAK_FUNC(sub_82D56CE0);
PPC_FUNC_IMPL(__imp__sub_82D56CE0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1080
	ctx.r5.s64 = ctx.r11.s64 + -1080;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,26072
	ctx.r4.s64 = ctx.r11.s64 + 26072;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D56CF8"))) PPC_WEAK_FUNC(sub_82D56CF8);
PPC_FUNC_IMPL(__imp__sub_82D56CF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D56D00;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D56D08;
	__savefpr_14(ctx, base);
	// mulli r11,r7,112
	ctx.r11.s64 = ctx.r7.s64 * 112;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-112
	ctx.r11.s64 = ctx.r11.s64 + -112;
	// bge cr6,0x82d57424
	if (!ctx.cr6.lt) goto loc_82D57424;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// stw r10,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lfs f13,-7588(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lfs f0,-7584(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-28552(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f11.f64 = double(temp.f32);
	// stw r10,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r10.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f9,-12288(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -12288);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-7592(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7592);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f12.f64 = double(temp.f32);
loc_82D56D5C:
	// mulli r8,r6,40
	ctx.r8.s64 = ctx.r6.s64 * 40;
	// lfs f8,32(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f8.f64 = double(temp.f32);
	// mulli r10,r6,20
	ctx.r10.s64 = ctx.r6.s64 * 20;
	// lfs f7,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f2,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f29,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f8,f29
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// lfsx f28,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// add r27,r8,r3
	ctx.r27.u64 = ctx.r8.u64 + ctx.r3.u64;
	// fmuls f29,f7,f29
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// mulli r9,r6,24
	ctx.r9.s64 = ctx.r6.s64 * 24;
	// lfs f27,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f6,f27
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfsx f25,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// lfsx f24,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// add r26,r8,r4
	ctx.r26.u64 = ctx.r8.u64 + ctx.r4.u64;
	// fmadds f7,f7,f28,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 + ctx.f19.f64));
	// fmsubs f8,f8,f28,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 - ctx.f29.f64));
	// mulli r31,r6,44
	ctx.r31.s64 = ctx.r6.s64 * 44;
	// fmuls f29,f4,f25
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// fmuls f28,f3,f25
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f25,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f20,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f5,f5,f26,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64 + ctx.f18.f64));
	// fmsubs f6,f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 - ctx.f27.f64));
	// add r24,r31,r3
	ctx.r24.u64 = ctx.r31.u64 + ctx.r3.u64;
	// mulli r5,r6,36
	ctx.r5.s64 = ctx.r6.s64 * 36;
	// fmadds f3,f3,f24,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 + ctx.f29.f64));
	// fmsubs f4,f4,f24,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f28.f64));
	// lfs f24,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f24.f64 = double(temp.f32);
	// lfs f21,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f23,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f27,f2,f23
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// fadds f29,f5,f7
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// add r25,r5,r4
	ctx.r25.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fadds f7,f6,f8
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// mulli r30,r6,56
	ctx.r30.s64 = ctx.r6.s64 * 56;
	// fsubs f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fmuls f26,f1,f23
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// lfs f23,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f18,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f1,f1,f22,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f27.f64));
	// lfs f27,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// rlwinm r7,r6,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f8,f5,f12
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// add r23,r8,r3
	ctx.r23.u64 = ctx.r8.u64 + ctx.r3.u64;
	// fadds f28,f7,f30
	ctx.f28.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// add r22,r8,r4
	ctx.r22.u64 = ctx.r8.u64 + ctx.r4.u64;
	// fadds f5,f29,f31
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// add r21,r30,r3
	ctx.r21.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fnmsubs f7,f7,f11,f30
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f11.f64 - ctx.f30.f64)));
	// lfs f30,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f31,f29,f11,f31
	ctx.f31.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f31.f64)));
	// lfs f29,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f30,f21
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// add r20,r7,r3
	ctx.r20.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fmuls f21,f29,f21
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f21.f64));
	// add r19,r7,r4
	ctx.r19.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmsubs f2,f2,f22,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f26.f64));
	// lfs f26,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f26.f64 = double(temp.f32);
	// lfs f22,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f17,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f29,f29,f20,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfs f19,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f30,f30,f20,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f21,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f27,f21
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fmuls f21,f26,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// rlwinm r29,r6,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fmuls f15,f24,f19
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// mulli r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 * 12;
	// fmuls f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmuls f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// fmuls f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmadds f26,f26,f20,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f16.f64));
	// mulli r28,r6,48
	ctx.r28.s64 = ctx.r6.s64 * 48;
	// fmsubs f21,f27,f20,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f27,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f25,f25,f18,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f23,f23,f27,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 - ctx.f14.f64));
	// fmadds f24,f24,f18,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f19.f64));
	// fmadds f27,f22,f27,f17
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 + ctx.f17.f64));
	// fadds f22,f26,f29
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f26,f26,f29
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// rlwinm r7,r6,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r18,r6,52
	ctx.r18.s64 = ctx.r6.s64 * 52;
	// fadds f29,f21,f30
	ctx.f29.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// fsubs f20,f30,f21
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f30,f23,f25
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f21,f27,f24
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fsubs f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// add r17,r29,r3
	ctx.r17.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// add r16,r18,r3
	ctx.r16.u64 = ctx.r18.u64 + ctx.r3.u64;
	// add r18,r18,r4
	ctx.r18.u64 = ctx.r18.u64 + ctx.r4.u64;
	// add r15,r28,r4
	ctx.r15.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fadds f19,f29,f4
	ctx.f19.f64 = double(float(ctx.f29.f64 + ctx.f4.f64));
	// fnmsubs f4,f29,f11,f4
	ctx.f4.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f4.f64)));
	// fmuls f27,f20,f12
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmuls f29,f25,f12
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fadds f18,f21,f1
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fnmsubs f1,f21,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f21.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// fadds f20,f22,f3
	ctx.f20.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// fnmsubs f3,f22,f11,f3
	ctx.f3.f64 = double(float(-(ctx.f22.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// fadds f22,f30,f2
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fnmsubs f2,f30,f11,f2
	ctx.f2.f64 = double(float(-(ctx.f30.f64 * ctx.f11.f64 - ctx.f2.f64)));
	// fadds f25,f4,f26
	ctx.f25.f64 = double(float(ctx.f4.f64 + ctx.f26.f64));
	// stfs f25,-320(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f4,f4,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f26.f64));
	// stfs f4,-348(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfsx f26,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-360(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fsubs f4,f1,f29
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfs f4,-352(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fadds f4,f29,f1
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// lfsx f1,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,-356(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fsubs f30,f3,f27
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f27.f64));
	// lfsx f1,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// stfs f1,-336(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfsx f1,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f16,f24,f2
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// stfs f1,-340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fadds f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// lfsx f1,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f27,f18,f20
	ctx.f27.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f4,-312(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f4,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f24,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f15,f4
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// stfs f1,-332(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f25,f24,f4
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// lfsx f1,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,-328(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f29,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfs f4,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f4.f64 = double(temp.f32);
	// lfs f1,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f4,f29
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f14,f1,f29
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// lfs f29,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f26.f64));
	// lfs f26,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f26.f64 = double(temp.f32);
	// stfs f29,-356(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fmr f29,f26
	ctx.f29.f64 = ctx.f26.f64;
	// lfs f26,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// mulli r14,r6,28
	ctx.r14.s64 = ctx.r6.s64 * 28;
	// fsubs f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fmadds f25,f15,f29,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f29.f64 + ctx.f25.f64));
	// fmsubs f24,f24,f29,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 - ctx.f23.f64));
	// lfs f29,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// lfs f29,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f1,f1,f29,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f21.f64));
	// stfs f1,-364(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fmsubs f4,f4,f29,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f14.f64));
	// stfs f4,-368(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f29,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f29.f64 = double(temp.f32);
	// stw r14,-340(r1)
	PPC_STORE_U32(ctx.r1.u32 + -340, ctx.r14.u32);
	// lfs f1,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmuls f14,f1,f29
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// lfs f4,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f4,f29
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// lfs f23,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f26,f26,f23,f29
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f23.f64 + ctx.f29.f64));
	// lfs f29,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f23,f29,f23,f15
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f23.f64 - ctx.f15.f64));
	// lfs f29,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f4,f4,f29,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f14.f64));
	// stfs f4,-324(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmadds f21,f1,f29,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f21.f64));
	// lfs f29,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f29.f64 = double(temp.f32);
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// lfs f4,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f4.f64 = double(temp.f32);
	// fadds f15,f4,f25
	ctx.f15.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// lfs f4,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// stfs f4,-360(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f4,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f14,f4,f29
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// stfs f15,-336(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fmuls f29,f1,f29
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// stfs f29,-332(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fadds f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// stfs f15,-356(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f15,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f15.f64 = double(temp.f32);
	// fadds f29,f15,f23
	ctx.f29.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// lfs f15,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f19,f1,f15,f14
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f1,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f1.f64 = double(temp.f32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// fmsubs f24,f4,f15,f14
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f4,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f4.f64 = double(temp.f32);
	// stw r14,-364(r1)
	PPC_STORE_U32(ctx.r1.u32 + -364, ctx.r14.u32);
	// fsubs f25,f4,f25
	ctx.f25.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// lwz r14,-340(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	// lfs f4,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f4,f11,f26
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f26.f64)));
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fmuls f14,f22,f13
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// stw r14,-328(r1)
	PPC_STORE_U32(ctx.r1.u32 + -328, ctx.r14.u32);
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fmuls f26,f25,f12
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f25,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f23
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f23.f64)));
	// fsubs f23,f4,f1
	ctx.f23.f64 = double(float(ctx.f4.f64 - ctx.f1.f64));
	// fadds f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// stfs f4,-336(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f1,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f1.f64 = double(temp.f32);
	// fadds f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f4,-332(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f4,-360(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f4,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f4.f64 = double(temp.f32);
	// lwz r14,-364(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	// lfs f26,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f4,f26
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// fmuls f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lwz r14,-328(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	// lfs f25,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f1,f1,f25,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64 + ctx.f15.f64));
	// fmsubs f4,f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64 - ctx.f26.f64));
	// fadds f26,f1,f19
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f19.f64));
	// lfs f15,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f1,f19
	ctx.f25.f64 = double(float(ctx.f1.f64 - ctx.f19.f64));
	// fadds f1,f4,f24
	ctx.f1.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// fsubs f24,f24,f4
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// lfs f18,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f4,f25,f12
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fadds f19,f1,f15
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f15.f64));
	// fmuls f25,f24,f12
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fadds f24,f26,f21
	ctx.f24.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// fnmsubs f26,f26,f11,f21
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// lfs f21,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f1,f1,f11,f15
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f15.f64)));
	// fsubs f15,f29,f19
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// fadds f29,f19,f29
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// fadds f21,f24,f21
	ctx.f21.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// fsubs f19,f26,f25
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fadds f25,f1,f4
	ctx.f25.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fsubs f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// lfs f18,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f2.f64));
	// fadds f1,f21,f27
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// fsubs f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// fmuls f21,f15,f13
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f21,-324(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmadds f21,f15,f0,f14
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f14.f64));
	// fadds f15,f1,f5
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// stfs f15,0(r3)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fnmsubs f5,f1,f9,f5
	ctx.f5.f64 = double(float(-(ctx.f1.f64 * ctx.f9.f64 - ctx.f5.f64)));
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fadds f1,f5,f27
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f27.f64));
	// fsubs f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f27.f64));
	// fsubs f15,f1,f21
	ctx.f15.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f21.f64));
	// stfsx f21,r9,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f1,f19,f23
	ctx.f1.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// lfs f21,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// lfs f19,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// fsubs f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f19.f64));
	// lfs f19,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f29,f17
	ctx.f15.f64 = double(float(ctx.f29.f64 + ctx.f17.f64));
	// fsubs f17,f29,f17
	ctx.f17.f64 = double(float(ctx.f29.f64 - ctx.f17.f64));
	// lfs f29,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f29.f64 = double(temp.f32);
	// fadds f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// lfs f19,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f29,f29,f4
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// fadds f4,f19,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// fmuls f27,f17,f10
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fmuls f17,f18,f13
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f19,f29,f13
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfs f14,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f14.f64 = double(temp.f32);
	// stfs f4,-324(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fsubs f4,f7,f8
	ctx.f4.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// stfs f4,-340(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fadds f4,f21,f1
	ctx.f4.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fsubs f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfs f4,-328(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmuls f21,f24,f13
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmsubs f22,f22,f0,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 - ctx.f14.f64));
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fnmsubs f4,f15,f9,f28
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f9.f64 - ctx.f28.f64)));
	// fadds f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// fsubs f14,f31,f6
	ctx.f14.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// fmadds f29,f29,f0,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f17.f64));
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmadds f28,f20,f0,f21
	ctx.f28.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fsubs f21,f5,f22
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfsx f21,r7,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// stfsx f5,r8,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f24,f20,f13,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f24.f64));
	// stfsx f15,r30,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f5,f18,f0,f19
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fmuls f21,f30,f13
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f20,f23,f13
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f22,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f23,f0,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fsubs f19,f2,f22
	ctx.f19.f64 = double(float(ctx.f2.f64 - ctx.f22.f64));
	// lfs f21,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f21.f64 = double(temp.f32);
	// fadds f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// addi r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 + 112;
	// fmsubs f30,f30,f0,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f20.f64));
	// fsubs f20,f4,f27
	ctx.f20.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// fadds f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f27.f64));
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fadds f7,f31,f6
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// fmuls f22,f19,f10
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fadds f19,f21,f14
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fnmsubs f21,f21,f9,f14
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f9.f64 - ctx.f14.f64)));
	// fsubs f27,f21,f1
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f1.f64));
	// fadds f1,f21,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fsubs f21,f28,f20
	ctx.f21.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// stfsx f21,r28,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f20,f28
	ctx.f28.f64 = double(float(ctx.f20.f64 + ctx.f28.f64));
	// stfsx f28,r31,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f24,f4
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// stfsx f28,r5,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f4,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// stfsx f4,r29,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// stfsx f19,r10,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,-316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// lfs f21,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f21.f64 = double(temp.f32);
	// lfs f28,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f31,f21,f25
	ctx.f31.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// lfs f24,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f4,f27,f5
	ctx.f4.f64 = double(float(ctx.f27.f64 - ctx.f5.f64));
	// stfsx f4,r7,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f5.f64));
	// stfsx f5,r9,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f1,f29
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfs f5,0(r4)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f5,f1,f29
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// lfs f27,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f27.f64 = double(temp.f32);
	// stfsx f5,r8,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f29,f27,f3
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// fsubs f6,f3,f27
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f27.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f5,f16,f28
	ctx.f5.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// subf r4,r10,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r10.s64;
	// fadds f4,f21,f25
	ctx.f4.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// fadds f1,f26,f24
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// fsubs f3,f24,f26
	ctx.f3.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// lfs f26,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f2,f9,f26
	ctx.f27.f64 = double(float(-(ctx.f2.f64 * ctx.f9.f64 - ctx.f26.f64)));
	// fadds f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// stfs f2,0(r25)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fadds f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// fmuls f21,f31,f13
	ctx.f21.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// fmuls f26,f6,f13
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fsubs f2,f5,f4
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fadds f4,f4,f5
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fmuls f25,f3,f13
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fadds f5,f29,f1
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// fsubs f1,f1,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// fadds f29,f27,f22
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f22.f64));
	// fsubs f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f27.f64));
	// fmuls f24,f28,f13
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmadds f3,f3,f0,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f26.f64));
	// fmsubs f28,f28,f0,f21
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 - ctx.f21.f64));
	// fsubs f26,f2,f8
	ctx.f26.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmsubs f6,f6,f0,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fadds f25,f5,f7
	ctx.f25.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fnmsubs f7,f5,f9,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f9.f64 - ctx.f7.f64)));
	// fsubs f5,f30,f29
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// stfs f5,0(r17)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// fadds f5,f29,f30
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// stfs f5,0(r15)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// fadds f5,f27,f23
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// stfs f5,0(r24)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fsubs f5,f27,f23
	ctx.f5.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfs f5,0(r21)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// stfs f26,0(r27)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmadds f31,f31,f0,f24
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fmadds f8,f2,f9,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fadds f5,f4,f8
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// lwz r10,-364(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// fadds f4,f7,f1
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fsubs f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// fadds f2,f5,f3
	ctx.f2.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// stfs f2,0(r26)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f5,0(r18)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fsubs f5,f6,f8
	ctx.f5.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// stfs f5,0(r16)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,0(r14)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// stfs f25,0(r19)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fsubs f8,f4,f31
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// stfs f8,0(r20)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fadds f8,f4,f31
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// stfs f8,0(r23)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fsubs f8,f7,f28
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// fadds f8,f7,f28
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f28.f64));
	// stfs f8,0(r22)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// lwz r10,-344(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r10.u32);
	// bne 0x82d56d5c
	if (!ctx.cr0.eq) goto loc_82D56D5C;
loc_82D57424:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D5742C;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D57430"))) PPC_WEAK_FUNC(sub_82D57430);
PPC_FUNC_IMPL(__imp__sub_82D57430) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-1024
	ctx.r5.s64 = ctx.r11.s64 + -1024;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,27896
	ctx.r4.s64 = ctx.r11.s64 + 27896;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D57448"))) PPC_WEAK_FUNC(sub_82D57448);
PPC_FUNC_IMPL(__imp__sub_82D57448) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e34
	ctx.lr = 0x82D57450;
	__savegprlr_15(ctx, base);
	// addi r12,r1,-144
	ctx.r12.s64 = ctx.r1.s64 + -144;
	// bl 0x82e28ee0
	ctx.lr = 0x82D57458;
	__savefpr_14(ctx, base);
	// mulli r11,r7,88
	ctx.r11.s64 = ctx.r7.s64 * 88;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-88
	ctx.r11.s64 = ctx.r11.s64 + -88;
	// bge cr6,0x82d57870
	if (!ctx.cr6.lt) goto loc_82D57870;
	// rlwinm r16,r9,2,0,29
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// subf r25,r7,r8
	ctx.r25.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D57488:
	// rlwinm r7,r6,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f12,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r5,r6,5,0,26
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// add r24,r7,r3
	ctx.r24.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfs f10,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// mulli r31,r6,20
	ctx.r31.s64 = ctx.r6.s64 * 20;
	// lfs f6,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f30,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfs f9,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f9.f64 = double(temp.f32);
	// lfs f31,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f21,f12,f31
	ctx.f21.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// lfs f5,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f31,f11,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f1,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r30,r6,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f28,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// add r23,r5,r3
	ctx.r23.u64 = ctx.r5.u64 + ctx.r3.u64;
	// lfsx f24,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// add r22,r31,r3
	ctx.r22.u64 = ctx.r31.u64 + ctx.r3.u64;
	// lfs f8,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f8.f64 = double(temp.f32);
	// add r21,r30,r3
	ctx.r21.u64 = ctx.r30.u64 + ctx.r3.u64;
	// lfs f7,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f7.f64 = double(temp.f32);
	// mulli r10,r6,36
	ctx.r10.s64 = ctx.r6.s64 * 36;
	// lfs f4,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f22,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f29,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfs f25,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f11,f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f23,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f12,f12,f30,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f31.f64));
	// fmuls f20,f10,f29
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfsx f27,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f2,f23
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfsx f26,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f31,f6,f25
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// rlwinm r29,r6,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// mulli r28,r6,40
	ctx.r28.s64 = ctx.r6.s64 * 40;
	// fmuls f30,f5,f25
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// lfs f25,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f1,f23
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// fmuls f19,f8,f27
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// fmadds f9,f9,f28,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f20.f64));
	// lfsx f20,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f1,f1,f22,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f21.f64));
	// add r20,r29,r3
	ctx.r20.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fmadds f5,f5,f24,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f31.f64));
	// add r19,r28,r3
	ctx.r19.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// lfs f29,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f6,f6,f24,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f30.f64));
	// lfs f28,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f2,f2,f22,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f23.f64));
	// lfs f24,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f7,f7,f26,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f19.f64));
	// lfsx f22,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfs f27,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f26.f64 = double(temp.f32);
	// mulli r9,r6,24
	ctx.r9.s64 = ctx.r6.s64 * 24;
	// lfs f21,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fadds f31,f9,f11
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f9,f9,f11
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fadds f23,f1,f5
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fadds f11,f10,f12
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fadds f5,f2,f6
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// mulli r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 * 12;
	// fsubs f10,f12,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fsubs f2,f2,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f6.f64));
	// fmuls f12,f9,f0
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fnmsubs f9,f31,f13,f4
	ctx.f9.f64 = double(float(-(ctx.f31.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// fmuls f6,f1,f0
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f1,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f30,f11,f13,f3
	ctx.f30.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fnmsubs f16,f23,f13,f7
	ctx.f16.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// stfs f16,-300(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fnmsubs f16,f5,f13,f8
	ctx.f16.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// lfsx f19,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f16,-296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmuls f15,f28,f1
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// fmuls f16,f29,f1
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f1.f64));
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f1,f25,f19
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// stfs f1,-304(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmuls f14,f27,f21
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// lfsx f17,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f26,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// mulli r27,r6,44
	ctx.r27.s64 = ctx.r6.s64 * 44;
	// fadds f7,f23,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 + ctx.f7.f64));
	// lfs f23,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// mulli r26,r6,28
	ctx.r26.s64 = ctx.r6.s64 * 28;
	// fadds f11,f11,f3
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// lfs f31,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f31.f64 = double(temp.f32);
	// fadds f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// fmsubs f29,f29,f22,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 - ctx.f15.f64));
	// fmadds f1,f28,f22,f16
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f16.f64));
	// fmuls f22,f24,f19
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// lfs f19,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f28,f26,f20,f14
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f14.f64));
	// fmsubs f27,f27,f20,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f20,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f20.f64 = double(temp.f32);
	// add r18,r27,r3
	ctx.r18.u64 = ctx.r27.u64 + ctx.r3.u64;
	// add r17,r26,r3
	ctx.r17.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fmsubs f25,f25,f18,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 - ctx.f22.f64));
	// lfs f21,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f24,f18,f21
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f21.f64));
	// lfs f21,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// fadds f24,f28,f1
	ctx.f24.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f28,f1,f28
	ctx.f28.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// fadds f1,f27,f29
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fsubs f27,f27,f29
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// fmuls f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmuls f29,f28,f0
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fnmsubs f22,f1,f13,f25
	ctx.f22.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// fmuls f28,f27,f0
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f25.f64));
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f27,f24,f13,f26
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfsx f24,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// fsubs f3,f11,f1
	ctx.f3.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// fadds f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// fadds f5,f26,f4
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f4.f64));
	// fsubs f4,f4,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f26.f64));
	// fmsubs f26,f23,f24,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f24.f64 - ctx.f17.f64));
	// lfs f23,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f1,f25,f24,f18
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f25,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f21,f25
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f19,f23
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfsx f18,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f23,f31,f23
	ctx.f23.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// fmuls f16,f20,f25
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmadds f25,f20,f24,f17
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f24.f64 + ctx.f17.f64));
	// fmadds f31,f31,f18,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f18.f64 + ctx.f15.f64));
	// fmsubs f23,f19,f18,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f23.f64));
	// fmsubs f24,f21,f24,f16
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 - ctx.f16.f64));
	// fadds f21,f31,f25
	ctx.f21.f64 = double(float(ctx.f31.f64 + ctx.f25.f64));
	// fsubs f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f31.f64));
	// fadds f31,f23,f24
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fadds f23,f21,f1
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fnmsubs f1,f21,f13,f1
	ctx.f1.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// fadds f20,f31,f26
	ctx.f20.f64 = double(float(ctx.f31.f64 + ctx.f26.f64));
	// fnmsubs f31,f31,f13,f26
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fadds f26,f7,f23
	ctx.f26.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// fsubs f7,f23,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 - ctx.f7.f64));
	// fsubs f23,f20,f8
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f8.f64));
	// fadds f8,f8,f20
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f20.f64));
	// fsubs f21,f5,f26
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// stfsx f21,r31,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f7,f3
	ctx.f21.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f7,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// stfsx f7,r5,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fadds f7,f26,f5
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// stfs f7,0(r3)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f7,f4,f23
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f23.f64));
	// stfsx f7,r8,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f8,f11
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// stfsx f7,r9,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f9,f10
	ctx.f7.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// lfs f17,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f5,f27,f28
	ctx.f5.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// lfs f16,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f3,f1,f24
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// fsubs f26,f17,f2
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f2.f64));
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// fsubs f21,f30,f12
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f12.f64));
	// add r3,r16,r3
	ctx.r3.u64 = ctx.r16.u64 + ctx.r3.u64;
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// addi r11,r11,88
	ctx.r11.s64 = ctx.r11.s64 + 88;
	// fsubs f19,f31,f25
	ctx.f19.f64 = double(float(ctx.f31.f64 - ctx.f25.f64));
	// fsubs f18,f6,f16
	ctx.f18.f64 = double(float(ctx.f6.f64 - ctx.f16.f64));
	// fsubs f20,f22,f29
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// fadds f9,f27,f28
	ctx.f9.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// fadds f2,f17,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// fadds f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// stfsx f11,r27,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fadds f31,f31,f25
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f25.f64));
	// fadds f6,f16,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 + ctx.f6.f64));
	// fadds f12,f30,f12
	ctx.f12.f64 = double(float(ctx.f30.f64 + ctx.f12.f64));
	// fadds f11,f23,f4
	ctx.f11.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// stfsx f11,r29,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fadds f30,f22,f29
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// fadds f11,f5,f7
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fsubs f8,f7,f5
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fadds f7,f26,f3
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fadds f4,f20,f21
	ctx.f4.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f29,f18,f19
	ctx.f29.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// fadds f27,f9,f10
	ctx.f27.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f9,f2,f1
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// fsubs f5,f26,f3
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f28,f18,f19
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f1,f31,f6
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// fsubs f3,f21,f20
	ctx.f3.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// fsubs f31,f12,f30
	ctx.f31.f64 = double(float(ctx.f12.f64 - ctx.f30.f64));
	// fadds f12,f30,f12
	ctx.f12.f64 = double(float(ctx.f30.f64 + ctx.f12.f64));
	// fsubs f30,f11,f7
	ctx.f30.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfs f30,0(r20)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fsubs f30,f29,f4
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// stfs f30,0(r23)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fadds f4,f29,f4
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f4.f64));
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f11,r8,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f8,f28
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f8,f28,f8
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// fsubs f7,f5,f3
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfs f7,0(r18)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fadds f11,f5,f3
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfs f8,0(r22)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fsubs f11,f27,f9
	ctx.f11.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// stfsx f11,r30,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f1,f10
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f10.f64));
	// stfs f8,0(r21)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fadds f11,f9,f27
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// stfs f11,0(r24)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fsubs f10,f10,f1
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f1.f64));
	// stfsx f10,r7,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f2,f31
	ctx.f11.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfs f11,0(r17)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// fadds f10,f6,f12
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// stfsx f10,r26,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fadds f11,f2,f31
	ctx.f11.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// stfsx f11,r28,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// stfs f12,0(r19)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// lwz r10,3532(r15)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r15.u32 + 3532);
	// subf r4,r16,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r16.s64;
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d57488
	if (!ctx.cr0.eq) goto loc_82D57488;
loc_82D57870:
	// addi r12,r1,-144
	ctx.r12.s64 = ctx.r1.s64 + -144;
	// bl 0x82e28f2c
	ctx.lr = 0x82D57878;
	__restfpr_14(ctx, base);
	// b 0x82e28e84
	__restgprlr_15(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D57880"))) PPC_WEAK_FUNC(sub_82D57880);
PPC_FUNC_IMPL(__imp__sub_82D57880) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-968
	ctx.r5.s64 = ctx.r11.s64 + -968;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,29768
	ctx.r4.s64 = ctx.r11.s64 + 29768;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D57898"))) PPC_WEAK_FUNC(sub_82D57898);
PPC_FUNC_IMPL(__imp__sub_82D57898) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82D578A0;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28ee0
	ctx.lr = 0x82D578A8;
	__savefpr_14(ctx, base);
	// mulli r11,r7,72
	ctx.r11.s64 = ctx.r7.s64 * 72;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-72
	ctx.r11.s64 = ctx.r11.s64 + -72;
	// bge cr6,0x82d57c68
	if (!ctx.cr6.lt) goto loc_82D57C68;
	// subf r22,r7,r8
	ctx.r22.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r21,r9,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lfs f13,-7588(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7584(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-12288(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -12288);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-7592(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7592);
	ctx.f12.f64 = double(temp.f32);
loc_82D578E8:
	// mulli r5,r6,20
	ctx.r5.s64 = ctx.r6.s64 * 20;
	// lfs f10,32(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// mulli r8,r6,24
	ctx.r8.s64 = ctx.r6.s64 * 24;
	// lfs f6,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f29,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f10,f29
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfs f4,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// lfs f2,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f2.f64 = double(temp.f32);
	// lfs f7,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f3,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f1.f64 = double(temp.f32);
	// lfs f31,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f30,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// add r29,r5,r4
	ctx.r29.u64 = ctx.r5.u64 + ctx.r4.u64;
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r31,r6,36
	ctx.r31.s64 = ctx.r6.s64 * 36;
	// lfs f28,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f25,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f9,f9,f28,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f19.f64));
	// lfsx f27,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// lfsx f23,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f29,f6,f25
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f28,f5,f25
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// lfsx f26,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// add r27,r8,r3
	ctx.r27.u64 = ctx.r8.u64 + ctx.r3.u64;
	// fmuls f25,f4,f23
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f18,f8,f27
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// add r26,r8,r4
	ctx.r26.u64 = ctx.r8.u64 + ctx.r4.u64;
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// add r28,r31,r4
	ctx.r28.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfsx f24,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r25,r6,28
	ctx.r25.s64 = ctx.r6.s64 * 28;
	// lfs f21,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f2,f21
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// lfs f20,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// lfs f22,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f6,f6,f24,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f28.f64));
	// lfs f28,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f3,f3,f22,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f25.f64));
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f5,f5,f24,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f29.f64));
	// add r24,r25,r3
	ctx.r24.u64 = ctx.r25.u64 + ctx.r3.u64;
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfs f27,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f4,f4,f22,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f23.f64));
	// lfs f23,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f7,f7,f26,f18
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f18.f64));
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f29,f31,f9
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f9.f64));
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// fadds f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// fmadds f1,f1,f20,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfs f19,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f2,f2,f20,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f21,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// fadds f31,f10,f30
	ctx.f31.f64 = double(float(ctx.f10.f64 + ctx.f30.f64));
	// fsubs f10,f30,f10
	ctx.f10.f64 = double(float(ctx.f30.f64 - ctx.f10.f64));
	// lfs f30,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r30,r6,5,0,26
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f22,f4,f8
	ctx.f22.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// add r25,r25,r4
	ctx.r25.u64 = ctx.r25.u64 + ctx.r4.u64;
	// fsubs f26,f7,f3
	ctx.f26.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// lfs f3,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f24,f1,f5
	ctx.f24.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fadds f20,f2,f6
	ctx.f20.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// fsubs f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f4,f24,f26
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fadds f2,f20,f22
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f2,-260(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// fsubs f2,f6,f8
	ctx.f2.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// lfsx f17,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// add r23,r30,r3
	ctx.r23.u64 = ctx.r30.u64 + ctx.r3.u64;
	// stfs f17,-272(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f2,-264(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fsubs f6,f22,f20
	ctx.f6.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// lfsx f2,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-268(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fmuls f16,f30,f2
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// fmuls f2,f28,f2
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// lfsx f1,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f18,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f27,f18
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f14,f25,f18
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f18.f64));
	// fmuls f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmuls f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// fmuls f20,f8,f13
	ctx.f20.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmadds f28,f28,f1,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f1.f64 + ctx.f16.f64));
	// fmsubs f1,f30,f1,f2
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 - ctx.f2.f64));
	// lfs f2,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f2.f64 = double(temp.f32);
	// stfs f18,-272(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmr f18,f2
	ctx.f18.f64 = ctx.f2.f64;
	// lfs f2,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f19,f2
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// fmadds f30,f25,f18,f15
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 + ctx.f15.f64));
	// fmuls f15,f3,f2
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f2,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f27,f27,f18,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f25,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f21,f2,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 + ctx.f25.f64));
	// fmsubs f2,f23,f2,f17
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f17.f64));
	// lfs f23,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f3,f3,f23,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 + ctx.f16.f64));
	// fmsubs f23,f19,f23,f15
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f23.f64 - ctx.f15.f64));
	// fsubs f21,f28,f25
	ctx.f21.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fsubs f19,f3,f30
	ctx.f19.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fadds f30,f3,f30
	ctx.f30.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// fadds f3,f5,f7
	ctx.f3.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fadds f25,f2,f1
	ctx.f25.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// fadds f18,f23,f27
	ctx.f18.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// fsubs f1,f23,f27
	ctx.f1.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// fadds f17,f19,f21
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fadds f16,f30,f28
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fadds f15,f18,f25
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// fadds f27,f17,f4
	ctx.f27.f64 = double(float(ctx.f17.f64 + ctx.f4.f64));
	// fadds f23,f16,f3
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// fsubs f22,f16,f3
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f3.f64));
	// fsubs f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f4.f64));
	// fsubs f3,f21,f19
	ctx.f3.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fsubs f4,f25,f18
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fmuls f19,f6,f13
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fnmsubs f21,f23,f11,f9
	ctx.f21.f64 = double(float(-(ctx.f23.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// fmuls f24,f22,f12
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f25,f17,f12
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f17,f3,f0
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f18,f4,f13
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fadds f22,f1,f2
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fnmsubs f1,f27,f11,f29
	ctx.f1.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f29.f64)));
	// fadds f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// lfs f27,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f27.f64 = double(temp.f32);
	// stfsx f29,r10,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f4,f4,f0,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f19.f64));
	// fmsubs f9,f6,f0,f18
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 - ctx.f18.f64));
	// fmsubs f6,f26,f13,f17
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f17.f64));
	// fmadds f3,f26,f0,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f3.f64));
	// fmuls f26,f2,f13
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fsubs f29,f27,f22
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// fmadds f2,f2,f0,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f20.f64));
	// fmsubs f8,f8,f0,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f26.f64));
	// fsubs f26,f1,f25
	ctx.f26.f64 = double(float(ctx.f1.f64 - ctx.f25.f64));
	// fmuls f27,f27,f12
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fadds f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f25.f64));
	// fadds f25,f21,f24
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// addic. r22,r22,-1
	ctx.xer.ca = ctx.r22.u32 > 0;
	ctx.r22.s64 = ctx.r22.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// fsubs f22,f29,f10
	ctx.f22.f64 = double(float(ctx.f29.f64 - ctx.f10.f64));
	// addi r11,r11,72
	ctx.r11.s64 = ctx.r11.s64 + 72;
	// fmadds f10,f29,f11,f10
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f11.f64 + ctx.f10.f64));
	// fsubs f29,f26,f8
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f8.f64));
	// stfsx f29,r8,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// fadds f8,f26,f8
	ctx.f8.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// stfsx f8,r7,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fsubs f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfsx f8,r9,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfs f23,0(r3)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fsubs f8,f25,f4
	ctx.f8.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f25,f4
	ctx.f8.f64 = double(float(ctx.f25.f64 + ctx.f4.f64));
	// stfsx f8,r7,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f24,f9
	ctx.f8.f64 = double(float(ctx.f24.f64 - ctx.f9.f64));
	// stfsx f8,r8,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f24,f9
	ctx.f9.f64 = double(float(ctx.f24.f64 + ctx.f9.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f10,f27
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f27.f64));
	// stfsx f22,r5,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fsubs f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f27.f64));
	// fsubs f8,f6,f9
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// stfsx f8,r31,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f4,f9,f6
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// lfs f6,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f6.f64 = double(temp.f32);
	// fadds f9,f15,f6
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f6.f64));
	// stfsx f4,r30,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f28,f30
	ctx.f8.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// add r3,r21,r3
	ctx.r3.u64 = ctx.r21.u64 + ctx.r3.u64;
	// fsubs f6,f15,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 - ctx.f6.f64));
	// subf r4,r21,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r21.s64;
	// fsubs f1,f3,f10
	ctx.f1.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// stfs f1,0(r24)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fadds f10,f10,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// stfs f10,0(r26)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fmuls f4,f7,f13
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fnmsubs f10,f9,f11,f31
	ctx.f10.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f31.f64)));
	// fmuls f5,f8,f13
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fadds f2,f9,f31
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// stfs f2,0(r28)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fmadds f8,f8,f0,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmsubs f9,f7,f0,f5
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fsubs f7,f10,f6
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// stfs f6,0(r23)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// stfs f9,0(r25)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f9,f8,f10
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// stfs f10,0(r29)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// lwz r10,3532(r20)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r20.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d578e8
	if (!ctx.cr0.eq) goto loc_82D578E8;
loc_82D57C68:
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28f2c
	ctx.lr = 0x82D57C70;
	__restfpr_14(ctx, base);
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D57C78"))) PPC_WEAK_FUNC(sub_82D57C78);
PPC_FUNC_IMPL(__imp__sub_82D57C78) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-912
	ctx.r5.s64 = ctx.r11.s64 + -912;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,30872
	ctx.r4.s64 = ctx.r11.s64 + 30872;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D57C90"))) PPC_WEAK_FUNC(sub_82D57C90);
PPC_FUNC_IMPL(__imp__sub_82D57C90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D57C98;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ee0
	ctx.lr = 0x82D57CA0;
	__savefpr_14(ctx, base);
	// rlwinm r11,r7,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-64
	ctx.r11.s64 = ctx.r11.s64 + -64;
	// bge cr6,0x82d5805c
	if (!ctx.cr6.lt) goto loc_82D5805C;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// subf r25,r7,r8
	ctx.r25.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f10,-5076(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -5076);
	ctx.f10.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// stfs f10,-248(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lfs f10,-5080(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -5080);
	ctx.f10.f64 = double(temp.f32);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// stfs f10,-252(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f10,-6140(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -6140);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,-240(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f10,-6144(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -6144);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,-6156(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -6156);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-28552(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-6160(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -6160);
	ctx.f11.f64 = double(temp.f32);
	// stfs f10,-244(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
loc_82D57D10:
	// mulli r9,r6,24
	ctx.r9.s64 = ctx.r6.s64 * 24;
	// lfs f8,40(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f8.f64 = double(temp.f32);
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f7,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f4,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f27,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f8,f27
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// lfsx f26,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// lfs f31,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f31.f64 = double(temp.f32);
	// lfs f3,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f30.f64 = double(temp.f32);
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f29,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f10,f29
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfsx f28,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r7,r6,20
	ctx.r7.s64 = ctx.r6.s64 * 20;
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmadds f7,f7,f26,f18
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f18.f64));
	// lfs f1,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfsx f23,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f27,f4,f23
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// lfsx f22,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r5,r6,5,0,26
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fmuls f26,f3,f23
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// fmadds f9,f9,f28,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f19.f64));
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// rlwinm r31,r6,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r30,r6,28
	ctx.r30.s64 = ctx.r6.s64 * 28;
	// lfs f23,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f21,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f31,f21
	ctx.f19.f64 = double(float(ctx.f31.f64 * ctx.f21.f64));
	// lfsx f25,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// lfsx f20,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f29,f6,f25
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfsx f24,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f3,f3,f22,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f27.f64));
	// lfs f27,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f4,f4,f22,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f26.f64));
	// rlwinm r29,r6,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f28,f5,f25
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// add r28,r31,r3
	ctx.r28.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r27,r30,r3
	ctx.r27.u64 = ctx.r30.u64 + ctx.r3.u64;
	// lfs f26,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f26.f64 = double(temp.f32);
	// add r26,r29,r3
	ctx.r26.u64 = ctx.r29.u64 + ctx.r3.u64;
	// lfs f25,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f25.f64 = double(temp.f32);
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// lfs f22,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f22.f64 = double(temp.f32);
	// add r30,r30,r4
	ctx.r30.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fmadds f30,f30,f20,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 + ctx.f19.f64));
	// add r29,r29,r4
	ctx.r29.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fmsubs f31,f31,f20,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f20.f64 - ctx.f21.f64));
	// fmadds f5,f5,f24,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f29.f64));
	// lfs f19,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fadds f29,f7,f9
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// lfs f17,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f7,f7,f9
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// lfs f20,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fadds f9,f8,f10
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// lfs f18,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f8,f10,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fmsubs f6,f6,f24,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f28.f64));
	// lfs f24,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f24.f64 = double(temp.f32);
	// fadds f21,f30,f3
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fsubs f30,f30,f3
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// fadds f3,f31,f4
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// fsubs f31,f4,f31
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// fmuls f10,f7,f0
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fnmsubs f7,f29,f13,f2
	ctx.f7.f64 = double(float(-(ctx.f29.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f28,f9,f13,f1
	ctx.f28.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// lfs f30,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fadds f14,f3,f6
	ctx.f14.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// lfs f16,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f6,f3,f13,f6
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// stfs f6,-256(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fmuls f3,f25,f19
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// fmuls f6,f27,f30
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fadds f15,f21,f5
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// fmuls f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fnmsubs f5,f21,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fmuls f21,f24,f19
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// fmuls f19,f23,f17
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fsubs f29,f7,f8
	ctx.f29.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fmadds f3,f24,f18,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f3.f64));
	// fmuls f24,f22,f17
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmadds f6,f26,f20,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f6.f64));
	// fmsubs f30,f27,f20,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f30.f64));
	// lfs f20,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f20.f64 = double(temp.f32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fmsubs f27,f25,f18,f21
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 - ctx.f21.f64));
	// fmadds f26,f22,f16,f19
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f19.f64));
	// fmsubs f25,f23,f16,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 - ctx.f24.f64));
	// fsubs f24,f5,f31
	ctx.f24.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// fadds f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// fsubs f22,f30,f27
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// fmuls f18,f24,f20
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// fmuls f27,f22,f0
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fadds f21,f30,f25
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// lfs f23,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f31,f23,f4
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// fadds f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// fadds f23,f3,f6
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f3,f3,f6
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fnmsubs f6,f30,f13,f25
	ctx.f6.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// fadds f25,f21,f14
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// fadds f22,f23,f26
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fnmsubs f26,f23,f13,f26
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f7,f21,f0
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fadds f30,f22,f15
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// fsubs f23,f26,f27
	ctx.f23.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fmuls f19,f23,f11
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmuls f17,f23,f12
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f23,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f24,f23
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// fmsubs f24,f31,f23,f18
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f23.f64 - ctx.f18.f64));
	// fsubs f23,f28,f10
	ctx.f23.f64 = double(float(ctx.f28.f64 - ctx.f10.f64));
	// fadds f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fmuls f28,f22,f0
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fadds f22,f25,f9
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f9.f64));
	// fnmsubs f9,f25,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f25.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fmadds f1,f31,f20,f16
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f20.f64 + ctx.f16.f64));
	// fadds f31,f27,f26
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f27,f6,f3
	ctx.f27.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// fadds f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fadds f3,f30,f2
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// stfs f3,0(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fnmsubs f3,f30,f13,f2
	ctx.f3.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// fmuls f25,f31,f26
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// fmadds f2,f27,f12,f19
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 + ctx.f19.f64));
	// fmsubs f30,f27,f11,f17
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 - ctx.f17.f64));
	// fadds f27,f3,f7
	ctx.f27.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfsx f27,r10,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f27,f28,f9
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f9.f64));
	// fadds f28,f9,f28
	ctx.f28.f64 = double(float(ctx.f9.f64 + ctx.f28.f64));
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// stfsx f7,r8,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f24,f2
	ctx.f9.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// fadds f3,f1,f30
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fsubs f7,f30,f1
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// fsubs f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// fadds f1,f9,f29
	ctx.f1.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// stfsx f1,r8,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f1,f7,f23
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fnmsubs f9,f9,f13,f29
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// stfsx f1,r9,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f7,f7,f13,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 - ctx.f23.f64));
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// addi r11,r11,64
	ctx.r11.s64 = ctx.r11.s64 + 64;
	// fsubs f1,f9,f3
	ctx.f1.f64 = double(float(ctx.f9.f64 - ctx.f3.f64));
	// stfs f1,0(r4)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f7,f2
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// stfsx f9,r7,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f7,f2
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// stfsx f9,r5,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f4,f12
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmuls f3,f31,f9
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f9.f64));
	// stfsx f27,r9,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmuls f2,f5,f12
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfsx f22,r5,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f6,f9,f25
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f25.f64));
	// stfsx f28,r7,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// subf r4,r24,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r24.s64;
	// fmadds f7,f5,f11,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fmsubs f6,f6,f26,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 - ctx.f3.f64));
	// fmsubs f5,f4,f11,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 - ctx.f2.f64));
	// fadds f4,f7,f9
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fsubs f7,f7,f9
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fadds f9,f5,f6
	ctx.f9.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f5,f4,f8
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// stfs f5,0(r26)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fnmsubs f8,f4,f13,f8
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// fadds f5,f9,f10
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f10,f9,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fsubs f9,f8,f6
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f9,0(r29)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f9,f8,f6
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// stfs f5,0(r30)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fsubs f9,f7,f10
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// stfs f10,0(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lwz r10,3532(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d57d10
	if (!ctx.cr0.eq) goto loc_82D57D10;
loc_82D5805C:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f2c
	ctx.lr = 0x82D58064;
	__restfpr_14(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58068"))) PPC_WEAK_FUNC(sub_82D58068);
PPC_FUNC_IMPL(__imp__sub_82D58068) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-856
	ctx.r5.s64 = ctx.r11.s64 + -856;
	// lis r11,-32043
	ctx.r11.s64 = -2099970048;
	// addi r4,r11,31888
	ctx.r4.s64 = ctx.r11.s64 + 31888;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58080"))) PPC_WEAK_FUNC(sub_82D58080);
PPC_FUNC_IMPL(__imp__sub_82D58080) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D58088;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ef4
	ctx.lr = 0x82D58090;
	__savefpr_19(ctx, base);
	// mulli r11,r7,56
	ctx.r11.s64 = ctx.r7.s64 * 56;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-56
	ctx.r11.s64 = ctx.r11.s64 + -56;
	// bge cr6,0x82d58308
	if (!ctx.cr6.lt) goto loc_82D58308;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r29,r7,r8
	ctx.r29.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f0,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D580B8:
	// mulli r5,r6,28
	ctx.r5.s64 = ctx.r6.s64 * 28;
	// lfs f13,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r7,r6,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f12,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f29,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfs f5,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f5.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// add r27,r5,r3
	ctx.r27.u64 = ctx.r5.u64 + ctx.r3.u64;
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// add r28,r7,r4
	ctx.r28.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r31,r6,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// mulli r9,r6,24
	ctx.r9.s64 = ctx.r6.s64 * 24;
	// lfs f3,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfs f30,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f13,f1
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmuls f21,f11,f30
	ctx.f21.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f31,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f1,f12,f1
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// lfsx f26,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f30,f10,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfsx f24,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// fmadds f12,f12,f31,f22
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 + ctx.f22.f64));
	// lfsx f28,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f10,f10,f29,f21
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64 + ctx.f21.f64));
	// fmsubs f13,f13,f31,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f1.f64));
	// lfsx f27,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f1,f7,f26
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// add r26,r31,r4
	ctx.r26.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmsubs f11,f11,f29,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 - ctx.f30.f64));
	// rlwinm r30,r6,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f30,f5,f24
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// mulli r8,r6,20
	ctx.r8.s64 = ctx.r6.s64 * 20;
	// fmuls f31,f6,f26
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// lfs f29,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f20,f9,f28
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f28,f8,f28
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f25,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f4,f24
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// lfsx f24,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f6,f6,f25,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f1.f64));
	// add r25,r30,r3
	ctx.r25.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fmadds f1,f4,f23,f30
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 + ctx.f30.f64));
	// fmsubs f7,f7,f25,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 - ctx.f31.f64));
	// lfsx f25,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f8,f8,f27,f20
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 + ctx.f20.f64));
	// fmsubs f9,f9,f27,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f28.f64));
	// lfs f28,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// fadds f31,f12,f3
	ctx.f31.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fmsubs f5,f5,f23,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f26.f64));
	// lfsx f23,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f12,f3,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 - ctx.f12.f64));
	// fsubs f30,f2,f13
	ctx.f30.f64 = double(float(ctx.f2.f64 - ctx.f13.f64));
	// fadds f13,f13,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f2.f64));
	// lfs f2,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// fadds f27,f1,f6
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fsubs f6,f6,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fadds f3,f8,f10
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// lfs f9,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fadds f1,f27,f31
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fsubs f31,f31,f27
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fadds f27,f5,f7
	ctx.f27.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// lfs f5,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f26,f30,f6
	ctx.f26.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// fadds f4,f11,f10
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// fsubs f22,f13,f27
	ctx.f22.f64 = double(float(ctx.f13.f64 - ctx.f27.f64));
	// fadds f13,f27,f13
	ctx.f13.f64 = double(float(ctx.f27.f64 + ctx.f13.f64));
	// fsubs f21,f12,f7
	ctx.f21.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fmuls f27,f9,f5
	ctx.f27.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmuls f19,f29,f25
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f25.f64));
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// fmuls f20,f2,f5
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fmuls f25,f28,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f5,f2,f23,f27
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f23.f64 + ctx.f27.f64));
	// fsubs f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fadds f10,f6,f30
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// fmadds f2,f28,f24,f19
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f24.f64 + ctx.f19.f64));
	// fmsubs f9,f9,f23,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f23.f64 - ctx.f20.f64));
	// fmsubs f29,f29,f24,f25
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 - ctx.f25.f64));
	// fsubs f28,f5,f2
	ctx.f28.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fadds f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fsubs f2,f9,f29
	ctx.f2.f64 = double(float(ctx.f9.f64 - ctx.f29.f64));
	// fadds f9,f29,f9
	ctx.f9.f64 = double(float(ctx.f29.f64 + ctx.f9.f64));
	// fadds f29,f5,f3
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fsubs f27,f28,f2
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f2.f64));
	// fsubs f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fadds f3,f9,f8
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// fsubs f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// fsubs f8,f1,f29
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f4,f27
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f27.f64));
	// fsubs f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// fadds f1,f29,f1
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// stfs f1,0(r3)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f1,f5,f22
	ctx.f1.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfsx f1,r9,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// stfsx f5,r8,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f3,f13
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f13.f64));
	// fadds f3,f13,f3
	ctx.f3.f64 = double(float(ctx.f13.f64 + ctx.f3.f64));
	// fsubs f1,f31,f9
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f9.f64));
	// fadds f31,f9,f31
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// fmuls f13,f8,f0
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f9,f4,f0
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fsubs f8,f21,f13
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f13.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f9,f26
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f26.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f13,f13,f21
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f21.f64));
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f13,f9,f26
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f26.f64));
	// stfsx f13,r8,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f2,f28
	ctx.f13.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// stfsx f5,r7,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// stfsx f3,r5,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// stfsx f1,r31,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// stfsx f31,r30,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// subf r4,r24,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r24.s64;
	// fadds f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fmuls f13,f9,f0
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fsubs f9,f12,f13
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfs f9,0(r26)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fadds f9,f11,f10
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// stfs f13,0(r25)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f13,f11,f10
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// stfs f13,0(r27)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// lwz r10,3532(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d580b8
	if (!ctx.cr0.eq) goto loc_82D580B8;
loc_82D58308:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f40
	ctx.lr = 0x82D58310;
	__restfpr_19(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58318"))) PPC_WEAK_FUNC(sub_82D58318);
PPC_FUNC_IMPL(__imp__sub_82D58318) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-800
	ctx.r5.s64 = ctx.r11.s64 + -800;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-32640
	ctx.r4.s64 = ctx.r11.s64 + -32640;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58330"))) PPC_WEAK_FUNC(sub_82D58330);
PPC_FUNC_IMPL(__imp__sub_82D58330) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D58338;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ee0
	ctx.lr = 0x82D58340;
	__savefpr_14(ctx, base);
	// mulli r11,r7,48
	ctx.r11.s64 = ctx.r7.s64 * 48;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-48
	ctx.r11.s64 = ctx.r11.s64 + -48;
	// bge cr6,0x82d58614
	if (!ctx.cr6.lt) goto loc_82D58614;
	// subf r25,r7,r8
	ctx.r25.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f9,-4940(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -4940);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-4944(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -4944);
	ctx.f10.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f11,-4948(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -4948);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-4960(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -4960);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-4952(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -4952);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-4956(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4956);
	ctx.f0.f64 = double(temp.f32);
loc_82D58390:
	// mulli r8,r6,20
	ctx.r8.s64 = ctx.r6.s64 * 20;
	// lfs f6,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// lfs f31,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f31.f64 = double(temp.f32);
	// lfs f4,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// lfs f2,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// add r29,r8,r3
	ctx.r29.u64 = ctx.r8.u64 + ctx.r3.u64;
	// lfs f27,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// mulli r10,r6,24
	ctx.r10.s64 = ctx.r6.s64 * 24;
	// lfsx f20,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f26,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f29,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfs f21,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f6,f29
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// fmuls f16,f5,f29
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfsx f25,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f29,f31,f21
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f21.f64));
	// stfs f29,-240(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fmuls f15,f4,f25
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// rlwinm r7,r6,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f25,f3,f25
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// add r31,r9,r4
	ctx.r31.u64 = ctx.r9.u64 + ctx.r4.u64;
	// add r30,r7,r3
	ctx.r30.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfsx f24,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r5,r6,12
	ctx.r5.s64 = ctx.r6.s64 * 12;
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// lfs f28,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f23,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f29,f5,f28,f17
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f28.f64 + ctx.f17.f64));
	// fmuls f14,f2,f23
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// fmsubs f28,f6,f28,f16
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f28.f64 - ctx.f16.f64));
	// add r28,r5,r3
	ctx.r28.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fmsubs f4,f4,f24,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f25.f64));
	// fmuls f23,f1,f23
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmadds f3,f3,f24,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 + ctx.f15.f64));
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmsubs f24,f31,f20,f21
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f20.f64 - ctx.f21.f64));
	// rlwinm r27,r6,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f19,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// add r26,r27,r3
	ctx.r26.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fmuls f6,f27,f19
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// lfs f22,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f1,f1,f22,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f14.f64));
	// lfs f18,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// add r27,r27,r4
	ctx.r27.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fsubs f31,f28,f4
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f4.f64));
	// fmsubs f2,f2,f22,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f23.f64));
	// fadds f5,f4,f28
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f28.f64));
	// fmadds f23,f26,f18,f6
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 + ctx.f6.f64));
	// fmuls f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fadds f6,f3,f29
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// fsubs f28,f2,f24
	ctx.f28.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// fmsubs f26,f27,f18,f26
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 - ctx.f26.f64));
	// fmadds f21,f6,f9,f8
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f8.f64));
	// lfs f25,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f30,f20,f25
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 + ctx.f25.f64));
	// fsubs f30,f3,f29
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fadds f3,f24,f2
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// lfs f2,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f20,f5,f9,f7
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fsubs f29,f1,f25
	ctx.f29.f64 = double(float(ctx.f1.f64 - ctx.f25.f64));
	// fadds f4,f25,f1
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f1.f64));
	// lfs f1,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f31,f13
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// fmuls f27,f30,f0
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f24,f30,f13
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmadds f22,f28,f0,f25
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 + ctx.f25.f64));
	// fmuls f25,f3,f10
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmadds f19,f29,f12,f27
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 + ctx.f27.f64));
	// lfs f27,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f2,f27
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// fmuls f27,f1,f27
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fnmadds f18,f5,f11,f25
	ctx.f18.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 + ctx.f25.f64)));
	// lfs f25,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f1,f1,f25,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64 + ctx.f17.f64));
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// fmsubs f25,f2,f25,f27
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f25.f64 - ctx.f27.f64));
	// addi r11,r11,48
	ctx.r11.s64 = ctx.r11.s64 + 48;
	// fadds f2,f1,f23
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f23.f64));
	// fsubs f27,f1,f23
	ctx.f27.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// fadds f1,f25,f26
	ctx.f1.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fmuls f25,f2,f10
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fadds f17,f2,f4
	ctx.f17.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fmuls f23,f1,f10
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fadds f16,f1,f3
	ctx.f16.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fmadds f14,f27,f12,f24
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 + ctx.f24.f64));
	// fnmsubs f24,f27,f13,f19
	ctx.f24.f64 = double(float(-(ctx.f27.f64 * ctx.f13.f64 - ctx.f19.f64)));
	// fnmadds f15,f4,f11,f25
	ctx.f15.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f25.f64)));
	// fadds f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f6.f64));
	// fnmadds f25,f3,f11,f23
	ctx.f25.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f23.f64)));
	// stfs f25,-240(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fmadds f25,f26,f12,f22
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f22.f64));
	// fadds f16,f16,f5
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f5.f64));
	// fnmsubs f22,f29,f0,f14
	ctx.f22.f64 = double(float(-(ctx.f29.f64 * ctx.f0.f64 - ctx.f14.f64)));
	// fmuls f29,f29,f13
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fmadds f3,f3,f9,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fadds f23,f15,f21
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// fmadds f30,f30,f12,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f29.f64));
	// fnmadds f5,f1,f11,f5
	ctx.f5.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 + ctx.f5.f64)));
	// fsubs f19,f23,f25
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// fadds f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fmuls f23,f6,f10
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fnmadds f29,f2,f11,f23
	ctx.f29.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 + ctx.f23.f64)));
	// fmadds f2,f2,f9,f8
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f8.f64));
	// lfs f21,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// fadds f20,f17,f8
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f8.f64));
	// stfs f20,0(r3)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f19,0(r4)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f20,f16,f7
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f7.f64));
	// stfsx f25,r9,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f20,r10,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f22,f21
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f25,f21,f22
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f25,r8,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fmuls f25,f26,f0
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// subf r4,r24,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r24.s64;
	// fmadds f21,f1,f9,f7
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fmuls f22,f4,f10
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmadds f4,f4,f9,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmadds f7,f27,f0,f30
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f30.f64));
	// fmadds f1,f31,f12,f25
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 + ctx.f25.f64));
	// fmsubs f31,f31,f0,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 - ctx.f26.f64));
	// fadds f8,f18,f21
	ctx.f8.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fnmadds f26,f6,f11,f22
	ctx.f26.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 + ctx.f22.f64)));
	// fadds f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fadds f4,f29,f4
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f4.f64));
	// fnmsubs f5,f28,f13,f1
	ctx.f5.f64 = double(float(-(ctx.f28.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// fnmsubs f3,f28,f12,f31
	ctx.f3.f64 = double(float(-(ctx.f28.f64 * ctx.f12.f64 - ctx.f31.f64)));
	// fsubs f1,f24,f8
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f8.f64));
	// stfs f1,0(r29)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// fadds f8,f8,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f24.f64));
	// stfs f8,0(r27)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f8,f7,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// stfs f8,0(r26)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfs f8,0(r7)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fadds f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f8,0(r28)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fsubs f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// stfs f8,0(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f8,0(r30)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// lwz r10,3532(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d58390
	if (!ctx.cr0.eq) goto loc_82D58390;
loc_82D58614:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f2c
	ctx.lr = 0x82D5861C;
	__restfpr_14(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58620"))) PPC_WEAK_FUNC(sub_82D58620);
PPC_FUNC_IMPL(__imp__sub_82D58620) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-744
	ctx.r5.s64 = ctx.r11.s64 + -744;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-31952
	ctx.r4.s64 = ctx.r11.s64 + -31952;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58638"))) PPC_WEAK_FUNC(sub_82D58638);
PPC_FUNC_IMPL(__imp__sub_82D58638) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D58640;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28ef4
	ctx.lr = 0x82D58648;
	__savefpr_19(ctx, base);
	// mulli r11,r7,40
	ctx.r11.s64 = ctx.r7.s64 * 40;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-40
	ctx.r11.s64 = ctx.r11.s64 + -40;
	// bge cr6,0x82d58838
	if (!ctx.cr6.lt) goto loc_82D58838;
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// subf r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D58678:
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// lfs f12,16(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r5,r6,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f4.f64 = double(temp.f32);
	// add r30,r7,r3
	ctx.r30.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// add r29,r5,r3
	ctx.r29.u64 = ctx.r5.u64 + ctx.r3.u64;
	// lfs f3,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f2,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// mulli r31,r6,20
	ctx.r31.s64 = ctx.r6.s64 * 20;
	// lfs f1,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfs f31,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f29,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f21,f12,f31
	ctx.f21.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f20,f10,f29
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfsx f27,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f31,f11,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfsx f26,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmuls f19,f8,f27
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// add r28,r31,r3
	ctx.r28.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lfs f30,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// lfsx f25,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f11,f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f28,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f12,f12,f30,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f31.f64));
	// lfs f23,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmuls f31,f6,f25
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfsx f24,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f29,f4,f23
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// lfs f22,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f30,f5,f25
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// fmadds f9,f9,f28,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f20.f64));
	// fmadds f7,f7,f26,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f19.f64));
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// fmadds f5,f5,f24,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f31.f64));
	// fmadds f31,f3,f22,f29
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f29.f64));
	// fmuls f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// fmsubs f6,f6,f24,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f30.f64));
	// fsubs f30,f2,f11
	ctx.f30.f64 = double(float(ctx.f2.f64 - ctx.f11.f64));
	// fadds f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fsubs f2,f9,f7
	ctx.f2.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f7,f8,f10
	ctx.f7.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// fadds f29,f12,f1
	ctx.f29.f64 = double(float(ctx.f12.f64 + ctx.f1.f64));
	// fsubs f8,f5,f31
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// fadds f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// fmsubs f4,f4,f22,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f3.f64));
	// fsubs f12,f1,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 - ctx.f12.f64));
	// fadds f3,f8,f2
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fadds f1,f5,f9
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f5,f5,f9
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fsubs f2,f2,f8
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// fsubs f9,f6,f4
	ctx.f9.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f8,f4,f6
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fadds f4,f3,f30
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// stfsx f4,r9,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f31,f1,f11
	ctx.f31.f64 = double(float(ctx.f1.f64 + ctx.f11.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f6,f2,f0
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fsubs f4,f10,f9
	ctx.f4.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f2,f8,f7
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fadds f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fnmsubs f10,f3,f13,f30
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fnmsubs f11,f1,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f3,f4,f12
	ctx.f3.f64 = double(float(ctx.f4.f64 - ctx.f12.f64));
	// fmadds f12,f4,f13,f12
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fnmsubs f7,f2,f13,f29
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// fadds f1,f2,f29
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f29.f64));
	// fadds f4,f10,f9
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// stfsx f4,r10,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f31,0(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f10,f11,f8
	ctx.f10.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// stfsx f10,r10,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// stfsx f11,r9,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f11,f12,f6
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// stfs f3,0(r30)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fsubs f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// stfs f11,0(r5)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// stfs f12,0(r28)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fsubs f12,f5,f7
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f12,f7,f5
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// stfs f1,0(r31)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// subf r4,r27,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r27.s64;
	// stfs f12,0(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lwz r10,3532(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d58678
	if (!ctx.cr0.eq) goto loc_82D58678;
loc_82D58838:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f40
	ctx.lr = 0x82D58840;
	__restfpr_19(ctx, base);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58848"))) PPC_WEAK_FUNC(sub_82D58848);
PPC_FUNC_IMPL(__imp__sub_82D58848) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-688
	ctx.r5.s64 = ctx.r11.s64 + -688;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-31176
	ctx.r4.s64 = ctx.r11.s64 + -31176;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58860"))) PPC_WEAK_FUNC(sub_82D58860);
PPC_FUNC_IMPL(__imp__sub_82D58860) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D58868;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28ef8
	ctx.lr = 0x82D58870;
	__savefpr_20(ctx, base);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// bge cr6,0x82d58a34
	if (!ctx.cr6.lt) goto loc_82D58A34;
	// subf r28,r7,r8
	ctx.r28.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f24,-12288(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -12288);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,-7592(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7592);
	ctx.f25.f64 = double(temp.f32);
	// lfs f13,-7588(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7584(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
loc_82D588B0:
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r8,r6,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// mulli r9,r6,12
	ctx.r9.s64 = ctx.r6.s64 * 12;
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f7,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f1,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r7,r6,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f28,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// add r5,r10,r3
	ctx.r5.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfsx f30,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// add r30,r8,r3
	ctx.r30.u64 = ctx.r8.u64 + ctx.r3.u64;
	// lfs f4,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// add r31,r9,r3
	ctx.r31.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// add r29,r7,r3
	ctx.r29.u64 = ctx.r7.u64 + ctx.r3.u64;
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lfsx f26,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// lfs f2,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f29,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f12,f2
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// lfs f31,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f21,f8,f29
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// lfs f27,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f10,f31
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f20,f6,f27
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// fmuls f2,f11,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// fmuls f29,f7,f29
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// fmuls f31,f9,f31
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// fmadds f11,f11,f1,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f23.f64));
	// fmadds f7,f7,f28,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 + ctx.f21.f64));
	// fmadds f9,f9,f30,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f22.f64));
	// fmadds f5,f5,f26,f20
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64 + ctx.f20.f64));
	// fmsubs f12,f12,f1,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f1.f64 - ctx.f2.f64));
	// fmsubs f8,f8,f28,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmsubs f10,f10,f30,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 - ctx.f31.f64));
	// fmsubs f6,f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 - ctx.f27.f64));
	// fadds f2,f7,f11
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fsubs f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 - ctx.f11.f64));
	// fadds f7,f5,f9
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f9,f5,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fsubs f5,f12,f8
	ctx.f5.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fadds f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fsubs f8,f6,f10
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fadds f6,f7,f2
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// fsubs f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// fmuls f31,f5,f13
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f30,f8,f13
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fadds f1,f10,f12
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f2,f12,f10
	ctx.f2.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fnmsubs f10,f6,f24,f4
	ctx.f10.f64 = double(float(-(ctx.f6.f64 * ctx.f24.f64 - ctx.f4.f64)));
	// fmuls f12,f7,f25
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// fmsubs f8,f8,f0,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f31.f64));
	// fmadds f5,f5,f0,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f30.f64));
	// fadds f30,f6,f4
	ctx.f30.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// stfs f30,0(r3)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f4,f9,f13
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fnmsubs f7,f1,f24,f3
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f24.f64 - ctx.f3.f64)));
	// fmuls f6,f2,f25
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmuls f30,f11,f13
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fadds f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fmsubs f11,f11,f0,f4
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f4.f64));
	// fadds f4,f10,f12
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fsubs f10,f7,f6
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fadds f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fmadds f9,f9,f0,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f30.f64));
	// fsubs f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfs f6,0(r4)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f6,f12,f8
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// stfsx f6,r10,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fsubs f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// stfsx f3,r8,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// stfs f12,0(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f12,f7,f11
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f12,f10,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// stfsx f12,r7,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f12,f11,f7
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfs f12,0(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// lwz r10,3532(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// subf r4,r27,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r27.s64;
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d588b0
	if (!ctx.cr0.eq) goto loc_82D588B0;
loc_82D58A34:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f44
	ctx.lr = 0x82D58A3C;
	__restfpr_20(ctx, base);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58A40"))) PPC_WEAK_FUNC(sub_82D58A40);
PPC_FUNC_IMPL(__imp__sub_82D58A40) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-632
	ctx.r5.s64 = ctx.r11.s64 + -632;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-30624
	ctx.r4.s64 = ctx.r11.s64 + -30624;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58A58"))) PPC_WEAK_FUNC(sub_82D58A58);
PPC_FUNC_IMPL(__imp__sub_82D58A58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D58A60;
	__savegprlr_28(ctx, base);
	// stfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f29.u64);
	// stfd f30,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// bge cr6,0x82d58b88
	if (!ctx.cr6.lt) goto loc_82D58B88;
	// rlwinm r29,r9,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
loc_82D58A8C:
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,8(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 * 12;
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f3,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f1,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// add r5,r10,r3
	ctx.r5.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// add r31,r9,r3
	ctx.r31.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// add r30,r8,r3
	ctx.r30.u64 = ctx.r8.u64 + ctx.r3.u64;
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// lfs f6,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f31,f0,f6
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f2,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f30,f12,f4
	ctx.f30.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmuls f29,f10,f2
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmuls f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmuls f6,f13,f6
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmadds f13,f13,f5,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f31.f64));
	// fmadds f11,f11,f3,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmadds f9,f9,f1,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64 + ctx.f29.f64));
	// fmsubs f12,f12,f3,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 - ctx.f4.f64));
	// fmsubs f10,f10,f1,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f1.f64 - ctx.f2.f64));
	// fmsubs f0,f0,f5,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f5.f64 - ctx.f6.f64));
	// fadds f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fsubs f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fsubs f9,f12,f10
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fadds f10,f0,f7
	ctx.f10.f64 = double(float(ctx.f0.f64 + ctx.f7.f64));
	// fsubs f0,f7,f0
	ctx.f0.f64 = double(float(ctx.f7.f64 - ctx.f0.f64));
	// fsubs f7,f6,f8
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// stfsx f7,r9,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,0(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f8,f13,f9
	ctx.f8.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfs f13,0(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fsubs f13,f12,f10
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfs f13,0(r5)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f13,f10,f12
	ctx.f13.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfsx f13,r8,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f11,f0
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfs f13,0(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// stfsx f0,r10,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,3532(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// subf r4,r29,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r29.s64;
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d58a8c
	if (!ctx.cr0.eq) goto loc_82D58A8C;
loc_82D58B88:
	// lfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f30,-56(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58B98"))) PPC_WEAK_FUNC(sub_82D58B98);
PPC_FUNC_IMPL(__imp__sub_82D58B98) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-576
	ctx.r5.s64 = ctx.r11.s64 + -576;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-30120
	ctx.r4.s64 = ctx.r11.s64 + -30120;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58BB0"))) PPC_WEAK_FUNC(sub_82D58BB0);
PPC_FUNC_IMPL(__imp__sub_82D58BB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r11,r11,-16
	ctx.r11.s64 = ctx.r11.s64 + -16;
	// bge cr6,0x82d58cb0
	if (!ctx.cr6.lt) goto loc_82D58CB0;
	// rlwinm r31,r9,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r7,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f3,-7656(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7656);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f4.f64 = double(temp.f32);
loc_82D58BE8:
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// add r5,r10,r3
	ctx.r5.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// add r7,r8,r3
	ctx.r7.u64 = ctx.r8.u64 + ctx.r3.u64;
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// lfs f6,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f1,f12,f6
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// fmuls f2,f0,f8
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f7,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f8,f13,f8
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fmuls f6,f11,f6
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmadds f11,f11,f5,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64 + ctx.f1.f64));
	// fmadds f13,f13,f7,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f7.f64 + ctx.f2.f64));
	// fmsubs f0,f0,f7,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 - ctx.f8.f64));
	// fmsubs f12,f12,f5,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 - ctx.f6.f64));
	// fadds f8,f11,f13
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fadds f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fmuls f0,f11,f3
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fadds f11,f8,f10
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f12,f12,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fnmsubs f11,f8,f4,f10
	ctx.f11.f64 = double(float(-(ctx.f8.f64 * ctx.f4.f64 - ctx.f10.f64)));
	// fadds f7,f13,f9
	ctx.f7.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// fnmsubs f13,f13,f4,f9
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f4.f64 - ctx.f9.f64)));
	// fsubs f10,f11,f12
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// stfs f12,0(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lwz r10,3532(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// subf r4,r31,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r31.s64;
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d58be8
	if (!ctx.cr0.eq) goto loc_82D58BE8;
loc_82D58CB0:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D58CC0"))) PPC_WEAK_FUNC(sub_82D58CC0);
PPC_FUNC_IMPL(__imp__sub_82D58CC0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-520
	ctx.r5.s64 = ctx.r11.s64 + -520;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-29776
	ctx.r4.s64 = ctx.r11.s64 + -29776;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58CD8"))) PPC_WEAK_FUNC(sub_82D58CD8);
PPC_FUNC_IMPL(__imp__sub_82D58CD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r10,r11,-8
	ctx.r10.s64 = ctx.r11.s64 + -8;
	// bgelr cr6
	if (!ctx.cr6.lt) return;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r7,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
loc_82D58CF8:
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f12,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f0,f10
	ctx.f8.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmadds f13,f13,f9,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmsubs f0,f0,f9,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 - ctx.f10.f64));
	// fsubs f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfs f10,0(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// stfs f13,0(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f13,f0,f11
	ctx.f13.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// stfsx f13,r11,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// stfsx f0,r11,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// lwz r11,3532(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 3532);
	// add r3,r5,r3
	ctx.r3.u64 = ctx.r5.u64 + ctx.r3.u64;
	// subf r4,r5,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r5.s64;
	// xor r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 ^ ctx.r6.u64;
	// bne 0x82d58cf8
	if (!ctx.cr0.eq) goto loc_82D58CF8;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D58D68"))) PPC_WEAK_FUNC(sub_82D58D68);
PPC_FUNC_IMPL(__imp__sub_82D58D68) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-464
	ctx.r5.s64 = ctx.r11.s64 + -464;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-29480
	ctx.r4.s64 = ctx.r11.s64 + -29480;
	// b 0x82d77f10
	sub_82D77F10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D58D80"))) PPC_WEAK_FUNC(sub_82D58D80);
PPC_FUNC_IMPL(__imp__sub_82D58D80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D58D88;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D58D90;
	__savefpr_14(ctx, base);
	// stwu r1,-896(r1)
	ea = -896 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5bf38
	if (!ctx.cr6.gt) goto loc_82D5BF38;
	// lwz r11,980(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lfs f27,-2196(r15)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -2196);
	ctx.f27.f64 = double(temp.f32);
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// stfs f27,576(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// stw r11,584(r1)
	PPC_STORE_U32(ctx.r1.u32 + 584, ctx.r11.u32);
	// lfs f27,-2184(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -2184);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,988(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	// stfs f27,564(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lfs f29,-2192(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -2192);
	ctx.f29.f64 = double(temp.f32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f30,-2188(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -2188);
	ctx.f30.f64 = double(temp.f32);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f31,-5424(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -5424);
	ctx.f31.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f28,-2200(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -2200);
	ctx.f28.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f1,-5420(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -5420);
	ctx.f1.f64 = double(temp.f32);
	// stw r11,592(r1)
	PPC_STORE_U32(ctx.r1.u32 + 592, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f2,-5432(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -5432);
	ctx.f2.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f3,-5428(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -5428);
	ctx.f3.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f4,-5440(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -5440);
	ctx.f4.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f5,-5436(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -5436);
	ctx.f5.f64 = double(temp.f32);
	// stw r11,448(r1)
	PPC_STORE_U32(ctx.r1.u32 + 448, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f6,-5448(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -5448);
	ctx.f6.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f7,-5444(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -5444);
	ctx.f7.f64 = double(temp.f32);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f8,-8000(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8000);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f9,-8004(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8004);
	ctx.f9.f64 = double(temp.f32);
	// stw r11,456(r1)
	PPC_STORE_U32(ctx.r1.u32 + 456, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f10,-8012(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8012);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-8008(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8008);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// stw r11,364(r1)
	PPC_STORE_U32(ctx.r1.u32 + 364, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,336(r1)
	PPC_STORE_U32(ctx.r1.u32 + 336, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r11.u32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// stw r11,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r11.u32);
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,16(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfs f27,-2180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2180);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,20(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// stfs f27,588(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// lfs f27,-2172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2172);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,28(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// stfs f27,568(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// lfs f27,-2176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2176);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,32(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// stfs f27,556(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 556, temp.u32);
	// lfs f27,-2156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2156);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,144(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// stfs f27,580(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// lfs f27,-2160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2160);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stfs f27,536(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// lfs f27,-2168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2168);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,292(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// stfs f27,572(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// lfs f27,-2164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2164);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,336(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	// stfs f27,548(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// lfs f27,-2152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2152);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,364(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// stfs f27,552(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// lfs f27,-2148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2148);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,456(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	// stfs f27,540(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// lfs f27,-2144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2144);
	ctx.f27.f64 = double(temp.f32);
	// lwz r11,448(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	// stfs f27,560(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// lfs f27,-2140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -2140);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,544(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
loc_82D58F3C:
	// rlwinm r29,r7,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f27,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// mulli r28,r7,144
	ctx.r28.s64 = ctx.r7.s64 * 144;
	// lfsx f22,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f21,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// mulli r11,r7,224
	ctx.r11.s64 = ctx.r7.s64 * 224;
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfsx f26,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// mulli r10,r7,96
	ctx.r10.s64 = ctx.r7.s64 * 96;
	// lfsx f25,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f16,f26,f25
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// rlwinm r31,r7,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// mulli r30,r7,160
	ctx.r30.s64 = ctx.r7.s64 * 160;
	// lfsx f24,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f15,f24,f23
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// rlwinm r21,r7,7,0,24
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 7) & 0xFFFFFF80;
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// rlwinm r20,r7,6,0,25
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// mulli r19,r7,192
	ctx.r19.s64 = ctx.r7.s64 * 192;
	// lfsx f21,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,20(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f21,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,28(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// mulli r27,r7,48
	ctx.r27.s64 = ctx.r7.s64 * 48;
	// lfsx f21,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,40(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f20,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r26,r7,176
	ctx.r26.s64 = ctx.r7.s64 * 176;
	// lfsx f19,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// mulli r25,r7,80
	ctx.r25.s64 = ctx.r7.s64 * 80;
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfsx f18,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r24,r7,208
	ctx.r24.s64 = ctx.r7.s64 * 208;
	// lfsx f17,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// mulli r23,r7,240
	ctx.r23.s64 = ctx.r7.s64 * 240;
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f17,f24,f26
	ctx.f17.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfs f26,504(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// lfsx f25,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r22,r7,112
	ctx.r22.s64 = ctx.r7.s64 * 112;
	// lfsx f23,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f26,f23,f25
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fmuls f23,f16,f0
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f16,f15,f27
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// fsubs f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f15.f64));
	// stfs f27,24(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f27,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f15.f64));
	// stfs f27,20(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f27,f20,f12
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fsubs f15,f14,f19
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f15,f18,f12
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f24,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f24.f64 = double(temp.f32);
	// stfs f27,16(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fadds f27,f19,f14
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// fmsubs f19,f22,f13,f15
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f15.f64));
	// fsubs f15,f26,f21
	ctx.f15.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// fadds f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// lfs f21,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f24,f21
	ctx.f21.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// stfs f21,484(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f14,f25,f13,f14
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// rlwinm r14,r7,3,0,28
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f24,524(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f24,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f24.f64 = double(temp.f32);
	// mulli r18,r7,40
	ctx.r18.s64 = ctx.r7.s64 * 40;
	// fsubs f14,f23,f24
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// stfs f14,380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// stw r14,324(r1)
	PPC_STORE_U32(ctx.r1.u32 + 324, ctx.r14.u32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,456(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfs f24,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f24.f64 = double(temp.f32);
	// fadds f23,f15,f24
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// fsubs f15,f15,f24
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// mulli r14,r7,136
	ctx.r14.s64 = ctx.r7.s64 * 136;
	// fadds f24,f26,f27
	ctx.f24.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f26,f17,f21
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f26,304(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f26,f21,f17
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfs f26,284(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// stw r14,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r14.u32);
	// mulli r14,r7,72
	ctx.r14.s64 = ctx.r7.s64 * 72;
	// fmuls f26,f23,f0
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f26,424(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fmuls f26,f15,f0
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f26,528(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// stw r14,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r14.u32);
	// mulli r14,r7,200
	ctx.r14.s64 = ctx.r7.s64 * 200;
	// stw r14,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r14.u32);
	// mulli r14,r7,248
	ctx.r14.s64 = ctx.r7.s64 * 248;
	// stw r14,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r14.u32);
	// mulli r14,r7,56
	ctx.r14.s64 = ctx.r7.s64 * 56;
	// stw r14,72(r1)
	PPC_STORE_U32(ctx.r1.u32 + 72, ctx.r14.u32);
	// lfs f26,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f26.f64 = double(temp.f32);
	// fadds f23,f26,f19
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// stfs f23,520(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fsubs f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f19.f64));
	// stfs f26,448(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// fmuls f26,f20,f13
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// mulli r14,r7,184
	ctx.r14.s64 = ctx.r7.s64 * 184;
	// fmuls f23,f22,f12
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stw r14,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r14.u32);
	// lwz r14,324(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// mulli r17,r7,168
	ctx.r17.s64 = ctx.r7.s64 * 168;
	// fmsubs f26,f25,f12,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 - ctx.f26.f64));
	// fmadds f25,f18,f13,f23
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f23.f64));
	// lfsx f23,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f15,f23,f22
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// mulli r16,r7,232
	ctx.r16.s64 = ctx.r7.s64 * 232;
	// fsubs f21,f26,f25
	ctx.f21.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f21,500(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfsx f25,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mulli r15,r7,104
	ctx.r15.s64 = ctx.r7.s64 * 104;
	// stfs f26,516(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// lfsx f21,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f20,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r14,264(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// lfsx f26,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lwz r14,96(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,104(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r7,120
	ctx.r14.s64 = ctx.r7.s64 * 120;
	// lfsx f22,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,72(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f14,f21,f26
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// fadds f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// fadds f21,f20,f25
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// fadds f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// mulli r14,r7,24
	ctx.r14.s64 = ctx.r7.s64 * 24;
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f18,f22,f17
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// fsubs f17,f14,f15
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stw r14,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r14.u32);
	// fsubs f17,f26,f23
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// lwz r14,120(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// fadds f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// fsubs f14,f21,f20
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f21,24(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f20,f17,f12
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f23,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fsubs f21,f23,f19
	ctx.f21.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f21,f15,f25
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// fmuls f19,f14,f12
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// fadds f15,f26,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f15.f64));
	// stfs f15,204(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f15,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// stfs f26,236(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmadds f26,f14,f13,f20
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f26,308(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fmuls f20,f21,f10
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fmsubs f26,f17,f13,f19
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f19.f64));
	// stfs f26,220(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f19,f25,f8
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fmuls f25,f25,f9
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// lfs f26,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f20,f26,f11,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 + ctx.f20.f64));
	// stfs f20,508(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fmsubs f26,f26,f10,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 - ctx.f21.f64));
	// stfs f26,480(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// fmadds f26,f23,f9,f19
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f9.f64 + ctx.f19.f64));
	// stfs f26,488(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmsubs f26,f23,f8,f25
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f8.f64 - ctx.f25.f64));
	// stfs f26,336(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfsx f26,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// mulli r14,r7,152
	ctx.r14.s64 = ctx.r7.s64 * 152;
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fadds f23,f26,f21
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// stw r14,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r14.u32);
	// mulli r14,r7,216
	ctx.r14.s64 = ctx.r7.s64 * 216;
	// stw r14,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r14.u32);
	// mulli r14,r7,88
	ctx.r14.s64 = ctx.r7.s64 * 88;
	// stw r14,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r14.u32);
	// mulli r14,r7,36
	ctx.r14.s64 = ctx.r7.s64 * 36;
	// stw r14,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r14.u32);
	// mulli r14,r7,164
	ctx.r14.s64 = ctx.r7.s64 * 164;
	// stw r14,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r14.u32);
	// mulli r14,r7,228
	ctx.r14.s64 = ctx.r7.s64 * 228;
	// stw r14,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r14.u32);
	// lwz r14,132(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lfsx f25,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lwz r14,140(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lfsx f21,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r14,136(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lfsx f20,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r14,152(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lwz r14,168(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,228(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,160(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f14,f18,f23
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// mulli r14,r7,100
	ctx.r14.s64 = ctx.r7.s64 * 100;
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// rlwinm r14,r7,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f18,f25,f21
	ctx.f18.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// fadds f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// lfsx f21,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r14,r7,132
	ctx.r14.s64 = ctx.r7.s64 * 132;
	// stfs f21,20(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f21,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,36(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// mulli r14,r7,68
	ctx.r14.s64 = ctx.r7.s64 * 68;
	// lfsx f21,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,28(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// mulli r14,r7,196
	ctx.r14.s64 = ctx.r7.s64 * 196;
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f19,f17,f15
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f19,32(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f19,f15,f17
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f19,88(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f17,f14,f12
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,144(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// fsubs f15,f21,f18
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f18,f21,f18
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// fsubs f21,f20,f25
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// fadds f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f25,24(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f25,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f25.f64 = double(temp.f32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f20,28(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// fmuls f20,f15,f0
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f20,f18,f0
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f20,36(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fadds f15,f18,f20
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fsubs f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// fmuls f20,f15,f0
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f18,f21,f12
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmadds f21,f21,f13,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f21,316(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,332(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmsubs f18,f14,f13,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f18,404(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f26,f15,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// fmuls f18,f23,f11
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// mulli r14,r7,20
	ctx.r14.s64 = ctx.r7.s64 * 20;
	// fmuls f17,f21,f11
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fmuls f15,f26,f9
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fmsubs f21,f21,f10,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 - ctx.f18.f64));
	// stfs f21,492(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// stw r14,64(r1)
	PPC_STORE_U32(ctx.r1.u32 + 64, ctx.r14.u32);
	// mulli r14,r7,84
	ctx.r14.s64 = ctx.r7.s64 * 84;
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f23,f23,f10,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f17.f64));
	// stfs f23,496(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// fmsubs f23,f22,f8,f15
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f8.f64 - ctx.f15.f64));
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f26,f22,f9,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 + ctx.f26.f64));
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// stw r14,56(r1)
	PPC_STORE_U32(ctx.r1.u32 + 56, ctx.r14.u32);
	// stfs f23,532(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// stfs f26,364(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fadds f23,f18,f21
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// mulli r14,r7,212
	ctx.r14.s64 = ctx.r7.s64 * 212;
	// fadds f26,f17,f22
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f19,f20
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// fsubs f18,f15,f25
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stw r14,48(r1)
	PPC_STORE_U32(ctx.r1.u32 + 48, ctx.r14.u32);
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// mulli r14,r7,244
	ctx.r14.s64 = ctx.r7.s64 * 244;
	// fadds f15,f23,f26
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f15,348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f26,108(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stw r14,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r14.u32);
	// lwz r14,64(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r7,148
	ctx.r14.s64 = ctx.r7.s64 * 148;
	// lfsx f26,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lwz r14,56(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// lfsx f23,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,48(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,124(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r7,116
	ctx.r14.s64 = ctx.r7.s64 * 116;
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r14,r7,52
	ctx.r14.s64 = ctx.r7.s64 * 52;
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// mulli r14,r7,180
	ctx.r14.s64 = ctx.r7.s64 * 180;
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f14,f26,f19
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// mulli r14,r7,252
	ctx.r14.s64 = ctx.r7.s64 * 252;
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// mulli r14,r7,124
	ctx.r14.s64 = ctx.r7.s64 * 124;
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,36(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f19,f15,f23
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,24(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// stfs f19,144(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f23,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f19,f23
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfs f23,88(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f19,f23
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfs f23,28(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f19,f26,f12
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r7,28
	ctx.r14.s64 = ctx.r7.s64 * 28;
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f23,320(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f23,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f15,f14,f23
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f19,f14,f13,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f19.f64));
	// stfs f19,144(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,328(r1)
	PPC_STORE_U32(ctx.r1.u32 + 328, ctx.r14.u32);
	// mulli r14,r7,156
	ctx.r14.s64 = ctx.r7.s64 * 156;
	// stw r14,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r14.u32);
	// fmsubs f26,f26,f13,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f26,292(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f26,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f15,f26,f19
	ctx.f15.f64 = double(float(ctx.f26.f64 - ctx.f19.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// fmuls f14,f15,f13
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmsubs f14,f19,f12,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmadds f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f15,f19
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// fadds f15,f26,f23
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// stfs f15,300(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f26,116(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f26,f14,f0
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fsubs f19,f14,f15
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fadds f14,f26,f22
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// stfs f14,408(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// stfs f26,276(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fadds f26,f23,f21
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// stfs f26,360(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fsubs f26,f23,f21
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f26,80(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f26,f19,f18
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f26,388(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fsubs f26,f19,f18
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f26,216(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f26,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f26.f64 = double(temp.f32);
	// fadds f23,f26,f17
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// stfs f23,444(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// stfs f26,260(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f26,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// fadds f23,f26,f25
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stfs f23,292(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f26,396(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// fadds f26,f15,f20
	ctx.f26.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f26,400(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// fsubs f26,f20,f15
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f26,268(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f26,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f25.f64 = double(temp.f32);
	// mulli r14,r7,220
	ctx.r14.s64 = ctx.r7.s64 * 220;
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stw r14,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r14.u32);
	// mulli r14,r7,92
	ctx.r14.s64 = ctx.r7.s64 * 92;
	// stw r14,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r14.u32);
	// mulli r14,r7,12
	ctx.r14.s64 = ctx.r7.s64 * 12;
	// stw r14,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r14.u32);
	// mulli r14,r7,140
	ctx.r14.s64 = ctx.r7.s64 * 140;
	// stw r14,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r14.u32);
	// mulli r14,r7,76
	ctx.r14.s64 = ctx.r7.s64 * 76;
	// stw r14,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r14.u32);
	// lwz r14,328(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	// lfsx f25,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r14,r7,204
	ctx.r14.s64 = ctx.r7.s64 * 204;
	// stw r14,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r14.u32);
	// lwz r14,176(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// lfsx f23,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,92(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fsubs f15,f25,f23
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r14,r7,108
	ctx.r14.s64 = ctx.r7.s64 * 108;
	// stw r14,232(r1)
	PPC_STORE_U32(ctx.r1.u32 + 232, ctx.r14.u32);
	// lwz r14,180(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lfsx f21,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r14,184(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lfsx f20,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r14,84(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lwz r14,192(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,200(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r7,236
	ctx.r14.s64 = ctx.r7.s64 * 236;
	// lfsx f23,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,232(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r7,44
	ctx.r14.s64 = ctx.r7.s64 * 44;
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f14,f22,f21
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfsx f21,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r14,r7,172
	ctx.r14.s64 = ctx.r7.s64 * 172;
	// lfsx f21,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,20(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// mulli r14,r7,60
	ctx.r14.s64 = ctx.r7.s64 * 60;
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// mulli r14,r7,188
	ctx.r14.s64 = ctx.r7.s64 * 188;
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,36(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// fadds f17,f14,f15
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f17,f15
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,112(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fmuls f15,f21,f12
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,256(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmuls f14,f19,f12
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// fmadds f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f19,224(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f20,f18
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f19,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f21,f21,f13,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f14.f64));
	// fmuls f14,f19,f12
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f19,f15,f13,f14
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f12,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f15,248(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// fadds f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fsubs f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// fadds f17,f19,f21
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,172(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f26,f17
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,512(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,376(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fsubs f17,f22,f25
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// lfsx f22,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,344(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfsx f17,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f17,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f17,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,320(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f14,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,256(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fadds f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f22,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,28(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f20,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f19,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,76(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f19,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f19,420(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f19,68(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,240(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfsx f19,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,248(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfsx f19,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,100(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f14,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfsx f18,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,252(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f18,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,256(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// lfs f14,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,384(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fsubs f17,f26,f25
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f17,392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f26,312(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f26,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f23,f26
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// stfs f25,212(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fadds f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// stfs f26,196(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fadds f26,f21,f20
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f26,472(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// fsubs f26,f21,f20
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f26,440(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// lfs f25,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f25.f64 = double(temp.f32);
	// lwz r11,328(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f23,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfs f25,248(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f25,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f25.f64 = double(temp.f32);
	// fadds f23,f19,f25
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f19,f25
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f25.f64));
	// lfs f25,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f25,f12
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f25,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f25,f12
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f25,f12
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f25,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f23,100(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f23,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f14,f23,f13
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f23,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f13,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f19.f64));
	// lfs f19,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f19,f13,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f20.f64));
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f17,f19,f13,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f17,112(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f19,f19,f12,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f19,68(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fsubs f19,f15,f22
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fadds f14,f25,f19
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// fadds f14,f17,f19
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f14,428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,148(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f19,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f17,f19
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f14,320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,416(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fsubs f17,f15,f22
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfsx f19,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lwz r11,176(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// fsubs f14,f25,f17
	ctx.f14.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// lfsx f25,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stfs f25,176(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f25,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// stfs f25,328(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfsx f25,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lwz r11,180(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// stfs f25,92(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fsubs f25,f21,f26
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// stfs f25,32(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f25,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,16(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f25,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// stfs f25,180(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lwz r11,184(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fadds f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// lfsx f25,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfs f25,20(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// lfsx f17,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r11,192(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfsx f17,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r11,200(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	// stfs f17,192(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,88(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f18,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r7,236
	ctx.r11.s64 = ctx.r7.s64 * 236;
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f17,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f18,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r11,232(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	// stfs f18,200(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f18,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f14,232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfsx f17,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r7,44
	ctx.r11.s64 = ctx.r7.s64 * 44;
	// lfsx f15,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r7,172
	ctx.r11.s64 = ctx.r7.s64 * 172;
	// lfsx f14,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r7,252
	ctx.r11.s64 = ctx.r7.s64 * 252;
	// lfsx f21,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,252(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// mulli r11,r7,124
	ctx.r11.s64 = ctx.r7.s64 * 124;
	// lfs f21,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// lfsx f21,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,244(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// mulli r11,r7,60
	ctx.r11.s64 = ctx.r7.s64 * 60;
	// lfsx f21,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,184(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfsx f21,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,100(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f21,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f21,60(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f21,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f21,176(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f21,92(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f19,288(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f19,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f21,76(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f19,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,192(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,68(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f15,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f14,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,248(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// lfs f14,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fadds f15,f20,f25
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f15,476(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// stfs f25,164(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f15,f25,f20
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// stfs f15,256(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fadds f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f25,328(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fsubs f25,f18,f22
	ctx.f25.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f25,224(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fadds f25,f22,f18
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f25,112(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f25,f23,f26
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f25,468(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// stfs f26,296(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f26,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f23,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f20,f22,f23
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fadds f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f23,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f23,f12
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f15,f23,f13
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,232(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f23,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f13
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmuls f23,f17,f13
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// stfs f23,16(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f23,f20,f0
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f20,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f22,f20,f13,f18
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f18.f64));
	// fmadds f20,f20,f12,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f20,184(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f20,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,180(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f18,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// fmadds f18,f17,f12,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f18,252(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f18,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f18.f64 = double(temp.f32);
	// lwz r11,324(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f18,f12,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f15.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r11,264(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// stfs f14,128(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fadds f15,f17,f18
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r11,132(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// stfs f18,96(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfsx f17,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// lfsx f17,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,264(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfsx f17,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f17,352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfsx f17,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,324(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f17,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f17,288(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfsx f17,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r11,140(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// stfs f17,132(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// stfs f26,464(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// lfs f17,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f26,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// lwz r11,136(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stfs f26,88(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f15,136(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f26,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfsx f17,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lfsx f15,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r7,120
	ctx.r11.s64 = ctx.r7.s64 * 120;
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fadds f14,f23,f25
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfs f14,372(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fsubs f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// stfs f25,452(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r11,72(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	// stfs f14,152(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lfsx f25,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,120(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f23,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// lfs f23,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f23,232(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f23,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,244(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f23,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f20,460(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,128(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f23,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,96(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f23,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f20,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,84(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f20,72(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f20,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,28(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f23,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f20,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f20.f64 = double(temp.f32);
	// fadds f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// fsubs f20,f17,f15
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,132(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,184(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,192(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f17,f18
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f15,180(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,200(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f18,f19,f21
	ctx.f18.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f18,264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f21,252(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f19,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f21.f64 = double(temp.f32);
	// fadds f18,f19,f21
	ctx.f18.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f18,352(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f21,176(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f21,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f26,f21
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// stfs f19,88(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// stfs f26,100(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f26,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f26.f64 = double(temp.f32);
	// fadds f21,f22,f26
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f21,432(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// stfs f26,208(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f26,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f26.f64 = double(temp.f32);
	// fadds f22,f25,f26
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f26,368(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f25,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f21,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f21.f64 = double(temp.f32);
	// lfs f25,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// stfs f22,288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f22,f19,f21
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fadds f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// lfs f19,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f15,f20,f18
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f23,120(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f23,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f19,f22
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// stfs f14,324(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f17,f0
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// mulli r11,r7,132
	ctx.r11.s64 = ctx.r7.s64 * 132;
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,152(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// mulli r11,r7,68
	ctx.r11.s64 = ctx.r7.s64 * 68;
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f14,f17,f26
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// mulli r11,r7,196
	ctx.r11.s64 = ctx.r7.s64 * 196;
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fsubs f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// stfs f26,84(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// stfs f14,140(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfsx f26,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,36(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fsubs f14,f15,f25
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stfs f14,372(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fadds f26,f15,f25
	ctx.f26.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// mulli r11,r7,116
	ctx.r11.s64 = ctx.r7.s64 * 116;
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f21,f13
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f17,f19,f13
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfsx f25,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r11,r7,52
	ctx.r11.s64 = ctx.r7.s64 * 52;
	// stfs f25,68(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f25,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// lfsx f20,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,124(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,128(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmuls f18,f21,f12
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f20,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f19,f12
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f23,f20
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fmr f21,f19
	ctx.f21.f64 = ctx.f19.f64;
	// fmsubs f19,f21,f13,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f19,96(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f21,f12,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f15.f64));
	// fmadds f18,f19,f12,f17
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stfs f21,76(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmuls f15,f26,f8
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fmuls f17,f26,f9
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fmuls f26,f25,f9
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f21,f19,f13,f18
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f18.f64));
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfs f21,92(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f19,156(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f19,f14,f11
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f11.f64));
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f25,f8
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fadds f25,f20,f22
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f18,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f23,132(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f20,f20,f22
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// lfs f23,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f23,f10
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// stfs f26,44(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmr f26,f22
	ctx.f26.f64 = ctx.f22.f64;
	// fmuls f23,f23,f11
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// stfs f25,60(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fmadds f22,f26,f11,f21
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 + ctx.f21.f64));
	// stfs f22,452(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// fmsubs f26,f26,f10,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 - ctx.f23.f64));
	// stfs f26,464(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// lfs f26,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f26,f26,f10,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 - ctx.f19.f64));
	// stfs f26,460(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f26,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f10,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f18.f64));
	// stfs f26,372(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f26,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f26.f64 = double(temp.f32);
	// fmr f25,f26
	ctx.f25.f64 = ctx.f26.f64;
	// lfs f23,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f26,f25,f8,f17
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f17.f64));
	// stfs f26,28(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f25,f25,f9,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f15.f64));
	// fadds f22,f23,f26
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f25,16(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f25,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f23,f25,f9,f14
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f14.f64));
	// fmsubs f25,f25,f8,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f21.f64));
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// stfs f23,32(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lfs f22,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f23.f64 = double(temp.f32);
	// stfs f25,20(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f25,f21,f0
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fadds f21,f22,f23
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f21,128(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// lfs f21,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f20,f0
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f20,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,72(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f20,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f19,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// stfs f21,104(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f21,120(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f21,f18
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f20,96(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f21,152(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfsx f21,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r11,228(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f20,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r11,160(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// fmuls f14,f17,f12
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfsx f19,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r11,r7,100
	ctx.r11.s64 = ctx.r7.s64 * 100;
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r11,64(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// lfsx f17,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r7,148
	ctx.r11.s64 = ctx.r7.s64 * 148;
	// lfsx f15,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r11,48(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f15,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r11,56(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f15,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r7,180
	ctx.r11.s64 = ctx.r7.s64 * 180;
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f15,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,160(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f15,f21,f20
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,228(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,156(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f18,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,92(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fsubs f17,f20,f15
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// fadds f18,f20,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// fsubs f20,f19,f21
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f20,48(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f21,168(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fadds f15,f20,f21
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f20,f21
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f21,140(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f19,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f21,136(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f21,124(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f19,272(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fmuls f21,f18,f0
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f21,64(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f21,160(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f21,f15,f0
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,228(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f19,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f19,44(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f18,f15,f13,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f18,280(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f18,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f18.f64 = double(temp.f32);
	// fadds f15,f21,f18
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// fmr f17,f15
	ctx.f17.f64 = ctx.f15.f64;
	// stfs f21,356(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fsubs f15,f20,f17
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fadds f21,f20,f17
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f20,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f15,f11
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f20,f13,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f20,156(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f14,f21,f9
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fmuls f21,f21,f8
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f20,f10
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fmadds f18,f19,f11,f18
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f18.f64));
	// fmsubs f20,f19,f10,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 - ctx.f20.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r11,r8,7,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 7) & 0xFFFFFF80;
	// stfs f21,156(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// rlwinm r10,r9,7,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0xFFFFFF80;
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// mulli r31,r8,192
	ctx.r31.s64 = ctx.r8.s64 * 192;
	// fmr f21,f19
	ctx.f21.f64 = ctx.f19.f64;
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// rlwinm r30,r8,6,0,25
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// rlwinm r29,r9,6,0,25
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0xFFFFFFC0;
	// mulli r28,r9,192
	ctx.r28.s64 = ctx.r9.s64 * 192;
	// fadds f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f19,92(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f21,96(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f10,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 - ctx.f17.f64));
	// stfs f21,76(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f10,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f21,36(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f21,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f20,f21,f8,f14
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 - ctx.f14.f64));
	// stfs f20,60(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f20,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f21,f21,f9,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f18.f64));
	// stfs f21,44(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f21,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f20,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f24,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f17,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,356(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f17,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f15,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,160(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,272(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,168(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r27,r8,8,0,23
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFFFF00;
	// lfs f15,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,300(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// stfs f24,304(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// stfs f24,188(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f24,f13,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f24,152(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f24,f21,f20
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f24,140(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f24,f20,f21
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f24,264(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fsubs f24,f19,f18
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f24,136(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f24,f18,f19
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f24,132(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f21,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fadds f20,f21,f24
	ctx.f20.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// stfs f20,356(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fsubs f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f21.f64));
	// stfs f24,156(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f21,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f24.f64 = double(temp.f32);
	// fadds f20,f21,f24
	ctx.f20.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// stfs f20,204(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfs f24,348(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f24,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f20,f24,f8
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// lfs f21,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f24,f9
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// lfs f24,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f24.f64 = double(temp.f32);
	// fadds f18,f21,f24
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fsubs f17,f21,f24
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// lfs f21,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f24.f64 = double(temp.f32);
	// fadds f15,f21,f24
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fsubs f14,f21,f24
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// lfs f21,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// stfs f24,272(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fmr f24,f21
	ctx.f24.f64 = ctx.f21.f64;
	// fmadds f21,f24,f9,f20
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f20.f64));
	// stfs f21,72(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmuls f20,f15,f0
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f20,48(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmsubs f24,f24,f8,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 - ctx.f19.f64));
	// lfs f19,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f24,104(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f24,f18,f0
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fadds f18,f19,f20
	ctx.f18.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f18,124(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f20,160(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f20,168(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f20,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f20,f13,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f20,64(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f20,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f20.f64 = double(temp.f32);
	// fadds f17,f19,f20
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f20,f19
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f19,f18
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f19,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f19.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f14,280(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// mulli r26,r8,96
	ctx.r26.s64 = ctx.r8.s64 * 96;
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfsx f19,r11,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fmuls f19,f17,f0
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfsx f18,r10,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// mulli r11,r8,224
	ctx.r11.s64 = ctx.r8.s64 * 224;
	// rlwinm r10,r8,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f17,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f17,f20
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// fadds f17,f20,f17
	ctx.f17.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f20,f19
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfsx f14,r31,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfsx f20,r30,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f20,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r31,r9,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f19,f18,f20
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfsx f19,r29,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfsx f20,r28,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f19,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f19.f64 = double(temp.f32);
	// mulli r30,r9,224
	ctx.r30.s64 = ctx.r9.s64 * 224;
	// lfs f20,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f20,280(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f20,196(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f20,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f20,f12
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f19,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f20.f64 = double(temp.f32);
	// mulli r29,r9,96
	ctx.r29.s64 = ctx.r9.s64 * 96;
	// stfsx f15,r27,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// stfs f17,0(r5)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f17,f19,f20
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f12
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// mulli r28,r9,160
	ctx.r28.s64 = ctx.r9.s64 * 160;
	// fmsubs f20,f20,f13,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f20,300(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f20,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f20,f12
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f20,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f20,272(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// mulli r27,r8,160
	ctx.r27.s64 = ctx.r8.s64 * 160;
	// stfs f19,188(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f19,332(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f19,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f19.f64 = double(temp.f32);
	// stfs f20,348(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmsubs f19,f19,f13,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f18.f64));
	// lfs f20,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// stfs f19,304(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f19,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f19,f12
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// lfs f18,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f18,f12
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fmuls f14,f19,f9
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// fmuls f19,f19,f8
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// stfs f19,236(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmsubs f19,f18,f13,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f17.f64));
	// lfs f17,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// lfs f18,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f13,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f15.f64));
	// fmsubs f15,f17,f8,f14
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 - ctx.f14.f64));
	// stfs f15,228(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f15,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f25,f15
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f15,280(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fmuls f14,f15,f10
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f15,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f17,f17,f9,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f15.f64));
	// stfs f17,168(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f17,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfs f15,356(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfs f27,188(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f27,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfs f15,204(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f15,332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmadds f15,f15,f11,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f14.f64));
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f14,196(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f14,284(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,236(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f18,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfsx f18,r10,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f18,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfsx f14,r31,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfsx f18,r30,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f18,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f19,f18
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// stfsx f14,r29,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfsx f19,r28,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f19,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f20,f19
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfsx f18,r27,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfsx f20,r26,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// lfs f20,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f20.f64 = double(temp.f32);
	// fadds f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// lfs f20,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r8,240
	ctx.r11.s64 = ctx.r8.s64 * 240;
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f19,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f18.f64 = double(temp.f32);
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f25,f18,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 - ctx.f25.f64));
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// rlwinm r31,r9,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r30,r9,240
	ctx.r30.s64 = ctx.r9.s64 * 240;
	// fmsubs f20,f14,f13,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f20.f64));
	// stfs f20,284(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// lfs f14,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f19,f14,f12,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 + ctx.f19.f64));
	// stfs f19,116(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// mulli r29,r9,112
	ctx.r29.s64 = ctx.r9.s64 * 112;
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// stfs f14,280(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f14.f64));
	// stfs f27,272(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fmuls f14,f25,f8
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// lfs f27,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f25,f25,f9
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// stfs f25,236(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmsubs f27,f27,f10,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f18.f64));
	// stfs f27,108(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f27,f21,f11
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// mulli r28,r9,144
	ctx.r28.s64 = ctx.r9.s64 * 144;
	// fmuls f18,f24,f11
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// mulli r27,r8,144
	ctx.r27.s64 = ctx.r8.s64 * 144;
	// fmsubs f27,f24,f10,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f27.f64));
	// fmadds f25,f21,f10,f18
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f18.f64));
	// mulli r26,r8,112
	ctx.r26.s64 = ctx.r8.s64 * 112;
	// mulli r25,r8,208
	ctx.r25.s64 = ctx.r8.s64 * 208;
	// mulli r24,r8,48
	ctx.r24.s64 = ctx.r8.s64 * 48;
	// lfs f24,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f24.f64 = double(temp.f32);
	// mulli r23,r9,48
	ctx.r23.s64 = ctx.r9.s64 * 48;
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f24
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// stfs f21,212(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// fmadds f21,f22,f9,f14
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 + ctx.f14.f64));
	// mulli r22,r9,208
	ctx.r22.s64 = ctx.r9.s64 * 208;
	// lfs f18,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f22,f8,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f8.f64 - ctx.f18.f64));
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f15,f27
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// fsubs f27,f27,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f15.f64));
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,284(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f25,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f25
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfs f15,236(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// fsubs f15,f20,f18
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfsx f15,r11,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfsx f20,r10,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f20,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f19,f20
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// fadds f19,f20,f19
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f20,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r9,80
	ctx.r11.s64 = ctx.r9.s64 * 80;
	// fadds f15,f14,f20
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfsx f15,r31,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfsx f20,r30,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f20,f27,f25
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// stfsx f20,r29,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// lfs f25,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f27,r28,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// fadds f27,f24,f17
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// stfsx f18,r27,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// stfsx f19,r26,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// lfs f15,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f15.f64 = double(temp.f32);
	// mulli r10,r9,176
	ctx.r10.s64 = ctx.r9.s64 * 176;
	// lfs f18,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// mulli r31,r8,176
	ctx.r31.s64 = ctx.r8.s64 * 176;
	// fsubs f20,f27,f25
	ctx.f20.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfsx f20,r25,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f19,f25,f27
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfs f27,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f22.f64));
	// lfs f25,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f19,r24,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// lfs f19,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f19.f64 = double(temp.f32);
	// mulli r30,r8,80
	ctx.r30.s64 = ctx.r8.s64 * 80;
	// fadds f20,f27,f25
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// stfsx f20,r23,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// fadds f25,f26,f15
	ctx.f25.f64 = double(float(ctx.f26.f64 + ctx.f15.f64));
	// stfsx f27,r22,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fsubs f26,f15,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// stfs f26,344(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfs f26,392(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f26,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f19,f26,f9
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// lfs f26,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f9
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// lfs f27,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// stfs f26,276(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,284(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f23,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f9
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f26,f23,f18
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f23,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f21,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f18,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,376(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f21,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f8,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 + ctx.f19.f64));
	// stfs f21,416(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f19,f21,f8,f15
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 - ctx.f15.f64));
	// stfs f19,80(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f19,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f8,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 - ctx.f14.f64));
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f19,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f21,f9,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f19.f64));
	// stfs f21,236(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f21,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f21,212(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f19,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f25,f6
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f21,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f20,f6
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f21,332(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f27,f6
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fmuls f17,f21,f6
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// lfs f21,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f21,f4
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f4.f64));
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// stfs f21,276(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmsubs f27,f27,f7,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 - ctx.f18.f64));
	// fmadds f25,f25,f7,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f19.f64));
	// lfs f19,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f19.f64 = double(temp.f32);
	// fadds f18,f23,f19
	ctx.f18.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// stfsx f18,r11,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfsx f23,r10,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f23,f24,f22
	ctx.f23.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfsx f23,r31,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfsx f24,r30,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f24,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f21,f20,f7,f17
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 - ctx.f17.f64));
	// fsubs f23,f16,f24
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// lfs f22,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,216
	ctx.r11.s64 = ctx.r8.s64 * 216;
	// lfs f19,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f19.f64 = double(temp.f32);
	// mulli r10,r8,40
	ctx.r10.s64 = ctx.r8.s64 * 40;
	// lfs f17,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f7,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f15.f64));
	// fmuls f15,f26,f5
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fsubs f24,f23,f22
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f22,f19,f18
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fmadds f18,f17,f5,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfs f14,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f17,f17,f4,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 - ctx.f14.f64));
	// stfs f17,196(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f17,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,108(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f17,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f4,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f4.f64 - ctx.f15.f64));
	// stfs f15,276(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmuls f14,f26,f4
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fadds f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f26,344(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fadds f26,f15,f18
	ctx.f26.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f26,376(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f26,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f26.f64 = double(temp.f32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// stfs f15,416(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f18,80(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f18,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// fmadds f22,f22,f5,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 + ctx.f14.f64));
	// stfs f18,212(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fadds f14,f20,f27
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// stfs f24,276(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fadds f15,f17,f19
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f24,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// lfs f20,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f17,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,308(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fadds f18,f21,f25
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// lfs f20,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f21,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,424(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// lfs f20,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// lfs f17,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f17.f64 = double(temp.f32);
	// mulli r31,r9,40
	ctx.r31.s64 = ctx.r9.s64 * 40;
	// fsubs f16,f20,f17
	ctx.f16.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfsx f16,r11,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// fadds f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f16,404(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// mulli r30,r9,216
	ctx.r30.s64 = ctx.r9.s64 * 216;
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfsx f20,r10,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f20,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f16,f24,f18
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// fadds f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f17,f20,f26
	ctx.f17.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fadds f24,f14,f15
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f14,f25,f19
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// fsubs f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 - ctx.f19.f64));
	// fsubs f25,f23,f27
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// stfs f25,344(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fadds f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// mulli r29,r9,88
	ctx.r29.s64 = ctx.r9.s64 * 88;
	// fmuls f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// mulli r28,r9,168
	ctx.r28.s64 = ctx.r9.s64 * 168;
	// mulli r27,r8,168
	ctx.r27.s64 = ctx.r8.s64 * 168;
	// lfs f26,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f2
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// mulli r11,r8,88
	ctx.r11.s64 = ctx.r8.s64 * 88;
	// lfs f27,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// stfs f27,108(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f27,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// mulli r10,r8,232
	ctx.r10.s64 = ctx.r8.s64 * 232;
	// fmadds f26,f21,f3,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f26.f64));
	// lfs f21,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f22,f21,f3,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 - ctx.f22.f64));
	// stfs f22,308(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f22,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f22.f64 = double(temp.f32);
	// fmr f25,f22
	ctx.f25.f64 = ctx.f22.f64;
	// lfs f22,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f22.f64 = double(temp.f32);
	// mulli r26,r8,24
	ctx.r26.s64 = ctx.r8.s64 * 24;
	// fadds f22,f22,f25
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// mulli r25,r9,24
	ctx.r25.s64 = ctx.r9.s64 * 24;
	// mulli r24,r9,232
	ctx.r24.s64 = ctx.r9.s64 * 232;
	// mulli r23,r9,104
	ctx.r23.s64 = ctx.r9.s64 * 104;
	// mulli r22,r9,152
	ctx.r22.s64 = ctx.r9.s64 * 152;
	// stfsx f22,r31,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// mulli r31,r8,152
	ctx.r31.s64 = ctx.r8.s64 * 152;
	// lfs f22,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// lfs f22,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f22.f64 = double(temp.f32);
	// stfs f24,80(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmr f24,f22
	ctx.f24.f64 = ctx.f22.f64;
	// stfsx f25,r30,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// mulli r30,r9,248
	ctx.r30.s64 = ctx.r9.s64 * 248;
	// lfs f25,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f17,r29,r6
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// stfsx f20,r28,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f25,f24
	ctx.f22.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfsx f22,r27,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfsx f25,r11,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// stfsx f16,r10,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r8,104
	ctx.r11.s64 = ctx.r8.s64 * 104;
	// stfsx f18,r26,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// lfs f24,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f24,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f24.f64 = double(temp.f32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r29,r9,120
	ctx.r29.s64 = ctx.r9.s64 * 120;
	// mulli r28,r9,136
	ctx.r28.s64 = ctx.r9.s64 * 136;
	// mulli r27,r8,136
	ctx.r27.s64 = ctx.r8.s64 * 136;
	// lfs f22,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f22,r25,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// stfsx f15,r24,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// stfsx f14,r23,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// stfsx f19,r22,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f22,r31,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r31,r9,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// stfsx f23,r11,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r8,248
	ctx.r11.s64 = ctx.r8.s64 * 248;
	// lfs f23,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// lfs f22,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f21,f10
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f19,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f21,f11
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f21,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f21,f11
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f19,f11
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// lfs f19,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f17,f11,f20
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f20.f64));
	// lfs f20,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f17,f17,f10,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f16.f64));
	// lfs f16,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f10,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f15.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// stfs f16,52(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmsubs f18,f14,f10,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 - ctx.f18.f64));
	// lfs f16,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f22,f1
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmuls f14,f16,f2
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// fmuls f16,f25,f31
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fmuls f25,f25,f1
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// stfs f25,360(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fmuls f22,f22,f31
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// stfs f22,408(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// fmsubs f22,f23,f31,f15
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f31.f64 - ctx.f15.f64));
	// fmadds f25,f24,f1,f16
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f16.f64));
	// lfs f16,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f24,f24,f31,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f31.f64 - ctx.f16.f64));
	// lfs f16,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f23,f23,f1,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f16.f64));
	// fadds f16,f19,f20
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// lfs f19,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f18,f21
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// fadds f18,f19,f17
	ctx.f18.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f18,220(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// fmuls f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// lfs f17,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f17,f3,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 - ctx.f18.f64));
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f3,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 + ctx.f14.f64));
	// fadds f14,f22,f25
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fadds f22,f23,f24
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfs f23,52(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f16,f15
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f15,316(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfsx f15,r11,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r8,120
	ctx.r11.s64 = ctx.r8.s64 * 120;
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f15,r10,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f15,f23,f24
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// mulli r10,r8,200
	ctx.r10.s64 = ctx.r8.s64 * 200;
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfsx f14,r31,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// mulli r31,r8,56
	ctx.r31.s64 = ctx.r8.s64 * 56;
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfsx f22,r30,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f22,f25,f16
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfsx f22,r29,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfsx f25,r28,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfs f25,52(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// lfs f22,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f3
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// stfs f25,220(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f14,f22,f2
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// lfs f25,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f25.f64 = double(temp.f32);
	// fadds f22,f19,f27
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f27.f64));
	// stfs f22,316(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fadds f22,f18,f26
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// stfs f22,368(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fadds f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfsx f15,r27,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// stfs f22,360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fmuls f15,f25,f2
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f25,f25,f3
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// stfs f25,268(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fadds f25,f17,f22
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f21,f20
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f21,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f26,f18,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 - ctx.f26.f64));
	// fsubs f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// lfs f19,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f19.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// lfs f18,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f19.f64 = double(temp.f32);
	// mulli r30,r9,56
	ctx.r30.s64 = ctx.r9.s64 * 56;
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f17,f17,f3,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 - ctx.f15.f64));
	// fmadds f18,f18,f2,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64 + ctx.f16.f64));
	// stfs f17,408(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f16,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f16.f64 = double(temp.f32);
	// mulli r29,r9,200
	ctx.r29.s64 = ctx.r9.s64 * 200;
	// lfs f17,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f16,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f3,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f14.f64));
	// stfsx f24,r11,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f14.f64 = double(temp.f32);
	// lfs f24,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f15,f15,f2,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 + ctx.f14.f64));
	// lfs f23,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r9,72
	ctx.r11.s64 = ctx.r9.s64 * 72;
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,216(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f23,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,172(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f23,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,240(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f23,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f23.f64 = double(temp.f32);
	// mulli r28,r9,184
	ctx.r28.s64 = ctx.r9.s64 * 184;
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfsx f14,r10,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfsx f23,r31,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f23.f64 = double(temp.f32);
	// fadds f14,f25,f23
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// stfsx f14,r30,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// mulli r27,r8,184
	ctx.r27.s64 = ctx.r8.s64 * 184;
	// stfsx f25,r29,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f25,f26,f22
	ctx.f25.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// stfsx f25,r11,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfsx f26,r28,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f26,f27,f21
	ctx.f26.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// fadds f25,f19,f20
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfsx f26,r27,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f26,f20,f19
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fsubs f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// mulli r26,r8,72
	ctx.r26.s64 = ctx.r8.s64 * 72;
	// stfsx f27,r26,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// lfs f27,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f23,f18,f27
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// fadds f22,f27,f18
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// lfs f27,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f27.f64 = double(temp.f32);
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f21,f27,f17
	ctx.f21.f64 = double(float(ctx.f27.f64 - ctx.f17.f64));
	// fadds f20,f17,f27
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f27.f64));
	// fmuls f15,f24,f29
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f29.f64));
	// lfs f27,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f27,f29
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f29.f64));
	// lfs f27,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f27.f64 = double(temp.f32);
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f27
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// fmsubs f24,f24,f30,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f30.f64 - ctx.f17.f64));
	// lfs f17,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f28,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 + ctx.f16.f64));
	// lfs f14,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r8,220
	ctx.r11.s64 = ctx.r8.s64 * 220;
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,268(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f14,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r8,36
	ctx.r10.s64 = ctx.r8.s64 * 36;
	// lfs f16,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,52(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f16,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f27
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f16,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f30,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64 + ctx.f15.f64));
	// fadds f15,f23,f26
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f15,216(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f15,f19,f21
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// fadds f19,f20,f22
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f19,368(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// lfs f20,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f22,360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fadds f23,f18,f25
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// mulli r31,r9,36
	ctx.r31.s64 = ctx.r9.s64 * 36;
	// fmsubs f19,f19,f28,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 - ctx.f14.f64));
	// stfs f19,172(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// mulli r30,r9,220
	ctx.r30.s64 = ctx.r9.s64 * 220;
	// mulli r29,r9,92
	ctx.r29.s64 = ctx.r9.s64 * 92;
	// mulli r28,r9,164
	ctx.r28.s64 = ctx.r9.s64 * 164;
	// mulli r27,r8,164
	ctx.r27.s64 = ctx.r8.s64 * 164;
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f22,f19,f20
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f22,240(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f14,148(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// mulli r26,r8,92
	ctx.r26.s64 = ctx.r8.s64 * 92;
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f22,340(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// stfs f20,268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// mulli r25,r8,228
	ctx.r25.s64 = ctx.r8.s64 * 228;
	// fmuls f14,f14,f29
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f29.f64));
	// fmuls f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// mulli r24,r8,28
	ctx.r24.s64 = ctx.r8.s64 * 28;
	// mulli r23,r9,28
	ctx.r23.s64 = ctx.r9.s64 * 28;
	// mulli r22,r9,228
	ctx.r22.s64 = ctx.r9.s64 * 228;
	// mulli r21,r9,100
	ctx.r21.s64 = ctx.r9.s64 * 100;
	// lfs f19,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f29
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f29.f64));
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// stfs f27,148(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmadds f27,f22,f30,f19
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 + ctx.f19.f64));
	// lfs f22,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f30,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 - ctx.f14.f64));
	// lfs f19,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f19,f28,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 + ctx.f20.f64));
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f19,f28,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 - ctx.f14.f64));
	// fadds f14,f27,f24
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// fadds f24,f22,f16
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f20,f16
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// lfs f16,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfsx f16,r11,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f16.f64 = double(temp.f32);
	// mulli r11,r9,156
	ctx.r11.s64 = ctx.r9.s64 * 156;
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfsx f16,r10,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f16,f24,f15
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfsx f16,r31,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// stfsx f24,r30,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f24,f27,f21
	ctx.f24.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// stfsx f24,r29,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// stfsx f27,r28,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f26,f22
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfsx f27,r27,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f22,f26
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfsx f27,r26,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// lfs f27,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fsubs f26,f23,f27
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// stfsx f26,r25,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// stfsx f27,r24,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f19,f17
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// lfs f26,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f23.f64 = double(temp.f32);
	// mulli r10,r8,156
	ctx.r10.s64 = ctx.r8.s64 * 156;
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f24,f27,f26
	ctx.f24.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// stfsx f24,r23,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// stfsx f27,r22,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f27.f64 = double(temp.f32);
	// fadds f26,f20,f27
	ctx.f26.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// stfsx f26,r21,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f20,f27
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// lfs f26,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// lfs f24,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// lfs f24,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f22,r11,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r8,100
	ctx.r11.s64 = ctx.r8.s64 * 100;
	// lfs f23,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f22,f5
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// lfs f22,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f16,f5
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f5.f64));
	// stfs f21,208(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmuls f14,f22,f5
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// lfs f20,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f22,f4
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// stfs f22,260(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fsubs f22,f17,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f19,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// lfs f19,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// lfs f17,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f16,f4,f15
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 + ctx.f15.f64));
	// lfs f16,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,148(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f16,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f18,f4,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 - ctx.f14.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f16,f4,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 - ctx.f15.f64));
	// lfs f15,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f5,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfs f14,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f27
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f27.f64));
	// stfs f14,208(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f14,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f27
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f27.f64));
	// lfs f27,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// stfs f27,384(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f27,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// stfs f27,440(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// lfs f27,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f26,f24,f27
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfs f26,396(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// fadds f24,f27,f24
	ctx.f24.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// lfs f27,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f26,f27,f23
	ctx.f26.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfs f26,164(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// fsubs f27,f25,f22
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfsx f27,r10,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f22,f25
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfsx f27,r11,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f20,f21
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f27,52(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f27,f19,f18
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f27,172(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f27,f18,f19
	ctx.f27.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f27,340(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f27,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f22,f21,f20
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fsubs f25,f27,f17
	ctx.f25.f64 = double(float(ctx.f27.f64 - ctx.f17.f64));
	// stfs f25,148(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f27,f17,f27
	ctx.f27.f64 = double(float(ctx.f17.f64 + ctx.f27.f64));
	// stfs f27,216(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fsubs f27,f16,f15
	ctx.f27.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f27,260(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fadds f27,f15,f16
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f27,220(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f27,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f27.f64 = double(temp.f32);
	// mulli r11,r8,212
	ctx.r11.s64 = ctx.r8.s64 * 212;
	// lfs f25,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f25.f64 = double(temp.f32);
	// mulli r10,r8,44
	ctx.r10.s64 = ctx.r8.s64 * 44;
	// fmuls f20,f14,f25
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// fmuls f15,f23,f25
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// lfs f21,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f21,f27
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// lfs f21,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f21,f27
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// lfs f17,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// lfs f16,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f27
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// fmuls f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f26,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f26.f64 = double(temp.f32);
	// stfs f27,296(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fmr f27,f26
	ctx.f27.f64 = ctx.f26.f64;
	// fmsubs f26,f21,f27,f19
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f27.f64 - ctx.f19.f64));
	// stfs f26,240(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f26,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f19,f14,f26,f17
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 - ctx.f17.f64));
	// fmadds f21,f21,f26,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 + ctx.f20.f64));
	// lfs f20,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f27,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f27.f64 + ctx.f18.f64));
	// lfs f18,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f24,f25
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f25,f24,f26,f15
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 - ctx.f15.f64));
	// lfs f24,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f18,f18,f27,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f15,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f23,f26,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f17.f64));
	// fadds f17,f14,f15
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f16,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f27,f24,f27,f16
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 - ctx.f16.f64));
	// lfs f24,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f24.f64 = double(temp.f32);
	// stfs f15,296(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// lfs f23,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// fadds f16,f27,f20
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f20.f64 = double(temp.f32);
	// mulli r31,r9,44
	ctx.r31.s64 = ctx.r9.s64 * 44;
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f20,268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f20,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f20.f64 = double(temp.f32);
	// mulli r30,r9,212
	ctx.r30.s64 = ctx.r9.s64 * 212;
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f15,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f25,f21
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f14,208(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// stfs f18,164(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// stfs f20,368(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfs f14,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfs f21,148(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f18,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f18.f64 = double(temp.f32);
	// mulli r29,r9,84
	ctx.r29.s64 = ctx.r9.s64 * 84;
	// fmuls f18,f18,f31
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// lfs f15,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f1
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// lfs f14,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// lfs f14,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f14.f64 = double(temp.f32);
	// mulli r28,r9,172
	ctx.r28.s64 = ctx.r9.s64 * 172;
	// fmadds f18,f14,f1,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f1.f64 + ctx.f18.f64));
	// lfs f14,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f31,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f31.f64 - ctx.f15.f64));
	// stfs f15,340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f14,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,380(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// lfs f14,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f14.f64 = double(temp.f32);
	// mulli r27,r8,172
	ctx.r27.s64 = ctx.r8.s64 * 172;
	// lfs f15,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f26,f19
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// fsubs f19,f24,f23
	ctx.f19.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfsx f19,r11,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfsx f24,r10,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f24,f16,f17
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfsx f24,r31,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f16,f17
	ctx.f24.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfsx f24,r30,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f24,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f24.f64 = double(temp.f32);
	// mulli r11,r8,84
	ctx.r11.s64 = ctx.r8.s64 * 84;
	// fsubs f16,f20,f25
	ctx.f16.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// fadds f20,f25,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// mulli r10,r8,236
	ctx.r10.s64 = ctx.r8.s64 * 236;
	// lfs f23,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f23.f64 = double(temp.f32);
	// fadds f19,f23,f24
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfsx f19,r29,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// stfsx f24,r28,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f22,f27
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f27.f64));
	// stfsx f24,r27,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f22.f64));
	// stfsx f27,r11,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f24,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f24.f64 = double(temp.f32);
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// lfs f27,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f25.f64 = double(temp.f32);
	// fadds f19,f24,f27
	ctx.f19.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// fsubs f17,f24,f27
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// lfs f22,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// fadds f27,f21,f25
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// fsubs f24,f25,f21
	ctx.f24.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// mulli r31,r9,20
	ctx.r31.s64 = ctx.r9.s64 * 20;
	// fsubs f21,f22,f14
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfsx f21,r10,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// mulli r30,r9,236
	ctx.r30.s64 = ctx.r9.s64 * 236;
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f22,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f19,r31,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f21,f26,f22
	ctx.f21.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f19.f64 = double(temp.f32);
	// fadds f25,f23,f18
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f14,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f17,r30,r6
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// mulli r29,r9,108
	ctx.r29.s64 = ctx.r9.s64 * 108;
	// fadds f18,f25,f27
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfsx f21,r29,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r9,148
	ctx.r11.s64 = ctx.r9.s64 * 148;
	// stfsx f26,r11,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f26.f64 = double(temp.f32);
	// mulli r11,r8,148
	ctx.r11.s64 = ctx.r8.s64 * 148;
	// fadds f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f16,r11,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r8,108
	ctx.r11.s64 = ctx.r8.s64 * 108;
	// stfsx f20,r11,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f20,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f19,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f19,f1
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f19,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f1
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// stfs f27,400(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// lfs f27,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f27.f64 = double(temp.f32);
	// mulli r11,r8,252
	ctx.r11.s64 = ctx.r8.s64 * 252;
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfs f19,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmsubs f17,f14,f31,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f31.f64 - ctx.f17.f64));
	// lfs f14,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f14.f64 = double(temp.f32);
	// stfs f27,288(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fmadds f16,f14,f31,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f31.f64 + ctx.f16.f64));
	// lfs f27,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f27.f64 = double(temp.f32);
	// rlwinm r31,r9,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f25,f22,f27
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// lfs f14,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f14.f64 = double(temp.f32);
	// lfs f27,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f14,f21,f27
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// lfs f27,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// stfs f27,388(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f27,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f27.f64 = double(temp.f32);
	// mulli r30,r9,252
	ctx.r30.s64 = ctx.r9.s64 * 252;
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// stfs f27,412(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f27,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 - ctx.f27.f64));
	// stfs f27,420(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f27,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// stfs f27,428(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// lfs f27,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// stfs f27,436(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// mulli r29,r9,124
	ctx.r29.s64 = ctx.r9.s64 * 124;
	// fadds f27,f16,f17
	ctx.f27.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// mulli r28,r9,132
	ctx.r28.s64 = ctx.r9.s64 * 132;
	// stfs f27,164(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fsubs f27,f16,f17
	ctx.f27.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfs f26,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f25,f26
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// stfs f27,352(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f27,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f14,f26
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f26.f64));
	// fmuls f21,f14,f27
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f27.f64));
	// lfs f14,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f25,f27
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f25,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f25
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// fmsubs f22,f14,f27,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 - ctx.f22.f64));
	// stfs f22,208(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f22,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f25
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// lfs f22,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f26,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64 + ctx.f21.f64));
	// lfs f21,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f21,f26,f20
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 + ctx.f20.f64));
	// lfs f21,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f25
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// lfs f20,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f20.f64 = double(temp.f32);
	// stfs f21,296(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fmsubs f21,f20,f27,f17
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f27.f64 - ctx.f17.f64));
	// lfs f17,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f17.f64 = double(temp.f32);
	// lfs f27,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f27.f64 = double(temp.f32);
	// fadds f20,f27,f19
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// fsubs f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// stfs f27,260(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f27,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// stfs f27,164(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f25,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f25.f64 = double(temp.f32);
	// fmr f27,f25
	ctx.f27.f64 = ctx.f25.f64;
	// lfs f25,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f25.f64 = double(temp.f32);
	// lfs f19,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f25,f25,f27,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f27.f64 + ctx.f16.f64));
	// fmsubs f19,f19,f27,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 - ctx.f14.f64));
	// lfs f16,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f17,f27,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 - ctx.f16.f64));
	// lfs f16,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f27,f16,f27,f14
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f27.f64 + ctx.f14.f64));
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f22,f14
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// fsubs f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfsx f18,r10,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f18,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,132
	ctx.r11.s64 = ctx.r8.s64 * 132;
	// fadds f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// mulli r10,r8,124
	ctx.r10.s64 = ctx.r8.s64 * 124;
	// fsubs f18,f22,f18
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fadds f22,f21,f26
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// fsubs f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// lfs f21,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f24
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fadds f14,f22,f20
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfsx f14,r31,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfsx f22,r30,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f16,r29,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfsx f18,r28,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f20,44(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f20,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f20,f7
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fmuls f14,f18,f6
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// stfs f21,60(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fmuls f18,f18,f7
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64));
	// stfs f20,432(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fadds f21,f27,f19
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// stfs f18,444(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// stfs f21,164(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f21,f15,f23
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// lfs f19,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f21,296(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fadds f21,f17,f25
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// fsubs f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// lfs f17,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// lfs f19,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f19,f17
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f19.f64 = double(temp.f32);
	// mulli r31,r8,196
	ctx.r31.s64 = ctx.r8.s64 * 196;
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f17,f6,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 + ctx.f16.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f7,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 - ctx.f14.f64));
	// stfs f17,208(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f16,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f16.f64 = double(temp.f32);
	// mulli r30,r8,60
	ctx.r30.s64 = ctx.r8.s64 * 60;
	// lfs f17,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,260(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f16,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// mulli r29,r9,60
	ctx.r29.s64 = ctx.r9.s64 * 60;
	// mulli r28,r9,196
	ctx.r28.s64 = ctx.r9.s64 * 196;
	// mulli r27,r9,68
	ctx.r27.s64 = ctx.r9.s64 * 68;
	// mulli r26,r9,188
	ctx.r26.s64 = ctx.r9.s64 * 188;
	// lfs f14,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f7,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 - ctx.f14.f64));
	// lfs f14,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f6,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f6.f64 + ctx.f14.f64));
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,292(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f22,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f22.f64 = double(temp.f32);
	// mulli r25,r8,188
	ctx.r25.s64 = ctx.r8.s64 * 188;
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,144(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f14,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfsx f26,r10,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f26,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f26.f64 = double(temp.f32);
	// mulli r11,r8,68
	ctx.r11.s64 = ctx.r8.s64 * 68;
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfsx f14,r31,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfsx f26,r30,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f26,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f26.f64 = double(temp.f32);
	// fadds f14,f21,f26
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfsx f14,r29,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// stfsx f26,r28,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f26,f27,f23
	ctx.f26.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// stfsx f26,r27,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfsx f27,r26,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f24,f25
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// stfsx f27,r25,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f26,f25,f24
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f27,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f27.f64 = double(temp.f32);
	// fadds f23,f19,f20
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfsx f26,r11,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f20,f27,f18
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// lfs f26,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f19,f27,f18
	ctx.f19.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// lfs f27,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f27.f64 = double(temp.f32);
	// fadds f18,f17,f27
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f27.f64));
	// lfs f24,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f17,f17,f27
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f27.f64));
	// mulli r11,r8,244
	ctx.r11.s64 = ctx.r8.s64 * 244;
	// fsubs f27,f15,f16
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f27,336(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f27,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f27.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fmuls f25,f27,f26
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f22,f24
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// lfs f27,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f27.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fmsubs f25,f15,f27,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f27.f64 - ctx.f25.f64));
	// stfs f25,472(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// lfs f25,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// mulli r31,r9,12
	ctx.r31.s64 = ctx.r9.s64 * 12;
	// fmadds f16,f15,f25,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f25.f64 + ctx.f16.f64));
	// stfs f16,364(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f22,f25
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// fmuls f16,f16,f26
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// mulli r30,r9,244
	ctx.r30.s64 = ctx.r9.s64 * 244;
	// fadds f22,f20,f23
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f22,f14,f18
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// mulli r29,r9,116
	ctx.r29.s64 = ctx.r9.s64 * 116;
	// fmadds f16,f14,f27,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f16.f64));
	// fadds f14,f17,f19
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f14,444(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// fmsubs f15,f14,f24,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f24.f64 - ctx.f15.f64));
	// stfs f15,432(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// lfs f15,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,164(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// mulli r28,r9,140
	ctx.r28.s64 = ctx.r9.s64 * 140;
	// lfs f17,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f17.f64 = double(temp.f32);
	// mulli r27,r8,140
	ctx.r27.s64 = ctx.r8.s64 * 140;
	// lfs f20,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f21
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// mulli r26,r8,116
	ctx.r26.s64 = ctx.r8.s64 * 116;
	// mulli r25,r8,204
	ctx.r25.s64 = ctx.r8.s64 * 204;
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// mulli r24,r8,52
	ctx.r24.s64 = ctx.r8.s64 * 52;
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// mulli r23,r9,52
	ctx.r23.s64 = ctx.r9.s64 * 52;
	// fmuls f14,f19,f26
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// mulli r22,r9,204
	ctx.r22.s64 = ctx.r9.s64 * 204;
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// fmuls f26,f17,f24
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// fmuls f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// stfs f26,476(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// fmadds f26,f19,f27,f15
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f15.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f27,f19,f27,f14
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 - ctx.f14.f64));
	// lfs f19,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f24,f19,f24,f17
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f24.f64 - ctx.f17.f64));
	// lfs f17,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f25,f19,f25,f15
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f25.f64 + ctx.f15.f64));
	// lfs f15,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f26,f17
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// fadds f17,f27,f16
	ctx.f17.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// fsubs f27,f16,f27
	ctx.f27.f64 = double(float(ctx.f16.f64 - ctx.f27.f64));
	// fadds f16,f25,f15
	ctx.f16.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// fsubs f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfsx f19,r10,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f19,f17,f22
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfsx f19,r31,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f22,r30,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f15,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f26,f18
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// stfsx f22,r29,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f18.f64));
	// fadds f15,f24,f15
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfsx f26,r28,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f26,f23,f27
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// stfsx f26,r27,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// stfsx f27,r26,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f27,f20,f16
	ctx.f27.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfsx f27,r25,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f16,f20
	ctx.f27.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfsx f27,r24,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// lfs f27,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f27.f64 = double(temp.f32);
	// mulli r11,r9,76
	ctx.r11.s64 = ctx.r9.s64 * 76;
	// mulli r10,r9,180
	ctx.r10.s64 = ctx.r9.s64 * 180;
	// lfs f23,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f23.f64 = double(temp.f32);
	// fadds f22,f25,f23
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f26,f15,f27
	ctx.f26.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfsx f26,r23,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfsx f27,r22,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfsx f22,r11,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,584(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	// stfsx f25,r10,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// mulli r10,r8,180
	ctx.r10.s64 = ctx.r8.s64 * 180;
	// fsubs f25,f27,f26
	ctx.f25.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfsx f25,r10,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// mulli r31,r8,76
	ctx.r31.s64 = ctx.r8.s64 * 76;
	// stfsx f27,r31,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// lwz r11,592(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	// add r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 + ctx.r6.u64;
	// add r5,r11,r5
	ctx.r5.u64 = ctx.r11.u64 + ctx.r5.u64;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lwz r11,3532(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3532);
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d58f3c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D58F3C;
loc_82D5BF38:
	// addi r1,r1,896
	ctx.r1.s64 = ctx.r1.s64 + 896;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D5BF44;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5BF48"))) PPC_WEAK_FUNC(sub_82D5BF48);
PPC_FUNC_IMPL(__imp__sub_82D5BF48) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-416
	ctx.r5.s64 = ctx.r11.s64 + -416;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-29312
	ctx.r4.s64 = ctx.r11.s64 + -29312;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5BF60"))) PPC_WEAK_FUNC(sub_82D5BF60);
PPC_FUNC_IMPL(__imp__sub_82D5BF60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e38
	ctx.lr = 0x82D5BF68;
	__savegprlr_16(ctx, base);
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82e28ee0
	ctx.lr = 0x82D5BF70;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5d22c
	if (!ctx.cr6.gt) goto loc_82D5D22C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// rlwinm r18,r11,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// rlwinm r17,r11,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f31,-5428(r19)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -5428);
	ctx.f31.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f1,-5432(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -5432);
	ctx.f1.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f2,-5420(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -5420);
	ctx.f2.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f3,-5424(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -5424);
	ctx.f3.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f4,-5444(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -5444);
	ctx.f4.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f5,-5448(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -5448);
	ctx.f5.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f6,-5436(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -5436);
	ctx.f6.f64 = double(temp.f32);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f7,-5440(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -5440);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f8,-8012(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8012);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f9,-8008(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8008);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8000(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8000);
	ctx.f10.f64 = double(temp.f32);
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// lfs f11,-8004(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8004);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D5C008:
	// mulli r26,r7,124
	ctx.r26.s64 = ctx.r7.s64 * 124;
	// lfs f30,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// mulli r25,r7,60
	ctx.r25.s64 = ctx.r7.s64 * 60;
	// lfs f29,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-532(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfsx f14,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-544(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// mulli r11,r7,112
	ctx.r11.s64 = ctx.r7.s64 * 112;
	// lfsx f28,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// mulli r24,r7,28
	ctx.r24.s64 = ctx.r7.s64 * 28;
	// lfsx f14,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-536(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// mulli r11,r7,92
	ctx.r11.s64 = ctx.r7.s64 * 92;
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-508(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// mulli r10,r7,48
	ctx.r10.s64 = ctx.r7.s64 * 48;
	// lfsx f26,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f14,f28,f26
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfs f14,-500(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// rlwinm r31,r7,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f25,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r30,r7,80
	ctx.r30.s64 = ctx.r7.s64 * 80;
	// fsubs f14,f27,f25
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfsx f24,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// rlwinm r29,r7,6,0,25
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// lfsx f21,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// rlwinm r28,r7,5,0,26
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// mulli r27,r7,96
	ctx.r27.s64 = ctx.r7.s64 * 96;
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfsx f20,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f20,f30
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// lfsx f18,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// lfsx f17,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f20,-540(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fadds f20,f17,f29
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// lfsx f16,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfsx f15,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f17.f64));
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// mulli r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 * 12;
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f16,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,-516(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f15,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-484(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfsx f26,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// mulli r31,r7,76
	ctx.r31.s64 = ctx.r7.s64 * 76;
	// lfs f15,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,-448(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f15,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-536(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f25,f16
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// fsubs f16,f16,f25
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// fsubs f25,f14,f23
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfs f25,-544(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fadds f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// fadds f23,f22,f27
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// stfs f23,-508(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fadds f25,f24,f28
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// fsubs f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// fmuls f23,f15,f0
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f24,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f16,f0
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f14,f0
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// mulli r30,r7,108
	ctx.r30.s64 = ctx.r7.s64 * 108;
	// fadds f14,f18,f20
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f14,-544(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f14,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f14.f64 = double(temp.f32);
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// mulli r29,r7,44
	ctx.r29.s64 = ctx.r7.s64 * 44;
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// fadds f14,f23,f30
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// fsubs f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// stfs f30,-384(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f30,f22,f19
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f30,-436(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fadds f30,f22,f19
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f30,-380(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fsubs f30,f16,f17
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f30,-352(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fadds f30,f16,f17
	ctx.f30.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f30,-408(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f30,f15,f29
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f29.f64));
	// stfs f30,-344(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fsubs f30,f29,f15
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// lfsx f15,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f30,-376(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// mulli r10,r7,68
	ctx.r10.s64 = ctx.r7.s64 * 68;
	// lfs f30,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f30.f64 = double(temp.f32);
	// fadds f18,f25,f24
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f16,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// lfsx f17,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f19,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r28,r7,52
	ctx.r28.s64 = ctx.r7.s64 * 52;
	// mulli r27,r7,36
	ctx.r27.s64 = ctx.r7.s64 * 36;
	// lfs f29,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f29.f64 = double(temp.f32);
	// stfs f15,-544(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fadds f23,f30,f29
	ctx.f23.f64 = double(float(ctx.f30.f64 + ctx.f29.f64));
	// lfs f15,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f30.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f30,-312(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfsx f30,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f15,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f23,-296(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// stfs f15,-508(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fsubs f15,f26,f30
	ctx.f15.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// lfsx f29,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// lfsx f23,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r26,r7,100
	ctx.r26.s64 = ctx.r7.s64 * 100;
	// fadds f26,f23,f29
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f16,-300(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// stfs f29,-392(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fsubs f23,f19,f17
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfsx f16,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f29,f17,f19
	ctx.f29.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f23,-444(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// stfs f15,-536(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfsx f15,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r31,r7,116
	ctx.r31.s64 = ctx.r7.s64 * 116;
	// lfsx f17,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r30,r7,20
	ctx.r30.s64 = ctx.r7.s64 * 20;
	// lfs f19,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f19.f64 = double(temp.f32);
	// fadds f23,f16,f19
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-540(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfsx f16,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-500(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfsx f16,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfsx f16,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-404(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfsx f16,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-484(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfsx f16,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-400(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfsx f16,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-396(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f16,f26,f29
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fadds f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// lfs f26,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f15.f64));
	// stfs f26,-532(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// stfs f29,-512(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f16,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f29,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-504(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f29,f16,f17
	ctx.f29.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f26,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f26.f64 = double(temp.f32);
	// stfs f17,-540(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fsubs f26,f15,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// lfs f16,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,-388(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-488(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f17,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,-520(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-480(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f17,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,-452(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f15,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fsubs f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f15,-524(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f16,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f29,f16
	ctx.f16.f64 = double(float(ctx.f29.f64 + ctx.f16.f64));
	// fsubs f15,f29,f15
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// stfs f17,-492(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fadds f29,f19,f26
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// stfs f29,-544(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fsubs f19,f26,f19
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f19.f64));
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fadds f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// stfs f26,-536(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f26,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f26.f64 = double(temp.f32);
	// fadds f29,f23,f26
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// lfs f26,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// stfs f30,-420(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fmuls f30,f16,f0
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f26,f15,f0
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f16,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f23,f16,f0
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f15,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,-308(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f15,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,-304(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f22,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f29,f22
	ctx.f15.f64 = double(float(ctx.f29.f64 + ctx.f22.f64));
	// stfs f15,-424(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fsubs f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// lfs f22,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f30,f22
	ctx.f15.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// stfs f15,-368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fsubs f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// stfs f30,-400(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f30,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f30.f64 = double(temp.f32);
	// mulli r22,r7,72
	ctx.r22.s64 = ctx.r7.s64 * 72;
	// fsubs f22,f26,f30
	ctx.f22.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// mulli r21,r7,24
	ctx.r21.s64 = ctx.r7.s64 * 24;
	// fadds f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// stfs f30,-396(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f30,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f30.f64 = double(temp.f32);
	// fadds f26,f23,f30
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// stfs f26,-508(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fsubs f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// stfs f30,-404(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f30,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f26,f19,f30
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// stfs f26,-500(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fadds f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// stfs f30,-356(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f30,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f13,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f30,-316(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f30,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f16,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f30,f30,f13,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f16,-524(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f23,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f23.f64 = double(temp.f32);
	// mulli r20,r7,88
	ctx.r20.s64 = ctx.r7.s64 * 88;
	// lfs f26,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f16,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f30,-392(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fsubs f30,f26,f23
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f16,-544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f22,-484(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfsx f16,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// mulli r29,r7,120
	ctx.r29.s64 = ctx.r7.s64 * 120;
	// fmuls f15,f30,f12
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfsx f23,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r19,r7,40
	ctx.r19.s64 = ctx.r7.s64 * 40;
	// stfs f22,-536(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfsx f16,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-512(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// mulli r29,r7,104
	ctx.r29.s64 = ctx.r7.s64 * 104;
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-540(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// mulli r25,r7,56
	ctx.r25.s64 = ctx.r7.s64 * 56;
	// lfsx f22,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f19,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f16,f22,f23
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// mulli r24,r7,84
	ctx.r24.s64 = ctx.r7.s64 * 84;
	// stfs f19,-532(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f22,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,-448(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfsx f19,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f23,f19,f22
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// rlwinm r23,r7,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// lfs f19,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f17,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,-444(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f19,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfs f19,-524(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f19,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f19
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f17,-544(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,-516(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f19,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f19
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f17,-512(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,-528(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f19,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// stfs f19,-540(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f19,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f19,f22
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfs f19,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f19.f64 = double(temp.f32);
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// stfs f23,-520(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f23,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f19,f17,f0
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f19,-452(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,-480(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f22,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,-544(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmr f23,f22
	ctx.f23.f64 = ctx.f22.f64;
	// fsubs f22,f16,f23
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// stfs f22,-496(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f22,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f23.f64));
	// fmuls f19,f22,f12
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f23,-324(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmuls f17,f22,f13
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f22,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f22,f13,f19
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f19.f64));
	// lfs f19,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f22,f12,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f17.f64));
	// stfs f22,-460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f22,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f17,-516(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f22,-320(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f19,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f12
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f13,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f17.f64));
	// fmadds f30,f30,f13,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f30,-388(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f30,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f30.f64 = double(temp.f32);
	// lfs f17,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f19,f13,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f17.f64));
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f17,-504(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// stfs f26,-476(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f26,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f17,f26,f30
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// stfs f17,-336(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// stfs f30,-512(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f26,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f30.f64 = double(temp.f32);
	// fadds f17,f26,f30
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// stfs f17,-544(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// stfs f30,-332(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f30,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f30,f13,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f30,-444(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f30,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f30.f64 = double(temp.f32);
	// lfs f26,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f26.f64 = double(temp.f32);
	// fadds f17,f30,f26
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// lfs f16,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f16.f64 = double(temp.f32);
	// lfs f26,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// stfs f26,-480(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fmuls f26,f17,f0
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f26,-452(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// stfs f30,-448(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fadds f30,f23,f22
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfs f30,-328(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f30,f23,f22
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f30,-340(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f15,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-492(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfsx f15,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfsx f15,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-496(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f22,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f22.f64 = double(temp.f32);
	// lfs f30,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f15,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f30,f19
	ctx.f26.f64 = double(float(ctx.f30.f64 - ctx.f19.f64));
	// stfs f15,-532(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fadds f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// lfs f23,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f15,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// stfs f26,-348(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fsubs f26,f23,f22
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfsx f15,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f15,-432(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// stfs f26,-540(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// stfs f30,-516(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfsx f26,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f30,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f15,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f23,-524(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// stfs f15,-472(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fsubs f15,f30,f26
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// lfsx f22,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// lfsx f23,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f26,f23,f22
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfsx f19,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfsx f17,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f23,-520(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fsubs f23,f19,f17
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfsx f16,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f23,-528(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fadds f23,f17,f19
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f15,-464(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f22,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f19,f16,f22
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f19,-428(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f22,-460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f22,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f17,-536(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f22,-492(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f19,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f22,-364(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,-496(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f19,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f16,-472(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,-488(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// fmuls f19,f15,f12
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f26,f13
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,-440(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fsubs f15,f23,f30
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// stfs f15,-412(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fmuls f15,f26,f12
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f16,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f16.f64 = double(temp.f32);
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// lfs f23,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f26,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// stfs f26,-432(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fmsubs f26,f23,f12,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 - ctx.f17.f64));
	// lfs f23,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f23.f64 = double(temp.f32);
	// stfs f22,-464(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmadds f23,f23,f13,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f23,-532(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// rlwinm r11,r8,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f17,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r10,r9,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f23,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f23.f64 = double(temp.f32);
	// rlwinm r31,r8,7,0,24
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 7) & 0xFFFFFF80;
	// fadds f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f22,f17,f13,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f19.f64));
	// lfs f19,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f19,-520(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f17,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f17.f64 = double(temp.f32);
	// mulli r30,r8,96
	ctx.r30.s64 = ctx.r8.s64 * 96;
	// lfs f19,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,-468(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,-456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f19,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f19,f12
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f19,f13,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f17,-464(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f17,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f16,f17,f13,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f16,-428(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f16,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmsubs f19,f17,f12,f16
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f16.f64));
	// stfs f19,-416(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f17,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f19.f64 = double(temp.f32);
	// fadds f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f17,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f26,f17
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// stfs f17,-360(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f17,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f17.f64 = double(temp.f32);
	// fadds f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f26,-440(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fadds f26,f23,f30
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// stfs f26,-412(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fsubs f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// lfs f23,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f23.f64 = double(temp.f32);
	// fadds f17,f23,f22
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfs f30,-472(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f23,-372(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// stfs f17,-536(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fmuls f23,f16,f0
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f23,-524(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f23,-528(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f23,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f22.f64 = double(temp.f32);
	// fadds f19,f22,f23
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f19,-532(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,-540(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fadds f23,f19,f22
	ctx.f23.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// lfs f19,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfs f26,-464(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f26,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f26.f64 = double(temp.f32);
	// stfs f23,-468(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// stfs f22,-456(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f26,-428(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f26,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f26.f64 = double(temp.f32);
	// fadds f23,f26,f29
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fmuls f19,f30,f12
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfs f30,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f17,f30,f12
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfs f30,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f30,f12
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// mulli r29,r9,96
	ctx.r29.s64 = ctx.r9.s64 * 96;
	// fsubs f30,f29,f26
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// stfs f30,-476(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f29,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fadds f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// stfs f29,-432(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f26,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f26.f64 = double(temp.f32);
	// rlwinm r28,r8,5,0,26
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f29,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// stfs f29,-520(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f29,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f29.f64 = double(temp.f32);
	// lfs f26,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f26.f64 = double(temp.f32);
	// rlwinm r27,r9,5,0,26
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// stfs f29,-412(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f29,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f29.f64 = double(temp.f32);
	// mulli r26,r8,112
	ctx.r26.s64 = ctx.r8.s64 * 112;
	// lfs f26,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f26.f64 = double(temp.f32);
	// fadds f30,f29,f26
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// fsubs f29,f24,f25
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// lfs f24,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f26,f23,f0
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f23,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f24,f24,f13,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f22.f64));
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f13,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f16.f64));
	// lfs f25,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f23,f23,f13,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f17.f64));
	// lfs f16,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f25,f25,f13,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f19.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f16.f64 = double(temp.f32);
	// mulli r25,r9,112
	ctx.r25.s64 = ctx.r9.s64 * 112;
	// lfs f19,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f19.f64 = double(temp.f32);
	// stfs f17,-476(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f17,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-468(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f16,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-456(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f16,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,-472(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f18,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f13,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f18,-504(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f18,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f16,f18
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f16,f16,f18
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,-424(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f16,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,-480(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f16,r11,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f16,f30,f15
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// fsubs f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// stfsx f30,r10,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f26,f29
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// fadds f26,f24,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// lfs f22,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f22,f19
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f15,-492(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fsubs f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// stfs f22,-364(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// fadds f19,f17,f22
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f15,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// lfs f22,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f15,-460(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f15,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f22,-496(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f19,f0
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f22,-504(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fmuls f22,f17,f0
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f22,-488(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f22,f18
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f19,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f18,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfsx f18,r31,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f18,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f18.f64 = double(temp.f32);
	// mulli r31,r9,48
	ctx.r31.s64 = ctx.r9.s64 * 48;
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f18,0(r5)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfsx f17,r30,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f15,r29,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// stfsx f22,r28,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f22,f30,f26
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// stfsx f19,r27,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// stfsx f22,r26,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// lfs f17,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f17.f64 = double(temp.f32);
	// mulli r30,r8,48
	ctx.r30.s64 = ctx.r8.s64 * 48;
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f27
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// lfs f22,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f24,f22
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfsx f16,r25,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// lfs f16,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f21,f16
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f16,-476(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f30,r11,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// lfs f30,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f30.f64 = double(temp.f32);
	// lfs f18,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// lfs f17,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,-416(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// stfs f15,-468(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfs f15,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfs f21,-456(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f21,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// fadds f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// stfsx f30,r10,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f30,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f30.f64 = double(temp.f32);
	// mulli r11,r9,80
	ctx.r11.s64 = ctx.r9.s64 * 80;
	// fadds f26,f30,f25
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// stfsx f26,r31,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f26,f23,f29
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfsx f26,r30,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f26,f25,f30
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// lfs f30,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f25,f29,f23
	ctx.f25.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// lfs f29,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f29.f64 = double(temp.f32);
	// stfsx f26,r11,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r8,80
	ctx.r11.s64 = ctx.r8.s64 * 80;
	// fadds f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f29.f64));
	// lfs f29,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// lfs f26,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f28,f17,f10
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// fmuls f24,f22,f10
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f23,f17,f11
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fmuls f15,f22,f11
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f25,r11,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f25,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f25.f64 = double(temp.f32);
	// stfs f28,-416(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fadds f28,f25,f26
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// mulli r11,r8,104
	ctx.r11.s64 = ctx.r8.s64 * 104;
	// fmadds f25,f19,f11,f24
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f24.f64));
	// fmsubs f23,f18,f10,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 - ctx.f23.f64));
	// fmsubs f19,f19,f10,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 - ctx.f15.f64));
	// fadds f24,f22,f16
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// lfs f16,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f21,f16
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fsubs f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// fadds f16,f23,f25
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// mulli r31,r9,24
	ctx.r31.s64 = ctx.r9.s64 * 24;
	// mulli r30,r9,104
	ctx.r30.s64 = ctx.r9.s64 * 104;
	// mulli r29,r9,40
	ctx.r29.s64 = ctx.r9.s64 * 40;
	// mulli r28,r9,88
	ctx.r28.s64 = ctx.r9.s64 * 88;
	// mulli r27,r8,88
	ctx.r27.s64 = ctx.r8.s64 * 88;
	// lfs f15,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f18,f18,f11,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f15.f64));
	// mulli r26,r8,40
	ctx.r26.s64 = ctx.r8.s64 * 40;
	// fadds f23,f18,f19
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// fsubs f18,f28,f16
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// stfsx f18,r11,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f28,f16,f28
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f28.f64));
	// stfsx f28,r10,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f28,f25,f22
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// mulli r11,r8,120
	ctx.r11.s64 = ctx.r8.s64 * 120;
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fadds f22,f23,f24
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfsx f22,r31,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// stfsx f24,r30,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f28,r29,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f26,f19
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f19.f64));
	// stfsx f25,r28,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// stfsx f28,r27,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stfsx f26,r26,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r31,r9,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f26,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f26.f64 = double(temp.f32);
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfs f25,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f24,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f25.f64 = double(temp.f32);
	// lfs f28,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f24,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f24.f64 = double(temp.f32);
	// fadds f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f20.f64));
	// lfs f23,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fmuls f18,f20,f10
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// lfs f22,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f20,f11
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f19,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fadds f22,f29,f30
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfs f20,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f19,f11
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// mulli r30,r9,120
	ctx.r30.s64 = ctx.r9.s64 * 120;
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfs f29,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f29.f64 = double(temp.f32);
	// mulli r29,r9,56
	ctx.r29.s64 = ctx.r9.s64 * 56;
	// fmadds f29,f29,f11,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f11.f64 + ctx.f18.f64));
	// lfs f18,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f18,-356(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfs f18,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f10,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 - ctx.f16.f64));
	// stfs f18,-384(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f18,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,-420(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f18,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f16,f18,f20
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f16,-516(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,-332(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f20,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f28,f9
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f9.f64));
	// fmsubs f20,f20,f10,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 - ctx.f15.f64));
	// stfs f20,-512(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmuls f20,f28,f8
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// mulli r28,r9,72
	ctx.r28.s64 = ctx.r9.s64 * 72;
	// fmuls f28,f23,f6
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// stfs f28,-380(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fmuls f18,f19,f10
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fmuls f19,f25,f9
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// fmuls f15,f26,f9
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// mulli r27,r8,72
	ctx.r27.s64 = ctx.r8.s64 * 72;
	// fmadds f20,f27,f9,f20
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 + ctx.f20.f64));
	// stfs f20,-340(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fmuls f20,f24,f6
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmsubs f27,f27,f8,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f8.f64 - ctx.f16.f64));
	// fmsubs f28,f26,f8,f19
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 - ctx.f19.f64));
	// fmadds f26,f25,f8,f15
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 + ctx.f15.f64));
	// mulli r26,r8,56
	ctx.r26.s64 = ctx.r8.s64 * 56;
	// lfs f19,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f25,f24,f7,f19
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 - ctx.f19.f64));
	// fmadds f24,f23,f7,f20
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f20.f64));
	// lfs f20,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f20.f64 = double(temp.f32);
	// fadds f23,f20,f29
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f29.f64));
	// fsubs f29,f20,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f29.f64));
	// lfs f19,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f28,f19
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// fadds f19,f26,f27
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fsubs f26,f17,f20
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfsx f26,r11,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f26,f20,f17
	ctx.f26.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfsx f26,r10,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f26,f28,f30
	ctx.f26.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lfs f20,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// mulli r11,r8,116
	ctx.r11.s64 = ctx.r8.s64 * 116;
	// fadds f28,f19,f22
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfsx f28,r31,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f19,f22
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// stfsx f28,r30,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f26,r29,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f21,f27
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// stfsx f30,r28,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f27,f21
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f28,r27,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// stfsx f30,r26,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f30,f20,f22
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f26,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// lfs f27,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f30,f5
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// lfs f17,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f26.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fadds f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfs f20,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f20,f11,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f18.f64));
	// lfs f21,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f21.f64 = double(temp.f32);
	// mulli r31,r9,12
	ctx.r31.s64 = ctx.r9.s64 * 12;
	// fadds f28,f19,f21
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f18,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// fadds f19,f23,f18
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// fmuls f18,f30,f4
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// fmuls f17,f26,f5
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fmuls f15,f26,f4
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f26,f22,f6
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// stfs f26,-372(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// fmuls f30,f21,f6
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// stfs f30,-408(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// mulli r30,r9,116
	ctx.r30.s64 = ctx.r9.s64 * 116;
	// fmadds f30,f28,f5,f18
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f5.f64 + ctx.f18.f64));
	// fmsubs f28,f28,f4,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f4.f64 - ctx.f16.f64));
	// lfs f16,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f18,f27,f4,f17
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f17.f64));
	// stfs f18,-376(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f18,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f27,f27,f5,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f15.f64));
	// fadds f26,f20,f18
	ctx.f26.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// mulli r29,r9,52
	ctx.r29.s64 = ctx.r9.s64 * 52;
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// mulli r28,r9,76
	ctx.r28.s64 = ctx.r9.s64 * 76;
	// fadds f17,f26,f16
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// fadds f16,f27,f28
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// lfs f27,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// mulli r27,r8,76
	ctx.r27.s64 = ctx.r8.s64 * 76;
	// mulli r26,r8,52
	ctx.r26.s64 = ctx.r8.s64 * 52;
	// mulli r25,r8,108
	ctx.r25.s64 = ctx.r8.s64 * 108;
	// mulli r24,r8,20
	ctx.r24.s64 = ctx.r8.s64 * 20;
	// lfs f18,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f22,f7,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f18.f64));
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f21,f21,f7,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 - ctx.f18.f64));
	// lfs f15,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f15.f64 = double(temp.f32);
	// mulli r23,r9,20
	ctx.r23.s64 = ctx.r9.s64 * 20;
	// fadds f18,f15,f30
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// fsubs f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f30.f64));
	// mulli r22,r9,108
	ctx.r22.s64 = ctx.r9.s64 * 108;
	// fsubs f15,f19,f18
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfsx f15,r11,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfsx f19,r10,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfsx f18,r31,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfsx f18,r30,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f19,f30,f26
	ctx.f19.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfsx f19,r29,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// stfsx f30,r28,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f30,f23,f28
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f28.f64));
	// stfsx f30,r27,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f30,f28,f23
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f23.f64));
	// stfsx f30,r26,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f30,f22,f25
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fsubs f28,f27,f30
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// stfsx f28,r25,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// stfsx f30,r24,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// lfs f30,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f30.f64 = double(temp.f32);
	// fadds f28,f21,f24
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fadds f27,f28,f30
	ctx.f27.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfsx f27,r23,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fsubs f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfsx f30,r22,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// lfs f30,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fmuls f16,f30,f9
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// lfs f27,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f21.f64));
	// lfs f18,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// lfs f23,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r9,44
	ctx.r11.s64 = ctx.r9.s64 * 44;
	// fsubs f27,f18,f23
	ctx.f27.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// lfs f19,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f19.f64 = double(temp.f32);
	// lfs f26,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f26.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f18,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// lfs f30,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f30.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f30,f9
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// lfs f17,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f17.f64 = double(temp.f32);
	// mulli r10,r9,84
	ctx.r10.s64 = ctx.r9.s64 * 84;
	// fmadds f18,f18,f8,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f16.f64));
	// lfs f30,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f30.f64 = double(temp.f32);
	// lfs f16,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f16.f64 = double(temp.f32);
	// fadds f30,f30,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-368(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f16,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-344(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f16,f17,f8,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 - ctx.f15.f64));
	// stfs f16,-484(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// fmuls f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// stfs f24,-352(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// lfs f24,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f24.f64 = double(temp.f32);
	// stfs f22,-336(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fsubs f22,f14,f24
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f22,-408(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f26,f1
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// lfs f15,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f15.f64 = double(temp.f32);
	// mulli r31,r8,84
	ctx.r31.s64 = ctx.r8.s64 * 84;
	// stfs f24,-500(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fsubs f29,f29,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// lfs f24,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f22,f22,f8,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f8.f64 - ctx.f16.f64));
	// stfs f22,-328(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f22,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f19,f2
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// fmadds f22,f22,f8,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f8.f64 + ctx.f17.f64));
	// stfs f22,-360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f22,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f22.f64 = double(temp.f32);
	// mulli r30,r8,44
	ctx.r30.s64 = ctx.r8.s64 * 44;
	// fadds f21,f22,f24
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f21,-508(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f21,f26,f31
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfs f24,-436(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmuls f24,f28,f2
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// fmuls f22,f30,f2
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// fmuls f17,f23,f2
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// lfs f26,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f18,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 - ctx.f26.f64));
	// stfs f26,-544(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f26,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f1
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// fmuls f14,f26,f31
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fadds f26,f25,f29
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// stfsx f26,r11,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// stfsx f29,r10,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f28,f28,f3,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f3.f64 + ctx.f22.f64));
	// lfs f29,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f30,f30,f3,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f3.f64 - ctx.f24.f64));
	// fsubs f25,f29,f26
	ctx.f25.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// lfs f22,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f24.f64 = double(temp.f32);
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// stfsx f25,r31,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f25,f24,f22
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfsx f29,r30,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fmadds f26,f27,f1,f21
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f29,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f27,f27,f31,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64 - ctx.f20.f64));
	// fadds f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// lfs f20,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f23,f23,f3,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 - ctx.f16.f64));
	// mulli r11,r8,100
	ctx.r11.s64 = ctx.r8.s64 * 100;
	// fmsubs f21,f20,f31,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f31.f64 - ctx.f15.f64));
	// lfs f15,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f20,f20,f1,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64 + ctx.f14.f64));
	// lfs f14,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f14.f64 = double(temp.f32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// mulli r10,r8,28
	ctx.r10.s64 = ctx.r8.s64 * 28;
	// fmadds f22,f19,f3,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f17.f64));
	// lfs f19,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// fadds f17,f25,f14
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f29,f14
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// stfs f14,-348(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f14,f23,f28
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfs f14,-436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fadds f18,f21,f26
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f20,f27
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// lfs f21,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// mulli r31,r9,28
	ctx.r31.s64 = ctx.r9.s64 * 28;
	// fsubs f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// lfs f20,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f20.f64 = double(temp.f32);
	// fadds f15,f22,f30
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// fadds f20,f24,f20
	ctx.f20.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// fsubs f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// lfs f22,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// fsubs f23,f19,f18
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfsx f23,r11,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f18,f19
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// mulli r30,r9,100
	ctx.r30.s64 = ctx.r9.s64 * 100;
	// fadds f23,f16,f17
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfsx f23,r31,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f23,f16,f17
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f22,f15,f20
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfsx f23,r30,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f23,f26,f25
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// mulli r29,r9,36
	ctx.r29.s64 = ctx.r9.s64 * 36;
	// fadds f25,f27,f21
	ctx.f25.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// stfsx f23,r29,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f23,f20,f15
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// mulli r28,r9,92
	ctx.r28.s64 = ctx.r9.s64 * 92;
	// stfsx f26,r28,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f26,f21,f27
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// mulli r27,r8,92
	ctx.r27.s64 = ctx.r8.s64 * 92;
	// stfsx f26,r27,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// lfs f27,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f26.f64 = double(temp.f32);
	// fadds f21,f26,f27
	ctx.f21.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfsx f25,r11,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f26,f30,f29
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f29.f64));
	// mulli r11,r8,124
	ctx.r11.s64 = ctx.r8.s64 * 124;
	// stfsx f23,r11,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// mulli r31,r9,124
	ctx.r31.s64 = ctx.r9.s64 * 124;
	// fsubs f29,f24,f28
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f28.f64));
	// fadds f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// stfsx f21,r10,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfsx f27,r31,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r9,60
	ctx.r11.s64 = ctx.r9.s64 * 60;
	// stfsx f26,r11,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r9,68
	ctx.r11.s64 = ctx.r9.s64 * 68;
	// stfsx f30,r11,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r8,68
	ctx.r11.s64 = ctx.r8.s64 * 68;
	// stfsx f29,r11,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r8,60
	ctx.r11.s64 = ctx.r8.s64 * 60;
	// stfsx f28,r11,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r16)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r16.u32 + 3532);
	// add r3,r18,r3
	ctx.r3.u64 = ctx.r18.u64 + ctx.r3.u64;
	// add r4,r18,r4
	ctx.r4.u64 = ctx.r18.u64 + ctx.r4.u64;
	// add r5,r17,r5
	ctx.r5.u64 = ctx.r17.u64 + ctx.r5.u64;
	// add r6,r17,r6
	ctx.r6.u64 = ctx.r17.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5c008
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5C008;
loc_82D5D22C:
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82e28f2c
	ctx.lr = 0x82D5D234;
	__restfpr_14(ctx, base);
	// b 0x82e28e88
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5D238"))) PPC_WEAK_FUNC(sub_82D5D238);
PPC_FUNC_IMPL(__imp__sub_82D5D238) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-368
	ctx.r5.s64 = ctx.r11.s64 + -368;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-16544
	ctx.r4.s64 = ctx.r11.s64 + -16544;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5D250"))) PPC_WEAK_FUNC(sub_82D5D250);
PPC_FUNC_IMPL(__imp__sub_82D5D250) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e38
	ctx.lr = 0x82D5D258;
	__savegprlr_16(ctx, base);
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82e28ee0
	ctx.lr = 0x82D5D260;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5d8e4
	if (!ctx.cr6.gt) goto loc_82D5D8E4;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r21,r11,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f8,-8004(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -8004);
	ctx.f8.f64 = double(temp.f32);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f9,-8000(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8000);
	ctx.f9.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f10,-8008(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8008);
	ctx.f10.f64 = double(temp.f32);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lfs f11,-8012(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8012);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D5D2B8:
	// mulli r11,r7,60
	ctx.r11.s64 = ctx.r7.s64 * 60;
	// lfs f7,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r10,r7,28
	ctx.r10.s64 = ctx.r7.s64 * 28;
	// lfsx f6,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f23,f6,f4
	ctx.f23.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// lfsx f3,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f4,f5,f3
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f2,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// mulli r30,r7,44
	ctx.r30.s64 = ctx.r7.s64 * 44;
	// lfsx f31,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f21,f2,f31
	ctx.f21.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// lfsx f30,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// mulli r28,r7,40
	ctx.r28.s64 = ctx.r7.s64 * 40;
	// lfsx f29,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f28,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f18,f29,f28
	ctx.f18.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// mulli r27,r7,56
	ctx.r27.s64 = ctx.r7.s64 * 56;
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fmuls f17,f21,f12
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f16,f21,f13
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfsx f27,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// mulli r26,r7,24
	ctx.r26.s64 = ctx.r7.s64 * 24;
	// lfsx f26,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f28,f27,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// mulli r25,r7,36
	ctx.r25.s64 = ctx.r7.s64 * 36;
	// lfsx f25,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f26,f25,f24
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// mulli r31,r7,52
	ctx.r31.s64 = ctx.r7.s64 * 52;
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r7,20
	ctx.r10.s64 = ctx.r7.s64 * 20;
	// stfs f14,-336(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfsx f3,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f24,f3,f22
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// rlwinm r30,r7,5,0,26
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f3,f22,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// rlwinm r24,r7,4,0,27
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f22,f2,f6
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// mulli r23,r7,48
	ctx.r23.s64 = ctx.r7.s64 * 48;
	// fsubs f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// lfsx f31,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f20,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f2,f31,f7
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// lfsx f19,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// fadds f31,f19,f20
	ctx.f31.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f19,f28,f18
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// fsubs f18,f28,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// fadds f28,f27,f29
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fsubs f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// fmadds f20,f23,f13,f17
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmsubs f23,f23,f12,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 - ctx.f16.f64));
	// fmuls f16,f24,f12
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f17,f26,f12
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmuls f27,f19,f0
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmuls f19,f18,f0
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fadds f18,f3,f25
	ctx.f18.f64 = double(float(ctx.f3.f64 + ctx.f25.f64));
	// fsubs f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 - ctx.f3.f64));
	// fadds f25,f31,f2
	ctx.f25.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fmsubs f31,f26,f13,f16
	ctx.f31.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f16.f64));
	// lfsx f16,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f24,f13,f17
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f17.f64));
	// lfsx f24,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f17,f30,f1
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f14,-316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fadds f15,f28,f25
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// fsubs f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// lfsx f30,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-320(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfsx f30,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// stfs f30,-324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfsx f30,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r31,r8,6,0,25
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// stfs f30,-304(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// mulli r29,r9,48
	ctx.r29.s64 = ctx.r9.s64 * 48;
	// lfsx f30,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-332(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfsx f30,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-300(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfsx f30,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-328(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fadds f30,f17,f5
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f5.f64));
	// stfs f30,-308(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fadds f30,f16,f24
	ctx.f30.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// fsubs f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// lfsx f14,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f5,f5,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f17.f64));
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,-312(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f16,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r10,r9,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfsx f18,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f25,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// mulli r30,r8,48
	ctx.r30.s64 = ctx.r8.s64 * 48;
	// stfs f16,-296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fadds f16,f18,f25
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// stfs f16,-292(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// lfs f16,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-288(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f18,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-336(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-304(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f18,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-332(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-300(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// lfs f14,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfsx f15,r11,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f15,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f24
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// lfs f17,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f15,f24
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// lfs f24,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f24.f64 = double(temp.f32);
	// fadds f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// fsubs f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// stfs f30,-324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f30,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f30.f64 = double(temp.f32);
	// fadds f24,f16,f30
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// stfs f24,-312(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fsubs f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// stfs f30,-320(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f30,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f30.f64 = double(temp.f32);
	// lfs f24,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f24.f64 = double(temp.f32);
	// fadds f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// stfs f30,-296(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f24,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f24.f64 = double(temp.f32);
	// lfs f30,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f16,f24,f30
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// fadds f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// stfs f30,-292(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmuls f24,f15,f0
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f24,-316(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fmuls f30,f14,f0
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f15,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f15.f64 = double(temp.f32);
	// stfs f14,-292(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,-308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f17,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,-296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f14,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// fsubs f14,f30,f1
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// fadds f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// lfs f30,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f4
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f30,-328(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f30,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// fsubs f30,f16,f18
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fadds f16,f15,f25
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfs f16,-312(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,-300(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f25,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f25,f16
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,-292(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfsx f17,r10,r6
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f16,-296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f25,-308(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f25,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f25,f17
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// stfsx f15,r31,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// stfs f25,0(r5)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f25,f28,f16
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// stfsx f25,r30,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f24,f12
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// mulli r31,r8,56
	ctx.r31.s64 = ctx.r8.s64 * 56;
	// lfs f25,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfsx f25,r29,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f25,f3,f6
	ctx.f25.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f3,f6,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// lfs f6,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f15,f6,f12
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// mulli r30,r9,56
	ctx.r30.s64 = ctx.r9.s64 * 56;
	// fmuls f6,f5,f12
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f6,-288(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmsubs f5,f5,f13,f16
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 - ctx.f16.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f25,-292(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f25,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f6,f25,f13,f17
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmsubs f25,f24,f13,f15
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f24,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f16,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f16.f64 = double(temp.f32);
	// lfs f24,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f30,f10
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fmadds f24,f24,f13,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f24,-288(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmuls f16,f14,f11
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f11.f64));
	// rlwinm r29,r8,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f14,f14,f10
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// rlwinm r28,r9,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// mulli r27,r9,24
	ctx.r27.s64 = ctx.r9.s64 * 24;
	// fadds f24,f31,f20
	ctx.f24.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// fmsubs f30,f30,f11,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64 - ctx.f17.f64));
	// lfs f17,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f17.f64 = double(temp.f32);
	// mulli r26,r8,24
	ctx.r26.s64 = ctx.r8.s64 * 24;
	// fmadds f17,f17,f10,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f16.f64));
	// lfs f16,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f16.f64 = double(temp.f32);
	// fadds f28,f16,f28
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f28.f64));
	// stfsx f28,r11,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f28,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// stfsx f28,r10,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f28,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f11,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 + ctx.f15.f64));
	// lfs f15,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f22,f22,f11,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f14.f64));
	// fadds f14,f3,f29
	ctx.f14.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// mulli r25,r9,40
	ctx.r25.s64 = ctx.r9.s64 * 40;
	// fadds f16,f15,f2
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fsubs f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fsubs f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f15.f64));
	// fadds f15,f5,f6
	ctx.f15.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f6.f64));
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// mulli r10,r9,60
	ctx.r10.s64 = ctx.r9.s64 * 60;
	// lfs f29,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f29.f64 = double(temp.f32);
	// fadds f5,f29,f25
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f25.f64));
	// fsubs f29,f29,f25
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fadds f25,f27,f7
	ctx.f25.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// stfs f25,-288(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f25,-292(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f25,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fadds f24,f17,f30
	ctx.f24.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// fsubs f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// fadds f17,f22,f28
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f17,-288(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfsx f17,r31,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f16,f6,f3
	ctx.f16.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fsubs f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// fsubs f3,f5,f14
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f14.f64));
	// stfsx f3,r30,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f17,r29,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f14.f64));
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f29,f2
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// stfsx f16,r27,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f3,f2,f29
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// stfsx f5,r26,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fmuls f29,f1,f8
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// stfsx f6,r25,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fmuls f16,f1,f9
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// lfs f6,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f5,f19,f21
	ctx.f5.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// fmuls f2,f6,f9
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// stfsx f3,r11,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fmuls f17,f6,f8
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// mulli r11,r8,60
	ctx.r11.s64 = ctx.r8.s64 * 60;
	// fsubs f6,f23,f26
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fadds f3,f26,f23
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// rlwinm r30,r9,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f2,f18,f8,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f2.f64));
	// lfs f26,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// lfs f23,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f1,f4,f9,f29
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 - ctx.f29.f64));
	// fsubs f22,f26,f23
	ctx.f22.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f22,f30,f25
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// mulli r29,r9,28
	ctx.r29.s64 = ctx.r9.s64 * 28;
	// fmsubs f29,f18,f9,f17
	ctx.f29.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 - ctx.f17.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fsubs f31,f20,f31
	ctx.f31.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// fadds f27,f19,f21
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fmadds f4,f4,f8,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f16.f64));
	// fsubs f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fadds f30,f5,f6
	ctx.f30.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f5,f3,f7
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fsubs f7,f7,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fadds f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// fadds f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fadds f1,f27,f31
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fadds f26,f4,f29
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fsubs f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f29.f64));
	// mulli r28,r9,36
	ctx.r28.s64 = ctx.r9.s64 * 36;
	// fsubs f29,f24,f30
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// stfsx f29,r10,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfsx f23,r31,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// stfsx f30,r30,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f31,f31,f27
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fadds f30,f6,f28
	ctx.f30.f64 = double(float(ctx.f6.f64 + ctx.f28.f64));
	// stfsx f30,r29,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f28,f6
	ctx.f6.f64 = double(float(ctx.f28.f64 - ctx.f6.f64));
	// stfsx f6,r28,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f3,f5
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f30,f5,f3
	ctx.f30.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// mulli r27,r8,36
	ctx.r27.s64 = ctx.r8.s64 * 36;
	// fsubs f5,f26,f1
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f1.f64));
	// stfsx f25,r27,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// mulli r26,r8,52
	ctx.r26.s64 = ctx.r8.s64 * 52;
	// stfsx f30,r26,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// mulli r25,r9,52
	ctx.r25.s64 = ctx.r9.s64 * 52;
	// stfsx f5,r25,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// mulli r24,r8,12
	ctx.r24.s64 = ctx.r8.s64 * 12;
	// stfsx f6,r24,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f1,f26
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// mulli r23,r9,12
	ctx.r23.s64 = ctx.r9.s64 * 12;
	// stfsx f6,r23,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f31,f2
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// mulli r19,r9,20
	ctx.r19.s64 = ctx.r9.s64 * 20;
	// stfsx f6,r19,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f4,f7
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fsubs f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// mulli r18,r8,20
	ctx.r18.s64 = ctx.r8.s64 * 20;
	// stfsx f6,r18,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f2,f31
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// mulli r17,r9,44
	ctx.r17.s64 = ctx.r9.s64 * 44;
	// stfsx f6,r17,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r6.u32, temp.u32);
	// mulli r16,r8,44
	ctx.r16.s64 = ctx.r8.s64 * 44;
	// stfsx f7,r16,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 3532);
	// add r3,r22,r3
	ctx.r3.u64 = ctx.r22.u64 + ctx.r3.u64;
	// add r4,r22,r4
	ctx.r4.u64 = ctx.r22.u64 + ctx.r4.u64;
	// add r5,r21,r5
	ctx.r5.u64 = ctx.r21.u64 + ctx.r5.u64;
	// add r6,r21,r6
	ctx.r6.u64 = ctx.r21.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5d2b8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5D2B8;
loc_82D5D8E4:
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82e28f2c
	ctx.lr = 0x82D5D8EC;
	__restfpr_14(ctx, base);
	// b 0x82e28e88
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5D8F0"))) PPC_WEAK_FUNC(sub_82D5D8F0);
PPC_FUNC_IMPL(__imp__sub_82D5D8F0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-320
	ctx.r5.s64 = ctx.r11.s64 + -320;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-11696
	ctx.r4.s64 = ctx.r11.s64 + -11696;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5D908"))) PPC_WEAK_FUNC(sub_82D5D908);
PPC_FUNC_IMPL(__imp__sub_82D5D908) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82D5D910;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28ef8
	ctx.lr = 0x82D5D918;
	__savefpr_20(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5db54
	if (!ctx.cr6.gt) goto loc_82D5DB54;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f12,-8016(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8016);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D5D950:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r31,r7,24
	ctx.r31.s64 = ctx.r7.s64 * 24;
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f26,f11,f9
	ctx.f26.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// lfsx f7,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f9,f8,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfsx f6,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f5,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// mulli r29,r7,20
	ctx.r29.s64 = ctx.r7.s64 * 20;
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fadds f25,f6,f10
	ctx.f25.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fadds f7,f4,f5
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// lfsx f3,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f2,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f26,f13
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfsx f1,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f6,f3,f2
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// mulli r28,r7,28
	ctx.r28.s64 = ctx.r7.s64 * 28;
	// lfsx f31,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f3,f1,f31
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmuls f23,f9,f13
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfsx f30,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f29,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r27,r7,12
	ctx.r27.s64 = ctx.r7.s64 * 12;
	// fmadds f9,f9,f12,f24
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 + ctx.f24.f64));
	// fmuls f24,f3,f12
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fmuls f22,f3,f13
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfsx f28,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f1,f30,f28
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfsx f27,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// rlwinm r23,r8,4,0,27
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f28,f8,f11
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// rlwinm r22,r9,4,0,27
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f31,f29,f27
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// rlwinm r21,r9,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// mulli r20,r9,28
	ctx.r20.s64 = ctx.r9.s64 * 28;
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fmsubs f8,f26,f12,f23
	ctx.f8.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 - ctx.f23.f64));
	// fadds f27,f7,f25
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// fsubs f26,f1,f6
	ctx.f26.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// fadds f23,f1,f6
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fadds f6,f30,f4
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fadds f3,f2,f29
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f29.f64));
	// fsubs f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f2.f64));
	// fmsubs f29,f31,f13,f24
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f13.f64 - ctx.f24.f64));
	// fmadds f31,f31,f12,f22
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 + ctx.f22.f64));
	// fmuls f1,f26,f0
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f26,f23,f0
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fsubs f24,f27,f6
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// stfsx f24,r23,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f3,f28
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// stfsx f24,r22,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fsubs f23,f29,f9
	ctx.f23.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// fadds f21,f8,f31
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f31.f64));
	// fsubs f8,f31,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f8.f64));
	// fsubs f24,f1,f5
	ctx.f24.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fadds f22,f26,f10
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f10.f64));
	// fadds f20,f23,f24
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfsx f20,r21,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// stfsx f24,r20,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// fadds f24,f11,f2
	ctx.f24.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fsubs f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f11.f64));
	// fsubs f11,f10,f26
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f26.f64));
	// fadds f10,f9,f29
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// fadds f9,f1,f5
	ctx.f9.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f5,f30,f4
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// mulli r31,r8,20
	ctx.r31.s64 = ctx.r8.s64 * 20;
	// fadds f4,f28,f3
	ctx.f4.f64 = double(float(ctx.f28.f64 + ctx.f3.f64));
	// mulli r30,r9,20
	ctx.r30.s64 = ctx.r9.s64 * 20;
	// fsubs f1,f22,f21
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfsx f1,r11,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 - ctx.f7.f64));
	// fmuls f3,f24,f0
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fadds f1,f21,f22
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f1,r10,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fsubs f1,f11,f10
	ctx.f1.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// stfsx f1,r31,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fadds f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f10,f7,f3
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// stfsx f11,r11,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f8,f9
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// mulli r10,r9,12
	ctx.r10.s64 = ctx.r9.s64 * 12;
	// stfsx f11,r10,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f11,f8,f9
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// stfsx f11,r30,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f11,f6,f4
	ctx.f11.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// mulli r29,r8,24
	ctx.r29.s64 = ctx.r8.s64 * 24;
	// stfsx f10,r29,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f3,f7
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r27,r9,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r23,r9,24
	ctx.r23.s64 = ctx.r9.s64 * 24;
	// stfsx f10,r28,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f2,f5
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// stfsx f10,r27,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f2,f5
	ctx.f10.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// stfsx f10,r23,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// stfsx f11,r11,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f4,f6
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfs f11,0(r5)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,3532(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5d950
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5D950;
loc_82D5DB54:
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28f44
	ctx.lr = 0x82D5DB5C;
	__restfpr_20(ctx, base);
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5DB60"))) PPC_WEAK_FUNC(sub_82D5DB60);
PPC_FUNC_IMPL(__imp__sub_82D5DB60) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-272
	ctx.r5.s64 = ctx.r11.s64 + -272;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-9976
	ctx.r4.s64 = ctx.r11.s64 + -9976;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5DB78"))) PPC_WEAK_FUNC(sub_82D5DB78);
PPC_FUNC_IMPL(__imp__sub_82D5DB78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D5DB80;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28ee0
	ctx.lr = 0x82D5DB88;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5de14
	if (!ctx.cr6.gt) goto loc_82D5DE14;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f15,-164(r21)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -164);
	ctx.f15.f64 = double(temp.f32);
	// lis r28,-32255
	ctx.r28.s64 = -2113863680;
	// lfs f16,-168(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -168);
	ctx.f16.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f12,-7588(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -7588);
	ctx.f12.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f13,-7584(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -7584);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f17,-12288(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -12288);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-7592(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -7592);
	ctx.f18.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f19,-172(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -172);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,-176(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -176);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f21.f64 = double(temp.f32);
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D5DBF8:
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// lfs f11,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f8,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f27,f8,f11
	ctx.f27.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// lfsx f7,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// mulli r24,r7,28
	ctx.r24.s64 = ctx.r7.s64 * 28;
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f9,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f8,f6,f9
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// lfsx f1,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f5,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfsx f2,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r29,r7,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// mulli r28,r7,24
	ctx.r28.s64 = ctx.r7.s64 * 24;
	// fadds f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fsubs f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// lfsx f3,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f26,f9,f11
	ctx.f26.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fadds f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// lfsx f30,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f31,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f1,f30,f31
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// lfsx f29,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f31,f31,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// lfsx f28,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f9,f8,f29
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f29.f64));
	// mulli r24,r9,20
	ctx.r24.s64 = ctx.r9.s64 * 20;
	// fnmsubs f8,f8,f0,f29
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f29.f64)));
	// fadds f30,f27,f2
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// fadds f25,f4,f10
	ctx.f25.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fnmsubs f2,f27,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fadds f27,f6,f28
	ctx.f27.f64 = double(float(ctx.f6.f64 + ctx.f28.f64));
	// fnmsubs f10,f4,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fnmsubs f6,f6,f0,f28
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f28.f64)));
	// mulli r23,r8,20
	ctx.r23.s64 = ctx.r8.s64 * 20;
	// fnmsubs f4,f1,f0,f3
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// fadds f29,f5,f31
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f31.f64));
	// fsubs f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 - ctx.f5.f64));
	// fadds f31,f1,f3
	ctx.f31.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fadds f3,f9,f30
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// fsubs f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// fadds f1,f8,f2
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fsubs f8,f2,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r10,r8,28
	ctx.r10.s64 = ctx.r8.s64 * 28;
	// fadds f24,f6,f4
	ctx.f24.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// fsubs f28,f26,f29
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fmuls f23,f5,f19
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmuls f22,f5,f20
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fadds f5,f27,f31
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fsubs f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fmuls f4,f7,f21
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f2,f29,f26
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r29,r9,12
	ctx.r29.s64 = ctx.r9.s64 * 12;
	// fsubs f14,f28,f7
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f7.f64));
	// fmadds f23,f11,f20,f23
	ctx.f23.f64 = double(float(ctx.f11.f64 * ctx.f20.f64 + ctx.f23.f64));
	// fmsubs f11,f11,f19,f22
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64 - ctx.f22.f64));
	// fadds f22,f24,f1
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// fsubs f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// fsubs f7,f31,f27
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fsubs f31,f5,f3
	ctx.f31.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fmuls f24,f14,f21
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f21.f64));
	// stfsx f24,r24,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fadds f24,f5,f3
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fadds f14,f22,f10
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f10.f64));
	// stfsx f14,r23,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fmuls f1,f1,f18
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// fnmsubs f10,f22,f17,f10
	ctx.f10.f64 = double(float(-(ctx.f22.f64 * ctx.f17.f64 - ctx.f10.f64)));
	// fsubs f5,f10,f1
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f1.f64));
	// fadds f10,f10,f1
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f1.f64));
	// fmuls f3,f2,f15
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// mulli r28,r9,24
	ctx.r28.s64 = ctx.r9.s64 * 24;
	// fmuls f2,f31,f18
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f18.f64));
	// mulli r24,r8,12
	ctx.r24.s64 = ctx.r8.s64 * 12;
	// fmuls f31,f8,f12
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmadds f4,f28,f16,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 + ctx.f4.f64));
	// fmuls f30,f6,f12
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fmuls f28,f7,f12
	ctx.f28.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f27,f7,f13
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fnmsubs f1,f24,f17,f25
	ctx.f1.f64 = double(float(-(ctx.f24.f64 * ctx.f17.f64 - ctx.f25.f64)));
	// fadds f29,f24,f25
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fmadds f7,f6,f13,f31
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f31.f64));
	// fadds f6,f5,f11
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// stfsx f6,r11,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// stfsx f11,r10,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f10,f23
	ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f23.f64));
	// stfsx f5,r31,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f3,f4
	ctx.f11.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// mulli r23,r8,24
	ctx.r23.s64 = ctx.r8.s64 * 24;
	// fsubs f10,f10,f23
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f23.f64));
	// stfsx f10,r30,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fmsubs f8,f8,f13,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 - ctx.f30.f64));
	// fsubs f6,f3,f4
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// fmadds f10,f9,f13,f28
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f28.f64));
	// stfsx f10,r29,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f10,f9,f12,f27
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f27.f64));
	// stfsx f10,r28,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f1,f2
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfsx f10,r24,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r22,r9,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f29,0(r5)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// mulli r21,r9,28
	ctx.r21.s64 = ctx.r9.s64 * 28;
	// fadds f10,f1,f2
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfsx f10,r23,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f11,f7
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f10,r22,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f8,f6
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfsx f10,r21,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r20,r9,4,0,27
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r19,r9,3,0,28
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// stfsx f11,r20,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// fadds f11,f8,f6
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfsx f11,r19,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5dbf8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5DBF8;
loc_82D5DE14:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f2c
	ctx.lr = 0x82D5DE1C;
	__restfpr_14(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5DE20"))) PPC_WEAK_FUNC(sub_82D5DE20);
PPC_FUNC_IMPL(__imp__sub_82D5DE20) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-224
	ctx.r5.s64 = ctx.r11.s64 + -224;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-9352
	ctx.r4.s64 = ctx.r11.s64 + -9352;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5DE38"))) PPC_WEAK_FUNC(sub_82D5DE38);
PPC_FUNC_IMPL(__imp__sub_82D5DE38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82D5DE40;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28ef4
	ctx.lr = 0x82D5DE48;
	__savefpr_19(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5e0a0
	if (!ctx.cr6.gt) goto loc_82D5E0A0;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f9,-4940(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -4940);
	ctx.f9.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f10,-4944(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -4944);
	ctx.f10.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f11,-4948(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -4948);
	ctx.f11.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f12,-4960(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -4960);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-4952(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4952);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-4956(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4956);
	ctx.f0.f64 = double(temp.f32);
loc_82D5DE98:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f6,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// mulli r10,r7,20
	ctx.r10.s64 = ctx.r7.s64 * 20;
	// lfs f7,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f25,f8,f5
	ctx.f25.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// mulli r31,r7,24
	ctx.r31.s64 = ctx.r7.s64 * 24;
	// fadds f24,f5,f8
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// lfsx f3,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f5,f2,f4
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f23,f4,f2
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// rlwinm r29,r7,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r28,r7,12
	ctx.r28.s64 = ctx.r7.s64 * 12;
	// lfsx f31,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f28,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f4,f31,f30
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// lfsx f27,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f21,f28,f1
	ctx.f21.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fsubs f20,f27,f6
	ctx.f20.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// lfsx f29,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f22,f3,f29
	ctx.f22.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// lfsx f26,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f19,f29,f3
	ctx.f19.f64 = double(float(ctx.f29.f64 + ctx.f3.f64));
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f28,f1,f28
	ctx.f28.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// mulli r23,r9,20
	ctx.r23.s64 = ctx.r9.s64 * 20;
	// fsubs f8,f7,f26
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// fadds f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// fadds f26,f30,f31
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fadds f27,f6,f27
	ctx.f27.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f3,f5,f4
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f1,f20,f21
	ctx.f1.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// mulli r22,r9,12
	ctx.r22.s64 = ctx.r9.s64 * 12;
	// fsubs f2,f22,f25
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fadds f4,f20,f21
	ctx.f4.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f6,f22,f25
	ctx.f6.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fmuls f31,f3,f13
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// mulli r21,r8,12
	ctx.r21.s64 = ctx.r8.s64 * 12;
	// fmuls f25,f5,f10
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fmuls f30,f1,f13
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f29,f1,f0
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fadds f22,f4,f5
	ctx.f22.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fmadds f21,f6,f9,f8
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f8.f64));
	// mulli r20,r8,28
	ctx.r20.s64 = ctx.r8.s64 * 28;
	// fmadds f31,f2,f0,f31
	ctx.f31.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f31.f64));
	// fnmadds f25,f4,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f25.f64)));
	// fmadds f30,f2,f12,f30
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 + ctx.f30.f64));
	// fmadds f29,f3,f12,f29
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f29.f64));
	// fadds f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f6.f64));
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fmadds f1,f1,f12,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f31.f64));
	// stfsx f1,r24,r6
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fadds f1,f27,f28
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fnmsubs f3,f3,f0,f30
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f30.f64)));
	// stfsx f3,r23,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f3,f2,f13,f29
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// stfsx f3,r22,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f28,f27
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fmuls f28,f4,f10
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// rlwinm r31,r9,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f3,f25,f21
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// stfsx f3,r21,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f22,f8
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f8.f64));
	// stfsx f3,r20,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// fmuls f27,f6,f10
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// mulli r30,r9,24
	ctx.r30.s64 = ctx.r9.s64 * 24;
	// fsubs f31,f23,f26
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fsubs f30,f24,f19
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// fadds f3,f26,f23
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// fadds f2,f19,f24
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fnmadds f6,f6,f11,f28
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 + ctx.f28.f64)));
	// rlwinm r29,r9,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r28,r8,24
	ctx.r28.s64 = ctx.r8.s64 * 24;
	// fmadds f28,f5,f9,f8
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f8.f64));
	// rlwinm r24,r8,3,0,28
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f8,f4,f9,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f8.f64));
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fnmadds f5,f5,f11,f27
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 + ctx.f27.f64)));
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fmuls f4,f1,f10
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmadds f27,f1,f9,f7
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fmuls f26,f3,f10
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fadds f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f28.f64));
	// stfsx f6,r11,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fmuls f6,f30,f0
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// stfsx f8,r10,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f8,f31,f0
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f5,f30,f13
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f28,f2,f10
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fnmadds f4,f2,f11,f4
	ctx.f4.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 + ctx.f4.f64)));
	// fmadds f6,f29,f12,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fmadds f8,f30,f12,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f8.f64));
	// fmsubs f5,f29,f0,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fmadds f30,f3,f9,f7
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fnmadds f28,f3,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f28.f64)));
	// fmadds f8,f29,f13,f8
	ctx.f8.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f8.f64));
	// stfsx f8,r31,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f8,f31,f13,f6
	ctx.f8.f64 = double(float(-(ctx.f31.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// stfsx f8,r30,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f8,f31,f12,f5
	ctx.f8.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// stfsx f8,r29,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f8,f4,f30
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// stfsx f8,r28,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f28,f27
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfsx f8,r24,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fnmadds f8,f1,f11,f26
	ctx.f8.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 + ctx.f26.f64)));
	// add r6,r26,r6
	ctx.r6.u64 = ctx.r26.u64 + ctx.r6.u64;
	// fmadds f6,f2,f9,f7
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fadds f5,f1,f2
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfsx f8,r11,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f5,f3
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fadds f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,3532(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 3532);
	// add r5,r26,r5
	ctx.r5.u64 = ctx.r26.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5de98
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5DE98;
loc_82D5E0A0:
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28f40
	ctx.lr = 0x82D5E0A8;
	__restfpr_19(ctx, base);
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5E0B0"))) PPC_WEAK_FUNC(sub_82D5E0B0);
PPC_FUNC_IMPL(__imp__sub_82D5E0B0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-160
	ctx.r5.s64 = ctx.r11.s64 + -160;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-8648
	ctx.r4.s64 = ctx.r11.s64 + -8648;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5E0C8"))) PPC_WEAK_FUNC(sub_82D5E0C8);
PPC_FUNC_IMPL(__imp__sub_82D5E0C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D5E0D0;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D5E0D8;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5e420
	if (!ctx.cr6.gt) goto loc_82D5E420;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// lfs f12,-4268(r19)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -4268);
	ctx.f12.f64 = double(temp.f32);
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// stfs f12,-320(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// stw r11,-332(r1)
	PPC_STORE_U32(ctx.r1.u32 + -332, ctx.r11.u32);
	// lfs f12,-32(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -32);
	ctx.f12.f64 = double(temp.f32);
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stfs f12,-308(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f12,-4264(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -4264);
	ctx.f12.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f12,-312(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lfs f12,-36(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -36);
	ctx.f12.f64 = double(temp.f32);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// stfs f12,-324(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f12,-40(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -40);
	ctx.f12.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// stfs f12,-328(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// stw r11,-336(r1)
	PPC_STORE_U32(ctx.r1.u32 + -336, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r24,-32229
	ctx.r24.s64 = -2112159744;
	// lfs f23,-4312(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -4312);
	ctx.f23.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f22,-4316(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -4316);
	ctx.f22.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f18,-52(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -52);
	ctx.f18.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f19,-56(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -56);
	ctx.f19.f64 = double(temp.f32);
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f13,-13884(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -13884);
	ctx.f13.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f20,-6320(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -6320);
	ctx.f20.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f21,-4320(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -4320);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,-4308(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -4308);
	ctx.f24.f64 = double(temp.f32);
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// lfs f12,-152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -152);
	ctx.f12.f64 = double(temp.f32);
	// lfs f25,-60(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -60);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,-64(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -64);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,-48(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -48);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-44(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -44);
	ctx.f16.f64 = double(temp.f32);
	// stfs f12,-316(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lwz r28,-332(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	// lwz r27,-336(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + -336);
loc_82D5E1C0:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r30,r7,20
	ctx.r30.s64 = ctx.r7.s64 * 20;
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f30,f9,f7
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fadds f29,f8,f6
	ctx.f29.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// lfsx f3,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// mulli r29,r7,12
	ctx.r29.s64 = ctx.r7.s64 * 12;
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f5,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fsubs f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fadds f6,f2,f3
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfsx f1,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f3,f5,f1
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fsubs f2,f31,f4
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f4.f64));
	// mulli r26,r7,24
	ctx.r26.s64 = ctx.r7.s64 * 24;
	// fadds f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f1,f30,f12
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f12.f64));
	// fsubs f28,f9,f8
	ctx.f28.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// lfsx f10,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f12,f30,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fadds f31,f29,f10
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f10.f64));
	// fnmsubs f10,f29,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f29.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// fadds f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fadds f30,f4,f5
	ctx.f30.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f29,f5,f4
	ctx.f29.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fsubs f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fmuls f5,f28,f27
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f27.f64));
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// rlwinm r31,r9,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// mulli r30,r9,12
	ctx.r30.s64 = ctx.r9.s64 * 12;
	// fadds f31,f8,f7
	ctx.f31.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fnmsubs f8,f8,f0,f7
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fadds f28,f30,f6
	ctx.f28.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// fmuls f3,f29,f27
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f27.f64));
	// fsubs f29,f12,f10
	ctx.f29.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fnmsubs f7,f30,f0,f6
	ctx.f7.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// rlwinm r29,r9,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f10,f9,f4
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// mulli r26,r9,24
	ctx.r26.s64 = ctx.r9.s64 * 24;
	// fmuls f15,f1,f25
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fadds f9,f4,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// fmuls f14,f31,f25
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// fadds f30,f8,f5
	ctx.f30.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fadds f4,f28,f2
	ctx.f4.f64 = double(float(ctx.f28.f64 + ctx.f2.f64));
	// fsubs f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// fsubs f6,f29,f3
	ctx.f6.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// fadds f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// fsubs f28,f2,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// lfs f2,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmsubs f5,f1,f26,f14
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f26.f64 - ctx.f14.f64));
	// fsubs f1,f12,f7
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fmadds f7,f31,f26,f15
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f26.f64 + ctx.f15.f64));
	// fadds f31,f4,f11
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// stfs f31,0(r5)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmuls f31,f30,f23
	ctx.f31.f64 = double(float(ctx.f30.f64 * ctx.f23.f64));
	// fmuls f29,f8,f21
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// fmuls f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f24.f64));
	// fmuls f15,f3,f21
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// fmuls f14,f10,f18
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f18.f64));
	// fmsubs f31,f6,f24,f31
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f31.f64));
	// fmadds f3,f3,f22,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f29.f64));
	// fmadds f6,f6,f23,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64 + ctx.f30.f64));
	// stfs f2,-332(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f30,f28,f17
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f29,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f2,f1,f19,f14
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f19.f64 - ctx.f14.f64));
	// fmsubs f8,f8,f22,f15
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f22.f64 - ctx.f15.f64));
	// rlwinm r25,r8,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r24,r8,20
	ctx.r24.s64 = ctx.r8.s64 * 20;
	// rlwinm r23,r8,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// lfs f28,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f29,f12,f29,f28
	ctx.f29.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 + ctx.f28.f64));
	// lfs f28,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f28,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f11,f4,f28,f11
	ctx.f11.f64 = double(float(-(ctx.f4.f64 * ctx.f28.f64 - ctx.f11.f64)));
	// lfs f4,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f12,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmadds f12,f10,f16,f1
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f16.f64 + ctx.f1.f64));
	// lfs f10,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f1,f8,f31
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f31.f64));
	// fmsubs f10,f9,f10,f4
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 - ctx.f4.f64));
	// fadds f4,f8,f31
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f31.f64));
	// fadds f31,f6,f3
	ctx.f31.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fsubs f9,f3,f6
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fsubs f8,f30,f2
	ctx.f8.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// fsubs f6,f11,f29
	ctx.f6.f64 = double(float(ctx.f11.f64 - ctx.f29.f64));
	// fmadds f2,f2,f13,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f30.f64));
	// fmadds f11,f29,f13,f11
	ctx.f11.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f11.f64));
	// fmuls f3,f1,f20
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// fsubs f30,f5,f4
	ctx.f30.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fmuls f1,f31,f20
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f20.f64));
	// fsubs f31,f12,f10
	ctx.f31.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f10,f7,f9
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fmadds f5,f4,f13,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f5.f64));
	// stfsx f5,r11,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmadds f9,f9,f13,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f7.f64));
	// stfsx f9,r10,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f6,f8
	ctx.f29.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fadds f9,f11,f2
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fsubs f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f2.f64));
	// fsubs f7,f3,f10
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// stfsx f7,r31,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f10,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// stfsx f10,r30,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f30,f1
	ctx.f10.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// stfsx f10,r29,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f30,f1
	ctx.f10.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// stfsx f10,r26,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// stfsx f9,r25,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f29,f31
	ctx.f10.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// stfsx f11,r24,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f6,f8
	ctx.f11.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfsx f10,r23,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f29,f31
	ctx.f10.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// stfsx f10,r11,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f10,f11,f12
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// stfsx f10,r10,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// add r6,r27,r6
	ctx.r6.u64 = ctx.r27.u64 + ctx.r6.u64;
	// stfsx f12,r11,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r14)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r14.u32 + 3532);
	// add r5,r27,r5
	ctx.r5.u64 = ctx.r27.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5e1c0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5E1C0;
loc_82D5E420:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D5E428;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5E430"))) PPC_WEAK_FUNC(sub_82D5E430);
PPC_FUNC_IMPL(__imp__sub_82D5E430) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-112
	ctx.r5.s64 = ctx.r11.s64 + -112;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-7992
	ctx.r4.s64 = ctx.r11.s64 + -7992;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5E448"))) PPC_WEAK_FUNC(sub_82D5E448);
PPC_FUNC_IMPL(__imp__sub_82D5E448) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D5E450;
	__savegprlr_19(ctx, base);
	// stfd f29,-136(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -136, ctx.f29.u64);
	// stfd f30,-128(r1)
	PPC_STORE_U64(ctx.r1.u32 + -128, ctx.f30.u64);
	// stfd f31,-120(r1)
	PPC_STORE_U64(ctx.r1.u32 + -120, ctx.f31.u64);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5e5f8
	if (!ctx.cr6.gt) goto loc_82D5E5F8;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r28,r11,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D5E48C:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 * 12;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f31,f10,f12
	ctx.f31.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f10,f6,f9
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// lfsx f5,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// rlwinm r29,r7,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r25,r8,12
	ctx.r25.s64 = ctx.r8.s64 * 12;
	// lfsx f4,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f6,f4,f8
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fadds f30,f3,f5
	ctx.f30.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f1,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f8,f4,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// lfsx f2,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// mulli r24,r9,12
	ctx.r24.s64 = ctx.r9.s64 * 12;
	// fnmsubs f3,f31,f0,f1
	ctx.f3.f64 = double(float(-(ctx.f31.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fadds f4,f31,f1
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fadds f1,f10,f2
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f2.f64));
	// fsubs f31,f9,f12
	ctx.f31.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// fnmsubs f10,f10,f0,f2
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fadds f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// fadds f9,f6,f11
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// fadds f2,f30,f7
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f7.f64));
	// rlwinm r23,r9,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmsubs f11,f6,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// mulli r22,r9,20
	ctx.r22.s64 = ctx.r9.s64 * 20;
	// fsubs f29,f8,f5
	ctx.f29.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// fnmsubs f7,f30,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fadds f30,f4,f1
	ctx.f30.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fsubs f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fsubs f4,f3,f10
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fadds f10,f3,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f10.f64));
	// fmuls f31,f31,f13
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// mulli r21,r8,20
	ctx.r21.s64 = ctx.r8.s64 * 20;
	// fadds f3,f2,f9
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfsx f9,r25,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fmuls f6,f29,f13
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// stfsx f1,r24,r6
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f11,f7
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// rlwinm r20,r8,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r19,r8,24
	ctx.r19.s64 = ctx.r8.s64 * 24;
	// fadds f7,f4,f6
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfsx f7,r23,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f4,f6
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// stfsx f7,r22,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f9,f31
	ctx.f4.f64 = double(float(ctx.f9.f64 - ctx.f31.f64));
	// stfsx f4,r21,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f31,f9
	ctx.f9.f64 = double(float(ctx.f31.f64 + ctx.f9.f64));
	// stfsx f9,r20,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f7,f3,f30
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// stfsx f7,r19,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f30,f3
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f9,f11,f10
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// stfsx f9,r11,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// stfsx f11,r10,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f5,f8
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// add r5,r27,r5
	ctx.r5.u64 = ctx.r27.u64 + ctx.r5.u64;
	// fsubs f10,f12,f11
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// fmuls f11,f10,f13
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// stfsx f11,r11,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfsx f12,r10,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// add r6,r27,r6
	ctx.r6.u64 = ctx.r27.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5e48c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5E48C;
loc_82D5E5F8:
	// lfd f29,-136(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -136);
	// lfd f30,-128(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -128);
	// lfd f31,-120(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5E608"))) PPC_WEAK_FUNC(sub_82D5E608);
PPC_FUNC_IMPL(__imp__sub_82D5E608) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-24
	ctx.r5.s64 = ctx.r11.s64 + -24;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-7096
	ctx.r4.s64 = ctx.r11.s64 + -7096;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5E620"))) PPC_WEAK_FUNC(sub_82D5E620);
PPC_FUNC_IMPL(__imp__sub_82D5E620) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D5E628;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28ee4
	ctx.lr = 0x82D5E630;
	__savefpr_15(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5e898
	if (!ctx.cr6.gt) goto loc_82D5E898;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// rlwinm r21,r11,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f25,108(r23)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 108);
	ctx.f25.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f26,104(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f27,100(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 100);
	ctx.f27.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f28,96(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 96);
	ctx.f28.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f29,92(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 92);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,88(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f31,84(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 84);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,80(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,76(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 76);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f3.f64 = double(temp.f32);
loc_82D5E6A0:
	// mulli r28,r7,20
	ctx.r28.s64 = ctx.r7.s64 * 20;
	// lfs f13,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfsx f12,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f8,f12,f13
	ctx.f8.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r31,r7,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// lfsx f11,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// lfsx f5,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f6,f5,f9
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// lfsx f24,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f11,f5,f9
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fadds f10,f24,f4
	ctx.f10.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// lfsx f23,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f5,f24,f4
	ctx.f5.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f9,f22,f23
	ctx.f9.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// rlwinm r28,r9,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f24,f13,f28
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// rlwinm r27,r8,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f4,f22,f23
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// rlwinm r26,r9,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f23,f8,f31
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// fmuls f21,f7,f2
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f2.f64));
	// fmuls f22,f8,f1
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmuls f20,f6,f31
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f18,f6,f2
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// fmuls f19,f10,f26
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fmuls f17,f5,f31
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmadds f16,f12,f25,f0
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f25.f64 + ctx.f0.f64));
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f24,f9,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f9.f64 * ctx.f29.f64 + ctx.f24.f64)));
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// fmuls f15,f10,f29
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// fmadds f23,f4,f3,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f23.f64));
	// fmadds f21,f8,f3,f21
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 + ctx.f21.f64));
	// fmadds f22,f7,f3,f22
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f3.f64 + ctx.f22.f64));
	// fmsubs f20,f5,f1,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 - ctx.f20.f64));
	// fnmadds f18,f5,f30,f18
	ctx.f18.f64 = double(float(-(ctx.f5.f64 * ctx.f30.f64 + ctx.f18.f64)));
	// fmsubs f19,f11,f27,f19
	ctx.f19.f64 = double(float(ctx.f11.f64 * ctx.f27.f64 - ctx.f19.f64));
	// fmsubs f17,f6,f30,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f30.f64 - ctx.f17.f64));
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// fadds f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// fmuls f20,f9,f26
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmuls f19,f11,f28
	ctx.f19.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// fmuls f18,f10,f28
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f17,f11,f26
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f26.f64));
	// fnmsubs f21,f4,f30,f21
	ctx.f21.f64 = double(float(-(ctx.f4.f64 * ctx.f30.f64 - ctx.f21.f64)));
	// stfsx f21,r28,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fmuls f21,f8,f30
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// stfsx f24,r27,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fnmsubs f24,f7,f1,f23
	ctx.f24.f64 = double(float(-(ctx.f7.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// stfsx f24,r26,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f24,f4,f2,f22
	ctx.f24.f64 = double(float(-(ctx.f4.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// stfsx f24,r11,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f22,f7,f30
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// fmuls f24,f4,f31
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fadds f23,f10,f11
	ctx.f23.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f16,f9,f28
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmadds f22,f5,f3,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 + ctx.f22.f64));
	// fmadds f8,f8,f2,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 + ctx.f24.f64));
	// fadds f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f12.f64));
	// fmsubs f7,f6,f3,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 - ctx.f7.f64));
	// fmadds f5,f5,f2,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f2.f64 + ctx.f21.f64));
	// fnmadds f24,f13,f29,f20
	ctx.f24.f64 = double(float(-(ctx.f13.f64 * ctx.f29.f64 + ctx.f20.f64)));
	// fmsubs f21,f10,f25,f19
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 - ctx.f19.f64));
	// add r3,r22,r3
	ctx.r3.u64 = ctx.r22.u64 + ctx.r3.u64;
	// fadds f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// add r4,r22,r4
	ctx.r4.u64 = ctx.r22.u64 + ctx.r4.u64;
	// fnmadds f20,f12,f29,f18
	ctx.f20.f64 = double(float(-(ctx.f12.f64 * ctx.f29.f64 + ctx.f18.f64)));
	// fmsubs f19,f9,f27,f17
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f17.f64));
	// fnmadds f18,f12,f26,f16
	ctx.f18.f64 = double(float(-(ctx.f12.f64 * ctx.f26.f64 + ctx.f16.f64)));
	// fadds f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f13.f64));
	// fmsubs f17,f11,f25,f15
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f25.f64 - ctx.f15.f64));
	// fmuls f11,f11,f29
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// fadds f8,f22,f8
	ctx.f8.f64 = double(float(ctx.f22.f64 + ctx.f8.f64));
	// fadds f5,f24,f21
	ctx.f5.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// fmadds f24,f12,f27,f0
	ctx.f24.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 + ctx.f0.f64));
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fmadds f21,f13,f25,f0
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f25.f64 + ctx.f0.f64));
	// fadds f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// fmadds f19,f13,f27,f0
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f27.f64 + ctx.f0.f64));
	// fadds f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// fadds f20,f18,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// fmadds f8,f6,f1,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f8.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f8,f4,f1,f7
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f1.f64 - ctx.f7.f64)));
	// stfsx f8,r11,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fadds f8,f5,f24
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fnmadds f13,f13,f26,f12
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f26.f64 + ctx.f12.f64)));
	// fmsubs f12,f10,f27,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 - ctx.f11.f64));
	// fadds f8,f22,f21
	ctx.f8.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfsx f8,r30,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f23,f0
	ctx.f8.f64 = double(float(ctx.f23.f64 + ctx.f0.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmadds f0,f9,f25,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f25.f64 + ctx.f0.f64));
	// add r6,r21,r6
	ctx.r6.u64 = ctx.r21.u64 + ctx.r6.u64;
	// fadds f8,f20,f19
	ctx.f8.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfsx f8,r28,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfsx f0,r11,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r5,r21,r5
	ctx.r5.u64 = ctx.r21.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5e6a0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5E6A0;
loc_82D5E898:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28f30
	ctx.lr = 0x82D5E8A0;
	__restfpr_15(ctx, base);
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5E8A8"))) PPC_WEAK_FUNC(sub_82D5E8A8);
PPC_FUNC_IMPL(__imp__sub_82D5E8A8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,24
	ctx.r5.s64 = ctx.r11.s64 + 24;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-6624
	ctx.r4.s64 = ctx.r11.s64 + -6624;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5E8C0"))) PPC_WEAK_FUNC(sub_82D5E8C0);
PPC_FUNC_IMPL(__imp__sub_82D5E8C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D5E8C8;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f18
	ctx.lr = 0x82D5E8D0;
	__savefpr_28(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5ea58
	if (!ctx.cr6.gt) goto loc_82D5EA58;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r30,-32255
	ctx.r30.s64 = -2113863680;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r28,r11,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f30,-12288(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -12288);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,-7592(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7592);
	ctx.f31.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f13,-7584(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7584);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7588(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7588);
	ctx.f0.f64 = double(temp.f32);
loc_82D5E910:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f2,f10,f9
	ctx.f2.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfsx f5,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f1,f8,f12
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfsx f7,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f9,f11,f5
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// fadds f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// rlwinm r26,r9,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r25,r9,12
	ctx.r25.s64 = ctx.r9.s64 * 12;
	// lfsx f4,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f8,f4,f7
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f7.f64));
	// fsubs f5,f6,f3
	ctx.f5.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// fadds f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fadds f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// rlwinm r24,r8,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// mulli r23,r8,20
	ctx.r23.s64 = ctx.r8.s64 * 20;
	// fadds f2,f12,f10
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fadds f10,f5,f8
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// fsubs f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// fadds f5,f6,f7
	ctx.f5.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// mulli r22,r8,12
	ctx.r22.s64 = ctx.r8.s64 * 12;
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fadds f6,f10,f4
	ctx.f6.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// rlwinm r21,r9,3,0,28
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f4,f10,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// rlwinm r20,r9,4,0,27
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f10,f5,f2
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// rlwinm r19,r8,3,0,28
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f2,f8,f13
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fmuls f29,f8,f0
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// add r4,r29,r4
	ctx.r4.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fmuls f28,f7,f0
	ctx.f28.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmadds f7,f7,f13,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fmuls f8,f4,f31
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmsubs f4,f3,f0,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f2.f64));
	// stfsx f4,r26,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fmadds f4,f3,f13,f29
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f29.f64));
	// stfsx f4,r25,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f4,f12,f13,f28
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f28.f64));
	// fnmsubs f12,f6,f30,f9
	ctx.f12.f64 = double(float(-(ctx.f6.f64 * ctx.f30.f64 - ctx.f9.f64)));
	// fadds f2,f10,f11
	ctx.f2.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fnmsubs f11,f10,f30,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f30.f64 - ctx.f11.f64)));
	// fadds f3,f6,f9
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// fadds f10,f12,f8
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// stfsx f10,r24,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// stfsx f3,r23,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// stfsx f12,r22,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f11,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// stfsx f4,r21,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// stfsx f7,r20,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// add r6,r28,r6
	ctx.r6.u64 = ctx.r28.u64 + ctx.r6.u64;
	// stfsx f12,r19,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f11,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// stfs f2,0(r5)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfsx f12,r11,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// add r5,r28,r5
	ctx.r5.u64 = ctx.r28.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5e910
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5E910;
loc_82D5EA58:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f64
	ctx.lr = 0x82D5EA60;
	__restfpr_28(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5EA68"))) PPC_WEAK_FUNC(sub_82D5EA68);
PPC_FUNC_IMPL(__imp__sub_82D5EA68) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,112
	ctx.r5.s64 = ctx.r11.s64 + 112;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-5952
	ctx.r4.s64 = ctx.r11.s64 + -5952;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5EA80"))) PPC_WEAK_FUNC(sub_82D5EA80);
PPC_FUNC_IMPL(__imp__sub_82D5EA80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e3c
	ctx.lr = 0x82D5EA88;
	__savegprlr_17(ctx, base);
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28ef0
	ctx.lr = 0x82D5EA90;
	__savefpr_18(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5ec7c
	if (!ctx.cr6.gt) goto loc_82D5EC7C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// rlwinm r18,r11,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// rlwinm r17,r11,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f19,-1832(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -1832);
	ctx.f19.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f20,-5080(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -5080);
	ctx.f20.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f21,-5076(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -5076);
	ctx.f21.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f22,-1828(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -1828);
	ctx.f22.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f27,-6156(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -6156);
	ctx.f27.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f28,-1824(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -1824);
	ctx.f28.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f23,-6140(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -6140);
	ctx.f23.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f24,-1812(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -1812);
	ctx.f24.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f29,-6160(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -6160);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,-1820(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -1820);
	ctx.f30.f64 = double(temp.f32);
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f25,-1816(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -1816);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,-6144(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -6144);
	ctx.f26.f64 = double(temp.f32);
	// lfs f9,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f9.f64 = double(temp.f32);
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D5EB20:
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// lfs f11,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f13,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r29,r9,12
	ctx.r29.s64 = ctx.r9.s64 * 12;
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f3,f13,f7
	ctx.f3.f64 = double(float(ctx.f13.f64 + ctx.f7.f64));
	// lfsx f12,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// fadds f2,f12,f6
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// lfsx f4,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f5,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f7,f10,f4
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// fsubs f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f6.f64));
	// mulli r30,r8,12
	ctx.r30.s64 = ctx.r8.s64 * 12;
	// fsubs f6,f10,f4
	ctx.f6.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// fadds f4,f3,f11
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f11.f64));
	// fnmsubs f11,f3,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// fadds f1,f2,f5
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// rlwinm r28,r8,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmsubs f10,f2,f0,f5
	ctx.f10.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f5.f64)));
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f31,f7,f8
	ctx.f31.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// rlwinm r26,r8,4,0,27
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fnmsubs f8,f7,f0,f8
	ctx.f8.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f18,f13,f25
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// rlwinm r10,r9,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f5,f6,f9
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// rlwinm r31,r8,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r18,r3
	ctx.r3.u64 = ctx.r18.u64 + ctx.r3.u64;
	// add r4,r18,r4
	ctx.r4.u64 = ctx.r18.u64 + ctx.r4.u64;
	// fmuls f2,f11,f23
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// fadds f7,f1,f4
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fmuls f3,f10,f29
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// fmuls f1,f10,f27
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fmsubs f2,f13,f24,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f24.f64 - ctx.f2.f64));
	// fmuls f4,f4,f9
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// stfsx f4,r29,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmadds f4,f11,f26,f18
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f26.f64 + ctx.f18.f64));
	// fmadds f3,f12,f30,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 + ctx.f3.f64));
	// fmsubs f1,f12,f28,f1
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f28.f64 - ctx.f1.f64));
	// fadds f18,f7,f31
	ctx.f18.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// fnmsubs f7,f7,f0,f31
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f31.f64)));
	// stfsx f7,r30,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfs f18,0(r5)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f7,f3,f4
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f3,f3,f4
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fmadds f3,f2,f9,f8
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fadds f2,f7,f8
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfsx f2,r28,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fmuls f2,f4,f0
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f4,f4,f5
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfsx f4,r27,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fmuls f4,f10,f21
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// fnmsubs f7,f7,f0,f3
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// stfsx f7,r26,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fmsubs f7,f6,f9,f2
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 - ctx.f2.f64));
	// stfsx f7,r11,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f6,f11,f27
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// fmuls f7,f12,f19
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f19.f64));
	// fmsubs f12,f12,f22,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f22.f64 - ctx.f4.f64));
	// fmadds f11,f11,f29,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 + ctx.f8.f64));
	// fnmadds f6,f13,f28,f6
	ctx.f6.f64 = double(float(-(ctx.f13.f64 * ctx.f28.f64 + ctx.f6.f64)));
	// fnmadds f10,f10,f20,f7
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f20.f64 + ctx.f7.f64)));
	// fadds f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fsubs f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f5.f64));
	// stfsx f12,r10,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f13,f13,f30,f11
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f30.f64 - ctx.f11.f64)));
	// add r6,r17,r6
	ctx.r6.u64 = ctx.r17.u64 + ctx.r6.u64;
	// stfsx f13,r31,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 3532);
	// add r5,r17,r5
	ctx.r5.u64 = ctx.r17.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5eb20
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5EB20;
loc_82D5EC7C:
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28f3c
	ctx.lr = 0x82D5EC84;
	__restfpr_18(ctx, base);
	// b 0x82e28e8c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5EC88"))) PPC_WEAK_FUNC(sub_82D5EC88);
PPC_FUNC_IMPL(__imp__sub_82D5EC88) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,160
	ctx.r5.s64 = ctx.r11.s64 + 160;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-5504
	ctx.r4.s64 = ctx.r11.s64 + -5504;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5ECA0"))) PPC_WEAK_FUNC(sub_82D5ECA0);
PPC_FUNC_IMPL(__imp__sub_82D5ECA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D5ECA8;
	__savegprlr_21(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5edb4
	if (!ctx.cr6.gt) goto loc_82D5EDB4;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f5,140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f5.f64 = double(temp.f32);
loc_82D5ECD0:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mulli r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 * 12;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f12,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f6,f0,f12
	ctx.f6.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fadds f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// lfsx f11,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f12,f10,f13
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// fsubs f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r9,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r25,r8,12
	ctx.r25.s64 = ctx.r8.s64 * 12;
	// lfsx f8,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f10,f11,f8
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// lfsx f7,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fadds f8,f9,f7
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// rlwinm r24,r8,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r9,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r22,r9,12
	ctx.r22.s64 = ctx.r9.s64 * 12;
	// fadds f4,f6,f10
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f6,f10,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f10,f8,f12
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fadds f7,f0,f11
	ctx.f7.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// stfsx f12,r27,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfsx f0,r26,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r21,r8,4,0,27
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fmuls f0,f4,f5
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f12,f6,f5
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fsubs f11,f10,f7
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fsubs f8,f13,f0
	ctx.f8.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// stfsx f8,r25,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// stfsx f0,r24,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f12,f9
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfsx f0,r23,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fadds f0,f12,f9
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// stfsx f0,r22,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// stfsx f11,r21,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// add r6,r29,r6
	ctx.r6.u64 = ctx.r29.u64 + ctx.r6.u64;
	// stfs f10,0(r5)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,3532(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// add r5,r29,r5
	ctx.r5.u64 = ctx.r29.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5ecd0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5ECD0;
loc_82D5EDB4:
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5EDB8"))) PPC_WEAK_FUNC(sub_82D5EDB8);
PPC_FUNC_IMPL(__imp__sub_82D5EDB8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,208
	ctx.r5.s64 = ctx.r11.s64 + 208;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-4960
	ctx.r4.s64 = ctx.r11.s64 + -4960;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5EDD0"))) PPC_WEAK_FUNC(sub_82D5EDD0);
PPC_FUNC_IMPL(__imp__sub_82D5EDD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D5EDD8;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f08
	ctx.lr = 0x82D5EDE0;
	__savefpr_24(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5ef28
	if (!ctx.cr6.gt) goto loc_82D5EF28;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f2,-4940(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -4940);
	ctx.f2.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f3,-4944(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -4944);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f4,-4948(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -4948);
	ctx.f4.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f5,-4960(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -4960);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-4952(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4952);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,-4956(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4956);
	ctx.f7.f64 = double(temp.f32);
loc_82D5EE30:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mulli r28,r7,12
	ctx.r28.s64 = ctx.r7.s64 * 12;
	// lfsx f11,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f8,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f12,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f9,f8,f11
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// fsubs f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// lfsx f1,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fadds f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// rlwinm r28,r9,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f11,f31,f1
	ctx.f11.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f8,f31,f1
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// rlwinm r26,r8,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r25,r9,12
	ctx.r25.s64 = ctx.r9.s64 * 12;
	// fmuls f29,f9,f6
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f1,f10,f6
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// fmuls f31,f13,f3
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f27,f9,f7
	ctx.f27.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// mulli r24,r8,12
	ctx.r24.s64 = ctx.r8.s64 * 12;
	// fmuls f28,f11,f3
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f26,f12,f3
	ctx.f26.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fadds f25,f12,f11
	ctx.f25.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// fmadds f24,f12,f2,f0
	ctx.f24.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 + ctx.f0.f64));
	// fmadds f30,f13,f2,f0
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f0.f64));
	// fmsubs f29,f10,f7,f29
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 - ctx.f29.f64));
	// fmadds f1,f8,f7,f1
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 + ctx.f1.f64));
	// rlwinm r23,r8,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f12,f12,f4,f31
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f4.f64 + ctx.f31.f64)));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fmadds f10,f10,f5,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 + ctx.f27.f64));
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fnmadds f28,f13,f4,f28
	ctx.f28.f64 = double(float(-(ctx.f13.f64 * ctx.f4.f64 + ctx.f28.f64)));
	// fmadds f31,f11,f2,f0
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f0.f64));
	// fnmadds f11,f11,f4,f26
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 + ctx.f26.f64)));
	// fadds f13,f25,f13
	ctx.f13.f64 = double(float(ctx.f25.f64 + ctx.f13.f64));
	// fnmsubs f29,f8,f5,f29
	ctx.f29.f64 = double(float(-(ctx.f8.f64 * ctx.f5.f64 - ctx.f29.f64)));
	// stfsx f29,r28,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fmadds f9,f9,f5,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64 + ctx.f1.f64));
	// stfsx f9,r27,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f10,f8,f6,f10
	ctx.f10.f64 = double(float(-(ctx.f8.f64 * ctx.f6.f64 - ctx.f10.f64)));
	// fadds f9,f28,f24
	ctx.f9.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// stfsx f9,r26,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// stfsx f10,r25,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f31.f64));
	// stfsx f12,r24,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f11,f30
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f30.f64));
	// stfsx f12,r23,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,3532(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r6,r30,r6
	ctx.r6.u64 = ctx.r30.u64 + ctx.r6.u64;
	// add r5,r30,r5
	ctx.r5.u64 = ctx.r30.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5ee30
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5EE30;
loc_82D5EF28:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f54
	ctx.lr = 0x82D5EF30;
	__restfpr_24(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5EF38"))) PPC_WEAK_FUNC(sub_82D5EF38);
PPC_FUNC_IMPL(__imp__sub_82D5EF38) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,256
	ctx.r5.s64 = ctx.r11.s64 + 256;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-4656
	ctx.r4.s64 = ctx.r11.s64 + -4656;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5EF50"))) PPC_WEAK_FUNC(sub_82D5EF50);
PPC_FUNC_IMPL(__imp__sub_82D5EF50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D5EF58;
	__savegprlr_24(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5f038
	if (!ctx.cr6.gt) goto loc_82D5F038;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f5,-28552(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-7656(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7656);
	ctx.f6.f64 = double(temp.f32);
loc_82D5EF88:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r26,r8,12
	ctx.r26.s64 = ctx.r8.s64 * 12;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f8,f11,f0
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// fsubs f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f11,f13,f9
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// rlwinm r25,r9,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// rlwinm r24,r8,3,0,28
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fadds f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fadds f9,f12,f0
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fmuls f12,f8,f6
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// stfsx f12,r28,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fnmsubs f11,f10,f5,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f5.f64 - ctx.f11.f64)));
	// stfsx f11,r27,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// stfsx f12,r26,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fmuls f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfsx f0,r25,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f0,f9,f5,f13
	ctx.f0.f64 = double(float(-(ctx.f9.f64 * ctx.f5.f64 - ctx.f13.f64)));
	// stfsx f0,r24,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f9,f13
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,3532(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// add r6,r30,r6
	ctx.r6.u64 = ctx.r30.u64 + ctx.r6.u64;
	// add r5,r30,r5
	ctx.r5.u64 = ctx.r30.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5ef88
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5EF88;
loc_82D5F038:
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F040"))) PPC_WEAK_FUNC(sub_82D5F040);
PPC_FUNC_IMPL(__imp__sub_82D5F040) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,304
	ctx.r5.s64 = ctx.r11.s64 + 304;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-4272
	ctx.r4.s64 = ctx.r11.s64 + -4272;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F058"))) PPC_WEAK_FUNC(sub_82D5F058);
PPC_FUNC_IMPL(__imp__sub_82D5F058) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D5F060;
	__savegprlr_25(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5f140
	if (!ctx.cr6.gt) goto loc_82D5F140;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r27,-32255
	ctx.r27.s64 = -2113863680;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f5,-12288(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -12288);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,-7592(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -7592);
	ctx.f6.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f7,-7588(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -7588);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,-7584(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7584);
	ctx.f8.f64 = double(temp.f32);
loc_82D5F0A0:
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r9,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r8,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f12,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r25,r8,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f9,f0,f12
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// lfsx f11,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fadds f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fmuls f4,f0,f7
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fadds f10,f12,f9
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// fsubs f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// fmuls f9,f11,f7
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmuls f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// fmsubs f0,f0,f8,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f0,r28,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fmadds f0,f11,f8,f4
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + ctx.f4.f64));
	// fadds f11,f10,f13
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// stfs f11,0(r5)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfsx f0,r27,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f0,f10,f5,f13
	ctx.f0.f64 = double(float(-(ctx.f10.f64 * ctx.f5.f64 - ctx.f13.f64)));
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// fadds f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// stfsx f13,r26,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// stfsx f0,r25,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5f0a0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5F0A0;
loc_82D5F140:
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F148"))) PPC_WEAK_FUNC(sub_82D5F148);
PPC_FUNC_IMPL(__imp__sub_82D5F148) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,352
	ctx.r5.s64 = ctx.r11.s64 + 352;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-4008
	ctx.r4.s64 = ctx.r11.s64 + -4008;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F160"))) PPC_WEAK_FUNC(sub_82D5F160);
PPC_FUNC_IMPL(__imp__sub_82D5F160) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D5F168;
	__savegprlr_27(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5f1f4
	if (!ctx.cr6.gt) goto loc_82D5F1F4;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D5F188:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfsx f11,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// fadds f10,f12,f0
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// stfsx f0,r29,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f11,f13
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// stfsx f0,r28,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// fsubs f0,f10,f9
	ctx.f0.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfsx f0,r27,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f9,f10
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5f188
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5F188;
loc_82D5F1F4:
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F1F8"))) PPC_WEAK_FUNC(sub_82D5F1F8);
PPC_FUNC_IMPL(__imp__sub_82D5F1F8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,400
	ctx.r5.s64 = ctx.r11.s64 + 400;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-3744
	ctx.r4.s64 = ctx.r11.s64 + -3744;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F210"))) PPC_WEAK_FUNC(sub_82D5F210);
PPC_FUNC_IMPL(__imp__sub_82D5F210) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D5F218;
	__savegprlr_28(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5f2a4
	if (!ctx.cr6.gt) goto loc_82D5F2A4;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f9,-7656(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -7656);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f10.f64 = double(temp.f32);
loc_82D5F248:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fadds f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fadds f12,f11,f13
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fnmsubs f13,f11,f10,f13
	ctx.f13.f64 = double(float(-(ctx.f11.f64 * ctx.f10.f64 - ctx.f13.f64)));
	// stfsx f13,r29,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fmuls f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// stfsx f0,r28,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82d5f248
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5F248;
loc_82D5F2A4:
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F2A8"))) PPC_WEAK_FUNC(sub_82D5F2A8);
PPC_FUNC_IMPL(__imp__sub_82D5F2A8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,448
	ctx.r5.s64 = ctx.r11.s64 + 448;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-3568
	ctx.r4.s64 = ctx.r11.s64 + -3568;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F2C0"))) PPC_WEAK_FUNC(sub_82D5F2C0);
PPC_FUNC_IMPL(__imp__sub_82D5F2C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D5F2E0:
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfsx f12,r10,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r10,3532(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 3532);
	// add r5,r9,r5
	ctx.r5.u64 = ctx.r9.u64 + ctx.r5.u64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bdnz 0x82d5f2e0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D5F2E0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D5F318"))) PPC_WEAK_FUNC(sub_82D5F318);
PPC_FUNC_IMPL(__imp__sub_82D5F318) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,496
	ctx.r5.s64 = ctx.r11.s64 + 496;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-3392
	ctx.r4.s64 = ctx.r11.s64 + -3392;
	// b 0x82d77ea8
	sub_82D77EA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F330"))) PPC_WEAK_FUNC(sub_82D5F330);
PPC_FUNC_IMPL(__imp__sub_82D5F330) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D5F338;
	__savegprlr_22(ctx, base);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82d5f3b0
	if (!ctx.cr6.gt) goto loc_82D5F3B0;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D5F35C:
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// ble cr6,0x82d5f3a0
	if (!ctx.cr6.gt) goto loc_82D5F3A0;
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// subf r26,r3,r4
	ctx.r26.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subf r25,r6,r5
	ctx.r25.s64 = ctx.r5.s64 - ctx.r6.s64;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
loc_82D5F380:
	// lfsx f0,r26,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r11,r27,r11
	ctx.r11.u64 = ctx.r27.u64 + ctx.r11.u64;
	// stfsx f13,r25,r10
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r10.u32, temp.u32);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// add r10,r28,r10
	ctx.r10.u64 = ctx.r28.u64 + ctx.r10.u64;
	// bne 0x82d5f380
	if (!ctx.cr0.eq) goto loc_82D5F380;
loc_82D5F3A0:
	// addic. r24,r24,-1
	ctx.xer.ca = ctx.r24.u32 > 0;
	ctx.r24.s64 = ctx.r24.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// add r30,r22,r30
	ctx.r30.u64 = ctx.r22.u64 + ctx.r30.u64;
	// add r29,r23,r29
	ctx.r29.u64 = ctx.r23.u64 + ctx.r29.u64;
	// bne 0x82d5f35c
	if (!ctx.cr0.eq) goto loc_82D5F35C;
loc_82D5F3B0:
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F3B8"))) PPC_WEAK_FUNC(sub_82D5F3B8);
PPC_FUNC_IMPL(__imp__sub_82D5F3B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r10
	ctx.r31.u64 = ctx.r10.u64;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// neg r30,r8
	ctx.r30.s64 = -ctx.r8.s64;
	// blt cr6,0x82d5f3e0
	if (ctx.cr6.lt) goto loc_82D5F3E0;
	// mr r30,r8
	ctx.r30.u64 = ctx.r8.u64;
loc_82D5F3E0:
	// lwz r11,212(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// neg r10,r11
	ctx.r10.s64 = -ctx.r11.s64;
	// blt cr6,0x82d5f3f4
	if (ctx.cr6.lt) goto loc_82D5F3F4;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82D5F3F4:
	// cmpw cr6,r30,r10
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82d5f414
	if (!ctx.cr6.lt) goto loc_82D5F414;
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// lwz r31,220(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// bl 0x82d5f330
	ctx.lr = 0x82D5F410;
	sub_82D5F330(ctx, base);
	// b 0x82d5f430
	goto loc_82D5F430;
loc_82D5F414:
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// stw r9,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r9.u32);
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// lwz r9,220(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// bl 0x82d5f330
	ctx.lr = 0x82D5F430;
	sub_82D5F330(ctx, base);
loc_82D5F430:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D5F448"))) PPC_WEAK_FUNC(sub_82D5F448);
PPC_FUNC_IMPL(__imp__sub_82D5F448) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r10
	ctx.r31.u64 = ctx.r10.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// neg r30,r9
	ctx.r30.s64 = -ctx.r9.s64;
	// blt cr6,0x82d5f470
	if (ctx.cr6.lt) goto loc_82D5F470;
	// mr r30,r9
	ctx.r30.u64 = ctx.r9.u64;
loc_82D5F470:
	// lwz r11,220(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// neg r10,r11
	ctx.r10.s64 = -ctx.r11.s64;
	// blt cr6,0x82d5f484
	if (ctx.cr6.lt) goto loc_82D5F484;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82D5F484:
	// cmpw cr6,r30,r10
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82d5f4a4
	if (!ctx.cr6.lt) goto loc_82D5F4A4;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// lwz r11,212(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82d5f330
	ctx.lr = 0x82D5F4A0;
	sub_82D5F330(ctx, base);
	// b 0x82d5f4c0
	goto loc_82D5F4C0;
loc_82D5F4A4:
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// stw r9,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r9.u32);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// lwz r8,212(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// bl 0x82d5f330
	ctx.lr = 0x82D5F4C0;
	sub_82D5F330(ctx, base);
loc_82D5F4C0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D5F4D8"))) PPC_WEAK_FUNC(sub_82D5F4D8);
PPC_FUNC_IMPL(__imp__sub_82D5F4D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D5F4E0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D5F500;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D5F518;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F520"))) PPC_WEAK_FUNC(sub_82D5F520);
PPC_FUNC_IMPL(__imp__sub_82D5F520) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D5F528;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D5F550;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D5F570;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F578"))) PPC_WEAK_FUNC(sub_82D5F578);
PPC_FUNC_IMPL(__imp__sub_82D5F578) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// bl 0x82d0c350
	ctx.lr = 0x82D5F59C;
	sub_82D0C350(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82d0c350
	ctx.lr = 0x82D5F5A8;
	sub_82D0C350(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D5F5C0"))) PPC_WEAK_FUNC(sub_82D5F5C0);
PPC_FUNC_IMPL(__imp__sub_82D5F5C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82d0c300
	ctx.lr = 0x82D5F5DC;
	sub_82D0C300(ctx, base);
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// bl 0x82d0c300
	ctx.lr = 0x82D5F5E4;
	sub_82D0C300(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D5F5F8"))) PPC_WEAK_FUNC(sub_82D5F5F8);
PPC_FUNC_IMPL(__imp__sub_82D5F5F8) {
	PPC_FUNC_PROLOGUE();
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r11,r11,-2856
	ctx.r11.s64 = ctx.r11.s64 + -2856;
	// lwz r9,56(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// addi r11,r11,21752
	ctx.r11.s64 = ctx.r11.s64 + 21752;
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// beq cr6,0x82d5f624
	if (ctx.cr6.eq) goto loc_82D5F624;
	// addi r5,r11,4
	ctx.r5.s64 = ctx.r11.s64 + 4;
loc_82D5F624:
	// addi r4,r11,8
	ctx.r4.s64 = ctx.r11.s64 + 8;
	// lwz r8,64(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// lwz r7,68(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 68);
	// lwz r6,72(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_82D5F640"))) PPC_WEAK_FUNC(sub_82D5F640);
PPC_FUNC_IMPL(__imp__sub_82D5F640) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82d5f6c4
	if (!ctx.cr6.eq) goto loc_82D5F6C4;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bgt cr6,0x82d5f6c4
	if (ctx.cr6.gt) goto loc_82D5F6C4;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// beq cr6,0x82d5f69c
	if (ctx.cr6.eq) goto loc_82D5F69C;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82d5f69c
	if (ctx.cr6.eq) goto loc_82D5F69C;
	// lwz r10,152(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 152);
	// rlwinm. r10,r10,0,7,7
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000000;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82d5f6c4
	if (!ctx.cr0.eq) goto loc_82D5F6C4;
loc_82D5F69C:
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// bl 0x82d0ebb8
	ctx.lr = 0x82D5F6A8;
	sub_82D0EBB8(ctx, base);
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// ble cr6,0x82d5f6c4
	if (!ctx.cr6.gt) goto loc_82D5F6C4;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpw cr6,r11,r3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r3.s32, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bgt cr6,0x82d5f6c8
	if (ctx.cr6.gt) goto loc_82D5F6C8;
loc_82D5F6C4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82D5F6C8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D5F6E0"))) PPC_WEAK_FUNC(sub_82D5F6E0);
PPC_FUNC_IMPL(__imp__sub_82D5F6E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D5F6E8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82d5f640
	ctx.lr = 0x82D5F6FC;
	sub_82D5F640(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d5f70c
	if (!ctx.cr0.eq) goto loc_82D5F70C;
loc_82D5F704:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82d5f75c
	goto loc_82D5F75C;
loc_82D5F70C:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82d5f758
	if (ctx.cr6.eq) goto loc_82D5F758;
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d5f758
	if (ctx.cr6.eq) goto loc_82D5F758;
	// lwz r11,152(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 152);
	// rlwinm. r11,r11,0,15,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d5f758
	if (ctx.cr0.eq) goto loc_82D5F758;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82d5f704
	if (ctx.cr0.eq) goto loc_82D5F704;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D5F750;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d5f704
	if (ctx.cr0.eq) goto loc_82D5F704;
loc_82D5F758:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82D5F75C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5F768"))) PPC_WEAK_FUNC(sub_82D5F768);
PPC_FUNC_IMPL(__imp__sub_82D5F768) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D5F770;
	__savegprlr_22(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r5
	ctx.r24.u64 = ctx.r5.u64;
	// li r23,0
	ctx.r23.s64 = 0;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r26,r23
	ctx.r26.u64 = ctx.r23.u64;
	// lwz r11,152(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 152);
	// mr r22,r23
	ctx.r22.u64 = ctx.r23.u64;
	// rlwinm. r11,r11,0,10,10
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x200000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d5f7a4
	if (ctx.cr0.eq) goto loc_82D5F7A4;
	// lwz r11,148(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 148);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bgt cr6,0x82d5f7bc
	if (ctx.cr6.gt) goto loc_82D5F7BC;
loc_82D5F7A4:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82d5f6e0
	ctx.lr = 0x82D5F7B4;
	sub_82D5F6E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d5f7c4
	if (!ctx.cr0.eq) goto loc_82D5F7C4;
loc_82D5F7BC:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82d5fa7c
	goto loc_82D5FA7C;
loc_82D5F7C4:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// addi r29,r11,4
	ctx.r29.s64 = ctx.r11.s64 + 4;
	// lwz r30,0(r29)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82d0ebb8
	ctx.lr = 0x82D5F7DC;
	sub_82D0EBB8(ctx, base);
	// rotlwi r11,r30,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r30.u32, 1);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// andc r11,r28,r11
	ctx.r11.u64 = ctx.r28.u64 & ~ctx.r11.u64;
	// addi r5,r1,136
	ctx.r5.s64 = ctx.r1.s64 + 136;
	// addi r4,r1,132
	ctx.r4.s64 = ctx.r1.s64 + 132;
	// divw r30,r30,r28
	ctx.r30.s32 = ctx.r30.s32 / ctx.r28.s32;
	// twllei r28,0
	// twlgei r11,-1
	// bl 0x82d1f0d0
	ctx.lr = 0x82D5F80C;
	sub_82D1F0D0(ctx, base);
	// lwz r11,12(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82d5f824
	if (ctx.cr6.lt) goto loc_82D5F824;
	// beq cr6,0x82d5f88c
	if (ctx.cr6.eq) goto loc_82D5F88C;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bge cr6,0x82d5fa54
	if (!ctx.cr6.lt) goto loc_82D5FA54;
loc_82D5F824:
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// lwz r9,132(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// bne cr6,0x82d5f960
	if (!ctx.cr6.eq) goto loc_82D5F960;
	// mr r25,r10
	ctx.r25.u64 = ctx.r10.u64;
	// cmpw cr6,r28,r9
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r9.s32, ctx.xer);
	// mullw r26,r11,r30
	ctx.r26.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// bne cr6,0x82d5fa24
	if (!ctx.cr6.eq) goto loc_82D5FA24;
	// mullw r8,r10,r28
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	// cmpw cr6,r11,r8
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x82d5fa24
	if (!ctx.cr6.eq) goto loc_82D5FA24;
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// bne cr6,0x82d5fa24
	if (!ctx.cr6.eq) goto loc_82D5FA24;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mullw r7,r8,r28
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r28.s32);
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// bne cr6,0x82d5fa24
	if (!ctx.cr6.eq) goto loc_82D5FA24;
	// cmpw cr6,r10,r8
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x82d5fa24
	if (!ctx.cr6.eq) goto loc_82D5FA24;
	// lwz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmpw cr6,r26,r11
	ctx.cr6.compare<int32_t>(ctx.r26.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82d5f968
	if (ctx.cr6.eq) goto loc_82D5F968;
	// b 0x82d5fa24
	goto loc_82D5FA24;
loc_82D5F88C:
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// stw r6,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r6.u32);
	// mullw r6,r8,r30
	ctx.r6.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r30.s32);
	// stw r5,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r5.u32);
	// lwz r9,132(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// stw r24,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r24.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// stw r23,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r23.u32);
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D5F8D8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq 0x82d5fa24
	if (ctx.cr0.eq) goto loc_82D5FA24;
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r27,24(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mullw r5,r11,r30
	ctx.r5.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// lwz r26,20(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r25,16(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r8,128(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r7,136(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r6,132(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r4,4(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// bl 0x82d20d38
	ctx.lr = 0x82D5F910;
	sub_82D20D38(ctx, base);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r5,8(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mullw r4,r11,r28
	ctx.r4.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// bl 0x82d0f150
	ctx.lr = 0x82D5F928;
	sub_82D0F150(ctx, base);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// bl 0x82d0efb8
	ctx.lr = 0x82D5F940;
	sub_82D0EFB8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82d0e108
	ctx.lr = 0x82D5F94C;
	sub_82D0E108(ctx, base);
	// mr. r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// beq 0x82d5fa24
	if (ctx.cr0.eq) goto loc_82D5FA24;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r5,r11,-2856
	ctx.r5.s64 = ctx.r11.s64 + -2856;
	// b 0x82d5fa40
	goto loc_82D5FA40;
loc_82D5F960:
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
	// mullw r25,r11,r30
	ctx.r25.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
loc_82D5F968:
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stw r23,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r23.u32);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// lwz r27,16(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// lwz r23,12(r31)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r8,4(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// stw r24,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r24.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// mullw r5,r8,r30
	ctx.r5.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r30.s32);
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// stw r27,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r27.u32);
	// stw r23,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r23.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D5F9AC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq 0x82d5fa24
	if (ctx.cr0.eq) goto loc_82D5FA24;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// lwz r27,24(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// lwz r26,20(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r22,16(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r8,128(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r6,132(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r5,8(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// bl 0x82d20d38
	ctx.lr = 0x82D5F9E0;
	sub_82D20D38(ctx, base);
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,4(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// mullw r5,r11,r28
	ctx.r5.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// bl 0x82d0f150
	ctx.lr = 0x82D5F9F8;
	sub_82D0F150(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r6,r22
	ctx.r6.u64 = ctx.r22.u64;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// bl 0x82d0efb8
	ctx.lr = 0x82D5FA10;
	sub_82D0EFB8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82d0e108
	ctx.lr = 0x82D5FA1C;
	sub_82D0E108(ctx, base);
	// mr. r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// bne 0x82d5fa38
	if (!ctx.cr0.eq) goto loc_82D5FA38;
loc_82D5FA24:
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82d0c300
	ctx.lr = 0x82D5FA2C;
	sub_82D0C300(ctx, base);
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82d0c300
	ctx.lr = 0x82D5FA34;
	sub_82D0C300(ctx, base);
	// b 0x82d5f7bc
	goto loc_82D5F7BC;
loc_82D5FA38:
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r5,r11,-2784
	ctx.r5.s64 = ctx.r11.s64 + -2784;
loc_82D5FA40:
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// li r3,80
	ctx.r3.s64 = 80;
	// addi r4,r10,544
	ctx.r4.s64 = ctx.r10.s64 + 544;
	// bl 0x82d223c8
	ctx.lr = 0x82D5FA50;
	sub_82D223C8(ctx, base);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
loc_82D5FA54:
	// addi r5,r26,8
	ctx.r5.s64 = ctx.r26.s64 + 8;
	// stw r22,64(r26)
	PPC_STORE_U32(ctx.r26.u32 + 64, ctx.r22.u32);
	// addi r4,r23,8
	ctx.r4.s64 = ctx.r23.s64 + 8;
	// stw r23,68(r26)
	PPC_STORE_U32(ctx.r26.u32 + 68, ctx.r23.u32);
	// addi r3,r22,8
	ctx.r3.s64 = ctx.r22.s64 + 8;
	// stw r28,72(r26)
	PPC_STORE_U32(ctx.r26.u32 + 72, ctx.r28.u32);
	// bl 0x82d0c750
	ctx.lr = 0x82D5FA70;
	sub_82D0C750(ctx, base);
	// lwz r11,52(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 52);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stw r11,52(r26)
	PPC_STORE_U32(ctx.r26.u32 + 52, ctx.r11.u32);
loc_82D5FA7C:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5FA88"))) PPC_WEAK_FUNC(sub_82D5FA88);
PPC_FUNC_IMPL(__imp__sub_82D5FA88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D5FA90;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// addi r4,r11,560
	ctx.r4.s64 = ctx.r11.s64 + 560;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// bl 0x82d0e650
	ctx.lr = 0x82D5FAB0;
	sub_82D0E650(ctx, base);
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// stw r30,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r30.u32);
	// stw r29,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r29.u32);
	// stw r28,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r28.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D5FAC8"))) PPC_WEAK_FUNC(sub_82D5FAC8);
PPC_FUNC_IMPL(__imp__sub_82D5FAC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82d0c2a0
	ctx.lr = 0x82D5FAE0;
	sub_82D0C2A0(ctx, base);
	// stw r31,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r31.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D5FAF8"))) PPC_WEAK_FUNC(sub_82D5FAF8);
PPC_FUNC_IMPL(__imp__sub_82D5FAF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D5FB00;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D5FB08;
	__savefpr_14(ctx, base);
	// stwu r1,-624(r1)
	ea = -624 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82d60968
	if (!ctx.cr6.lt) goto loc_82D60968;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r10,288(r1)
	PPC_STORE_U32(ctx.r1.u32 + 288, ctx.r10.u32);
	// subf r10,r8,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r8.s64;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// stw r10,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r10.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D5FB3C:
	// mulli r8,r6,3
	ctx.r8.s64 = ctx.r6.s64 * 3;
	// lfs f12,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// add r5,r8,r7
	ctx.r5.u64 = ctx.r8.u64 + ctx.r7.u64;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f27,f10,f12
	ctx.f27.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// rlwinm r24,r5,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// rlwinm r26,r7,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f10,f11,f9
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// rlwinm r31,r7,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// add r23,r31,r10
	ctx.r23.u64 = ctx.r31.u64 + ctx.r10.u64;
	// add r22,r30,r10
	ctx.r22.u64 = ctx.r30.u64 + ctx.r10.u64;
	// lfsx f29,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// add r27,r6,r7
	ctx.r27.u64 = ctx.r6.u64 + ctx.r7.u64;
	// lfsx f2,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// mulli r8,r7,12
	ctx.r8.s64 = ctx.r7.s64 * 12;
	// lfsx f28,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f20,f29,f2
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// lfsx f1,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f2,f2,f29
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// lfsx f8,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f29,f1,f28
	ctx.f29.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// lfsx f9,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// lfsx f26,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f28,f8,f9
	ctx.f28.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// lfsx f7,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// lfsx f25,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fadds f8,f26,f7
	ctx.f8.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// mulli r20,r27,12
	ctx.r20.s64 = ctx.r27.s64 * 12;
	// lfsx f6,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// lfsx f24,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f5,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f26,f25,f6
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// fsubs f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f25.f64));
	// lfsx f31,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f25,f5,f24
	ctx.f25.f64 = double(float(ctx.f5.f64 - ctx.f24.f64));
	// lfsx f30,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f5,f24,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// lfsx f22,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f24,f22,f31
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f31.f64));
	// lfsx f21,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r9,r7,20
	ctx.r9.s64 = ctx.r7.s64 * 20;
	// fsubs f31,f31,f22
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f22.f64));
	// stfs f31,140(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fsubs f31,f30,f21
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f31,f21,f30
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f31,188(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfsx f4,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// add r21,r9,r10
	ctx.r21.u64 = ctx.r9.u64 + ctx.r10.u64;
	// mulli r5,r6,5
	ctx.r5.s64 = ctx.r6.s64 * 5;
	// lfsx f23,r4,r21
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r21.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f31,f4,f23
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f23.f64));
	// fadds f4,f23,f4
	ctx.f4.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// stfs f4,56(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// add r19,r5,r7
	ctx.r19.u64 = ctx.r5.u64 + ctx.r7.u64;
	// lfsx f4,r3,r21
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r21.u32);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r25,r6,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f30,f4,f3
	ctx.f30.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// rlwinm r17,r27,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// rlwinm r29,r6,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// stfs f30,136(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// rlwinm r16,r19,2,0,29
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f4,116(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// add r19,r25,r7
	ctx.r19.u64 = ctx.r25.u64 + ctx.r7.u64;
	// add r15,r29,r7
	ctx.r15.u64 = ctx.r29.u64 + ctx.r7.u64;
	// rlwinm r29,r6,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r17,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r17.u32);
	// mulli r5,r6,20
	ctx.r5.s64 = ctx.r6.s64 * 20;
	// rlwinm r28,r6,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r19,r19,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f14,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r18,r15,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r15.u32 | (ctx.r15.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// add r14,r16,r3
	ctx.r14.u64 = ctx.r16.u64 + ctx.r3.u64;
	// lfsx f14,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r16,r16,r4
	ctx.r16.u64 = ctx.r16.u64 + ctx.r4.u64;
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f23,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f14,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// stw r14,312(r1)
	PPC_STORE_U32(ctx.r1.u32 + 312, ctx.r14.u32);
	// stw r16,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r16.u32);
	// lfsx f30,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f14,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r16,r17,r4
	ctx.r16.u64 = ctx.r17.u64 + ctx.r4.u64;
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f14,f23,f30
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// lfsx f21,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// lfsx f22,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f4,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfsx f19,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfsx f18,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f21,f4,f19
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f19.f64));
	// lfsx f3,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f4.f64));
	// fsubs f4,f18,f3
	ctx.f4.f64 = double(float(ctx.f18.f64 - ctx.f3.f64));
	// stfs f4,16(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f18.f64));
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// stw r16,296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 296, ctx.r16.u32);
	// lfs f4,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f4.f64 = double(temp.f32);
	// fadds f18,f16,f4
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f4.f64));
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f16.f64));
	// stfs f4,76(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f4,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f4
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f4.f64));
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r17,112(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// fadds f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,72(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f18,f15
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f18,f21,f14
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f19,f30
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// fsubs f15,f22,f3
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f3.f64));
	// fsubs f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// fadds f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// stfs f3,192(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f3,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f3.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fadds f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f23.f64));
	// stfs f3,124(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fadds f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// stfs f21,128(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f30,152(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f3,f18,f0
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f3,224(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f3,f17,f0
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f3,220(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f3,f16,f0
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f3,200(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f3,f15,f0
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f3,216(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f3,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f30.f64 = double(temp.f32);
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f21,f3,f23
	ctx.f21.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// rlwinm r16,r7,1,0,30
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r15,r15,3,0,28
	ctx.r15.u64 = __builtin_rotateleft64(ctx.r15.u32 | (ctx.r15.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f19,f30,f22
	ctx.f19.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// add r16,r16,r6
	ctx.r16.u64 = ctx.r16.u64 + ctx.r6.u64;
	// fadds f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f23.f64));
	// stfs f3,120(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f3,f30,f22
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// stfs f3,72(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmuls f3,f21,f0
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// stfs f3,308(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// mulli r17,r7,3
	ctx.r17.s64 = ctx.r7.s64 * 3;
	// stw r15,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r15.u32);
	// lfs f30,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f30.f64 = double(temp.f32);
	// stw r16,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r16.u32);
	// fmuls f3,f19,f0
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f3,272(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// add r15,r8,r29
	ctx.r15.u64 = ctx.r8.u64 + ctx.r29.u64;
	// lfs f3,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f3.f64 = double(temp.f32);
	// add r14,r17,r6
	ctx.r14.u64 = ctx.r17.u64 + ctx.r6.u64;
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfs f3,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f3.f64 = double(temp.f32);
	// add r16,r31,r5
	ctx.r16.u64 = ctx.r31.u64 + ctx.r5.u64;
	// rlwinm r14,r14,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f23,f30,f3
	ctx.f23.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// fadds f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// stfs f3,76(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// rlwinm r17,r27,3,0,28
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r15,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r15.u32);
	// add r15,r8,r5
	ctx.r15.u64 = ctx.r8.u64 + ctx.r5.u64;
	// lfsx f22,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stw r16,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r16.u32);
	// stw r14,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r14.u32);
	// stw r15,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r15.u32);
	// add r15,r8,r28
	ctx.r15.u64 = ctx.r8.u64 + ctx.r28.u64;
	// fmuls f3,f23,f0
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f3,264(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f3,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f30,f3,f4
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// lfsx f23,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfsx f3,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,196(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// stw r15,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r15.u32);
	// lfsx f17,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// stfs f4,244(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfsx f4,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// rlwinm r14,r14,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r14,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r14.u32);
	// lwz r14,168(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lwz r16,184(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lfsx f30,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f21,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f19,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lwz r14,96(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfsx f15,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r16,96(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,104(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfsx f14,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r16,160(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lfsx f14,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f14,f4,f3
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fadds f3,f22,f23
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f22,f18,f19
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r16,r7,5
	ctx.r16.s64 = ctx.r7.s64 * 5;
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// add r14,r16,r6
	ctx.r14.u64 = ctx.r16.u64 + ctx.r6.u64;
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f21
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lwz r16,20(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fsubs f21,f18,f22
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// fsubs f15,f17,f19
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// add r15,r26,r6
	ctx.r15.u64 = ctx.r26.u64 + ctx.r6.u64;
	// rlwinm r16,r16,3,0,28
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r16.u32 | (ctx.r16.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,180(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f22,f17,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f22,132(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// rlwinm r15,r15,2,0,29
	ctx.r15.u64 = __builtin_rotateleft64(ctx.r15.u32 | (ctx.r15.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f18,f4,f30
	ctx.f18.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// stw r16,40(r1)
	PPC_STORE_U32(ctx.r1.u32 + 40, ctx.r16.u32);
	// rlwinm r16,r27,4,0,27
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r27,r27,20
	ctx.r27.s64 = ctx.r27.s64 * 20;
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f4,164(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stw r15,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r15.u32);
	// fmuls f22,f21,f0
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// stfs f22,276(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f22,228(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// add r15,r9,r29
	ctx.r15.u64 = ctx.r9.u64 + ctx.r29.u64;
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// stw r27,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r27.u32);
	// add r27,r9,r28
	ctx.r27.u64 = ctx.r9.u64 + ctx.r28.u64;
	// fadds f4,f22,f14
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f4,68(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fsubs f19,f14,f22
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f4,f21,f3
	ctx.f4.f64 = double(float(ctx.f21.f64 + ctx.f3.f64));
	// stfs f4,156(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f21,f3
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f3.f64));
	// lfs f4,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// stw r27,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r27.u32);
	// rlwinm r27,r14,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// fadds f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// stfs f4,64(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f23,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// stw r27,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r27.u32);
	// fmuls f4,f19,f0
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f4,232(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f4,f18,f0
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f4,88(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f4,f17,f0
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f4,172(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f4,f15,f0
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f4,240(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lwz r27,24(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// add r14,r27,r4
	ctx.r14.u64 = ctx.r27.u64 + ctx.r4.u64;
	// add r27,r27,r3
	ctx.r27.u64 = ctx.r27.u64 + ctx.r3.u64;
	// stw r14,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r14.u32);
	// stw r27,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r27.u32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lwz r27,144(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// add r27,r27,r4
	ctx.r27.u64 = ctx.r27.u64 + ctx.r4.u64;
	// lfsx f22,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stw r27,44(r1)
	PPC_STORE_U32(ctx.r1.u32 + 44, ctx.r27.u32);
	// lwz r27,104(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfsx f4,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lwz r27,40(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lfsx f3,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// add r27,r30,r5
	ctx.r27.u64 = ctx.r30.u64 + ctx.r5.u64;
	// lfsx f30,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lwz r14,40(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lfsx f15,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f19,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f18,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f14,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f21,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,24(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f4.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f4,f4,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f15.f64));
	// fadds f15,f30,f3
	ctx.f15.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fsubs f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fadds f30,f22,f23
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fsubs f22,f21,f19
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lwz r14,32(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,44(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,100(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// fsubs f14,f16,f4
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// fadds f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f16.f64));
	// stfs f4,60(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// lfs f4,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f16.f64));
	// stfs f4,48(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f16,f23,f3
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f3.f64));
	// fadds f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f3,52(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fadds f3,f18,f21
	ctx.f3.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// stfs f3,284(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmuls f4,f17,f0
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f4,268(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f4,f14,f0
	ctx.f4.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f4,236(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fadds f4,f30,f15
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// stfs f4,252(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f17,f30,f15
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// fadds f30,f19,f22
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f30,36(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f15,f22,f19
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fsubs f14,f21,f18
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f19,f23,f22
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f30,f21
	ctx.f18.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,20(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lwz r14,144(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f17,208(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f17,256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f17,248(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f17,f14,f0
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stw r14,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r14.u32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f30,300(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// stfs f23,304(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fmuls f23,f18,f0
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f23,108(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f14,f4,f26
	ctx.f14.f64 = double(float(ctx.f4.f64 + ctx.f26.f64));
	// lfs f23,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f23,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f11.f64));
	// lfs f19,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f18,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f1.f64));
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fadds f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f8.f64));
	// fadds f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f9.f64));
	// lfs f4,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfsx f4,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,84(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lwz r14,92(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lfs f4,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// stfs f23,0(r3)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f22,0(r4)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfsx f21,r25,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// stfsx f19,r25,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// stfsx f18,r10,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f17,r29,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// stfsx f16,r29,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f3,r28,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r5,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f22.f64 = double(temp.f32);
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fadds f3,f4,f30
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// fsubs f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// fadds f30,f3,f22
	ctx.f30.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// fadds f23,f4,f21
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f21.f64));
	// fsubs f4,f4,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f21.f64));
	// fsubs f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// fmuls f22,f4,f0
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f4,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfsx f4,r5,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f21,f23,f4
	ctx.f21.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// lfs f4,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// stfsx f14,r28,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f19,f4
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fmuls f16,f18,f4
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// lfs f4,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// fadds f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fmadds f18,f18,f4,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f17.f64));
	// stfsx f18,r10,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f19,f4,f16
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 - ctx.f16.f64));
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfs f19,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f4,f21
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// fmuls f17,f19,f21
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f19,f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 + ctx.f18.f64));
	// stfsx f19,r10,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f4,f21,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f21.f64 - ctx.f17.f64));
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,292(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// fadds f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f12.f64));
	// lfs f21,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f21,f4
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f4.f64));
	// fmuls f17,f19,f4
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f4,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fmadds f19,f19,f4,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 + ctx.f18.f64));
	// stfsx f19,r8,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f21,f4,f17
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 - ctx.f17.f64));
	// stfsx f4,r8,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f4.f64 = double(temp.f32);
	// fadds f19,f4,f25
	ctx.f19.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// lfs f4,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f4.f64 = double(temp.f32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f4,f17
	ctx.f17.f64 = double(float(ctx.f4.f64 + ctx.f17.f64));
	// lfs f4,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f4.f64 = double(temp.f32);
	// fadds f16,f4,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 + ctx.f16.f64));
	// lfs f4,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// fadds f15,f4,f7
	ctx.f15.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// lfs f4,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f4.f64 = double(temp.f32);
	// fadds f14,f4,f28
	ctx.f14.f64 = double(float(ctx.f4.f64 + ctx.f28.f64));
	// lfs f4,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f30,f13,f4
	ctx.f4.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// stfs f4,100(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f30,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f30.f64 = double(temp.f32);
	// lfs f4,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f4,f13,f30
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// stfs f4,56(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f4,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f6
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f21,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f30,f21,f4
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f4.f64));
	// fmuls f4,f18,f4
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// fmadds f30,f18,f19,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 + ctx.f30.f64));
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f21,f19,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f19.f64 - ctx.f4.f64));
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f30,f18,f19
	ctx.f30.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f3.f64));
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fadds f3,f18,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// fmuls f18,f4,f17
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// fmuls f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// fmadds f21,f21,f16,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64 + ctx.f18.f64));
	// stfsx f21,r20,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f4,f16,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f16.f64 - ctx.f17.f64));
	// stfsx f4,r20,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f4,f15
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f15.f64));
	// lfs f21,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f21,f15
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f15.f64));
	// fmadds f21,f21,f14,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f14.f64 + ctx.f18.f64));
	// lwz r10,184(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// fmsubs f4,f4,f14,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f14.f64 - ctx.f17.f64));
	// lfs f16,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f16.f64 = double(temp.f32);
	// addi r8,r11,32
	ctx.r8.s64 = ctx.r11.s64 + 32;
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// addi r5,r11,36
	ctx.r5.s64 = ctx.r11.s64 + 36;
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,212(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// lfs f4,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f4,f30
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmuls f17,f21,f30
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f21,f21,f30,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 + ctx.f18.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f4,f30,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 - ctx.f17.f64));
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f4.f64 = double(temp.f32);
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// lfs f30,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f4,f19
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f19,f30,f19
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f30,f30,f3,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f3.f64 + ctx.f21.f64));
	// stfsx f30,r27,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f4,f3,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 - ctx.f19.f64));
	// lfs f3,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f12,f3,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// lfs f3,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f10,f3,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// lfs f30,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f30.f64 = double(temp.f32);
	// lfs f3,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f3,f3,f13,f30
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// lfs f21,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f21.f64 = double(temp.f32);
	// lfs f30,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f30,f30,f13,f21
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f21.f64)));
	// lfs f21,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f8,f21,f13,f8
	ctx.f8.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// lfs f21,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f9,f21,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// stfsx f4,r27,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f12,f18
	ctx.f19.f64 = double(float(ctx.f12.f64 + ctx.f18.f64));
	// fsubs f12,f12,f18
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f18.f64));
	// fadds f18,f10,f17
	ctx.f18.f64 = double(float(ctx.f10.f64 + ctx.f17.f64));
	// fsubs f10,f10,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f17.f64));
	// fadds f17,f3,f16
	ctx.f17.f64 = double(float(ctx.f3.f64 + ctx.f16.f64));
	// fsubs f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f16.f64));
	// fadds f16,f30,f15
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// fsubs f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// fsubs f15,f8,f14
	ctx.f15.f64 = double(float(ctx.f8.f64 - ctx.f14.f64));
	// fadds f8,f8,f14
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 - ctx.f14.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fadds f9,f9,f14
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f14.f64));
	// fmuls f14,f4,f19
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// fmadds f21,f21,f18,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f18.f64 + ctx.f14.f64));
	// stfsx f21,r26,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f4,f18,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f18.f64 - ctx.f19.f64));
	// stfsx f4,r26,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f4,f12
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmuls f12,f21,f12
	ctx.f12.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmadds f21,f21,f10,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f19.f64));
	// stfsx f21,r9,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f4,f10,f12
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 - ctx.f12.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f12,f17
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// lfs f10,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f21,f10,f17
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// fmadds f10,f10,f16,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f16.f64 + ctx.f4.f64));
	// stfsx f10,r24,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f16,f21
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f16.f64 - ctx.f21.f64));
	// stfsx f12,r24,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,40(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lfs f10,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f12,f3
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f3,f10,f3
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f21,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f10,f10,f30,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 + ctx.f4.f64));
	// stfsx f10,r3,r21
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + ctx.r21.u32, temp.u32);
	// fmsubs f12,f12,f30,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f3.f64));
	// stfsx f12,r4,r21
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + ctx.r21.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f12,f15
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f15.f64));
	// fmuls f30,f10,f15
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f15.f64));
	// lfs f4,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f10,f10,f4,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f3.f64));
	// lfs f3,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f12,f12,f4,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 - ctx.f30.f64));
	// lfs f4,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f4,f13,f24
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f24.f64)));
	// lfs f30,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f10,r17,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fnmsubs f3,f3,f13,f30
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// stfsx f12,r17,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f30.f64 = double(temp.f32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f30,f30,f13,f20
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f20.f64)));
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f19,f12,f8
	ctx.f19.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmuls f18,f10,f8
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f24,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f1,f24,f13,f1
	ctx.f1.f64 = double(float(-(ctx.f24.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// lfs f20,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f8,f4,f20
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f20.f64));
	// fadds f4,f4,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f20.f64));
	// lfs f20,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f24,f3,f21
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f21.f64));
	// fadds f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f21.f64));
	// fsubs f21,f30,f20
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// fadds f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f20.f64));
	// lfs f20,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f10,f10,f9,f19
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 + ctx.f19.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f9,f18
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 - ctx.f18.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f10,f1,f20
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f20.f64));
	// fadds f9,f1,f20
	ctx.f9.f64 = double(float(ctx.f1.f64 + ctx.f20.f64));
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f12,f8
	ctx.f20.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lwz r9,160(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// fmuls f8,f1,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmadds f1,f1,f24,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64 + ctx.f20.f64));
	// stfsx f1,r23,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f24,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f24.f64 - ctx.f8.f64));
	// stfsx f12,r23,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f1,f12,f4
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmuls f4,f8,f4
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmadds f8,f8,f3,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 + ctx.f1.f64));
	// stfsx f8,r22,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f3,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 - ctx.f4.f64));
	// stfsx f12,r22,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f12,f21
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// fmuls f3,f8,f21
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// lfs f1,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f8,f8,f10,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 + ctx.f4.f64));
	// stfsx f8,r9,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f10,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f3.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f12,f30
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f8,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f10,f30
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fnmsubs f8,f8,f13,f26
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// lwz r9,28(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// fmadds f12,f12,f9,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f4.f64));
	// lfs f4,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f5,f1,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fnmsubs f11,f4,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// lfs f4,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f7,f4,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f1,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f1.f64 = double(temp.f32);
	// lfs f30,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f10,f9,f3
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f3.f64));
	// lfs f3,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f4,f8,f3
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fadds f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// lwz r9,168(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lfs f9,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f3,f5,f1
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// lfs f26,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f9,f9,f13,f27
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f27.f64)));
	// lfs f27,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f27.f64 = double(temp.f32);
	// fadds f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f24,f12,f4
	ctx.f24.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmuls f4,f10,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// fsubs f1,f9,f30
	ctx.f1.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// fadds f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// fsubs f30,f11,f27
	ctx.f30.f64 = double(float(ctx.f11.f64 - ctx.f27.f64));
	// fadds f11,f11,f27
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f27.f64));
	// fadds f27,f7,f26
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// fmadds f10,f10,f3,f24
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f24.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f3,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 - ctx.f4.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f12,f8
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmuls f8,f10,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f3,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f10,f10,f5,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 + ctx.f4.f64));
	// stfsx f10,r16,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f5,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 - ctx.f8.f64));
	// stfsx f12,r16,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f12,f1
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// fmuls f5,f10,f1
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f10,f10,f30,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 + ctx.f8.f64));
	// stfsx f10,r31,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f30,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f5.f64));
	// stfsx f12,r31,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f12,f9
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmuls f9,f10,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f5,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f5,f5,f13,f29
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// fmadds f10,f10,f11,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f8.f64));
	// lfs f8,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f12,f12,f11,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f9.f64));
	// lfs f9,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f9,f9,f13,f28
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f28.f64)));
	// stfsx f10,r30,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fnmsubs f8,f8,f13,f6
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// lfs f6,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f6.f64 = double(temp.f32);
	// stfsx f12,r30,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fnmsubs f6,f6,f13,f2
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// lfs f2,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f10,f7,f26
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f28,f12,f27
	ctx.f28.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// lfs f7,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f11,f27
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// fnmsubs f7,f7,f13,f25
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// fadds f4,f9,f3
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// fsubs f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f3.f64));
	// fadds f3,f8,f2
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fsubs f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// fmadds f11,f11,f4,f28
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f4.f64 + ctx.f28.f64));
	// stfsx f11,r18,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f4,f27
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 - ctx.f27.f64));
	// stfsx f12,r18,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fadds f2,f7,f1
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f12,f10
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fmuls f10,f11,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f30,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// lwz r9,16(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fadds f1,f6,f30
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// lfs f29,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// lwz r31,288(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	// fadds f30,f5,f29
	ctx.f30.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fsubs f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f29.f64));
	// fmadds f11,f11,f9,f4
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f4.f64));
	// stfsx f11,r15,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 - ctx.f10.f64));
	// stfsx f12,r15,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f3
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f9,f11,f3
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmadds f11,f11,f2,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f10.f64));
	// stfsx f11,r19,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f2,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 - ctx.f9.f64));
	// stfsx f12,r19,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f8
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmuls f9,f11,f8
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// fmadds f11,f11,f7,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f10.f64));
	// stfsx f11,r9,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f7,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 - ctx.f9.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,280(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// fmuls f10,f12,f1
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// lfs f9,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f9,f9,f13,f31
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// fmadds f10,f11,f30,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f10.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmuls f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// lwz r31,296(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// lfs f10,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f10,f23,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// lwz r9,176(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// fadds f7,f9,f22
	ctx.f7.f64 = double(float(ctx.f9.f64 + ctx.f22.f64));
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// fsubs f9,f9,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f22.f64));
	// stw r9,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r9.u32);
	// fmsubs f12,f12,f30,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f11.f64));
	// stfs f12,0(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,44(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f12,f6
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// fmuls f3,f11,f6
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f6,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f6.f64 = double(temp.f32);
	// fadds f8,f10,f6
	ctx.f8.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fmadds f11,f11,f5,f4
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64 + ctx.f4.f64));
	// stfs f11,0(r14)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fmsubs f12,f12,f5,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 - ctx.f3.f64));
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f12,f8
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmuls f8,f11,f8
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lwz r10,312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	// fmadds f11,f11,f7,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f6.f64));
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// fmsubs f12,f12,f7,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 - ctx.f8.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,32(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f11,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// fmadds f11,f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f8.f64));
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,24(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// fmsubs f12,f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 - ctx.f10.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// xor r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// bne 0x82d5fb3c
	if (!ctx.cr0.eq) goto loc_82D5FB3C;
loc_82D60968:
	// addi r1,r1,624
	ctx.r1.s64 = ctx.r1.s64 + 624;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D60974;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D60978"))) PPC_WEAK_FUNC(sub_82D60978);
PPC_FUNC_IMPL(__imp__sub_82D60978) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,584
	ctx.r5.s64 = ctx.r11.s64 + 584;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,-1288
	ctx.r4.s64 = ctx.r11.s64 + -1288;
	// b 0x82d77f68
	sub_82D77F68(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D60990"))) PPC_WEAK_FUNC(sub_82D60990);
PPC_FUNC_IMPL(__imp__sub_82D60990) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D60998;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D609A0;
	__savefpr_14(ctx, base);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82d613f4
	if (!ctx.cr6.lt) goto loc_82D613F4;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r5,-32255
	ctx.r5.s64 = -2113863680;
	// stw r10,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r10.u32);
	// subf r10,r8,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r8.s64;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lfs f11,-12288(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -12288);
	ctx.f11.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// stw r10,-352(r1)
	PPC_STORE_U32(ctx.r1.u32 + -352, ctx.r10.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f13,-7588(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7584(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,-7592(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7592);
	ctx.f12.f64 = double(temp.f32);
loc_82D609E0:
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfs f10,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r5,r6,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f4,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r31,r6,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// add r27,r6,r7
	ctx.r27.u64 = ctx.r6.u64 + ctx.r7.u64;
	// rlwinm r9,r6,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// mulli r30,r6,3
	ctx.r30.s64 = ctx.r6.s64 * 3;
	// lfsx f7,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f29,f6,f7
	ctx.f29.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfsx f8,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfsx f2,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f28,f2,f8
	ctx.f28.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// lfsx f1,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f5,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// lfsx f3,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f27,f1,f3
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// rlwinm r28,r27,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// add r30,r30,r7
	ctx.r30.u64 = ctx.r30.u64 + ctx.r7.u64;
	// add r29,r8,r7
	ctx.r29.u64 = ctx.r8.u64 + ctx.r7.u64;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f24,f7,f13
	ctx.f24.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// rlwinm r26,r30,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r25,r29,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f26,f28,f29
	ctx.f26.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// add r16,r28,r3
	ctx.r16.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fsubs f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fmuls f28,f8,f13
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// rlwinm r23,r7,1,0,30
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// fadds f25,f27,f6
	ctx.f25.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// rlwinm r22,r9,3,0,28
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f2,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// lfsx f31,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f23,f5,f13
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfsx f4,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f31,f2
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// lfs f1,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fmuls f22,f3,f13
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// add r20,r23,r6
	ctx.r20.u64 = ctx.r23.u64 + ctx.r6.u64;
	// fmadds f8,f8,f0,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f24.f64));
	// add r15,r28,r4
	ctx.r15.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fadds f24,f4,f1
	ctx.f24.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// rlwinm r9,r20,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r9,r3
	ctx.r28.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmuls f31,f29,f12
	ctx.f31.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fmsubs f7,f7,f0,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 - ctx.f28.f64));
	// fmuls f29,f27,f12
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// rlwinm r23,r27,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f3,f3,f0,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f23.f64));
	// lfs f23,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f30,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f28,f26,f11,f10
	ctx.f28.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// fmuls f19,f2,f13
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfsx f21,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f5,f5,f0,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f22.f64));
	// lfsx f22,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f27,f25,f11,f9
	ctx.f27.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// add r21,r29,r10
	ctx.r21.u64 = ctx.r29.u64 + ctx.r10.u64;
	// fsubs f20,f24,f6
	ctx.f20.f64 = double(float(ctx.f24.f64 - ctx.f6.f64));
	// stw r28,-328(r1)
	PPC_STORE_U32(ctx.r1.u32 + -328, ctx.r28.u32);
	// fmuls f18,f4,f13
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fadds f1,f24,f6
	ctx.f1.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// lfsx f6,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f24,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f4,f4,f0,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f19.f64));
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmsubs f2,f2,f0,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f18.f64));
	// fadds f16,f24,f6
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// lfsx f18,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f6,f6,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f24.f64));
	// lfsx f19,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// add r19,r30,r6
	ctx.r19.u64 = ctx.r30.u64 + ctx.r6.u64;
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// rlwinm r20,r20,3,0,28
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 3) & 0xFFFFFFF8;
	// fnmsubs f22,f1,f11,f30
	ctx.f22.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f30.f64)));
	// stfs f22,-340(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f22,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r18,r19,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f22,-392(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfsx f17,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// add r14,r18,r4
	ctx.r14.u64 = ctx.r18.u64 + ctx.r4.u64;
	// rlwinm r17,r27,4,0,27
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f15,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// add r18,r18,r3
	ctx.r18.u64 = ctx.r18.u64 + ctx.r3.u64;
	// fmuls f22,f6,f13
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// stw r9,-320(r1)
	PPC_STORE_U32(ctx.r1.u32 + -320, ctx.r9.u32);
	// fadds f14,f24,f16
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmuls f14,f23,f13
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fsubs f16,f24,f16
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// stw r18,-312(r1)
	PPC_STORE_U32(ctx.r1.u32 + -312, ctx.r18.u32);
	// fmadds f24,f23,f0,f22
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f22.f64));
	// fmsubs f23,f6,f0,f14
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 - ctx.f14.f64));
	// fmuls f6,f16,f12
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f6,-332(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f6,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r28,r7,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f16,f18,f6
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f6.f64));
	// fsubs f6,f6,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f18.f64));
	// add r19,r28,r10
	ctx.r19.u64 = ctx.r28.u64 + ctx.r10.u64;
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,-392(r1)
	PPC_STORE_U32(ctx.r1.u32 + -392, ctx.r14.u32);
	// fadds f22,f14,f19
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// add r14,r17,r4
	ctx.r14.u64 = ctx.r17.u64 + ctx.r4.u64;
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f18,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f18.f64 = double(temp.f32);
	// stw r14,-336(r1)
	PPC_STORE_U32(ctx.r1.u32 + -336, ctx.r14.u32);
	// fnmsubs f18,f18,f11,f21
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// stfs f18,-348(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f18,f16,f22
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f18,-444(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// fmuls f14,f19,f13
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f16,f6,f13
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f22,-368(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fmadds f6,f6,f0,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f14.f64));
	// stfs f6,-324(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmsubs f22,f19,f0,f16
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 - ctx.f16.f64));
	// stfs f22,-360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fnmsubs f6,f18,f11,f17
	ctx.f6.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f17.f64)));
	// stfs f6,-356(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfsx f6,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f22,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f14,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fadds f14,f22,f6
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f6.f64));
	// lfs f19,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f22.f64));
	// lfsx f18,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// add r9,r17,r3
	ctx.r9.u64 = ctx.r17.u64 + ctx.r3.u64;
	// stfs f6,-424(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fadds f6,f18,f19
	ctx.f6.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f6,-404(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfsx f6,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,-400(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfsx f16,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stw r9,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r9.u32);
	// lfsx f6,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// stfs f16,-380(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// stfs f14,-416(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// stfs f6,-388(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfsx f16,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f6,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lwz r9,-392(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	// stfs f6,-396(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f22,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fadds f25,f25,f9
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f9.f64));
	// lfs f9,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f9.f64 = double(temp.f32);
	// fadds f26,f26,f10
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f10.f64));
	// fadds f21,f9,f21
	ctx.f21.f64 = double(float(ctx.f9.f64 + ctx.f21.f64));
	// lfs f9,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f9.f64 = double(temp.f32);
	// fadds f10,f1,f30
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// lfs f6,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fadds f17,f9,f17
	ctx.f17.f64 = double(float(ctx.f9.f64 + ctx.f17.f64));
	// fadds f18,f22,f6
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f6.f64));
	// stfs f18,-432(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fsubs f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f22.f64));
	// stfs f6,-436(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f6,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// mulli r9,r7,12
	ctx.r9.s64 = ctx.r7.s64 * 12;
	// fsubs f22,f6,f14
	ctx.f22.f64 = double(float(ctx.f6.f64 - ctx.f14.f64));
	// stfs f22,-420(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f22,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f22.f64 = double(temp.f32);
	// fadds f6,f14,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 + ctx.f6.f64));
	// lfs f18,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f18.f64 = double(temp.f32);
	// mulli r18,r7,3
	ctx.r18.s64 = ctx.r7.s64 * 3;
	// fadds f18,f18,f22
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f18,-448(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// stfs f6,-440(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmuls f18,f19,f13
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f6,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// fmadds f6,f19,f0,f6
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f6.f64));
	// stfs f6,-372(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f6,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f6,f6,f0,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 - ctx.f18.f64));
	// stfs f6,-408(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fmuls f6,f22,f12
	ctx.f6.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f22.f64 = double(temp.f32);
	// stfs f6,-364(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fadds f6,f22,f16
	ctx.f6.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// fsubs f19,f16,f22
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// lfs f22,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f22.f64 = double(temp.f32);
	// stfs f19,-416(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f16,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f16,f22
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f18,-412(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f22,-424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f22,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f16,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f14,f14,f11,f15
	ctx.f14.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f15.f64)));
	// stfs f14,-396(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f6.f64));
	// stfs f14,-404(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f6.f64));
	// lfs f6,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 - ctx.f18.f64));
	// lfs f6,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f6,f6,f0,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f19.f64));
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f19,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f19,f0,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 - ctx.f22.f64));
	// fmuls f19,f14,f12
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f14,f0,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 - ctx.f16.f64));
	// stfs f16,-384(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f16,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f16,f14,f11,f16
	ctx.f16.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f16.f64)));
	// stfs f16,-388(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f14,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// add r18,r18,r6
	ctx.r18.u64 = ctx.r18.u64 + ctx.r6.u64;
	// lfs f9,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f9.f64 = double(temp.f32);
	// mulli r27,r27,12
	ctx.r27.s64 = ctx.r27.s64 * 12;
	// stfs f10,-432(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fmadds f10,f9,f0,f14
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f14.f64));
	// lfs f9,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f1,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f14,f9,f15
	ctx.f14.f64 = double(float(ctx.f9.f64 + ctx.f15.f64));
	// stfs f1,-424(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfsx f1,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f30,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-440(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// rlwinm r14,r18,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r18.u32 | (ctx.r18.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f1,-412(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// add r18,r9,r5
	ctx.r18.u64 = ctx.r9.u64 + ctx.r5.u64;
	// lfsx f1,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// add r17,r9,r31
	ctx.r17.u64 = ctx.r9.u64 + ctx.r31.u64;
	// lfs f9,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f9,f16,f11,f9
	ctx.f9.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// stw r14,-444(r1)
	PPC_STORE_U32(ctx.r1.u32 + -444, ctx.r14.u32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,-416(r1)
	PPC_STORE_U32(ctx.r1.u32 + -416, ctx.r14.u32);
	// lwz r14,-444(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,-444(r1)
	PPC_STORE_U32(ctx.r1.u32 + -444, ctx.r14.u32);
	// lwz r14,-416(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	// lfs f30,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-448(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lwz r14,-444(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	// lfs f30,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-436(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfsx f30,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-444(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfsx f30,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-420(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfsx f30,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-428(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfsx f30,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f26,0(r3)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f25,0(r4)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f26,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f26,r8,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f21,r8,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// stfsx f17,r5,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f15.f64 = double(temp.f32);
	// fadds f26,f1,f15
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f15.f64));
	// fsubs f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 - ctx.f1.f64));
	// stfs f1,-432(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// lfs f1,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// stfs f1,-448(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f21,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f21.f64 = double(temp.f32);
	// fadds f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// lfs f21,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// lfs f1,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f30,f17
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// fsubs f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f30.f64));
	// stfs f1,-376(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// stfs f30,-444(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fadds f15,f25,f26
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f15,-420(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f1,-440(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fadds f25,f17,f21
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f25,-428(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmuls f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fsubs f17,f17,f21
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// fmuls f1,f26,f12
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f15,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// lfs f25,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// stfs f30,-436(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f26,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f26.f64 = double(temp.f32);
	// addi r8,r11,4
	ctx.r8.s64 = ctx.r11.s64 + 4;
	// fmsubs f30,f26,f0,f25
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 - ctx.f25.f64));
	// lfs f26,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f0,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f15.f64));
	// lfs f15,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f25,f0,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f15.f64));
	// lfs f21,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f21.f64 = double(temp.f32);
	// stfs f17,-432(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f17,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f14,r5,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// addi r5,r11,28
	ctx.r5.s64 = ctx.r11.s64 + 28;
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f21,f21,f0,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 - ctx.f15.f64));
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f17,f15,f11,f17
	ctx.f17.f64 = double(float(-(ctx.f15.f64 * ctx.f11.f64 - ctx.f17.f64)));
	// stfs f17,-436(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f17,f17,f11,f15
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f15.f64)));
	// fadds f15,f28,f31
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// stfs f15,-448(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fadds f15,f27,f29
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r31,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfsx f16,r31,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f27,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f16,r10,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f15.f64 = double(temp.f32);
	// lfs f27,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfsx f16,r10,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f16,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// addi r10,r11,24
	ctx.r10.s64 = ctx.r11.s64 + 24;
	// lfs f15,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f3.f64));
	// stfs f14,-376(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f8
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// stfs f14,-444(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f3,f14,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 - ctx.f3.f64));
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// fadds f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 + ctx.f8.f64));
	// fsubs f14,f31,f5
	ctx.f14.f64 = double(float(ctx.f31.f64 - ctx.f5.f64));
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fadds f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// lfs f31,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f31.f64 = double(temp.f32);
	// fadds f14,f29,f7
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fsubs f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 - ctx.f7.f64));
	// fsubs f29,f28,f31
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// stfs f29,-408(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// stfs f31,-380(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f31,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// stfs f31,-400(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f31,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f29,f16,f31
	ctx.f29.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fmuls f28,f15,f31
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// lfs f31,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f29,f15,f31,f29
	ctx.f29.f64 = double(float(ctx.f15.f64 * ctx.f31.f64 + ctx.f29.f64));
	// stfsx f29,r30,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f31,f16,f31,f28
	ctx.f31.f64 = double(float(ctx.f16.f64 * ctx.f31.f64 - ctx.f28.f64));
	// stfsx f31,r30,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f31,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f29,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f3
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f29,f29,f8,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f28.f64));
	// stfsx f29,r28,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f31,f8,f3
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 - ctx.f3.f64));
	// stfsx f8,r28,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f31,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f31.f64 = double(temp.f32);
	// lfs f3,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f29,f8,f31
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f31,f3,f31
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f28,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f3,f3,f14,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f14.f64 + ctx.f29.f64));
	// stfsx f3,r29,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f14,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f14.f64 - ctx.f31.f64));
	// stfsx f8,r29,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f31,f8,f5
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// lfs f3,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f29,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// lfs f28,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f3,f3,f7,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 + ctx.f31.f64));
	// stfsx f3,r9,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f3,f9,f18
	ctx.f3.f64 = double(float(ctx.f9.f64 - ctx.f18.f64));
	// lfs f31,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f8,f8,f7,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f5.f64));
	// lfs f5,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f31,f31,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f19.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 - ctx.f5.f64));
	// lfs f27,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f27.f64 = double(temp.f32);
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f8,f27
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f14,f7,f27
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// fsubs f27,f3,f22
	ctx.f27.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// fadds f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// lfs f22,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f22.f64 = double(temp.f32);
	// fadds f16,f31,f16
	ctx.f16.f64 = double(float(ctx.f31.f64 + ctx.f16.f64));
	// fsubs f31,f31,f22
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f22.f64));
	// lfs f22,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f29,f22
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f22.f64));
	// stfs f22,-408(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f22,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f7,f22,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f22.f64 + ctx.f15.f64));
	// lfs f15,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f7,r23,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f22,f14
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f22,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f7,f28,f15
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfsx f8,r23,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fadds f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f29,f29,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f22.f64));
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f8,f15
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f15.f64));
	// fmuls f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// fmadds f22,f22,f5,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 + ctx.f14.f64));
	// stfsx f22,r18,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f5,f15
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 - ctx.f15.f64));
	// stfsx f8,r18,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f8,f27
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// fmadds f5,f5,f16,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f16.f64 + ctx.f22.f64));
	// stfsx f5,r22,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f16,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f16.f64 - ctx.f27.f64));
	// stfsx f8,r22,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f8,f3
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fadds f9,f9,f18
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f18.f64));
	// fmadds f5,f5,f31,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 + ctx.f27.f64));
	// stfsx f5,r17,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f31,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f31.f64 - ctx.f3.f64));
	// stfsx f8,r17,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f3,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f3.f64 = double(temp.f32);
	// lfs f5,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f31,f8,f3
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f27,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f5,f5,f7,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f31.f64));
	// stfsx f5,r24,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f7,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f3.f64));
	// stfsx f8,r24,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f8,f29
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f29,f7,f29
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// lfs f31,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f31.f64 = double(temp.f32);
	// fadds f3,f17,f31
	ctx.f3.f64 = double(float(ctx.f17.f64 + ctx.f31.f64));
	// fmadds f5,f7,f28,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 + ctx.f5.f64));
	// stfsx f5,r20,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f27,f1
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fsubs f7,f27,f1
	ctx.f7.f64 = double(float(ctx.f27.f64 - ctx.f1.f64));
	// fsubs f1,f17,f31
	ctx.f1.f64 = double(float(ctx.f17.f64 - ctx.f31.f64));
	// lfs f31,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f8,f8,f28,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 - ctx.f29.f64));
	// stfsx f8,r20,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fadds f31,f31,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f19.f64));
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f29,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f27,f3,f26
	ctx.f27.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// fadds f3,f3,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f26.f64));
	// fadds f28,f5,f25
	ctx.f28.f64 = double(float(ctx.f5.f64 + ctx.f25.f64));
	// fsubs f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// fadds f25,f1,f30
	ctx.f25.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fsubs f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fadds f30,f9,f6
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// fsubs f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fsubs f22,f31,f10
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f10.f64));
	// fadds f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f26,f7,f21
	ctx.f26.f64 = double(float(ctx.f7.f64 - ctx.f21.f64));
	// fadds f7,f7,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f21.f64));
	// fmuls f6,f8,f28
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// fmuls f31,f29,f28
	ctx.f31.f64 = double(float(ctx.f29.f64 * ctx.f28.f64));
	// fmadds f6,f29,f27,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f27.f64 + ctx.f6.f64));
	// stfsx f6,r26,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f27,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 - ctx.f31.f64));
	// stfsx f8,r26,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f31,f8,f5
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f5,f6,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmadds f6,f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 + ctx.f31.f64));
	// stfsx f6,r19,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 - ctx.f5.f64));
	// stfsx f8,r19,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f8,f26
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmuls f3,f6,f26
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmadds f6,f6,f25,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f5.f64));
	// stfsx f6,r21,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f25,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f25.f64 - ctx.f3.f64));
	// stfsx f8,r21,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f8,f7
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmadds f6,f6,f1,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f5.f64));
	// stfsx f6,r27,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f1,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f1.f64 - ctx.f7.f64));
	// stfsx f8,r27,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f8,f30
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f5,f7,f30
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmadds f7,f7,f22,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f22.f64 + ctx.f6.f64));
	// stfsx f7,r25,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f22,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f22.f64 - ctx.f5.f64));
	// lwz r9,-352(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	// stfsx f8,r25,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lwz r31,-316(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// lfs f7,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f3,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f29,f7,f9
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fsubs f8,f3,f20
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f20.f64));
	// lfs f5,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f28,f5,f9
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f31,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f1.f64 = double(temp.f32);
	// fadds f3,f3,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f20.f64));
	// stw r9,-352(r1)
	PPC_STORE_U32(ctx.r1.u32 + -352, ctx.r9.u32);
	// fsubs f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// lwz r9,-344(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmadds f5,f5,f10,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f29.f64));
	// stfs f5,0(r9)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fsubs f31,f8,f23
	ctx.f31.f64 = double(float(ctx.f8.f64 - ctx.f23.f64));
	// lwz r9,-336(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	// fmsubs f10,f7,f10,f28
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f10.f64 - ctx.f28.f64));
	// fadds f8,f8,f23
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f23.f64));
	// fadds f9,f6,f2
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fsubs f30,f1,f4
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// stfs f10,0(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r9,-328(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fadds f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// lfs f7,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// fadds f2,f3,f24
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f24.f64));
	// fsubs f3,f3,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f24.f64));
	// fmuls f5,f10,f31
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f1,f7,f31
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmadds f7,f7,f9,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 + ctx.f5.f64));
	// stfs f7,0(r9)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r9,-320(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	// fmsubs f10,f10,f9,f1
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f1.f64));
	// stfs f10,0(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r9,-416(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f8,f9,f8
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmadds f9,f9,f6,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f6.f64 + ctx.f7.f64));
	// stfs f9,0(r9)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fmsubs f10,f10,f6,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f6.f64 - ctx.f8.f64));
	// stfs f10,0(r14)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// lfs f9,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f10,f2
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmuls f7,f9,f2
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmadds f9,f9,f30,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f8.f64));
	// stfs f9,0(r16)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fmsubs f10,f10,f30,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 - ctx.f7.f64));
	// stfs f10,0(r15)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// lfs f10,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,-312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	// fmuls f8,f10,f3
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f9,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f9,f3
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmadds f9,f9,f4,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64 + ctx.f8.f64));
	// stfs f9,0(r10)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-392(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	// fmsubs f10,f10,f4,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 - ctx.f7.f64));
	// stfs f10,0(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// xor r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// bne 0x82d609e0
	if (!ctx.cr0.eq) goto loc_82D609E0;
loc_82D613F4:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D613FC;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D61400"))) PPC_WEAK_FUNC(sub_82D61400);
PPC_FUNC_IMPL(__imp__sub_82D61400) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,656
	ctx.r5.s64 = ctx.r11.s64 + 656;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,2448
	ctx.r4.s64 = ctx.r11.s64 + 2448;
	// b 0x82d77f68
	sub_82D77F68(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D61418"))) PPC_WEAK_FUNC(sub_82D61418);
PPC_FUNC_IMPL(__imp__sub_82D61418) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D61420;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ef4
	ctx.lr = 0x82D61428;
	__savefpr_19(ctx, base);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82d61684
	if (!ctx.cr6.lt) goto loc_82D61684;
	// rlwinm r24,r10,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r28,r8,r9
	ctx.r28.s64 = ctx.r9.s64 - ctx.r8.s64;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f13,-7656(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7656);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D61454:
	// rlwinm r9,r6,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f12,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r7,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r8,r9,r7
	ctx.r8.u64 = ctx.r9.u64 + ctx.r7.u64;
	// add r5,r10,r6
	ctx.r5.u64 = ctx.r10.u64 + ctx.r6.u64;
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r30,r6,r7
	ctx.r30.u64 = ctx.r6.u64 + ctx.r7.u64;
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r31,r30,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// add r26,r29,r4
	ctx.r26.u64 = ctx.r29.u64 + ctx.r4.u64;
	// lfsx f9,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r8,r5,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f25,f9,f10
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfsx f7,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r30,r30,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// rlwinm r27,r7,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f29,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f6,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfsx f28,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f7,f6,f29
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// lfs f5,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// add r25,r27,r4
	ctx.r25.u64 = ctx.r27.u64 + ctx.r4.u64;
	// rlwinm r5,r7,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f4,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// add r27,r27,r3
	ctx.r27.u64 = ctx.r27.u64 + ctx.r3.u64;
	// lfsx f27,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f24,f5,f28
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f28.f64));
	// lfsx f3,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f26,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f23,f27,f4
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// fsubs f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// lfs f31,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 - ctx.f5.f64));
	// lfsx f2,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f22,f26,f3
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// lfsx f1,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f29,f4,f27
	ctx.f29.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// lfs f30,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f4,f25,f0,f12
	ctx.f4.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fadds f12,f25,f12
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f12.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f12,f7,f2
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f24,f1
	ctx.f12.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fnmsubs f27,f7,f0,f2
	ctx.f27.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// addi r10,r11,8
	ctx.r10.s64 = ctx.r11.s64 + 8;
	// fadds f12,f23,f31
	ctx.f12.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fnmsubs f21,f24,f0,f1
	ctx.f21.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f5,f5,f13
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fnmsubs f20,f23,f0,f31
	ctx.f20.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f31.f64)));
	// fmuls f29,f29,f13
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fnmsubs f28,f10,f0,f11
	ctx.f28.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// fnmsubs f19,f22,f0,f30
	ctx.f19.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f30.f64)));
	// fsubs f31,f26,f3
	ctx.f31.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fmuls f9,f9,f13
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fadds f12,f22,f30
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f2,f21,f6
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f6.f64));
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f3,f27,f5
	ctx.f3.f64 = double(float(ctx.f27.f64 - ctx.f5.f64));
	// addi r9,r11,12
	ctx.r9.s64 = ctx.r11.s64 + 12;
	// fadds f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f27.f64));
	// fadds f6,f21,f6
	ctx.f6.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// fsubs f7,f19,f29
	ctx.f7.f64 = double(float(ctx.f19.f64 - ctx.f29.f64));
	// fadds f1,f19,f29
	ctx.f1.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// fadds f10,f28,f9
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f9.f64));
	// fadds f12,f8,f4
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fmuls f31,f31,f13
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// lfs f30,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f11,f12
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmuls f12,f30,f12
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// fsubs f29,f20,f31
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// fadds f31,f31,f20
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// fmadds f30,f30,f10,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 + ctx.f27.f64));
	// stfsx f30,r5,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f11,f10,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 - ctx.f12.f64));
	// stfsx f12,r5,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f7
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// fmuls f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmadds f11,f11,f29,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 + ctx.f10.f64));
	// stfsx f11,r30,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f29,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 - ctx.f7.f64));
	// stfsx f12,r30,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f3
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f7,f11,f3
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmadds f11,f11,f2,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f10.f64));
	// stfsx f11,r8,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f2,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 - ctx.f7.f64));
	// stfsx f12,r8,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f5
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// fmuls f7,f11,f5
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmadds f11,f11,f6,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f6.f64 + ctx.f10.f64));
	// stfsx f11,r31,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f6,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f6.f64 - ctx.f7.f64));
	// stfsx f12,r31,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fmuls f10,f12,f1
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f11,f1
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// fmadds f10,f11,f31,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f31.f64 + ctx.f10.f64));
	// stfsx f10,r29,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f11,f4,f8
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fmsubs f12,f12,f31,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 - ctx.f7.f64));
	// stfs f12,0(r26)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f10,f28,f9
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f9.f64));
	// lfs f9,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f12,f11
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmuls f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// fmadds f9,f9,f10,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 + ctx.f8.f64));
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fmsubs f12,f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f11.f64));
	// stfs f12,0(r25)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// lwz r10,3532(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// xor r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// bne 0x82d61454
	if (!ctx.cr0.eq) goto loc_82D61454;
loc_82D61684:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f40
	ctx.lr = 0x82D6168C;
	__restfpr_19(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D61690"))) PPC_WEAK_FUNC(sub_82D61690);
PPC_FUNC_IMPL(__imp__sub_82D61690) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,728
	ctx.r5.s64 = ctx.r11.s64 + 728;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,5144
	ctx.r4.s64 = ctx.r11.s64 + 5144;
	// b 0x82d77f68
	sub_82D77F68(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D616A8"))) PPC_WEAK_FUNC(sub_82D616A8);
PPC_FUNC_IMPL(__imp__sub_82D616A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D616B0;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D616B8;
	__savefpr_14(ctx, base);
	// stwu r1,-944(r1)
	ea = -944 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r8,56
	ctx.r11.s64 = ctx.r8.s64 * 56;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82d630e0
	if (!ctx.cr6.lt) goto loc_82D630E0;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r10,612(r1)
	PPC_STORE_U32(ctx.r1.u32 + 612, ctx.r10.u32);
	// subf r10,r8,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r8.s64;
	// stw r10,364(r1)
	PPC_STORE_U32(ctx.r1.u32 + 364, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f0,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D616E4:
	// rlwinm r31,r6,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r8,r6,5
	ctx.r8.s64 = ctx.r6.s64 * 5;
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f27,f11,f13
	ctx.f27.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// mulli r10,r6,3
	ctx.r10.s64 = ctx.r6.s64 * 3;
	// fsubs f11,f12,f10
	ctx.f11.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// mulli r9,r6,7
	ctx.r9.s64 = ctx.r6.s64 * 7;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// add r27,r6,r7
	ctx.r27.u64 = ctx.r6.u64 + ctx.r7.u64;
	// rlwinm r26,r6,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r25,r6,24
	ctx.r25.s64 = ctx.r6.s64 * 24;
	// lfsx f9,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f6,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f10,f8,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
	// lfsx f7,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// rlwinm r20,r8,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f8,f7,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// rlwinm r17,r27,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// rlwinm r19,r9,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r18,r10,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r8,r7,3
	ctx.r8.s64 = ctx.r7.s64 * 3;
	// stw r10,44(r1)
	PPC_STORE_U32(ctx.r1.u32 + 44, ctx.r10.u32);
	// lfsx f5,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f30,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f3,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f26,f5,f30
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// lfsx f31,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// lfsx f29,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f6,f31,f3
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// lfsx f4,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// lfsx f28,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f30,f29,f4
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// lfsx f2,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// add r28,r8,r6
	ctx.r28.u64 = ctx.r8.u64 + ctx.r6.u64;
	// fsubs f31,f2,f28
	ctx.f31.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// mulli r8,r7,7
	ctx.r8.s64 = ctx.r7.s64 * 7;
	// fadds f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fadds f2,f28,f2
	ctx.f2.f64 = double(float(ctx.f28.f64 + ctx.f2.f64));
	// fadds f29,f10,f27
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f27.f64));
	// fadds f28,f9,f11
	ctx.f28.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stw r28,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r28.u32);
	// fsubs f25,f13,f8
	ctx.f25.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// fsubs f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 - ctx.f10.f64));
	// mulli r24,r7,24
	ctx.r24.s64 = ctx.r7.s64 * 24;
	// fadds f27,f7,f12
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fadds f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fsubs f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fadds f9,f6,f26
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f26.f64));
	// fsubs f8,f6,f26
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// fadds f7,f30,f5
	ctx.f7.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// lfsx f1,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f6,f30,f5
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// add r8,r8,r6
	ctx.r8.u64 = ctx.r8.u64 + ctx.r6.u64;
	// fsubs f5,f3,f31
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// add r16,r24,r31
	ctx.r16.u64 = ctx.r24.u64 + ctx.r31.u64;
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// mulli r5,r27,28
	ctx.r5.s64 = ctx.r27.s64 * 28;
	// stfs f3,492(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// fsubs f30,f4,f2
	ctx.f30.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// lfsx f3,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// stw r5,548(r1)
	PPC_STORE_U32(ctx.r1.u32 + 548, ctx.r5.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r10,r6,20
	ctx.r10.s64 = ctx.r6.s64 * 20;
	// stw r8,564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 564, ctx.r8.u32);
	// mulli r9,r7,28
	ctx.r9.s64 = ctx.r7.s64 * 28;
	// mulli r30,r6,12
	ctx.r30.s64 = ctx.r6.s64 * 12;
	// mulli r15,r27,24
	ctx.r15.s64 = ctx.r27.s64 * 24;
	// rlwinm r28,r28,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f2,f3,f1
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// add r23,r30,r9
	ctx.r23.u64 = ctx.r30.u64 + ctx.r9.u64;
	// fsubs f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// rlwinm r22,r6,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f31,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// add r29,r9,r10
	ctx.r29.u64 = ctx.r9.u64 + ctx.r10.u64;
	// lfsx f1,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f18,f1,f31
	ctx.f18.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f26,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stw r28,536(r1)
	PPC_STORE_U32(ctx.r1.u32 + 536, ctx.r28.u32);
	// lfsx f14,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stw r23,604(r1)
	PPC_STORE_U32(ctx.r1.u32 + 604, ctx.r23.u32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stw r29,556(r1)
	PPC_STORE_U32(ctx.r1.u32 + 556, ctx.r29.u32);
	// lfsx f14,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f17,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f22,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f26,f17
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfsx f31,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f31,f22
	ctx.f17.f64 = double(float(ctx.f31.f64 + ctx.f22.f64));
	// lfsx f21,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f31,f22,f31
	ctx.f31.f64 = double(float(ctx.f22.f64 - ctx.f31.f64));
	// lfsx f15,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f21,f16
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// lfsx f24,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// fadds f16,f24,f15
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// lfsx f23,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// lfsx f20,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// fadds f15,f22,f31
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f31.f64));
	// stfs f15,600(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// fsubs f31,f22,f31
	ctx.f31.f64 = double(float(ctx.f22.f64 - ctx.f31.f64));
	// stfs f31,568(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// fadds f31,f16,f2
	ctx.f31.f64 = double(float(ctx.f16.f64 + ctx.f2.f64));
	// stfs f31,288(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fsubs f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f16.f64));
	// stfs f2,380(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fadds f2,f24,f18
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f18.f64));
	// stfs f2,452(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// fadds f2,f23,f1
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// stfs f2,348(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fsubs f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// stfs f1,340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f31,f3,f2
	ctx.f31.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f31,460(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f3,620(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// lfs f3,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f31,f18,f24
	ctx.f31.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// fadds f2,f3,f17
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f17.f64));
	// stfs f2,52(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f2,f21,f19
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f2,308(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fadds f2,f19,f21
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f31,628(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// stfs f2,60(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// mulli r8,r6,6
	ctx.r8.s64 = ctx.r6.s64 * 6;
	// lfs f2,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f2.f64 = double(temp.f32);
	// add r28,r8,r7
	ctx.r28.u64 = ctx.r8.u64 + ctx.r7.u64;
	// fsubs f1,f20,f2
	ctx.f1.f64 = double(float(ctx.f20.f64 - ctx.f2.f64));
	// fadds f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// stfs f2,504(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fsubs f3,f3,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f17.f64));
	// stfs f3,292(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f3,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// stfs f1,496(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// lfsx f1,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r5,r6,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// lfsx f31,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// rlwinm r28,r28,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r5,r7
	ctx.r5.u64 = ctx.r5.u64 + ctx.r7.u64;
	// add r29,r22,r7
	ctx.r29.u64 = ctx.r22.u64 + ctx.r7.u64;
	// rlwinm r14,r5,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r29,r29,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r8,r6,28
	ctx.r8.s64 = ctx.r6.s64 * 28;
	// stw r28,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r28.u32);
	// stw r5,48(r1)
	PPC_STORE_U32(ctx.r1.u32 + 48, ctx.r5.u32);
	// stw r14,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r14.u32);
	// lfsx f21,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stw r29,428(r1)
	PPC_STORE_U32(ctx.r1.u32 + 428, ctx.r29.u32);
	// lfsx f19,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f24,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r28,r7,6
	ctx.r28.s64 = ctx.r7.s64 * 6;
	// lfsx f23,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// add r23,r28,r6
	ctx.r23.u64 = ctx.r28.u64 + ctx.r6.u64;
	// rlwinm r21,r7,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r23,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r23.u32 | (ctx.r23.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r10,r24
	ctx.r28.u64 = ctx.r10.u64 + ctx.r24.u64;
	// lfsx f22,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f15,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stw r23,424(r1)
	PPC_STORE_U32(ctx.r1.u32 + 424, ctx.r23.u32);
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f15,f3,f2
	ctx.f15.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfsx f20,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f16,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stw r28,472(r1)
	PPC_STORE_U32(ctx.r1.u32 + 472, ctx.r28.u32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r14.u32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f15,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// stw r14,636(r1)
	PPC_STORE_U32(ctx.r1.u32 + 636, ctx.r14.u32);
	// lwz r29,84(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lfs f18,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lwz r29,96(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfsx f2,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,24(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f2,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,32(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f2,f1,f24
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// fsubs f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// fsubs f24,f23,f31
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// fadds f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f19,88(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// stfs f19,560(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfs f26,488(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f26,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fadds f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// rlwinm r23,r7,1,0,30
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r5,r5,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// add r14,r23,r6
	ctx.r14.u64 = ctx.r23.u64 + ctx.r6.u64;
	// fadds f16,f2,f14
	ctx.f16.f64 = double(float(ctx.f2.f64 + ctx.f14.f64));
	// add r23,r9,r26
	ctx.r23.u64 = ctx.r9.u64 + ctx.r26.u64;
	// stfs f16,180(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f16,f1,f24
	ctx.f16.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// stfs f16,480(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// fsubs f16,f3,f31
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// add r29,r8,r24
	ctx.r29.u64 = ctx.r8.u64 + ctx.r24.u64;
	// stw r5,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r5.u32);
	// rlwinm r5,r27,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f3,188(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// stw r23,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, ctx.r23.u32);
	// add r23,r9,r25
	ctx.r23.u64 = ctx.r9.u64 + ctx.r25.u64;
	// fadds f3,f24,f1
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// stfs f3,196(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fsubs f3,f2,f14
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f3,164(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stw r5,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r5.u32);
	// fadds f3,f19,f23
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// stfs f3,324(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fsubs f3,f23,f19
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stw r23,304(r1)
	PPC_STORE_U32(ctx.r1.u32 + 304, ctx.r23.u32);
	// stfs f3,388(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fadds f3,f18,f21
	ctx.f3.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f3,532(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// fadds f3,f17,f20
	ctx.f3.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f3,280(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// stw r29,584(r1)
	PPC_STORE_U32(ctx.r1.u32 + 584, ctx.r29.u32);
	// rlwinm r23,r7,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r5,44(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// stfs f16,172(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfsx f1,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// stw r14,64(r1)
	PPC_STORE_U32(ctx.r1.u32 + 64, ctx.r14.u32);
	// rlwinm r5,r5,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f31,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// stw r5,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r5.u32);
	// mulli r5,r14,12
	ctx.r5.s64 = ctx.r14.s64 * 12;
	// stw r5,464(r1)
	PPC_STORE_U32(ctx.r1.u32 + 464, ctx.r5.u32);
	// lfs f3,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f2,f22,f3
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f3.f64));
	// stfs f2,540(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// fsubs f2,f21,f18
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f2,508(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fadds f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// stfs f3,500(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// lfsx f3,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f2,f20,f17
	ctx.f2.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f2,168(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f2,f15,f3
	ctx.f2.f64 = double(float(ctx.f15.f64 - ctx.f3.f64));
	// add r28,r9,r31
	ctx.r28.u64 = ctx.r9.u64 + ctx.r31.u64;
	// fadds f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f15.f64));
	// lfsx f18,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f15,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f23,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// stw r28,576(r1)
	PPC_STORE_U32(ctx.r1.u32 + 576, ctx.r28.u32);
	// fadds f24,f2,f26
	ctx.f24.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// stfs f24,436(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fsubs f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// stfs f2,444(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// lfsx f24,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f2,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lwz r29,352(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// lfsx f26,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lwz r28,304(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// lfsx f22,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f20,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r29,264(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// lfsx f21,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f19,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f17,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r29,112(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f16,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r14,r14,3,0,28
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 3) & 0xFFFFFFF8;
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r29,r7,12
	ctx.r29.s64 = ctx.r7.s64 * 12;
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r5,124(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f16,f26,f1
	ctx.f16.f64 = double(float(ctx.f26.f64 + ctx.f1.f64));
	// fsubs f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// fsubs f26,f31,f23
	ctx.f26.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// stw r14,336(r1)
	PPC_STORE_U32(ctx.r1.u32 + 336, ctx.r14.u32);
	// fadds f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// add r14,r29,r10
	ctx.r14.u64 = ctx.r29.u64 + ctx.r10.u64;
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// rlwinm r28,r7,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fsubs f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stw r14,252(r1)
	PPC_STORE_U32(ctx.r1.u32 + 252, ctx.r14.u32);
	// add r14,r29,r8
	ctx.r14.u64 = ctx.r29.u64 + ctx.r8.u64;
	// stw r14,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r14.u32);
	// add r14,r28,r25
	ctx.r14.u64 = ctx.r28.u64 + ctx.r25.u64;
	// stw r14,384(r1)
	PPC_STORE_U32(ctx.r1.u32 + 384, ctx.r14.u32);
	// lwz r14,112(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// fadds f14,f23,f16
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// stfs f23,300(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fadds f23,f22,f26
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f23,516(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// fadds f23,f20,f31
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f31.f64));
	// stfs f23,56(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f23,f1,f21
	ctx.f23.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfs f23,524(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// fadds f1,f21,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// stfs f1,512(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// fsubs f31,f31,f20
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f20.f64));
	// stfs f31,236(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f26,376(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f31,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f31.f64 = double(temp.f32);
	// fadds f26,f31,f1
	ctx.f26.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfs f26,332(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfs f1,316(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f1,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f31,f24,f1
	ctx.f31.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// stfs f31,160(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f31,f3,f2
	ctx.f31.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f31,356(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f3,372(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fadds f3,f1,f24
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// stfs f3,24(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f3,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lwz r5,28(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lfs f1,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f2,f3,f1
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// fsubs f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// lfsx f1,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// stw r5,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r5.u32);
	// mulli r5,r27,12
	ctx.r5.s64 = ctx.r27.s64 * 12;
	// stw r5,44(r1)
	PPC_STORE_U32(ctx.r1.u32 + 44, ctx.r5.u32);
	// rlwinm r5,r27,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 4) & 0xFFFFFFF0;
	// stw r5,552(r1)
	PPC_STORE_U32(ctx.r1.u32 + 552, ctx.r5.u32);
	// lfsx f21,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r14,124(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lfsx f20,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r5,336(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	// fadds f26,f2,f19
	ctx.f26.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// lfsx f23,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// stfs f2,432(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fadds f2,f3,f17
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f17.f64));
	// lfsx f22,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f31,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f3,f17,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 - ctx.f3.f64));
	// lfsx f19,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f1,f31
	ctx.f17.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r5,252(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lwz r14,88(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stfs f3,596(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// stfs f2,520(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// stfs f26,200(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfsx f31,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f14,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r5,244(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f3,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lwz r14,44(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// lfsx f14,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r5,384(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f26,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f24,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f14,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f14,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f14,f21,f23
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fsubs f21,f18,f17
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f21,608(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// fadds f21,f1,f15
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f15.f64));
	// stfs f21,208(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fsubs f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 - ctx.f1.f64));
	// stfs f1,400(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// fadds f1,f17,f18
	ctx.f1.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f1,588(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// fsubs f1,f22,f20
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fadds f20,f31,f3
	ctx.f20.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f31,f2,f21
	ctx.f31.f64 = double(float(ctx.f2.f64 - ctx.f21.f64));
	// fadds f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f2.f64));
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fadds f18,f26,f21
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f21,f24
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// lfs f21,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f21.f64 = double(temp.f32);
	// fadds f15,f21,f19
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f19,f31,f3
	ctx.f19.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f19,268(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fsubs f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// stfs f3,276(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fadds f3,f18,f20
	ctx.f3.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f3,176(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f3,f18,f20
	ctx.f3.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f3,440(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fsubs f3,f26,f17
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// stfs f3,260(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fsubs f3,f2,f24
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// stfs f3,624(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// fadds f3,f24,f2
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// mulli r14,r7,5
	ctx.r14.s64 = ctx.r7.s64 * 5;
	// stfs f3,396(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// add r14,r14,r6
	ctx.r14.u64 = ctx.r14.u64 + ctx.r6.u64;
	// fadds f3,f17,f26
	ctx.f3.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f3,284(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fadds f2,f15,f14
	ctx.f2.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f3,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f16.f64));
	// stfs f2,184(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f2,f14,f15
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f2,248(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f2,f21,f1
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// stfs f2,616(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// lfs f2,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// mulli r27,r27,20
	ctx.r27.s64 = ctx.r27.s64 * 20;
	// fsubs f31,f23,f2
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f2.f64));
	// fadds f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f23.f64));
	// stfs f2,528(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// stfs f31,632(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 632, temp.u32);
	// stfs f1,420(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// fadds f2,f3,f22
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// stfs f2,404(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fsubs f3,f22,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f3.f64));
	// stfs f3,240(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// rlwinm r14,r14,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f3,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stw r27,476(r1)
	PPC_STORE_U32(ctx.r1.u32 + 476, ctx.r27.u32);
	// mulli r5,r7,20
	ctx.r5.s64 = ctx.r7.s64 * 20;
	// stw r14,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r14.u32);
	// lwz r14,64(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// rlwinm r14,r14,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r14,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r14.u32);
	// add r14,r23,r10
	ctx.r14.u64 = ctx.r23.u64 + ctx.r10.u64;
	// stw r14,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r14.u32);
	// add r14,r23,r8
	ctx.r14.u64 = ctx.r23.u64 + ctx.r8.u64;
	// stw r14,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r14.u32);
	// add r14,r23,r30
	ctx.r14.u64 = ctx.r23.u64 + ctx.r30.u64;
	// stw r14,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r14.u32);
	// add r14,r5,r8
	ctx.r14.u64 = ctx.r5.u64 + ctx.r8.u64;
	// stw r14,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r14.u32);
	// add r14,r5,r30
	ctx.r14.u64 = ctx.r5.u64 + ctx.r30.u64;
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,484(r1)
	PPC_STORE_U32(ctx.r1.u32 + 484, ctx.r14.u32);
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r27,204(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// lfsx f1,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f19,f3,f1
	ctx.f19.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// fsubs f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// fsubs f1,f31,f2
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// lwz r27,152(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// fadds f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// lfsx f26,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lwz r27,136(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lfsx f24,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lwz r27,152(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// fadds f31,f24,f26
	ctx.f31.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f31,36(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// lfsx f23,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r27,136(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lfsx f22,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r27,116(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// fadds f31,f22,f23
	ctx.f31.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f24,f23,f22
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfsx f21,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r27,104(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfsx f20,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r27,116(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// fadds f23,f20,f21
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfsx f18,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r27,104(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfsx f17,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r27,272(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// fadds f22,f17,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfsx f16,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,48(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// add r27,r21,r6
	ctx.r27.u64 = ctx.r21.u64 + ctx.r6.u64;
	// fsubs f20,f18,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// mulli r14,r14,12
	ctx.r14.s64 = ctx.r14.s64 * 12;
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f1,f3
	ctx.f14.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// stfs f14,220(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// stw r14,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r14.u32);
	// fsubs f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// stfs f3,228(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fadds f3,f24,f26
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// add r14,r29,r26
	ctx.r14.u64 = ctx.r29.u64 + ctx.r26.u64;
	// stfs f3,68(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// rlwinm r27,r27,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f3,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// fadds f1,f23,f3
	ctx.f1.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f1,360(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fsubs f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f3.f64));
	// stfs f3,216(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fsubs f3,f24,f26
	ctx.f3.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfs f3,36(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f1,f31,f22
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f22.f64));
	// stfs f1,224(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stw r14,296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 296, ctx.r14.u32);
	// lfsx f24,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// stw r27,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r27.u32);
	// add r27,r28,r10
	ctx.r27.u64 = ctx.r28.u64 + ctx.r10.u64;
	// fadds f1,f22,f31
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f31.f64));
	// stfs f1,312(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fsubs f1,f21,f20
	ctx.f1.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f1,76(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f1,f18,f19
	ctx.f1.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f1,192(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fsubs f1,f18,f19
	ctx.f1.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f1,320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// stw r27,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r27.u32);
	// add r27,r28,r8
	ctx.r27.u64 = ctx.r28.u64 + ctx.r8.u64;
	// fsubs f1,f17,f16
	ctx.f1.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f1,212(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fsubs f1,f2,f15
	ctx.f1.f64 = double(float(ctx.f2.f64 - ctx.f15.f64));
	// stfs f1,232(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fadds f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// stfs f2,412(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fadds f2,f16,f17
	ctx.f2.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f2,64(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// stw r27,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r27.u32);
	// add r27,r28,r30
	ctx.r27.u64 = ctx.r28.u64 + ctx.r30.u64;
	// fadds f2,f20,f21
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f2,28(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f3,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// stw r27,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r27.u32);
	// add r27,r5,r31
	ctx.r27.u64 = ctx.r5.u64 + ctx.r31.u64;
	// stw r27,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r27.u32);
	// add r27,r29,r31
	ctx.r27.u64 = ctx.r29.u64 + ctx.r31.u64;
	// lfsx f31,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f26,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// lfsx f23,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,296(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// lfsx f21,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r14,108(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfsx f20,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lwz r14,108(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,120(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,100(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,120(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,100(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,32(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r5,r26
	ctx.r14.u64 = ctx.r5.u64 + ctx.r26.u64;
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f14,f31,f3
	ctx.f14.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fsubs f31,f2,f26
	ctx.f31.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// fadds f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// fadds f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,92(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r14.u32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// add r14,r5,r25
	ctx.r14.u64 = ctx.r5.u64 + ctx.r25.u64;
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f1
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f1.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f15,f26,f14
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfs f15,448(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// fsubs f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfs f26,256(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fadds f26,f24,f31
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f31.f64));
	// stfs f26,572(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// fadds f26,f22,f2
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// stfs f26,544(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fsubs f14,f3,f23
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// stfs f14,580(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// fsubs f31,f31,f24
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f24.f64));
	// stfs f31,48(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f22.f64));
	// stfs f2,392(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fadds f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f3,468(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fadds f3,f19,f20
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f3,344(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fsubs f2,f17,f21
	ctx.f2.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f2,368(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fsubs f3,f19,f20
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f3,408(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f31,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f31.f64 = double(temp.f32);
	// fadds f3,f17,f21
	ctx.f3.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// lfs f23,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// lfs f21,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f4
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// lfs f20,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// lfs f19,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f19.f64 = double(temp.f32);
	// stfs f3,456(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfs f24,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f2,f31,f24
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f24.f64));
	// stfs f2,92(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f31,f24,f31
	ctx.f31.f64 = double(float(ctx.f24.f64 + ctx.f31.f64));
	// stfs f31,80(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f2,f18,f16
	ctx.f2.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f31,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f31.f64 = double(temp.f32);
	// lfs f24,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f24.f64 = double(temp.f32);
	// fadds f31,f31,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f29.f64));
	// stfs f2,328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fadds f2,f16,f18
	ctx.f2.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f2,592(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// fadds f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f18,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f19.f64 = double(temp.f32);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// lfs f17,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f16,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f2,f16
	ctx.f16.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// lfs f2,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f2.f64 = double(temp.f32);
	// fadds f15,f3,f2
	ctx.f15.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// lfs f2,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f3.f64 = double(temp.f32);
	// fadds f14,f2,f3
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f2,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f2,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfs f2,148(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f2,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfs f2,52(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f2,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f2.f64 = double(temp.f32);
	// stw r14,56(r1)
	PPC_STORE_U32(ctx.r1.u32 + 56, ctx.r14.u32);
	// add r14,r5,r25
	ctx.r14.u64 = ctx.r5.u64 + ctx.r25.u64;
	// lfs f1,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfs f2,416(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stfs f3,144(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfsx f3,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// stw r14,40(r1)
	PPC_STORE_U32(ctx.r1.u32 + 40, ctx.r14.u32);
	// lwz r14,32(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfsx f2,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f2,60(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f2,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lwz r14,56(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// lfs f2,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f2,72(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f2,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lwz r14,40(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// stfs f2,140(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f2,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,40(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// stfs f31,0(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f24,0(r4)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfsx f23,r22,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// stfsx f22,r22,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// stfsx f21,r30,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// stfsx f20,r26,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f2,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f2.f64 = double(temp.f32);
	// stfsx f19,r26,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fadds f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f1,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f1.f64 = double(temp.f32);
	// stfsx f26,r30,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// lfs f31,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f31.f64 = double(temp.f32);
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f18,r25,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f17,r25,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f26.f64 = double(temp.f32);
	// fadds f1,f26,f31
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// fsubs f31,f31,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// fadds f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f23,f1,f2
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f22,f19,f31
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f31.f64));
	// fadds f21,f26,f20
	ctx.f21.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// fadds f20,f24,f3
	ctx.f20.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// fsubs f24,f3,f24
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f24.f64));
	// lfs f3,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f3,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f31,f31,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f19.f64));
	// fadds f3,f21,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 + ctx.f3.f64));
	// stfsx f3,r10,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f3,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f3.f64 = double(temp.f32);
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// fsubs f2,f10,f3
	ctx.f2.f64 = double(float(ctx.f10.f64 - ctx.f3.f64));
	// lfs f3,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f3.f64 = double(temp.f32);
	// stfsx f16,r31,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 - ctx.f3.f64));
	// stfsx f15,r31,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfsx f14,r8,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfsx f18,r8,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// stfs f16,156(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f18,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f18,f2
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,144(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f14,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f19,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f9,f14,f9
	ctx.f9.f64 = double(float(ctx.f14.f64 - ctx.f9.f64));
	// stfs f9,140(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmsubs f3,f19,f3,f17
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 - ctx.f17.f64));
	// stfsx f3,r24,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f3,f19,f2,f18
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 + ctx.f18.f64));
	// stfsx f3,r24,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f3,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// lfs f2,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f2.f64 = double(temp.f32);
	// stfs f9,132(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f15,f3,f2
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f9,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f4,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f4.f64 = double(temp.f32);
	// lfs f19,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f9,f4
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// lfs f2,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// lfs f18,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f4,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f4.f64 = double(temp.f32);
	// lfs f18,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f8.f64));
	// fmadds f9,f9,f4,f15
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64 + ctx.f15.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// fmsubs f9,f3,f4,f14
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 - ctx.f14.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// lfs f9,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f4,f19
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmsubs f3,f9,f2,f3
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f2.f64 - ctx.f3.f64));
	// stfsx f3,r15,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f19,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f19.f64 + ctx.f4.f64));
	// stfsx f9,r15,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f9.f64 = double(temp.f32);
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,424(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	// fmuls f3,f4,f17
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f4,f4,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// lfs f15,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f3,f9,f18,f3
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f18.f64 - ctx.f3.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f17,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f17.f64 + ctx.f4.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,584(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	// lfs f3,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f4,f2
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f9,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f9.f64 = double(temp.f32);
	// lfs f18,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f3,f9,f3,f19
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 - ctx.f19.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f2,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f2.f64 + ctx.f4.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,384(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	// lfs f3,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f4,f16
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f3,f9,f3,f2
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 + ctx.f2.f64));
	// stfsx f3,r10,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f9,f9,f16,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f16.f64 - ctx.f4.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// lwz r10,108(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfs f3,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f9,f3
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmuls f19,f4,f3
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f4,f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f2.f64));
	// stfsx f4,r10,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f9,f9,f3,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 - ctx.f19.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lfs f9,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// lfs f3,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfs f2,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// lfs f19,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f19.f64 = double(temp.f32);
	// lfs f2,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// lfs f19,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fadds f12,f19,f12
	ctx.f12.f64 = double(float(ctx.f19.f64 + ctx.f12.f64));
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fadds f10,f19,f10
	ctx.f10.f64 = double(float(ctx.f19.f64 + ctx.f10.f64));
	// lfs f16,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// lfs f19,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f16,f4
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// lfs f17,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fadds f8,f19,f8
	ctx.f8.f64 = double(float(ctx.f19.f64 + ctx.f8.f64));
	// lfs f19,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f19.f64 = double(temp.f32);
	// fadds f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// lfs f19,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// fmsubs f9,f17,f9,f14
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 - ctx.f14.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f17,f4,f16
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f16.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f4,f2
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// lwz r10,124(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f16,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f3,f9,f3,f17
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 - ctx.f17.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f2,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f2.f64 + ctx.f4.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// fmuls f3,f4,f10
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f17,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f17.f64 = double(temp.f32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f12,f9,f12,f3
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f3.f64));
	// stfsx f12,r23,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f9,f10,f4
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 + ctx.f4.f64));
	// stfsx f12,r23,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f29
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f29.f64));
	// fmuls f4,f10,f29
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfs f3,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f3.f64 = double(temp.f32);
	// lfs f29,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fmadds f10,f10,f27,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 + ctx.f9.f64));
	// stfsx f10,r28,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f27,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f4.f64));
	// stfsx f12,r28,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f30
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f27,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 - ctx.f27.f64));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f14,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f14.f64 = double(temp.f32);
	// lfs f4,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// fmsubs f9,f12,f8,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f30,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 + ctx.f10.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,536(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	// fmuls f9,f10,f18
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f18.f64));
	// lfs f12,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// lfs f4,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfs f3,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfs f30,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f30.f64 = double(temp.f32);
	// lfs f2,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f30.f64));
	// lfs f30,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f1,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fmsubs f9,f12,f19,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f19.f64 - ctx.f9.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmuls f19,f10,f19
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// lfs f9,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f9,f9,f16
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f16.f64));
	// fsubs f10,f10,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f17.f64));
	// fmadds f12,f12,f18,f19
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f18,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lwz r10,464(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	// fmuls f14,f18,f9
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// lfs f12,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// fmsubs f10,f12,f10,f14
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f14.f64));
	// stfsx f10,r10,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f9,f18
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f18.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f8
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmuls f8,f10,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmadds f10,f10,f4,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f9.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f4,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 - ctx.f8.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lwz r10,552(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f3
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f8,f10,f3
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f4,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f10,f10,f2,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f2.f64 + ctx.f9.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f2,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 - ctx.f8.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f10,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,472(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	// fmuls f9,f10,f29
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfs f12,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f8,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f8.f64 = double(temp.f32);
	// lfs f2,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// lfs f1,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f26,f1
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f1.f64));
	// lfs f26,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// fmsubs f9,f12,f30,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f9.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f29,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 + ctx.f10.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fmuls f9,f10,f19
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// lfs f12,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fmsubs f9,f12,f27,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f9.f64));
	// stfsx f9,r16,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f19,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f19.f64 + ctx.f10.f64));
	// stfsx f12,r16,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f30,f10,f21
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// fmuls f29,f12,f21
	ctx.f29.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// lfs f9,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// lfs f8,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// lfs f27,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f27.f64 = double(temp.f32);
	// lfs f4,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfs f3,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f15.f64));
	// fmadds f12,f12,f23,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f23.f64 + ctx.f30.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f10,f10,f23,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f23.f64 - ctx.f29.f64));
	// lfs f23,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f10,r10,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,336(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	// fmuls f21,f10,f9
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f30,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f30.f64 = double(temp.f32);
	// lfs f12,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f12.f64 = double(temp.f32);
	// fadds f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f30.f64));
	// lfs f30,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// lfs f27,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f9,f27,f9
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fadds f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f17.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmadds f27,f27,f8,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f8.f64 + ctx.f21.f64));
	// stfsx f27,r10,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f10,f10,f8,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f10,r10,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// fmuls f8,f9,f3
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// lfs f15,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f18.f64 = double(temp.f32);
	// lfs f27,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f27.f64 = double(temp.f32);
	// lfs f14,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f8,f10,f4,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 - ctx.f8.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f10,f3,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f9.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// fmuls f8,f9,f1
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f4,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f16,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// fmsubs f8,f10,f2,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f2.f64 - ctx.f8.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f10,f1,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f1.f64 + ctx.f9.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// lwz r10,264(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// fmuls f8,f9,f30
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fadds f2,f21,f18
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmsubs f12,f10,f12,f8
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f8.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f10,f30,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 + ctx.f9.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// fmuls f9,f10,f26
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// fsubs f8,f15,f17
	ctx.f8.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmsubs f9,f12,f29,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 - ctx.f9.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f26,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 + ctx.f10.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f10,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f26,f25,f4
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// fsubs f9,f10,f12
	ctx.f9.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// lfs f10,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f12,f10,f23
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f23.f64));
	// lfs f30,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f30.f64 = double(temp.f32);
	// fadds f10,f23,f10
	ctx.f10.f64 = double(float(ctx.f23.f64 + ctx.f10.f64));
	// lfs f23,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f23.f64 = double(temp.f32);
	// fadds f3,f23,f19
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// lfs f1,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// fadds f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// lfs f25,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f2.f64));
	// lwz r10,576(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f29,f27,f9
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// fadds f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// fsubs f27,f28,f8
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f8.f64));
	// fadds f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fsubs f28,f14,f3
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f3.f64));
	// fadds f3,f3,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f14.f64));
	// lfs f14,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f14.f64 = double(temp.f32);
	// fadds f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// fmuls f14,f30,f12
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f29.f64));
	// fmsubs f12,f1,f12,f30
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 - ctx.f30.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f1,f29,f14
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f14.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// lfs f1,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f30,f1,f9
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmsubs f10,f12,f10,f30
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f30.f64));
	// stfsx f10,r27,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f9,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f1.f64));
	// stfsx f12,r27,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f26
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// lfs f12,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// lfs f30,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f9,f12,f27,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f9.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f26,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 + ctx.f10.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// lwz r9,272(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// fmuls f9,f10,f4
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f27,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f9,f12,f8,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f9,r29,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f4,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 + ctx.f10.f64));
	// stfsx f12,r29,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f9,f12,f28
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f10,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f10,f28
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f4,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// lfs f28,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f10,f10,f25,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 + ctx.f9.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f12,f12,f25,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64 - ctx.f8.f64));
	// lfs f10,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfs f9,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// lfs f4,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,352(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// fmuls f14,f12,f3
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// lfs f25,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f8,f4,f0
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f4,f1,f0
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f1,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// fmadds f1,f1,f2,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f14.f64));
	// stfsx f1,r19,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fsubs f30,f28,f10
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f10.f64));
	// fsubs f29,f27,f9
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// fadds f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fadds f9,f27,f9
	ctx.f9.f64 = double(float(ctx.f27.f64 + ctx.f9.f64));
	// fmsubs f12,f12,f2,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 - ctx.f3.f64));
	// stfsx f12,r19,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f3,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f28,f25,f8
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f8.f64));
	// lfs f12,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f27,f26,f4
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f4.f64));
	// fadds f4,f26,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 + ctx.f4.f64));
	// fadds f8,f25,f8
	ctx.f8.f64 = double(float(ctx.f25.f64 + ctx.f8.f64));
	// fmuls f2,f3,f29
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmsubs f2,f12,f30,f2
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f2.f64));
	// stfsx f2,r9,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f29,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 + ctx.f3.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lwz r9,296(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// lfs f3,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f3,f9
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f25,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f25.f64 = double(temp.f32);
	// lfs f14,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f29.f64 = double(temp.f32);
	// lfs f26,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f10,f12,f10,f2
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f2.f64));
	// stfsx f10,r9,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f9,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f3.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,32(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfs f10,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f28
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fmuls f3,f10,f28
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f2,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f10,f10,f27,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 + ctx.f9.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f27,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f3.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,428(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// fmuls f9,f12,f8
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f10,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f3,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f8,f10,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f27,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f9,f10,f4,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f9.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f12,f12,f4,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 - ctx.f8.f64));
	// fadds f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// lfs f3,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f10.f64 = double(temp.f32);
	// fadds f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// fsubs f2,f10,f25
	ctx.f2.f64 = double(float(ctx.f10.f64 - ctx.f25.f64));
	// lfs f10,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f1,f14,f10
	ctx.f1.f64 = double(float(ctx.f14.f64 - ctx.f10.f64));
	// lfs f10,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f10.f64 = double(temp.f32);
	// fadds f30,f10,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 + ctx.f30.f64));
	// lfs f10,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f10.f64 = double(temp.f32);
	// fadds f29,f10,f29
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f29.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,476(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// lfs f4,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f10,f9,f0
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f9,f3,f0
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f8,f2,f0
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f2,f30,f0
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f1,f29,f0
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fsubs f30,f31,f10
	ctx.f30.f64 = double(float(ctx.f31.f64 - ctx.f10.f64));
	// fsubs f29,f24,f9
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f9.f64));
	// fadds f9,f24,f9
	ctx.f9.f64 = double(float(ctx.f24.f64 + ctx.f9.f64));
	// lfs f24,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f24.f64 = double(temp.f32);
	// fadds f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f31,f27,f8
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f8.f64));
	// fsubs f28,f26,f3
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fadds f8,f8,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f27.f64));
	// fsubs f27,f24,f2
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// fadds f3,f3,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f26.f64));
	// lfs f26,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f26.f64 = double(temp.f32);
	// fadds f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// lfs f24,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f26,f26,f1
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f1.f64));
	// fadds f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// fmuls f24,f12,f30
	ctx.f24.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f30,f4,f30
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmadds f4,f4,f29,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 + ctx.f24.f64));
	// stfsx f4,r9,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f29,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 - ctx.f30.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f30,f12,f10
	ctx.f30.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fmuls f10,f4,f10
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lwz r9,304(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// fmadds f4,f4,f9,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f30.f64));
	// stfsx f4,r20,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f30.f64 = double(temp.f32);
	// fadds f4,f7,f5
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// lfs f29,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f12,f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 - ctx.f10.f64));
	// stfsx f12,r20,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f10,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f28
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f12,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmsubs f9,f12,f31,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 - ctx.f9.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f28,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64 + ctx.f10.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// lwz r9,20(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fmuls f9,f10,f3
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f28,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f9,f12,f8,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f3,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f10.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,484(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	// fmuls f9,f12,f27
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// lfs f10,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// fadds f3,f6,f30
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// fadds f8,f16,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 + ctx.f8.f64));
	// fmadds f9,f10,f26,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f26.f64 + ctx.f9.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fadds f9,f17,f15
	ctx.f9.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmsubs f12,f12,f26,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 - ctx.f10.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmuls f10,f9,f0
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f9,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f27,f12,f2
	ctx.f27.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmuls f26,f9,f2
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fsubs f31,f11,f8
	ctx.f31.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fadds f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fsubs f8,f29,f3
	ctx.f8.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// fsubs f2,f13,f10
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// fmadds f9,f9,f1,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64 + ctx.f27.f64));
	// stfsx f9,r18,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f1,f26
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f1.f64 - ctx.f26.f64));
	// stfsx f12,r18,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fadds f9,f3,f29
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// lfs f3,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// fadds f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// fsubs f10,f28,f4
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f4.f64));
	// fadds f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f28.f64));
	// fmuls f1,f12,f2
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmadds f3,f3,f31,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f1.f64));
	// stfsx f3,r5,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f31,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 - ctx.f2.f64));
	// stfsx f12,r5,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f3,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f12,f13
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f13,f3,f13
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmadds f3,f3,f11,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 + ctx.f2.f64));
	// stfsx f3,r21,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f13,f12,f11,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f13.f64));
	// stfsx f13,r21,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f10
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f12,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f12,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fmadds f12,f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 + ctx.f11.f64));
	// lwz r9,204(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// fmsubs f13,f13,f8,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 - ctx.f10.f64));
	// fsubs f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// lfs f8,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f8.f64 = double(temp.f32);
	// lfs f2,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// lfs f3,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lwz r9,548(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f12,f4
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmuls f11,f13,f4
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// lfs f4,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// lfs f29,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmsubs f13,f13,f9,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f10.f64));
	// fmadds f12,f12,f9,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f11.f64));
	// lfs f9,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f10,f21,f18
	ctx.f10.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfsx f12,r17,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fsubs f11,f19,f23
	ctx.f11.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// stfsx f13,r17,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfs f8,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// lfs f12,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f1,f30,f7
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// lfs f13,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fadds f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// fsubs f31,f29,f6
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f6.f64));
	// fadds f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f4,f2,f10
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f10.f64));
	// fsubs f5,f3,f11
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// fadds f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f10.f64));
	// fadds f11,f3,f11
	ctx.f11.f64 = double(float(ctx.f3.f64 + ctx.f11.f64));
	// fsubs f2,f22,f8
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f8.f64));
	// fsubs f3,f20,f9
	ctx.f3.f64 = double(float(ctx.f20.f64 - ctx.f9.f64));
	// fadds f8,f22,f8
	ctx.f8.f64 = double(float(ctx.f22.f64 + ctx.f8.f64));
	// fadds f9,f20,f9
	ctx.f9.f64 = double(float(ctx.f20.f64 + ctx.f9.f64));
	// fmuls f30,f12,f4
	ctx.f30.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmuls f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// fmsubs f5,f13,f5,f30
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 - ctx.f30.f64));
	// stfsx f5,r9,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f4,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f4.f64 + ctx.f12.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,244(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// fmuls f5,f12,f10
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmsubs f11,f13,f11,f5
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f5.f64));
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f10,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,556(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	// lfs f13,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f12,f2
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmuls f10,f13,f2
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmsubs f13,f13,f3,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f11.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f12,f3,f10
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f10.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,252(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// fmuls f11,f12,f8
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmsubs f11,f13,f9,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f11.f64));
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f8,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f12.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f13,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,564(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	// fmuls f11,f12,f31
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// lfs f10,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f12,f12,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// lfs f8,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f11,f13,f1,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 - ctx.f11.f64));
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f11,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f13,f13,f31,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f12.f64));
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f10,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfs f9,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f9.f64 = double(temp.f32);
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// lfs f8,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f8.f64 = double(temp.f32);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// fadds f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// lfs f5,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f5.f64 = double(temp.f32);
	// fadds f30,f25,f5
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// lfs f1,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f12,f11,f0
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f31,f11,f6
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmuls f29,f11,f7
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f11,f4,f12
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f12.f64));
	// fsubs f5,f3,f10
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fmsubs f7,f13,f7,f31
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64 - ctx.f31.f64));
	// stfsx f7,r9,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f6,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f6.f64 + ctx.f29.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f7,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f7.f64 = double(temp.f32);
	// fadds f10,f3,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f10.f64));
	// fadds f12,f4,f12
	ctx.f12.f64 = double(float(ctx.f4.f64 + ctx.f12.f64));
	// lwz r9,604(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	// lfs f13,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f4,f1,f9
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f9.f64));
	// fsubs f3,f2,f8
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fadds f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fmuls f6,f7,f5
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// fmuls f7,f7,f11
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fmsubs f11,f13,f11,f6
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f6.f64));
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f5,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f7.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// lwz r9,44(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// fmuls f7,f11,f10
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmsubs f12,f13,f12,f7
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 - ctx.f7.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f10,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 + ctx.f11.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f13,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// lwz r9,16(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfs f12,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f13,f4
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmuls f10,f12,f4
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmadds f12,f12,f3,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f11.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f13,f13,f3,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f10.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// fmuls f11,f13,f9
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f12,f9
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmadds f12,f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 + ctx.f11.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f13,f13,f8,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 - ctx.f10.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f30,f0
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f10,f14,f13
	ctx.f10.f64 = double(float(ctx.f14.f64 + ctx.f13.f64));
	// lfs f8,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f7.f64 = double(temp.f32);
	// lwz r9,364(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// lfs f13,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// lwz r8,612(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	// lfs f11,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f11.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// add r3,r8,r3
	ctx.r3.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r4,r8,r4
	ctx.r4.u64 = ctx.r8.u64 + ctx.r4.u64;
	// stw r9,364(r1)
	PPC_STORE_U32(ctx.r1.u32 + 364, ctx.r9.u32);
	// fsubs f9,f8,f12
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// lwz r9,56(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// fsubs f8,f7,f10
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fadds f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fmuls f7,f13,f9
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmuls f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// fmadds f11,f11,f8,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + ctx.f7.f64));
	// stfs f11,0(r14)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fmsubs f13,f13,f8,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfs f13,0(r9)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fmuls f9,f13,f12
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// fmuls f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmadds f11,f11,f10,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 + ctx.f9.f64));
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,636(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	// fmsubs f13,f13,f10,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 - ctx.f12.f64));
	// stfs f13,0(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// xor r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// bne 0x82d616e4
	if (!ctx.cr0.eq) goto loc_82D616E4;
loc_82D630E0:
	// addi r1,r1,944
	ctx.r1.s64 = ctx.r1.s64 + 944;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D630EC;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D630F0"))) PPC_WEAK_FUNC(sub_82D630F0);
PPC_FUNC_IMPL(__imp__sub_82D630F0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,800
	ctx.r5.s64 = ctx.r11.s64 + 800;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,5800
	ctx.r4.s64 = ctx.r11.s64 + 5800;
	// b 0x82d77f68
	sub_82D77F68(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D63108"))) PPC_WEAK_FUNC(sub_82D63108);
PPC_FUNC_IMPL(__imp__sub_82D63108) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D63110;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D63118;
	__savefpr_14(ctx, base);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82d6359c
	if (!ctx.cr6.lt) goto loc_82D6359C;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r23,r8,r9
	ctx.r23.s64 = ctx.r9.s64 - ctx.r8.s64;
	// stw r10,-304(r1)
	PPC_STORE_U32(ctx.r1.u32 + -304, ctx.r10.u32);
loc_82D63134:
	// rlwinm r8,r7,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r31,r6,1,0,30
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r27,r8,r6
	ctx.r27.u64 = ctx.r8.u64 + ctx.r6.u64;
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r5,r6,3
	ctx.r5.s64 = ctx.r6.s64 * 3;
	// lfsx f8,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f23,f8,f0
	ctx.f23.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// fsubs f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// add r29,r31,r7
	ctx.r29.u64 = ctx.r31.u64 + ctx.r7.u64;
	// fsubs f8,f13,f7
	ctx.f8.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// add r28,r5,r7
	ctx.r28.u64 = ctx.r5.u64 + ctx.r7.u64;
	// fadds f13,f7,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 + ctx.f13.f64));
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfsx f12,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r31,r6,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r29,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// add r26,r6,r7
	ctx.r26.u64 = ctx.r6.u64 + ctx.r7.u64;
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r22,r5,r3
	ctx.r22.u64 = ctx.r5.u64 + ctx.r3.u64;
	// rlwinm r25,r26,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f6,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// add r21,r5,r4
	ctx.r21.u64 = ctx.r5.u64 + ctx.r4.u64;
	// lfsx f5,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f7,f12,f6
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// rlwinm r29,r28,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// add r20,r25,r3
	ctx.r20.u64 = ctx.r25.u64 + ctx.r3.u64;
	// lfsx f4,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r24,r26,3,0,28
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f3,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// add r19,r25,r4
	ctx.r19.u64 = ctx.r25.u64 + ctx.r4.u64;
	// fsubs f6,f5,f11
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// fadds f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// lfs f1,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f2,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f5,f3,f4
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// add r18,r24,r3
	ctx.r18.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfs f28,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f31,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f3,f2,f1
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// add r17,r24,r4
	ctx.r17.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// rlwinm r28,r27,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f27,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f30,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f1,f31,f28
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f28.f64));
	// add r27,r9,r10
	ctx.r27.u64 = ctx.r9.u64 + ctx.r10.u64;
	// fsubs f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// lfs f26,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f28,f27,f30
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// lfsx f10,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// lfs f25,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fadds f27,f26,f10
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f10.f64));
	// lfsx f9,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f10,f10,f26
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f26.f64));
	// lfsx f29,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f26,f9,f25
	ctx.f26.f64 = double(float(ctx.f9.f64 - ctx.f25.f64));
	// lfsx f24,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f9,f25,f9
	ctx.f9.f64 = double(float(ctx.f25.f64 + ctx.f9.f64));
	// fadds f25,f24,f29
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// mulli r25,r7,3
	ctx.r25.s64 = ctx.r7.s64 * 3;
	// fadds f18,f7,f23
	ctx.f18.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// fadds f17,f11,f13
	ctx.f17.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fadds f16,f1,f5
	ctx.f16.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f22,f12,f8
	ctx.f22.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// fadds f15,f30,f2
	ctx.f15.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// fsubs f21,f0,f6
	ctx.f21.f64 = double(float(ctx.f0.f64 - ctx.f6.f64));
	// add r25,r25,r6
	ctx.r25.u64 = ctx.r25.u64 + ctx.r6.u64;
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// mulli r16,r26,12
	ctx.r16.s64 = ctx.r26.s64 * 12;
	// fadds f14,f25,f27
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// mulli r5,r7,12
	ctx.r5.s64 = ctx.r7.s64 * 12;
	// rlwinm r15,r25,2,0,29
	ctx.r15.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r26,r11,16
	ctx.r26.s64 = ctx.r11.s64 + 16;
	// add r14,r16,r4
	ctx.r14.u64 = ctx.r16.u64 + ctx.r4.u64;
	// lfsx f19,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// add r16,r16,r3
	ctx.r16.u64 = ctx.r16.u64 + ctx.r3.u64;
	// stfs f19,-320(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfsx f19,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// add r24,r5,r8
	ctx.r24.u64 = ctx.r5.u64 + ctx.r8.u64;
	// stfs f19,-328(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// addi r25,r11,20
	ctx.r25.s64 = ctx.r11.s64 + 20;
	// lfsx f20,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// stw r16,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r16.u32);
	// add r16,r15,r4
	ctx.r16.u64 = ctx.r15.u64 + ctx.r4.u64;
	// add r15,r15,r3
	ctx.r15.u64 = ctx.r15.u64 + ctx.r3.u64;
	// stfs f19,-312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfsx f24,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// stw r15,-324(r1)
	PPC_STORE_U32(ctx.r1.u32 + -324, ctx.r15.u32);
	// lwz r15,-316(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// lfs f19,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lwz r15,-324(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	// stfs f19,-308(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f19,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-332(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f19,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-336(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f19,f20,f24
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fsubs f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// lfsx f20,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-324(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfsx f20,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f18,0(r3)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f17,0(r4)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfsx f16,r31,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfsx f15,r31,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfsx f14,r8,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f19,f9
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f9.f64));
	// stfsx f14,r8,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-336(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f14,-332(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f20,-328(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// fadds f14,f18,f15
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfsx f14,r10,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f18,-312(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f14,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f14,f21
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f21.f64));
	// fmuls f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f22.f64));
	// lfs f18,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f18,f22,f15
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfsx f22,r5,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fmadds f22,f18,f21,f14
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 + ctx.f14.f64));
	// stfsx f22,r5,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f22,f17
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmuls f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// fadds f0,f6,f0
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// lfs f15,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fmadds f18,f21,f15,f18
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f15.f64 + ctx.f18.f64));
	// stfsx f18,r27,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// lfs f21,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f30.f64));
	// lfs f18,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f18.f64 = double(temp.f32);
	// fadds f11,f29,f26
	ctx.f11.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// fsubs f30,f26,f29
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fsubs f8,f23,f7
	ctx.f8.f64 = double(float(ctx.f23.f64 - ctx.f7.f64));
	// fmsubs f1,f22,f15,f17
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f15.f64 - ctx.f17.f64));
	// stfsx f1,r27,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f29,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f7,f10,f24
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f24.f64));
	// fmuls f26,f29,f0
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// lfs f1,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fadds f23,f21,f18
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// fsubs f6,f20,f16
	ctx.f6.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// fadds f10,f24,f10
	ctx.f10.f64 = double(float(ctx.f24.f64 + ctx.f10.f64));
	// fmsubs f12,f1,f12,f26
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 - ctx.f26.f64));
	// stfsx f12,r30,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fmadds f0,f1,f0,f29
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f29.f64));
	// stfsx f0,r30,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f0,f8
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// fmuls f8,f12,f8
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmadds f12,f12,f13,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f1.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f0,f0,f13,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - ctx.f8.f64));
	// stfsx f0,r9,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r9,-304(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	// fmuls f12,f13,f7
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f0,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fsubs f8,f3,f31
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fmsubs f12,f0,f11,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f11.f64 - ctx.f12.f64));
	// stfsx f12,r24,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fmadds f0,f0,f7,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 + ctx.f13.f64));
	// stfsx f0,r24,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fadds f7,f28,f4
	ctx.f7.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// fmuls f12,f13,f23
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmsubs f12,f0,f6,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f6.f64 - ctx.f12.f64));
	// stfsx f12,r29,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fmadds f0,f0,f23,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64 + ctx.f13.f64));
	// stfsx f0,r29,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f5
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f11,f13,f5
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fsubs f5,f4,f28
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// fmadds f13,f13,f2,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f12.f64));
	// stfsx f13,r28,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f0,f0,f2,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f2.f64 - ctx.f11.f64));
	// stfsx f0,r28,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f9,f19
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f19.f64));
	// fmuls f6,f13,f10
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f13,f30
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r4,r9,r4
	ctx.r4.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fsubs f13,f27,f25
	ctx.f13.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f11,f16,f20
	ctx.f11.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fsubs f9,f18,f21
	ctx.f9.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// fmsubs f6,f0,f30,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f30.f64 - ctx.f6.f64));
	// stfs f6,0(r21)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fmadds f0,f0,f10,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 + ctx.f2.f64));
	// stfs f0,0(r22)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fadds f6,f31,f3
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lwz r9,-316(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f0,f13
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fmuls f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmadds f10,f10,f12,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f4.f64));
	// stfs f10,0(r18)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fmsubs f0,f0,f12,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64 - ctx.f13.f64));
	// stfs f0,0(r17)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// lfs f13,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f9
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f0,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmsubs f12,f0,f11,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f11.f64 - ctx.f12.f64));
	// stfs f12,0(r14)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fmadds f0,f0,f9,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 + ctx.f13.f64));
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// fmuls f12,f13,f7
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fmsubs f12,f0,f8,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f8.f64 - ctx.f12.f64));
	// stfs f12,0(r19)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fmadds f0,f0,f7,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 + ctx.f13.f64));
	// stfs f0,0(r20)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// lfs f13,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f5
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// lfs f0,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmsubs f12,f0,f6,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f6.f64 - ctx.f12.f64));
	// stfs f12,0(r16)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fmadds f0,f0,f5,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f5.f64 + ctx.f13.f64));
	// stfs f0,0(r15)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// xor r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// bne 0x82d63134
	if (!ctx.cr0.eq) goto loc_82D63134;
loc_82D6359C:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D635A4;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D635A8"))) PPC_WEAK_FUNC(sub_82D635A8);
PPC_FUNC_IMPL(__imp__sub_82D635A8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,872
	ctx.r5.s64 = ctx.r11.s64 + 872;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,12552
	ctx.r4.s64 = ctx.r11.s64 + 12552;
	// b 0x82d77f68
	sub_82D77F68(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D635C0"))) PPC_WEAK_FUNC(sub_82D635C0);
PPC_FUNC_IMPL(__imp__sub_82D635C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D635C8;
	__savegprlr_26(ctx, base);
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82d636c0
	if (!ctx.cr6.lt) goto loc_82D636C0;
	// rlwinm r27,r10,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r8.s64;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
loc_82D635E4:
	// add r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 + ctx.r7.u64;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r8,r7,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r30,r9,r3
	ctx.r30.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r29,r8,r3
	ctx.r29.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r28,r5,r3
	ctx.r28.u64 = ctx.r5.u64 + ctx.r3.u64;
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fadds f6,f12,f0
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// lfs f9,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// lfs f11,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fadds f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfs f8,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// addi r31,r11,4
	ctx.r31.s64 = ctx.r11.s64 + 4;
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stfs f6,0(r3)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f6,f11,f13
	ctx.f6.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfs f6,0(r4)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfs f12,0(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fsubs f12,f10,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f10,0(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f9,f8,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfs f8,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fmuls f11,f10,f12
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmuls f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmadds f11,f8,f9,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f11.f64));
	// stfs f11,0(r28)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fmsubs f12,f10,f9,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f12.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// lfs f11,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f0
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmadds f11,f11,f13,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f10.f64));
	// stfs f11,0(r29)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fmsubs f0,f12,f13,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f0.f64));
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lwz r9,3532(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// xor r6,r9,r6
	ctx.r6.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// xor r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 ^ ctx.r7.u64;
	// bne 0x82d635e4
	if (!ctx.cr0.eq) goto loc_82D635E4;
loc_82D636C0:
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D636C8"))) PPC_WEAK_FUNC(sub_82D636C8);
PPC_FUNC_IMPL(__imp__sub_82D636C8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,944
	ctx.r5.s64 = ctx.r11.s64 + 944;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,13760
	ctx.r4.s64 = ctx.r11.s64 + 13760;
	// b 0x82d77f68
	sub_82D77F68(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D636E0"))) PPC_WEAK_FUNC(sub_82D636E0);
PPC_FUNC_IMPL(__imp__sub_82D636E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D636E8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D636F0;
	__savefpr_14(ctx, base);
	// stwu r1,-960(r1)
	ea = -960 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r7,40
	ctx.r11.s64 = ctx.r7.s64 * 40;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d673f8
	if (!ctx.cr6.lt) goto loc_82D673F8;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f0,-5420(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -5420);
	ctx.f0.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// stfs f0,632(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 632, temp.u32);
	// stw r10,652(r1)
	PPC_STORE_U32(ctx.r1.u32 + 652, ctx.r10.u32);
	// lfs f0,-5424(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -5424);
	ctx.f0.f64 = double(temp.f32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// stfs f0,620(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f0,-5428(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -5428);
	ctx.f0.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// stfs f0,648(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 648, temp.u32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f0,-5432(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -5432);
	ctx.f0.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// stfs f0,640(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 640, temp.u32);
	// stw r10,588(r1)
	PPC_STORE_U32(ctx.r1.u32 + 588, ctx.r10.u32);
	// lfs f0,-5444(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -5444);
	ctx.f0.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// stfs f0,628(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f0,-5448(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -5448);
	ctx.f0.f64 = double(temp.f32);
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// stfs f0,624(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// lfs f0,-5440(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -5440);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// stfs f0,644(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 644, temp.u32);
	// lfs f0,-5436(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -5436);
	ctx.f0.f64 = double(temp.f32);
	// lfs f7,-8008(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8008);
	ctx.f7.f64 = double(temp.f32);
	// lfs f10,-8016(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -8016);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,136(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 136);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
	// lfs f6,-8012(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -8012);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,-8000(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8000);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,-8004(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8004);
	ctx.f4.f64 = double(temp.f32);
	// stfs f0,636(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 636, temp.u32);
loc_82D637AC:
	// lfs f1,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfs f9,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f31,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f23,f9,f1
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// stfs f23,24(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f23,f9,f31
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f3,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f3.f64 = double(temp.f32);
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f27,f3,f31
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// stfs f23,40(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f23,f8,f3
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// stfs f23,16(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f30,f3,f1
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f2,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f14,f9,f3
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmuls f23,f8,f2
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// lfs f0,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f28,f2,f31
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f23,20(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f26,f13,f31
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f25,f0,f31
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f31,f8,f31
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// stfs f31,344(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fmuls f21,f13,f1
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmuls f24,f0,f1
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmuls f15,f9,f2
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmuls f29,f2,f1
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// fmuls f18,f0,f3
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmuls f17,f13,f2
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f16,f13,f3
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f19,f0,f2
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f1,f8,f1
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// stfs f1,248(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fsubs f1,f30,f28
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f1,204(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fadds f22,f21,f25
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfs f22,232(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fsubs f21,f21,f25
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// stfs f21,456(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,408(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// fsubs f28,f24,f26
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfs f28,412(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fadds f23,f24,f26
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f23,268(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fadds f31,f27,f29
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfs f31,468(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fsubs f20,f18,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f20,208(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fadds f26,f17,f18
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f26,464(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfs f29,384(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fsubs f27,f16,f19
	ctx.f27.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfs f27,472(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f19,424(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f25.f64 = double(temp.f32);
	// fadds f24,f25,f15
	ctx.f24.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f24,292(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,188(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f25,f9,f13
	ctx.f25.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f24,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f24.f64 = double(temp.f32);
	// fadds f18,f24,f14
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f18,496(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// fmuls f18,f8,f0
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f24,316(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fmuls f24,f9,f0
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fadds f17,f18,f25
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f17,f8,f13
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fsubs f15,f17,f24
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fadds f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,532(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f24,452(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// fmuls f14,f9,f30
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f14,f8,f29
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f14,f1,f13
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f14,f31,f0
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f14,f1,f0
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f14,f30,f13
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// stfs f25,388(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fmuls f24,f8,f30
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// stfs f15,500(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f0,f29,f0
	ctx.f0.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// stfs f0,92(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmuls f30,f31,f13
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// stfs f30,248(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f25,f8,f1
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f15,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f9,f31
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f17,f9,f29
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f16,f9,f1
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// fmuls f15,f8,f31
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f30,f29,f13
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fsubs f13,f25,f18
	ctx.f13.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// stfs f13,196(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fadds f13,f18,f25
	ctx.f13.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f13,f17,f24
	ctx.f13.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// stfs f13,76(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f13,f24,f17
	ctx.f13.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// stfs f13,68(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fadds f13,f15,f16
	ctx.f13.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f13,320(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fsubs f13,f16,f15
	ctx.f13.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f13,104(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f13,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// lfs f29,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f25,f13,f29
	ctx.f25.f64 = double(float(ctx.f13.f64 - ctx.f29.f64));
	// stfs f25,144(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fadds f13,f29,f13
	ctx.f13.f64 = double(float(ctx.f29.f64 + ctx.f13.f64));
	// stfs f13,128(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fadds f29,f0,f14
	ctx.f29.f64 = double(float(ctx.f0.f64 + ctx.f14.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f13,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f13.f64 = double(temp.f32);
	// fadds f18,f13,f15
	ctx.f18.f64 = double(float(ctx.f13.f64 + ctx.f15.f64));
	// lfs f0,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f0.f64 = double(temp.f32);
	// lfs f24,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f24.f64 = double(temp.f32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f25,f24,f30
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// fadds f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// lfs f24,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f24.f64 = double(temp.f32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f24,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f13,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// stfs f18,276(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// stfs f29,448(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// stfs f25,436(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// stfs f30,192(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// stfs f17,432(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f24,344(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// stfs f15,264(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f14,f18,f8
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f18,f9,f21
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f18,f8,f23
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f23.f64));
	// stfs f18,348(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmuls f23,f9,f23
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// stfs f23,416(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f23,f9,f19
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f19.f64));
	// stfs f23,332(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmuls f23,f8,f20
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f20.f64));
	// stfs f23,340(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f23,f8,f19
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// stfs f23,352(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fmuls f23,f9,f20
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f20.f64));
	// stfs f23,356(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fmuls f21,f8,f21
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// stfs f21,428(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// fmuls f23,f9,f22
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f22.f64));
	// stfs f23,260(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f23,f8,f28
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// stfs f23,20(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f23,f8,f22
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// stfs f23,24(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f23,f9,f28
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// stfs f23,364(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fmuls f22,f30,f9
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// stfs f22,60(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f22,f30,f8
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// stfs f22,376(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmuls f22,f17,f9
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// stfs f22,404(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fmuls f22,f16,f8
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f8.f64));
	// stfs f22,420(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// fmuls f22,f16,f9
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// stfs f22,372(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fmuls f22,f24,f8
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmuls f22,f15,f8
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// stfs f22,380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fmuls f22,f15,f9
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// stfs f22,400(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// fmuls f20,f9,f26
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmuls f21,f8,f27
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f19,f9,f27
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmuls f18,f8,f26
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmuls f17,f17,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// fadds f23,f20,f21
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f23,444(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,328(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fsubs f23,f19,f18
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f23,284(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f22,440(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// lfs f15,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f22,460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f15,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f15,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// lfs f20,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f21
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f22,396(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// stfs f20,160(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f22,308(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// stfs f20,304(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fadds f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f20,216(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f20,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f29,f9
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,164(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f20,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f25,f9
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// lfs f21,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f31,f0,f31
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,212(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f21,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// stfs f21,272(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f20,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f25,f8
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// lfs f21,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f21,220(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f20,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fmuls f20,f29,f8
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fsubs f15,f19,f16
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f15,332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f15,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f0,f15
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f15.f64));
	// fadds f21,f18,f20
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f21,36(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,100(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f20,f16,f19
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f20,520(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// lfs f20,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// stfs f20,428(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// fadds f20,f17,f18
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f20,416(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f20,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f16,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,336(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f19,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f20,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f20,352(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fmuls f20,f24,f9
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// stfs f18,356(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f17,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f14.f64 = double(temp.f32);
	// stfs f19,260(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// stfs f18,364(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fsubs f16,f16,f20
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f16,540(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,348(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f20.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f20,340(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmadds f20,f13,f23,f15
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f23.f64 + ctx.f15.f64));
	// stfs f20,380(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f20,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f0,f20
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f20.f64));
	// fmsubs f20,f13,f21,f20
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f21.f64 - ctx.f20.f64));
	// stfs f20,172(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f20,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f0,f18
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f18.f64));
	// fmuls f20,f0,f20
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f20.f64));
	// fmuls f14,f0,f3
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmuls f3,f0,f1
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// stfs f3,16(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmsubs f1,f13,f1,f31
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 - ctx.f31.f64));
	// stfs f1,48(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmuls f29,f0,f29
	ctx.f29.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// lfs f1,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f24,f13,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// fmuls f19,f0,f19
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmuls f21,f0,f21
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f21.f64));
	// fmuls f23,f0,f23
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmuls f2,f0,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// stfs f2,20(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmsubs f31,f13,f1,f20
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 - ctx.f20.f64));
	// stfs f31,180(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f31,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f17,f0,f22
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f22.f64));
	// fmsubs f31,f13,f31,f18
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f18.f64));
	// stfs f31,244(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f31,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f22,f13,f22
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// fmadds f31,f13,f31,f29
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f29.f64));
	// lfs f29,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f29.f64 = double(temp.f32);
	// stfs f31,372(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fmadds f31,f0,f29,f24
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f29.f64 + ctx.f24.f64));
	// stfs f31,120(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f16,f13,f28
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f31,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f27,f0,f27
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fmadds f31,f13,f31,f19
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f19.f64));
	// stfs f31,124(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f31,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f25,f0,f25
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmadds f31,f13,f31,f21
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f21.f64));
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f31,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f15,f0,f30
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmsubs f31,f13,f31,f23
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f23.f64));
	// stfs f31,400(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// lfs f31,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f13,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fmr f3,f31
	ctx.f3.f64 = ctx.f31.f64;
	// fmuls f28,f0,f28
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// fmuls f26,f0,f26
	ctx.f26.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// fmsubs f31,f13,f3,f17
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f17.f64));
	// stfs f31,492(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// fmadds f3,f0,f3,f22
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f3.f64 + ctx.f22.f64));
	// stfs f3,528(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// lfs f3,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f3.f64 = double(temp.f32);
	// fmr f2,f3
	ctx.f2.f64 = ctx.f3.f64;
	// lfs f31,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f3,f0,f2,f16
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f2.f64 + ctx.f16.f64));
	// stfs f3,224(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f3,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f3,f13,f3,f27
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 + ctx.f27.f64));
	// stfs f3,28(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f3,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f13,f3,f25
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f25.f64));
	// stfs f3,376(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmsubs f3,f13,f31,f15
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f15.f64));
	// stfs f3,508(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// lfs f3,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f3,f13,f3,f14
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 + ctx.f14.f64));
	// stfs f3,420(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f3,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f3.f64 = double(temp.f32);
	// lfs f27,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f3,f13,f3,f27
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 + ctx.f27.f64));
	// stfs f3,156(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmadds f3,f0,f31,f30
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f31.f64 + ctx.f30.f64));
	// stfs f3,524(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// fmsubs f3,f13,f2,f28
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 - ctx.f28.f64));
	// stfs f3,324(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f3,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f3,f13,f3,f30
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f30.f64));
	// stfs f3,404(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// lfs f3,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f13,f3,f26
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f26.f64));
	// stfs f3,52(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f3,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f31,f0,f3
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f23,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f0,f23
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// stfs f23,24(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f25,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f0,f25
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// lfs f25,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f25.f64 = double(temp.f32);
	// lfs f3,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f0,f25
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f30,f0,f3
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f25,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f25.f64 = double(temp.f32);
	// lfs f3,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f25,f0,f25
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f28,f0,f3
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// stfs f25,20(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f0,f3
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f31,f13,f29,f31
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f29.f64 - ctx.f31.f64));
	// stfs f31,140(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f31,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f24,f0,f3
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmr f23,f31
	ctx.f23.f64 = ctx.f31.f64;
	// lfs f2,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f19,f13,f3
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// lfs f3,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f0,f3
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f0,f3
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f0,f2
	ctx.f26.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f15,f0,f3
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f0,f3
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f0,f3
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// stfs f3,16(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f20,f13,f2
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// lfs f3,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f1,f13,f23,f1
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f23.f64 + ctx.f1.f64));
	// stfs f1,288(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f1,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f0,f2
	ctx.f16.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmr f25,f1
	ctx.f25.f64 = ctx.f1.f64;
	// fmuls f2,f13,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmadds f1,f13,f25,f30
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f25.f64 + ctx.f30.f64));
	// stfs f1,84(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f1,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f13,f1,f28
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f28.f64));
	// stfs f1,228(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f1,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f13,f1,f27
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f27,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f27.f64 = double(temp.f32);
	// stfs f1,176(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmsubs f1,f13,f27,f26
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f27.f64 - ctx.f26.f64));
	// stfs f1,512(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// fmsubs f1,f13,f3,f24
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f24.f64));
	// stfs f1,72(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f1,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f1,f13,f1,f22
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 - ctx.f22.f64));
	// lfs f26,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f26.f64 = double(temp.f32);
	// stfs f1,368(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fmsubs f1,f13,f26,f21
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f26.f64 - ctx.f21.f64));
	// stfs f1,184(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmadds f1,f0,f27,f20
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f27.f64 + ctx.f20.f64));
	// stfs f1,504(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fmadds f1,f0,f3,f19
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f3.f64 + ctx.f19.f64));
	// lfs f28,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f28.f64 = double(temp.f32);
	// stfs f1,116(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmsubs f1,f13,f28,f18
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f28.f64 - ctx.f18.f64));
	// stfs f1,516(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// lfs f1,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f1.f64 = double(temp.f32);
	// lfs f30,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f1,f13,f1,f17
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 - ctx.f17.f64));
	// stfs f1,200(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmsubs f1,f13,f30,f16
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f30.f64 - ctx.f16.f64));
	// stfs f1,240(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// stfs f2,40(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// rlwinm r9,r6,6,0,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f1,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f1.f64 = double(temp.f32);
	// mulli r8,r6,192
	ctx.r8.s64 = ctx.r6.s64 * 192;
	// fmadds f1,f13,f1,f15
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f15.f64));
	// stfs f1,384(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f1,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f31,f13,f1,f14
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f14.f64));
	// stfs f31,112(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f31,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f31.f64 = double(temp.f32);
	// lfs f2,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f31,f13,f2,f31
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 - ctx.f31.f64));
	// stfs f31,388(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f31,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f31.f64 = double(temp.f32);
	// rlwinm r7,r6,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f24,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f24.f64 = double(temp.f32);
	// mulli r5,r6,160
	ctx.r5.s64 = ctx.r6.s64 * 160;
	// fmsubs f24,f13,f31,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f24.f64));
	// stfs f24,360(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f13,f22,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f22.f64 - ctx.f24.f64));
	// stfs f24,456(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// rlwinm r10,r6,7,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 7) & 0xFFFFFF80;
	// lfsx f17,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f19,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f15.f64));
	// lfsx f18,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f0,f30,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f30.f64 + ctx.f24.f64));
	// stfs f24,132(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f24,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f21,f13,f24
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// lfs f24,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f24.f64 = double(temp.f32);
	// stfs f17,268(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f20,f13,f24
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// lfsx f17,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,276(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfsx f17,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f17,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f17,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f21,f0,f28,f21
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f28.f64 + ctx.f21.f64));
	// stfs f21,536(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// fmadds f21,f0,f31,f20
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f31.f64 + ctx.f20.f64));
	// stfs f21,256(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfsx f21,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// lfsx f20,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f19,f16
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f19,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f19,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f18,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmadds f19,f20,f18,f17
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 + ctx.f17.f64));
	// lfs f18,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f20,f18,f21
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 - ctx.f21.f64));
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f21,f20,f16
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f16.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f20,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f20.f64));
	// lfs f17,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f21,f17,f15
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f16,f21,f16,f14
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,408(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f16,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f16.f64 = double(temp.f32);
	// mulli r30,r6,96
	ctx.r30.s64 = ctx.r6.s64 * 96;
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f21,f16,f15
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f21,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f15,f15,f21,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f20.f64 = double(temp.f32);
	// mulli r28,r6,144
	ctx.r28.s64 = ctx.r6.s64 * 144;
	// fmsubs f21,f20,f21,f14
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,24(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f21,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fadds f20,f19,f21
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f20,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fsubs f14,f20,f18
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfs f18,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f18,232(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f18,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f18.f64 = double(temp.f32);
	// mulli r31,r6,224
	ctx.r31.s64 = ctx.r6.s64 * 224;
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fsubs f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,408(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f16,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fsubs f16,f14,f19
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,392(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fsubs f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f19,616(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f21,592(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f19,416(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// lfs f19,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// stfs f21,296(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fmuls f18,f20,f19
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f21,f19
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// lfs f19,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f21,f19,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f19,f15,f21
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfs f21,412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fsubs f21,f18,f20
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// lfsx f15,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f20,60(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f20,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f18,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f21,f19
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f21,264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfsx f21,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,20(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f21,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f21,268(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfsx f21,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f14,232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stfs f21,276(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// mulli r27,r6,80
	ctx.r27.s64 = ctx.r6.s64 * 80;
	// lfs f21,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f21.f64 = double(temp.f32);
	// mulli r26,r6,208
	ctx.r26.s64 = ctx.r6.s64 * 208;
	// fmuls f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64));
	// lfs f19,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// lfs f19,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f14,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f21,f18,f14,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f18,f14,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f14.f64 - ctx.f20.f64));
	// stfs f20,24(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f19,f20,f14,f19
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f19,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f14.f64));
	// lfs f19,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f15.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f19,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f19
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f19,f20,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64 + ctx.f18.f64));
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfs f19,396(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f15.f64));
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f15,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfs f14,400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// fadds f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,300(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f21,f15
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfs f18,364(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfs f21,376(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f21,f14
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// fadds f15,f14,f21
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// lfs f21,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f19,f21
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// fmuls f19,f18,f12
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f19,584(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// fmuls f19,f15,f12
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfs f19,488(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f19,f14,f12
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f19,548(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// stfs f21,556(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 556, temp.u32);
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f20,f21
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f21,460(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// mulli r25,r6,240
	ctx.r25.s64 = ctx.r6.s64 * 240;
	// lfs f21,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f21.f64 = double(temp.f32);
	// mulli r24,r6,112
	ctx.r24.s64 = ctx.r6.s64 * 112;
	// fmsubs f21,f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 - ctx.f19.f64));
	// lfs f20,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// stfs f18,92(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f15,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f15,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f18,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f19,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f15,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,396(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// lfsx f15,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,424(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// stfs f21,264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfsx f21,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f14.f64));
	// fmuls f15,f21,f15
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f15.f64));
	// lfs f21,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// lfsx f20,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f21,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f20,f21,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 + ctx.f15.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f20,f15,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 - ctx.f14.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f15.f64));
	// lfs f20,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f14,f20,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f20.f64 + ctx.f18.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f14,f20,f19
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f19,f14,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f19,f15,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64 - ctx.f18.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fsubs f18,f15,f20
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f19,f15
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,44(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fsubs f19,f15,f18
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// lfs f14,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f18,f14,f20
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// lfs f15,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f18,f15,f21
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfs f21,380(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fadds f21,f20,f14
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f21,412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmuls f20,f19,f10
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fmuls f15,f21,f11
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f21,f11
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// rlwinm r21,r6,3,0,28
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f21,468(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// mulli r22,r6,176
	ctx.r22.s64 = ctx.r6.s64 * 176;
	// fmsubs f20,f21,f11,f20
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 - ctx.f20.f64));
	// stfs f20,552(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// fmadds f21,f21,f10,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f19.f64));
	// stfs f21,596(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f10,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 - ctx.f15.f64));
	// stfs f21,480(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f19,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f19.f64 = double(temp.f32);
	// mulli r23,r6,48
	ctx.r23.s64 = ctx.r6.s64 * 48;
	// lfs f20,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f19,f20
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// fmadds f21,f21,f10,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f14.f64));
	// stfs f21,564(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// lfs f21,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f19,f21
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f19,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f21,f19,f21,f18
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 + ctx.f18.f64));
	// fmsubs f20,f19,f20,f15
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64 - ctx.f15.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f15,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f15,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f19,f21
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f18,92(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f21,264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f21,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f19,f21,f20
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f19,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// stfs f21,44(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f21,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f14.f64));
	// fmuls f15,f21,f15
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f15.f64));
	// lfs f21,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f18,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// lfsx f20,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f20,f21,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 + ctx.f15.f64));
	// lfs f15,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f20,f15,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 - ctx.f14.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f26
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f20,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f14,f20,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f20.f64 + ctx.f18.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f25
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f14,f20,f19
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f25,f19,f25,f15
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f25.f64 + ctx.f15.f64));
	// fmsubs f26,f19,f26,f18
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 - ctx.f18.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// mulli r19,r6,72
	ctx.r19.s64 = ctx.r6.s64 * 72;
	// fsubs f18,f15,f20
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// mulli r18,r6,200
	ctx.r18.s64 = ctx.r6.s64 * 200;
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f19,f15
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f18
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// mulli r17,r6,40
	ctx.r17.s64 = ctx.r6.s64 * 40;
	// fsubs f18,f15,f21
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfs f21,276(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f21,268(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f15,f19,f10
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// mulli r16,r6,168
	ctx.r16.s64 = ctx.r6.s64 * 168;
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// mulli r15,r6,232
	ctx.r15.s64 = ctx.r6.s64 * 232;
	// mulli r20,r6,136
	ctx.r20.s64 = ctx.r6.s64 * 136;
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f10
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,428(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f18,f11,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f20.f64));
	// stfs f20,612(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f21,f20,f11,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 - ctx.f21.f64));
	// stfs f21,604(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f18,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f21,f11,f15
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f15.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmsubs f21,f21,f10,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 - ctx.f19.f64));
	// lfsx f18,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f18,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f18,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f18,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f18,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f18,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,204(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfsx f18,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,292(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfsx f18,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f21,600(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// stfs f18,316(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfsx f21,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f21,f18
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// lfs f18,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f21,f18
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// lfsx f19,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// stfs f20,572(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// lfsx f20,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// stfs f21,24(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmadds f21,f20,f18,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f20,f20,f18,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfs f20,100(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f20,f18
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f18.f64));
	// fmuls f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f15.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f23,f20,f23,f14
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 + ctx.f14.f64));
	// lfs f14,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f20,f14,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f14.f64 - ctx.f19.f64));
	// stfs f20,232(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f20,f24
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f24.f64));
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f24
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f24.f64));
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f20,f24,f18
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f20,f20,f18,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 - ctx.f15.f64));
	// stfs f20,140(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f20,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f20.f64));
	// fmuls f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f31,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64 + ctx.f19.f64));
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f31,f19,f31,f14
	ctx.f31.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 - ctx.f14.f64));
	// stfs f31,16(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f31,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f31.f64 = double(temp.f32);
	// lfs f19,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f31,f19
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f19.f64));
	// lfs f19,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f19.f64 = double(temp.f32);
	// lfs f31,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f31,f31,f19,f18
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f18,f19,f15
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f15.f64));
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f18,f24,f23
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fadds f15,f31,f20
	ctx.f15.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// fsubs f31,f20,f31
	ctx.f31.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// stfs f31,20(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f31,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f31.f64 = double(temp.f32);
	// fadds f20,f19,f31
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f31.f64));
	// stfs f20,56(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f31,f31,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f19.f64));
	// stfs f31,120(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f31,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f31.f64 = double(temp.f32);
	// lfs f20,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64));
	// lfs f19,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f19.f64 = double(temp.f32);
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f20,f19,f31,f14
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 + ctx.f14.f64));
	// lfs f31,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f31.f64 = double(temp.f32);
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f31.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f31.f64));
	// lfs f31,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f26,f26,f31
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f31.f64));
	// fsubs f31,f23,f24
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// stfs f31,20(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f31,f21,f25
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// lfs f24,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f31,f24
	ctx.f24.f64 = double(float(ctx.f31.f64 - ctx.f24.f64));
	// stfs f24,100(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f24,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfs f24,204(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,104
	ctx.r14.s64 = ctx.r6.s64 * 104;
	// lfs f23,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f23,f24,f14
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64 - ctx.f14.f64));
	// lfs f21,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fadds f31,f21,f31
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f31.f64));
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f18,f26
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// stfs f14,484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// fsubs f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f18.f64));
	// stfs f26,580(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// fsubs f26,f25,f23
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfs f26,576(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// fadds f26,f23,f25
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfs f26,476(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfsx f26,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f23,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r14,r6,248
	ctx.r14.s64 = ctx.r6.s64 * 248;
	// stfs f23,20(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f25,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r14,r6,120
	ctx.r14.s64 = ctx.r6.s64 * 120;
	// stfs f25,24(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f25,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,120(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfsx f25,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,36(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f25,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f23,f25
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// fmuls f14,f26,f25
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f18,f25
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// lfs f25,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f26,f25,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f25.f64 + ctx.f23.f64));
	// stfs f26,40(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f23,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f26,f23
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f26,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f26,f26,f25,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f25.f64 - ctx.f14.f64));
	// stfs f26,140(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f25,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f25.f64 = double(temp.f32);
	// lfs f14,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f26,f25
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f26,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f26,f14,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f26,f26,f18,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 - ctx.f23.f64));
	// lfs f23,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f25,f23,f18,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f18.f64 + ctx.f25.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f20,f18
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f24,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfs f18,112(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fadds f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// fsubs f18,f20,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f23,f18
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,292(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// fadds f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// stfs f24,316(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f20,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f20.f64 = double(temp.f32);
	// mulli r14,r6,184
	ctx.r14.s64 = ctx.r6.s64 * 184;
	// lfs f24,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// stfs f24,152(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f24,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f24.f64 = double(temp.f32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f20,f24
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stw r14,420(r1)
	PPC_STORE_U32(ctx.r1.u32 + 420, ctx.r14.u32);
	// fadds f20,f24,f20
	ctx.f20.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// mulli r14,r6,56
	ctx.r14.s64 = ctx.r6.s64 * 56;
	// fsubs f24,f19,f23
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// stfs f24,16(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// stfs f20,560(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stfs f23,332(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f23,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f31,f19
	ctx.f19.f64 = double(float(ctx.f31.f64 - ctx.f19.f64));
	// stfs f19,384(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f19,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f19,232(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f19,312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,236(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f19,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fadds f24,f19,f18
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// stfs f20,608(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f15,f12
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmsubs f23,f23,f20,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64 - ctx.f14.f64));
	// stfs f23,60(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f20,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f19,568(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// lfs f14,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f23,204(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfsx f23,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,420(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// fmuls f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f14.f64));
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,24
	ctx.r14.s64 = ctx.r6.s64 * 24;
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,152
	ctx.r14.s64 = ctx.r6.s64 * 152;
	// stfs f15,112(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,136(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,216
	ctx.r14.s64 = ctx.r6.s64 * 216;
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,140(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,88
	ctx.r14.s64 = ctx.r6.s64 * 88;
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// lfs f23,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// fmuls f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// lfs f23,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f20,f23,f15
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 + ctx.f15.f64));
	// stfs f23,36(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f23,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f20,f23,f14
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,56(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f23,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f23
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f23
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// lfs f23,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f23,f23,f20,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64 + ctx.f18.f64));
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f20,f18,f20,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f20.f64 - ctx.f19.f64));
	// stfs f20,208(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f20,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f30,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 + ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f30,f15,f30,f14
	ctx.f30.f64 = double(float(ctx.f15.f64 * ctx.f30.f64 - ctx.f14.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f30,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f30.f64 = double(temp.f32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f15.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f19,f14,f30,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f30.f64 + ctx.f19.f64));
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f19,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f19.f64));
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f30,f19,f30,f18
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 - ctx.f18.f64));
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f15,f18,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,112(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f15,f20
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f30,f15
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f30.f64));
	// stfs f30,72(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f30,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f30.f64 = double(temp.f32);
	// lfs f15,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f15.f64));
	// fmuls f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f14.f64));
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f20.f64));
	// stfs f30,20(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// stfs f30,24(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f30,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f20,f30,f15
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 + ctx.f15.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// lfs f15,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,252
	ctx.r14.s64 = ctx.r6.s64 * 252;
	// fmsubs f20,f20,f15,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f25,f15
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,92(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfs f25,72(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// lfs f25,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// stfs f25,108(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f25,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f25.f64 = double(temp.f32);
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfs f25,56(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// fsubs f14,f19,f30
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// fadds f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f19.f64));
	// fadds f19,f23,f26
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f19,536(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// fsubs f19,f18,f20
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// lfs f18,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f18,516(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// lfs f18,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,452(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// lfsx f23,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,124
	ctx.r14.s64 = ctx.r6.s64 * 124;
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,60
	ctx.r14.s64 = ctx.r6.s64 * 60;
	// stfs f18,60(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f30,f18
	ctx.f18.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfs f18,264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fadds f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f18.f64));
	// stfs f30,44(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fsubs f30,f14,f19
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f19,f20
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f18,72(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f20,204(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmuls f19,f23,f13
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfsx f20,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f20,f23,f0
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,208(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f18,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f23,f18
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// fmuls f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f14.f64));
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f0,f23,f0,f19
	ctx.f0.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 - ctx.f19.f64));
	// stfs f0,140(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f0,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f13,f23,f13,f20
	ctx.f13.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f13,188(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f23,f30,f0
	ctx.f23.f64 = double(float(ctx.f30.f64 - ctx.f0.f64));
	// fadds f20,f0,f30
	ctx.f20.f64 = double(float(ctx.f0.f64 + ctx.f30.f64));
	// lfs f13,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// mulli r14,r6,188
	ctx.r14.s64 = ctx.r6.s64 * 188;
	// fsubs f19,f0,f13
	ctx.f19.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f30,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f30.f64 = double(temp.f32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f13,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
	// lfs f13,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stw r14,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, ctx.r14.u32);
	// rotlwi r14,r14,0
	ctx.r14.u64 = __builtin_rotateleft32(ctx.r14.u32, 0);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmadds f13,f0,f13,f18
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f13,112(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f13,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f18,f13,f30
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f0,f0,f13,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f30,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f30.f64 = double(temp.f32);
	// lfs f13,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f30.f64));
	// stfs f13,388(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f13,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f25,f13
	ctx.f13.f64 = double(float(ctx.f25.f64 - ctx.f13.f64));
	// stfs f13,372(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f13,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 - ctx.f30.f64));
	// stfs f30,404(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f13.f64));
	// fmuls f13,f19,f12
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f13,532(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// lfs f19,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f13,f19,f12
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f13,356(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f13,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f19,f15,f13
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f13.f64));
	// stfs f19,252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f13,f13,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f15.f64));
	// stfs f13,464(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// lfs f13,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f18,f19,f13,f18
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f18,100(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,120(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f13,f18,f13
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f18,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f13,f19,f18,f13
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f13.f64));
	// stfs f13,208(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f13,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// mulli r14,r6,28
	ctx.r14.s64 = ctx.r6.s64 * 28;
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,156
	ctx.r14.s64 = ctx.r6.s64 * 156;
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f15,284(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,196(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,220
	ctx.r14.s64 = ctx.r6.s64 * 220;
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,320(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,92
	ctx.r14.s64 = ctx.r6.s64 * 92;
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,72(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// fmuls f14,f13,f19
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// lfs f19,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// lfs f19,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f13,f13,f19,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64 + ctx.f18.f64));
	// stfs f13,36(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f13,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f13.f64 = double(temp.f32);
	// lfs f18,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f13,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// lfs f13,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f13,f13,f19,f14
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64 - ctx.f14.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// lfs f19,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f13,f19
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// lfs f14,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f14.f64 = double(temp.f32);
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f15,f13,f14,f15
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,124(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f14,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f13,f13,f14,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f14.f64 - ctx.f18.f64));
	// stfs f13,244(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f13,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f13.f64 = double(temp.f32);
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f13,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// lfs f13,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f19,f13,f14,f19
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,216(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f14.f64));
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f13,f13,f14,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f14.f64 - ctx.f15.f64));
	// stfs f13,328(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f13,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f13.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f13,f15
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// lfs f13,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f18,f13,f14,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,324(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f18,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f13,f13,f18,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f18.f64 - ctx.f19.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f18,f19,f15
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 + ctx.f15.f64));
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f18,f15,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,320(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,196(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f14,224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fadds f14,f18,f13
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f13.f64));
	// fsubs f13,f13,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f18.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// lfs f13,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f18.f64));
	// stfs f13,244(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f13,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f13.f64 = double(temp.f32);
	// lfs f18,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f18.f64 = double(temp.f32);
	// fadds f13,f13,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f18.f64));
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f18,284(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f0,f18
	ctx.f18.f64 = double(float(ctx.f0.f64 + ctx.f18.f64));
	// stfs f18,124(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,80(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,104(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f18,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,124(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,224(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f0,f18,f0
	ctx.f0.f64 = double(float(ctx.f18.f64 - ctx.f0.f64));
	// stfs f0,92(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f0,f18
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f18.f64));
	// stfs f0,60(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f0,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f0.f64 = double(temp.f32);
	// fadds f18,f13,f0
	ctx.f18.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f18,424(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f0,320(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f0,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f18,f0,f13
	ctx.f18.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f0,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f15,f19,f0
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f0.f64));
	// fadds f19,f0,f19
	ctx.f19.f64 = double(float(ctx.f0.f64 + ctx.f19.f64));
	// lfs f0,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f0.f64));
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f0,f0,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f14.f64));
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r14,r6,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f0.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fadds f0,f0,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f14.f64));
	// stfs f0,64(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f0,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f0.f64));
	// stfs f14,544(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// fadds f0,f0,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f14.f64));
	// stfs f0,444(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fmuls f0,f18,f12
	ctx.f0.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f0,492(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// fmuls f0,f13,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f0,340(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f0,f15,f12
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfs f0,540(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// fmuls f0,f19,f12
	ctx.f0.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f0,348(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f13,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f19,f0,f13
	ctx.f19.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f19,188(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,168(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f13,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// fadds f19,f13,f0
	ctx.f19.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f19,508(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfsx f13,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,124(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f0,336(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// mulli r14,r6,132
	ctx.r14.s64 = ctx.r6.s64 * 132;
	// fmuls f15,f1,f0
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfsx f13,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,68
	ctx.r14.s64 = ctx.r6.s64 * 68;
	// stfs f19,244(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,80(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,196
	ctx.r14.s64 = ctx.r6.s64 * 196;
	// stfs f19,116(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f18,f2,f0
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f0,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f14,f0,f13
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// stfs f13,284(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f19,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f19.f64 = double(temp.f32);
	// stfs f0,124(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmr f0,f19
	ctx.f0.f64 = ctx.f19.f64;
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f13,f1,f0,f18
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f18.f64));
	// fmsubs f2,f2,f0,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f15.f64));
	// lfs f0,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f0,f1
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f0,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f0,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f14.f64));
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f19,f0,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 - ctx.f15.f64));
	// lfs f0,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// lfs f15,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f0,f28,f0,f15
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 + ctx.f15.f64));
	// stfs f0,328(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f28,f0,f18
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 - ctx.f18.f64));
	// stfs f0,196(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fadds f28,f19,f2
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// stfs f28,216(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f18,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,36
	ctx.r14.s64 = ctx.r6.s64 * 36;
	// lfs f28,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f28.f64 = double(temp.f32);
	// fadds f0,f1,f13
	ctx.f0.f64 = double(float(ctx.f1.f64 + ctx.f13.f64));
	// fmuls f15,f28,f18
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f28,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f18
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f28,f28,f18,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f15,f18,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f15,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f15.f64 = double(temp.f32);
	// stfs f28,284(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,228(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,164
	ctx.r14.s64 = ctx.r6.s64 * 164;
	// stfs f18,212(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,368(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fadds f14,f28,f0
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// mulli r14,r6,228
	ctx.r14.s64 = ctx.r6.s64 * 228;
	// stfs f0,224(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f0,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f0.f64 = double(temp.f32);
	// fadds f0,f15,f0
	ctx.f0.f64 = double(float(ctx.f15.f64 + ctx.f0.f64));
	// stfs f0,324(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,220(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfsx f0,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f0.f64 = double(temp.f32);
	// mulli r14,r6,100
	ctx.r14.s64 = ctx.r6.s64 * 100;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,124(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfsx f0,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,244(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f0,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// lfs f28,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f0,f15,f0
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f18
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f18.f64));
	// fmuls f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f18.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f28,f14,f3,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f3.f64 + ctx.f28.f64));
	// stfs f28,228(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f28,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f0,f28,f3,f0
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f3.f64 - ctx.f0.f64));
	// stfs f0,212(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f0,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f0.f64 = double(temp.f32);
	// lfs f3,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f0,f3
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f0,f3
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f3.f64 = double(temp.f32);
	// lfs f0,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f3,f3,f0,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f15.f64));
	// stfs f3,200(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f3,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f0,f3,f0,f18
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f18.f64));
	// stfs f0,176(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// lfs f3,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f0
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f3,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f0,f3,f0
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f3,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// lfs f18,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f18.f64 = double(temp.f32);
	// stfs f0,132(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmadds f0,f3,f18,f28
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f18.f64 + ctx.f28.f64));
	// lfs f28,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// fmsubs f3,f3,f28,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64 - ctx.f14.f64));
	// lfs f18,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,148
	ctx.r14.s64 = ctx.r6.s64 * 148;
	// fmadds f28,f28,f18,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f15,f18,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,220(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r14.u32);
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f13,368(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fadds f14,f28,f0
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// lfs f1,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fadds f28,f18,f3
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// fsubs f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f18.f64));
	// fsubs f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// stfs f13,124(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f18,132(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// stfs f28,240(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f28,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f28,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f28,208(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// stfs f28,32(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f28,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f28.f64 = double(temp.f32);
	// lfs f18,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f18,224(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f18,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// fsubs f18,f0,f3
	ctx.f18.f64 = double(float(ctx.f0.f64 - ctx.f3.f64));
	// stfs f18,132(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// fadds f0,f3,f0
	ctx.f0.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,240(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fsubs f3,f2,f19
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// lfs f19,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// lfs f2,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// fsubs f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f13,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// lfs f1,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f14,f13,f1
	ctx.f14.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f13,f1,f13
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f13.f64));
	// mulli r14,r6,20
	ctx.r14.s64 = ctx.r6.s64 * 20;
	// fsubs f1,f18,f0
	ctx.f1.f64 = double(float(ctx.f18.f64 - ctx.f0.f64));
	// fadds f0,f0,f18
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f18.f64));
	// fadds f18,f2,f3
	ctx.f18.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f14,f3,f2
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f13,f1,f12
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// stfs f13,496(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// stfs f0,440(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fadds f0,f15,f19
	ctx.f0.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f0,216(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f13,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f2,f0,f13
	ctx.f2.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f2,504(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,36(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// lfsx f13,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,140(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lfsx f2,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// mulli r14,r6,52
	ctx.r14.s64 = ctx.r6.s64 * 52;
	// stfs f1,240(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f3,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// stfs f3,512(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// fsubs f3,f19,f15
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,76(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,180
	ctx.r14.s64 = ctx.r6.s64 * 180;
	// stfs f19,144(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f2,132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f15,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f0,f15
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f15.f64));
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,176(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,200(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f19,f0,f22
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f22.f64));
	// lfs f0,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmuls f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// stfs f0,272(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f2,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f0,f13,f2,f19
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f19.f64));
	// fmsubs f13,f13,f22,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f22.f64 - ctx.f15.f64));
	// lfs f22,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f22.f64 = double(temp.f32);
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// lfs f2,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f2.f64 = double(temp.f32);
	// lfs f19,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f1,f2,f19,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f19.f64 + ctx.f1.f64));
	// stfs f1,280(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f19,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f19.f64 = double(temp.f32);
	// lfs f1,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f19,f1
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f19,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f2,f2,f19,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f22,f15,f29,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f29.f64 + ctx.f22.f64));
	// stfs f22,272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f1,f22,f29,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 - ctx.f1.f64));
	// lfs f22,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f22.f64 = double(temp.f32);
	// lfs f29,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f29,f22,f29,f19
	ctx.f29.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 + ctx.f19.f64));
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,244
	ctx.r14.s64 = ctx.r6.s64 * 244;
	// fmsubs f22,f22,f19,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f15,f0
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f0.f64));
	// fsubs f0,f0,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f15.f64));
	// fadds f15,f2,f13
	ctx.f15.f64 = double(float(ctx.f2.f64 + ctx.f13.f64));
	// stfs f15,200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stw r14,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r14.u32);
	// mulli r14,r6,116
	ctx.r14.s64 = ctx.r6.s64 * 116;
	// fsubs f13,f13,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// stfs f13,228(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f13,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f13.f64 = double(temp.f32);
	// fadds f2,f29,f13
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f13.f64));
	// stfs f2,80(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f29.f64));
	// stfs f13,220(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fsubs f2,f1,f22
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f22.f64));
	// stfs f2,212(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fadds f13,f22,f1
	ctx.f13.f64 = double(float(ctx.f22.f64 + ctx.f1.f64));
	// stfs f13,104(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f22,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f22.f64 = double(temp.f32);
	// stw r14,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r14.u32);
	// lwz r14,196(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lfsx f13,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f2,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lwz r14,120(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lfsx f1,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f29,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r14,r6,84
	ctx.r14.s64 = ctx.r6.s64 * 84;
	// stfs f29,288(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfsx f29,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,180(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfsx f29,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r14,r6,212
	ctx.r14.s64 = ctx.r6.s64 * 212;
	// stfs f29,76(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f29,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,144(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfsx f29,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,176(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f29,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f13
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfs f13,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f15,f1,f13
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f13,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f13,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f2,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f29.f64));
	// lfs f29,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f2,f29,f2,f22
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f2.f64 - ctx.f22.f64));
	// stfs f2,84(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f29,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f29.f64 = double(temp.f32);
	// lfs f22,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f22.f64 = double(temp.f32);
	// lfs f2,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f29,f2,f29
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f29.f64));
	// lfs f2,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f22,f2,f22,f15
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f22.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f2,f2,f15,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64 - ctx.f1.f64));
	// stfs f2,280(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f2,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f2,f1
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,360(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f1,f27,f29
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 + ctx.f29.f64));
	// lfs f1,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f1.f64 = double(temp.f32);
	// lfs f29,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f1,f1,f27,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 - ctx.f22.f64));
	// lfs f27,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f27.f64 = double(temp.f32);
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f29,f27,f29,f15
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f15.f64));
	// lfs f15,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f27,f27,f22,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64 - ctx.f15.f64));
	// lfs f15,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f13,f15
	ctx.f22.f64 = double(float(ctx.f13.f64 - ctx.f15.f64));
	// mulli r14,r6,12
	ctx.r14.s64 = ctx.r6.s64 * 12;
	// fadds f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 + ctx.f13.f64));
	// stfs f13,76(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// lfs f13,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f13.f64));
	// stfs f15,180(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fadds f13,f13,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f15.f64));
	// fadds f15,f29,f2
	ctx.f15.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fsubs f2,f2,f29
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fadds f29,f27,f1
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fsubs f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// stfs f1,184(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f27,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f27.f64 = double(temp.f32);
	// lfs f1,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// stfs f1,68(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f27,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f27.f64 = double(temp.f32);
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// fadds f27,f15,f19
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f29
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f29.f64));
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fadds f29,f29,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f15.f64));
	// stfs f29,84(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f29,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// stfs f29,256(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f15,f1,f10
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmsubs f29,f29,f11,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f11.f64 - ctx.f15.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfs f15,368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,68(r1)
	PPC_STORE_U32(ctx.r1.u32 + 68, ctx.r14.u32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// mulli r14,r6,140
	ctx.r14.s64 = ctx.r6.s64 * 140;
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,324(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r14.u32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,328(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f13,f19
	ctx.f19.f64 = double(float(ctx.f13.f64 + ctx.f19.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f15,176(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f0,f15
	ctx.f15.f64 = double(float(ctx.f0.f64 - ctx.f15.f64));
	// stfs f19,240(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// stfs f15,360(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f19,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f2,f19
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// fsubs f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fadds f0,f15,f0
	ctx.f0.f64 = double(float(ctx.f15.f64 + ctx.f0.f64));
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,184(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f22,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f22.f64 = double(temp.f32);
	// stfs f2,132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f13,f13,f22
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f22.f64));
	// stfs f0,272(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// stfs f13,280(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fmuls f22,f0,f11
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f15,f0,f11
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f1,f11
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// stfs f0,256(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stw r14,396(r1)
	PPC_STORE_U32(ctx.r1.u32 + 396, ctx.r14.u32);
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,60(r1)
	PPC_STORE_U32(ctx.r1.u32 + 60, ctx.r14.u32);
	// fmadds f13,f1,f10,f13
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f13.f64));
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// stfs f13,528(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// lfs f13,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f13.f64 = double(temp.f32);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fmuls f1,f13,f11
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmuls f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stw r14,40(r1)
	PPC_STORE_U32(ctx.r1.u32 + 40, ctx.r14.u32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmadds f1,f19,f10,f1
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f1.f64));
	// stfs f1,432(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fmsubs f13,f19,f11,f13
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f13.f64));
	// stfs f13,520(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// lfs f13,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f13.f64 = double(temp.f32);
	// stw r14,344(r1)
	PPC_STORE_U32(ctx.r1.u32 + 344, ctx.r14.u32);
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,448(r1)
	PPC_STORE_U32(ctx.r1.u32 + 448, ctx.r14.u32);
	// lfs f13,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f1,f0,f13
	ctx.f1.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f1,200(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f0,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f0,f10,f22
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 - ctx.f22.f64));
	// stfs f0,104(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f1,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f1.f64 = double(temp.f32);
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f2,f1,f10,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f2.f64));
	// fmsubs f0,f0,f10,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 - ctx.f15.f64));
	// stfs f0,212(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f2,220(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f2,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f0,f10,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 + ctx.f2.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,60(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	// lfs f2,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f2,f13
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lwz r14,40(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lfs f0,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,256(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lwz r14,344(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// lfs f1,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lwz r14,448(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	// lfs f22,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,396(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,68(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f0,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,128(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f19,f2,f0
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f2,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,304(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmr f2,f1
	ctx.f2.f64 = ctx.f1.f64;
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f13,f2,f13,f19
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f19.f64));
	// fmsubs f0,f2,f0,f15
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f15.f64));
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// lwz r14,344(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// fmuls f19,f2,f1
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lwz r14,448(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	// fmadds f1,f1,f2,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f22.f64));
	// stfs f1,164(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f1
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// lfs f22,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f22.f64 = double(temp.f32);
	// lfs f1,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// mulli r14,r6,172
	ctx.r14.s64 = ctx.r6.s64 * 172;
	// fmsubs f2,f1,f2,f22
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f22.f64));
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// lfs f1,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f22,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f19.f64));
	// lfs f19,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,460(r1)
	PPC_STORE_U32(ctx.r1.u32 + 460, ctx.r14.u32);
	// mulli r14,r6,76
	ctx.r14.s64 = ctx.r6.s64 * 76;
	// fmsubs f22,f19,f22,f15
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stw r14,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r14.u32);
	// mulli r14,r6,204
	ctx.r14.s64 = ctx.r6.s64 * 204;
	// stw r14,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r14.u32);
	// mulli r14,r6,236
	ctx.r14.s64 = ctx.r6.s64 * 236;
	// stw r14,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, ctx.r14.u32);
	// mulli r14,r6,108
	ctx.r14.s64 = ctx.r6.s64 * 108;
	// stw r14,68(r1)
	PPC_STORE_U32(ctx.r1.u32 + 68, ctx.r14.u32);
	// lfs f19,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f19,f13
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f13.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f19.f64));
	// stfs f13,180(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f13,f2,f0
	ctx.f13.f64 = double(float(ctx.f2.f64 + ctx.f0.f64));
	// stfs f13,76(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f2.f64));
	// stfs f0,184(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lwz r14,96(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r14.u32);
	// lwz r14,96(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,436(r1)
	PPC_STORE_U32(ctx.r1.u32 + 436, ctx.r14.u32);
	// lwz r14,192(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r14.u32);
	// lwz r14,192(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r14.u32);
	// lwz r14,248(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r14.u32);
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r14.u32);
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r14.u32);
	// lwz r14,460(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	// lfsx f2,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// stfs f2,164(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f13,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,436(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f19,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lwz r14,248(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// lfsx f13,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,192(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lwz r14,264(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// lfs f13,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,68(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lwz r14,92(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lfs f13,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f13,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f15,f0,f13
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f13,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,24(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// fmadds f0,f0,f13,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f2.f64));
	// stfs f0,148(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f0,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// lfs f0,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f0,f13,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f0,172(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f0,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f15,f0,f13
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f19.f64));
	// stfs f13,164(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f13,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,436(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f13,f19
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// lfs f13,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fmsubs f0,f13,f0,f2
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 - ctx.f2.f64));
	// stfs f0,304(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f13,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fmuls f2,f0,f13
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fmadds f13,f0,f13,f15
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f13,52(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f13,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f13.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f13,f15
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// lfs f13,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f0,f0,f13,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - ctx.f19.f64));
	// stfs f0,28(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f19,f0,f9
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f13,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f0,f13,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f2.f64));
	// lfs f2,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f9,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f13,f9,f13,f15
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f9,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f9,f8,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f19.f64));
	// lfs f19,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f8,f19,f8,f2
	ctx.f8.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 - ctx.f2.f64));
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// fadds f2,f19,f1
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f1.f64));
	// fsubs f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f19.f64));
	// lfs f15,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f15,f22
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f22,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,308(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f22,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,160(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// fadds f15,f9,f0
	ctx.f15.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// fsubs f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// fadds f9,f8,f13
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// stfs f13,28(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f8,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f8.f64 = double(temp.f32);
	// lfs f13,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fadds f8,f15,f2
	ctx.f8.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// stfs f8,156(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// stfs f8,148(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f8,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// stfs f13,68(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f8,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f13,f9,f19
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f19.f64));
	// stfs f13,192(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f13,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f9,f9,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f19.f64));
	// lfs f8,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f8.f64 = double(temp.f32);
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// lfs f8,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f22.f64));
	// stfs f8,156(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f8,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// fadds f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f1.f64));
	// stfs f8,172(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f0,f8
	ctx.f8.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// stfs f8,164(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f8,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// lfs f1,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// fadds f0,f0,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// stfs f0,48(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f0,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// lfs f0,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f0.f64 = double(temp.f32);
	// fadds f0,f22,f0
	ctx.f0.f64 = double(float(ctx.f22.f64 + ctx.f0.f64));
	// stfs f0,52(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// stfs f9,28(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f0,f15,f2
	ctx.f0.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// lfs f2,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfs f9,304(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f2,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfs f9,256(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f2,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// stfs f9,280(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f2,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// lfs f22,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// stfs f9,288(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f9,f22,f28
	ctx.f9.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f9,108(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f2,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// stfs f9,132(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f2,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// stfs f9,272(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f9,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// stfs f9,124(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f2,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// lfs f31,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f31.f64 = double(temp.f32);
	// lfs f2,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f2.f64 = double(temp.f32);
	// stfs f9,240(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fadds f9,f31,f2
	ctx.f9.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f9,368(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f9,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f9.f64 = double(temp.f32);
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// stfs f1,360(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fadds f15,f9,f19
	ctx.f15.f64 = double(float(ctx.f9.f64 + ctx.f19.f64));
	// fsubs f9,f9,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f19.f64));
	// stfs f9,160(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// lfs f9,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f9.f64 = double(temp.f32);
	// stfs f2,284(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fadds f9,f9,f21
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f21.f64));
	// fsubs f2,f28,f22
	ctx.f2.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f9,84(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f2,244(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fmuls f21,f8,f11
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f9,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f1,f11
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f2,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f2.f64 = double(temp.f32);
	// fadds f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// stfs f9,116(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f9,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f9.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f2,f9,f10
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fadds f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f0.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f31,f9,f11
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f0,f0,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f15.f64));
	// stfs f0,180(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f28,f9,f11
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fsubs f0,f0,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f15.f64));
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f0,f13,f11,f2
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f2.f64));
	// stfs f0,424(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// lfs f2,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f0,f13,f10,f31
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 + ctx.f31.f64));
	// stfs f0,524(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f0,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f13,f0,f10,f28
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 + ctx.f28.f64));
	// stfs f13,456(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// fmsubs f0,f0,f11,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64 - ctx.f9.f64));
	// stfs f0,500(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// lfs f13,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f8,f10,f22
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 + ctx.f22.f64));
	// stfs f0,316(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f0,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f0,f10,f21
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 - ctx.f21.f64));
	// stfs f0,44(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f0,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f9,f0,f13
	ctx.f9.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f9,76(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,184(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f0,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f0,f10,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 - ctx.f19.f64));
	// stfs f0,292(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f0,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f0,f0,f10,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 + ctx.f1.f64));
	// lfs f13,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,56(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fadds f0,f9,f13
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// fsubs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// stfs f13,256(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f9,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// fadds f8,f9,f13
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfs f8,304(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f8,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// lfs f1,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f1.f64 = double(temp.f32);
	// fadds f9,f2,f8
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fsubs f8,f2,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// lfs f31,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f31.f64 = double(temp.f32);
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfs f1,360(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f28,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f28.f64 = double(temp.f32);
	// lfs f31,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f31.f64 = double(temp.f32);
	// fadds f1,f28,f31
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// fadds f28,f22,f21
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fsubs f21,f19,f28
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// fadds f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// lfs f19,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// stfs f28,308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fsubs f28,f19,f22
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fadds f25,f19,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// stfs f25,64(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f25,f9,f0
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// fsubs f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// lfs f9,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f9.f64 = double(temp.f32);
	// fadds f19,f28,f1
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f28,f28,f1
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// lfs f1,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f1.f64 = double(temp.f32);
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// stfs f9,172(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f1,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f1.f64 = double(temp.f32);
	// fadds f15,f22,f31
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f31.f64));
	// lfs f9,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f22,f31,f22
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f22.f64));
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// lfs f31,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfs f1,156(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f31,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfs f1,148(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f28,f28,f12
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fsubs f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// stfs f1,128(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f31,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfs f22,280(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fadds f31,f8,f13
	ctx.f31.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// lfs f22,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// lfs f8,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f22.f64));
	// stfs f8,28(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// lfs f8,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f8.f64 = double(temp.f32);
	// stfs f1,192(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fsubs f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f22.f64));
	// fmuls f1,f19,f12
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f19,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f22,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// stfs f1,288(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fmuls f1,f15,f12
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f19,f22
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,160(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f22,f25,f2
	ctx.f22.f64 = double(float(ctx.f25.f64 - ctx.f2.f64));
	// stfsx f22,r10,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// stfs f2,0(r3)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f25,f0,f21
	ctx.f25.f64 = double(float(ctx.f0.f64 - ctx.f21.f64));
	// fadds f22,f0,f21
	ctx.f22.f64 = double(float(ctx.f0.f64 + ctx.f21.f64));
	// fmuls f2,f9,f11
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f0,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f21,f9,f10
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f9,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f19,f0,f9
	ctx.f19.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// fadds f15,f9,f0
	ctx.f15.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// stfs f0,64(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f9,f31,f1
	ctx.f9.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfs f9,272(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// fadds f31,f13,f28
	ctx.f31.f64 = double(float(ctx.f13.f64 + ctx.f28.f64));
	// fsubs f28,f13,f28
	ctx.f28.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// lfs f13,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// stfs f13,132(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f13,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f8,f13
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// lfs f13,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f13.f64 = double(temp.f32);
	// fmr f9,f13
	ctx.f9.f64 = ctx.f13.f64;
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f13,f9,f10,f2
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 - ctx.f2.f64));
	// fmadds f9,f9,f11,f21
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f11.f64 + ctx.f21.f64));
	// stfs f9,84(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f9,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f15,f12
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fadds f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// stfs f8,28(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// lfs f21,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f8,f19,f12
	ctx.f8.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f1,164(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f21,f11,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f19.f64));
	// stfs f21,240(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f21,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f21.f64 = double(temp.f32);
	// fmr f1,f21
	ctx.f1.f64 = ctx.f21.f64;
	// lfs f21,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// stfs f21,64(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f21,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfs f1,156(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// lfs f21,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// stfs f21,148(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f21,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfs f1,172(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f21,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f21.f64 = double(temp.f32);
	// lfs f1,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f1.f64 = double(temp.f32);
	// fadds f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f21.f64));
	// stfs f21,0(r4)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f21,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfsx f1,r10,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f25,r8,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f25.f64 = double(temp.f32);
	// stfs f31,64(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmr f31,f25
	ctx.f31.f64 = ctx.f25.f64;
	// lfs f1,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f1.f64 = double(temp.f32);
	// stfsx f22,r9,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f25,f31,f1
	ctx.f25.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f31,f1
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// lfs f1,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f1.f64 = double(temp.f32);
	// lfs f31,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f31.f64 = double(temp.f32);
	// stfsx f22,r8,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f31,f1
	ctx.f25.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// fadds f22,f1,f31
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f31.f64));
	// lfs f1,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f1.f64 = double(temp.f32);
	// lfs f31,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f31.f64 = double(temp.f32);
	// stfsx f25,r5,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fsubs f25,f31,f1
	ctx.f25.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfsx f22,r7,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f31.f64));
	// lfs f22,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f22,r7,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f22,r5,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// stfsx f25,r31,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfsx f1,r30,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f25.f64 = double(temp.f32);
	// lfs f31,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f1.f64 = double(temp.f32);
	// stfsx f25,r30,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// stfsx f28,r31,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f28.f64 = double(temp.f32);
	// lfs f31,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f31,f28
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// lfs f25,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f25.f64 = double(temp.f32);
	// lfs f28,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// lfs f22,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// lfs f22,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f22.f64 = double(temp.f32);
	// fadds f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f22.f64));
	// lfs f21,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f21,f10
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fadds f21,f8,f19
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f19.f64));
	// fsubs f8,f19,f8
	ctx.f8.f64 = double(float(ctx.f19.f64 - ctx.f8.f64));
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f2,f19
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// stfs f19,148(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// stfs f2,172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f19,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// lfs f2,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// lfs f19,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f11,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f15.f64));
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f15,f1,f10
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fsubs f19,f25,f28
	ctx.f19.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fmuls f25,f22,f10
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,48(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmuls f2,f31,f10
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// fmadds f31,f31,f11,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f11.f64 + ctx.f15.f64));
	// fmuls f28,f28,f12
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmadds f25,f27,f11,f25
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f25.f64));
	// fmsubs f27,f27,f10,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f22.f64));
	// fmsubs f2,f1,f11,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 - ctx.f2.f64));
	// fmuls f1,f19,f12
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f2,f19
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// fsubs f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// fadds f19,f1,f9
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f9.f64));
	// fsubs f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f1.f64));
	// fadds f1,f28,f0
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// fsubs f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f31,f15
	ctx.f15.f64 = double(float(ctx.f31.f64 + ctx.f15.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f31,f15,f31
	ctx.f31.f64 = double(float(ctx.f15.f64 - ctx.f31.f64));
	// fadds f15,f25,f13
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f13.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f25.f64));
	// fadds f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// fsubs f27,f21,f22
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfsx f27,r22,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f27,f22,f21
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfsx f27,r23,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f27,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f27.f64 = double(temp.f32);
	// fadds f25,f19,f27
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f27.f64));
	// stfsx f25,r23,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// stfsx f27,r22,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// fsubs f27,f8,f31
	ctx.f27.f64 = double(float(ctx.f8.f64 - ctx.f31.f64));
	// stfsx f27,r25,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f31,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f8.f64));
	// stfsx f8,r24,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f9,f2
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// stfsx f8,r24,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfsx f9,r25,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f1,f9
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f9.f64));
	// stfsx f8,r28,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// stfsx f9,r29,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f9.f64 = double(temp.f32);
	// fadds f8,f9,f15
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f15.f64));
	// stfsx f8,r29,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f9,f15
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f15.f64));
	// stfsx f9,r28,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f0,f28
	ctx.f9.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// stfsx f9,r26,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f28,f0
	ctx.f0.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// stfsx f0,r27,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f0,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f0.f64 = double(temp.f32);
	// fadds f9,f0,f13
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// stfsx f9,r27,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f0,r26,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f9,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// lfs f8,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// lfs f27,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f27.f64 = double(temp.f32);
	// lfs f2,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f31,f27,f11
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f8,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f27,f10
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f25,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// fmuls f2,f25,f10
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f19,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// lfs f19,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f19.f64 = double(temp.f32);
	// lfs f28,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f1,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f21,f17,f1
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f1.f64));
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f1,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f31,f19,f10,f31
	ctx.f31.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f31.f64));
	// fmuls f19,f28,f10
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmsubs f2,f28,f11,f2
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 - ctx.f2.f64));
	// lfs f28,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// fmuls f27,f22,f12
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f11,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f13.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f1,f21,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 - ctx.f1.f64));
	// fsubs f15,f3,f9
	ctx.f15.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// fmadds f25,f25,f11,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 + ctx.f19.f64));
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f15,f15,f8
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f8.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f0.f64));
	// fadds f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// lfs f3,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f3.f64 = double(temp.f32);
	// fadds f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f2,f31
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// lwz r9,420(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// mulli r10,r6,56
	ctx.r10.s64 = ctx.r6.s64 * 56;
	// fadds f31,f28,f27
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfs f28,160(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f28,f22,f25
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f28,96(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fsubs f28,f22,f25
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfs f28,308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f28,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f19,f6
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// fmuls f28,f28,f6
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f6.f64));
	// lfs f27,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fadds f0,f0,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 + ctx.f13.f64));
	// fmsubs f28,f19,f7,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 - ctx.f28.f64));
	// stfs f28,252(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f28,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f27,f28,f7,f27
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f7.f64 + ctx.f27.f64));
	// stfs f27,52(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmuls f19,f28,f6
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f6.f64));
	// fmuls f28,f9,f4
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// stfs f28,152(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f25,f0,f4
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fmuls f15,f13,f4
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmuls f27,f8,f4
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmadds f13,f13,f5,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f25.f64));
	// lfs f25,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f28,f25,f7,f22
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f22.f64));
	// fmsubs f9,f9,f5,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64 - ctx.f27.f64));
	// lfs f27,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f27,f27,f7,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 - ctx.f19.f64));
	// fmsubs f0,f0,f5,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f5.f64 - ctx.f15.f64));
	// lfs f22,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f8,f8,f5,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 + ctx.f25.f64));
	// stfs f8,28(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f8,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f8.f64 = double(temp.f32);
	// fadds f25,f3,f1
	ctx.f25.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// fadds f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f22.f64));
	// fsubs f19,f25,f8
	ctx.f19.f64 = double(float(ctx.f25.f64 - ctx.f8.f64));
	// stfsx f19,r9,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f8,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f25.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f8,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f8.f64 = double(temp.f32);
	// lfs f25,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f8,f25
	ctx.f25.f64 = double(float(ctx.f8.f64 + ctx.f25.f64));
	// lfs f19,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f19.f64 = double(temp.f32);
	// fadds f8,f27,f28
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// stfs f8,252(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f8,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fadds f8,f19,f8
	ctx.f8.f64 = double(float(ctx.f19.f64 + ctx.f8.f64));
	// stfs f8,152(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f8,f1,f3
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// stfs f8,312(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fsubs f8,f27,f28
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// stfs f8,64(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f8,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f27,f30,f11
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// lfs f3,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f3.f64 = double(temp.f32);
	// fadds f1,f8,f3
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// lfs f8,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f28,f8,f11
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmuls f3,f25,f12
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// stfs f3,156(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f19,f8,f10
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f3,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f3.f64 = double(temp.f32);
	// lfs f8,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f8.f64 = double(temp.f32);
	// lfs f25,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f8,f11
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fadds f25,f3,f25
	ctx.f25.f64 = double(float(ctx.f3.f64 + ctx.f25.f64));
	// lfs f8,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// lfs f3,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f3.f64 = double(temp.f32);
	// fadds f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// stfs f8,236(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f3,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f30,f30,f10,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 - ctx.f15.f64));
	// fsubs f3,f22,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f3.f64));
	// stfs f3,148(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f3,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f8,f3,f22
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// lfs f3,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f21.f64));
	// stfs f3,172(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f3,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// stfs f3,164(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f3,f9,f13
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfs f3,256(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fadds f3,f31,f2
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f3,304(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// lfs f9,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// lfs f22,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f9,f31,f2
	ctx.f9.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// lfs f3,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f31,f24,f10,f28
	ctx.f31.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f28.f64));
	// lfs f28,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f10,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 + ctx.f27.f64));
	// lfs f2,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f27,f25,f12
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f25,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f24,f24,f11,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f19.f64));
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// fsubs f3,f21,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 - ctx.f3.f64));
	// lfs f21,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f21.f64 = double(temp.f32);
	// fadds f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f17.f64));
	// lfs f19,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f19,f12
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f19,f21
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// mulli r10,r6,248
	ctx.r10.s64 = ctx.r6.s64 * 248;
	// stfsx f21,r9,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,120
	ctx.r9.s64 = ctx.r6.s64 * 120;
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f21,f19
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f21,r9,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f21,f19,f17
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f17,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f8,f17
	ctx.f15.f64 = double(float(ctx.f8.f64 + ctx.f17.f64));
	// stfsx f15,r9,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f8,f17
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f17.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,152
	ctx.r9.s64 = ctx.r6.s64 * 152;
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// lfs f8,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f15,f8,f17
	ctx.f15.f64 = double(float(ctx.f8.f64 - ctx.f17.f64));
	// fadds f8,f17,f8
	ctx.f8.f64 = double(float(ctx.f17.f64 + ctx.f8.f64));
	// lfs f17,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f15,r9,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// mulli r10,r6,24
	ctx.r10.s64 = ctx.r6.s64 * 24;
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f8,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f8.f64 = double(temp.f32);
	// fadds f15,f17,f8
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f8.f64));
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f17,f8
	ctx.f8.f64 = double(float(ctx.f17.f64 - ctx.f8.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,216
	ctx.r10.s64 = ctx.r6.s64 * 216;
	// fsubs f8,f3,f13
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f13.f64));
	// fadds f13,f13,f3
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f3.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// mulli r9,r6,88
	ctx.r9.s64 = ctx.r6.s64 * 88;
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f9,f0
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f9,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// stfsx f0,r10,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f31,f28
	ctx.f9.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// mulli r10,r6,104
	ctx.r10.s64 = ctx.r6.s64 * 104;
	// fadds f8,f28,f31
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f0,f2,f1
	ctx.f0.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f13,f1,f2
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fadds f1,f30,f24
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// fsubs f31,f30,f24
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// lfs f24,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f30,f28,f22
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fsubs f2,f25,f27
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f3,f25,f27
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfs f25,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f27.f64 = double(temp.f32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// fadds f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// lfs f25,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmuls f15,f19,f7
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// fmuls f24,f30,f5
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fmuls f22,f30,f4
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// fmuls f17,f28,f7
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// fmuls f30,f27,f12
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmuls f27,f25,f12
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fmsubs f25,f21,f4,f24
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 - ctx.f24.f64));
	// fmadds f24,f21,f5,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 + ctx.f22.f64));
	// fadds f22,f9,f0
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// fsubs f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// fadds f21,f31,f2
	ctx.f21.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fsubs f9,f2,f31
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fmadds f31,f28,f6,f15
	ctx.f31.f64 = double(float(ctx.f28.f64 * ctx.f6.f64 + ctx.f15.f64));
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f19,f6,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f2,f1,f13
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f13.f64));
	// fsubs f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// fsubs f1,f17,f30
	ctx.f1.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// fadds f30,f30,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// fadds f27,f27,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f17.f64));
	// stfs f27,88(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f28,f3,f8
	ctx.f28.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// fmuls f27,f15,f5
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// fmuls f17,f1,f5
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f15,f30,f6
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fmuls f30,f30,f7
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// fmadds f1,f1,f4,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f27,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmsubs f30,f27,f4,f17
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f17.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f27,f17,f7,f15
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f17,f6,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 - ctx.f15.f64));
	// fadds f15,f1,f25
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f25.f64));
	// fsubs f1,f25,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 - ctx.f1.f64));
	// fadds f25,f30,f24
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// fadds f24,f17,f31
	ctx.f24.f64 = double(float(ctx.f17.f64 + ctx.f31.f64));
	// fsubs f31,f17,f31
	ctx.f31.f64 = double(float(ctx.f17.f64 - ctx.f31.f64));
	// fsubs f17,f22,f15
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfsx f17,r16,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfsx f22,r17,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f21,f25
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfsx f22,r17,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// stfsx f25,r16,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f0,f30
	ctx.f25.f64 = double(float(ctx.f0.f64 - ctx.f30.f64));
	// stfsx f25,r15,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f30,f0
	ctx.f0.f64 = double(float(ctx.f30.f64 + ctx.f0.f64));
	// stfsx f0,r10,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f9,f1
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// stfsx f0,r10,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f9,f1
	ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f1.f64));
	// stfsx f0,r15,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fadds f0,f27,f19
	ctx.f0.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// lfs f30,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// lfs f25,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// lfs f22,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f21.f64 = double(temp.f32);
	// lfs f1,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f19.f64 = double(temp.f32);
	// lfs f3,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// lfs f19,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f9,f2,f0
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f0.f64));
	// stfsx f9,r20,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f2.f64));
	// stfsx f0,r21,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f28,f24
	ctx.f0.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// stfsx f0,r21,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f28,f24
	ctx.f0.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// lfs f28,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// lfs f28,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// lfs f24,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f0,r20,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fsubs f0,f13,f31
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// lfs f24,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f0,r18,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f31,f13
	ctx.f0.f64 = double(float(ctx.f31.f64 + ctx.f13.f64));
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// lfs f22,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f0,r19,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f13,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f21,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// lfs f9,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// lfs f13,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f13.f64 = double(temp.f32);
	// lfs f1,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// lfs f31,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 - ctx.f1.f64));
	// lfs f17,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfs f19,88(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f17,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f9,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f9.f64 = double(temp.f32);
	// stfs f19,236(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fsubs f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f23.f64));
	// lfs f17,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f0,f6
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f19,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfs f19,168(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f17,f13,f6
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fsubs f19,f1,f31
	ctx.f19.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f31,f30,f28
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,296(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fsubs f30,f25,f24
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f30,152(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f30,f9,f7
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f28,f24,f25
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f30,f22,f21
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f25,f21,f22
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fmuls f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmsubs f24,f0,f7,f17
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 - ctx.f17.f64));
	// fmadds f22,f13,f7,f15
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f7.f64 + ctx.f15.f64));
	// fadds f0,f8,f27
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f27.f64));
	// stfsx f0,r19,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f8,f27
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f27.f64));
	// stfsx f0,r18,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f13,f3,f0
	ctx.f13.f64 = double(float(ctx.f3.f64 - ctx.f0.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f0,f0,f3
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f3.f64));
	// stfs f0,48(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmsubs f0,f2,f7,f9
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 - ctx.f9.f64));
	// stfs f0,32(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// stfs f13,300(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmadds f27,f2,f6,f17
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f17.f64));
	// lfs f13,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f0.f64 = double(temp.f32);
	// fadds f9,f13,f0
	ctx.f9.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f8,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// stfs f0,28(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f0,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f3,f28,f8
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f13,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f0,f8
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// fmuls f0,f30,f13
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f3,168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f21,f31,f13
	ctx.f21.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// lfs f15,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f1,f8
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// stfs f9,52(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmr f0,f15
	ctx.f0.f64 = ctx.f15.f64;
	// fmuls f9,f19,f13
	ctx.f9.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f3,f31,f0,f9
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f9,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f2,f1,f9,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 - ctx.f2.f64));
	// fsubs f1,f24,f27
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// fadds f31,f27,f24
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fmsubs f27,f19,f0,f21
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 - ctx.f21.f64));
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f24,f21,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f9,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f17.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f19,f15,f0,f17
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 - ctx.f17.f64));
	// lfs f17,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f25,f9,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f17.f64));
	// fmuls f25,f25,f8
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// stfs f25,32(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmadds f30,f30,f0,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f15.f64));
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f1,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f15.f64));
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f15,f19,f3
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// stfs f15,168(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// fadds f15,f24,f15
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 - ctx.f1.f64));
	// stfs f1,312(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f15,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f15.f64 = double(temp.f32);
	// lfs f1,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 - ctx.f1.f64));
	// stfs f1,160(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f15.f64 = double(temp.f32);
	// lfs f1,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f1.f64 = double(temp.f32);
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 - ctx.f1.f64));
	// lfs f15,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f25,f26,f15
	ctx.f25.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// fadds f19,f22,f19
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f19,156(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f19,f17,f2
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f28,f28,f9,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 - ctx.f15.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// fadds f15,f31,f15
	ctx.f15.f64 = double(float(ctx.f31.f64 + ctx.f15.f64));
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f31,f17,f31
	ctx.f31.f64 = double(float(ctx.f17.f64 - ctx.f31.f64));
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lwz r9,352(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// lfs f17,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f17.f64 = double(temp.f32);
	// mulli r10,r6,60
	ctx.r10.s64 = ctx.r6.s64 * 60;
	// lfs f31,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f17,f31
	ctx.f31.f64 = double(float(ctx.f17.f64 - ctx.f31.f64));
	// stfs f31,296(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f31,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f31,f17
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f17.f64));
	// lfs f15,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,236(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f17,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,300(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fadds f17,f30,f27
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// stfs f17,252(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// stfs f30,64(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f27,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f17,f30,f27
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfsx f17,r9,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f1,f5
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f17,f30,f5
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fadds f30,f28,f21
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f21.f64));
	// stfs f30,88(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f30,f28,f21
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f21.f64));
	// stfs f30,168(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f30,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f30.f64 = double(temp.f32);
	// fadds f21,f24,f3
	ctx.f21.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// fsubs f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f3.f64));
	// fmuls f28,f25,f5
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// fmadds f1,f1,f4,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f17.f64));
	// fmuls f30,f30,f5
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// lfs f3,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f15,f3,f19
	ctx.f15.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fsubs f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 - ctx.f19.f64));
	// fsubs f3,f22,f2
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f2.f64));
	// stfs f3,32(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// lfs f2,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfs f2,172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f2,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f2,28(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f31,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f31.f64 = double(temp.f32);
	// fmr f3,f31
	ctx.f3.f64 = ctx.f31.f64;
	// fmadds f31,f25,f4,f30
	ctx.f31.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f30.f64));
	// lfs f30,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// lfs f2,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f2,52(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f2,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// lfs f2,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f30,f30,f4,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f4.f64 - ctx.f28.f64));
	// lfs f28,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f2,f2,f4,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 - ctx.f27.f64));
	// lfs f27,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f27.f64 = double(temp.f32);
	// fadds f25,f28,f27
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfsx f25,r10,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfsx f28,r9,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f28.f64 = double(temp.f32);
	// mulli r10,r6,252
	ctx.r10.s64 = ctx.r6.s64 * 252;
	// lfs f27,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f27.f64 = double(temp.f32);
	// mulli r9,r6,124
	ctx.r9.s64 = ctx.r6.s64 * 124;
	// fsubs f25,f28,f27
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f21,r9,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f24,r10,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,156
	ctx.r9.s64 = ctx.r6.s64 * 156;
	// lfs f28,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f25,f28,f27
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f24,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f27,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f27.f64 = double(temp.f32);
	// lfs f21,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f25,r9,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// mulli r10,r6,28
	ctx.r10.s64 = ctx.r6.s64 * 28;
	// stfsx f28,r10,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f19,r9,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,220
	ctx.r10.s64 = ctx.r6.s64 * 220;
	// lfs f28,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f28,f27
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// lfs f19,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f27,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f24,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f24.f64 = double(temp.f32);
	// mulli r9,r6,92
	ctx.r9.s64 = ctx.r6.s64 * 92;
	// stfsx f22,r9,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// lfs f22,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// lfs f22,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f21,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f19,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f15,f2,f31
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f28,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f15,f30,f1
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f2,48(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f30,f30,f1
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fsubs f31,f25,f24
	ctx.f31.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fadds f2,f21,f22
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f2,168(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f2,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f1,f28,f27
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f27,f24,f25
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f25,f22,f21
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f17,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f22,88(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f24,f19,f17
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f21,f2
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f2.f64));
	// stfs f19,296(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fsubs f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f21.f64));
	// stfs f2,312(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// fadds f19,f15,f3
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// fsubs f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f15.f64));
	// stfs f19,252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// stfs f3,64(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmuls f21,f31,f2
	ctx.f21.f64 = double(float(ctx.f31.f64 * ctx.f2.f64));
	// lfs f3,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f24,f2
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmuls f19,f31,f3
	ctx.f19.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// lfs f31,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f17,f24,f3
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// mulli r9,r6,180
	ctx.r9.s64 = ctx.r6.s64 * 180;
	// fmuls f24,f28,f31
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// stfs f24,32(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f22,f22,f31
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// stfs f22,236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmadds f24,f1,f3,f21
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f3.f64 + ctx.f21.f64));
	// mulli r10,r6,52
	ctx.r10.s64 = ctx.r6.s64 * 52;
	// fmsubs f22,f1,f2,f19
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f19.f64));
	// lfs f19,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f1,f27,f31
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// stfs f1,152(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmr f1,f19
	ctx.f1.f64 = ctx.f19.f64;
	// fmsubs f21,f25,f2,f17
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 - ctx.f17.f64));
	// fmadds f25,f25,f3,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f15.f64));
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f27,f27,f1,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f19.f64));
	// stfs f27,300(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f27,f1
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f27,f19,f1,f15
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 - ctx.f15.f64));
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f28,f28,f1,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f1.f64 - ctx.f15.f64));
	// fadds f15,f22,f25
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fmadds f19,f19,f31,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 + ctx.f17.f64));
	// fadds f17,f24,f21
	ctx.f17.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfsx f21,r9,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f21,f15
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfsx f21,r9,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,196(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lfs f21,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f21.f64 = double(temp.f32);
	// lwz r9,120(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// fsubs f17,f21,f25
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// fadds f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f25,r9,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f25.f64 = double(temp.f32);
	// fadds f21,f25,f24
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfsx f21,r9,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfsx f25,r10,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f25.f64 = double(temp.f32);
	// lwz r9,140(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// fadds f25,f30,f25
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// mulli r10,r6,20
	ctx.r10.s64 = ctx.r6.s64 * 20;
	// lfs f21,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f21.f64 = double(temp.f32);
	// fadds f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// lfs f21,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// fsubs f24,f25,f22
	ctx.f24.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfsx f24,r9,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f22,f25
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// lfs f22,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// lfs f22,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f20,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f17,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,476(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// fadds f15,f28,f19
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f19,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// fsubs f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f19,88(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,168(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f14,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,236(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f14,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f19,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f25,f7
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,152(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f19,64(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,480(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f16,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,156(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f16,f24,f7
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fsubs f19,f21,f20
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fmadds f24,f24,f6,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f14.f64));
	// fmsubs f25,f25,f6,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 - ctx.f16.f64));
	// lfs f20,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,336(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f20,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,488(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f26,f7
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmr f20,f16
	ctx.f20.f64 = ctx.f16.f64;
	// fmuls f17,f22,f7
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// fadds f16,f15,f20
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfsx f16,r10,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfsx f20,r9,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,212
	ctx.r9.s64 = ctx.r6.s64 * 212;
	// fsubs f20,f30,f28
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// mulli r10,r6,84
	ctx.r10.s64 = ctx.r6.s64 * 84;
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f20,r9,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f28,f27
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f30,f26,f6,f17
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f17.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfsx f28,r9,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f28,f22,f6,f17
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f22,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f19,f9
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// fsubs f27,f26,f22
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f20.f64 = double(temp.f32);
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f16,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,88(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f15,f21,f0
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// stfs f21,32(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f16,f19,f8
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// lfs f19,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f19,f9,f16
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 + ctx.f16.f64));
	// lfs f19,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f16,f25,f30
	ctx.f16.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fadds f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// fsubs f25,f28,f24
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// fadds f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// lfs f24,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f24,f8,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 - ctx.f14.f64));
	// fmsubs f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f15,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f0,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f14.f64));
	// stfs f15,336(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f16,f27
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f27.f64));
	// stfs f14,252(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f16.f64));
	// stfs f27,312(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f16,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f25,f20
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// lfs f27,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// fadds f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// stfs f27,484(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// lfs f16,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f28,f26
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// lfs f27,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// fadds f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// lfs f26,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f26.f64 = double(temp.f32);
	// fadds f16,f30,f22
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fsubs f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// stfs f30,64(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f30,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,168(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f26,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,236(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f26,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,152(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f26,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,392(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f26,f30,f9
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fmuls f30,f30,f8
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// mulli r9,r6,164
	ctx.r9.s64 = ctx.r6.s64 * 164;
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// mulli r10,r6,36
	ctx.r10.s64 = ctx.r6.s64 * 36;
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmsubs f8,f17,f8,f26
	ctx.f8.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 - ctx.f26.f64));
	// lfs f26,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f9,f17,f9,f30
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f30.f64));
	// lfs f30,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f13,f30,f13,f22
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f22.f64));
	// lfs f22,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f0,f30,f0,f15
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f15.f64));
	// lfs f15,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f26,f22
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// fmuls f17,f27,f4
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// lfs f22,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f15,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f15,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f15,f5,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 - ctx.f17.f64));
	// fadds f15,f8,f21
	ctx.f15.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f15,392(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fadds f15,f9,f24
	ctx.f15.f64 = double(float(ctx.f9.f64 + ctx.f24.f64));
	// fsubs f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f21.f64));
	// fadds f21,f0,f19
	ctx.f21.f64 = double(float(ctx.f0.f64 + ctx.f19.f64));
	// fsubs f9,f24,f9
	ctx.f9.f64 = double(float(ctx.f24.f64 - ctx.f9.f64));
	// lfs f24,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f0,f19,f0
	ctx.f0.f64 = double(float(ctx.f19.f64 - ctx.f0.f64));
	// lfs f19,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f19.f64 = double(temp.f32);
	// fadds f24,f13,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 + ctx.f24.f64));
	// fsubs f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f19.f64));
	// stfs f13,32(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f13,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f13.f64 = double(temp.f32);
	// lfs f19,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f13,f19
	ctx.f19.f64 = double(float(ctx.f13.f64 - ctx.f19.f64));
	// stfsx f19,r9,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f19.f64 = double(temp.f32);
	// fadds f13,f19,f13
	ctx.f13.f64 = double(float(ctx.f19.f64 + ctx.f13.f64));
	// stfsx f13,r10,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f14,f15
	ctx.f13.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f13,r10,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f14,f15
	ctx.f13.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,228
	ctx.r10.s64 = ctx.r6.s64 * 228;
	// lfs f13,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f19,f13,f9
	ctx.f19.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// fadds f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfsx f19,r10,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// mulli r9,r6,100
	ctx.r9.s64 = ctx.r6.s64 * 100;
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f25,f8
	ctx.f13.f64 = double(float(ctx.f25.f64 + ctx.f8.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f25,f8
	ctx.f13.f64 = double(float(ctx.f25.f64 - ctx.f8.f64));
	// mulli r9,r6,132
	ctx.r9.s64 = ctx.r6.s64 * 132;
	// stfsx f13,r10,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f20,f24
	ctx.f13.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f24,f20
	ctx.f13.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stfsx f13,r10,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f16,f21
	ctx.f13.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfsx f13,r10,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f16,f21
	ctx.f13.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,196
	ctx.r9.s64 = ctx.r6.s64 * 196;
	// fsubs f13,f28,f0
	ctx.f13.f64 = double(float(ctx.f28.f64 - ctx.f0.f64));
	// fadds f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f28.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f13,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// mulli r10,r6,68
	ctx.r10.s64 = ctx.r6.s64 * 68;
	// stfsx f0,r10,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f0,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f0.f64 = double(temp.f32);
	// fadds f9,f0,f13
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f0,r9,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f0,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f0.f64 = double(temp.f32);
	// fadds f0,f23,f0
	ctx.f0.f64 = double(float(ctx.f23.f64 + ctx.f0.f64));
	// lfs f9,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f27,f27,f5
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f25,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f0,f5
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f13,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f13.f64 = double(temp.f32);
	// lwz r9,460(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	// lfs f28,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f28.f64 = double(temp.f32);
	// fadds f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// lfs f8,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f8.f64 = double(temp.f32);
	// lfs f24,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f24.f64 = double(temp.f32);
	// lwz r10,396(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// lfs f9,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f9.f64 = double(temp.f32);
	// lfs f25,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f25.f64 = double(temp.f32);
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f23,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f23.f64 = double(temp.f32);
	// lfs f8,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f8.f64 = double(temp.f32);
	// lfs f24,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f24.f64 = double(temp.f32);
	// fadds f8,f8,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f29.f64));
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// lfs f21,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f21.f64 = double(temp.f32);
	// lfs f29,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f29.f64 = double(temp.f32);
	// lfs f23,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f23.f64 = double(temp.f32);
	// fadds f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// lfs f20,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f0,f4
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f27,f20,f4,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fsubs f20,f9,f8
	ctx.f20.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f8,f25,f24
	ctx.f8.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fsubs f0,f29,f28
	ctx.f0.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f28,f23,f21
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fmadds f24,f13,f4,f19
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f4.f64 + ctx.f19.f64));
	// fmsubs f13,f13,f5,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 - ctx.f18.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fmuls f19,f20,f1
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// fmuls f14,f9,f2
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmuls f16,f8,f1
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmuls f18,f0,f1
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmuls f15,f28,f1
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// fsubs f1,f17,f24
	ctx.f1.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// fsubs f21,f13,f27
	ctx.f21.f64 = double(float(ctx.f13.f64 - ctx.f27.f64));
	// fadds f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f27.f64));
	// fmsubs f0,f0,f31,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64 - ctx.f19.f64));
	// fmuls f19,f9,f3
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmadds f20,f20,f31,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64 + ctx.f18.f64));
	// fmuls f18,f23,f3
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fmuls f23,f23,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fmsubs f9,f8,f31,f15
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f31.f64 - ctx.f15.f64));
	// fmadds f8,f28,f31,f16
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f31.f64 + ctx.f16.f64));
	// fmsubs f28,f29,f3,f14
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f3.f64 - ctx.f14.f64));
	// fadds f27,f1,f30
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fsubs f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// fmadds f29,f29,f2,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f2.f64 + ctx.f19.f64));
	// fadds f31,f24,f17
	ctx.f31.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// fadds f30,f21,f22
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fmadds f2,f25,f2,f18
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f18.f64));
	// fmsubs f3,f25,f3,f23
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 - ctx.f23.f64));
	// fadds f25,f9,f20
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f20.f64));
	// fadds f24,f8,f0
	ctx.f24.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// fsubs f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// fsubs f9,f9,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f20.f64));
	// fsubs f8,f27,f25
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfsx f8,r9,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f25,f27
	ctx.f8.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f30,f24
	ctx.f8.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,248(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// fsubs f8,f30,f24
	ctx.f8.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f1,f0
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,588(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lwz r9,652(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	// fsubs f8,f22,f21
	ctx.f8.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f23,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f23.f64 = double(temp.f32);
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fadds f30,f13,f26
	ctx.f30.f64 = double(float(ctx.f13.f64 + ctx.f26.f64));
	// add r4,r9,r4
	ctx.r4.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lwz r9,264(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// fadds f27,f3,f29
	ctx.f27.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// stw r10,588(r1)
	PPC_STORE_U32(ctx.r1.u32 + 588, ctx.r10.u32);
	// fadds f0,f0,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fadds f25,f2,f28
	ctx.f25.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// fadds f24,f31,f23
	ctx.f24.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fsubs f13,f26,f13
	ctx.f13.f64 = double(float(ctx.f26.f64 - ctx.f13.f64));
	// fsubs f2,f28,f2
	ctx.f2.f64 = double(float(ctx.f28.f64 - ctx.f2.f64));
	// fsubs f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fadds f0,f8,f9
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,344(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// fsubs f0,f8,f9
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// stfs f0,0(r14)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fsubs f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// fsubs f0,f30,f27
	ctx.f0.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,60(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	// fadds f0,f27,f30
	ctx.f0.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,40(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// fadds f0,f24,f25
	ctx.f0.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,448(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	// fsubs f0,f24,f25
	ctx.f0.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,24(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// fsubs f0,f13,f2
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,20(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fadds f0,f2,f13
	ctx.f0.f64 = double(float(ctx.f2.f64 + ctx.f13.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,436(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	// fadds f0,f31,f3
	ctx.f0.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,16(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fsubs f0,f31,f3
	ctx.f0.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d637ac
	if (!ctx.cr0.eq) goto loc_82D637AC;
loc_82D673F8:
	// addi r1,r1,960
	ctx.r1.s64 = ctx.r1.s64 + 960;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D67404;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D67408"))) PPC_WEAK_FUNC(sub_82D67408);
PPC_FUNC_IMPL(__imp__sub_82D67408) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1032
	ctx.r5.s64 = ctx.r11.s64 + 1032;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,14048
	ctx.r4.s64 = ctx.r11.s64 + 14048;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D67420"))) PPC_WEAK_FUNC(sub_82D67420);
PPC_FUNC_IMPL(__imp__sub_82D67420) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D67428;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D67430;
	__savefpr_14(ctx, base);
	// stwu r1,-624(r1)
	ea = -624 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82d68b28
	if (!ctx.cr6.lt) goto loc_82D68B28;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// stw r10,300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 300, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f31,-8012(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8012);
	ctx.f31.f64 = double(temp.f32);
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lfs f1,-8008(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8008);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,-8004(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -8004);
	ctx.f2.f64 = double(temp.f32);
	// lfs f11,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f11.f64 = double(temp.f32);
	// stw r10,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f3,-8000(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8000);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,136(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
loc_82D6748C:
	// lfs f0,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f30,f0,f9
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f7,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f0,f8
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f9,f7
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f8,f6
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f29,f5,f7
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmuls f28,f4,f6
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f13,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f26,f4,f7
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// fmuls f27,f5,f6
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f20,f0,f5
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f16,f13,f4
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmadds f30,f13,f8,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f30.f64));
	// stfs f30,124(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmuls f19,f0,f6
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// fmuls f15,f13,f7
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmsubs f30,f13,f9,f25
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f25.f64));
	// stfs f30,136(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f16,f20
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f22,152(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fadds f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f23,f9,f6
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f18,f0,f4
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fmuls f22,f13,f5
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmuls f17,f0,f7
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fsubs f25,f21,f23
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fsubs f21,f22,f18
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f21,160(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f21,f13,f6
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fsubs f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f22,212(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmuls f19,f13,f27
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// fmuls f18,f0,f27
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fmuls f15,f25,f0
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fsubs f22,f17,f21
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f22,56(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f22,f20,f16
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmuls f16,f26,f0
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fadds f14,f21,f17
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfs f14,208(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmuls f14,f24,f0
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f22,f0,f30
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f21,f13,f30
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fmuls f20,f0,f29
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// fmuls f17,f13,f28
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmadds f16,f25,f13,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmsubs f16,f26,f13,f15
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmadds f16,f23,f13,f14
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f16,140(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f16,f19,f22
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f16,196(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f22,f21,f18
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f22,200(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f22,f18,f21
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f22,120(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmuls f21,f0,f28
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// rlwinm r10,r6,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// fmuls f22,f13,f29
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// fmuls f18,f8,f5
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f19,f9,f4
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f16,f9,f30
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f15,f8,f27
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f17,f8,f4
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmuls f14,f8,f30
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fadds f20,f21,f22
	ctx.f20.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f20,108(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,112(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fmuls f22,f9,f27
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f21,f18,f19
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f18,f23,f0
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f20,f9,f5
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmsubs f18,f24,f13,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f18,188(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fsubs f18,f16,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f18,168(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f18,100(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f16,f8,f28
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,176(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f17,f9,f29
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmuls f14,f19,f0
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f15,220(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,172(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f16,f9,f28
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f17,f8,f29
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,216(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,144(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f15,f20,f0
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmsubs f20,f20,f13,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f20,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f22,f0
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f16,f21,f0
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmadds f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f19,64(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f19,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,180(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f19,f18,f0
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmadds f17,f21,f13,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmsubs f17,f22,f13,f16
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f17,88(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmadds f20,f18,f13,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f20,96(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmsubs f20,f20,f13,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f19.f64));
	// stfs f20,184(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f20,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f18,f19,f0
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f17,f19,f13,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f17,164(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// mulli r8,r6,96
	ctx.r8.s64 = ctx.r6.s64 * 96;
	// fmadds f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f17,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f17,f13,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f20.f64));
	// stfs f20,132(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f20,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r9,r6,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fmadds f20,f20,f13,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f20,28(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// add r30,r7,r3
	ctx.r30.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfs f17,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f17.f64 = double(temp.f32);
	// mulli r5,r6,100
	ctx.r5.s64 = ctx.r6.s64 * 100;
	// fmuls f16,f20,f17
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f17.f64));
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f20,f18
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f18.f64));
	// lfs f20,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// stw r30,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r30.u32);
	// mulli r31,r6,68
	ctx.r31.s64 = ctx.r6.s64 * 68;
	// fmadds f18,f20,f18,f16
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 + ctx.f16.f64));
	// fmsubs f17,f20,f17,f15
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f20,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// add r29,r5,r3
	ctx.r29.u64 = ctx.r5.u64 + ctx.r3.u64;
	// add r28,r31,r3
	ctx.r28.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fadds f16,f18,f20
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f16,100(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfsx f16,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stw r7,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r7.u32);
	// lfs f16,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// stw r29,288(r1)
	PPC_STORE_U32(ctx.r1.u32 + 288, ctx.r29.u32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stw r5,312(r1)
	PPC_STORE_U32(ctx.r1.u32 + 312, ctx.r5.u32);
	// stfs f20,128(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stw r28,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, ctx.r28.u32);
	// lfs f20,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// stw r31,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r31.u32);
	// fsubs f18,f20,f17
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f18,192(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,116(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f20,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f20,f26
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfsx f17,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// fmadds f25,f18,f25,f16
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f16.f64));
	// fmsubs f20,f18,f26,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 - ctx.f20.f64));
	// lfs f26,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f6
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f18,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f26,f18,f15
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f26,f26,f15,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f15.f64 - ctx.f17.f64));
	// stfs f26,20(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f7.f64));
	// lfs f26,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f26,f17
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f26,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f15.f64));
	// lfs f26,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f6,f26,f6,f14
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f14.f64));
	// stfs f6,96(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmsubs f26,f26,f7,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 - ctx.f16.f64));
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f16,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f16.f64 = double(temp.f32);
	// mulli r7,r6,124
	ctx.r7.s64 = ctx.r6.s64 * 124;
	// lfs f6,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// mulli r29,r6,36
	ctx.r29.s64 = ctx.r6.s64 * 36;
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fmadds f17,f7,f16,f17
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f7,f16,f15
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f7,f18,f25
	ctx.f7.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fsubs f18,f20,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// mulli r5,r6,92
	ctx.r5.s64 = ctx.r6.s64 * 92;
	// fadds f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 + ctx.f15.f64));
	// stfs f15,196(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f7
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f7.f64));
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f25.f64));
	// stfs f7,260(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// fadds f25,f25,f7
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f7.f64));
	// lfs f7,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f7,f18
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f18.f64));
	// stfs f7,228(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f7,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f7.f64 = double(temp.f32);
	// add r28,r29,r3
	ctx.r28.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fadds f18,f18,f7
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f7.f64));
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// fadds f7,f7,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f20.f64));
	// stfs f7,192(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// add r29,r29,r4
	ctx.r29.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fsubs f7,f7,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f20.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// stfs f7,200(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f7,f6,f20
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// stfs f7,20(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// mulli r30,r6,28
	ctx.r30.s64 = ctx.r6.s64 * 28;
	// lfs f7,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// stw r28,296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 296, ctx.r28.u32);
	// fmadds f6,f7,f20,f14
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f20.f64 + ctx.f14.f64));
	// lfs f20,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f20.f64 = double(temp.f32);
	// stw r29,304(r1)
	PPC_STORE_U32(ctx.r1.u32 + 304, ctx.r29.u32);
	// mulli r31,r6,60
	ctx.r31.s64 = ctx.r6.s64 * 60;
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f7,f7,f20,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f20.f64 - ctx.f14.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f6,f14
	ctx.f20.f64 = double(float(ctx.f6.f64 + ctx.f14.f64));
	// fsubs f6,f14,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 - ctx.f6.f64));
	// stfs f6,156(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f6,f7,f26
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// stfs f6,100(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 - ctx.f7.f64));
	// lfsx f26,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,180(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfsx f26,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,184(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfsx f26,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,152(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f6,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f26,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f6,20(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stfs f26,188(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfsx f6,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f26,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f7,116(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f7,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// stfs f6,96(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f26,160(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfsx f26,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f7,f8
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// stfs f26,128(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f26,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// mulli r28,r6,48
	ctx.r28.s64 = ctx.r6.s64 * 48;
	// stfs f26,148(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f26,f7,f9
	ctx.f26.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f6,f7
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// mulli r27,r6,80
	ctx.r27.s64 = ctx.r6.s64 * 80;
	// fmsubs f9,f7,f9,f14
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 - ctx.f14.f64));
	// stfs f9,140(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f9,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f9.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f8,f7,f8,f26
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f26.f64));
	// stfs f8,20(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f8,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// lfs f7,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f9,f7
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f9,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f8,f9,f8,f6
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,108(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f8,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f9,f9,f8,f26
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 - ctx.f26.f64));
	// stfs f9,120(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f9,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f9,f8
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f8,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f26,f9,f8
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f8,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f8,f9,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f7.f64));
	// lfs f7,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f8,f8,f7,f14
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f14.f64));
	// stfs f8,72(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f7,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f14,f8,f19
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// lfs f8,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f7,f8,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f6.f64));
	// lfs f6,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f7,f7,f6,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 - ctx.f26.f64));
	// lfs f26,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// fadds f6,f26,f17
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// fsubs f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f16,f6,f20
	ctx.f16.f64 = double(float(ctx.f6.f64 + ctx.f20.f64));
	// fsubs f6,f20,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 - ctx.f6.f64));
	// stfs f6,160(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f6,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f6.f64 = double(temp.f32);
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 - ctx.f20.f64));
	// stfs f20,152(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// fadds f6,f20,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// stfs f20,268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// stfs f26,204(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f26,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f20,f26,f17
	ctx.f20.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// stfs f20,252(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f26,308(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f26,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f26.f64 = double(temp.f32);
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f20,f26
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f20,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f26,f20,f26,f14
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f26.f64 + ctx.f14.f64));
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f17.f64));
	// fadds f19,f8,f14
	ctx.f19.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// lfs f17,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f7,f17
	ctx.f17.f64 = double(float(ctx.f7.f64 + ctx.f17.f64));
	// mulli r26,r6,112
	ctx.r26.s64 = ctx.r6.s64 * 112;
	// fsubs f7,f14,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 - ctx.f7.f64));
	// fadds f14,f26,f9
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f9.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f9,f26,f9
	ctx.f9.f64 = double(float(ctx.f26.f64 - ctx.f9.f64));
	// lfsx f26,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,148(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fsubs f17,f8,f20
	ctx.f17.f64 = double(float(ctx.f8.f64 - ctx.f20.f64));
	// stfs f17,284(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fadds f8,f20,f8
	ctx.f8.f64 = double(float(ctx.f20.f64 + ctx.f8.f64));
	// stfs f8,184(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfsx f8,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,20(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f8,f9,f7
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// stfs f8,224(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// lfsx f8,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f26,f29
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// stfs f8,24(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f9,96(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f9,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f20,f9,f22
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f22.f64));
	// lfs f8,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f17,f9,f21
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// lfs f9,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f14,f8,f9
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f8,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// stfs f9,164(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f8,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f9,f8,f28,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 + ctx.f7.f64));
	// lfs f28,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f8,f8,f29,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f29.f64 - ctx.f26.f64));
	// lfs f29,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f7,f28,f21,f20
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfs f26,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f29
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmuls f29,f20,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f29.f64));
	// stfs f29,104(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmsubs f29,f28,f22,f17
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 - ctx.f17.f64));
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// stfs f26,52(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmr f26,f28
	ctx.f26.f64 = ctx.f28.f64;
	// lfs f28,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f28,f28,f26,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f26.f64 + ctx.f14.f64));
	// fmsubs f26,f22,f26,f17
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f26.f64 - ctx.f17.f64));
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r25,r6,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f22,f20,f21,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 + ctx.f17.f64));
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// mulli r24,r6,104
	ctx.r24.s64 = ctx.r6.s64 * 104;
	// fmsubs f21,f20,f21,f17
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 - ctx.f17.f64));
	// fadds f20,f28,f9
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f9.f64));
	// fsubs f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f28.f64));
	// fadds f17,f26,f8
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// mulli r23,r6,72
	ctx.r23.s64 = ctx.r6.s64 * 72;
	// fsubs f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f26.f64));
	// fadds f14,f22,f7
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f7.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f7,f22,f7
	ctx.f7.f64 = double(float(ctx.f22.f64 - ctx.f7.f64));
	// fadds f14,f21,f29
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f29,f21,f29
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// lfsx f26,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,164(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// mulli r22,r6,40
	ctx.r22.s64 = ctx.r6.s64 * 40;
	// fsubs f28,f8,f9
	ctx.f28.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// fadds f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// lfsx f26,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f8,f29,f7
	ctx.f8.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// stfs f8,176(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f8,f7,f29
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// lfsx f7,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,56(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// mulli r21,r6,120
	ctx.r21.s64 = ctx.r6.s64 * 120;
	// lfsx f29,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,52(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// stfs f26,104(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfsx f26,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,156(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfsx f26,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f8,100(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f26,20(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f8,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f26,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f8,f27
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// stfs f26,108(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f26,f8,f30
	ctx.f26.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// lfsx f7,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f21,f7,f8
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f29,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fmuls f14,f7,f8
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f8,f29,f8
	ctx.f8.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fmuls f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f7.f64));
	// stfs f7,148(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f29,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f29.f64 = double(temp.f32);
	// fmr f7,f29
	ctx.f7.f64 = ctx.f29.f64;
	// stfs f8,56(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f29,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f8,f7,f27,f26
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f27.f64 + ctx.f26.f64));
	// lfs f27,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f7,f7,f30,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f22.f64));
	// lfs f30,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f29,f30,f29,f21
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 + ctx.f21.f64));
	// stfs f29,52(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f29,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f26,f29,f24
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// fmuls f21,f29,f23
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f23.f64));
	// lfs f29,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f30,f30,f29,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 - ctx.f14.f64));
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// mulli r20,r6,88
	ctx.r20.s64 = ctx.r6.s64 * 88;
	// lfs f29,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// mulli r19,r6,56
	ctx.r19.s64 = ctx.r6.s64 * 56;
	// fmadds f29,f27,f29,f22
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f22.f64));
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f27,f22,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f26,f22,f23,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f26.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f24,f22,f24,f21
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f21.f64));
	// fadds f23,f29,f8
	ctx.f23.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// fsubs f8,f8,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f29.f64));
	// fadds f22,f27,f7
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// lfs f27,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f26,f27
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// mulli r18,r6,24
	ctx.r18.s64 = ctx.r6.s64 * 24;
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f26,f24,f30
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fsubs f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// mulli r17,r6,20
	ctx.r17.s64 = ctx.r6.s64 * 20;
	// fadds f24,f29,f23
	ctx.f24.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// fsubs f23,f22,f26
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fadds f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// fadds f22,f27,f7
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// stfs f7,188(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f7,f8,f30
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f30.f64));
	// stfs f7,112(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f8,f30,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 + ctx.f8.f64));
	// stfs f8,180(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f8,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f8.f64 = double(temp.f32);
	// mulli r16,r6,84
	ctx.r16.s64 = ctx.r6.s64 * 84;
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f30,f8
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// lfs f7,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f21,f7,f8
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// add r15,r17,r3
	ctx.r15.u64 = ctx.r17.u64 + ctx.r3.u64;
	// add r14,r16,r3
	ctx.r14.u64 = ctx.r16.u64 + ctx.r3.u64;
	// add r17,r17,r4
	ctx.r17.u64 = ctx.r17.u64 + ctx.r4.u64;
	// add r16,r16,r4
	ctx.r16.u64 = ctx.r16.u64 + ctx.r4.u64;
	// fmadds f7,f7,f8,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f27.f64));
	// lfsx f27,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f8,f30,f8,f21
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f21.f64));
	// stfs f27,48(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f30,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stw r15,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r15.u32);
	// stfs f30,56(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// stw r17,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, ctx.r17.u32);
	// lfsx f30,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// stw r14,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, ctx.r14.u32);
	// stfs f30,68(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// stw r16,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r16.u32);
	// lfsx f30,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,52(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f8,104(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfsx f8,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f30,f8,f30
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// stfs f7,124(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfsx f7,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f7,f14
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f14.f64));
	// fmuls f21,f7,f21
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// lfs f7,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f8,f8,f7,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 + ctx.f27.f64));
	// stfs f8,28(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f8,f8,f7,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f30.f64));
	// stfs f8,136(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f7,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f30,f8,f7
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f8,f7
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f7,f8,f21
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f21.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f7,f7,f21,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 - ctx.f14.f64));
	// stfs f7,92(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f7,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f21,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f7,f21
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f7,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f30,f7,f14,f30
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f14.f64 + ctx.f30.f64));
	// stfs f30,60(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f30,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// mulli r15,r6,116
	ctx.r15.s64 = ctx.r6.s64 * 116;
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f14.f64));
	// lfs f30,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f7,f7,f30,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f27.f64));
	// lfs f27,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f27,f30,f21
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f27,f27,f21,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f21.f64 - ctx.f14.f64));
	// lfs f21,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f8,f21
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f21,84(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f21,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// stfs f8,48(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f8,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f8
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f8.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f7,f14
	ctx.f14.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f14.f64));
	// stfs f7,68(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f7,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f7.f64));
	// stfs f14,124(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f14.f64));
	// stfs f7,208(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f7,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f7.f64));
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fadds f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// stfs f7,132(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f7,f8,f21
	ctx.f7.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f7,148(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f8,f21,f8
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// stfs f8,108(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f7,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfs f21,164(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f8,232(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f8,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f7.f64 = double(temp.f32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f8,f7
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// stfs f8,16(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f7,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f8,f7,f21,f14
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 + ctx.f14.f64));
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r15,r3
	ctx.r14.u64 = ctx.r15.u64 + ctx.r3.u64;
	// fmsubs f7,f7,f21,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 - ctx.f14.f64));
	// add r15,r15,r4
	ctx.r15.u64 = ctx.r15.u64 + ctx.r4.u64;
	// fsubs f21,f30,f8
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f8.f64));
	// fadds f8,f8,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f30.f64));
	// stfs f8,40(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// mulli r17,r6,12
	ctx.r17.s64 = ctx.r6.s64 * 12;
	// stw r14,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r14.u32);
	// stw r15,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r15.u32);
	// fsubs f8,f27,f7
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f7.f64));
	// mulli r15,r6,52
	ctx.r15.s64 = ctx.r6.s64 * 52;
	// fadds f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f27.f64));
	// stfs f7,48(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// add r14,r15,r3
	ctx.r14.u64 = ctx.r15.u64 + ctx.r3.u64;
	// add r15,r15,r4
	ctx.r15.u64 = ctx.r15.u64 + ctx.r4.u64;
	// fadds f14,f8,f21
	ctx.f14.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f14,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r16,r6,76
	ctx.r16.s64 = ctx.r6.s64 * 76;
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f21.f64));
	// stfs f8,56(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f8,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// stw r14,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, ctx.r14.u32);
	// stw r15,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r15.u32);
	// stfs f8,16(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f8,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,60(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f8,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,92(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f8,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f8.f64 = double(temp.f32);
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// lfs f27,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// lwz r15,172(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lfs f7,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lwz r15,20(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fmuls f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmuls f7,f7,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// lfs f21,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f27,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fmuls f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f8,f30,f14,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f14.f64 + ctx.f8.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f7,f30,f14,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f14.f64 - ctx.f7.f64));
	// stfs f7,84(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f7,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f7,f5
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// lfs f30,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f30.f64 = double(temp.f32);
	// lwz r15,144(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lfs f7,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f30,f7,f30,f21
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 + ctx.f21.f64));
	// stfs f30,28(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f30,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f30,f4
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// lfs f30,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f7,f7,f30,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f27.f64));
	// lfs f30,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f30.f64 = double(temp.f32);
	// lfs f27,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f30,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f4,f30,f4,f14
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f4.f64 + ctx.f14.f64));
	// fmsubs f5,f30,f5,f21
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f5.f64 - ctx.f21.f64));
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// lfs f30,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f21,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f21.f64 + ctx.f27.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f8,f21
	ctx.f27.f64 = double(float(ctx.f8.f64 - ctx.f21.f64));
	// fadds f8,f21,f8
	ctx.f8.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// fsubs f21,f14,f7
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f7.f64));
	// fadds f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f14,f27,f21
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f21.f64));
	// stfs f8,212(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// mulli r15,r6,108
	ctx.r15.s64 = ctx.r6.s64 * 108;
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// fsubs f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfs f21,88(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f8,64(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f8,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f8.f64 = double(temp.f32);
	// fadds f21,f8,f14
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// fsubs f7,f14,f8
	ctx.f7.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// lfs f8,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f14,f8,f27
	ctx.f14.f64 = double(float(ctx.f8.f64 - ctx.f27.f64));
	// fadds f8,f27,f8
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f8.f64));
	// stfs f8,16(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f8,f7,f12
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f7,f21,f12
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f27,f14,f12
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// stfs f21,156(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f14.f64));
	// fadds f14,f30,f4
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f30,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// stfs f30,44(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f30,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,28(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f30,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f30,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f30.f64 = double(temp.f32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f30,f14,f30,f21
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f30.f64 - ctx.f21.f64));
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,40(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f14,f30,f5
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// lfsx f21,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// stfs f30,60(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f30,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f21,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f14,f5,f4
	ctx.f14.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f5,56(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// lfs f5,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f14,f21,f5
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f5,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f5,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f13,f5,f13,f4
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f4.f64));
	// fmsubs f0,f5,f0,f30
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f30.f64));
	// lfs f4,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f4,f5,f14
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfs f30,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f4,f4,f30,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 - ctx.f21.f64));
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f5,f13
	ctx.f30.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// fsubs f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f5.f64));
	// fadds f5,f4,f0
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f0.f64));
	// fsubs f0,f0,f4
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f4.f64));
	// fadds f4,f30,f21
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f21,f5,f14
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f14.f64));
	// stfs f21,44(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f21,f0,f13
	ctx.f21.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// fsubs f13,f14,f5
	ctx.f13.f64 = double(float(ctx.f14.f64 - ctx.f5.f64));
	// stfs f13,92(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f13,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// lfs f5,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f5.f64 = double(temp.f32);
	// fadds f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// stfs f13,36(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f13,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f5,f13,f21
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f21.f64));
	// fadds f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f13.f64));
	// lfs f13,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f14,f0,f13
	ctx.f14.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,16(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f0,f5,f12
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f13,f21,f12
	ctx.f13.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f5,f14,f12
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f5,128(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f5,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f5,168(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fadds f21,f5,f16
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f16.f64));
	// lfs f5,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f5.f64 = double(temp.f32);
	// fadds f14,f4,f5
	ctx.f14.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f5,f14,f21
	ctx.f5.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// fsubs f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfs f21,32(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,36(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f21,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f14,f21,f5
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f5.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f21.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// lfs f5,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f14,f14,f5
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f5.f64));
	// stfsx f14,r10,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfs f21,0(r3)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// fadds f5,f5,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f21.f64));
	// stfs f5,0(r4)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// lfs f5,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f21,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f5.f64));
	// stfsx f5,r8,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f5,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f21.f64));
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f6,f6,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f21.f64));
	// stfsx f5,r8,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f21,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 - ctx.f4.f64));
	// fsubs f5,f16,f5
	ctx.f5.f64 = double(float(ctx.f16.f64 - ctx.f5.f64));
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f17,f23,f29
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f29,48(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f23,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f29,84(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f23,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f29,44(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f29,76(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// stfsx f29,r9,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f29,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f29.f64 = double(temp.f32);
	// lfs f23,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// lfs f23,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f23,40(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f23,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f29,r9,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f29,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f29.f64 = double(temp.f32);
	// stfs f20,80(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f29,f15,f29
	ctx.f29.f64 = double(float(ctx.f15.f64 - ctx.f29.f64));
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f6,f5
	ctx.f15.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fsubs f5,f4,f21
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f21.f64));
	// stfs f5,36(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f5,f21,f4
	ctx.f5.f64 = double(float(ctx.f21.f64 + ctx.f4.f64));
	// stfs f5,68(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fadds f5,f26,f16
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// stfs f5,32(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f5,f16,f26
	ctx.f5.f64 = double(float(ctx.f16.f64 - ctx.f26.f64));
	// stfs f5,52(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fadds f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// fmuls f21,f14,f10
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// lfs f5,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f5,f24
	ctx.f4.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// stfs f4,56(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f24.f64));
	// stfs f5,104(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f5,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f26,f5,f17
	ctx.f26.f64 = double(float(ctx.f5.f64 - ctx.f17.f64));
	// fadds f24,f17,f5
	ctx.f24.f64 = double(float(ctx.f17.f64 + ctx.f5.f64));
	// lfs f4,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f14,f11
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f11.f64));
	// fadds f16,f4,f5
	ctx.f16.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f14,f4,f5
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// lfs f5,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// stfs f5,16(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f4,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f5,f26,f12
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmuls f26,f24,f12
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// stfs f4,28(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f24,f16,f12
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f26,64(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f26,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f4,f26,f11,f21
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 - ctx.f21.f64));
	// fmadds f26,f26,f10,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f17.f64));
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f10,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f16.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f14,f12
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f17,f10,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f16.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f17,f6
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f6.f64));
	// fsubs f6,f6,f17
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f17.f64));
	// stfs f6,16(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fmuls f6,f16,f12
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmuls f17,f14,f12
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fsubs f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f6.f64));
	// stfsx f14,r27,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f6,f6,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f14.f64));
	// stfsx f6,r29,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f6,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f6.f64 = double(temp.f32);
	// fadds f14,f17,f6
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f6.f64));
	// stfsx f14,r29,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f6,f17
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f17.f64));
	// stfsx f6,r27,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f6.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fsubs f17,f6,f16
	ctx.f17.f64 = double(float(ctx.f6.f64 - ctx.f16.f64));
	// stfsx f17,r26,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f16,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 + ctx.f6.f64));
	// stfsx f6,r28,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fadds f16,f21,f23
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fadds f17,f15,f6
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f6.f64));
	// stfsx f17,r28,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f6,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f15.f64));
	// stfsx f6,r26,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f6,f19,f6
	ctx.f6.f64 = double(float(ctx.f19.f64 - ctx.f6.f64));
	// lfs f19,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fadds f17,f5,f29
	ctx.f17.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fsubs f5,f29,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// lfs f29,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f15,f28,f29
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// lfs f29,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f14,f29,f9
	ctx.f14.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// fsubs f29,f23,f21
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f24,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f23,28(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfs f24,48(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// lfs f21,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fmuls f15,f14,f12
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fmsubs f21,f22,f10,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f21.f64));
	// stfs f21,32(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f21,f30,f11
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fmuls f15,f6,f11
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f14,f19,f11
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fmuls f19,f19,f10
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fmsubs f6,f6,f10,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 - ctx.f21.f64));
	// fmadds f30,f30,f10,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 + ctx.f15.f64));
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f20,f10,f14
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f20,f11,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 - ctx.f19.f64));
	// fsubs f19,f15,f14
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 + ctx.f14.f64));
	// stfs f14,228(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f6,f6,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f14.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// fadds f14,f21,f4
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f4.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f4,f4,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f21.f64));
	// fadds f14,f20,f26
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// lfs f21,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f20,f17,f21
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfsx f20,r20,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfsx f21,r18,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fadds f20,f16,f21
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfsx f20,r18,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// stfsx f21,r20,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f5,f30
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// stfsx f21,r21,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfsx f5,r19,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f29,f6
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// stfsx f5,r19,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f29,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 - ctx.f6.f64));
	// stfsx f6,r21,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lfs f5,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f30,f6,f5
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// stfsx f30,r23,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfsx f6,r25,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f23,f14
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfsx f6,r25,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f23,f14
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfsx f6,r23,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f5,f6,f26
	ctx.f5.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// stfsx f5,r24,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// stfsx f6,r22,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f24,f4
	ctx.f6.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// stfsx f6,r22,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f24,f4
	ctx.f6.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// lfs f26,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f24.f64 = double(temp.f32);
	// lfs f29,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f5,f24,f27
	ctx.f5.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfsx f6,r24,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 - ctx.f0.f64));
	// lfs f23,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f6,f26,f8
	ctx.f6.f64 = double(float(ctx.f26.f64 - ctx.f8.f64));
	// lfs f30,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f30.f64 = double(temp.f32);
	// lfs f21,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f21.f64 = double(temp.f32);
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f16,f21,f10
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f21,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f21,f11
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f29,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f29.f64 = double(temp.f32);
	// lfs f20,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// fmuls f17,f20,f11
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fadds f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fadds f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// fmadds f24,f22,f11,f16
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fmsubs f23,f20,f10,f14
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 - ctx.f14.f64));
	// stfs f23,224(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f22,f6,f31
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f5,f31
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmadds f26,f21,f10,f17
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f17.f64));
	// fmuls f21,f30,f31
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fmuls f17,f4,f31
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f14,f27,f3
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fmuls f27,f27,f2
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// fmuls f16,f29,f2
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f2.f64));
	// fmadds f5,f5,f1,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f22.f64));
	// fmsubs f6,f6,f1,f20
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 - ctx.f20.f64));
	// fsubs f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fmsubs f4,f4,f1,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f1.f64 - ctx.f21.f64));
	// fmadds f30,f30,f1,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 + ctx.f17.f64));
	// fmuls f17,f29,f3
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// lfs f29,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f20,f8,f2,f14
	ctx.f20.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 + ctx.f14.f64));
	// fmsubs f8,f8,f3,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 - ctx.f27.f64));
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f26,f19,f23
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// fadds f27,f23,f19
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// fadds f23,f4,f5
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fadds f4,f30,f6
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// lfs f21,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f21,f24
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// fadds f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fmsubs f21,f0,f3,f16
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f3.f64 - ctx.f16.f64));
	// fmadds f0,f0,f2,f17
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f2.f64 + ctx.f17.f64));
	// fsubs f17,f27,f23
	ctx.f17.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfsx f17,r5,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfsx f27,r30,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f23,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f23.f64 = double(temp.f32);
	// fadds f19,f22,f25
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fsubs f30,f25,f22
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fadds f25,f24,f15
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// fadds f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f27,f19,f4
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// stfsx f27,r30,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f19,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 - ctx.f4.f64));
	// stfsx f4,r5,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f26,f6
	ctx.f4.f64 = double(float(ctx.f26.f64 - ctx.f6.f64));
	// stfsx f4,r7,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f26.f64));
	// stfsx f6,r31,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f30,f5
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfsx f6,r31,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f30,f5
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfsx f6,r7,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f5,f25,f22
	ctx.f5.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// lfs f6,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f6.f64 = double(temp.f32);
	// lfs f26,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f26.f64 = double(temp.f32);
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f27,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f4,f26,f7
	ctx.f4.f64 = double(float(ctx.f26.f64 - ctx.f7.f64));
	// stfsx f5,r16,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// lfs f5,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f30,f27,f23
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fadds f5,f13,f5
	ctx.f5.f64 = double(float(ctx.f13.f64 + ctx.f5.f64));
	// fadds f23,f26,f9
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f9.f64));
	// lfs f9,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f26,f15,f24
	ctx.f26.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// fadds f19,f9,f28
	ctx.f19.f64 = double(float(ctx.f9.f64 + ctx.f28.f64));
	// lfs f9,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f17,f9,f10
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f9,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f16,f9,f11
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f28,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// stfs f9,204(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmuls f14,f28,f10
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// lfs f28,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f28.f64 = double(temp.f32);
	// fadds f9,f8,f0
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// lfs f24,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f0.f64));
	// lwz r10,236(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// fadds f28,f29,f28
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// lwz r9,300(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// fsubs f8,f21,f20
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f21,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f21.f64 = double(temp.f32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfsx f25,r17,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// lfs f22,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f24,f23,f12
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f25,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f19,f12
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f21,f21,f11,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 - ctx.f17.f64));
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f19,f19,f11,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f14.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fmadds f20,f17,f10,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f16.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fmuls f14,f7,f31
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fsubs f13,f22,f13
	ctx.f13.f64 = double(float(ctx.f22.f64 - ctx.f13.f64));
	// fmuls f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// stfs f7,232(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f22,f6,f1
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// stw r10,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, ctx.r10.u32);
	// fmuls f15,f4,f3
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fmadds f7,f5,f31,f22
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 + ctx.f22.f64));
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// stfs f13,204(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmsubs f17,f17,f11,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f16.f64));
	// fmuls f13,f5,f1
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmuls f16,f30,f3
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmsubs f5,f30,f2,f15
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 - ctx.f15.f64));
	// fadds f30,f28,f9
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f9.f64));
	// stfsx f30,r17,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f28,f9
	ctx.f9.f64 = double(float(ctx.f28.f64 - ctx.f9.f64));
	// stfsx f9,r16,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f26,f0
	ctx.f9.f64 = double(float(ctx.f26.f64 - ctx.f0.f64));
	// stfsx f9,r15,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f0,f26
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f26.f64));
	// stfsx f0,r14,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f29,f8
	ctx.f0.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// stfsx f0,r14,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f29,f8
	ctx.f0.f64 = double(float(ctx.f29.f64 - ctx.f8.f64));
	// stfsx f0,r15,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f18,f24
	ctx.f0.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// lfs f30,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f30.f64 = double(temp.f32);
	// fadds f9,f24,f18
	ctx.f9.f64 = double(float(ctx.f24.f64 + ctx.f18.f64));
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmsubs f13,f6,f31,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f31.f64 - ctx.f13.f64));
	// add r4,r9,r4
	ctx.r4.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fadds f26,f17,f19
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f24,f17,f19
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f22,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f6,f4,f2,f16
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f2.f64 + ctx.f16.f64));
	// fmadds f4,f27,f1,f14
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f14.f64));
	// fadds f8,f23,f30
	ctx.f8.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// fsubs f29,f21,f20
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f28,f20,f21
	ctx.f28.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// fmsubs f27,f27,f31,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64 - ctx.f22.f64));
	// fmuls f18,f25,f3
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f19,f3
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmsubs f25,f25,f2,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 - ctx.f21.f64));
	// lwz r10,240(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	// fadds f23,f29,f0
	ctx.f23.f64 = double(float(ctx.f29.f64 + ctx.f0.f64));
	// fadds f22,f24,f30
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fsubs f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f29.f64));
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// fadds f24,f4,f13
	ctx.f24.f64 = double(float(ctx.f4.f64 + ctx.f13.f64));
	// fadds f29,f26,f9
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f9.f64));
	// fadds f21,f27,f7
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f27,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 - ctx.f7.f64));
	// fsubs f9,f9,f26
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f26.f64));
	// fadds f20,f28,f8
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// fsubs f13,f13,f4
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f4.f64));
	// fsubs f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// fadds f4,f25,f6
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// fmadds f19,f19,f2,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 + ctx.f18.f64));
	// fsubs f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 - ctx.f6.f64));
	// fsubs f28,f29,f24
	ctx.f28.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// fadds f27,f24,f29
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// fsubs f24,f9,f7
	ctx.f24.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f26,f20,f21
	ctx.f26.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f7,f8,f13
	ctx.f7.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fsubs f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fsubs f8,f23,f4
	ctx.f8.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,292(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// fadds f29,f19,f5
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f5.f64));
	// fadds f8,f4,f23
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// fsubs f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f19.f64));
	// fsubs f25,f20,f21
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,276(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// fadds f8,f30,f6
	ctx.f8.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// fadds f4,f22,f29
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// stfs f4,0(r10)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,244(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// fsubs f4,f22,f29
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// stfs f4,0(r10)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// fsubs f4,f0,f5
	ctx.f4.f64 = double(float(ctx.f0.f64 - ctx.f5.f64));
	// fadds f0,f5,f0
	ctx.f0.f64 = double(float(ctx.f5.f64 + ctx.f0.f64));
	// stfs f4,0(r10)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,248(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,144(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// fsubs f0,f30,f6
	ctx.f0.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,20(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,256(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	// stfs f28,0(r10)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,264(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// stfs f27,0(r10)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,272(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// stfs f26,0(r10)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,280(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// stfs f25,0(r10)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,288(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	// stfs f24,0(r10)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,296(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// stfs f9,0(r10)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,304(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// stfs f7,0(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	// stfs f13,0(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d6748c
	if (!ctx.cr0.eq) goto loc_82D6748C;
loc_82D68B28:
	// addi r1,r1,624
	ctx.r1.s64 = ctx.r1.s64 + 624;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D68B34;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D68B38"))) PPC_WEAK_FUNC(sub_82D68B38);
PPC_FUNC_IMPL(__imp__sub_82D68B38) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1120
	ctx.r5.s64 = ctx.r11.s64 + 1120;
	// lis r11,-32042
	ctx.r11.s64 = -2099904512;
	// addi r4,r11,29728
	ctx.r4.s64 = ctx.r11.s64 + 29728;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D68B50"))) PPC_WEAK_FUNC(sub_82D68B50);
PPC_FUNC_IMPL(__imp__sub_82D68B50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e3c
	ctx.lr = 0x82D68B58;
	__savegprlr_17(ctx, base);
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28ee0
	ctx.lr = 0x82D68B60;
	__savefpr_14(ctx, base);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82d69418
	if (!ctx.cr6.lt) goto loc_82D69418;
	// rlwinm r18,r9,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r22,r7,r8
	ctx.r22.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lfs f8,136(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
loc_82D68B94:
	// lfs f0,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r6,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r9,r6,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f13,f12
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f2,f0,f11
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f31,f13,f11
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f0,f12
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f7,f12
	ctx.f28.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f27,f7,f11
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f5,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f6,f11
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// add r21,r9,r4
	ctx.r21.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fmuls f25,f6,f12
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// add r20,r9,r3
	ctx.r20.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmuls f24,f0,f7
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f30,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f13,f6
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// lfs f29,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f0,f6
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// fadds f14,f1,f2
	ctx.f14.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfs f14,-352(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fmuls f21,f13,f7
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f16,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f3,f31
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// lfs f15,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f3,-316(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfs f3,-332(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f3,f28,f26
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f2,f25,f27
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f1,f25,f27
	ctx.f1.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f31,f26,f28
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f28,f24,f22
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f25,f22,f24
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f27,f21,f23
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f26,f21,f23
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fmuls f20,f5,f12
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f19,f5,f11
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f23,f13,f2
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f22,f0,f1
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmadds f20,f4,f11,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f20.f64));
	// fmsubs f19,f4,f12,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 - ctx.f19.f64));
	// lfs f24,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f21,f18,f24
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// fmuls f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// fmuls f24,f0,f3
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmadds f21,f17,f14,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f17,f14,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 - ctx.f18.f64));
	// fsubs f17,f24,f23
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-296(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmuls f23,f0,f2
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f24,f13,f3
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fadds f14,f23,f24
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f14,-288(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f24,-292(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmuls f23,f13,f1
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmuls f24,f0,f31
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-304(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmuls f24,f13,f31
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fadds f23,f22,f24
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f21,f30
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f22,-320(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f22,f29,f18
	ctx.f22.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// mulli r31,r6,48
	ctx.r31.s64 = ctx.r6.s64 * 48;
	// fmuls f21,f15,f3
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// add r23,r31,r3
	ctx.r23.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fmuls f18,f15,f2
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// mulli r7,r6,56
	ctx.r7.s64 = ctx.r6.s64 * 56;
	// fmadds f2,f16,f2,f21
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f21.f64));
	// lfsx f21,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-328(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmsubs f3,f16,f3,f18
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f18.f64));
	// stfs f3,-308(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// lfs f15,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-324(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfsx f15,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r5,r6,24
	ctx.r5.s64 = ctx.r6.s64 * 24;
	// stfs f15,-352(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f15,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-312(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfsx f3,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f15,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// mulli r8,r6,40
	ctx.r8.s64 = ctx.r6.s64 * 40;
	// lfsx f15,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-344(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmuls f15,f3,f1
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f1,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f18,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f16,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-340(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fmuls f16,f16,f1
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// stfs f18,-336(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fmuls f18,f18,f1
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// add r19,r31,r4
	ctx.r19.u64 = ctx.r31.u64 + ctx.r4.u64;
	// mulli r31,r6,60
	ctx.r31.s64 = ctx.r6.s64 * 60;
	// mulli r30,r6,44
	ctx.r30.s64 = ctx.r6.s64 * 44;
	// lfs f1,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,-316(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fmadds f1,f3,f31,f21
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f21.f64));
	// lfs f3,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f3,f31,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 - ctx.f15.f64));
	// stfs f3,-324(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f3,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f25
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f3,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f3.f64 = double(temp.f32);
	// lfs f21,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f21.f64 = double(temp.f32);
	// lfs f31,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f21,f21,f3,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 - ctx.f18.f64));
	// fmadds f31,f31,f3,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f16.f64));
	// lfs f3,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f20
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// lfs f3,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f25,f3,f25,f16
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64 + ctx.f16.f64));
	// lfs f16,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f3,f3,f27,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64 - ctx.f15.f64));
	// lfs f27,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f28
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f27,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f27,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f27.f64 = double(temp.f32);
	// stfs f28,-312(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f16,f16,f19
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f19.f64));
	// fmadds f28,f27,f19,f18
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f1,f31
	ctx.f19.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f31,f18,f21
	ctx.f31.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// fadds f18,f25,f2
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fsubs f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// fmsubs f27,f27,f20,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f16.f64));
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f25,f16,f3
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f3.f64));
	// lfs f20,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f20.f64 = double(temp.f32);
	// fadds f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f16.f64));
	// fmadds f20,f20,f26,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64 + ctx.f15.f64));
	// fsubs f16,f31,f19
	ctx.f16.f64 = double(float(ctx.f31.f64 - ctx.f19.f64));
	// fadds f31,f19,f31
	ctx.f31.f64 = double(float(ctx.f19.f64 + ctx.f31.f64));
	// lfs f19,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f26,f19,f26,f15
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 - ctx.f15.f64));
	// mulli r29,r6,28
	ctx.r29.s64 = ctx.r6.s64 * 28;
	// fsubs f19,f28,f20
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// mulli r28,r6,12
	ctx.r28.s64 = ctx.r6.s64 * 12;
	// fadds f28,f20,f28
	ctx.f28.f64 = double(float(ctx.f20.f64 + ctx.f28.f64));
	// fsubs f20,f27,f26
	ctx.f20.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfsx f26,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-308(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfsx f26,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-332(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// rlwinm r27,r6,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f27,-316(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfsx f27,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// mulli r26,r6,52
	ctx.r26.s64 = ctx.r6.s64 * 52;
	// fadds f15,f20,f19
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f15,-324(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f20,-328(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfsx f20,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f27,f4
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// stfs f20,-312(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfsx f20,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r25,r6,36
	ctx.r25.s64 = ctx.r6.s64 * 36;
	// stfs f20,-344(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfsx f15,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-336(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfsx f20,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-340(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f20,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-352(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f20,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-348(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfsx f20,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-300(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmuls f20,f27,f5
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f27,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f27.f64));
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f27,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f4,f27,f4,f20
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 + ctx.f20.f64));
	// fmsubs f5,f27,f5,f19
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f19.f64));
	// lfs f20,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f20.f64 = double(temp.f32);
	// lfs f27,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f27,f14
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// lfs f27,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f24,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f24.f64 + ctx.f15.f64));
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f26,f15,f24,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f24.f64 - ctx.f26.f64));
	// lfs f24,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// fmuls f15,f24,f7
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// stfs f24,-304(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmadds f24,f20,f23,f19
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 + ctx.f19.f64));
	// lfs f20,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f23,f20,f23,f14
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 - ctx.f14.f64));
	// lfs f20,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f12
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f20,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f6,f20,f6,f15
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f15.f64));
	// lfs f19,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f7,f20,f7,f19
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 - ctx.f19.f64));
	// fsubs f20,f4,f24
	ctx.f20.f64 = double(float(ctx.f4.f64 - ctx.f24.f64));
	// fadds f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// fsubs f24,f6,f27
	ctx.f24.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fadds f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f19,f5,f23
	ctx.f19.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// fadds f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// fsubs f27,f7,f26
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// fadds f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// fsubs f23,f4,f6
	ctx.f23.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fadds f26,f24,f19
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// fsubs f15,f20,f27
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// stfs f15,-332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fadds f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// lfs f20,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f20,f11
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f20,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f5,f7
	ctx.f15.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// fmadds f11,f20,f11,f14
	ctx.f11.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f14.f64));
	// stfs f11,-352(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f11,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f11.f64 = double(temp.f32);
	// fmsubs f12,f20,f12,f19
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 - ctx.f19.f64));
	// fsubs f14,f16,f11
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f11.f64));
	// lfs f11,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f31.f64));
	// stfs f11,-300(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmuls f19,f26,f9
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// stfs f12,-340(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f12,f30,f25
	ctx.f12.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// mulli r24,r6,20
	ctx.r24.s64 = ctx.r6.s64 * 20;
	// fadds f11,f2,f22
	ctx.f11.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// fmuls f20,f14,f10
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// lfs f14,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f10
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// stfs f14,-300(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f14,f8,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f8.f64 - ctx.f19.f64));
	// stfs f19,-336(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f19,f20,f12
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f12.f64));
	// stfs f19,-312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fsubs f12,f12,f20
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f20.f64));
	// stfs f12,-276(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfsx f19,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f14,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f19,-304(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f0,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f12.f64 = double(temp.f32);
	// fadds f20,f11,f12
	ctx.f20.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// stfs f20,-280(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// lfsx f11,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,-344(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfsx f11,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,-348(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfsx f20,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f11,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f11.f64 = double(temp.f32);
	// stfs f12,-284(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfsx f12,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// stfs f20,-300(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fmuls f11,f12,f11
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// stfs f11,-292(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmr f11,f0
	ctx.f11.f64 = ctx.f0.f64;
	// fmadds f0,f12,f11,f20
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f20.f64));
	// lfs f12,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f12.f64 = double(temp.f32);
	// lfs f20,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f12,f12,f11,f20
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f20.f64));
	// lfs f11,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f20,f11,f17
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// lfs f11,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f17,f11,f17
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// lfs f11,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f11,f11,f13,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f13,f14,f13,f19
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f19.f64));
	// lfs f14,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f14,f19,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 + ctx.f20.f64));
	// lfs f14,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f14,f19,f17
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 - ctx.f17.f64));
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f13.f64));
	// stfs f14,-344(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f11.f64));
	// fadds f11,f11,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f14.f64));
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f13,f13,f14
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f14.f64));
	// fsubs f14,f20,f0
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f0.f64));
	// fadds f0,f20,f0
	ctx.f0.f64 = double(float(ctx.f20.f64 + ctx.f0.f64));
	// fsubs f20,f19,f12
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f12.f64));
	// fadds f12,f19,f12
	ctx.f12.f64 = double(float(ctx.f19.f64 + ctx.f12.f64));
	// lfs f19,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,-340(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f19,f17,f20
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f19,-288(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f19,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f19.f64 = double(temp.f32);
	// stfs f20,-344(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// fsubs f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f2.f64));
	// lfs f20,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f20,f8
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// stfs f26,-288(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmuls f14,f20,f9
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// lfs f20,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f26,f11,f0
	ctx.f26.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// fmadds f20,f20,f9,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 + ctx.f17.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f17,-292(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,-296(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fsubs f20,f13,f12
	ctx.f20.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f17,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// fadds f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// stfs f20,-304(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fsubs f20,f23,f15
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f20,-300(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f20,f13,f12
	ctx.f20.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// lfs f15,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// lfs f20,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f20,f20,f8,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f14,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f9,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64 + ctx.f14.f64));
	// stfs f15,-332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f15,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f19,f8
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// fadds f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f31.f64));
	// lfs f31,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f31.f64 = double(temp.f32);
	// fadds f16,f31,f16
	ctx.f16.f64 = double(float(ctx.f31.f64 + ctx.f16.f64));
	// fmuls f31,f24,f8
	ctx.f31.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// stfs f31,-288(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fadds f31,f25,f30
	ctx.f31.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// fmuls f30,f15,f10
	ctx.f30.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// stfs f30,-324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmuls f30,f16,f10
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// stfs f30,-328(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f30,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f30.f64 = double(temp.f32);
	// lfs f25,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f22,f30,f25
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// stfsx f22,r30,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f16,f25,f30
	ctx.f16.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// lfs f30,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f9,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f14.f64));
	// stfs f30,-308(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f30,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f30.f64 = double(temp.f32);
	// lfs f25,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f15,f30,f25
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// fadds f14,f25,f30
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// lfs f25,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f25.f64 = double(temp.f32);
	// lfs f30,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f27,f9,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f30.f64));
	// stfs f30,-336(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f30,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f30.f64 = double(temp.f32);
	// fadds f22,f25,f30
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// fsubs f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// stfs f30,-292(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fadds f25,f23,f26
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// lfs f23,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f30,f21,f23
	ctx.f30.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfs f30,-284(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// stfs f26,-288(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f26,f28,f1
	ctx.f26.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fadds f30,f30,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// stfs f30,-296(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f30,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// stfs f30,-304(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// stfs f25,-284(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fsubs f30,f29,f3
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// fmuls f23,f22,f10
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// stfs f23,-300(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f17,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f28,f1
	ctx.f23.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fadds f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f31.f64));
	// addic. r22,r22,-1
	ctx.xer.ca = ctx.r22.u32 > 0;
	ctx.r22.s64 = ctx.r22.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// fsubs f25,f29,f3
	ctx.f25.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fmuls f27,f27,f8
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fadds f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fadds f11,f6,f4
	ctx.f11.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// lfs f26,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// stfs f26,-340(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f26,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// lfs f20,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fmuls f20,f20,f10
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// lfs f22,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f22.f64 = double(temp.f32);
	// stfs f17,-284(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fmuls f23,f22,f10
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f17,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f31,f31,f17
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f17.f64));
	// lfs f17,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f2,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 + ctx.f17.f64));
	// stfs f17,-312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f17,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// stfs f2,-292(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f2,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// lfs f22,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f22.f64 = double(temp.f32);
	// stfs f17,-288(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmuls f22,f22,f10
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f2,f17,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 - ctx.f2.f64));
	// stfs f2,-308(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f2,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f2,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// stfsx f17,r30,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f16,r28,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f17,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// stfsx f2,r28,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f2,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f17,f2,f26
	ctx.f17.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// stfsx f17,r31,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f17,f26,f2
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// stfsx f15,r31,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f2,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f2.f64 = double(temp.f32);
	// lfs f26,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f17,r29,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f16,f2,f26
	ctx.f16.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// stfsx f14,r29,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fadds f26,f26,f2
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// stfsx f16,r8,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fsubs f17,f30,f23
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// stfsx f17,r8,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// lfs f2,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f2.f64 = double(temp.f32);
	// stfsx f26,r9,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f23,f2,f22
	ctx.f23.f64 = double(float(ctx.f2.f64 - ctx.f22.f64));
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f26,f25,f20
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// stfsx f23,r7,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// stfsx f26,r7,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f30,f20,f25
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfsx f2,r5,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f2,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f2.f64 = double(temp.f32);
	// stfsx f30,r5,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f2,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f18,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 + ctx.f2.f64));
	// fadds f4,f3,f29
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// lfs f6,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f6.f64 = double(temp.f32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fadds f12,f7,f5
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// lfs f5,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f19,f9,f30
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 - ctx.f30.f64));
	// lfs f30,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f30.f64 = double(temp.f32);
	// fadds f6,f6,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f21.f64));
	// fsubs f29,f5,f30
	ctx.f29.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// stfsx f29,r25,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f29,f30,f5
	ctx.f29.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// lfs f5,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f5.f64 = double(temp.f32);
	// lfs f30,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f7,f24,f9,f27
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f27.f64));
	// fsubs f28,f5,f30
	ctx.f28.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// fadds f27,f30,f5
	ctx.f27.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// fadds f5,f1,f2
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f1,f11,f0
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// fadds f11,f4,f6
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fadds f4,f12,f13
	ctx.f4.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fadds f30,f7,f3
	ctx.f30.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fsubs f12,f5,f1
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f3,f6,f0
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f0.f64));
	// fadds f6,f0,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 + ctx.f6.f64));
	// lfs f0,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f26,f0,f30
	ctx.f26.f64 = double(float(ctx.f0.f64 - ctx.f30.f64));
	// stfsx f26,r25,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// stfsx f29,r27,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f30,f0
	ctx.f0.f64 = double(float(ctx.f30.f64 + ctx.f0.f64));
	// stfsx f0,r27,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f31,f7
	ctx.f0.f64 = double(float(ctx.f31.f64 - ctx.f7.f64));
	// stfsx f0,r26,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f7,f31
	ctx.f0.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// stfsx f28,r26,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fsubs f1,f11,f4
	ctx.f1.f64 = double(float(ctx.f11.f64 - ctx.f4.f64));
	// stfsx f0,r24,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f11,f4,f11
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// stfsx f27,r24,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f2,f13
	ctx.f0.f64 = double(float(ctx.f2.f64 - ctx.f13.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f13,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f2.f64));
	// stfsx f1,r10,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfs f5,0(r3)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// add r3,r18,r3
	ctx.r3.u64 = ctx.r18.u64 + ctx.r3.u64;
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// add r4,r18,r4
	ctx.r4.u64 = ctx.r18.u64 + ctx.r4.u64;
	// stfs f0,0(r23)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// stfs f3,0(r19)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// stfs f13,0(r20)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// stfs f6,0(r21)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// lwz r10,3532(r17)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r17.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d68b94
	if (!ctx.cr0.eq) goto loc_82D68B94;
loc_82D69418:
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28f2c
	ctx.lr = 0x82D69420;
	__restfpr_14(ctx, base);
	// b 0x82e28e8c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D69428"))) PPC_WEAK_FUNC(sub_82D69428);
PPC_FUNC_IMPL(__imp__sub_82D69428) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1208
	ctx.r5.s64 = ctx.r11.s64 + 1208;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,-29872
	ctx.r4.s64 = ctx.r11.s64 + -29872;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D69440"))) PPC_WEAK_FUNC(sub_82D69440);
PPC_FUNC_IMPL(__imp__sub_82D69440) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D69448;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ef4
	ctx.lr = 0x82D69450;
	__savefpr_19(ctx, base);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d696f4
	if (!ctx.cr6.lt) goto loc_82D696F4;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f6,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f6.f64 = double(temp.f32);
loc_82D69474:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mulli r8,r6,28
	ctx.r8.s64 = ctx.r6.s64 * 28;
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f10,f0
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f10,f13
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f3,f9,f13
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f9,f0
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f5,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f31,f12,f13
	ctx.f31.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f4,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// mulli r5,r6,12
	ctx.r5.s64 = ctx.r6.s64 * 12;
	// lfsx f30,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f26,f8,f3
	ctx.f26.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// lfsx f29,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f25,f2,f7
	ctx.f25.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// add r31,r8,r3
	ctx.r31.u64 = ctx.r8.u64 + ctx.r3.u64;
	// fadds f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// add r29,r5,r3
	ctx.r29.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fsubs f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// add r30,r8,r4
	ctx.r30.u64 = ctx.r8.u64 + ctx.r4.u64;
	// fmadds f1,f11,f13,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f1.f64));
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmsubs f31,f11,f0,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f31.f64));
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r27,r6,20
	ctx.r27.s64 = ctx.r6.s64 * 20;
	// lfs f28,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f3,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f28,f12
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f24,f30,f26
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// lfs f27,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f2,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f28,f28,f11
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmuls f22,f3,f10
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f21,f3,f9
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// rlwinm r28,r6,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r8,r6,24
	ctx.r8.s64 = ctx.r6.s64 * 24;
	// fmadds f3,f29,f25,f24
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f25.f64 + ctx.f24.f64));
	// fmsubs f30,f29,f26,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f26.f64 - ctx.f30.f64));
	// fmsubs f28,f27,f12,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 - ctx.f28.f64));
	// fmadds f29,f27,f11,f23
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f23.f64));
	// fmadds f9,f2,f9,f22
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f22.f64));
	// add r25,r27,r3
	ctx.r25.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fmuls f26,f12,f7
	ctx.f26.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// add r26,r28,r3
	ctx.r26.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fmuls f27,f12,f8
	ctx.f27.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// add r27,r27,r4
	ctx.r27.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fmsubs f12,f2,f10,f21
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 - ctx.f21.f64));
	// add r28,r28,r4
	ctx.r28.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fadds f2,f3,f5
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfs f23,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// lfs f25,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f3,f4,f30
	ctx.f3.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// lfs f22,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// lfs f24,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fadds f30,f9,f29
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// fsubs f9,f29,f9
	ctx.f9.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// fmsubs f10,f11,f8,f26
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f26.f64));
	// lfsx f26,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f29,f12,f28
	ctx.f29.f64 = double(float(ctx.f12.f64 + ctx.f28.f64));
	// fsubs f12,f28,f12
	ctx.f12.f64 = double(float(ctx.f28.f64 - ctx.f12.f64));
	// lfsx f28,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f21,f28,f8
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmuls f20,f28,f7
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// lfsx f28,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f11,f11,f7,f27
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfsx f27,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f7,f28,f7,f21
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f7.f64 + ctx.f21.f64));
	// fmsubs f8,f28,f8,f20
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f8.f64 - ctx.f20.f64));
	// fmuls f28,f27,f1
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f21,f25,f0
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f20,f22,f10
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// fmuls f19,f23,f10
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fmadds f10,f26,f31,f28
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f31.f64 + ctx.f28.f64));
	// fmadds f31,f23,f11,f20
	ctx.f31.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f20.f64));
	// fmadds f13,f24,f13,f21
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f21.f64));
	// fmsubs f1,f26,f1,f27
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 - ctx.f27.f64));
	// fmsubs f0,f24,f0,f25
	ctx.f0.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fmsubs f11,f22,f11,f19
	ctx.f11.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f19.f64));
	// fadds f28,f10,f7
	ctx.f28.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fsubs f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fadds f7,f31,f13
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f13.f64));
	// fadds f27,f1,f8
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// fsubs f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// fsubs f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// fadds f1,f11,f0
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fsubs f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// fadds f11,f28,f2
	ctx.f11.f64 = double(float(ctx.f28.f64 + ctx.f2.f64));
	// fsubs f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// fadds f28,f7,f30
	ctx.f28.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// fadds f31,f27,f4
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// fsubs f7,f30,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// fsubs f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// fadds f30,f1,f29
	ctx.f30.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// fsubs f1,f1,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// fsubs f29,f11,f28
	ctx.f29.f64 = double(float(ctx.f11.f64 - ctx.f28.f64));
	// stfsx f29,r10,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f11,f28,f11
	ctx.f11.f64 = double(float(ctx.f28.f64 + ctx.f11.f64));
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f11,f4,f7
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fsubs f4,f4,f7
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f7.f64));
	// fadds f7,f31,f30
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f30.f64));
	// stfs f7,0(r4)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f7,f31,f30
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f2,f1
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfsx f7,r8,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f1,f2
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfsx f7,r9,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fadds f7,f12,f9
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// stfsx f4,r8,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fsubs f13,f9,f12
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fsubs f12,f5,f8
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// fadds f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fsubs f9,f3,f10
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fadds f10,f10,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// fsubs f5,f11,f7
	ctx.f5.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fadds f7,f13,f0
	ctx.f7.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// fsubs f4,f13,f0
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// fmuls f0,f5,f6
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f13,f11,f6
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmuls f11,f7,f6
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmuls f7,f4,f6
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// fsubs f5,f12,f0
	ctx.f5.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// stfs f5,0(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fsubs f5,f9,f13
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// stfs f5,0(r27)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f0,f13,f9
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// stfs f0,0(r28)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fsubs f0,f8,f11
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// stfs f0,0(r25)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f0,f10,f7
	ctx.f0.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fadds f0,f11,f8
	ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// stfs f0,0(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fadds f0,f7,f10
	ctx.f0.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r10,3532(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d69474
	if (!ctx.cr0.eq) goto loc_82D69474;
loc_82D696F4:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f40
	ctx.lr = 0x82D696FC;
	__restfpr_19(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D69700"))) PPC_WEAK_FUNC(sub_82D69700);
PPC_FUNC_IMPL(__imp__sub_82D69700) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1288
	ctx.r5.s64 = ctx.r11.s64 + 1288;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,-27584
	ctx.r4.s64 = ctx.r11.s64 + -27584;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D69718"))) PPC_WEAK_FUNC(sub_82D69718);
PPC_FUNC_IMPL(__imp__sub_82D69718) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D69720;
	__savegprlr_29(ctx, base);
	// stfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f29.u64);
	// stfd f30,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f31.u64);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82d6984c
	if (!ctx.cr6.lt) goto loc_82D6984C;
	// rlwinm r30,r9,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
loc_82D69748:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// fmuls f8,f12,f0
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f3,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r31,r7,r3
	ctx.r31.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r5,r9,r3
	ctx.r5.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmadds f8,f11,f13,f8
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f8.f64));
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// fmsubs f7,f11,f0,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f7.f64));
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f29,f2,f12
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f30,f4,f0
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f1,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f31,f6,f8
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f6,f6,f7
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmadds f11,f1,f11,f29
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f29.f64));
	// fmadds f13,f3,f13,f30
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f30.f64));
	// fmsubs f12,f1,f12,f2
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 - ctx.f2.f64));
	// fmsubs f0,f3,f0,f4
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f4.f64));
	// fmadds f7,f5,f7,f31
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f31.f64));
	// fmsubs f8,f5,f8,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 - ctx.f6.f64));
	// fadds f6,f7,f10
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fsubs f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f7,f11,f13
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fadds f11,f8,f9
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f8,f12,f0
	ctx.f8.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fsubs f12,f6,f7
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f7,f6
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fsubs f12,f9,f13
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// fadds f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// fadds f9,f11,f8
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// stfs f9,0(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// stfsx f11,r10,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f10,f0
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f0.f64));
	// stfs f11,0(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f10.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// stfs f13,0(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lwz r10,3532(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d69748
	if (!ctx.cr0.eq) goto loc_82D69748;
loc_82D6984C:
	// lfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f30,-48(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D69860"))) PPC_WEAK_FUNC(sub_82D69860);
PPC_FUNC_IMPL(__imp__sub_82D69860) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1368
	ctx.r5.s64 = ctx.r11.s64 + 1368;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,-26856
	ctx.r4.s64 = ctx.r11.s64 + -26856;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D69878"))) PPC_WEAK_FUNC(sub_82D69878);
PPC_FUNC_IMPL(__imp__sub_82D69878) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D69880;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D69888;
	__savefpr_14(ctx, base);
	// stwu r1,-928(r1)
	ea = -928 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r7,504
	ctx.r11.s64 = ctx.r7.s64 * 504;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d6d1c4
	if (!ctx.cr6.lt) goto loc_82D6D1C4;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// stw r10,628(r1)
	PPC_STORE_U32(ctx.r1.u32 + 628, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f31,-5436(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -5436);
	ctx.f31.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f1,-5440(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -5440);
	ctx.f1.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f2,-5448(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -5448);
	ctx.f2.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f3,-5444(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -5444);
	ctx.f3.f64 = double(temp.f32);
	// stw r10,384(r1)
	PPC_STORE_U32(ctx.r1.u32 + 384, ctx.r10.u32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f4,-5432(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -5432);
	ctx.f4.f64 = double(temp.f32);
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lfs f5,-5428(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -5428);
	ctx.f5.f64 = double(temp.f32);
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f6,-5420(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -5420);
	ctx.f6.f64 = double(temp.f32);
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lfs f7,-5424(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -5424);
	ctx.f7.f64 = double(temp.f32);
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// lfs f8,-8000(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8000);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f9,-8004(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8004);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8012(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -8012);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-8008(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8008);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-8016(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -8016);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,136(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D69924:
	// mulli r8,r6,192
	ctx.r8.s64 = ctx.r6.s64 * 192;
	// lfs f30,248(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r7,r6,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f29,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,376(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 376);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f16,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f25,380(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 380);
	ctx.f25.f64 = double(temp.f32);
	// rlwinm r9,r6,6,0,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f22,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// mulli r5,r6,160
	ctx.r5.s64 = ctx.r6.s64 * 160;
	// lfs f21,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f16,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f17,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r10,r6,7,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 7) & 0xFFFFFF80;
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r31,r6,224
	ctx.r31.s64 = ctx.r6.s64 * 224;
	// lfsx f16,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f18,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f28,f18
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfsx f17,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f20,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f16,f30,f20
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// lfsx f19,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f29,f20
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f20.f64));
	// fmuls f14,f26,f17
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// mulli r30,r6,96
	ctx.r30.s64 = ctx.r6.s64 * 96;
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// fmadds f29,f29,f19,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64 + ctx.f16.f64));
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmsubs f30,f30,f19,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f19.f64 - ctx.f20.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// fmadds f27,f27,f20,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 + ctx.f15.f64));
	// fmsubs f28,f28,f20,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f20.f64 - ctx.f18.f64));
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f25,f25,f20,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f20.f64 + ctx.f14.f64));
	// lfs f18,440(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 440);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f26,f26,f20,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 - ctx.f17.f64));
	// lfs f20,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,444(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 444);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f21,f21,f20,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f16.f64));
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f29,f24
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// fadds f24,f25,f27
	ctx.f24.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fsubs f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fsubs f19,f23,f30
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fadds f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f23.f64));
	// fadds f26,f24,f20
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// fsubs f20,f29,f25
	ctx.f20.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fadds f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fsubs f23,f19,f27
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// fadds f25,f30,f28
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fadds f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// lfs f19,316(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 316);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f28,312(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 312);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f16
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// fmuls f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f16,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,92(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f28,f28,f16,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f19,f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f15.f64));
	// fmuls f16,f18,f28
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// stfs f19,72(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmuls f15,f17,f28
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// lfs f28,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f28.f64 = double(temp.f32);
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fmr f28,f19
	ctx.f28.f64 = ctx.f19.f64;
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f17,f17,f28,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 + ctx.f16.f64));
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f28,f18,f28,f15
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,20(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f28,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f19
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f19,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f18,f19,f16,f14
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f19,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f19,f16,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f21,f16
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f16,92(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f19,f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f28,f28,f16,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 - ctx.f14.f64));
	// fsubs f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f18,f21
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fadds f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f16,176(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f22,f14
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// mulli r28,r6,144
	ctx.r28.s64 = ctx.r6.s64 * 144;
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,340(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f22,f16,f0
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f22,332(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmuls f22,f17,f0
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f16,280(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	ctx.f16.f64 = double(temp.f32);
	// mulli r27,r6,80
	ctx.r27.s64 = ctx.r6.s64 * 80;
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfsx f17,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f18,464(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// lfsx f18,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f16,f18
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f18.f64));
	// stfs f22,592(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// lfs f22,284(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 284);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r26,r6,208
	ctx.r26.s64 = ctx.r6.s64 * 208;
	// lfsx f17,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// lfsx f14,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r25,r6,240
	ctx.r25.s64 = ctx.r6.s64 * 240;
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fmuls f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f18,f17
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f22,f18,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f16.f64));
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f18,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f22,408(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 408);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f22,412(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 412);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f18,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f15,f18,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,412(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 412);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,408(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 408);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// fsubs f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// fsubs f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fsubs f15,f28,f18
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fsubs f15,f19,f22
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f22,236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f28,284(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmuls f22,f14,f12
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// fmuls f19,f14,f13
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f28,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,276(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmuls f18,f17,f13
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f28,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f16,f13
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// mulli r24,r6,112
	ctx.r24.s64 = ctx.r6.s64 * 112;
	// fadds f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f28,232(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// mulli r23,r6,48
	ctx.r23.s64 = ctx.r6.s64 * 48;
	// fmsubs f22,f28,f13,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f22.f64));
	// stfs f22,480(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f22,472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f12,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f19.f64));
	// stfs f28,472(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// lfs f19,476(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 476);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f28,f16,f12,f18
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f18.f64));
	// stfs f28,468(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fmadds f28,f17,f12,f14
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f28,452(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// lfsx f28,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f22,f28
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// lfs f18,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f19,f28
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// lfsx f28,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f28,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r22,r6,176
	ctx.r22.s64 = ctx.r6.s64 * 176;
	// stfs f28,20(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f28,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,48(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f28,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,32(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f28,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,68(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f28,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,56(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f28,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,128(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f17,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f19,f19,f28,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 + ctx.f15.f64));
	// stfs f19,148(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmsubs f28,f22,f28,f14
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 - ctx.f14.f64));
	// stfs f28,92(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f19,f18,f28
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// fmuls f15,f17,f28
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// lfs f28,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f14,f16,f22
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f22.f64));
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fmr f28,f22
	ctx.f28.f64 = ctx.f22.f64;
	// fmadds f22,f17,f28,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 + ctx.f19.f64));
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmsubs f28,f18,f28,f15
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,72(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f28,344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 344);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 348);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// fmuls f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 348);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f14.f64));
	// fmadds f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f15.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f16,f19,f14
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f28,f28,f17,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r21,r6,3,0,28
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// mulli r19,r6,72
	ctx.r19.s64 = ctx.r6.s64 * 72;
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// mulli r18,r6,200
	ctx.r18.s64 = ctx.r6.s64 * 200;
	// fsubs f18,f19,f28
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// fadds f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// mulli r17,r6,40
	ctx.r17.s64 = ctx.r6.s64 * 40;
	// fadds f19,f14,f16
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// fsubs f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// mulli r20,r6,136
	ctx.r20.s64 = ctx.r6.s64 * 136;
	// fmuls f17,f19,f13
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f14,228(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fadds f14,f28,f15
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// stfs f14,224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f14,f19,f12
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// fsubs f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// fmuls f15,f18,f13
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f17,f19,f12,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f17,552(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// fmsubs f19,f19,f13,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f19,608(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// fmuls f14,f16,f13
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f17,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f16,460(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfsx f16,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f16,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f16,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,128(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfsx f16,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmsubs f18,f18,f12,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f18,444(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fadds f18,f28,f22
	ctx.f18.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// lfsx f16,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// lfsx f22,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f28,352(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfsx f28,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f19,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f19.f64 = double(temp.f32);
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f16,f19,f28
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// lfsx f22,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f28,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f28.f64 = double(temp.f32);
	// stfs f18,240(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fmuls f14,f28,f22
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfsx f18,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// stfs f28,68(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f28,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmr f28,f22
	ctx.f28.f64 = ctx.f22.f64;
	// lfs f18,396(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 396);
	ctx.f18.f64 = double(temp.f32);
	// mulli r16,r6,168
	ctx.r16.s64 = ctx.r6.s64 * 168;
	// mulli r15,r6,232
	ctx.r15.s64 = ctx.r6.s64 * 232;
	// fmadds f22,f19,f28,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 + ctx.f17.f64));
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f28,f22,f28,f16
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 - ctx.f16.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// lfs f28,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f19,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64 + ctx.f15.f64));
	// stfs f28,24(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f28,392(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 392);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,104
	ctx.r14.s64 = ctx.r6.s64 * 104;
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,396(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 396);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f28,f16,f15
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f28,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f28,f17,f19
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f28,20(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f28,328(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 328);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,92(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f28,456(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 456);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,136(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f28,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f28,f15
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f15.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fsubs f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f22,304(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fadds f22,f16,f18
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f22,324(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f22,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,600(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f14.f64));
	// stfs f22,132(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfsx f22,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f28,f28,f19,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64 - ctx.f17.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f28,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f19,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f28,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,32(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,20(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f28,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,48(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f28,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f22
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f28,332(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 332);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f22,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f19
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f22,460(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 460);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f22,f19
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f22,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f17.f64));
	// stfs f28,72(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f28,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f22,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfs f28,56(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f28,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f28,f22
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f28,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,460(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 460);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f22,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f14.f64));
	// fmsubs f22,f15,f22,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f22.f64 - ctx.f19.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f15,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64 + ctx.f17.f64));
	// lfs f17,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f17,f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,136(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fsubs f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// fadds f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// fsubs f19,f22,f17
	ctx.f19.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f19,92(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,44(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f19,f28,f15
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// stfs f19,88(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f17,132(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f22,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f19,f22,f19
	ctx.f19.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f22,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,120(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,120
	ctx.r14.s64 = ctx.r6.s64 * 120;
	// lfs f22,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,192(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f22,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// stfs f19,408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// stw r14,516(r1)
	PPC_STORE_U32(ctx.r1.u32 + 516, ctx.r14.u32);
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,24
	ctx.r14.s64 = ctx.r6.s64 * 24;
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f17,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f17.f64 = double(temp.f32);
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r14.u32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f16,f18
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,248
	ctx.r14.s64 = ctx.r6.s64 * 248;
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// lfs f15,364(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 364);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f17,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,624(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f22,f16
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f19,f16
	ctx.f16.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f16,356(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f19,f28,f18
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f19,520(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f28,544(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f28,f14,f0
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f28,416(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f28,f22,f0
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f28,512(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,516(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,56
	ctx.r14.s64 = ctx.r6.s64 * 56;
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,184
	ctx.r14.s64 = ctx.r6.s64 * 184;
	// stfs f18,128(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,148(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f18,488(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f18,f28
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f18,492(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f28,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,56(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f22,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f16.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,152
	ctx.r14.s64 = ctx.r6.s64 * 152;
	// fmsubs f28,f28,f22,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 - ctx.f18.f64));
	// stfs f28,172(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f22
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f17,f22
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f22.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// stw r14,568(r1)
	PPC_STORE_U32(ctx.r1.u32 + 568, ctx.r14.u32);
	// lfs f28,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,92(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fmadds f28,f28,f22,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f14.f64));
	// fmsubs f22,f18,f22,f19
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,360(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 360);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f19
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f18,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmadds f22,f17,f18,f16
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 + ctx.f16.f64));
	// lfs f19,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,360(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 360);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f19,f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f18,f15,f16,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f17,f16,f14
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,132(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f16,f18,f22
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fadds f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// lfs f18,300(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 300);
	ctx.f18.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,296(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f14,424(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 424);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,208(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f16,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// lfs f16,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f16,f22,f15
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f16,424(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f22,508(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,568(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// mulli r14,r6,216
	ctx.r14.s64 = ctx.r6.s64 * 216;
	// fmuls f15,f18,f17
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,88
	ctx.r14.s64 = ctx.r6.s64 * 88;
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f22,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f14.f64));
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f16,f22,f14
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,108(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f17
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// lfs f22,428(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f18,f18,f22,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 + ctx.f16.f64));
	// stfs f18,96(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f18,f22,f15
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f22,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f22,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,428(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f18,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f14.f64));
	// fmsubs f18,f15,f18,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,136(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f17,f16,f18
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,220(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,328(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fsubs f17,f22,f18
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,252(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,124
	ctx.r14.s64 = ctx.r6.s64 * 124;
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,296(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f16,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// stfs f17,292(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// stw r14,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r14.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,252
	ctx.r14.s64 = ctx.r6.s64 * 252;
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f17,152(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f17,496(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f28,48(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f28,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// stfs f28,56(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f22,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f28,f19
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// fadds f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f14,f16,f28
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// fadds f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f16,348(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f22,264(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f22,f18,f0
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f22,576(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// fmuls f22,f19,f0
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f22,364(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// stfs f28,380(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fmuls f22,f14,f0
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f22,432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f19,f28,f22
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f19,528(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,484(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,180(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,60
	ctx.r14.s64 = ctx.r6.s64 * 60;
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,188
	ctx.r14.s64 = ctx.r6.s64 * 188;
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,500(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 500);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f17,f28
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f28,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,28
	ctx.r14.s64 = ctx.r6.s64 * 28;
	// fmuls f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f28,f19,f22,f16
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f16.f64));
	// fmsubs f22,f17,f22,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 - ctx.f18.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f18,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f14.f64));
	// stfs f22,132(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f15,f19
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// fmuls f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f19,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,368(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 368);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f18,372(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 372);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fmr f19,f18
	ctx.f19.f64 = ctx.f18.f64;
	// lfs f18,372(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 372);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f17.f64));
	// fmsubs f17,f15,f19,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f19.f64 - ctx.f16.f64));
	// lfs f19,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f16,f18,f19,f14
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 + ctx.f14.f64));
	// lfs f18,368(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 368);
	ctx.f18.f64 = double(temp.f32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// stfs f17,172(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f18,f19,f14
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfs f19,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// stfs f19,136(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f15,212(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f18,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,304(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,432(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,108(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f16,156(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,156
	ctx.r14.s64 = ctx.r6.s64 * 156;
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,220
	ctx.r14.s64 = ctx.r6.s64 * 220;
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,92
	ctx.r14.s64 = ctx.r6.s64 * 92;
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f15,f18,f19
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// stfs f16,128(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f19
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f19.f64));
	// lfs f19,308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 308);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f18,f18,f19,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 + ctx.f16.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f18,f19,f15
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,148(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f18
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f19,436(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 436);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f18
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 308);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f14.f64));
	// stfs f19,96(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f17.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f19,f18
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f19,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,436(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 436);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f16.f64));
	// lfs f16,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f18,f17,f18,f15
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f14,f17,f19
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// fadds f17,f16,f18
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f14,160(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,200(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,168(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// mulli r14,r6,132
	ctx.r14.s64 = ctx.r6.s64 * 132;
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stw r14,496(r1)
	PPC_STORE_U32(ctx.r1.u32 + 496, ctx.r14.u32);
	// rlwinm r14,r6,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f16,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,56(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,140(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f17,f19,f18
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f28,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f18,560(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f28,620(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// lfs f28,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f18,f15,f28
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fadds f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// stfs f28,196(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fmuls f28,f14,f0
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f28,488(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f28,f22,f0
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f28,268(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f28,f17,f0
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f28,396(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// fmuls f28,f19,f0
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f28,612(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f28.f64 = double(temp.f32);
	// fadds f19,f22,f28
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f19,388(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,344(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,496(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,68
	ctx.r14.s64 = ctx.r6.s64 * 68;
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f16,f28
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,196
	ctx.r14.s64 = ctx.r6.s64 * 196;
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,128(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,164
	ctx.r14.s64 = ctx.r6.s64 * 164;
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// lfs f28,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// stfs f28,48(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f28,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f28.f64 = double(temp.f32);
	// stw r14,400(r1)
	PPC_STORE_U32(ctx.r1.u32 + 400, ctx.r14.u32);
	// fmuls f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// mulli r14,r6,36
	ctx.r14.s64 = ctx.r6.s64 * 36;
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f28,f19,f22,f15
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f15.f64));
	// lfs f19,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f16,f22,f17
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 - ctx.f17.f64));
	// fmuls f16,f19,f18
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f15.f64));
	// fmadds f19,f19,f17,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f14.f64));
	// stfs f18,132(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f15.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f16.f64));
	// stfs f18,72(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f19,f28
	ctx.f18.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// lfs f17,384(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f17,324(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 324);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f17,448(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 448);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f17,452(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 452);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f17,388(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 388);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,108(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f16,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f16,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f15,f17,f16,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f17,384(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmsubs f16,f17,f16,f14
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,400(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// mulli r14,r6,228
	ctx.r14.s64 = ctx.r6.s64 * 228;
	// stfs f18,172(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,60(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,100
	ctx.r14.s64 = ctx.r6.s64 * 100;
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,52(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f18,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f18,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f18,320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 320);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f15,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 + ctx.f17.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 - ctx.f16.f64));
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f18,f17
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f15.f64));
	// lfs f18,320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 320);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f14.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f18,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f18,f17
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f16,f14,f18,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f18.f64 + ctx.f16.f64));
	// stfs f16,60(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f18,f16,f18,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f15,f16,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 + ctx.f17.f64));
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f15,f16,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// fadds f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,148
	ctx.r14.s64 = ctx.r6.s64 * 148;
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// stfs f28,308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f28,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f28.f64 = double(temp.f32);
	// stw r14,532(r1)
	PPC_STORE_U32(ctx.r1.u32 + 532, ctx.r14.u32);
	// mulli r14,r6,52
	ctx.r14.s64 = ctx.r6.s64 * 52;
	// fadds f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f16,256(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// stw r14,316(r1)
	PPC_STORE_U32(ctx.r1.u32 + 316, ctx.r14.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,180
	ctx.r14.s64 = ctx.r6.s64 * 180;
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// stw r14,320(r1)
	PPC_STORE_U32(ctx.r1.u32 + 320, ctx.r14.u32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,288(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f18,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,212(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,128(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,148(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f19,f28,f22
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fadds f15,f22,f28
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f28,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f14,f16,f28
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// fadds f16,f28,f16
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// lfs f28,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f22,f28,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,144(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f28,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f22,f17,f28
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// stfs f28,132(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f28.f64 = double(temp.f32);
	// fadds f17,f22,f28
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,588(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// fmuls f28,f19,f0
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f28,448(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// fmuls f28,f15,f0
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f28,556(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 556, temp.u32);
	// fmuls f28,f14,f0
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f28,440(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fmuls f28,f16,f0
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f28,580(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,20
	ctx.r14.s64 = ctx.r6.s64 * 20;
	// lfs f22,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f19,f28,f22
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f19,100(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,112(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f19,f28,f22
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f19,616(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,548(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,532(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// stfs f17,584(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// fmuls f15,f18,f28
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,316(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,84
	ctx.r14.s64 = ctx.r6.s64 * 84;
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f16,f28
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfs f28,288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 288);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,292(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 292);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// stw r14,540(r1)
	PPC_STORE_U32(ctx.r1.u32 + 540, ctx.r14.u32);
	// lwz r14,320(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f28,f19,f22,f15
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f15.f64));
	// fmsubs f22,f18,f22,f16
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f16.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f19,292(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f14.f64));
	// fmuls f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f18,288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 288);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f19,f28
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// stfs f28,96(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f19,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f19,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fadds f28,f18,f22
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f28,148(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f28,f22,f18
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f28,352(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 352);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 356);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,540(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,212
	ctx.r14.s64 = ctx.r6.s64 * 212;
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,244
	ctx.r14.s64 = ctx.r6.s64 * 244;
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,116
	ctx.r14.s64 = ctx.r6.s64 * 116;
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmuls f14,f28,f18
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// fmuls f18,f22,f18
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// fmadds f22,f22,f15,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64 + ctx.f14.f64));
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fmsubs f28,f28,f15,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f15.f64 - ctx.f18.f64));
	// stfs f28,24(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f22,f28
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// fmuls f15,f19,f28
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// lfs f28,416(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 416);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f28,f22
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f28,420(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 420);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f19,f22,f18
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f18.f64));
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f19,f22,f15
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f22,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f22,f19
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,420(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 420);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f14.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,484(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// lfs f22,416(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 416);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f22,f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 - ctx.f14.f64));
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f22,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f22,f19
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,484(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f22,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f18.f64));
	// stfs f19,32(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f18,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f19,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f19,f22,f15
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 - ctx.f15.f64));
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f14.f64));
	// fadds f18,f15,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,172(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// mulli r14,r6,12
	ctx.r14.s64 = ctx.r6.s64 * 12;
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,28(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,36(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,52(r1)
	PPC_STORE_U32(ctx.r1.u32 + 52, ctx.r14.u32);
	// mulli r14,r6,140
	ctx.r14.s64 = ctx.r6.s64 * 140;
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f15,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f19
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stw r14,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r14.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,48(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,52(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,64(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// lfs f19,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,36(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f19,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r14.u32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// lwz r14,52(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	// stfs f14,308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,32(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// stw r14,68(r1)
	PPC_STORE_U32(ctx.r1.u32 + 68, ctx.r14.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,108(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fsubs f19,f22,f28
	ctx.f19.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// stfs f28,212(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fsubs f28,f15,f16
	ctx.f28.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f28,368(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fadds f28,f16,f15
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f28,52(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// stw r14,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r14.u32);
	// fadds f22,f18,f28
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// lwz r14,108(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// fsubs f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f28,24(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stw r14,56(r1)
	PPC_STORE_U32(ctx.r1.u32 + 56, ctx.r14.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f28,f13
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f18,f28,f12
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// lfs f28,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f13
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f13
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fadds f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfs f14,436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// stfs f28,492(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// lfs f28,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f22,f28,f12,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f22.f64));
	// stfs f22,536(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// fmsubs f28,f28,f13,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f28,312(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f28,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// fadds f22,f17,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fmadds f28,f28,f12,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f16.f64));
	// lfs f16,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f19,f17
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f17,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f28,572(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f28,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f28.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f28,f28,f12,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f15.f64));
	// fmuls f15,f17,f13
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,280(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// stfs f28,604(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// fmuls f17,f22,f12
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f16,f22,f13
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f14,f22,f28
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// lfs f22,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// fmuls f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f22,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// lfs f19,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f19.f64 = double(temp.f32);
	// fmr f28,f19
	ctx.f28.f64 = ctx.f19.f64;
	// fmsubs f19,f28,f13,f17
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f17.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f28,f28,f12,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f28,336(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f17,392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// stfs f28,476(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f12,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f18.f64));
	// stfs f28,564(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f12,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f28,596(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// lfs f18,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f28,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 + ctx.f14.f64));
	// lfs f15,272(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmsubs f17,f17,f28,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 - ctx.f16.f64));
	// stw r14,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r14.u32);
	// mulli r14,r6,172
	ctx.r14.s64 = ctx.r6.s64 * 172;
	// lfs f28,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,52(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f28,336(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 336);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f28,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// stw r14,36(r1)
	PPC_STORE_U32(ctx.r1.u32 + 36, ctx.r14.u32);
	// mulli r14,r6,76
	ctx.r14.s64 = ctx.r6.s64 * 76;
	// stfs f28,96(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f16,276(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	ctx.f16.f64 = double(temp.f32);
	// stw r14,60(r1)
	PPC_STORE_U32(ctx.r1.u32 + 60, ctx.r14.u32);
	// mulli r14,r6,204
	ctx.r14.s64 = ctx.r6.s64 * 204;
	// stw r14,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r14.u32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,420(r1)
	PPC_STORE_U32(ctx.r1.u32 + 420, ctx.r14.u32);
	// lwz r14,148(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fmuls f14,f16,f28
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// stw r14,428(r1)
	PPC_STORE_U32(ctx.r1.u32 + 428, ctx.r14.u32);
	// lwz r14,36(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,412(r1)
	PPC_STORE_U32(ctx.r1.u32 + 412, ctx.r14.u32);
	// lwz r14,36(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,368(r1)
	PPC_STORE_U32(ctx.r1.u32 + 368, ctx.r14.u32);
	// lwz r14,56(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,60(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	// fmadds f16,f16,f28,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64 + ctx.f15.f64));
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmsubs f28,f15,f28,f14
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f28.f64 - ctx.f14.f64));
	// stw r14,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r14.u32);
	// lwz r14,60(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fadds f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f14,212(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fadds f14,f28,f17
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f28,136(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f28,f18,f16
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// stw r14,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r14.u32);
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,24(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,48(r1)
	PPC_STORE_U32(ctx.r1.u32 + 48, ctx.r14.u32);
	// lwz r14,24(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r14.u32);
	// lwz r14,420(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// lfs f15,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,412(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	// fmuls f16,f28,f15
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f15.f64));
	// lfs f28,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f15
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f15.f64));
	// lfs f18,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,428(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// fmuls f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// lfs f17,340(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 340);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// lfs f18,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f28,f28,f18,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f16.f64));
	// stfs f28,28(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f18,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 - ctx.f15.f64));
	// stfs f28,60(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f18,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,32(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,368(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	// fmuls f16,f18,f28
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f18,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f18,f28
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f18,340(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 340);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,48(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// fmadds f18,f18,f28,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 + ctx.f14.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f28,f18,f28,f17
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 - ctx.f17.f64));
	// stfs f28,24(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,400(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 400);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fmuls f14,f18,f28
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f18,404(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 404);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// stfs f28,172(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f28,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// lfs f17,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fmadds f28,f28,f18,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f16.f64));
	// fmsubs f18,f17,f18,f15
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f17,404(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 404);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,400(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 400);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,236
	ctx.r14.s64 = ctx.r6.s64 * 236;
	// fmadds f17,f17,f16,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f15,f16,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,184(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r14.u32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,108
	ctx.r14.s64 = ctx.r6.s64 * 108;
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,376(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fadds f15,f17,f28
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// fsubs f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// stfs f28,52(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// stw r14,36(r1)
	PPC_STORE_U32(ctx.r1.u32 + 36, ctx.r14.u32);
	// fadds f28,f16,f18
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,464(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f17,468(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 468);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f16,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stw r14,308(r1)
	PPC_STORE_U32(ctx.r1.u32 + 308, ctx.r14.u32);
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r14.u32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lwz r14,36(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fsubs f14,f28,f16
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// stw r14,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r14.u32);
	// stfs f14,524(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lwz r14,36(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// fadds f28,f16,f28
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f28.f64));
	// stfs f28,500(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fmuls f14,f15,f12
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stw r14,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r14.u32);
	// lwz r14,308(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// fmsubs f14,f18,f13,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f14,404(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fmadds f18,f18,f12,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f18,504(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,172(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lfs f18,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f17,f28
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// fmuls f15,f18,f28
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f28,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,212(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// stfs f16,300(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// stfs f28,372(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f28,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// lwz r14,216(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f18.f64 = double(temp.f32);
	// stfs f28,300(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmadds f28,f17,f18,f15
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f17,f18,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f17,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f17,f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f15,f16,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 - ctx.f14.f64));
	// fsubs f15,f28,f17
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// fadds f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// fsubs f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f16,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// stfs f14,124(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fadds f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f17,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f28,f17
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// stfs f28,300(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f28,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fsubs f17,f18,f28
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f28,184(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f16,f13
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f28,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f13
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// stfs f28,116(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmr f28,f17
	ctx.f28.f64 = ctx.f17.f64;
	// fadds f17,f15,f28
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmr f17,f15
	ctx.f17.f64 = ctx.f15.f64;
	// fsubs f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f28,108(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f28,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f28.f64 = double(temp.f32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// stfs f17,372(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// stfs f28,376(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f28,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f28.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f17,96(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f17,f12,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f18.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f17,300(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f12,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f14.f64));
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// stfs f17,216(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// stfs f15,124(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,204(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,220(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f16,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f16.f64 = double(temp.f32);
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmsubs f17,f17,f12,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f16.f64));
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,208(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// stfs f15,184(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfs f28,188(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfs f28,304(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,328(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f17,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,140(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,360(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f16,88(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,324(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,160(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f17,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f15,f17
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f16,116(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f17,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f16,208(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,188(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f22,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f28,f13
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f16,f22,f13
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmsubs f22,f22,f12,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f17.f64));
	// stfs f22,304(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fmadds f28,f28,f12,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f28,220(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f28,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f28.f64 = double(temp.f32);
	// fadds f17,f28,f14
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f28.f64 = double(temp.f32);
	// fadds f16,f22,f28
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// fsubs f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// lfs f28,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f22,124(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,184(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f28,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f28.f64 = double(temp.f32);
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f22,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f22.f64 = double(temp.f32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// stfs f28,60(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f22,140(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,88(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f28.f64 = double(temp.f32);
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,256(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f22,160(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f16,r10,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,0(r3)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f17,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// fadds f15,f17,f22
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f22,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f17,0(r4)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f22,r10,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f16,r8,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f15,r9,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f16,r9,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f17,r8,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f16,f28,f22
	ctx.f16.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fadds f17,f22,f28
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f16,r5,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f16,f28,f22
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfsx f17,r7,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// stfsx f16,r7,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f28,r5,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f28,f16,f17
	ctx.f28.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfsx f22,r31,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfs f28,208(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f22,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,140(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f28.f64 = double(temp.f32);
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// lfs f16,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f17.f64 = double(temp.f32);
	// stfs f28,104(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f22,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// stfs f26,260(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f16,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f16.f64 = double(temp.f32);
	// lfs f26,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f26.f64 = double(temp.f32);
	// stfs f22,120(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f22.f64 = double(temp.f32);
	// stfs f26,224(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f26,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f26.f64 = double(temp.f32);
	// lfs f16,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f16.f64 = double(temp.f32);
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// stfs f26,228(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f26,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f26,236(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f25,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfs f25,272(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f25,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfs f25,248(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f26,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f28,f12
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// lfs f16,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfs f25,280(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfs f25,288(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f16,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfs f25,164(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f25,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f22,f12
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// stfs f26,88(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f26,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stfsx f26,r30,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f25,f28,f13
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// lfs f28,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfs f28,116(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmuls f28,f26,f0
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// stfs f28,124(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f28,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f26,f28,f12,f25
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f25.f64));
	// stfs f26,104(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmsubs f28,f28,f13,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f28,284(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmuls f28,f17,f0
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f17,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// lfs f25,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f26,160(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f26,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f25,f26,f13,f16
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f25,252(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f25,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f25.f64 = double(temp.f32);
	// stfs f28,140(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmadds f28,f26,f12,f22
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f22.f64));
	// stfs f28,292(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f28,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f28,f13
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f28,f13
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// lfs f28,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// fmuls f16,f28,f13
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f13
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fadds f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfsx f14,r30,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// stfsx f28,r31,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// stfs f28,164(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f28,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f12,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f26.f64));
	// stfs f28,224(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f28,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f12,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f22.f64));
	// stfs f28,248(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f26,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// stfs f28,228(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f28,f25,f0
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f28,260(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f28,f17,f0
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f28,272(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f28,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f12,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f28,236(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f28,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f12,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f25.f64 = double(temp.f32);
	// fadds f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f15.f64));
	// stfs f28,288(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// fadds f28,f16,f17
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f14,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// fsubs f14,f28,f26
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfsx f14,r22,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfsx f28,r23,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f25,f22
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfsx f28,r23,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f25,f22
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfsx f28,r22,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// lfs f28,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f28,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f22,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f17,f16
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f28,280(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f28,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,104(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f28,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f12
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// stfs f26,284(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmuls f28,f28,f13
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f26,f25,f0
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f26,292(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f26,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f12
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f25,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f14,f25,f26
	ctx.f14.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f25,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,120(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f25,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// stfs f28,84(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f26,80(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f25,252(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f15,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f25,140(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f25,88(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f25,124(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f25,160(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f25,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,164(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,116(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f15,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,184(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f25,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f25,f15
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// lfs f25,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f26,f24,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// lfs f15,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f25,f22,f0
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f25,188(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f25,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f25.f64 = double(temp.f32);
	// lfs f22,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f25,f25,f13,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 - ctx.f17.f64));
	// fmuls f17,f14,f0
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmadds f22,f22,f13,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f16.f64));
	// lfs f16,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f14.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r25,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r24,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,296(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,244(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f14,r24,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f15,r25,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r28,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r29,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f14,r29,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f15,r28,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r26,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r27,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f28,f15
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// stfsx f14,r27,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f28,r26,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f26,f15
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// fadds f26,f15,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// lfs f14,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f25,f22
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f25,88(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f25,f30,f21
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f22,f25,f17
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// stfs f22,120(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// stfs f25,104(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f25,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f25.f64 = double(temp.f32);
	// fadds f22,f25,f16
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfs f22,348(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfs f25,356(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f25,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f25,f10
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f25,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f25,f8
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// lfs f25,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f25,f11,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f22.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f22,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// lfs f16,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// fmuls f14,f25,f10
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f25,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f9
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// stfs f25,84(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f25,f22,f0
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f22,f16,f0
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f22,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f9,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 + ctx.f17.f64));
	// lfs f17,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f11,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f14.f64));
	// stfs f17,296(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fadds f17,f15,f28
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f8,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f8.f64 - ctx.f14.f64));
	// stfs f15,244(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f15,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,84(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f26
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f26.f64));
	// stfs f16,104(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// mulli r9,r6,184
	ctx.r9.s64 = ctx.r6.s64 * 184;
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// mulli r10,r6,56
	ctx.r10.s64 = ctx.r6.s64 * 56;
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// stfs f26,88(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f26,f15,f16
	ctx.f26.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// stfs f26,116(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f26,f15,f25
	ctx.f26.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stfs f26,200(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// stfs f25,76(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f25,f16,f14
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fsubs f26,f16,f14
	ctx.f26.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// fmuls f14,f25,f8
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fmuls f25,f25,f9
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// stfs f25,100(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f15,f26,f10
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f16,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f10
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmadds f26,f26,f11,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 + ctx.f16.f64));
	// lfs f16,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f25,f16,f11,f15
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f15.f64));
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f15,f9,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f9.f64 + ctx.f14.f64));
	// lfs f14,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f8,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f26,f14
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfs f14,200(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f25,f14
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// lfs f14,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f14,100(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// fadds f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfsx f15,r9,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfsx f22,r10,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f17,f22
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f22,r9,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,248
	ctx.r10.s64 = ctx.r6.s64 * 248;
	// lwz r9,516(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// fsubs f22,f28,f25
	ctx.f22.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// stfsx f22,r10,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lwz r9,568(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfsx f25,r9,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f22,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// lfs f17,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfsx f28,r10,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f28.f64 = double(temp.f32);
	// fadds f26,f28,f14
	ctx.f26.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfsx f28,r9,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,216
	ctx.r10.s64 = ctx.r6.s64 * 216;
	// lfs f26,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f26.f64 = double(temp.f32);
	// mulli r9,r6,88
	ctx.r9.s64 = ctx.r6.s64 * 88;
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f14,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f28.f64 = double(temp.f32);
	// fadds f26,f28,f16
	ctx.f26.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// stfsx f26,r9,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// lfs f26,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f25,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// lfs f22,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfs f16,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,176(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f16,f17,f12,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f16.f64));
	// stfs f16,232(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f16,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fmuls f14,f17,f13
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmuls f21,f16,f0
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f14.f64));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f12,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// stfs f14,192(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfs f14,152(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,264(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// stfs f14,168(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f14,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fadds f17,f30,f21
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// stfs f17,232(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// stfs f30,276(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fadds f30,f15,f16
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f30,176(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f30,f15,f16
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f30,240(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f30,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f28,f11
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmuls f21,f30,f8
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// fmuls f15,f30,f9
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// lfs f30,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f26,f11
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// fmadds f26,f26,f10,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f16.f64));
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f30,f30,f9,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 - ctx.f21.f64));
	// stfs f30,144(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f21,f25,f11
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// lfs f30,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// stfs f25,40(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmadds f30,f30,f8,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 + ctx.f17.f64));
	// stfs f30,196(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fmadds f25,f16,f8,f15
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f8.f64 + ctx.f15.f64));
	// lfs f16,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f28,f28,f10,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f14.f64));
	// lfs f14,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f21,f22,f10,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f21.f64));
	// lfs f30,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f30.f64 = double(temp.f32);
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// fmsubs f17,f16,f9,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f9.f64 - ctx.f17.f64));
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f22,f11,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f16.f64));
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f15,f30,f16
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// lfs f16,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f15,r16,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,192(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f14,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fadds f15,f17,f25
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f17,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r6,104
	ctx.r10.s64 = ctx.r6.s64 * 104;
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f17,f22,f28
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f17,88(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f17,f21,f26
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,188(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// stfs f26,116(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f26,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfs f28,184(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f26,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfs f28,112(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f26,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfs f28,144(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f26,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfs f28,168(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f28,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f16,f10
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfsx f30,r17,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// lfs f30,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// fmuls f28,f30,f10
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// fmuls f14,f30,f11
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f30,f30,f10
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmr f30,f22
	ctx.f30.f64 = ctx.f22.f64;
	// lfs f22,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// stfsx f22,r17,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// stfsx f30,r16,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f15,f25
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stfsx f30,r15,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f30,f16,f11,f28
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f28.f64));
	// fadds f28,f25,f15
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfsx f28,r10,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f11,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 + ctx.f26.f64));
	// lfs f25,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f25.f64 = double(temp.f32);
	// lfs f22,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// fadds f26,f21,f22
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f26,f25,f10,f14
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f14.f64));
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfsx f22,r15,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f25,f25,f11,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f14.f64));
	// fsubs f16,f22,f21
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfsx f16,r20,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f22,r21,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// fadds f21,f17,f22
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfsx f21,r21,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f22,r20,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f24,f22
	ctx.f21.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfsx f21,r18,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfsx f24,r19,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f24.f64 = double(temp.f32);
	// fadds f21,f22,f24
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfsx f21,r19,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfsx f24,r18,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f22,f20,f24
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// lfs f21,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f21.f64 = double(temp.f32);
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f22,f21
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f27,f21
	ctx.f17.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f21,f17,f16
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f19,f16
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// fsubs f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fsubs f14,f30,f26
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// fadds f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// stfs f30,144(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f30,f25,f28
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// lfs f26,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f26.f64 = double(temp.f32);
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// lfs f25,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f26,40(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f25,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f26,76(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f25,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f26,100(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f26,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f18.f64));
	// stfs f26,84(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f25,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f26,80(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f25,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f25,f14,f24
	ctx.f25.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// stfs f25,112(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f25,f30,f17
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// stfs f25,104(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// stfs f30,88(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f30,f28,f22
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// stfs f30,124(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f25,f24,f14
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// stfs f25,120(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f30,f22,f28
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// stfs f30,116(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f28,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f30,f28,f25
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f22,f25,f24
	ctx.f22.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfs f24,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f30,f7
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// stfs f25,100(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f25,f24,f26
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fadds f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// mulli r9,r6,188
	ctx.r9.s64 = ctx.r6.s64 * 188;
	// fmuls f24,f30,f6
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// mulli r10,r6,60
	ctx.r10.s64 = ctx.r6.s64 * 60;
	// fmuls f30,f28,f5
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// stfs f30,76(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmuls f28,f28,f4
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// stfs f28,84(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmsubs f28,f16,f6,f22
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 - ctx.f22.f64));
	// fmuls f17,f25,f7
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fmuls f14,f25,f6
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fmadds f30,f16,f7,f24
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 + ctx.f24.f64));
	// fmuls f25,f26,f4
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f26,f26,f5
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// stfs f26,80(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f24,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f24.f64 = double(temp.f32);
	// stfs f25,40(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmr f25,f24
	ctx.f25.f64 = ctx.f24.f64;
	// lfs f16,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f16.f64 = double(temp.f32);
	// lfs f24,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f15,f4,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f24.f64));
	// fmsubs f26,f25,f6,f17
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f25,f25,f7,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f14.f64));
	// fmsubs f17,f15,f5,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 - ctx.f17.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f26,f30
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f16,f5,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 - ctx.f22.f64));
	// fmadds f16,f16,f4,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 + ctx.f14.f64));
	// fadds f14,f25,f28
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfsx f25,r9,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f25.f64 = double(temp.f32);
	// fadds f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fadds f15,f25,f14
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,252
	ctx.r10.s64 = ctx.r6.s64 * 252;
	// lwz r9,180(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lfs f25,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f15,f25,f28
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f28,f30
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,156
	ctx.r9.s64 = ctx.r6.s64 * 156;
	// lfs f30,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f28,f30,f26
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// fadds f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f16,f17
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// mulli r10,r6,28
	ctx.r10.s64 = ctx.r6.s64 * 28;
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// fadds f26,f30,f28
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f28,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// lfs f25,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f15,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// lfs f14,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,168(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f14,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,196(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f14,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,180(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// stfs f17,112(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fmuls f17,f30,f8
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// stfs f24,104(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f24,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfs f24,80(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f22,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f28,f8
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f24,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfs f24,120(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f22,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfs f24,88(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f28,f28,f9,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 + ctx.f17.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f25,f8
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fmsubs f30,f30,f9,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 - ctx.f21.f64));
	// lfs f24,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f24,f22
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f16,152(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,144(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f24,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f24,f22
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,192(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f24,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f26,f8
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// lfs f22,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// mulli r10,r6,220
	ctx.r10.s64 = ctx.r6.s64 * 220;
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// mulli r9,r6,92
	ctx.r9.s64 = ctx.r6.s64 * 92;
	// fmadds f25,f25,f9,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f16.f64));
	// stfs f25,180(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmsubs f26,f26,f9,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 - ctx.f14.f64));
	// lfs f25,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f22,f3
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f26,112(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfsx f17,r9,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f25
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// stfsx f16,r9,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f26,f17,f25
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f29,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// lfs f25,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f17,f26,f25
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f17,264(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f26,240(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f26,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fadds f17,f26,f25
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stfs f17,176(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f26,276(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f25,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f26,168(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f26,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f26,f2
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// lfs f17,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64));
	// fmuls f16,f26,f3
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f26,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f31
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// lfs f26,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f3,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64 + ctx.f25.f64));
	// lfs f25,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f25,f25,f1,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 - ctx.f17.f64));
	// lfs f17,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f30,f17
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f17.f64));
	// stfs f17,144(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f17,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f17,196(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// fadds f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f2,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 - ctx.f16.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f17,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f21,f31
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// fmadds f17,f17,f1,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 + ctx.f15.f64));
	// stfs f17,152(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmsubs f17,f24,f2,f14
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f2.f64 - ctx.f14.f64));
	// stfs f17,180(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f17,f22,f2
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// lfs f14,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f31
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,112(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f22,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f24,f24,f3,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f17.f64));
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f21,f21,f1,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f15.f64));
	// lfs f22,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f22.f64 = double(temp.f32);
	// lwz r9,320(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfs f14,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f17.f64 = double(temp.f32);
	// lwz r10,316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f14,f1,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f1.f64 - ctx.f16.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// fadds f29,f14,f29
	ctx.f29.f64 = double(float(ctx.f14.f64 + ctx.f29.f64));
	// stfs f29,332(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f14,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f14.f64 = double(temp.f32);
	// lfs f29,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// stfs f29,100(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f14.f64 = double(temp.f32);
	// lfs f29,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// lfs f14,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f23,340(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f14,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,364(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfs f14,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,116(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfsx f14,r9,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f23,r10,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f24,f14
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f24,40(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f24,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f17,f11
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f24,76(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f24,f21,f25
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// stfs f25,88(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f25,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f21,f22,f11
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fsubs f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// stfs f25,124(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fadds f16,f15,f26
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// fsubs f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// lfs f25,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f25,316(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f25,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f25.f64 = double(temp.f32);
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f25,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f29
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// stfs f25,320(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f25,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// fmsubs f25,f22,f10,f14
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f14.f64));
	// lfs f22,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f11
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmadds f22,f17,f10,f21
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f21.f64));
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f21,f23
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfsx f23,r9,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,244
	ctx.r10.s64 = ctx.r6.s64 * 244;
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// mulli r9,r6,116
	ctx.r9.s64 = ctx.r6.s64 * 116;
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f17,f23,f21
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f23,r9,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f16,r9,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lwz r9,532(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,20
	ctx.r10.s64 = ctx.r6.s64 * 20;
	// lfs f23,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f17,f23,f21
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f21,f23
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfs f23,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f17,r9,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f17,f23,f24
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f23,f23,f24
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f24,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f21,f28,f24
	ctx.f21.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f24,f24,f28
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// stfsx f23,r9,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,212
	ctx.r10.s64 = ctx.r6.s64 * 212;
	// lwz r9,540(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// lfs f28,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f28.f64 = double(temp.f32);
	// fadds f23,f30,f28
	ctx.f23.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// lfs f17,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f28,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f24,r9,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f23,r9,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// lfs f24,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f24.f64 = double(temp.f32);
	// lfs f28,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// lfs f23,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// lfs f21,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// lfs f21,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,268(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f16,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f11
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// fmadds f16,f16,f10,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f14.f64));
	// lfs f14,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f10,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 - ctx.f15.f64));
	// fsubs f14,f30,f28
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lwz r9,400(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	// fsubs f28,f24,f23
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// mulli r10,r6,36
	ctx.r10.s64 = ctx.r6.s64 * 36;
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f23,f21,f17
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f21,84(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f21
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f17,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f17.f64 = double(temp.f32);
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfs f21,100(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f21,f25,f16
	ctx.f21.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// fadds f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f25.f64));
	// stfs f25,344(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fsubs f25,f15,f22
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f25,76(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f25,f15,f22
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f25,268(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f22,f14,f4
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// fmuls f17,f14,f5
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// fmuls f14,f30,f6
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fmuls f30,f30,f7
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// fmadds f22,f28,f5,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f5.f64 + ctx.f22.f64));
	// fmsubs f28,f28,f4,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f4.f64 - ctx.f17.f64));
	// lfs f25,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f25,f5
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f15,f25,f4
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f25,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfs f25,80(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f25,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// fadds f21,f17,f29
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// fsubs f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f17.f64));
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f30,f23,f4,f16
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 - ctx.f16.f64));
	// fmuls f16,f17,f7
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmadds f23,f23,f5,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f15.f64));
	// fmsubs f17,f24,f7,f14
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 - ctx.f14.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f24,f24,f6,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f15.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f15,f6,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f6.f64 + ctx.f16.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f7,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 - ctx.f14.f64));
	// fadds f14,f30,f22
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f14,f23,f28
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// lfs f22,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfsx f22,r9,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f23,r10,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f21,f14
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfsx f23,r10,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f21,f14
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfsx f23,r9,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,228
	ctx.r10.s64 = ctx.r6.s64 * 228;
	// fsubs f23,f25,f28
	ctx.f23.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// stfsx f23,r10,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// mulli r9,r6,100
	ctx.r9.s64 = ctx.r6.s64 * 100;
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f29,f30
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f30.f64));
	// stfsx f28,r9,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f29.f64 = double(temp.f32);
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfs f28,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f28.f64 = double(temp.f32);
	// lfs f29,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f29.f64 = double(temp.f32);
	// lwz r9,496(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// lfs f25,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f25.f64 = double(temp.f32);
	// lfs f28,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f28.f64 = double(temp.f32);
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// lfs f23,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// lfs f22,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfs f19,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// lfs f14,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,336(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// stfs f19,312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fadds f19,f15,f24
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// stfs f19,76(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f19,f16,f17
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f19,100(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f16.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f14,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// lfs f14,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f14.f64 = double(temp.f32);
	// fadds f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 + ctx.f27.f64));
	// stfs f27,80(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f14.f64 = double(temp.f32);
	// lfs f27,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// stfs f27,120(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f14,f29,f9
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// fmuls f29,f29,f8
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// stfs f29,40(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f29,f23,f22
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f27,f22,f23
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fmuls f22,f28,f8
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfs f23,104(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fmuls f21,f28,f9
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f9.f64));
	// fmsubs f28,f30,f8,f14
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f30,f30,f9,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f14.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f30,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f30.f64 = double(temp.f32);
	// lfs f14,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// stfsx f14,r9,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f30.f64 = double(temp.f32);
	// fadds f14,f19,f30
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// stfsx f14,r10,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,196
	ctx.r9.s64 = ctx.r6.s64 * 196;
	// fsubs f30,f26,f17
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// mulli r10,r6,68
	ctx.r10.s64 = ctx.r6.s64 * 68;
	// fadds f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f19,f1
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// stfsx f30,r9,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f25,f9,f22
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f22.f64));
	// stfsx f26,r10,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f26,f25,f8,f21
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f21.f64));
	// fadds f25,f16,f24
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfsx f25,r10,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f16,f24
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// lfs f24,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f20,f24
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// fadds f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f27,f2
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// lwz r10,384(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	// fmuls f16,f29,f1
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f1.f64));
	// lwz r9,628(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	// fadds f22,f21,f15
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmuls f15,f23,f2
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// add r4,r9,r4
	ctx.r4.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fmadds f29,f29,f31,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f31.f64 + ctx.f17.f64));
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// addi r11,r11,504
	ctx.r11.s64 = ctx.r11.s64 + 504;
	// stw r10,384(r1)
	PPC_STORE_U32(ctx.r1.u32 + 384, ctx.r10.u32);
	// fmsubs f23,f23,f3,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 - ctx.f20.f64));
	// fsubs f20,f28,f30
	ctx.f20.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fsubs f28,f26,f17
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// fadds f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfs f17,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f19,f19,f31,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 - ctx.f16.f64));
	// lfs f16,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f27,f3,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f15.f64));
	// lfs f15,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fadds f15,f20,f25
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// fadds f20,f30,f22
	ctx.f20.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fadds f14,f28,f21
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f21.f64));
	// fsubs f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// fadds f21,f26,f24
	ctx.f21.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fsubs f24,f22,f17
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f17,f16,f18
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,100(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f16,f24,f1
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmuls f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fmuls f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// fmuls f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// fmsubs f24,f24,f31,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f31.f64 - ctx.f17.f64));
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmadds f22,f17,f31,f16
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f31.f64 + ctx.f16.f64));
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f17,f3,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 - ctx.f18.f64));
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f3,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 + ctx.f16.f64));
	// fadds f16,f24,f29
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// lwz r10,412(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	// fadds f24,f18,f27
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f27.f64));
	// fadds f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// fsubs f27,f18,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// fsubs f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fadds f19,f17,f23
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// fsubs f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f15,f18
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f17,0(r10)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,420(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,0(r10)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,428(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// fadds f18,f14,f16
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f18,0(r10)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,368(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	// fsubs f18,f14,f16
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f18,0(r10)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,308(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// fsubs f18,f25,f22
	ctx.f18.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f18,0(r10)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,212(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// stfs f25,0(r10)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// fadds f25,f28,f29
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// stfs f25,0(r14)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fsubs f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// fsubs f29,f21,f24
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fadds f29,f24,f21
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,68(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// fadds f29,f20,f19
	ctx.f29.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,56(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// fsubs f29,f20,f19
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,48(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// fsubs f29,f26,f23
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,32(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// fadds f29,f23,f26
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,20(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fadds f29,f30,f27
	ctx.f29.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,16(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d69924
	if (!ctx.cr0.eq) goto loc_82D69924;
loc_82D6D1C4:
	// addi r1,r1,928
	ctx.r1.s64 = ctx.r1.s64 + 928;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D6D1D0;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6D1D8"))) PPC_WEAK_FUNC(sub_82D6D1D8);
PPC_FUNC_IMPL(__imp__sub_82D6D1D8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1440
	ctx.r5.s64 = ctx.r11.s64 + 1440;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,-26504
	ctx.r4.s64 = ctx.r11.s64 + -26504;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6D1F0"))) PPC_WEAK_FUNC(sub_82D6D1F0);
PPC_FUNC_IMPL(__imp__sub_82D6D1F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D6D1F8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D6D200;
	__savefpr_14(ctx, base);
	// mulli r11,r7,248
	ctx.r11.s64 = ctx.r7.s64 * 248;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d6e6f4
	if (!ctx.cr6.lt) goto loc_82D6E6F4;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// stw r10,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lfs f8,-8012(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8012);
	ctx.f8.f64 = double(temp.f32);
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lfs f9,-8008(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8008);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8004(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -8004);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// stw r10,-380(r1)
	PPC_STORE_U32(ctx.r1.u32 + -380, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f11,-8000(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8000);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,136(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D6D258:
	// rlwinm r10,r6,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f7,120(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// rlwinm r9,r6,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f6,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f6.f64 = double(temp.f32);
	// mulli r8,r6,96
	ctx.r8.s64 = ctx.r6.s64 * 96;
	// lfs f5,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f28,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f19,f7,f28
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfsx f26,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f28,f6,f28
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfsx f24,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f5,f26
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f2,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f17,f3,f24
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fmuls f26,f4,f26
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// lfsx f27,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// lfs f30,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// add r31,r7,r3
	ctx.r31.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfsx f25,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f23,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lfs f29,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f29.f64 = double(temp.f32);
	// mulli r5,r6,100
	ctx.r5.s64 = ctx.r6.s64 * 100;
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f6,f6,f27,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f27.f64 + ctx.f19.f64));
	// lfs f31,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f22,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f7,f7,f27,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64 - ctx.f28.f64));
	// fmuls f28,f30,f22
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// lfs f21,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f4,f4,f25,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64 + ctx.f18.f64));
	// stw r31,-348(r1)
	PPC_STORE_U32(ctx.r1.u32 + -348, ctx.r31.u32);
	// fmadds f2,f2,f23,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64 + ctx.f17.f64));
	// stw r7,-340(r1)
	PPC_STORE_U32(ctx.r1.u32 + -340, ctx.r7.u32);
	// fmsubs f5,f5,f25,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 - ctx.f26.f64));
	// mulli r31,r6,68
	ctx.r31.s64 = ctx.r6.s64 * 68;
	// fmsubs f3,f3,f23,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 - ctx.f24.f64));
	// lfs f26,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f29,f22
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// lfs f25,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f29,f29,f21,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f21.f64 + ctx.f28.f64));
	// lfs f18,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f6,f1
	ctx.f28.f64 = double(float(ctx.f6.f64 + ctx.f1.f64));
	// add r30,r5,r3
	ctx.r30.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fsubs f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// add r29,r5,r4
	ctx.r29.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fadds f1,f2,f4
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// add r28,r31,r3
	ctx.r28.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// mulli r7,r6,124
	ctx.r7.s64 = ctx.r6.s64 * 124;
	// fsubs f2,f5,f3
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fmsubs f30,f30,f21,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f21.f64 - ctx.f27.f64));
	// lfs f21,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f31,f7
	ctx.f27.f64 = double(float(ctx.f31.f64 - ctx.f7.f64));
	// lfs f20,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stw r30,-324(r1)
	PPC_STORE_U32(ctx.r1.u32 + -324, ctx.r30.u32);
	// fadds f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// stw r29,-300(r1)
	PPC_STORE_U32(ctx.r1.u32 + -300, ctx.r29.u32);
	// stw r28,-356(r1)
	PPC_STORE_U32(ctx.r1.u32 + -356, ctx.r28.u32);
	// mulli r30,r6,36
	ctx.r30.s64 = ctx.r6.s64 * 36;
	// fadds f3,f1,f28
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// fsubs f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fsubs f28,f6,f2
	ctx.f28.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// fadds f6,f2,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// fsubs f31,f27,f4
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f4.f64));
	// fadds f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f27.f64));
	// lfs f27,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f27.f64 = double(temp.f32);
	// fadds f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// lfs f5,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f5.f64 = double(temp.f32);
	// mulli r5,r6,92
	ctx.r5.s64 = ctx.r6.s64 * 92;
	// fmuls f15,f5,f20
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// lfsx f16,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f27,f20
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// stfs f16,-560(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// add r27,r30,r3
	ctx.r27.u64 = ctx.r30.u64 + ctx.r3.u64;
	// lfsx f16,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// stfs f16,-532(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// add r30,r30,r4
	ctx.r30.u64 = ctx.r30.u64 + ctx.r4.u64;
	// lfs f20,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmadds f27,f27,f20,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 + ctx.f15.f64));
	// lfsx f15,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-516(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// stw r27,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r27.u32);
	// lfs f17,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// mulli r28,r6,48
	ctx.r28.s64 = ctx.r6.s64 * 48;
	// lfsx f16,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stw r30,-308(r1)
	PPC_STORE_U32(ctx.r1.u32 + -308, ctx.r30.u32);
	// stw r31,-332(r1)
	PPC_STORE_U32(ctx.r1.u32 + -332, ctx.r31.u32);
	// fmsubs f5,f5,f20,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f20.f64 - ctx.f14.f64));
	// stfs f5,-528(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fmuls f20,f26,f17
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f5,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// fmuls f15,f24,f5
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// fmuls f14,f23,f5
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lfs f5,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// mulli r31,r6,60
	ctx.r31.s64 = ctx.r6.s64 * 60;
	// fmadds f25,f25,f5,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f20.f64));
	// fmsubs f26,f26,f5,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 - ctx.f17.f64));
	// lfs f5,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f23,f23,f5,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f15.f64));
	// mulli r30,r6,28
	ctx.r30.s64 = ctx.r6.s64 * 28;
	// fmsubs f5,f24,f5,f14
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 - ctx.f14.f64));
	// fmuls f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f20,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f21,f20
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f20.f64));
	// fmuls f17,f22,f20
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// lfs f20,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f22,f22,f20,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f20.f64 - ctx.f15.f64));
	// fmadds f24,f21,f20,f17
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f17.f64));
	// lfs f17,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f26,f30
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fmuls f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f16,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// fadds f26,f23,f27
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// lfs f23,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f23.f64 = double(temp.f32);
	// fadds f21,f25,f29
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fsubs f29,f29,f25
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fadds f25,f5,f23
	ctx.f25.f64 = double(float(ctx.f5.f64 + ctx.f23.f64));
	// fsubs f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// fmadds f19,f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f15.f64));
	// stfs f19,-468(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fmsubs f19,f18,f16,f14
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f26,f21
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// stfs f16,-532(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f20,f25
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// stfs f16,-516(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// lfsx f16,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f27,f30
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f16,-552(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f19,-456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fsubs f27,f29,f5
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// lfsx f18,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// lfsx f16,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f29,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f19,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f18,-560(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// stfs f16,-556(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// fmuls f16,f29,f19
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// lfsx f18,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f17,f19
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f19.f64));
	// lfs f19,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f18
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f19,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,-560(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fmr f19,f18
	ctx.f19.f64 = ctx.f18.f64;
	// mulli r27,r6,80
	ctx.r27.s64 = ctx.r6.s64 * 80;
	// fmsubs f29,f29,f19,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64 - ctx.f15.f64));
	// stfs f29,-544(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmadds f18,f17,f19,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 + ctx.f16.f64));
	// stfs f18,-436(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f14.f64));
	// stfs f19,-548(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f18,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f18.f64 = double(temp.f32);
	// lfs f29,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f29.f64 = double(temp.f32);
	// lfs f19,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f29,f18
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f18.f64));
	// fmuls f15,f19,f18
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f14.f64));
	// stfs f18,-540(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f17,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f17,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f29,f17,f15
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f29,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f29.f64 = double(temp.f32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f24
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// fmadds f16,f29,f16,f14
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-560(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f14,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,-528(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-544(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,-532(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-548(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f14,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-372(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-444(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f15,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,-428(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fsubs f15,f24,f22
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f15,-376(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,-404(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f22,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f24.f64 = double(temp.f32);
	// fadds f15,f22,f24
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f15,-368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f24,-388(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f22,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f22.f64 = double(temp.f32);
	// mulli r26,r6,112
	ctx.r26.s64 = ctx.r6.s64 * 112;
	// fmuls f29,f29,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// lfs f22,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-560(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// rlwinm r25,r6,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f22,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-552(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f22,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-528(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// mulli r24,r6,104
	ctx.r24.s64 = ctx.r6.s64 * 104;
	// lfs f24,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f29,f18,f22,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f29.f64));
	// lfsx f22,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-532(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfsx f18,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-468(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfsx f18,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-516(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// mulli r23,r6,72
	ctx.r23.s64 = ctx.r6.s64 * 72;
	// lfsx f18,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-408(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfsx f18,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-456(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfsx f18,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f29,-508(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// stfs f18,-424(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfsx f29,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f18,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-460(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fmuls f18,f15,f29
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f29.f64));
	// fmuls f15,f24,f29
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f29.f64));
	// lfsx f22,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f22.f64));
	// lfs f29,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// stfs f29,-560(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f22,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f22.f64 = double(temp.f32);
	// fmr f29,f22
	ctx.f29.f64 = ctx.f22.f64;
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f24,f24,f29,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f18.f64));
	// stfs f24,-540(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f24,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f29,f24,f29,f15
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 - ctx.f15.f64));
	// stfs f29,-556(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f24,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f24.f64 = double(temp.f32);
	// lfs f29,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f18,f29,f24
	ctx.f18.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// lfs f29,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f29,f29,f22,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 + ctx.f14.f64));
	// stfs f29,-548(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f29,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f15,f29,f24
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// lfs f24,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f24,f24,f22,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f14.f64));
	// stfs f24,-544(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f22
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// lfs f24,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// stfs f24,-560(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f22,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f22.f64 = double(temp.f32);
	// fmr f24,f22
	ctx.f24.f64 = ctx.f22.f64;
	// lfs f22,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f29,f29,f24,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f18,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f24,f22,f24,f15
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f15.f64));
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f15,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f18,f15,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-532(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// mulli r22,r6,40
	ctx.r22.s64 = ctx.r6.s64 * 40;
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,-560(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// mulli r21,r6,120
	ctx.r21.s64 = ctx.r6.s64 * 120;
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,-516(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f16,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,-528(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// fsubs f14,f17,f19
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,-408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// mulli r20,r6,88
	ctx.r20.s64 = ctx.r6.s64 * 88;
	// mulli r19,r6,56
	ctx.r19.s64 = ctx.r6.s64 * 56;
	// lfs f19,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f19,f15
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f17,-436(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,-484(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f19,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f19,f17
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f15,-492(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,-452(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f19,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f16,f19
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f17,-456(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfs f16,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-556(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// stfs f19,-424(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f19,f16
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// fmuls f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfsx f16,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-560(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfsx f16,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-532(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfsx f16,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfsx f16,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-552(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfsx f16,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-516(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfsx f16,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f16,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f19,f19,f16,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f19,-540(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fmadds f17,f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfsx f19,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f17,-548(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// stfs f19,-536(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfsx f17,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f19,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f17,-560(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// stfs f19,-524(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f17,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f19,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f17
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f16.f64));
	// stfs f19,-528(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f19,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f19.f64 = double(temp.f32);
	// mulli r17,r6,20
	ctx.r17.s64 = ctx.r6.s64 * 20;
	// fmsubs f19,f19,f17,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 - ctx.f15.f64));
	// stfs f19,-508(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f19,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f19.f64 = double(temp.f32);
	// add r14,r17,r3
	ctx.r14.u64 = ctx.r17.u64 + ctx.r3.u64;
	// lfs f17,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f17,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f29
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// stfs f17,-556(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// add r17,r17,r4
	ctx.r17.u64 = ctx.r17.u64 + ctx.r4.u64;
	// fadds f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// stfs f17,-460(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// mulli r16,r6,84
	ctx.r16.s64 = ctx.r6.s64 * 84;
	// fsubs f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// stfs f24,-432(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f24,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// stfs f29,-412(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f29,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f29.f64 = double(temp.f32);
	// stw r14,-364(r1)
	PPC_STORE_U32(ctx.r1.u32 + -364, ctx.r14.u32);
	// lfs f24,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f29,f24
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// stfs f24,-532(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f17,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f17.f64 = double(temp.f32);
	// stw r17,-516(r1)
	PPC_STORE_U32(ctx.r1.u32 + -516, ctx.r17.u32);
	// lfs f24,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f14.f64));
	// fmsubs f17,f24,f17,f16
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 - ctx.f16.f64));
	// lfs f24,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f16,f29,f24,f15
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 + ctx.f15.f64));
	// lfs f29,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f29.f64 = double(temp.f32);
	// mulli r18,r6,24
	ctx.r18.s64 = ctx.r6.s64 * 24;
	// mulli r15,r6,116
	ctx.r15.s64 = ctx.r6.s64 * 116;
	// add r17,r16,r3
	ctx.r17.u64 = ctx.r16.u64 + ctx.r3.u64;
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f15,f29,f24,f15
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 - ctx.f15.f64));
	// lfs f24,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f24.f64 = double(temp.f32);
	// fadds f29,f24,f22
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f14,f18
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f29,f14
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f14,f29
	ctx.f29.f64 = double(float(ctx.f14.f64 - ctx.f29.f64));
	// stfs f29,-512(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f29,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f14,f29,f22
	ctx.f14.f64 = double(float(ctx.f29.f64 - ctx.f22.f64));
	// stfs f14,-464(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// stfs f29,-440(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f29,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f29.f64 = double(temp.f32);
	// fadds f22,f24,f29
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfs f22,-460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// stfs f29,-384(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f29,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f24,f29,f18
	ctx.f24.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfs f24,-412(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f22,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f22.f64 = double(temp.f32);
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// lfs f24,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f24,f22
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// stfs f29,-312(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f29,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f14,f29,f22
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// lfs f22,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f29,f29,f22,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 + ctx.f18.f64));
	// fmsubs f24,f24,f22,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f14.f64));
	// fadds f22,f29,f19
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f19.f64));
	// fsubs f29,f19,f29
	ctx.f29.f64 = double(float(ctx.f19.f64 - ctx.f29.f64));
	// stfs f29,-536(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fadds f29,f24,f17
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// stfs f29,-552(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fsubs f29,f17,f24
	ctx.f29.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// stfs f29,-540(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfsx f29,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stw r17,-320(r1)
	PPC_STORE_U32(ctx.r1.u32 + -320, ctx.r17.u32);
	// lfs f18,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// add r16,r16,r4
	ctx.r16.u64 = ctx.r16.u64 + ctx.r4.u64;
	// fmuls f17,f18,f29
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f29.f64));
	// lfs f18,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f29
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f29.f64));
	// lfs f19,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfs f29,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-532(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fmuls f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// stfs f29,-560(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// stw r16,-528(r1)
	PPC_STORE_U32(ctx.r1.u32 + -528, ctx.r16.u32);
	// lfsx f24,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// add r16,r15,r3
	ctx.r16.u64 = ctx.r15.u64 + ctx.r3.u64;
	// lfs f29,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f29.f64 = double(temp.f32);
	// add r15,r15,r4
	ctx.r15.u64 = ctx.r15.u64 + ctx.r4.u64;
	// fmadds f18,f18,f24,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f24.f64 + ctx.f17.f64));
	// stfs f18,-508(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f18,f29,f19
	ctx.f18.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// lfs f19,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f24,f19,f24,f14
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f24.f64 - ctx.f14.f64));
	// stfs f24,-556(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f24,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lwz r17,-516(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	// lfs f19,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// stw r16,-304(r1)
	PPC_STORE_U32(ctx.r1.u32 + -304, ctx.r16.u32);
	// fmuls f17,f19,f24
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// lfs f19,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f24
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// stw r15,-360(r1)
	PPC_STORE_U32(ctx.r1.u32 + -360, ctx.r15.u32);
	// lfs f24,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f19.f64 = double(temp.f32);
	// lwz r17,-528(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	// fmadds f29,f29,f24,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 + ctx.f19.f64));
	// lfs f19,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f24,f19,f24,f18
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f24.f64 - ctx.f18.f64));
	// stfs f24,-548(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f19,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// stfs f24,-560(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f19,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f24.f64 = double(temp.f32);
	// lfs f18,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f24,f24,f19,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f19.f64 + ctx.f17.f64));
	// fmsubs f19,f18,f19,f14
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfs f17,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f16
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-560(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,-472(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f17,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f17,-480(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f17,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,-432(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-396(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f17,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f16,-508(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// mulli r14,r6,52
	ctx.r14.s64 = ctx.r6.s64 * 52;
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,-336(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// mulli r17,r6,12
	ctx.r17.s64 = ctx.r6.s64 * 12;
	// lfs f17,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-556(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f16,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// stw r14,-536(r1)
	PPC_STORE_U32(ctx.r1.u32 + -536, ctx.r14.u32);
	// lfs f17,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f19
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfs f16,-560(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fsubs f17,f29,f24
	ctx.f17.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// fadds f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfs f29,-552(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f29,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f19,f29
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// stfs f29,-476(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f24,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f24.f64 = double(temp.f32);
	// lfs f29,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmsubs f29,f24,f29,f15
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 - ctx.f15.f64));
	// stfs f29,-496(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// mulli r16,r6,76
	ctx.r16.s64 = ctx.r6.s64 * 76;
	// lfs f24,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f24.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,-500(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// stw r14,-532(r1)
	PPC_STORE_U32(ctx.r1.u32 + -532, ctx.r14.u32);
	// mulli r15,r6,108
	ctx.r15.s64 = ctx.r6.s64 * 108;
	// lwz r14,-536(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// lfs f16,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,-504(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfsx f17,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-524(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// stw r14,-560(r1)
	PPC_STORE_U32(ctx.r1.u32 + -560, ctx.r14.u32);
	// lwz r14,-532(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	// lfs f19,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f24,f19
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// lwz r14,-560(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	// lfs f29,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-536(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfsx f29,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-420(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfsx f29,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-416(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfsx f29,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-540(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfsx f29,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-520(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfsx f29,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-548(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f29,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f16,f29,f19
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// lfs f19,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f19,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f24,f24,f19,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f29,f29,f19,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64 - ctx.f15.f64));
	// stfs f29,-524(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f29,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f29.f64 = double(temp.f32);
	// lfs f19,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f29,f19
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// lfs f29,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// lfs f19,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f19.f64 = double(temp.f32);
	// stfs f29,-536(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fmr f29,f19
	ctx.f29.f64 = ctx.f19.f64;
	// stfs f24,-544(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f24,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f24,f16
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// fmadds f19,f24,f29,f17
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f17.f64));
	// lfs f24,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f17,f24,f29,f16
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 - ctx.f16.f64));
	// lfs f29,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f29.f64 = double(temp.f32);
	// lfs f24,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f29,f29,f24,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 + ctx.f15.f64));
	// stfs f29,-556(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f16,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// lfs f29,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f29,f29,f24,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 - ctx.f16.f64));
	// stfs f29,-540(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f24,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f29,f18,f24
	ctx.f29.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// lfs f15,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f16.f64 = double(temp.f32);
	// fadds f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f18.f64));
	// fsubs f18,f16,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f15,-496(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f15,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f15,-544(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f15,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f24,f15
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfs f15,-420(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fsubs f15,f29,f18
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// lfs f18,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfs f24,-524(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f24,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f18,f24,f16
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// stfs f18,-536(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f24,-416(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f24,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f18,f15,f24
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// fadds f16,f24,f15
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// lfs f24,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f15,f24,f29
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// fadds f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// fmuls f24,f18,f0
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f24,-328(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmuls f24,f16,f0
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f24,-400(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmuls f24,f15,f0
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f24,-352(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fmuls f29,f29,f0
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// stfs f29,-392(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f18,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f24.f64 = double(temp.f32);
	// lfs f29,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f16,f24,f18
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// fmuls f15,f29,f18
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f18.f64));
	// lfs f18,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f3.f64));
	// stfs f17,-520(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f17,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-556(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f17,-552(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f17,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f29,f29,f17,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f24,f24,f16,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f16,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// lfs f15,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,-500(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f15,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f15.f64));
	// lfs f15,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f15,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-540(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-476(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f14,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-496(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fadds f17,f22,f3
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// stfs f17,-556(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// fsubs f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// stfs f3,-548(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f17,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f3,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f17,f3
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// stfs f17,-520(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f17,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f17,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// stfs f3,-504(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f3,f17,f22,f14
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 + ctx.f14.f64));
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f22,f17,f22,f14
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 - ctx.f14.f64));
	// fadds f17,f3,f29
	ctx.f17.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// fsubs f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// fadds f29,f22,f24
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f17,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// fadds f17,f29,f18
	ctx.f17.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// fadds f14,f24,f3
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// fsubs f3,f3,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f24.f64));
	// lfs f24,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 - ctx.f29.f64));
	// fsubs f18,f24,f14
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// fsubs f14,f3,f16
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f16.f64));
	// fadds f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// fmuls f3,f18,f0
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f18,f14,f0
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f18,-552(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fmuls f18,f16,f0
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f18,-544(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// fadds f16,f18,f23
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// fadds f18,f14,f16
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,-520(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// stfs f16,-500(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f16,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f25
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f25.f64));
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,-504(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,-440(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f16,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfsx f14,r10,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfs f16,0(r3)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f16,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,0(r4)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f18,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfsx f18,r8,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfsx f14,r8,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f15,r9,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f18,r9,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f18,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// lfs f18,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// lfs f16,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,-512(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f14,-472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f26,f14
	ctx.f14.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// stfs f14,-480(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f1,f14
	ctx.f14.f64 = double(float(ctx.f1.f64 - ctx.f14.f64));
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f7.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f14.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fadds f14,f25,f23
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// stfs f14,-504(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfs f25,-476(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fsubs f25,f22,f18
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f25,-492(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fadds f25,f18,f22
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f25,-500(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f25,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f25.f64 = double(temp.f32);
	// fadds f23,f2,f25
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f25.f64));
	// stfs f23,-496(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fsubs f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// stfs f2,-464(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f2,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f25,f17,f16
	ctx.f25.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// fadds f23,f16,f17
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fmuls f22,f2,f12
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f18,f2,f13
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f2.f64 = double(temp.f32);
	// fadds f17,f15,f2
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fsubs f16,f15,f2
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// lfs f2,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f2,f13
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f14,f2,f13
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f2,f26,f13
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f2,-512(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// stfs f26,-520(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fmuls f2,f25,f0
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f25,f23,f0
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f25,-524(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f25,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f17,f0
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f25,f29,f25
	ctx.f25.f64 = double(float(ctx.f29.f64 + ctx.f25.f64));
	// lfs f17,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f12,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f14.f64));
	// fmsubs f26,f25,f13,f22
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 - ctx.f22.f64));
	// fmadds f25,f25,f12,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 + ctx.f18.f64));
	// lfs f18,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f18.f64 = double(temp.f32);
	// stfs f17,-480(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fmadds f18,f18,f12,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f15.f64));
	// lfs f17,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f16,f0
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmadds f17,f21,f12,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f17,-536(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f21,f21,f13,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f21,-484(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f21,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f17,f21
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// lfs f17,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f21,-512(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmuls f21,f15,f0
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f17,f14,f0
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fsubs f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfsx f14,r27,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfsx f21,r29,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f17,f21
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfsx f14,r29,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfsx f21,r27,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f21,f16
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfsx f17,r26,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfsx f21,r28,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// lfs f16,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fadds f17,f15,f21
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfsx f17,r28,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfsx f21,r26,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f22,f7
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f7.f64));
	// fsubs f29,f21,f29
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// lfs f21,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f2,f16
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// fsubs f2,f16,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 - ctx.f2.f64));
	// stfs f2,-476(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f2,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f7,f7,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f22.f64));
	// lfs f16,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f2
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f2.f64));
	// lfs f2,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f15,f15,f2
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// lfs f2,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f2.f64 = double(temp.f32);
	// stfs f7,-496(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fmuls f14,f2,f13
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f2.f64 = double(temp.f32);
	// fadds f7,f23,f1
	ctx.f7.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// stfs f7,-520(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f7,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f7.f64 = double(temp.f32);
	// stfs f2,-512(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fadds f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// stfs f7,-504(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f2,f1,f23
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// lfs f7,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f16,f0
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f1,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f1.f64 = double(temp.f32);
	// fadds f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// fsubs f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f25.f64));
	// lfs f25,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f25.f64 = double(temp.f32);
	// stfs f7,-500(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f22,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f22.f64 = double(temp.f32);
	// lfs f7,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f7.f64 = double(temp.f32);
	// lfs f25,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f25.f64 = double(temp.f32);
	// fadds f7,f7,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f22.f64));
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f14,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f15,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f3,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 + ctx.f15.f64));
	// stfs f15,-464(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-484(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fmuls f15,f21,f13
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f14,f29,f13
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fmsubs f29,f29,f12,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 - ctx.f15.f64));
	// stfs f29,-444(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fmadds f29,f21,f12,f14
	ctx.f29.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f29,-492(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f29,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f29.f64 = double(temp.f32);
	// lfs f21,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f15,f29,f21
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f21.f64));
	// fadds f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// lfs f29,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f29.f64 = double(temp.f32);
	// fadds f14,f7,f29
	ctx.f14.f64 = double(float(ctx.f7.f64 + ctx.f29.f64));
	// fsubs f7,f7,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// stfs f7,-504(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f29,f2,f1
	ctx.f29.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfs f29,-500(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfs f2,-524(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fsubs f7,f28,f23
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// fadds f2,f23,f28
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// fadds f1,f25,f26
	ctx.f1.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f1,-472(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f1,f22,f4
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// fsubs f4,f4,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f22.f64));
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f16,f28
	ctx.f28.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// stfs f28,-452(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// stfs f28,-536(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f28,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f10
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// lfs f28,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// stfs f28,-488(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f28,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f28,-520(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f28,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f28.f64 = double(temp.f32);
	// fmr f29,f28
	ctx.f29.f64 = ctx.f28.f64;
	// lfs f28,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f29
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// stfs f28,-512(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f28,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// stfsx f28,r20,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// stfsx f28,r18,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f17,f28
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// stfsx f25,r18,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfsx f28,r20,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f25,f28,f29
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// stfsx f25,r21,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// stfsx f29,r19,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f28.f64 = double(temp.f32);
	// lfs f29,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f29.f64 = double(temp.f32);
	// fadds f25,f29,f28
	ctx.f25.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// stfsx f25,r19,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// stfsx f29,r21,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// stfsx f15,r23,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// stfsx f21,r25,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// stfsx f14,r25,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f21,r23,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f21,r24,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f21,r22,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f21,r22,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r24,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// lfs f22,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// lfs f22,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f21,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f23,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f28,f27,f23
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// lfs f25,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f25.f64 = double(temp.f32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// lfs f23,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f29,f20,f25
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// fadds f20,f19,f7
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f7.f64));
	// fsubs f7,f7,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f19.f64));
	// lfs f19,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f23,f13,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f22.f64));
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f12,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f21.f64));
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f21,f10
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fmsubs f21,f21,f11,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 - ctx.f16.f64));
	// fmuls f17,f28,f8
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmuls f16,f3,f8
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f15,f25,f10
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f14,f27,f10
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fmadds f19,f19,f11,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f18.f64));
	// stfs f19,-508(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f19,f29,f8
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fmuls f18,f26,f8
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fmsubs f29,f29,f9,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 - ctx.f17.f64));
	// fmadds f26,f26,f9,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 + ctx.f16.f64));
	// fmadds f27,f27,f11,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f15.f64));
	// fmsubs f25,f25,f11,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f14.f64));
	// fmadds f28,f28,f9,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 + ctx.f19.f64));
	// fmsubs f3,f3,f9,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 - ctx.f18.f64));
	// fsubs f19,f22,f23
	ctx.f19.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fadds f18,f27,f21
	ctx.f18.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// fadds f22,f3,f28
	ctx.f22.f64 = double(float(ctx.f3.f64 + ctx.f28.f64));
	// fsubs f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// fadds f28,f26,f29
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// fadds f26,f19,f4
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// fsubs f4,f4,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f19.f64));
	// fadds f19,f23,f2
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// lfs f17,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f20,f22
	ctx.f16.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfsx f16,r5,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfsx f22,r30,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f20,f26,f28
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfsx f20,r30,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfsx f28,r5,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f7,f29
	ctx.f22.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// stfsx f22,r7,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// stfsx f7,r31,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f4,f3
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// stfsx f7,r31,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f4,f3
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfsx f7,r7,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f19,f18
	ctx.f7.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfsx f7,r16,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f18,f19
	ctx.f7.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfsx f7,r17,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// lfs f7,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f7.f64 = double(temp.f32);
	// fadds f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// fadds f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// lfs f22,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f23.f64));
	// fmuls f14,f15,f12
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f26,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f26.f64 = double(temp.f32);
	// lfs f18,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f3,f5,f26
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// fadds f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// lfs f20,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// lfs f19,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f28,f30,f20
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// fadds f30,f20,f30
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// lfs f23,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// lfs f23,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// fadds f4,f7,f17
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f17.f64));
	// stfsx f4,r17,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f7,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f17.f64));
	// stfsx f7,r16,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f26,f16,f13,f14
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f4,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fadds f29,f7,f4
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fmuls f7,f17,f12
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f7,-404(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fadds f7,f18,f22
	ctx.f7.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f4,f24,f19
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f15,f13,f16
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f21,-384(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmuls f29,f29,f0
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f15,f5,f9
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f18,f13,f14
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fmuls f14,f24,f11
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// fsubs f16,f26,f20
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f20.f64));
	// stfs f16,-400(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmsubs f21,f17,f13,f18
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f21,-396(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f19,f6,f29
	ctx.f19.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// stfs f19,-388(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmuls f21,f4,f9
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// fmuls f19,f7,f9
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fmuls f18,f28,f11
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmuls f17,f3,f11
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmuls f16,f5,f8
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// fmuls f5,f22,f11
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// stfs f5,-392(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fadds f6,f29,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// lwz r10,-380(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	// fsubs f29,f2,f25
	ctx.f29.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// stfsx f29,r15,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// stfsx f2,r14,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f1,f27
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// stfsx f2,r14,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// fsubs f2,f1,f27
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// stfsx f2,r15,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fadds f1,f20,f26
	ctx.f1.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// lfs f20,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f3,f3,f10,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f18.f64));
	// lfs f27,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f22,f10,f14
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f14.f64));
	// addic. r9,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r9.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// fmsubs f7,f7,f8,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 - ctx.f21.f64));
	// lwz r10,-344(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	// fmadds f4,f4,f8,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f19.f64));
	// lfs f19,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f19.f64 = double(temp.f32);
	// fadds f5,f23,f31
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f2,f31,f23
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fmsubs f31,f28,f10,f17
	ctx.f31.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f17.f64));
	// lfs f28,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f28.f64 = double(temp.f32);
	// fadds f29,f27,f28
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lwz r10,-320(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// stw r9,-380(r1)
	PPC_STORE_U32(ctx.r1.u32 + -380, ctx.r9.u32);
	// fmadds f27,f30,f9,f16
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f16.f64));
	// addi r11,r11,248
	ctx.r11.s64 = ctx.r11.s64 + 248;
	// fmsubs f30,f30,f8,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f15.f64));
	// fadds f23,f26,f3
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fsubs f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fadds f26,f27,f7
	ctx.f26.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// lfs f21,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f25,f24,f10,f21
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f21.f64));
	// fadds f24,f19,f20
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f19,f1,f5
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fadds f21,f28,f2
	ctx.f21.f64 = double(float(ctx.f28.f64 + ctx.f2.f64));
	// fsubs f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// fadds f28,f29,f6
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// fsubs f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// fadds f22,f25,f31
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f31.f64));
	// fsubs f1,f24,f23
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-364(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	// fadds f1,f23,f24
	ctx.f1.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f31,f31,f25
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f25.f64));
	// fadds f25,f30,f4
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// fsubs f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-516(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	// fadds f1,f21,f22
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-528(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	// fsubs f1,f21,f22
	ctx.f1.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-304(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	// fsubs f1,f20,f31
	ctx.f1.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-532(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	// fadds f1,f31,f20
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-560(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	// fadds f1,f2,f3
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-360(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-356(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	// fsubs f3,f28,f26
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-348(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	// fadds f3,f26,f28
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-340(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	// fadds f3,f19,f25
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-332(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	// fsubs f3,f19,f25
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f25.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	// fsubs f3,f6,f4
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// stfs f6,0(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-308(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	// fadds f6,f5,f7
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fsubs f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfs f6,0(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-300(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	// stfs f7,0(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d6d258
	if (!ctx.cr0.eq) goto loc_82D6D258;
loc_82D6E6F4:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D6E6FC;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6E700"))) PPC_WEAK_FUNC(sub_82D6E700);
PPC_FUNC_IMPL(__imp__sub_82D6E700) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1512
	ctx.r5.s64 = ctx.r11.s64 + 1512;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,-11792
	ctx.r4.s64 = ctx.r11.s64 + -11792;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6E718"))) PPC_WEAK_FUNC(sub_82D6E718);
PPC_FUNC_IMPL(__imp__sub_82D6E718) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D6E720;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28ee0
	ctx.lr = 0x82D6E728;
	__savefpr_14(ctx, base);
	// mulli r11,r7,120
	ctx.r11.s64 = ctx.r7.s64 * 120;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d6ee24
	if (!ctx.cr6.lt) goto loc_82D6EE24;
	// rlwinm r20,r9,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r21,r7,r8
	ctx.r21.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f12,136(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D6E75C:
	// rlwinm r10,r6,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f11,56(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r9,r6,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r7,r6,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f8,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// mulli r5,r6,40
	ctx.r5.s64 = ctx.r6.s64 * 40;
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f30,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f28,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f11,f30
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f19,f9,f28
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// lfsx f29,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f10,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfsx f27,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f28,f8,f28
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfsx f24,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfs f3,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f3.f64 = double(temp.f32);
	// mulli r8,r6,48
	ctx.r8.s64 = ctx.r6.s64 * 48;
	// lfsx f22,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f2,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f23,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f10,f10,f29,f20
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64 + ctx.f20.f64));
	// lfsx f26,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f21,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f7,f26
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// fmsubs f11,f11,f29,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 - ctx.f30.f64));
	// lfs f6,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f9,f9,f27,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f28.f64));
	// lfsx f25,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f28,f3,f22
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f30,f5,f24
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// mulli r31,r6,56
	ctx.r31.s64 = ctx.r6.s64 * 56;
	// fmuls f29,f4,f24
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// lfs f31,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// fmuls f26,f6,f26
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmadds f8,f8,f27,f19
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 + ctx.f19.f64));
	// lfs f27,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f6,f6,f25,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f18.f64));
	// mulli r30,r6,24
	ctx.r30.s64 = ctx.r6.s64 * 24;
	// fmadds f4,f4,f23,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 + ctx.f30.f64));
	// fmadds f30,f2,f21,f28
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f21.f64 + ctx.f28.f64));
	// lfs f2,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f3,f3,f21,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f21.f64 - ctx.f22.f64));
	// lfsx f21,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f5,f5,f23,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f29.f64));
	// lfsx f20,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f7,f7,f25,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 - ctx.f26.f64));
	// lfs f23,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fadds f29,f10,f1
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f1.f64));
	// mulli r29,r6,60
	ctx.r29.s64 = ctx.r6.s64 * 60;
	// fsubs f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// lfs f26,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f26.f64 = double(temp.f32);
	// fadds f1,f6,f8
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// lfs f25,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// lfsx f19,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f28,f31,f11
	ctx.f28.f64 = double(float(ctx.f31.f64 - ctx.f11.f64));
	// fadds f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f31.f64));
	// lfs f31,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f24,f4,f30
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// lfsx f17,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// lfs f30,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f22,f5,f3
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// mulli r28,r6,44
	ctx.r28.s64 = ctx.r6.s64 * 44;
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// lfs f7,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f7.f64 = double(temp.f32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f3,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f16,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r27,r6,28
	ctx.r27.s64 = ctx.r6.s64 * 28;
	// fsubs f18,f22,f24
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// lfsx f22,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f15,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f31,f3
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// stfs f15,-280(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// rlwinm r25,r6,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f15,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r24,r6,52
	ctx.r24.s64 = ctx.r6.s64 * 52;
	// stfs f15,-284(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfsx f15,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-288(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmuls f15,f7,f3
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// fmuls f3,f27,f20
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// stfs f3,-276(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// fmuls f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// mulli r26,r6,12
	ctx.r26.s64 = ctx.r6.s64 * 12;
	// fmsubs f7,f7,f21,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 - ctx.f14.f64));
	// fmadds f3,f31,f21,f15
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f21.f64 + ctx.f15.f64));
	// fmuls f21,f2,f22
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// fmsubs f27,f27,f19,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f19.f64 - ctx.f20.f64));
	// mulli r23,r6,36
	ctx.r23.s64 = ctx.r6.s64 * 36;
	// fmuls f20,f23,f16
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// fmuls f22,f25,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f22.f64));
	// fmsubs f2,f2,f17,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64 - ctx.f22.f64));
	// lfs f22,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f31,f26,f19,f15
	ctx.f31.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 + ctx.f15.f64));
	// fmuls f19,f30,f16
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f16.f64));
	// lfs f16,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f25,f17,f21
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f17.f64 + ctx.f21.f64));
	// lfs f25,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f30,f30,f25,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 + ctx.f20.f64));
	// lfs f21,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f22,f16
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f20,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f25,f23,f25,f19
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f25.f64 - ctx.f19.f64));
	// lfs f19,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f23,f3,f31
	ctx.f23.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f31,f7,f27
	ctx.f31.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fadds f7,f27,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fadds f27,f31,f23
	ctx.f27.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// fsubs f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// lfs f23,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f16
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f16,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f23,f23,f16,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-280(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfsx f14,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-292(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfsx f14,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-288(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f14,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmadds f22,f22,f16,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfsx f16,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f15,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f26,f22
	ctx.f14.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f14,-320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f26,-284(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fsubs f26,f2,f23
	ctx.f26.f64 = double(float(ctx.f2.f64 - ctx.f23.f64));
	// stfs f26,-316(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fmuls f26,f21,f16
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfsx f22,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// stfs f2,-276(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// fmuls f23,f20,f16
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// lfsx f2,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,-312(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// stfs f22,-272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmadds f26,f20,f15,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 + ctx.f26.f64));
	// stfs f26,-300(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f2,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f19,f2
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// fmuls f20,f17,f2
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmsubs f2,f21,f15,f23
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f15.f64 - ctx.f23.f64));
	// stfs f2,-304(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f2,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f2.f64 = double(temp.f32);
	// lfs f23,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f2,f23
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f26,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// mulli r22,r6,20
	ctx.r22.s64 = ctx.r6.s64 * 20;
	// fmuls f14,f26,f23
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f23,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// stfs f22,-280(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f21,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f22,f17,f21,f16
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f21.f64 + ctx.f16.f64));
	// fmsubs f21,f19,f21,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 - ctx.f20.f64));
	// lfs f20,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f26,f26,f20,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f15.f64));
	// lfs f19,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f2,f20,f14
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f20.f64 - ctx.f14.f64));
	// lfs f2,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f2.f64 = double(temp.f32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f19,f2,f19,f16
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f16,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f30
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// fadds f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// fsubs f16,f15,f25
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// lfs f15,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f15,-280(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,-308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,-292(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f16,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,-288(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f17,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// lfs f14,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f17,-316(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f17,f18,f27
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// fmuls f16,f15,f13
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fsubs f15,f31,f24
	ctx.f15.f64 = double(float(ctx.f31.f64 - ctx.f24.f64));
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f19,f29,f1
	ctx.f19.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// fmsubs f2,f23,f14,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f14.f64 - ctx.f2.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,-272(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f23,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f12
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f17,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f10,f6
	ctx.f23.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fmsubs f17,f17,f12,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f16.f64));
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f15,-312(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fsubs f15,f21,f2
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// stfs f15,-308(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fadds f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f21.f64));
	// stfs f2,-280(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfsx f15,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f2,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f2.f64 = double(temp.f32);
	// fadds f21,f2,f23
	ctx.f21.f64 = double(float(ctx.f2.f64 + ctx.f23.f64));
	// stfs f21,-320(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 - ctx.f2.f64));
	// stfs f2,-268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f2,f8,f28
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fsubs f21,f5,f7
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// fadds f23,f2,f16
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// stfs f23,-304(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fsubs f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f16.f64));
	// stfs f2,-300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fadds f2,f21,f19
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f2,-264(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfsx f16,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f2,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f2.f64 = double(temp.f32);
	// lfs f23,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f2,f16
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// fmuls f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// fmadds f23,f23,f15,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64 + ctx.f14.f64));
	// fmsubs f2,f2,f15,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64 - ctx.f16.f64));
	// fsubs f16,f23,f26
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// lfs f14,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fsubs f26,f2,f20
	ctx.f26.f64 = double(float(ctx.f2.f64 - ctx.f20.f64));
	// fadds f20,f2,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// lfs f2,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f2.f64 = double(temp.f32);
	// fadds f31,f31,f24
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f24.f64));
	// fadds f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// fsubs f27,f3,f4
	ctx.f27.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// fadds f2,f16,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 + ctx.f2.f64));
	// fsubs f15,f22,f23
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fsubs f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfs f14,-272(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfs f26,-296(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f26,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f12
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f26,-272(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmadds f26,f2,f13,f14
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f2,f2,f12,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f14.f64));
	// fadds f14,f17,f26
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f14,-308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f14,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// fadds f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// stfs f14,-316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f14,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfsx f17,r28,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfsx f17,r28,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfsx f17,r26,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfsx f17,r26,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f17,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f17,f2
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f2.f64));
	// stfsx f14,r29,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f14.f64 = double(temp.f32);
	// fadds f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f17.f64));
	// fsubs f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfsx f14,r29,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// stfsx f2,r27,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f2,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// stfsx f2,r27,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f2,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f17,f2,f20
	ctx.f17.f64 = double(float(ctx.f2.f64 - ctx.f20.f64));
	// lfs f26,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f27,-304(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fadds f2,f17,f15
	ctx.f2.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f2,-272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f2,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fsubs f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f30.f64));
	// fsubs f14,f2,f26
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// fadds f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// stfs f2,-300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f2,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f26,f16,f12
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmuls f24,f2,f12
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f2,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f2,f12
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f2,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,-268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// lfs f27,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f6,f31,f0
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// lfs f31,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f31.f64 = double(temp.f32);
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// lfs f3,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f31,f31,f13,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f13.f64 + ctx.f26.f64));
	// addic. r21,r21,-1
	ctx.xer.ca = ctx.r21.u32 > 0;
	ctx.r21.s64 = ctx.r21.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r21.s32, 0, ctx.xer);
	// fmsubs f27,f27,f13,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f24.f64));
	// lfs f24,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f26,f18,f0
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfs f18,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// addi r11,r11,120
	ctx.r11.s64 = ctx.r11.s64 + 120;
	// fadds f1,f1,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// fsubs f19,f14,f3
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f3.f64));
	// fadds f29,f14,f3
	ctx.f29.f64 = double(float(ctx.f14.f64 + ctx.f3.f64));
	// lfs f3,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f24,f24,f13,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f18.f64));
	// fadds f18,f3,f17
	ctx.f18.f64 = double(float(ctx.f3.f64 + ctx.f17.f64));
	// fsubs f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f3.f64));
	// fsubs f2,f11,f9
	ctx.f2.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fsubs f8,f28,f8
	ctx.f8.f64 = double(float(ctx.f28.f64 - ctx.f8.f64));
	// fmsubs f28,f16,f13,f15
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f16,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f16.f64 = double(temp.f32);
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// lfs f9,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f9.f64 = double(temp.f32);
	// fadds f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fadds f9,f20,f9
	ctx.f9.f64 = double(float(ctx.f20.f64 + ctx.f9.f64));
	// fmuls f3,f29,f0
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f29,f19,f0
	ctx.f29.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmuls f19,f18,f0
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f18,f17,f0
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f17,f2,f16
	ctx.f17.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// fsubs f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f16.f64));
	// fadds f16,f6,f10
	ctx.f16.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f6,f27,f31
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fsubs f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// fadds f27,f8,f26
	ctx.f27.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// fsubs f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f26.f64));
	// fadds f26,f24,f28
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// lfs f24,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f15,f24,f3
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f3.f64));
	// stfsx f15,r5,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f3,f3,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f24.f64));
	// fsubs f24,f21,f18
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fsubs f18,f17,f19
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfsx f18,r5,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// stfsx f3,r7,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f3,f19,f17
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfsx f3,r7,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f2,f29
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// stfsx f24,r31,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// stfsx f3,r31,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f16,f6
	ctx.f3.f64 = double(float(ctx.f16.f64 - ctx.f6.f64));
	// stfsx f21,r30,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f6,f16
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f16.f64));
	// stfsx f2,r30,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f2,f27,f26
	ctx.f2.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// stfsx f3,r23,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fsubs f3,f8,f31
	ctx.f3.f64 = double(float(ctx.f8.f64 - ctx.f31.f64));
	// stfsx f2,r23,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f31,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f8.f64));
	// stfsx f6,r25,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfsx f6,r25,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f10,f28
	ctx.f6.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// stfsx f6,r24,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// stfsx f3,r24,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// stfsx f10,r22,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f23,f22
	ctx.f10.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfsx f8,r22,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f6.f64 = double(temp.f32);
	// fadds f8,f30,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 + ctx.f8.f64));
	// fadds f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// fadds f3,f8,f10
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// fadds f5,f4,f1
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f8,f11,f7
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// fsubs f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f7,f6,f9
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// fsubs f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fsubs f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfsx f6,r10,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f3,f5
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f5,f11,f10
	ctx.f5.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fsubs f3,f8,f7
	ctx.f3.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfs f6,0(r3)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f8,f4,f9
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f9.f64));
	// stfsx f8,r8,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// stfsx f5,r8,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// add r3,r20,r3
	ctx.r3.u64 = ctx.r20.u64 + ctx.r3.u64;
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,3532(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + 3532);
	// add r4,r20,r4
	ctx.r4.u64 = ctx.r20.u64 + ctx.r4.u64;
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d6e75c
	if (!ctx.cr0.eq) goto loc_82D6E75C;
loc_82D6EE24:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82e28f2c
	ctx.lr = 0x82D6EE2C;
	__restfpr_14(ctx, base);
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6EE30"))) PPC_WEAK_FUNC(sub_82D6EE30);
PPC_FUNC_IMPL(__imp__sub_82D6EE30) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1584
	ctx.r5.s64 = ctx.r11.s64 + 1584;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,-6376
	ctx.r4.s64 = ctx.r11.s64 + -6376;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6EE48"))) PPC_WEAK_FUNC(sub_82D6EE48);
PPC_FUNC_IMPL(__imp__sub_82D6EE48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D6EE50;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D6EE58;
	__savefpr_14(ctx, base);
	// mulli r11,r7,112
	ctx.r11.s64 = ctx.r7.s64 * 112;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d6f584
	if (!ctx.cr6.lt) goto loc_82D6F584;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// stw r10,-324(r1)
	PPC_STORE_U32(ctx.r1.u32 + -324, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lfs f13,-7588(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lfs f0,-7584(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-28552(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f11.f64 = double(temp.f32);
	// stw r10,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r10.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f9,-12288(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -12288);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-7592(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7592);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f12.f64 = double(temp.f32);
loc_82D6EEA8:
	// mulli r8,r6,40
	ctx.r8.s64 = ctx.r6.s64 * 40;
	// lfs f8,32(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f8.f64 = double(temp.f32);
	// mulli r5,r6,20
	ctx.r5.s64 = ctx.r6.s64 * 20;
	// lfs f7,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f2,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f29,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f8,f29
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// add r26,r3,r8
	ctx.r26.u64 = ctx.r3.u64 + ctx.r8.u64;
	// fmuls f29,f7,f29
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// add r27,r5,r4
	ctx.r27.u64 = ctx.r5.u64 + ctx.r4.u64;
	// mulli r10,r6,24
	ctx.r10.s64 = ctx.r6.s64 * 24;
	// lfs f27,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f6,f27
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f28,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// lfsx f25,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f7,f7,f28,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 + ctx.f19.f64));
	// lfsx f24,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// add r25,r4,r8
	ctx.r25.u64 = ctx.r4.u64 + ctx.r8.u64;
	// fmsubs f8,f8,f28,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmuls f29,f4,f25
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// mulli r31,r6,44
	ctx.r31.s64 = ctx.r6.s64 * 44;
	// fmuls f28,f3,f25
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f25,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f5,f5,f26,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64 + ctx.f18.f64));
	// lfsx f21,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f6,f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 - ctx.f27.f64));
	// mulli r9,r6,36
	ctx.r9.s64 = ctx.r6.s64 * 36;
	// fmadds f3,f3,f24,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 + ctx.f29.f64));
	// fmsubs f4,f4,f24,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f28.f64));
	// lfs f24,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f27,f2,f23
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfsx f22,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f29,f5,f7
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// add r24,r31,r4
	ctx.r24.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fadds f7,f6,f8
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// mulli r30,r6,56
	ctx.r30.s64 = ctx.r6.s64 * 56;
	// fsubs f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fmuls f26,f1,f23
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// lfs f23,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f1,f1,f22,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f27.f64));
	// lfs f27,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// rlwinm r7,r6,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f8,f5,f12
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// add r23,r8,r3
	ctx.r23.u64 = ctx.r8.u64 + ctx.r3.u64;
	// fadds f28,f7,f30
	ctx.f28.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// add r22,r8,r4
	ctx.r22.u64 = ctx.r8.u64 + ctx.r4.u64;
	// fadds f5,f29,f31
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// add r21,r30,r4
	ctx.r21.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fnmsubs f7,f7,f11,f30
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f11.f64 - ctx.f30.f64)));
	// lfs f30,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f31,f29,f11,f31
	ctx.f31.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f31.f64)));
	// lfs f29,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f30,f21
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// add r20,r7,r3
	ctx.r20.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fmuls f21,f29,f21
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f21.f64));
	// add r19,r7,r4
	ctx.r19.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmsubs f2,f2,f22,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f26.f64));
	// lfs f26,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f26.f64 = double(temp.f32);
	// lfs f22,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f18,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f29,f29,f20,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfsx f19,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f30,f30,f20,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f21,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f27,f21
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fmuls f21,f26,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// rlwinm r29,r6,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fmuls f15,f24,f19
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// mulli r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 * 12;
	// fmuls f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmuls f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// fmuls f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmadds f26,f26,f20,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f16.f64));
	// add r17,r29,r4
	ctx.r17.u64 = ctx.r29.u64 + ctx.r4.u64;
	// mulli r7,r6,48
	ctx.r7.s64 = ctx.r6.s64 * 48;
	// fmsubs f21,f27,f20,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f27,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f25,f25,f18,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f23,f23,f27,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 - ctx.f14.f64));
	// fmadds f24,f24,f18,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f19.f64));
	// fmadds f27,f22,f27,f17
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 + ctx.f17.f64));
	// fadds f22,f26,f29
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f26,f26,f29
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// mulli r18,r6,52
	ctx.r18.s64 = ctx.r6.s64 * 52;
	// fadds f29,f21,f30
	ctx.f29.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// fsubs f20,f30,f21
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f30,f23,f25
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f21,f27,f24
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fsubs f24,f27,f24
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// rlwinm r28,r6,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// add r16,r18,r3
	ctx.r16.u64 = ctx.r18.u64 + ctx.r3.u64;
	// add r18,r18,r4
	ctx.r18.u64 = ctx.r18.u64 + ctx.r4.u64;
	// add r15,r28,r4
	ctx.r15.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fadds f19,f29,f4
	ctx.f19.f64 = double(float(ctx.f29.f64 + ctx.f4.f64));
	// fnmsubs f4,f29,f11,f4
	ctx.f4.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f4.f64)));
	// fmuls f27,f20,f12
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmuls f29,f25,f12
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fadds f18,f21,f1
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fnmsubs f1,f21,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f21.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// fadds f20,f22,f3
	ctx.f20.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// fnmsubs f3,f22,f11,f3
	ctx.f3.f64 = double(float(-(ctx.f22.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// fadds f22,f30,f2
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fnmsubs f2,f30,f11,f2
	ctx.f2.f64 = double(float(-(ctx.f30.f64 * ctx.f11.f64 - ctx.f2.f64)));
	// fadds f25,f4,f26
	ctx.f25.f64 = double(float(ctx.f4.f64 + ctx.f26.f64));
	// stfs f25,-320(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f4,f4,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f26.f64));
	// stfs f4,-352(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f26,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-360(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fsubs f4,f1,f29
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfs f4,-348(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f4,f29,f1
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// lfs f1,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,-356(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fsubs f30,f3,f27
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f27.f64));
	// lfsx f1,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// stfs f1,-336(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfsx f1,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f16,f2,f24
	ctx.f16.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// stfs f1,-340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// lfsx f1,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f27,f18,f20
	ctx.f27.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f4,-312(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfsx f4,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfs f24,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f15,f4
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// stfs f1,-332(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f25,f24,f4
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// lfsx f1,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,-328(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f29,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfs f4,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f4.f64 = double(temp.f32);
	// lfs f1,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f4,f29
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f14,f1,f29
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// lfs f29,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f26.f64));
	// lfs f26,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f26.f64 = double(temp.f32);
	// stfs f29,-356(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fmr f29,f26
	ctx.f29.f64 = ctx.f26.f64;
	// lfs f26,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// mulli r14,r6,28
	ctx.r14.s64 = ctx.r6.s64 * 28;
	// fsubs f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fmadds f25,f15,f29,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f29.f64 + ctx.f25.f64));
	// fmsubs f24,f24,f29,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 - ctx.f23.f64));
	// lfs f29,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// lfs f29,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f1,f1,f29,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f21.f64));
	// stfs f1,-364(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fmsubs f4,f4,f29,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f14.f64));
	// stfs f4,-368(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f29,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f29.f64 = double(temp.f32);
	// lfs f1,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f1,f29
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// lfs f4,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f4,f29
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// lfs f23,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f29.f64 = double(temp.f32);
	// stw r14,-336(r1)
	PPC_STORE_U32(ctx.r1.u32 + -336, ctx.r14.u32);
	// fmadds f26,f26,f23,f29
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f23.f64 + ctx.f29.f64));
	// lfs f29,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f29.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmsubs f23,f29,f23,f15
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f23.f64 - ctx.f15.f64));
	// lfs f29,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f4,f4,f29,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f14.f64));
	// stfs f4,-340(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fmadds f21,f1,f29,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f21.f64));
	// lfs f29,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f29.f64 = double(temp.f32);
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// lfs f4,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f4.f64 = double(temp.f32);
	// fadds f15,f4,f25
	ctx.f15.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// lfs f4,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// stfs f4,-360(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f4,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f14,f4,f29
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// stfs f15,-332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f29,f1,f29
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// stfs f29,-328(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f29,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fadds f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// stfs f15,-356(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fmadds f19,f1,f29,f14
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f14.f64));
	// lfs f1,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f15,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f29,f4,f29,f14
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f14.f64));
	// lfs f4,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f4.f64 = double(temp.f32);
	// stw r14,-364(r1)
	PPC_STORE_U32(ctx.r1.u32 + -364, ctx.r14.u32);
	// fsubs f25,f4,f25
	ctx.f25.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// lwz r14,-336(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	// lfs f4,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f4,f11,f26
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f26.f64)));
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fmuls f14,f22,f13
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// stw r14,-328(r1)
	PPC_STORE_U32(ctx.r1.u32 + -328, ctx.r14.u32);
	// fmuls f26,f25,f12
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f25,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f23
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f23.f64)));
	// fsubs f24,f4,f1
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f1.f64));
	// fadds f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// stfs f4,-316(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f1,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f1.f64 = double(temp.f32);
	// fadds f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f4,-368(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fsubs f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f4,-360(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f4,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f4.f64 = double(temp.f32);
	// lwz r14,-364(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	// lfs f26,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f4,f26
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// fmuls f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lwz r14,-328(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	// lfs f25,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f1,f1,f25,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64 + ctx.f23.f64));
	// fmsubs f4,f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64 - ctx.f26.f64));
	// fsubs f25,f1,f19
	ctx.f25.f64 = double(float(ctx.f1.f64 - ctx.f19.f64));
	// fadds f26,f1,f19
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f19.f64));
	// lfs f19,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f19.f64 = double(temp.f32);
	// fadds f1,f4,f29
	ctx.f1.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fsubs f29,f29,f4
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f18,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f4,f25,f12
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fadds f25,f26,f21
	ctx.f25.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// fadds f23,f1,f19
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f19.f64));
	// fnmsubs f26,f26,f11,f21
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// lfs f21,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fnmsubs f1,f1,f11,f19
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f19.f64)));
	// fadds f21,f25,f21
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// fsubs f19,f15,f23
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// fsubs f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fadds f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// fadds f26,f1,f4
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fsubs f25,f18,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 - ctx.f25.f64));
	// fadds f1,f21,f27
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// fsubs f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// fmuls f21,f19,f13
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// stfs f21,-328(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmadds f21,f19,f0,f14
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f14.f64));
	// fsubs f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// fadds f19,f1,f5
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// stfs f19,0(r3)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fnmsubs f5,f1,f9,f5
	ctx.f5.f64 = double(float(-(ctx.f1.f64 * ctx.f9.f64 - ctx.f5.f64)));
	// fmuls f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// fadds f1,f5,f27
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f27.f64));
	// fsubs f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f27.f64));
	// lfs f27,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f19,f1,f21
	ctx.f19.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfsx f19,r9,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f19,f23,f17
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// lfs f17,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f4.f64));
	// stfs f17,-356(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fadds f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f21.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f21.f64 = double(temp.f32);
	// fadds f1,f15,f24
	ctx.f1.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// fadds f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// lfs f23,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f2.f64));
	// lfs f17,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fsubs f27,f24,f15
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// fmuls f24,f20,f13
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fadds f4,f17,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 + ctx.f4.f64));
	// lfs f17,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f17.f64 = double(temp.f32);
	// fadds f2,f17,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// fmuls f17,f23,f13
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// stfs f27,-328(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f27,f7,f8
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// stfs f27,-340(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fadds f27,f21,f1
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fmsubs f22,f22,f0,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 - ctx.f14.f64));
	// stfs f27,-332(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f27,f1,f21
	ctx.f27.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// fmuls f21,f25,f13
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmadds f25,f25,f0,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fsubs f14,f31,f6
	ctx.f14.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// fsubs f24,f5,f22
	ctx.f24.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfsx f24,r7,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// stfs f27,-336(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f27,f2,f4
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fadds f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// lfs f1,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f1,f13
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f24,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f1,f19,f9,f28
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f9.f64 - ctx.f28.f64)));
	// fadds f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// fmsubs f28,f20,f0,f21
	ctx.f28.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 - ctx.f21.f64));
	// fmadds f24,f24,f0,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f17.f64));
	// stfsx f5,r8,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f5,f23,f0,f15
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 - ctx.f15.f64));
	// lfs f23,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f30,f13
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f22,f23,f13
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// stfs f19,0(r4)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f19,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f19.f64 = double(temp.f32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fadds f7,f31,f6
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// addi r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 + 112;
	// fmadds f23,f23,f0,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fmsubs f30,f30,f0,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f22.f64));
	// lfs f22,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f22,f14
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// fnmsubs f22,f22,f9,f14
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f9.f64 - ctx.f14.f64)));
	// fadds f21,f1,f18
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f18.f64));
	// fsubs f1,f1,f18
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f18.f64));
	// fadds f20,f19,f22
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fsubs f19,f21,f25
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// stfsx f19,r10,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f1,f28
	ctx.f25.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfsx f25,r8,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// stfsx f1,r7,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// stfsx f17,r5,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fsubs f19,f4,f2
	ctx.f19.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfs f21,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f21.f64 = double(temp.f32);
	// lwz r10,-324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	// fadds f28,f29,f21
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// fsubs f6,f21,f29
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fsubs f1,f20,f24
	ctx.f1.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stfsx f1,r30,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f1,f20,f24
	ctx.f1.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// stfsx f1,r31,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f1,f22,f5
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f5.f64));
	// stfsx f1,r28,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// lfs f24,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f24.f64 = double(temp.f32);
	// lfs f20,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f20.f64 = double(temp.f32);
	// fadds f1,f24,f16
	ctx.f1.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// stfsx f5,r29,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f20,f26
	ctx.f5.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// lfs f22,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f29,f19,f10
	ctx.f29.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fadds f25,f22,f3
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f4,f3,f22
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// fsubs f3,f20,f26
	ctx.f3.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// lfs f26,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f31,f27,f9,f26
	ctx.f31.f64 = double(float(-(ctx.f27.f64 * ctx.f9.f64 - ctx.f26.f64)));
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// stfs f27,0(r27)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f2,f24,f16
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// fadds f27,f1,f5
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fadds f5,f25,f28
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fmuls f25,f6,f13
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fadds f26,f29,f31
	ctx.f26.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// fmuls f24,f4,f13
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f22,f3,f13
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f21,f2,f13
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fsubs f31,f31,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// fadds f29,f27,f8
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f8.f64));
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fnmsubs f8,f27,f9,f8
	ctx.f8.f64 = double(float(-(ctx.f27.f64 * ctx.f9.f64 - ctx.f8.f64)));
	// fmuls f28,f28,f10
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// fmsubs f4,f4,f0,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fadds f25,f5,f7
	ctx.f25.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fnmsubs f7,f5,f9,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f9.f64 - ctx.f7.f64)));
	// fsubs f5,f26,f23
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f5,0(r24)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fadds f5,f26,f23
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// stfs f5,0(r21)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fmadds f6,f6,f0,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fmsubs f2,f2,f0,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f22.f64));
	// fmadds f3,f3,f0,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fadds f5,f31,f30
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f30.f64));
	// stfs f5,0(r15)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// fsubs f5,f31,f30
	ctx.f5.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// stfs f5,0(r17)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// fsubs f5,f8,f1
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// stfs f29,0(r25)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fadds f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f1.f64));
	// lwz r10,-364(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	// fsubs f1,f7,f28
	ctx.f1.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// fadds f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f28.f64));
	// fadds f31,f5,f4
	ctx.f31.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// stfs f31,0(r14)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f5,0(r18)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fsubs f5,f8,f6
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f5,0(r22)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,0(r19)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// stfs f25,0(r26)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fadds f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// stfs f8,0(r16)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fsubs f8,f7,f3
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f8,0(r20)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fadds f8,f7,f3
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// stfs f8,0(r23)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// lwz r10,3532(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// lwz r10,-344(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r10.u32);
	// bne 0x82d6eea8
	if (!ctx.cr0.eq) goto loc_82D6EEA8;
loc_82D6F584:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D6F58C;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6F590"))) PPC_WEAK_FUNC(sub_82D6F590);
PPC_FUNC_IMPL(__imp__sub_82D6F590) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1656
	ctx.r5.s64 = ctx.r11.s64 + 1656;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,-4536
	ctx.r4.s64 = ctx.r11.s64 + -4536;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6F5A8"))) PPC_WEAK_FUNC(sub_82D6F5A8);
PPC_FUNC_IMPL(__imp__sub_82D6F5A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D6F5B0;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D6F5B8;
	__savefpr_14(ctx, base);
	// mulli r11,r7,88
	ctx.r11.s64 = ctx.r7.s64 * 88;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d6f9f4
	if (!ctx.cr6.lt) goto loc_82D6F9F4;
	// rlwinm r15,r9,2,0,29
	ctx.r15.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// subf r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D6F5E4:
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f12,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r9,r6,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f11,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// add r30,r10,r3
	ctx.r30.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f10,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// add r28,r9,r3
	ctx.r28.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f9,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f9.f64 = double(temp.f32);
	// mulli r5,r6,20
	ctx.r5.s64 = ctx.r6.s64 * 20;
	// lfs f6,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f5,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// lfs f31,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f21,f12,f31
	ctx.f21.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// lfs f29,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f31,f11,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f8,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f20,f10,f29
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfs f1,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// add r29,r10,r4
	ctx.r29.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// rlwinm r31,r6,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f7,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f7.f64 = double(temp.f32);
	// add r25,r5,r3
	ctx.r25.u64 = ctx.r5.u64 + ctx.r3.u64;
	// lfs f4,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// add r27,r9,r4
	ctx.r27.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// add r24,r31,r3
	ctx.r24.u64 = ctx.r31.u64 + ctx.r3.u64;
	// mulli r7,r6,36
	ctx.r7.s64 = ctx.r6.s64 * 36;
	// lfs f30,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f11,f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f25,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f12,f12,f30,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f31.f64));
	// lfs f28,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f31,f6,f25
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfs f23,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f9,f9,f28,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f20.f64));
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// lfs f29,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f21,f2,f23
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f28,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f28.f64 = double(temp.f32);
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmuls f30,f5,f25
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// add r26,r7,r3
	ctx.r26.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fmuls f23,f1,f23
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// lfs f25,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f25.f64 = double(temp.f32);
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// rlwinm r23,r6,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r22,r6,40
	ctx.r22.s64 = ctx.r6.s64 * 40;
	// lfs f24,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lfs f27,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f5,f5,f24,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f31.f64));
	// lfs f22,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fadds f31,f9,f11
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fmuls f19,f8,f27
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// lfs f26,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f9,f9,f11
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fadds f11,f10,f12
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// fmadds f1,f1,f22,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f21.f64));
	// add r21,r23,r3
	ctx.r21.u64 = ctx.r23.u64 + ctx.r3.u64;
	// fsubs f10,f12,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// add r20,r22,r3
	ctx.r20.u64 = ctx.r22.u64 + ctx.r3.u64;
	// fmsubs f2,f2,f22,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f23.f64));
	// mulli r10,r6,24
	ctx.r10.s64 = ctx.r6.s64 * 24;
	// fmsubs f6,f6,f24,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f30.f64));
	// lfs f24,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f7,f7,f26,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f19.f64));
	// fmuls f12,f9,f0
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fnmsubs f9,f31,f13,f4
	ctx.f9.f64 = double(float(-(ctx.f31.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfs f27,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f27.f64 = double(temp.f32);
	// fadds f23,f1,f5
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// lfs f26,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// mulli r9,r6,12
	ctx.r9.s64 = ctx.r6.s64 * 12;
	// fnmsubs f30,f11,f13,f3
	ctx.f30.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// fsubs f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// add r23,r23,r4
	ctx.r23.u64 = ctx.r23.u64 + ctx.r4.u64;
	// add r22,r22,r4
	ctx.r22.u64 = ctx.r22.u64 + ctx.r4.u64;
	// fadds f5,f2,f6
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// lfsx f19,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f16,f23,f13,f7
	ctx.f16.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// stfs f16,-316(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f2,f2,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f6.f64));
	// lfs f21,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f6,f1,f0
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f1,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f28,f1
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// lfs f22,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f27,f21
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// lfs f20,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f26,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// lfsx f18,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f7,f23,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 + ctx.f7.f64));
	// lfs f23,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f17,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// fadds f11,f11,f3
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// mulli r19,r6,44
	ctx.r19.s64 = ctx.r6.s64 * 44;
	// fnmsubs f16,f5,f13,f8
	ctx.f16.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// stfs f16,-312(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f16,f29,f1
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f1.f64));
	// mulli r18,r6,28
	ctx.r18.s64 = ctx.r6.s64 * 28;
	// fmuls f1,f25,f19
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// stfs f1,-320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fadds f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// lfs f31,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f29,f29,f22,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 - ctx.f15.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmsubs f27,f27,f20,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f21.f64));
	// fmadds f1,f28,f22,f16
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f16.f64));
	// fmadds f28,f26,f20,f14
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f14.f64));
	// lfs f20,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f24,f19
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// lfs f19,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// add r17,r19,r3
	ctx.r17.u64 = ctx.r19.u64 + ctx.r3.u64;
	// add r16,r18,r3
	ctx.r16.u64 = ctx.r18.u64 + ctx.r3.u64;
	// add r19,r19,r4
	ctx.r19.u64 = ctx.r19.u64 + ctx.r4.u64;
	// add r18,r18,r4
	ctx.r18.u64 = ctx.r18.u64 + ctx.r4.u64;
	// fmsubs f25,f25,f18,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 - ctx.f22.f64));
	// lfs f21,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f24,f18,f21
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f21.f64));
	// lfs f21,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// fadds f24,f28,f1
	ctx.f24.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f28,f1,f28
	ctx.f28.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// fadds f1,f27,f29
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fsubs f27,f27,f29
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// fmuls f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmuls f29,f28,f0
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fnmsubs f22,f1,f13,f25
	ctx.f22.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// fmuls f28,f27,f0
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f25.f64));
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f27,f24,f13,f26
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfsx f24,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// fadds f3,f11,f1
	ctx.f3.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// fsubs f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// fadds f5,f26,f4
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f4.f64));
	// fsubs f4,f4,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f26.f64));
	// fmadds f1,f25,f24,f18
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f25,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f26,f23,f24,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f24.f64 - ctx.f17.f64));
	// lfs f23,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f21,f25
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// lfs f24,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f19,f23
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfs f18,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f20,f25
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmuls f23,f31,f23
	ctx.f23.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// fmadds f25,f20,f24,f17
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f24.f64 + ctx.f17.f64));
	// fmadds f31,f31,f18,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f18.f64 + ctx.f15.f64));
	// fmsubs f24,f21,f24,f16
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 - ctx.f16.f64));
	// fmsubs f23,f19,f18,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f23.f64));
	// fadds f21,f31,f25
	ctx.f21.f64 = double(float(ctx.f31.f64 + ctx.f25.f64));
	// fsubs f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f31.f64));
	// fadds f31,f23,f24
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fadds f23,f21,f1
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// lfs f17,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f31,f26
	ctx.f20.f64 = double(float(ctx.f31.f64 + ctx.f26.f64));
	// lfs f16,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f31,f31,f13,f26
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// fnmsubs f1,f21,f13,f1
	ctx.f1.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// addi r11,r11,88
	ctx.r11.s64 = ctx.r11.s64 + 88;
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fadds f18,f16,f6
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f6.f64));
	// fsubs f6,f16,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 - ctx.f6.f64));
	// fadds f26,f7,f23
	ctx.f26.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// fsubs f7,f23,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 - ctx.f7.f64));
	// fadds f23,f8,f20
	ctx.f23.f64 = double(float(ctx.f8.f64 + ctx.f20.f64));
	// fsubs f8,f20,f8
	ctx.f8.f64 = double(float(ctx.f20.f64 - ctx.f8.f64));
	// fadds f19,f31,f25
	ctx.f19.f64 = double(float(ctx.f31.f64 + ctx.f25.f64));
	// fadds f20,f22,f29
	ctx.f20.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// fsubs f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// fsubs f31,f31,f25
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f25.f64));
	// fsubs f21,f5,f26
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// fsubs f26,f3,f23
	ctx.f26.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfs f5,0(r3)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f5,f23,f3
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f5,0(r4)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f5,f4,f8
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// stfsx f5,r9,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f7,f11
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f5,r9,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f5,f9,f10
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fadds f3,f27,f28
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// add r3,r15,r3
	ctx.r3.u64 = ctx.r15.u64 + ctx.r3.u64;
	// fadds f26,f1,f24
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// add r4,r15,r4
	ctx.r4.u64 = ctx.r15.u64 + ctx.r4.u64;
	// fadds f23,f17,f2
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// fadds f21,f30,f12
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f12.f64));
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fsubs f9,f27,f28
	ctx.f9.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// fsubs f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// fsubs f2,f17,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 - ctx.f2.f64));
	// fsubs f12,f30,f12
	ctx.f12.f64 = double(float(ctx.f30.f64 - ctx.f12.f64));
	// fadds f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// stfs f8,0(r26)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfs f11,0(r7)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fadds f11,f3,f5
	ctx.f11.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fadds f7,f23,f26
	ctx.f7.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fadds f4,f20,f21
	ctx.f4.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f30,f18,f19
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fadds f27,f9,f10
	ctx.f27.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f9,f2,f1
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// fsubs f8,f5,f3
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fsubs f28,f19,f18
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f1,f12,f29
	ctx.f1.f64 = double(float(ctx.f12.f64 + ctx.f29.f64));
	// fsubs f5,f26,f23
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// fsubs f3,f21,f20
	ctx.f3.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fsubs f12,f12,f29
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f29.f64));
	// fadds f29,f6,f31
	ctx.f29.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// fsubs f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// fsubs f31,f11,f7
	ctx.f31.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfs f31,0(r20)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fsubs f31,f4,f30
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// stfs f31,0(r22)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfs f11,0(r30)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fadds f11,f30,f4
	ctx.f11.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f11,0(r29)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fsubs f11,f8,f28
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// stfs f11,0(r16)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fadds f11,f28,f8
	ctx.f11.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// fadds f7,f5,f3
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// stfs f7,0(r18)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// stfs f11,0(r24)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fsubs f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fsubs f11,f27,f9
	ctx.f11.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// stfs f8,0(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// stfs f11,0(r21)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fsubs f8,f1,f29
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfs f8,0(r23)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fadds f11,f2,f12
	ctx.f11.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f9,f29,f1
	ctx.f9.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f9,f10,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// stfs f9,0(r17)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// stfs f11,0(r19)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fsubs f12,f12,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f2.f64));
	// stfs f10,0(r25)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r10,3532(r14)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r14.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d6f5e4
	if (!ctx.cr0.eq) goto loc_82D6F5E4;
loc_82D6F9F4:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D6F9FC;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6FA00"))) PPC_WEAK_FUNC(sub_82D6FA00);
PPC_FUNC_IMPL(__imp__sub_82D6FA00) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1728
	ctx.r5.s64 = ctx.r11.s64 + 1728;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,-2648
	ctx.r4.s64 = ctx.r11.s64 + -2648;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6FA18"))) PPC_WEAK_FUNC(sub_82D6FA18);
PPC_FUNC_IMPL(__imp__sub_82D6FA18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D6FA20;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28ee0
	ctx.lr = 0x82D6FA28;
	__savefpr_14(ctx, base);
	// mulli r11,r7,72
	ctx.r11.s64 = ctx.r7.s64 * 72;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d6fde0
	if (!ctx.cr6.lt) goto loc_82D6FDE0;
	// subf r23,r7,r8
	ctx.r23.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r22,r9,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f13,-7588(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7584(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-12288(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -12288);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-7592(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7592);
	ctx.f12.f64 = double(temp.f32);
loc_82D6FA64:
	// mulli r10,r6,20
	ctx.r10.s64 = ctx.r6.s64 * 20;
	// lfs f10,32(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f6,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f29,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f10,f29
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfsx f28,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// lfs f4,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r31,r6,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f2,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f2.f64 = double(temp.f32);
	// mulli r8,r6,36
	ctx.r8.s64 = ctx.r6.s64 * 36;
	// lfs f7,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f3,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f1.f64 = double(temp.f32);
	// lfs f31,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f25,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f27,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f23,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f8,f27
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmadds f9,f9,f28,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f19.f64));
	// lfsx f24,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r30,r6,24
	ctx.r30.s64 = ctx.r6.s64 * 24;
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmuls f29,f6,f25
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfsx f22,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f28,f5,f25
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// lfs f30,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f4,f23
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfsx f21,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f2,f21
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// fmuls f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// add r29,r31,r4
	ctx.r29.u64 = ctx.r31.u64 + ctx.r4.u64;
	// add r28,r30,r4
	ctx.r28.u64 = ctx.r30.u64 + ctx.r4.u64;
	// rlwinm r27,r6,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f5,f5,f24,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f29.f64));
	// rlwinm r26,r6,5,0,26
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fmsubs f6,f6,f24,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f28.f64));
	// add r25,r27,r3
	ctx.r25.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fmadds f3,f3,f22,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f25.f64));
	// lfs f28,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f29,f31,f9
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f9.f64));
	// lfs f20,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// fmsubs f4,f4,f22,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f23.f64));
	// lfs f27,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f1,f1,f20,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f2,f2,f20,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f23,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f7,f7,f26,f18
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f18.f64));
	// lfs f21,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// fadds f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// lfs f19,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f31,f30,f10
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f10.f64));
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// fadds f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f30.f64));
	// lfs f30,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fadds f22,f4,f8
	ctx.f22.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// fadds f20,f2,f6
	ctx.f20.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// mulli r5,r6,28
	ctx.r5.s64 = ctx.r6.s64 * 28;
	// fsubs f6,f2,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f6.f64));
	// fsubs f26,f7,f3
	ctx.f26.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fsubs f24,f1,f5
	ctx.f24.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// lfs f3,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// add r27,r27,r4
	ctx.r27.u64 = ctx.r27.u64 + ctx.r4.u64;
	// add r24,r26,r3
	ctx.r24.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fadds f2,f20,f22
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f2,-244(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// fadds f2,f6,f8
	ctx.f2.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f2,-248(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fadds f4,f24,f26
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfsx f17,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// add r26,r26,r4
	ctx.r26.u64 = ctx.r26.u64 + ctx.r4.u64;
	// stfs f17,-256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// lfs f2,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-252(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmuls f16,f30,f2
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// fmuls f2,f28,f2
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// lfs f1,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f18,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f25,f18
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f18.f64));
	// fmuls f15,f27,f18
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmuls f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// fmadds f28,f28,f1,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f1.f64 + ctx.f16.f64));
	// fmsubs f1,f30,f1,f2
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 - ctx.f2.f64));
	// lfs f2,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f2.f64 = double(temp.f32);
	// stfs f18,-256(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fmr f18,f2
	ctx.f18.f64 = ctx.f2.f64;
	// lfs f2,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f19,f2
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// fmadds f30,f25,f18,f15
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 + ctx.f15.f64));
	// fmuls f15,f3,f2
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f2,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f23,f23,f2,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f17.f64));
	// fmsubs f27,f27,f18,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f25,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f21,f2,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 + ctx.f25.f64));
	// lfs f2,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f3,f3,f2,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f2.f64 + ctx.f16.f64));
	// fmsubs f2,f19,f2,f15
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 - ctx.f15.f64));
	// fsubs f21,f28,f25
	ctx.f21.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fsubs f19,f3,f30
	ctx.f19.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fadds f30,f3,f30
	ctx.f30.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// fadds f18,f2,f27
	ctx.f18.f64 = double(float(ctx.f2.f64 + ctx.f27.f64));
	// fadds f25,f23,f1
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// fsubs f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// fsubs f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f27.f64));
	// fadds f3,f5,f7
	ctx.f3.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fadds f17,f19,f21
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f6,f21,f19
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fadds f16,f30,f28
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fadds f15,f18,f25
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fadds f27,f17,f4
	ctx.f27.f64 = double(float(ctx.f17.f64 + ctx.f4.f64));
	// fsubs f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f4.f64));
	// fsubs f4,f26,f24
	ctx.f4.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// fsubs f26,f22,f20
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f2,f1
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// fadds f23,f16,f3
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// fsubs f24,f16,f3
	ctx.f24.f64 = double(float(ctx.f16.f64 - ctx.f3.f64));
	// fmuls f19,f6,f13
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f20,f8,f13
	ctx.f20.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fnmsubs f1,f27,f11,f29
	ctx.f1.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f29.f64)));
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f29,r10,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f3,f17,f12
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f18,f4,f13
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f17,f26,f13
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f29,f25,f13
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fnmsubs f21,f23,f11,f9
	ctx.f21.f64 = double(float(-(ctx.f23.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// fadds f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmsubs f4,f4,f0,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fmadds f9,f6,f0,f18
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f18.f64));
	// fmadds f6,f25,f0,f17
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f17.f64));
	// fmsubs f29,f26,f0,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 - ctx.f29.f64));
	// lfs f26,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f2,f13
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fadds f27,f22,f26
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fmadds f2,f2,f0,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f20.f64));
	// fmsubs f8,f8,f0,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fsubs f25,f1,f3
	ctx.f25.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// fadds f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fadds f1,f21,f24
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fadds f22,f27,f31
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// fnmsubs f31,f27,f11,f31
	ctx.f31.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f31.f64)));
	// addi r11,r11,72
	ctx.r11.s64 = ctx.r11.s64 + 72;
	// fsubs f27,f25,f8
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f8.f64));
	// stfsx f27,r5,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f25,f8
	ctx.f8.f64 = double(float(ctx.f25.f64 + ctx.f8.f64));
	// stfsx f8,r7,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fsubs f8,f3,f2
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfsx f8,r8,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f3,f2
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// stfsx f8,r9,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f3,f1,f6
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// stfsx f22,r10,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f2,f1,f6
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fsubs f8,f31,f26
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// fadds f6,f31,f26
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f26.f64));
	// fsubs f1,f8,f4
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// stfsx f1,r7,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// stfsx f8,r5,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f6,f9
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// lfs f6,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f6.f64 = double(temp.f32);
	// stfsx f9,r8,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f7,f5
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fadds f9,f15,f6
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f6.f64));
	// stfs f23,0(r3)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f5,f15,f6
	ctx.f5.f64 = double(float(ctx.f15.f64 - ctx.f6.f64));
	// stfsx f3,r31,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f28,f30
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfsx f2,r30,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f6,f21,f24
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// add r3,r22,r3
	ctx.r3.u64 = ctx.r22.u64 + ctx.r3.u64;
	// fmuls f4,f8,f13
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fadds f2,f9,f10
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fnmsubs f10,f9,f11,f10
	ctx.f10.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f3,f7,f13
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fsubs f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// stfs f1,0(r25)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fadds f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// stfs f6,0(r24)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// stfs f2,0(r4)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// add r4,r22,r4
	ctx.r4.u64 = ctx.r22.u64 + ctx.r4.u64;
	// fmadds f9,f7,f0,f4
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fadds f7,f10,f5
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
	// fmsubs f8,f8,f0,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f3.f64));
	// fsubs f10,f10,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// fadds f6,f7,f9
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// stfs f6,0(r29)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f9,f10,f8
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfs f10,0(r26)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// lwz r10,3532(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d6fa64
	if (!ctx.cr0.eq) goto loc_82D6FA64;
loc_82D6FDE0:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28f2c
	ctx.lr = 0x82D6FDE8;
	__restfpr_14(ctx, base);
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6FDF0"))) PPC_WEAK_FUNC(sub_82D6FDF0);
PPC_FUNC_IMPL(__imp__sub_82D6FDF0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1800
	ctx.r5.s64 = ctx.r11.s64 + 1800;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,-1512
	ctx.r4.s64 = ctx.r11.s64 + -1512;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D6FE08"))) PPC_WEAK_FUNC(sub_82D6FE08);
PPC_FUNC_IMPL(__imp__sub_82D6FE08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D6FE10;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ee0
	ctx.lr = 0x82D6FE18;
	__savefpr_14(ctx, base);
	// rlwinm r11,r7,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82d701d0
	if (!ctx.cr6.lt) goto loc_82D701D0;
	// subf r25,r7,r8
	ctx.r25.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f12,-6140(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -6140);
	ctx.f12.f64 = double(temp.f32);
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lfs f10,-5076(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -5076);
	ctx.f10.f64 = double(temp.f32);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// stfs f12,-248(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f12,-6144(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -6144);
	ctx.f12.f64 = double(temp.f32);
	// stfs f10,-240(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f10,-5080(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -5080);
	ctx.f10.f64 = double(temp.f32);
	// stfs f12,-252(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f13,-28552(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,-6156(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -6156);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,-6160(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -6160);
	ctx.f11.f64 = double(temp.f32);
	// stfs f10,-244(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
loc_82D6FE84:
	// mulli r9,r6,24
	ctx.r9.s64 = ctx.r6.s64 * 24;
	// lfs f8,40(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f8.f64 = double(temp.f32);
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f7,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f4,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f27,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f8,f27
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// lfsx f26,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// lfs f31,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f31.f64 = double(temp.f32);
	// lfs f3,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f30.f64 = double(temp.f32);
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f29,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f10,f29
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfsx f28,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r7,r6,20
	ctx.r7.s64 = ctx.r6.s64 * 20;
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmadds f7,f7,f26,f18
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f18.f64));
	// lfs f1,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// rlwinm r5,r6,5,0,26
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// add r29,r7,r3
	ctx.r29.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fmadds f9,f9,f28,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f19.f64));
	// add r27,r5,r3
	ctx.r27.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r28,r7,r4
	ctx.r28.u64 = ctx.r7.u64 + ctx.r4.u64;
	// add r31,r8,r3
	ctx.r31.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r26,r5,r4
	ctx.r26.u64 = ctx.r5.u64 + ctx.r4.u64;
	// lfs f23,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// add r30,r8,r4
	ctx.r30.u64 = ctx.r8.u64 + ctx.r4.u64;
	// lfs f21,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f27,f4,f23
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f19,f31,f21
	ctx.f19.f64 = double(float(ctx.f31.f64 * ctx.f21.f64));
	// rlwinm r8,r6,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f26,f3,f23
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f22,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// lfs f25,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// lfs f20,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f29,f6,f25
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfs f24,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f28,f5,f25
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// mulli r7,r6,28
	ctx.r7.s64 = ctx.r6.s64 * 28;
	// lfs f25,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f3,f3,f22,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f27.f64));
	// lfs f27,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f30,f30,f20,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfsx f18,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f4,f4,f22,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f26.f64));
	// lfsx f19,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f31,f31,f20,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f20.f64 - ctx.f21.f64));
	// rlwinm r5,r6,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f5,f5,f24,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f29.f64));
	// lfs f26,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f26.f64 = double(temp.f32);
	// fadds f29,f7,f9
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// lfs f22,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f7,f7,f9
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// lfsx f20,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f9,f8,f10
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f8,f10,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fmsubs f6,f6,f24,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f28.f64));
	// lfsx f17,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f24,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f24.f64 = double(temp.f32);
	// fadds f21,f30,f3
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fsubs f30,f30,f3
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// fadds f3,f31,f4
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// fsubs f31,f4,f31
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// fmuls f10,f7,f0
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fnmsubs f7,f29,f13,f2
	ctx.f7.f64 = double(float(-(ctx.f29.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f28,f9,f13,f1
	ctx.f28.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// lfsx f30,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fadds f14,f3,f6
	ctx.f14.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f6,f3,f13,f6
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// stfs f6,-256(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fmuls f3,f25,f19
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// fmuls f6,f27,f30
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fadds f15,f21,f5
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// fmuls f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fnmsubs f5,f21,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fmuls f21,f24,f19
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// fmuls f19,f23,f17
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fadds f1,f7,f8
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fmadds f3,f24,f18,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f3.f64));
	// fmuls f24,f22,f17
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmadds f6,f26,f20,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f6.f64));
	// fmsubs f30,f27,f20,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f30.f64));
	// lfs f20,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fmsubs f27,f25,f18,f21
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 - ctx.f21.f64));
	// fmadds f26,f22,f16,f19
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f19.f64));
	// lfs f19,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f19.f64 = double(temp.f32);
	// fadds f29,f28,f10
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fsubs f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f10.f64));
	// fmsubs f25,f23,f16,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 - ctx.f24.f64));
	// fadds f24,f31,f5
	ctx.f24.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// fsubs f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// fsubs f22,f30,f27
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// fmuls f17,f24,f11
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// fmuls f16,f24,f12
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f27,f22,f0
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fadds f21,f30,f25
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// lfs f23,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f23.f64 = double(temp.f32);
	// fadds f31,f23,f4
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// fsubs f4,f23,f4
	ctx.f4.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// fadds f23,f3,f6
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fnmsubs f3,f30,f13,f25
	ctx.f3.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// fadds f25,f21,f14
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// fmadds f24,f31,f12,f17
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmsubs f31,f31,f11,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f11.f64 - ctx.f16.f64));
	// fadds f22,f23,f26
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fnmsubs f26,f23,f13,f26
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f7,f21,f0
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fadds f30,f22,f15
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// fadds f23,f27,f26
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f26,f3,f6
	ctx.f26.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fadds f3,f30,f2
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// stfs f3,0(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f18,f23,f19
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// fmuls f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// fnmsubs f3,f30,f13,f2
	ctx.f3.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// fmuls f28,f22,f0
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fadds f22,f9,f25
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f25.f64));
	// fnmsubs f9,f25,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f25.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fmuls f25,f27,f11
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fmadds f2,f26,f20,f18
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f18.f64));
	// fmsubs f30,f26,f19,f23
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 - ctx.f23.f64));
	// fadds f26,f3,f7
	ctx.f26.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfsx f26,r10,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// stfsx f7,r9,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfs f22,0(r4)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f7,f9,f28
	ctx.f7.f64 = double(float(ctx.f9.f64 - ctx.f28.f64));
	// stfsx f7,r9,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f28.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f24,f2
	ctx.f9.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// fsubs f3,f30,f31
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f31.f64));
	// fsubs f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// fadds f7,f31,f30
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f30.f64));
	// fadds f31,f9,f1
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fnmsubs f9,f9,f13,f1
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// stfsx f31,r5,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f31,f7,f29
	ctx.f31.f64 = double(float(ctx.f7.f64 + ctx.f29.f64));
	// stfsx f31,r5,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fnmsubs f7,f7,f13,f29
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// addi r11,r11,64
	ctx.r11.s64 = ctx.r11.s64 + 64;
	// fsubs f1,f9,f3
	ctx.f1.f64 = double(float(ctx.f9.f64 - ctx.f3.f64));
	// stfsx f1,r7,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// stfsx f9,r8,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f7,f2
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// stfsx f9,r8,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f3,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f9,f7,f2
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// lfs f7,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f5,f3
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fmuls f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// stfsx f9,r7,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fmuls f1,f27,f12
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// add r3,r3,r24
	ctx.r3.u64 = ctx.r3.u64 + ctx.r24.u64;
	// fmadds f9,f6,f12,f25
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f25.f64));
	// add r4,r4,r24
	ctx.r4.u64 = ctx.r4.u64 + ctx.r24.u64;
	// fmsubs f7,f4,f7,f2
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 - ctx.f2.f64));
	// fmadds f5,f4,f3,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f5.f64));
	// fmsubs f6,f6,f11,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64 - ctx.f1.f64));
	// fadds f4,f7,f9
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fsubs f7,f7,f9
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fsubs f9,f6,f5
	ctx.f9.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fadds f5,f4,f8
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// stfs f5,0(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fnmsubs f8,f4,f13,f8
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// fadds f5,f9,f10
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfs f5,0(r30)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f10,f9,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fsubs f9,f8,f6
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f9,f8,f6
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f9,0(r29)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f9,f10,f7
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fsubs f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// stfs f10,0(r26)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// lwz r10,3532(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d6fe84
	if (!ctx.cr0.eq) goto loc_82D6FE84;
loc_82D701D0:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f2c
	ctx.lr = 0x82D701D8;
	__restfpr_14(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D701E0"))) PPC_WEAK_FUNC(sub_82D701E0);
PPC_FUNC_IMPL(__imp__sub_82D701E0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1872
	ctx.r5.s64 = ctx.r11.s64 + 1872;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,-504
	ctx.r4.s64 = ctx.r11.s64 + -504;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D701F8"))) PPC_WEAK_FUNC(sub_82D701F8);
PPC_FUNC_IMPL(__imp__sub_82D701F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D70200;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ef4
	ctx.lr = 0x82D70208;
	__savefpr_19(ctx, base);
	// mulli r11,r7,56
	ctx.r11.s64 = ctx.r7.s64 * 56;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d7047c
	if (!ctx.cr6.lt) goto loc_82D7047C;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r29,r7,r8
	ctx.r29.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f0,140(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D7022C:
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// mulli r7,r6,28
	ctx.r7.s64 = ctx.r6.s64 * 28;
	// lfs f12,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f1,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f30,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f13,f1
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmuls f21,f11,f30
	ctx.f21.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfsx f31,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f1,f12,f1
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// mulli r5,r6,12
	ctx.r5.s64 = ctx.r6.s64 * 12;
	// fmuls f30,f10,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f5.f64 = double(temp.f32);
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f28,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f9,f28
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// lfs f3,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f12,f12,f31,f22
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 + ctx.f22.f64));
	// add r28,r7,r4
	ctx.r28.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmuls f28,f8,f28
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// mulli r8,r6,24
	ctx.r8.s64 = ctx.r6.s64 * 24;
	// fmsubs f13,f13,f31,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f1.f64));
	// lfs f2,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f26,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfs f29,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f7,f26
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// lfsx f24,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f31,f6,f26
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmsubs f11,f11,f29,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 - ctx.f30.f64));
	// lfsx f25,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f5,f24
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// add r27,r5,r4
	ctx.r27.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmuls f26,f4,f24
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// lfsx f23,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f10,f10,f29,f21
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64 + ctx.f21.f64));
	// rlwinm r31,r6,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r30,r6,20
	ctx.r30.s64 = ctx.r6.s64 * 20;
	// lfs f29,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f29.f64 = double(temp.f32);
	// lfs f27,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f8,f8,f27,f20
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 + ctx.f20.f64));
	// lfsx f24,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f6,f6,f25,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f1.f64));
	// fmsubs f7,f7,f25,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 - ctx.f31.f64));
	// lfsx f25,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f1,f4,f23,f30
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 + ctx.f30.f64));
	// add r26,r31,r3
	ctx.r26.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fmsubs f5,f5,f23,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f26.f64));
	// add r25,r30,r3
	ctx.r25.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fmsubs f9,f9,f27,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f28.f64));
	// lfs f28,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// fadds f31,f12,f3
	ctx.f31.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fsubs f12,f3,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 - ctx.f12.f64));
	// fsubs f30,f2,f13
	ctx.f30.f64 = double(float(ctx.f2.f64 - ctx.f13.f64));
	// fadds f13,f13,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f2.f64));
	// lfs f2,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// fadds f3,f8,f10
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// lfs f23,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fadds f27,f1,f6
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fadds f26,f5,f7
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// lfs f9,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f6,f6,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// lfs f5,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f9,f5
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fadds f1,f27,f31
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fadds f22,f26,f13
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f13.f64));
	// fsubs f31,f31,f27
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fsubs f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f26.f64));
	// fadds f4,f11,f10
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// fsubs f27,f30,f6
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// fsubs f26,f12,f7
	ctx.f26.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fmuls f19,f29,f23
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f23.f64));
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// fmuls f20,f2,f5
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fmuls f23,f28,f23
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmadds f5,f2,f24,f21
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f24.f64 + ctx.f21.f64));
	// fsubs f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fadds f10,f6,f30
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// fmadds f2,f28,f25,f19
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 + ctx.f19.f64));
	// fmsubs f9,f9,f24,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f24.f64 - ctx.f20.f64));
	// fmsubs f29,f29,f25,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f25.f64 - ctx.f23.f64));
	// fsubs f28,f5,f2
	ctx.f28.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fadds f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fsubs f2,f9,f29
	ctx.f2.f64 = double(float(ctx.f9.f64 - ctx.f29.f64));
	// fadds f9,f29,f9
	ctx.f9.f64 = double(float(ctx.f29.f64 + ctx.f9.f64));
	// fadds f29,f5,f3
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fsubs f25,f2,f28
	ctx.f25.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// fadds f24,f9,f8
	ctx.f24.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fsubs f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fsubs f5,f1,f29
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfsx f5,r10,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f3,f29,f1
	ctx.f3.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// stfs f3,0(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f5,f25,f4
	ctx.f5.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// fadds f3,f22,f24
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f3,0(r4)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// fsubs f3,f22,f24
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f31,f9
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f9.f64));
	// stfsx f3,r8,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f13,f8
	ctx.f9.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// stfsx f13,r8,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fmuls f13,f5,f0
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f9,f4,f0
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fsubs f8,f26,f13
	ctx.f8.f64 = double(float(ctx.f26.f64 - ctx.f13.f64));
	// stfsx f8,r7,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f26.f64));
	// fsubs f8,f27,f9
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// stfsx f8,r30,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// stfsx f13,r5,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f2,f28
	ctx.f13.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// fadds f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// stfsx f9,r31,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fadds f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fmuls f13,f9,f0
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fsubs f9,f12,f13
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfs f9,0(r25)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f9,f10,f11
	ctx.f9.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// stfs f13,0(r26)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fadds f13,f11,f10
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// stfs f13,0(r27)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// lwz r10,3532(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d7022c
	if (!ctx.cr0.eq) goto loc_82D7022C;
loc_82D7047C:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f40
	ctx.lr = 0x82D70484;
	__restfpr_19(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D70488"))) PPC_WEAK_FUNC(sub_82D70488);
PPC_FUNC_IMPL(__imp__sub_82D70488) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,1944
	ctx.r5.s64 = ctx.r11.s64 + 1944;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,504
	ctx.r4.s64 = ctx.r11.s64 + 504;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D704A0"))) PPC_WEAK_FUNC(sub_82D704A0);
PPC_FUNC_IMPL(__imp__sub_82D704A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D704A8;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ee0
	ctx.lr = 0x82D704B0;
	__savefpr_14(ctx, base);
	// mulli r11,r7,48
	ctx.r11.s64 = ctx.r7.s64 * 48;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d70778
	if (!ctx.cr6.lt) goto loc_82D70778;
	// subf r26,r7,r8
	ctx.r26.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r25,r9,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r5,-32234
	ctx.r5.s64 = -2112487424;
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f9,-4940(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -4940);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-4944(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -4944);
	ctx.f10.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f11,-4948(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -4948);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-4960(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -4960);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-4952(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -4952);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-4956(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4956);
	ctx.f0.f64 = double(temp.f32);
loc_82D704FC:
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f6,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// mulli r7,r6,24
	ctx.r7.s64 = ctx.r6.s64 * 24;
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f4.f64 = double(temp.f32);
	// lfs f31,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f31.f64 = double(temp.f32);
	// lfs f3,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f30,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// add r31,r8,r3
	ctx.r31.u64 = ctx.r8.u64 + ctx.r3.u64;
	// lfs f27,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// add r30,r7,r3
	ctx.r30.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfs f26,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// mulli r9,r6,20
	ctx.r9.s64 = ctx.r6.s64 * 20;
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f29,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfs f25,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f6,f29
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfsx f23,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f29,f5,f29
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfsx f21,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f4,f25
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// fmuls f15,f2,f23
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r5,r6,12
	ctx.r5.s64 = ctx.r6.s64 * 12;
	// fmuls f25,f3,f25
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// fmuls f14,f31,f21
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f21.f64));
	// lfsx f20,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f23,f1,f23
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// add r29,r5,r3
	ctx.r29.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fmadds f1,f1,f22,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f15.f64));
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmsubs f2,f2,f22,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f23.f64));
	// rlwinm r28,r6,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f28,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f19,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f29,f6,f28,f29
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f28.f64 - ctx.f29.f64));
	// lfs f24,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f6,f27,f19
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmsubs f4,f4,f24,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f25.f64));
	// lfs f18,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f5,f5,f28,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64 + ctx.f17.f64));
	// add r27,r28,r3
	ctx.r27.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fmadds f3,f3,f24,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 + ctx.f16.f64));
	// add r28,r28,r4
	ctx.r28.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fmsubs f25,f31,f20,f21
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f20.f64 - ctx.f21.f64));
	// fmadds f28,f30,f20,f14
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 + ctx.f14.f64));
	// fmadds f24,f26,f18,f6
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 + ctx.f6.f64));
	// fmuls f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fsubs f30,f29,f4
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// fadds f6,f3,f5
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f31,f3,f5
	ctx.f31.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fadds f3,f25,f2
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fadds f5,f4,f29
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fadds f4,f28,f1
	ctx.f4.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f29,f28,f1
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// lfs f1,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f28,f2,f25
	ctx.f28.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// lfs f2,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f25,f27,f18,f26
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 - ctx.f26.f64));
	// fmuls f26,f30,f13
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f27,f3,f10
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f23,f4,f10
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmadds f20,f28,f0,f26
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 + ctx.f26.f64));
	// lfs f26,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fnmadds f21,f5,f11,f27
	ctx.f21.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 + ctx.f27.f64)));
	// lfs f27,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fnmadds f22,f6,f11,f23
	ctx.f22.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 + ctx.f23.f64)));
	// fmuls f23,f2,f27
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// fmuls f27,f1,f27
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fmadds f1,f1,f26,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64 + ctx.f23.f64));
	// fmsubs f23,f2,f26,f27
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f26.f64 - ctx.f27.f64));
	// fadds f2,f1,f24
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// fsubs f27,f1,f24
	ctx.f27.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// fsubs f26,f25,f23
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f1,f23,f25
	ctx.f1.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// addic. r26,r26,-1
	ctx.xer.ca = ctx.r26.u32 > 0;
	ctx.r26.s64 = ctx.r26.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// fmuls f25,f27,f13
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// addi r11,r11,48
	ctx.r11.s64 = ctx.r11.s64 + 48;
	// fadds f23,f2,f4
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fmuls f24,f26,f13
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmadds f17,f2,f9,f8
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmuls f18,f2,f10
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fadds f19,f1,f3
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fmsubs f16,f31,f0,f25
	ctx.f16.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fadds f25,f23,f6
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// stfs f25,-224(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fmsubs f15,f30,f0,f24
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f24.f64));
	// fmadds f14,f1,f9,f7
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fadds f24,f22,f17
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// fmadds f25,f26,f12,f20
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f20.f64));
	// fnmadds f20,f4,f11,f18
	ctx.f20.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmadds f4,f4,f9,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fadds f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f5.f64));
	// fnmsubs f23,f29,f12,f16
	ctx.f23.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f16.f64)));
	// fnmsubs f22,f28,f12,f15
	ctx.f22.f64 = double(float(-(ctx.f28.f64 * ctx.f12.f64 - ctx.f15.f64)));
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fmadds f30,f30,f12,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f26.f64));
	// fmadds f26,f3,f9,f7
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fadds f19,f19,f7
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f7.f64));
	// lfs f18,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f8.f64));
	// stfs f18,0(r3)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f19,0(r4)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f19,f24,f22
	ctx.f19.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfsx f19,r9,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f21,f23
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfsx f24,r10,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f24,f21,f23
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfsx f24,r9,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmuls f23,f1,f10
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f24,f31,f13
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// add r3,r25,r3
	ctx.r3.u64 = ctx.r25.u64 + ctx.r3.u64;
	// fmuls f22,f6,f10
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// add r4,r25,r4
	ctx.r4.u64 = ctx.r25.u64 + ctx.r4.u64;
	// fmuls f19,f5,f10
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fmadds f6,f6,f9,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmuls f21,f27,f0
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmadds f5,f5,f9,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fnmadds f23,f3,f11,f23
	ctx.f23.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f23.f64)));
	// fmadds f24,f29,f0,f24
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fnmadds f2,f2,f11,f22
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 + ctx.f22.f64)));
	// fnmadds f1,f1,f11,f19
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 + ctx.f19.f64)));
	// fadds f8,f20,f6
	ctx.f8.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// fmadds f31,f31,f12,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 + ctx.f21.f64));
	// fadds f6,f23,f5
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// fmadds f7,f27,f12,f24
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 + ctx.f24.f64));
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fnmsubs f5,f28,f13,f30
	ctx.f5.f64 = double(float(-(ctx.f28.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fadds f2,f1,f26
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// fsubs f1,f8,f25
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f25.f64));
	// stfs f1,0(r30)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fnmsubs f3,f29,f13,f31
	ctx.f3.f64 = double(float(-(ctx.f29.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// fadds f8,f8,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f25.f64));
	// stfs f8,0(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfs f8,0(r8)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// fsubs f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// stfs f8,0(r7)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fsubs f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfs f8,0(r27)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f8,0(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// stfs f8,0(r28)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// lwz r10,3532(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d704fc
	if (!ctx.cr0.eq) goto loc_82D704FC;
loc_82D70778:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f2c
	ctx.lr = 0x82D70780;
	__restfpr_14(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D70788"))) PPC_WEAK_FUNC(sub_82D70788);
PPC_FUNC_IMPL(__imp__sub_82D70788) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2016
	ctx.r5.s64 = ctx.r11.s64 + 2016;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,1184
	ctx.r4.s64 = ctx.r11.s64 + 1184;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D707A0"))) PPC_WEAK_FUNC(sub_82D707A0);
PPC_FUNC_IMPL(__imp__sub_82D707A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D707A8;
	__savegprlr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82e28ef4
	ctx.lr = 0x82D707B0;
	__savefpr_19(ctx, base);
	// mulli r11,r7,40
	ctx.r11.s64 = ctx.r7.s64 * 40;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d70990
	if (!ctx.cr6.lt) goto loc_82D70990;
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// subf r5,r7,r8
	ctx.r5.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f13,-28552(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D707DC:
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfs f12,16(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r7,r6,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f21,f12,f31
	ctx.f21.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// lfs f7,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f31,f11,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfsx f30,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r31,r6,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f4,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f4.f64 = double(temp.f32);
	// add r30,r7,r4
	ctx.r30.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// add r29,r31,r3
	ctx.r29.u64 = ctx.r31.u64 + ctx.r3.u64;
	// lfs f3,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// mulli r8,r6,20
	ctx.r8.s64 = ctx.r6.s64 * 20;
	// lfs f2,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f29,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f20,f10,f29
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfsx f27,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// lfsx f26,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f19,f8,f27
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// lfs f28,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f12,f12,f30,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f31.f64));
	// lfsx f23,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// fmuls f31,f6,f25
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfsx f22,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmadds f11,f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f21.f64));
	// fmuls f30,f5,f25
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// lfs f1,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// fmadds f9,f9,f28,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f20.f64));
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmuls f29,f4,f23
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// lfs f24,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f7,f7,f26,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f19.f64));
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// fmadds f5,f5,f24,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f31.f64));
	// fmsubs f6,f6,f24,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f30.f64));
	// fsubs f30,f2,f11
	ctx.f30.f64 = double(float(ctx.f2.f64 - ctx.f11.f64));
	// fadds f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fmadds f31,f3,f22,f29
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f29.f64));
	// fmuls f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// fsubs f2,f9,f7
	ctx.f2.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f7,f8,f10
	ctx.f7.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fsubs f29,f1,f12
	ctx.f29.f64 = double(float(ctx.f1.f64 - ctx.f12.f64));
	// fadds f12,f12,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f1.f64));
	// fsubs f8,f5,f31
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// fadds f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// fmsubs f4,f4,f22,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f3.f64));
	// fadds f3,f8,f2
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fadds f1,f5,f9
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f2,f2,f8
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// fsubs f5,f9,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f5.f64));
	// fadds f8,f4,f6
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f9,f6,f4
	ctx.f9.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f4,f3,f30
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// stfsx f4,r10,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f31,f1,f11
	ctx.f31.f64 = double(float(ctx.f1.f64 + ctx.f11.f64));
	// fmuls f6,f2,f0
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f2,f8,f7
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fadds f4,f9,f10
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fnmsubs f10,f3,f13,f30
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fnmsubs f11,f1,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f7,f4,f13,f29
	ctx.f7.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// fadds f1,f2,f12
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// fnmsubs f12,f2,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// fadds f3,f4,f29
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fadds f4,f10,f9
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// stfsx f4,r9,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfsx f10,r8,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f11,f8
	ctx.f10.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fadds f9,f7,f6
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f7,f6
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// stfsx f9,r8,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f12,f5
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// stfs f31,0(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f5.f64));
	// stfsx f10,r7,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// stfs f11,0(r29)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// stfs f1,0(r4)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// stfs f9,0(r30)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// stfs f12,0(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lwz r10,3532(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d707dc
	if (!ctx.cr0.eq) goto loc_82D707DC;
loc_82D70990:
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82e28f40
	ctx.lr = 0x82D70998;
	__restfpr_19(ctx, base);
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D709A0"))) PPC_WEAK_FUNC(sub_82D709A0);
PPC_FUNC_IMPL(__imp__sub_82D709A0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2088
	ctx.r5.s64 = ctx.r11.s64 + 2088;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,1952
	ctx.r4.s64 = ctx.r11.s64 + 1952;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D709B8"))) PPC_WEAK_FUNC(sub_82D709B8);
PPC_FUNC_IMPL(__imp__sub_82D709B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D709C0;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28ef8
	ctx.lr = 0x82D709C8;
	__savefpr_20(ctx, base);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82d70b98
	if (!ctx.cr6.lt) goto loc_82D70B98;
	// subf r28,r7,r8
	ctx.r28.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f24,-12288(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -12288);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,-7592(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7592);
	ctx.f25.f64 = double(temp.f32);
	// lfs f13,-7588(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7584(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
loc_82D70A04:
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r8,r6,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// mulli r9,r6,12
	ctx.r9.s64 = ctx.r6.s64 * 12;
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f7,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r7,r6,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// add r5,r10,r3
	ctx.r5.u64 = ctx.r10.u64 + ctx.r3.u64;
	// add r30,r8,r3
	ctx.r30.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r31,r9,r3
	ctx.r31.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r29,r7,r3
	ctx.r29.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// lfs f2,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfs f29,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f12,f2
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// lfs f31,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f21,f8,f29
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// lfs f27,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f10,f31
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f20,f6,f27
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmuls f2,f11,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// lfs f1,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f29,f7,f29
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// lfs f28,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f31,f9,f31
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f30,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lfs f26,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fmadds f11,f11,f1,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f23.f64));
	// fmadds f7,f7,f28,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 + ctx.f21.f64));
	// fmadds f9,f9,f30,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f22.f64));
	// fmadds f5,f5,f26,f20
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64 + ctx.f20.f64));
	// fmsubs f12,f12,f1,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f1.f64 - ctx.f2.f64));
	// fmsubs f8,f8,f28,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmsubs f10,f10,f30,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 - ctx.f31.f64));
	// fmsubs f6,f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 - ctx.f27.f64));
	// fadds f2,f7,f11
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fsubs f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f7,f5,f9
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f9,f5,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fadds f5,f8,f12
	ctx.f5.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fadds f8,f6,f10
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// fadds f6,f7,f2
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// fsubs f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// fmuls f2,f12,f13
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fadds f1,f8,f5
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fmuls f31,f10,f13
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fsubs f5,f5,f8
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// fadds f30,f6,f4
	ctx.f30.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// stfs f30,0(r3)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fnmsubs f8,f6,f24,f4
	ctx.f8.f64 = double(float(-(ctx.f6.f64 * ctx.f24.f64 - ctx.f4.f64)));
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fmsubs f10,f10,f0,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f2.f64));
	// fadds f30,f1,f3
	ctx.f30.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// stfs f30,0(r4)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f31,f12,f0,f31
	ctx.f31.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f31.f64));
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fmuls f12,f7,f25
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// fmuls f7,f5,f25
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// fmuls f5,f11,f13
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmuls f30,f9,f13
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fnmsubs f6,f1,f24,f3
	ctx.f6.f64 = double(float(-(ctx.f1.f64 * ctx.f24.f64 - ctx.f3.f64)));
	// fmsubs f9,f9,f0,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fadds f5,f8,f12
	ctx.f5.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fsubs f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// fmadds f11,f11,f0,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f30.f64));
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// fsubs f6,f5,f31
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// stfs f6,0(r30)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fadds f6,f12,f10
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// stfs f6,0(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f6,f5,f31
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f31.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fsubs f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fsubs f12,f7,f9
	ctx.f12.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fadds f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// stfs f12,0(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// fadds f12,f7,f9
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// stfs f12,0(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lwz r10,3532(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d70a04
	if (!ctx.cr0.eq) goto loc_82D70A04;
loc_82D70B98:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82e28f44
	ctx.lr = 0x82D70BA0;
	__restfpr_20(ctx, base);
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D70BA8"))) PPC_WEAK_FUNC(sub_82D70BA8);
PPC_FUNC_IMPL(__imp__sub_82D70BA8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2160
	ctx.r5.s64 = ctx.r11.s64 + 2160;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,2488
	ctx.r4.s64 = ctx.r11.s64 + 2488;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D70BC0"))) PPC_WEAK_FUNC(sub_82D70BC0);
PPC_FUNC_IMPL(__imp__sub_82D70BC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D70BC8;
	__savegprlr_29(ctx, base);
	// stfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f29.u64);
	// stfd f30,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f31.u64);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82d70cec
	if (!ctx.cr6.lt) goto loc_82D70CEC;
	// rlwinm r30,r9,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
loc_82D70BF0:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,8(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f3,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// add r31,r7,r3
	ctx.r31.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r5,r9,r3
	ctx.r5.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f31,f0,f6
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f4,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f29,f10,f2
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmuls f30,f12,f4
	ctx.f30.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f13,f6
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// lfs f1,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmuls f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmadds f13,f13,f5,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f31.f64));
	// fmadds f9,f9,f1,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64 + ctx.f29.f64));
	// fmadds f11,f11,f3,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f0,f0,f5,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f5.f64 - ctx.f6.f64));
	// fmsubs f12,f12,f3,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 - ctx.f4.f64));
	// fmsubs f10,f10,f1,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f1.f64 - ctx.f2.f64));
	// fadds f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fsubs f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fadds f9,f0,f7
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f7.f64));
	// fsubs f0,f7,f0
	ctx.f0.f64 = double(float(ctx.f7.f64 - ctx.f0.f64));
	// fadds f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fsubs f10,f6,f8
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f8,f6
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f10,0(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fsubs f10,f0,f11
	ctx.f10.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// fadds f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fadds f11,f9,f7
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f11,f9,f7
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// stfsx f11,r10,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f13,f12
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// stfs f11,0(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f13,0(r5)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfsx f10,r9,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// stfs f0,0(r7)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lwz r10,3532(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 3532);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82d70bf0
	if (!ctx.cr0.eq) goto loc_82D70BF0;
loc_82D70CEC:
	// lfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f30,-48(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D70D00"))) PPC_WEAK_FUNC(sub_82D70D00);
PPC_FUNC_IMPL(__imp__sub_82D70D00) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2232
	ctx.r5.s64 = ctx.r11.s64 + 2232;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,3008
	ctx.r4.s64 = ctx.r11.s64 + 3008;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D70D18"))) PPC_WEAK_FUNC(sub_82D70D18);
PPC_FUNC_IMPL(__imp__sub_82D70D18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82d70e18
	if (!ctx.cr6.lt) goto loc_82D70E18;
	// rlwinm r31,r9,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f3,-7656(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -7656);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,-28552(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28552);
	ctx.f4.f64 = double(temp.f32);
loc_82D70D4C:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// add r7,r9,r3
	ctx.r7.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// add r5,r8,r3
	ctx.r5.u64 = ctx.r8.u64 + ctx.r3.u64;
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lfs f8,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// lfs f6,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f0,f8
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// fmuls f1,f12,f6
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// lfs f7,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f11,f6
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f5,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f8,f13,f8
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fmadds f13,f13,f7,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f7.f64 + ctx.f2.f64));
	// fmadds f11,f11,f5,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64 + ctx.f1.f64));
	// fmsubs f12,f12,f5,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 - ctx.f6.f64));
	// fmsubs f0,f0,f7,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 - ctx.f8.f64));
	// fadds f8,f11,f13
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fadds f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fmuls f0,f11,f3
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fadds f11,f8,f10
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f11,f13,f9
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f12,f12,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fnmsubs f11,f8,f4,f10
	ctx.f11.f64 = double(float(-(ctx.f8.f64 * ctx.f4.f64 - ctx.f10.f64)));
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fnmsubs f13,f13,f4,f9
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f4.f64 - ctx.f9.f64)));
	// fsubs f10,f11,f12
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// stfs f10,0(r5)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// stfs f12,0(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fadds f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lwz r9,3532(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// xor r6,r9,r6
	ctx.r6.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// bne 0x82d70d4c
	if (!ctx.cr0.eq) goto loc_82D70D4C;
loc_82D70E18:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D70E28"))) PPC_WEAK_FUNC(sub_82D70E28);
PPC_FUNC_IMPL(__imp__sub_82D70E28) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2304
	ctx.r5.s64 = ctx.r11.s64 + 2304;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,3352
	ctx.r4.s64 = ctx.r11.s64 + 3352;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D70E40"))) PPC_WEAK_FUNC(sub_82D70E40);
PPC_FUNC_IMPL(__imp__sub_82D70E40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r10,r11,r5
	ctx.r10.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bgelr cr6
	if (!ctx.cr6.lt) return;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r7,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
loc_82D70E5C:
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f12,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f0,f10
	ctx.f8.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmadds f13,f13,f9,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmsubs f0,f0,f9,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 - ctx.f10.f64));
	// fsubs f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfsx f10,r11,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// fsubs f12,f11,f0
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfsx f12,r11,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// stfs f13,0(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lwz r11,3532(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 3532);
	// add r3,r5,r3
	ctx.r3.u64 = ctx.r5.u64 + ctx.r3.u64;
	// add r4,r5,r4
	ctx.r4.u64 = ctx.r5.u64 + ctx.r4.u64;
	// xor r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 ^ ctx.r6.u64;
	// bne 0x82d70e5c
	if (!ctx.cr0.eq) goto loc_82D70E5C;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D70EC8"))) PPC_WEAK_FUNC(sub_82D70EC8);
PPC_FUNC_IMPL(__imp__sub_82D70EC8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2376
	ctx.r5.s64 = ctx.r11.s64 + 2376;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,3648
	ctx.r4.s64 = ctx.r11.s64 + 3648;
	// b 0x82d77f70
	sub_82D77F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D70EE0"))) PPC_WEAK_FUNC(sub_82D70EE0);
PPC_FUNC_IMPL(__imp__sub_82D70EE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e3c
	ctx.lr = 0x82D70EE8;
	__savegprlr_17(ctx, base);
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28ee0
	ctx.lr = 0x82D70EF0;
	__savefpr_14(ctx, base);
	// stwu r1,-800(r1)
	ea = -800 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d73b04
	if (!ctx.cr6.gt) goto loc_82D73B04;
	// lwz r11,884(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	// rlwinm r25,r10,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// rlwinm r24,r11,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f31,-5428(r17)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -5428);
	ctx.f31.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f1,-5432(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -5432);
	ctx.f1.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f2,-5424(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -5424);
	ctx.f2.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f3,-5420(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -5420);
	ctx.f3.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f4,-5440(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -5440);
	ctx.f4.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f5,-5436(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -5436);
	ctx.f5.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f6,-5448(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -5448);
	ctx.f6.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lfs f7,-5444(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -5444);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f8,-8000(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8000);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f9,-8004(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8004);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8008(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8008);
	ctx.f10.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f11,-8012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8012);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D70F88:
	// rlwinm r27,r7,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f30,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// mulli r26,r7,144
	ctx.r26.s64 = ctx.r7.s64 * 144;
	// lfs f29,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f14,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r10,r7,160
	ctx.r10.s64 = ctx.r7.s64 * 160;
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfsx f28,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f25,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f14,f28,f27
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// mulli r9,r7,224
	ctx.r9.s64 = ctx.r7.s64 * 224;
	// lfsx f26,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fsubs f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfsx f24,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r31,r7,96
	ctx.r31.s64 = ctx.r7.s64 * 96;
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f25,f24,f22
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f25,56(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// rlwinm r30,r7,7,0,24
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 7) & 0xFFFFFF80;
	// lfsx f21,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// rlwinm r29,r7,6,0,25
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// mulli r28,r7,192
	ctx.r28.s64 = ctx.r7.s64 * 192;
	// fsubs f25,f23,f21
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfsx f20,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f20,f30
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// lfsx f17,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// lfsx f18,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f21,f19,f29
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f17,f18
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfsx f15,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f19,f15,f16
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,268(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f15,f27,f14
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// fsubs f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f14.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// fadds f14,f24,f28
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fsubs f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f28.f64));
	// fadds f24,f23,f26
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// fadds f23,f20,f22
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fsubs f20,f21,f19
	ctx.f20.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f19,f30,f17
	ctx.f19.f64 = double(float(ctx.f30.f64 - ctx.f17.f64));
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// fsubs f17,f29,f18
	ctx.f17.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// stfs f29,500(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// lfs f29,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f29.f64 = double(temp.f32);
	// mulli r9,r7,240
	ctx.r9.s64 = ctx.r7.s64 * 240;
	// stfs f17,444(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fsubs f18,f29,f15
	ctx.f18.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// fadds f17,f15,f29
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f29.f64));
	// mulli r31,r7,112
	ctx.r31.s64 = ctx.r7.s64 * 112;
	// fadds f29,f25,f27
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f29,40(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f15,f27,f25
	ctx.f15.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f29,f14,f23
	ctx.f29.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// fsubs f27,f23,f14
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// lfsx f14,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f25,f20,f28
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f28.f64));
	// fadds f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f20.f64));
	// fmuls f23,f18,f0
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f23,508(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fmuls f23,f17,f0
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f23,432(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f24,f21
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r30,r7,48
	ctx.r30.s64 = ctx.r7.s64 * 48;
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f21,f22,f26
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fadds f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f22,468(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// lfsx f15,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// mulli r29,r7,176
	ctx.r29.s64 = ctx.r7.s64 * 176;
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r7,80
	ctx.r11.s64 = ctx.r7.s64 * 80;
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f20,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r7,208
	ctx.r10.s64 = ctx.r7.s64 * 208;
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f18,f0
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f22,452(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f22,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,260(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f22,f15
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f20,268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,140(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f16,f13
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,148(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f20,f12
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,172(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f18,f22,f13,f18
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f18,476(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// fmadds f22,f22,f12,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f20.f64));
	// stfs f22,464(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fmsubs f22,f16,f12,f17
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f17.f64));
	// stfs f22,480(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f22,260(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f20,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f14,384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f16,f18,f13
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmuls f15,f20,f13
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// mulli r31,r7,168
	ctx.r31.s64 = ctx.r7.s64 * 168;
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r30,r7,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f14,436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f18,f12,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f14,344(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// mulli r29,r7,136
	ctx.r29.s64 = ctx.r7.s64 * 136;
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f22,288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fmadds f22,f20,f12,f16
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f22,336(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// mulli r28,r7,72
	ctx.r28.s64 = ctx.r7.s64 * 72;
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f22,f13
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// stfs f18,268(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f18,f22,f12
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r27,r7,200
	ctx.r27.s64 = ctx.r7.s64 * 200;
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// stfs f14,96(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmadds f20,f22,f12,f20
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f20.f64));
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f22,f22,f13,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r11,r7,232
	ctx.r11.s64 = ctx.r7.s64 * 232;
	// stfs f22,496(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f20,396(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f22,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f20,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r7,104
	ctx.r10.s64 = ctx.r7.s64 * 104;
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// mulli r9,r7,40
	ctx.r9.s64 = ctx.r7.s64 * 40;
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fsubs f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f16,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,140(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,148(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f22,f20
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// fadds f17,f20,f22
	ctx.f17.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f17,f22,f20
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f20,f22
	ctx.f17.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f17,96(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fadds f20,f16,f22
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f20,64(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f18,f15
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f22,f20
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f22,f17,f0
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,196(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,460(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,228(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// mulli r31,r7,156
	ctx.r31.s64 = ctx.r7.s64 * 156;
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// mulli r30,r7,252
	ctx.r30.s64 = ctx.r7.s64 * 252;
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,352(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,372(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,412(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f16,f22
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f14,492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f22,240(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f22,f20
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f16,388(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,256(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// mulli r29,r7,124
	ctx.r29.s64 = ctx.r7.s64 * 124;
	// fsubs f20,f22,f17
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f20,520(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,324(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fsubs f22,f18,f15
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r7,220
	ctx.r11.s64 = ctx.r7.s64 * 220;
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfsx f20,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r28,r7,60
	ctx.r28.s64 = ctx.r7.s64 * 60;
	// fsubs f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f14,328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r7,188
	ctx.r11.s64 = ctx.r7.s64 * 188;
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// mulli r10,r7,92
	ctx.r10.s64 = ctx.r7.s64 * 92;
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,96(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// mulli r9,r7,28
	ctx.r9.s64 = ctx.r7.s64 * 28;
	// lfsx f14,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f17,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfsx f16,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f22,224(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfsx f22,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fadds f14,f22,f20
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f20,76(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,140(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f20,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f18,72(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,48(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f20,24(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,68(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f18,f20
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// mulli r31,r7,152
	ctx.r31.s64 = ctx.r7.s64 * 152;
	// mulli r30,r7,248
	ctx.r30.s64 = ctx.r7.s64 * 248;
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r7,216
	ctx.r11.s64 = ctx.r7.s64 * 216;
	// mulli r10,r7,88
	ctx.r10.s64 = ctx.r7.s64 * 88;
	// mulli r9,r7,24
	ctx.r9.s64 = ctx.r7.s64 * 24;
	// mulli r29,r7,120
	ctx.r29.s64 = ctx.r7.s64 * 120;
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,424(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// mulli r28,r7,56
	ctx.r28.s64 = ctx.r7.s64 * 56;
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,440(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,408(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,276(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,448(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,484(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,160(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f22,f20
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,308(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f18
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f20,148(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,216(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f17
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,316(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f20,96(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f20,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f16,272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fsubs f18,f17,f22
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f18,140(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f22,420(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// mulli r11,r7,184
	ctx.r11.s64 = ctx.r7.s64 * 184;
	// lfsx f22,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f14,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f14,f20,f22
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// fsubs f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f20,f17,f18
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,120(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f17,f20,f16
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,368(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r7,228
	ctx.r11.s64 = ctx.r7.s64 * 228;
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r7,100
	ctx.r10.s64 = ctx.r7.s64 * 100;
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,220(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f15,f20
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f20,264(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f20
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f17,f18
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// fadds f17,f18,f17
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// mulli r9,r7,36
	ctx.r9.s64 = ctx.r7.s64 * 36;
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,400(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// mulli r31,r7,164
	ctx.r31.s64 = ctx.r7.s64 * 164;
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r29,r7,132
	ctx.r29.s64 = ctx.r7.s64 * 132;
	// mulli r28,r7,68
	ctx.r28.s64 = ctx.r7.s64 * 68;
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f14,312(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,244(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// mulli r27,r7,196
	ctx.r27.s64 = ctx.r7.s64 * 196;
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,292(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f15,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f22,f15
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f14,304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// stfs f22,404(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fsubs f22,f15,f20
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f22,392(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f22,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f14,204(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f22,168(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f22,f17
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,220(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fadds f22,f20,f15
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f22,332(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f22,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f16
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f20,368(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,128(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f22,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfsx f20,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfsx f16,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,264(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,376(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f18,f15
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f22,380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f22,f17
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fmuls f18,f14,f0
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f22,f16,f0
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f14,416(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,192(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,208(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f20
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,472(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// lfs f20,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f20
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f14,516(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,180(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f20,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f20,f22
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfs f15,348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,280(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f18
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f20,252(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,524(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f22,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f17
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f20,76(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// mulli r31,r7,212
	ctx.r31.s64 = ctx.r7.s64 * 212;
	// stfs f22,456(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// mulli r30,r7,244
	ctx.r30.s64 = ctx.r7.s64 * 244;
	// lfs f22,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f16
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,376(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// mulli r29,r7,116
	ctx.r29.s64 = ctx.r7.s64 * 116;
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f22,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f20,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r28,r7,52
	ctx.r28.s64 = ctx.r7.s64 * 52;
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// mulli r11,r7,180
	ctx.r11.s64 = ctx.r7.s64 * 180;
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r7,148
	ctx.r10.s64 = ctx.r7.s64 * 148;
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// mulli r9,r7,84
	ctx.r9.s64 = ctx.r7.s64 * 84;
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fsubs f18,f20,f17
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,60(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,104(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f15,f17,f18
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fsubs f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,100(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f17,f12
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f12
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmadds f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f12
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,184(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f20,f16
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f15,320(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// stfs f20,104(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmsubs f20,f16,f13,f14
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f15,340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// mulli r9,r7,76
	ctx.r9.s64 = ctx.r7.s64 * 76;
	// fmuls f15,f14,f0
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f15,124(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,176(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,512(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r7,140
	ctx.r10.s64 = ctx.r7.s64 * 140;
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,44(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,64(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmuls f17,f16,f12
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f22,f13
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f15,f20,f12
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// mulli r31,r7,204
	ctx.r31.s64 = ctx.r7.s64 * 204;
	// fmuls f14,f20,f13
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f20,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f22,f20,f13,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmsubs f20,f18,f12,f16
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f16.f64));
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// mulli r30,r7,236
	ctx.r30.s64 = ctx.r7.s64 * 236;
	// fmadds f17,f16,f13,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f15.f64));
	// fmsubs f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f14.f64));
	// mulli r29,r7,108
	ctx.r29.s64 = ctx.r7.s64 * 108;
	// mulli r28,r7,44
	ctx.r28.s64 = ctx.r7.s64 * 44;
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f18,f18,f13,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f18,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,100(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r7,172
	ctx.r11.s64 = ctx.r7.s64 * 172;
	// stfs f18,84(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f18,f15
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// fadds f15,f15,f18
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f18,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f14,284(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfsx f14,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,356(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,108(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f22,64(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f15,504(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// stfs f22,264(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfsx f15,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f20,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,380(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// lfsx f17,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f16,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f16,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f16,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// fsubs f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f14,100(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,84(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,60(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,116(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f15,f16,f22
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f15,68(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r11,r8,7,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 7) & 0xFFFFFF80;
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// stfs f14,248(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f14,f16,f22
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,84(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f22,364(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// stfs f20,116(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f20,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,212(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f22,60(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f20,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f20,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f18,f20,f22
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfs f22,236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f22,f12
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f12
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f12
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f18,f15,f12
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmuls f15,f17,f12
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmsubs f22,f17,f13,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f20.f64));
	// lfs f20,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f20,f20,f13,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f18.f64));
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f13,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f16.f64));
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f16,f17,f13,f14
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f16,300(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f16,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f17,f12,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f16.f64));
	// stfs f17,232(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f15,364(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f12
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f17,f13
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f17,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f29
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// stfs f17,248(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,116(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f15,f12,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f16.f64));
	// fmadds f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f15,212(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fsubs f15,f22,f20
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f18,f22
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f20,68(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f22,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f22,f20
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f18,152(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,144(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f20,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f20,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f22
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// fadds f15,f22,f20
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f20
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmuls f20,f18,f0
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f20,36(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f20,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f16,f20
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f20,60(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f18,f0
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfs f18,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r10,r8,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// mulli r9,r8,192
	ctx.r9.s64 = ctx.r8.s64 * 192;
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,164(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,156(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// mulli r31,r8,160
	ctx.r31.s64 = ctx.r8.s64 * 160;
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f16,f18
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f16,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,300(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,232(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f14,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f14.f64 = double(temp.f32);
	// mulli r30,r8,224
	ctx.r30.s64 = ctx.r8.s64 * 224;
	// lfs f16,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfsx f15,r11,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// stfs f29,212(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f29,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f29.f64 = double(temp.f32);
	// lfs f14,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// stfs f29,236(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f29,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f29,364(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfs f23,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// stfs f29,248(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f23,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// stfs f29,372(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f23,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f29,384(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f23,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// stfs f29,196(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f23,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f29,200(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f29,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f29.f64 = double(temp.f32);
	// lfs f23,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f14,f29,f23
	ctx.f14.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// stfsx f14,r11,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,0(r5)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfs f29,0(r6)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f23,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f29.f64 = double(temp.f32);
	// fadds f18,f29,f23
	ctx.f18.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// lfs f23,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f23.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fsubs f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// lfs f23,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f23.f64 = double(temp.f32);
	// mulli r29,r8,96
	ctx.r29.s64 = ctx.r8.s64 * 96;
	// fsubs f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfs f23,344(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfs f23,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f23.f64 = double(temp.f32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfs f27,304(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f27,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f27.f64 = double(temp.f32);
	// stfs f29,92(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f29,f27,f24
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// lfs f23,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f18,r10,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfs f27,288(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f27,f23,f24
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfsx f14,r10,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fsubs f23,f16,f15
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// stfsx f18,r9,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfsx f17,r9,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,164(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f16,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f17,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f13
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f17,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,232(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f16,196(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f16,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f16,200(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f16,f23,f27
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fadds f15,f18,f24
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// fsubs f23,f23,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// fsubs f18,f24,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// fmuls f27,f16,f0
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f24,f15,f0
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fsubs f15,f16,f27
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f27.f64));
	// stfsx f15,r31,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// stfsx f27,r11,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f27,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f16,f27,f24
	ctx.f16.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// stfsx f16,r31,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// stfsx f27,r11,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f24,f27,f23
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfsx f24,r30,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfsx f27,r29,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f24,f27,f18
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// stfsx f24,r30,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f18,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 + ctx.f27.f64));
	// lfs f23,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r8,176
	ctx.r11.s64 = ctx.r8.s64 * 176;
	// lfs f24,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f24.f64 = double(temp.f32);
	// mulli r10,r8,48
	ctx.r10.s64 = ctx.r8.s64 * 48;
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// stfs f23,88(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f16,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f14,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f27,r29,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f27,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f27.f64 = double(temp.f32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,184(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// mulli r9,r8,240
	ctx.r9.s64 = ctx.r8.s64 * 240;
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f14,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,144(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f17,f29
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f17.f64));
	// stfs f29,164(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f29,f24,f13
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// mulli r31,r8,112
	ctx.r31.s64 = ctx.r8.s64 * 112;
	// fmuls f17,f23,f12
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// stfs f23,92(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fsubs f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// mulli r30,r8,144
	ctx.r30.s64 = ctx.r8.s64 * 144;
	// fmadds f29,f27,f12,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 + ctx.f29.f64));
	// stfs f29,192(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// rlwinm r29,r8,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r28,r8,208
	ctx.r28.s64 = ctx.r8.s64 * 208;
	// lfs f29,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f29.f64 = double(temp.f32);
	// stfs f24,88(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmr f23,f29
	ctx.f23.f64 = ctx.f29.f64;
	// fmuls f24,f14,f0
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f29,f23,f13,f17
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f17.f64));
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fadds f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f27,f27,f13,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f17.f64));
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f23,f12,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f17.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmadds f17,f17,f12,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f16.f64));
	// lfs f16,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f15.f64));
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// lfs f15,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f29,f15
	ctx.f15.f64 = double(float(ctx.f29.f64 + ctx.f15.f64));
	// fadds f14,f23,f27
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfs f14,184(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r10,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfsx f14,r11,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r8,80
	ctx.r11.s64 = ctx.r8.s64 * 80;
	// lfs f23,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f23.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f15,r10,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// fsubs f15,f24,f29
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// stfsx f15,r9,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// stfsx f29,r31,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f29,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f24,f29,f27
	ctx.f24.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfsx f24,r9,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f15,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f15.f64 = double(temp.f32);
	// lfs f29,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f27,f23,f29
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfsx f27,r30,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// stfsx f29,r29,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lfs f29,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f16,f29
	ctx.f29.f64 = double(float(ctx.f16.f64 + ctx.f29.f64));
	// lfs f27,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f24,f27,f29
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfsx f24,r30,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// stfsx f29,r29,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// lfs f24,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f24.f64 = double(temp.f32);
	// lfs f27,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// lfs f24,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f23,f24,f22
	ctx.f23.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f23,88(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f23,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f23.f64 = double(temp.f32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,192(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f23,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f23.f64 = double(temp.f32);
	// fadds f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// lfs f23,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f23,f13
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f23,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f23.f64 = double(temp.f32);
	// stfs f22,276(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,160(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f22,188(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f22,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f20.f64 = double(temp.f32);
	// fadds f15,f22,f20
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f22,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f20,f22,f12,f14
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f20,180(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f20,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f14,f20,f12,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f14,176(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f14,f22,f13
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f22,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f18,228(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f18,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f29,f8
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fmsubs f20,f18,f12,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f20.f64));
	// stfs f20,160(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f20,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f12,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f20,152(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f20,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f17
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfsx f18,r28,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfsx f20,r11,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f27,f8
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmuls f17,f20,f8
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f20,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f8
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmsubs f27,f27,f9,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f16.f64));
	// fmadds f29,f29,f9,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f18.f64));
	// stfs f29,88(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmsubs f29,f20,f9,f17
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 - ctx.f17.f64));
	// stfs f29,144(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f29,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f18,f24,f10
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fsubs f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// stfs f29,296(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f29,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f17,f23,f11
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmuls f20,f29,f10
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fmsubs f24,f24,f11,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 - ctx.f20.f64));
	// lfs f29,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f29.f64 = double(temp.f32);
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// fmuls f14,f23,f10
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f23,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f23.f64 = double(temp.f32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f26,188(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f26,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f23.f64 = double(temp.f32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// lfs f23,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f23,f23,f11,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f18.f64));
	// fsubs f18,f22,f20
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfsx f18,r28,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f20,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f22,f28,f20
	ctx.f22.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f20,f28
	ctx.f28.f64 = double(float(ctx.f20.f64 + ctx.f28.f64));
	// fmadds f20,f18,f10,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 + ctx.f17.f64));
	// lfs f17,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f9,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f15.f64));
	// lfs f16,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f18,f11,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 - ctx.f14.f64));
	// stfs f17,292(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,180(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f14,228(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f29,f14
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// stfs f14,244(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fadds f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f14,160(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fsubs f22,f15,f16
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f22,152(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,168
	ctx.r11.s64 = ctx.r8.s64 * 168;
	// lfs f22,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f22.f64 = double(temp.f32);
	// mulli r10,r8,40
	ctx.r10.s64 = ctx.r8.s64 * 40;
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,176(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fadds f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f22.f64 = double(temp.f32);
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,144(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f22,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f22,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// lfs f22,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f12
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f13
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f22,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// lfs f22,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// stfs f27,156(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f22,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f22.f64 = double(temp.f32);
	// mulli r9,r8,232
	ctx.r9.s64 = ctx.r8.s64 * 232;
	// lfs f27,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// fadds f22,f24,f20
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f22,f26,f28
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfs f22,232(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fsubs f26,f24,f20
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// lfs f24,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f24.f64 = double(temp.f32);
	// fadds f22,f23,f18
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stfs f24,172(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f24,f18,f23
	ctx.f24.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// mulli r31,r8,104
	ctx.r31.s64 = ctx.r8.s64 * 104;
	// fmuls f23,f17,f0
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f23,300(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmuls f23,f16,f0
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f23,236(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f23,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f13,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f23,360(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f23,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f12,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f23,212(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f23,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f23.f64 = double(temp.f32);
	// mulli r30,r8,136
	ctx.r30.s64 = ctx.r8.s64 * 136;
	// rlwinm r29,r8,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r28,r8,200
	ctx.r28.s64 = ctx.r8.s64 * 200;
	// lfs f20,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f23
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// stfsx f18,r11,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f17,f23,f20
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// mulli r27,r8,72
	ctx.r27.s64 = ctx.r8.s64 * 72;
	// lfs f20,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f23,f20
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f16,f20,f23
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f23,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f23,f20
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f23,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f17,r10,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f14,f23,f9
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// stfsx f18,r11,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,184
	ctx.r11.s64 = ctx.r8.s64 * 184;
	// stfs f23,88(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmr f23,f18
	ctx.f23.f64 = ctx.f18.f64;
	// stfsx f16,r10,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// mulli r10,r8,56
	ctx.r10.s64 = ctx.r8.s64 * 56;
	// stfsx f15,r9,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// stfsx f20,r31,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f29,f23
	ctx.f18.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// stfsx f18,r9,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f23,f29
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// lfs f29,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f17,f27,f29
	ctx.f17.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfsx f23,r31,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f16,f29,f27
	ctx.f16.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// lfs f29,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f15,f29,f22
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f22.f64));
	// lfs f27,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f27.f64 = double(temp.f32);
	// fadds f22,f22,f29
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// stfsx f17,r30,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f28,f26
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfs f29,244(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfs f28,228(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fsubs f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// stfs f27,160(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f26,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f26.f64 = double(temp.f32);
	// mulli r9,r8,248
	ctx.r9.s64 = ctx.r8.s64 * 248;
	// fadds f24,f24,f26
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f26,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f26.f64 = double(temp.f32);
	// fmr f28,f26
	ctx.f28.f64 = ctx.f26.f64;
	// stfsx f16,r29,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// stfsx f15,r30,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f22,r29,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// lfs f26,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f17,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f17.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f26,172(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f26,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f29,f21,f28
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f28.f64));
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f21,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// lfs f16,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f15,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f25,92(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f25,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f25,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f25,f25,f8,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f23,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f23,r28,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f23,r27,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f23,r28,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// stfsx f24,r27,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f20,f17
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfs f23,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f23.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f17,208(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f18,f8
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmadds f17,f17,f12,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f17,284(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f22,f11
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// fmadds f17,f17,f9,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f16.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// mulli r31,r8,120
	ctx.r31.s64 = ctx.r8.s64 * 120;
	// fadds f16,f17,f29
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// stfs f16,136(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f17.f64));
	// stfs f29,132(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f29,f24,f11
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// mulli r30,r8,152
	ctx.r30.s64 = ctx.r8.s64 * 152;
	// fmuls f17,f21,f11
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fmuls f16,f23,f11
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmadds f29,f23,f10,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f29.f64));
	// fmsubs f23,f22,f10,f17
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f17.f64));
	// fmadds f22,f21,f10,f15
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f15.f64));
	// lfs f21,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f21.f64 = double(temp.f32);
	// stfs f18,208(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmr f18,f21
	ctx.f18.f64 = ctx.f21.f64;
	// fmsubs f24,f24,f10,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f16.f64));
	// mulli r29,r8,24
	ctx.r29.s64 = ctx.r8.s64 * 24;
	// lfs f17,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f18,f17
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fmadds f17,f20,f9,f14
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 + ctx.f14.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f17,f25
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f20,f20,f8,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 - ctx.f16.f64));
	// fadds f16,f23,f29
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// fadds f23,f22,f24
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f21,f27
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f21,f18,f28
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfsx f16,r10,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f22,f23
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f14,r11,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfsx f23,r10,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f23,f27,f29
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfsx f23,r9,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// stfsx f29,r31,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f29,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f16,f16,f24
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// fadds f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfsx f16,r9,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f21,f15
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfsx f29,r30,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f15,f21
	ctx.f29.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfsx f29,r29,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r8,216
	ctx.r11.s64 = ctx.r8.s64 * 216;
	// lfs f29,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f29.f64 = double(temp.f32);
	// lfs f27,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// stfs f29,284(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// stfs f27,208(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f15,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// lfs f27,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f27.f64 = double(temp.f32);
	// stfsx f29,r30,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// fadds f29,f15,f16
	ctx.f29.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,132(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f21,108(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f23,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r8,88
	ctx.r10.s64 = ctx.r8.s64 * 88;
	// lfs f21,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,352(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f23,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f23,f9
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// lfs f21,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// stfs f23,168(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f15,f21,f8
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// fmuls f14,f21,f9
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// lfs f22,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f21,224(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// lfs f20,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f21,216(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f21,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f20,f21,f8,f16
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 - ctx.f16.f64));
	// stfs f20,240(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f18,f20,f9,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 + ctx.f15.f64));
	// stfs f18,128(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f17,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f20,f8,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f18,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,308(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f17,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f18.f64 = double(temp.f32);
	// stfs f20,124(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f20,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f24,f6
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// stfs f18,280(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// lfs f14,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f4
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f21,f9,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f16.f64));
	// stfs f21,168(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f21,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// stfsx f21,r29,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmuls f20,f29,f6
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f6.f64));
	// fmuls f21,f27,f6
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f18,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// fmsubs f27,f27,f7,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 - ctx.f20.f64));
	// lfs f20,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f29,f29,f7,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f7.f64 + ctx.f21.f64));
	// lfs f21,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f24,f24,f7,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 - ctx.f18.f64));
	// fsubs f18,f26,f25
	ctx.f18.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfsx f18,r11,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmadds f21,f21,f7,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f17.f64));
	// fmadds f20,f20,f5,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 + ctx.f16.f64));
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfsx f26,r10,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f26,f28,f22
	ctx.f26.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfsx f26,r11,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f25,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f25.f64 = double(temp.f32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f26,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f26.f64 = double(temp.f32);
	// mulli r11,r8,172
	ctx.r11.s64 = ctx.r8.s64 * 172;
	// stfsx f28,r10,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f26,f25
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f18,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f22,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// mulli r10,r8,44
	ctx.r10.s64 = ctx.r8.s64 * 44;
	// fsubs f25,f22,f18
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f16,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f18,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f5,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 - ctx.f15.f64));
	// lfs f15,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,136(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,108(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// fmsubs f15,f23,f5,f14
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 - ctx.f14.f64));
	// fmuls f14,f23,f4
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// mulli r9,r8,236
	ctx.r9.s64 = ctx.r8.s64 * 236;
	// fadds f23,f25,f28
	ctx.f23.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// stfs f23,128(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// stfs f28,308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fadds f25,f24,f29
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// lfs f24,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f30
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fadds f28,f16,f26
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f26.f64));
	// mulli r31,r8,108
	ctx.r31.s64 = ctx.r8.s64 * 108;
	// fadds f23,f15,f20
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f23,240(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// lfs f15,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// mulli r30,r8,140
	ctx.r30.s64 = ctx.r8.s64 * 140;
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// stfs f23,132(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// lfs f17,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,168(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f15,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,216(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f15,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f15,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f17,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f5,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f21,f27
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// stfs f24,108(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f14,224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// lfs f24,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f21,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f21.f64 = double(temp.f32);
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// lfs f21,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f21.f64 = double(temp.f32);
	// mulli r29,r8,12
	ctx.r29.s64 = ctx.r8.s64 * 12;
	// lfs f16,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f16.f64 = double(temp.f32);
	// mulli r28,r8,204
	ctx.r28.s64 = ctx.r8.s64 * 204;
	// fsubs f14,f21,f16
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f14,128(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,240(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fsubs f17,f28,f25
	ctx.f17.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f18,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f25,f28
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// lfs f28,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f25,f15,f28
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// fadds f15,f28,f15
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// fsubs f28,f22,f29
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// fadds f22,f29,f22
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f22.f64));
	// fsubs f29,f26,f27
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// stfs f29,224(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfs f26,280(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f26,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f26.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// fadds f29,f24,f26
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f26,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f26.f64 = double(temp.f32);
	// stfs f27,216(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmr f27,f26
	ctx.f27.f64 = ctx.f26.f64;
	// lfs f26,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f16,f23,f20
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f23,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f23.f64 = double(temp.f32);
	// stfs f28,168(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// mulli r27,r8,76
	ctx.r27.s64 = ctx.r8.s64 * 76;
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f21,r10,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f21,f23,f2
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fmsubs f26,f26,f2,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f18.f64));
	// stfs f26,108(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fmadds f28,f27,f3,f21
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f21.f64));
	// fmsubs f27,f27,f2,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 - ctx.f23.f64));
	// lfs f26,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f26.f64 = double(temp.f32);
	// stfs f25,128(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f24,f24,f26
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfsx f24,r11,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r8,164
	ctx.r11.s64 = ctx.r8.s64 * 164;
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fadds f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// lfs f24,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f24.f64 = double(temp.f32);
	// fmr f25,f24
	ctx.f25.f64 = ctx.f24.f64;
	// stfsx f26,r10,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f16,r9,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// stfsx f20,r31,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// mulli r10,r8,36
	ctx.r10.s64 = ctx.r8.s64 * 36;
	// fsubs f24,f26,f25
	ctx.f24.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfsx f24,r9,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfsx f26,r31,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// stfsx f17,r30,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f14,r29,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lfs f25,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f24,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// lfs f23,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f23,r30,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f15,r29,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// stfsx f23,r28,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f22,r27,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// stfsx f23,r28,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f23,r27,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// mulli r9,r8,228
	ctx.r9.s64 = ctx.r8.s64 * 228;
	// lfs f24,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f24.f64 = double(temp.f32);
	// mulli r31,r8,100
	ctx.r31.s64 = ctx.r8.s64 * 100;
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f17,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f17,f10
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f23,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f22,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f22,f10
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f22,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f10
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f22,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f10
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f20,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f22,f22,f11,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f21.f64));
	// lfs f21,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f20,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f14,f11,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 + ctx.f18.f64));
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f14,f11,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f16.f64));
	// stfs f16,256(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmadds f17,f17,f11,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f15.f64));
	// stfs f17,324(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f26,f31
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// lfs f16,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f24,f31
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// mulli r30,r8,132
	ctx.r30.s64 = ctx.r8.s64 * 132;
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f17,f16,f3,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f17.f64));
	// stfs f17,220(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f17,f25,f31
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fmuls f16,f23,f31
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// fmsubs f25,f25,f1,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 - ctx.f15.f64));
	// fmadds f23,f23,f1,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f14.f64));
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f26,f26,f1,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f17.f64));
	// fmsubs f24,f24,f1,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 - ctx.f16.f64));
	// fsubs f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f17,f21,f20
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f18,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f18,f15
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// fadds f15,f24,f26
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fadds f24,f23,f25
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f23,f16,f14
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// fadds f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// fsubs f17,f23,f15
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfsx f17,r11,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f23,f16,f25
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// fadds f17,f25,f16
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// fsubs f25,f14,f24
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfsx f25,r11,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f25,f24,f14
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfsx f25,r10,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f25,f20,f26
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// stfsx f25,r9,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// stfsx f26,r31,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f26.f64 = double(temp.f32);
	// fadds f25,f18,f29
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// fadds f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfsx f23,r9,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f25,f26
	ctx.f24.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f16,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f26,f25
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f20,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfsx f17,r31,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f26,f16,f20
	ctx.f26.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// lfs f15,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,196
	ctx.r11.s64 = ctx.r8.s64 * 196;
	// stfs f20,316(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fsubs f20,f17,f15
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f20,332(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fadds f25,f15,f17
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f20,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r8,68
	ctx.r10.s64 = ctx.r8.s64 * 68;
	// stfsx f24,r30,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fmuls f17,f20,f11
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f24,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// fadds f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfsx f23,r29,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fmuls f16,f20,f10
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f20,f11
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f23,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f20.f64 = double(temp.f32);
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// fmuls f14,f20,f11
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f18,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f21,f22
	ctx.f20.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f20,204(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// lfs f21,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f21.f64 = double(temp.f32);
	// fadds f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// lfs f21,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f19,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f10,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 - ctx.f17.f64));
	// lfs f17,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f11,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f16.f64));
	// stfs f17,252(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f16,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,340(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f16,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f17,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f10,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f15.f64));
	// stfs f17,324(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f17,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f23,f1
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// fmadds f17,f17,f10,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f14.f64));
	// stfs f17,128(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f23,f31
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// lfs f17,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fmuls f17,f25,f31
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fmuls f16,f25,f1
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// lfs f25,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// stfs f25,356(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fmuls f23,f23,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fmadds f25,f26,f1,f17
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f17.f64));
	// stfs f23,348(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmsubs f26,f26,f31,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f31.f64 - ctx.f16.f64));
	// lfs f17,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f23,f24,f31,f15
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f31.f64 - ctx.f15.f64));
	// fsubs f16,f17,f20
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfsx f16,r30,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfsx f20,r29,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f20,f22,f28
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// stfsx f20,r11,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// stfsx f28,r10,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f29,f27
	ctx.f28.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfsx f28,r11,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f29,r10,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f21,f19
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// lfs f22,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f22.f64 = double(temp.f32);
	// fadds f28,f19,f21
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f16,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f18,f22
	ctx.f27.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// fmadds f21,f21,f3,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f16.f64));
	// lfs f20,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f20.f64 = double(temp.f32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f24,f24,f1,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f14.f64));
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// mulli r11,r8,188
	ctx.r11.s64 = ctx.r8.s64 * 188;
	// mulli r10,r8,60
	ctx.r10.s64 = ctx.r8.s64 * 60;
	// mulli r9,r8,252
	ctx.r9.s64 = ctx.r8.s64 * 252;
	// mulli r31,r8,124
	ctx.r31.s64 = ctx.r8.s64 * 124;
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f20,f20,f3,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 - ctx.f16.f64));
	// lfs f16,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f2
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f2
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// fadds f16,f27,f29
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfs f16,272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// lfs f27,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f27.f64 = double(temp.f32);
	// fadds f16,f17,f19
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,328(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f27,f27,f3,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 - ctx.f15.f64));
	// lfs f19,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f23,f25
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfs f15,204(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,356(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fmadds f15,f15,f3,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 + ctx.f14.f64));
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// stfs f14,252(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f14,f24,f26
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// lfs f24,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// lfs f24,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f23.f64 = double(temp.f32);
	// fadds f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f23,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,256(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// mulli r30,r8,156
	ctx.r30.s64 = ctx.r8.s64 * 156;
	// lfs f23,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f23.f64 = double(temp.f32);
	// mulli r29,r8,28
	ctx.r29.s64 = ctx.r8.s64 * 28;
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f23,340(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fadds f23,f27,f21
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f21,f15,f20
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f21,336(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// fsubs f21,f20,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f21,348(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f21,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f19,f4
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fsubs f20,f17,f21
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// fadds f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// lfs f21,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f15,f21,f14
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// fsubs f14,f22,f25
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fadds f22,f25,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// fsubs f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfs f25,204(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfs f28,252(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f28,f30,f24
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// lfs f26,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f26.f64 = double(temp.f32);
	// fadds f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// lfs f24,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfsx f24,r11,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f24,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f24.f64 = double(temp.f32);
	// fmr f25,f26
	ctx.f25.f64 = ctx.f26.f64;
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfsx f24,r10,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f24,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f24.f64 = double(temp.f32);
	// mulli r28,r8,220
	ctx.r28.s64 = ctx.r8.s64 * 220;
	// fsubs f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// mulli r27,r8,92
	ctx.r27.s64 = ctx.r8.s64 * 92;
	// fmadds f26,f25,f5,f18
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f18.f64));
	// fmsubs f25,f25,f4,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 - ctx.f19.f64));
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// stfsx f23,r11,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r8,180
	ctx.r11.s64 = ctx.r8.s64 * 180;
	// fadds f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// stfsx f23,r10,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfsx f24,r9,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f24,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// stfsx f27,r31,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f24,f29,f27
	ctx.f24.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfsx f24,r9,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// stfsx f20,r30,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// mulli r10,r8,52
	ctx.r10.s64 = ctx.r8.s64 * 52;
	// lfs f27,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f29.f64 = double(temp.f32);
	// stfsx f17,r29,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfsx f15,r30,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f24,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f24.f64 = double(temp.f32);
	// lfs f27,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f27.f64 = double(temp.f32);
	// stfsx f21,r29,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfsx f14,r28,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// stfsx f22,r27,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f22,r28,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f22,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f22,r27,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// mulli r9,r8,244
	ctx.r9.s64 = ctx.r8.s64 * 244;
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f22,f8
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// lfs f22,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f8
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// lfs f17,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f17,f8
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// lfs f19,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f8
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// lfs f20,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// mulli r31,r8,116
	ctx.r31.s64 = ctx.r8.s64 * 116;
	// fmadds f19,f19,f9,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 + ctx.f18.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f17,f17,f9,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f15.f64));
	// stfs f17,388(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fmsubs f22,f22,f9,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 - ctx.f21.f64));
	// lfs f21,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f18,f18,f9,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 - ctx.f16.f64));
	// lfs f16,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f20,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f16,f5
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f5.f64));
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// fmuls f14,f17,f5
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// fmsubs f17,f17,f4,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 - ctx.f15.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f15,f27,f7
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmadds f17,f16,f4,f14
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 + ctx.f14.f64));
	// stfs f17,392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmuls f16,f23,f7
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f7.f64));
	// fmuls f17,f29,f7
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f7.f64));
	// fmuls f14,f24,f7
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fmsubs f29,f29,f6,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 - ctx.f15.f64));
	// fmsubs f24,f24,f6,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 - ctx.f16.f64));
	// fmadds f27,f27,f6,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f17.f64));
	// fmadds f23,f23,f6,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f14.f64));
	// fsubs f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f17,f21,f20
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f15,f24,f27
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// fadds f24,f23,f29
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// fadds f23,f16,f28
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f28.f64));
	// fsubs f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// lfs f19,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// fsubs f14,f23,f15
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f23,f28,f29
	ctx.f23.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// fadds f16,f20,f17
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// fadds f17,f19,f30
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// fsubs f28,f16,f24
	ctx.f28.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// stfsx f28,r11,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f28,f24,f16
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// stfsx f28,r10,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f20,f27
	ctx.f28.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// stfsx f28,r9,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f28,f27,f20
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// stfsx f28,r31,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f24,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f24.f64 = double(temp.f32);
	// mulli r11,r8,148
	ctx.r11.s64 = ctx.r8.s64 * 148;
	// stfsx f23,r9,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f28,f24,f25
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f27,f21,f22
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// fadds f29,f21,f22
	ctx.f29.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// mulli r9,r8,212
	ctx.r9.s64 = ctx.r8.s64 * 212;
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// mulli r31,r8,84
	ctx.r31.s64 = ctx.r8.s64 * 84;
	// fsubs f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f19.f64));
	// fsubs f24,f17,f18
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfsx f24,r11,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f18,f17
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f29,f28
	ctx.f24.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// stfsx f24,r11,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// stfsx f29,r10,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f27,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// stfsx f28,r9,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f26,f30,f25
	ctx.f26.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// stfsx f27,r31,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// stfsx f26,r9,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// stfsx f30,r31,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// add r3,r25,r3
	ctx.r3.u64 = ctx.r25.u64 + ctx.r3.u64;
	// add r4,r25,r4
	ctx.r4.u64 = ctx.r25.u64 + ctx.r4.u64;
	// add r6,r24,r6
	ctx.r6.u64 = ctx.r24.u64 + ctx.r6.u64;
	// add r5,r24,r5
	ctx.r5.u64 = ctx.r24.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d70f88
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D70F88;
loc_82D73B04:
	// addi r1,r1,800
	ctx.r1.s64 = ctx.r1.s64 + 800;
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82e28f2c
	ctx.lr = 0x82D73B10;
	__restfpr_14(ctx, base);
	// b 0x82e28e8c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D73B18"))) PPC_WEAK_FUNC(sub_82D73B18);
PPC_FUNC_IMPL(__imp__sub_82D73B18) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2440
	ctx.r5.s64 = ctx.r11.s64 + 2440;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,3808
	ctx.r4.s64 = ctx.r11.s64 + 3808;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D73B30"))) PPC_WEAK_FUNC(sub_82D73B30);
PPC_FUNC_IMPL(__imp__sub_82D73B30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D73B38;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28ee0
	ctx.lr = 0x82D73B40;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d74c20
	if (!ctx.cr6.gt) goto loc_82D74C20;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r23,r10,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lfs f8,-8004(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -8004);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f9,-8000(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -8000);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-8012(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8012);
	ctx.f10.f64 = double(temp.f32);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f11,-8008(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8008);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-8016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -8016);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D73B94:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f7,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r10,r7,80
	ctx.r10.s64 = ctx.r7.s64 * 80;
	// lfs f6,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f15,f5,f4
	ctx.f15.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// mulli r9,r7,112
	ctx.r9.s64 = ctx.r7.s64 * 112;
	// lfsx f3,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfsx f1,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// mulli r31,r7,48
	ctx.r31.s64 = ctx.r7.s64 * 48;
	// lfsx f30,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f2,f1,f30
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// stfs f2,-460(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// rlwinm r30,r7,6,0,25
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// lfsx f29,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// rlwinm r29,r7,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f2,f31,f29
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// mulli r28,r7,96
	ctx.r28.s64 = ctx.r7.s64 * 96;
	// fadds f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// lfsx f28,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f28,f7
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// lfsx f26,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f29,f27,f6
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// lfsx f25,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// rlwinm r27,r7,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f24,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r26,r7,72
	ctx.r26.s64 = ctx.r7.s64 * 72;
	// lfsx f23,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// fadds f28,f25,f26
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfsx f22,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfsx f21,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f20,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f24,f21,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// mulli r25,r7,40
	ctx.r25.s64 = ctx.r7.s64 * 40;
	// lfsx f19,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f19,f20
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfsx f18,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r24,r7,104
	ctx.r24.s64 = ctx.r7.s64 * 104;
	// lfsx f16,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f16,f18
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfsx f14,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f4,f15
	ctx.f18.f64 = double(float(ctx.f4.f64 + ctx.f15.f64));
	// fsubs f4,f4,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f15.f64));
	// lfs f15,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f2
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// fadds f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f15.f64));
	// fadds f15,f1,f5
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// stfs f15,-284(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fadds f15,f31,f3
	ctx.f15.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f1,f28,f30
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fsubs f31,f30,f28
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fsubs f30,f29,f26
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f26,f6,f27
	ctx.f26.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fadds f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// fsubs f27,f16,f18
	ctx.f27.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fsubs f28,f7,f25
	ctx.f28.f64 = double(float(ctx.f7.f64 - ctx.f25.f64));
	// fadds f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 + ctx.f7.f64));
	// fadds f25,f18,f16
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// fsubs f18,f4,f2
	ctx.f18.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fadds f16,f2,f4
	ctx.f16.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fmuls f4,f27,f0
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f27,f18,f0
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// mulli r11,r7,120
	ctx.r11.s64 = ctx.r7.s64 * 120;
	// fsubs f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// mulli r10,r7,56
	ctx.r10.s64 = ctx.r7.s64 * 56;
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fmuls f2,f25,f0
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f25,f16,f0
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f16,f19,f21
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fsubs f19,f24,f20
	ctx.f19.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// fadds f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// lfsx f20,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f23,f18
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f14,-460(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f14,-436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fsubs f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,-328(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// mulli r9,r7,24
	ctx.r9.s64 = ctx.r7.s64 * 24;
	// lfsx f22,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-388(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmuls f23,f21,f13
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// stfs f23,-416(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// stfs f18,-376(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfsx f22,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-312(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// mulli r31,r7,88
	ctx.r31.s64 = ctx.r7.s64 * 88;
	// lfsx f22,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-440(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-300(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// mulli r30,r7,124
	ctx.r30.s64 = ctx.r7.s64 * 124;
	// lfsx f22,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fmsubs f21,f21,f12,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 - ctx.f18.f64));
	// stfs f21,-264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfsx f22,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// mulli r29,r7,60
	ctx.r29.s64 = ctx.r7.s64 * 60;
	// lfsx f22,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-352(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f22,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-448(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f22,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f22.f64 = double(temp.f32);
	// fmr f23,f22
	ctx.f23.f64 = ctx.f22.f64;
	// fsubs f22,f14,f19
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f22,-392(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fmr f22,f14
	ctx.f22.f64 = ctx.f14.f64;
	// lfs f18,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f12,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f18.f64));
	// stfs f21,-280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fmuls f17,f23,f12
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// stfs f23,-460(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f22,-348(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f22,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfs f22,-456(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f19,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f23,f22,f19
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// lfs f22,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,-412(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fmr f20,f19
	ctx.f20.f64 = ctx.f19.f64;
	// lfs f22,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fmsubs f20,f16,f13,f17
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f17.f64));
	// lfs f17,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f16,f12,f17
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f17.f64));
	// lfs f17,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f17,f14
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f18.f64 = double(temp.f32);
	// mulli r10,r7,76
	ctx.r10.s64 = ctx.r7.s64 * 76;
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,-460(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f16,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f16.f64 = double(temp.f32);
	// mulli r9,r7,108
	ctx.r9.s64 = ctx.r7.s64 * 108;
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// fadds f14,f21,f23
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f14,-376(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,-448(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f23,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f23,-456(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,-416(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f21,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f21,f17
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f21,-364(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// mulli r31,r7,44
	ctx.r31.s64 = ctx.r7.s64 * 44;
	// mulli r30,r7,28
	ctx.r30.s64 = ctx.r7.s64 * 28;
	// rlwinm r28,r7,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r27,r7,68
	ctx.r27.s64 = ctx.r7.s64 * 68;
	// lfs f18,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f14,-460(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,-340(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f22,f13
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f18,f22,f12
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f22,f13
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f22,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f14,-320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,-460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// fmr f22,f14
	ctx.f22.f64 = ctx.f14.f64;
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f21,f22,f12,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f21.f64));
	// stfs f21,-312(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmsubs f22,f22,f13,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f22,-300(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f22,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f22,-272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f17,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f21,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f22,f22,f12,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f21.f64));
	// stfs f22,-288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f22,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r29,r7,92
	ctx.r29.s64 = ctx.r7.s64 * 92;
	// fadds f18,f22,f14
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfsx f21,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfsx f14,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-456(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfsx f14,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfsx f14,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-424(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// mulli r11,r7,36
	ctx.r11.s64 = ctx.r7.s64 * 36;
	// lfsx f14,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-388(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// mulli r10,r7,100
	ctx.r10.s64 = ctx.r7.s64 * 100;
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-432(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-408(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-372(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-356(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-460(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-420(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfsx f14,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-368(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f14,-376(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,-444(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-464(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfsx f17,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-416(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-396(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-440(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-456(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,-448(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,-432(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f14,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-424(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-436(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f14,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f17,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-384(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f17,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,-408(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f14,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,-400(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f17,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-296(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f17,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,-444(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-420(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-416(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-440(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfs f14,-304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f21,-256(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f21,-248(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f21,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f14,-316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f21,-260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f21,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,-276(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f21,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f16,f21
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// stfs f18,-376(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fadds f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// stfs f21,-292(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f21,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f22,f21
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f18,-268(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f22,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f22,f21
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f16,f21,f22
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// fmuls f21,f18,f0
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f21,-416(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fmuls f21,f16,f0
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f21,-296(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmuls f21,f14,f0
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f21,-412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,-252(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f22,f17
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f21,-464(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,-356(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// lfs f21,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f21.f64 = double(temp.f32);
	// mulli r10,r7,84
	ctx.r10.s64 = ctx.r7.s64 * 84;
	// lfs f22,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f21,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f18,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f21.f64 = double(temp.f32);
	// stfs f22,-424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fsubs f22,f18,f21
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,-448(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f21,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f18,f21
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f17,-440(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f17,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-372(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f16,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f16.f64 = double(temp.f32);
	// mulli r9,r7,116
	ctx.r9.s64 = ctx.r7.s64 * 116;
	// lfs f17,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fmuls f16,f22,f13
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f14,f22,f12
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f22,-396(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f22,f21,f18
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f18,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f18.f64 = double(temp.f32);
	// mulli r31,r7,52
	ctx.r31.s64 = ctx.r7.s64 * 52;
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f21,-452(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f21,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,-388(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f12,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f21,-324(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fsubs f21,f30,f5
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfs f21,-456(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f18,f21
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f17,-352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,-316(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f13,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f14,-304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,-380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fsubs f22,f31,f3
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// stfs f21,-332(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f17,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f21,-408(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f18,-428(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// stfs f17,-368(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfsx f21,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-344(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// lfsx f17,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f22,-360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfsx f22,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-464(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfsx f22,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-444(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f14,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fadds f14,f17,f21
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfs f22,-336(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f14,-400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fadds f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f17,-420(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f22,-396(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// fadds f16,f18,f21
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfs f21,-440(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f21,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfs f18,-464(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fsubs f18,f14,f17
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f18,-452(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f21,-436(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f18,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f18,f22
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// fadds f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f17,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f17.f64 = double(temp.f32);
	// stfs f18,-404(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-396(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-400(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f14,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-384(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f17,f21,f16
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// fadds f16,f16,f21
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f21,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,-420(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f18,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,-464(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f21,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f21,f18
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f18,-444(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f21,-308(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmuls f21,f16,f0
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f21,-428(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmuls f21,f14,f0
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f21,-440(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,-372(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f22,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f17,f22,f12
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f21,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f22,f13
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfs f5,-396(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f5,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f5.f64 = double(temp.f32);
	// fadds f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f31.f64));
	// lfs f30,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f30.f64 = double(temp.f32);
	// mulli r11,r8,88
	ctx.r11.s64 = ctx.r8.s64 * 88;
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fmsubs f5,f5,f12,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 - ctx.f18.f64));
	// fmsubs f22,f21,f13,f17
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f17.f64));
	// lfs f17,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f21,f21,f12,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f16.f64));
	// mulli r9,r8,120
	ctx.r9.s64 = ctx.r8.s64 * 120;
	// fsubs f16,f22,f17
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f16,-452(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,-400(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f22,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f22,f21
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f17,-332(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-324(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f22,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f17,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f17.f64 = double(temp.f32);
	// stfs f5,-464(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f16,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f16.f64 = double(temp.f32);
	// mulli r31,r8,56
	ctx.r31.s64 = ctx.r8.s64 * 56;
	// lfs f5,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f5.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfs f5,-392(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f30,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f30.f64 = double(temp.f32);
	// lfs f5,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// lfs f21,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f30,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f31,f23,f0
	ctx.f31.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f23,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f12,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f22.f64));
	// lfs f22,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f22.f64 = double(temp.f32);
	// stfs f5,-356(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// mulli r30,r8,72
	ctx.r30.s64 = ctx.r8.s64 * 72;
	// lfs f5,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f5,f12,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f5,-348(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fmuls f5,f16,f0
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f5,-320(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f5,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfs f5,-408(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f30,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f30.f64 = double(temp.f32);
	// lfs f5,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f22,f22,f12,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f21.f64));
	// fsubs f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfs f5,-444(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f5,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r29,r8,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r28,r8,104
	ctx.r28.s64 = ctx.r8.s64 * 104;
	// mulli r27,r8,40
	ctx.r27.s64 = ctx.r8.s64 * 40;
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f18,f5,f30
	ctx.f18.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// lfs f21,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f30,f5
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// lfs f30,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f16,f30,f21
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// lfs f5,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f5.f64 = double(temp.f32);
	// fadds f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 - ctx.f14.f64));
	// fadds f5,f21,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// stfs f30,-360(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fsubs f30,f22,f23
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfs f5,-336(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f5,f31,f3
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// stfsx f18,r11,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f31,f22,f23
	ctx.f31.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f23,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f22,r11,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r8,80
	ctx.r11.s64 = ctx.r8.s64 * 80;
	// fadds f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f17,r10,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// stfsx f22,r10,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f21,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f18.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,-344(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// stfsx f16,r9,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// stfsx f14,r9,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f18.f64 = double(temp.f32);
	// stfsx f18,r31,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f18,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f18,f17
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfsx f14,r31,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f18,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f1,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 - ctx.f18.f64));
	// lfs f17,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f17,-392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f17,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f16,f14,f0
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fsubs f14,f5,f31
	ctx.f14.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// stfsx f14,r30,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// fsubs f31,f22,f23
	ctx.f31.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f31,r30,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f5,r29,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f22,f23
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f5,r29,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f5,f21,f30
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f30.f64));
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f31,f3,f5
	ctx.f31.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfsx f31,r28,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f31,f21,f30
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfsx f31,r27,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// lfs f23,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f5,r27,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f30,f23,f24
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f3,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f3.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f22,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f22.f64 = double(temp.f32);
	// lfs f5,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f5.f64 = double(temp.f32);
	// fadds f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f1.f64));
	// fadds f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// lfs f31,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f31.f64 = double(temp.f32);
	// lfs f22,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f22.f64 = double(temp.f32);
	// lfs f3,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f3.f64 = double(temp.f32);
	// lfs f23,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f31,f29,f15
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// lfs f21,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f21.f64 = double(temp.f32);
	// fadds f29,f15,f29
	ctx.f29.f64 = double(float(ctx.f15.f64 + ctx.f29.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// mulli r9,r8,112
	ctx.r9.s64 = ctx.r8.s64 * 112;
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfs f21,-368(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f14.f64 = double(temp.f32);
	// mulli r31,r8,48
	ctx.r31.s64 = ctx.r8.s64 * 48;
	// lfs f21,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-364(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-328(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fsubs f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fadds f17,f3,f5
	ctx.f17.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// rlwinm r30,r8,6,0,25
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// fsubs f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfs f5,-404(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fadds f5,f30,f31
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// rlwinm r29,r8,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f3,f31,f30
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// mulli r28,r8,96
	ctx.r28.s64 = ctx.r8.s64 * 96;
	// fadds f31,f24,f1
	ctx.f31.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// fsubs f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// fadds f30,f22,f23
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fmuls f22,f17,f0
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f23,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f23,-336(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f23,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f17,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f21,-360(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f21,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f21,f29
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// stfs f17,-364(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fsubs f29,f29,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f21.f64));
	// lfs f21,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f21,-404(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// stfs f29,-344(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f29,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f17,f29,f10
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fsubs f29,f28,f27
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// stfs f21,-340(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f29,f29,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f21.f64));
	// stfs f29,-400(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fsubs f21,f6,f4
	ctx.f21.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// stfs f21,-404(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f29,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// fsubs f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// stfs f21,-324(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// fadds f29,f29,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// fmadds f21,f15,f11,f17
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f17.f64));
	// stfs f21,-332(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f21,f5,f16
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f16.f64));
	// fadds f17,f5,f16
	ctx.f17.f64 = double(float(ctx.f5.f64 + ctx.f16.f64));
	// lfs f5,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f16,f31,f30
	ctx.f16.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// fsubs f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfsx f5,r5,r11
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r11.u32, temp.u32);
	// fadds f31,f30,f31
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// stfsx f21,r11,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f23,f1
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// lfs f5,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// fadds f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// stfsx f5,r10,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f5,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f5.f64 = double(temp.f32);
	// mulli r11,r8,92
	ctx.r11.s64 = ctx.r8.s64 * 92;
	// stfsx f17,r10,r6
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f3,f5
	ctx.f22.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfsx f22,r9,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f21,f3,f5
	ctx.f21.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfsx f14,r9,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fmuls f17,f15,f10
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f5,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f5.f64 = double(temp.f32);
	// mulli r10,r8,28
	ctx.r10.s64 = ctx.r8.s64 * 28;
	// lfs f3,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f3.f64 = double(temp.f32);
	// stfsx f21,r31,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f3,f5
	ctx.f22.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfsx f18,r31,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfsx f16,r30,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f22,r30,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f5.f64 = double(temp.f32);
	// stfs f31,0(r5)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f21,f5,f24
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// stfs f3,0(r6)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fsubs f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f24.f64));
	// stfsx f21,r29,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// stfsx f30,r29,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// mulli r9,r8,124
	ctx.r9.s64 = ctx.r8.s64 * 124;
	// lfs f3,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f3.f64 = double(temp.f32);
	// lfs f5,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f5.f64 = double(temp.f32);
	// stfsx f1,r28,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// lfs f1,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// lfs f31,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// lfs f30,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f31.f64 = double(temp.f32);
	// mulli r31,r8,60
	ctx.r31.s64 = ctx.r8.s64 * 60;
	// fsubs f31,f30,f31
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f31.f64));
	// lfs f24,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f24.f64 = double(temp.f32);
	// lfs f30,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// lfs f23,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f7,f2
	ctx.f23.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f17,f16,f11,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f17.f64));
	// fmuls f15,f1,f8
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// lfs f22,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f1,f1,f9
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// stfs f1,-404(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// stfs f17,-360(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fmuls f17,f3,f10
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// mulli r30,r8,84
	ctx.r30.s64 = ctx.r8.s64 * 84;
	// fmuls f16,f5,f10
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fsubs f21,f26,f25
	ctx.f21.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fmuls f14,f24,f9
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fmuls f24,f24,f8
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// stfs f24,-364(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fmadds f24,f31,f9,f15
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f9.f64 + ctx.f15.f64));
	// mulli r29,r8,20
	ctx.r29.s64 = ctx.r8.s64 * 20;
	// fadds f1,f22,f23
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fmsubs f5,f5,f11,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 - ctx.f17.f64));
	// fmadds f3,f3,f11,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fadds f17,f18,f21
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fmsubs f16,f30,f8,f14
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f14.f64));
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// mulli r28,r8,116
	ctx.r28.s64 = ctx.r8.s64 * 116;
	// mulli r27,r8,52
	ctx.r27.s64 = ctx.r8.s64 * 52;
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f31,f31,f8,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 - ctx.f15.f64));
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f30,f30,f9,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f15.f64));
	// lfs f15,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f14,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f5,f15
	ctx.f22.f64 = double(float(ctx.f5.f64 + ctx.f15.f64));
	// fadds f18,f3,f14
	ctx.f18.f64 = double(float(ctx.f3.f64 + ctx.f14.f64));
	// fsubs f3,f14,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 - ctx.f3.f64));
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f15.f64));
	// fadds f15,f16,f24
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// fsubs f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// fadds f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// lfs f2,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f2.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f25,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f25.f64 = double(temp.f32);
	// fadds f16,f30,f31
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fsubs f31,f31,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f27,f28
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfsx f22,r10,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f22,f29,f18
	ctx.f22.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfsx f22,r11,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// stfsx f29,r10,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f29,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f29.f64 = double(temp.f32);
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f22,f29,f5
	ctx.f22.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// stfsx f22,r9,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// stfsx f5,r31,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f5.f64 = double(temp.f32);
	// mulli r11,r8,68
	ctx.r11.s64 = ctx.r8.s64 * 68;
	// fsubs f29,f5,f3
	ctx.f29.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfsx f29,r9,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfsx f5,r31,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f1,f15
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// stfsx f5,r30,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f15,f1
	ctx.f5.f64 = double(float(ctx.f15.f64 + ctx.f1.f64));
	// stfsx f5,r29,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f17,f16
	ctx.f5.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfsx f5,r30,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f16,f17
	ctx.f5.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfsx f5,r29,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f5,f21,f24
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f5,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f5.f64 = double(temp.f32);
	// mulli r9,r8,100
	ctx.r9.s64 = ctx.r8.s64 * 100;
	// fadds f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// lfs f1,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// lfs f29,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f29.f64 = double(temp.f32);
	// lfs f1,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f1,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// lfs f22,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f22.f64 = double(temp.f32);
	// lfs f29,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f22.f64));
	// lfs f22,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f22.f64 = double(temp.f32);
	// fadds f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// lfs f22,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f22.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// lfs f18,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f22.f64 = double(temp.f32);
	// mulli r31,r8,36
	ctx.r31.s64 = ctx.r8.s64 * 36;
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f28.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f4,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f4.f64 = double(temp.f32);
	// fadds f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// lfs f27,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f27.f64 = double(temp.f32);
	// fadds f4,f4,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f20.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// stfsx f24,r27,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f5,f11
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f21,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f21.f64 = double(temp.f32);
	// fadds f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// lfs f24,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f20,f29,f11
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f11.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// add r3,r23,r3
	ctx.r3.u64 = ctx.r23.u64 + ctx.r3.u64;
	// fmuls f21,f5,f10
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// add r4,r23,r4
	ctx.r4.u64 = ctx.r23.u64 + ctx.r4.u64;
	// fmuls f17,f1,f11
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// fadds f5,f2,f7
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// fsubs f7,f7,f2
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fmsubs f1,f1,f10,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmuls f20,f18,f8
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmadds f2,f3,f11,f21
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 + ctx.f21.f64));
	// fmsubs f3,f3,f10,f19
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmadds f29,f29,f10,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f10.f64 + ctx.f17.f64));
	// fsubs f19,f23,f31
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// stfsx f19,r28,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// stfsx f31,r27,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f21,f25,f26
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fmuls f25,f22,f8
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fadds f31,f28,f30
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f23,f1,f2
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// fadds f1,f29,f3
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f3.f64));
	// fsubs f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fsubs f28,f6,f4
	ctx.f28.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fmadds f4,f18,f9,f25
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 + ctx.f25.f64));
	// fmsubs f25,f22,f9,f20
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 - ctx.f20.f64));
	// fsubs f29,f5,f23
	ctx.f29.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// stfsx f29,r11,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// stfsx f5,r10,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f21,f1
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f1.f64));
	// stfsx f29,r11,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f21.f64));
	// stfsx f1,r10,r6
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f5,f26,f2
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f2.f64));
	// stfsx f5,r9,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// stfsx f2,r31,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f5,f7,f3
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfsx f5,r9,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfsx f7,r31,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fmuls f7,f24,f8
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// mulli r11,r8,76
	ctx.r11.s64 = ctx.r8.s64 * 76;
	// fmuls f5,f27,f8
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fmsubs f7,f27,f9,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f7.f64));
	// fmadds f5,f24,f9,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f5.f64));
	// mulli r9,r8,108
	ctx.r9.s64 = ctx.r8.s64 * 108;
	// fadds f3,f7,f4
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fsubs f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fadds f4,f5,f25
	ctx.f4.f64 = double(float(ctx.f5.f64 + ctx.f25.f64));
	// fsubs f5,f25,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 - ctx.f5.f64));
	// mulli r31,r8,44
	ctx.r31.s64 = ctx.r8.s64 * 44;
	// fsubs f2,f31,f3
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// stfsx f2,r11,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f31.f64));
	// stfsx f3,r10,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f2,f6,f4
	ctx.f2.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// stfsx f2,r11,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfsx f6,r10,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f3,f28,f7
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f7.f64));
	// stfsx f3,r9,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f28.f64));
	// stfsx f7,r31,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f30,f5
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfsx f7,r9,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f5,f30
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfsx f7,r31,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 3532);
	// add r6,r22,r6
	ctx.r6.u64 = ctx.r22.u64 + ctx.r6.u64;
	// add r5,r22,r5
	ctx.r5.u64 = ctx.r22.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d73b94
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D73B94;
loc_82D74C20:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28f2c
	ctx.lr = 0x82D74C28;
	__restfpr_14(ctx, base);
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D74C30"))) PPC_WEAK_FUNC(sub_82D74C30);
PPC_FUNC_IMPL(__imp__sub_82D74C30) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2504
	ctx.r5.s64 = ctx.r11.s64 + 2504;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,15152
	ctx.r4.s64 = ctx.r11.s64 + 15152;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D74C48"))) PPC_WEAK_FUNC(sub_82D74C48);
PPC_FUNC_IMPL(__imp__sub_82D74C48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D74C50;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28ee0
	ctx.lr = 0x82D74C58;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d7514c
	if (!ctx.cr6.gt) goto loc_82D7514C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r23,r10,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f12,136(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-8016(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8016);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D74C8C:
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f11,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// mulli r31,r7,60
	ctx.r31.s64 = ctx.r7.s64 * 60;
	// lfs f10,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f21,f9,f11
	ctx.f21.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// lfsx f3,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// mulli r30,r7,28
	ctx.r30.s64 = ctx.r7.s64 * 28;
	// fadds f9,f8,f10
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// lfsx f2,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// lfsx f1,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f18,f1,f3
	ctx.f18.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// mulli r9,r7,48
	ctx.r9.s64 = ctx.r7.s64 * 48;
	// fsubs f1,f2,f31
	ctx.f1.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f4,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// mulli r29,r7,12
	ctx.r29.s64 = ctx.r7.s64 * 12;
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f30,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f29,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r28,r7,44
	ctx.r28.s64 = ctx.r7.s64 * 44;
	// lfsx f28,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f31,f28,f30
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// rlwinm r27,r7,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// mulli r26,r7,40
	ctx.r26.s64 = ctx.r7.s64 * 40;
	// fsubs f28,f29,f27
	ctx.f28.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// lfsx f26,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f23,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r25,r7,56
	ctx.r25.s64 = ctx.r7.s64 * 56;
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f23,f8,f21
	ctx.f23.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// fsubs f8,f21,f8
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// lfsx f22,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f9,f6
	ctx.f21.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fadds f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// lfsx f20,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// fsubs f15,f2,f29
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fsubs f16,f3,f28
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// fadds f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f3.f64));
	// lfsx f4,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f19,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f6,f4,f22
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f22.f64));
	// fadds f17,f19,f20
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f4.f64));
	// fsubs f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fsubs f20,f11,f5
	ctx.f20.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// fadds f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// fsubs f5,f10,f7
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f19,f30,f1
	ctx.f19.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fadds f7,f31,f18
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f18.f64));
	// fadds f29,f6,f27
	ctx.f29.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fsubs f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fsubs f28,f25,f17
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// fadds f27,f17,f25
	ctx.f27.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// fsubs f31,f18,f31
	ctx.f31.f64 = double(float(ctx.f18.f64 - ctx.f31.f64));
	// fsubs f30,f24,f26
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fsubs f25,f4,f22
	ctx.f25.f64 = double(float(ctx.f4.f64 - ctx.f22.f64));
	// mulli r9,r7,20
	ctx.r9.s64 = ctx.r7.s64 * 20;
	// fsubs f18,f31,f15
	ctx.f18.f64 = double(float(ctx.f31.f64 - ctx.f15.f64));
	// mulli r31,r7,52
	ctx.r31.s64 = ctx.r7.s64 * 52;
	// fadds f31,f31,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f15.f64));
	// fadds f14,f27,f9
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f9.f64));
	// fsubs f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f27.f64));
	// fadds f27,f28,f8
	ctx.f27.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// lfsx f15,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f29,f23
	ctx.f17.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// stfs f15,-272(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f15,-264(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// fsubs f23,f21,f6
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f6.f64));
	// fadds f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// fadds f6,f6,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f21.f64));
	// lfsx f15,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-268(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfsx f15,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f15,-260(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// mulli r10,r7,36
	ctx.r10.s64 = ctx.r7.s64 * 36;
	// lfsx f28,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f24,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f15,f24,f28
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// lfsx f21,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f22,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// fadds f24,f21,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// rlwinm r30,r8,5,0,26
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// rlwinm r29,r8,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r28,r8,48
	ctx.r28.s64 = ctx.r8.s64 * 48;
	// mulli r27,r8,40
	ctx.r27.s64 = ctx.r8.s64 * 40;
	// mulli r26,r8,24
	ctx.r26.s64 = ctx.r8.s64 * 24;
	// rlwinm r25,r8,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r24,r8,56
	ctx.r24.s64 = ctx.r8.s64 * 56;
	// lfs f22,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-256(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f21,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-252(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f21,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-268(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f21,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f21,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f21,-260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f21,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f24,f21
	ctx.f21.f64 = double(float(ctx.f24.f64 - ctx.f21.f64));
	// stfs f21,-264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f21,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// lfs f15,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f15.f64 = double(temp.f32);
	// fadds f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// stfs f24,-252(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f15,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// fsubs f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,-272(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f22,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// stfs f28,-256(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f28,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f22.f64 = double(temp.f32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// fadds f22,f21,f7
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f7.f64));
	// stfs f22,-248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fsubs f7,f7,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f21.f64));
	// lfs f22,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// fsubs f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// stfs f2,-252(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f21,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r8,44
	ctx.r11.s64 = ctx.r8.s64 * 44;
	// lfs f2,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f2.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fsubs f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// fadds f21,f18,f28
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// fsubs f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// lfs f18,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfsx f18,r30,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f18,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,0(r5)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f18,f14,f22
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfsx f18,r30,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,0(r6)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f22,f9,f7
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// stfsx f22,r29,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// stfsx f9,r28,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f2,f31
	ctx.f22.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// mulli r9,r8,60
	ctx.r9.s64 = ctx.r8.s64 * 60;
	// mulli r31,r8,28
	ctx.r31.s64 = ctx.r8.s64 * 28;
	// lfs f9,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f7,f29,f9
	ctx.f7.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// stfsx f7,r28,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f9,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// stfsx f9,r29,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fmuls f9,f21,f0
	ctx.f9.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f7,f28,f0
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fsubs f28,f25,f26
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// fadds f21,f31,f2
	ctx.f21.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fmuls f31,f22,f0
	ctx.f31.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fsubs f29,f27,f9
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// stfsx f29,r27,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f7,f23
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// stfsx f29,r26,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fadds f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// stfsx f9,r25,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fsubs f9,f23,f7
	ctx.f9.f64 = double(float(ctx.f23.f64 - ctx.f7.f64));
	// stfsx f9,r24,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fmuls f27,f15,f13
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmuls f29,f19,f13
	ctx.f29.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f7,f15,f12
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmuls f23,f19,f12
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f9,f30,f4
	ctx.f9.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmsubs f2,f24,f12,f27
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 - ctx.f27.f64));
	// fadds f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fmadds f7,f24,f13,f7
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f7.f64));
	// lfs f24,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f29,f16,f12,f29
	ctx.f29.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f29.f64));
	// fadds f26,f4,f30
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// fmadds f4,f16,f13,f23
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f23.f64));
	// fmuls f25,f19,f12
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// fmuls f23,f1,f12
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f18,f24,f12
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f30,f21,f0
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fadds f21,f28,f10
	ctx.f21.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f22,f29,f7
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fsubs f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 - ctx.f7.f64));
	// fadds f29,f4,f2
	ctx.f29.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// fmadds f25,f24,f13,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f25.f64));
	// fmsubs f24,f3,f13,f23
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 - ctx.f23.f64));
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// fadds f23,f9,f20
	ctx.f23.f64 = double(float(ctx.f9.f64 + ctx.f20.f64));
	// fsubs f2,f8,f31
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f31.f64));
	// stfsx f2,r24,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fsubs f9,f20,f9
	ctx.f9.f64 = double(float(ctx.f20.f64 - ctx.f9.f64));
	// fsubs f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// fadds f2,f30,f6
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// stfsx f2,r25,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fadds f8,f31,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f8.f64));
	// stfsx f8,r26,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f10,f7
	ctx.f28.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// add r3,r3,r23
	ctx.r3.u64 = ctx.r3.u64 + ctx.r23.u64;
	// fsubs f8,f6,f30
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// stfsx f8,r27,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// add r4,r4,r23
	ctx.r4.u64 = ctx.r4.u64 + ctx.r23.u64;
	// fsubs f30,f23,f22
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfsx f30,r11,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f21,f29
	ctx.f7.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// stfsx f7,r11,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f22,f23
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f30,r10,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f29,f21
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// stfsx f7,r10,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfsx f28,r9,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f9,f4
	ctx.f7.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// stfsx f7,r9,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f4,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// stfsx f10,r31,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f8,f27,f11
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f11.f64));
	// stfsx f9,r31,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fmuls f9,f3,f12
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fadds f2,f24,f25
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// fmsubs f10,f19,f13,f18
	ctx.f10.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f18.f64));
	// fsubs f6,f5,f26
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// fadds f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// fsubs f31,f24,f25
	ctx.f31.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fsubs f11,f11,f27
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f27.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r9,r8,52
	ctx.r9.s64 = ctx.r8.s64 * 52;
	// fmadds f9,f1,f13,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f9.f64));
	// fsubs f7,f8,f2
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// stfsx f7,r11,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f2,f8
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fsubs f3,f6,f31
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f31.f64));
	// fadds f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// mulli r31,r8,20
	ctx.r31.s64 = ctx.r8.s64 * 20;
	// fadds f8,f9,f10
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fsubs f9,f5,f8
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// stfsx f9,r11,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// stfsx f4,r10,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f8,f5
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// stfsx f9,r10,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f11,f10
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// stfsx f3,r9,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// stfsx f9,r9,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// stfsx f6,r31,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// add r6,r22,r6
	ctx.r6.u64 = ctx.r22.u64 + ctx.r6.u64;
	// stfsx f11,r31,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 3532);
	// add r5,r22,r5
	ctx.r5.u64 = ctx.r22.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d74c8c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D74C8C;
loc_82D7514C:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28f2c
	ctx.lr = 0x82D75154;
	__restfpr_14(ctx, base);
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D75158"))) PPC_WEAK_FUNC(sub_82D75158);
PPC_FUNC_IMPL(__imp__sub_82D75158) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2568
	ctx.r5.s64 = ctx.r11.s64 + 2568;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,19528
	ctx.r4.s64 = ctx.r11.s64 + 19528;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D75170"))) PPC_WEAK_FUNC(sub_82D75170);
PPC_FUNC_IMPL(__imp__sub_82D75170) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D75178;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28ee0
	ctx.lr = 0x82D75180;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d757e8
	if (!ctx.cr6.gt) goto loc_82D757E8;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r25,r10,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r24,r11,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32255
	ctx.r31.s64 = -2113863680;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f13,-7588(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f0,-7584(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f9,-12288(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -12288);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-7592(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7592);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-7656(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7656);
	ctx.f12.f64 = double(temp.f32);
loc_82D751CC:
	// mulli r11,r7,44
	ctx.r11.s64 = ctx.r7.s64 * 44;
	// lfs f8,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// mulli r9,r7,56
	ctx.r9.s64 = ctx.r7.s64 * 56;
	// lfsx f4,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f21,f4,f6
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fadds f20,f3,f5
	ctx.f20.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f2,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r31,r7,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f1,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f4,f4,f6
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// mulli r30,r7,20
	ctx.r30.s64 = ctx.r7.s64 * 20;
	// fsubs f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// lfsx f31,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f6,f31,f2
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fadds f5,f30,f1
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// lfsx f29,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r29,r7,40
	ctx.r29.s64 = ctx.r7.s64 * 40;
	// fsubs f31,f31,f2
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// fsubs f30,f1,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// lfsx f28,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// lfsx f27,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f26,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f2,f27,f29
	ctx.f2.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// mulli r28,r7,24
	ctx.r28.s64 = ctx.r7.s64 * 24;
	// fadds f1,f26,f28
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fsubs f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// fmuls f31,f31,f12
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// fmuls f30,f30,f12
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfsx f25,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f21,f25
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// mulli r27,r7,36
	ctx.r27.s64 = ctx.r7.s64 * 36;
	// fadds f26,f20,f24
	ctx.f26.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fnmsubs f24,f20,f11,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f11.f64 - ctx.f24.f64)));
	// fnmsubs f25,f21,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// fmuls f28,f28,f12
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfsx f23,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f21,f6,f23
	ctx.f21.f64 = double(float(ctx.f6.f64 + ctx.f23.f64));
	// fadds f20,f5,f22
	ctx.f20.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fnmsubs f6,f6,f11,f23
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f23.f64)));
	// mulli r10,r7,52
	ctx.r10.s64 = ctx.r7.s64 * 52;
	// fnmsubs f5,f5,f11,f22
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 - ctx.f22.f64)));
	// fadds f23,f2,f8
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fadds f22,f1,f7
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fnmsubs f8,f2,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// fnmsubs f7,f1,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fsubs f1,f24,f4
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// fadds f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// fsubs f2,f25,f3
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f3.f64));
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f18,f20,f26
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// mulli r31,r7,28
	ctx.r31.s64 = ctx.r7.s64 * 28;
	// fsubs f24,f6,f30
	ctx.f24.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// fsubs f17,f5,f31
	ctx.f17.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// fadds f6,f30,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// stfs f6,-236(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// lfsx f6,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f19,f21,f27
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// fsubs f16,f8,f28
	ctx.f16.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// fadds f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fadds f28,f7,f29
	ctx.f28.f64 = double(float(ctx.f7.f64 + ctx.f29.f64));
	// fsubs f7,f7,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// fsubs f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f20.f64));
	// fadds f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f31.f64));
	// fadds f29,f24,f2
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// fadds f15,f17,f1
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// fadds f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f25.f64));
	// mulli r29,r7,48
	ctx.r29.s64 = ctx.r7.s64 * 48;
	// lfsx f20,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f26,f13
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f20,-244(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// lfsx f20,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-240(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfsx f20,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-248(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfsx f20,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-288(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f20,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-280(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfsx f20,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-272(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfsx f20,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-264(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f20,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-256(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fadds f20,f31,f6
	ctx.f20.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// stfs f20,-284(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fsubs f20,f31,f6
	ctx.f20.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// lfsx f25,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f30,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f6,f25,f30
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// stfs f6,-276(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// fsubs f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// lfs f6,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f6.f64 = double(temp.f32);
	// lfs f31,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f31.f64 = double(temp.f32);
	// fadds f25,f31,f6
	ctx.f25.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// stfs f25,-268(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fsubs f25,f31,f6
	ctx.f25.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// lfs f6,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f6.f64 = double(temp.f32);
	// lfs f31,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f31,f6
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// stfs f31,-260(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f31,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f31.f64));
	// stfs f6,-240(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fmuls f31,f30,f12
	ctx.f31.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f6,f20,f12
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmuls f30,f25,f12
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f20,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f12
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// stfs f25,-244(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// lfs f25,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f25,-252(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f20,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f25,-288(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f20,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// stfs f25,-248(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f20,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f25,-240(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfs f20,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f20.f64)));
	// stfs f25,-280(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f20,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f20.f64)));
	// stfs f25,-272(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f20,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f20.f64)));
	// stfs f25,-264(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f20,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f20.f64)));
	// stfs f25,-268(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f20,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// lfs f20,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f20.f64 = double(temp.f32);
	// stfs f25,-276(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f25,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fsubs f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// stfs f20,-256(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f20,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// lfs f20,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// stfs f20,-284(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfs f20,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// fsubs f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f6.f64));
	// stfs f20,-260(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f20,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fadds f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// lfs f6,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f6.f64 = double(temp.f32);
	// fadds f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// stfs f6,-288(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f6,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f6.f64 = double(temp.f32);
	// lfs f31,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f31,f6
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// stfs f31,-280(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f31,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f31.f64 = double(temp.f32);
	// fadds f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// stfs f6,-244(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// lfs f6,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f31,f6,f30
	ctx.f31.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// stfs f31,-264(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// stfs f6,-240(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfs f6,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f6.f64 = double(temp.f32);
	// fadds f31,f6,f19
	ctx.f31.f64 = double(float(ctx.f6.f64 + ctx.f19.f64));
	// stfs f31,-272(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f30,f6,f19
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f19.f64));
	// stfs f27,-276(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f21,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f21.f64 = double(temp.f32);
	// mulli r9,r8,48
	ctx.r9.s64 = ctx.r8.s64 * 48;
	// lfs f27,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fsubs f21,f25,f18
	ctx.f21.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fmuls f30,f30,f10
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f6,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f6,f13
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// lfs f31,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f31.f64 = double(temp.f32);
	// lfs f6,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f26,f26,f0,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fadds f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// stfs f6,-268(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f19,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f0,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f14.f64));
	// lfs f31,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f31.f64 = double(temp.f32);
	// fadds f14,f25,f18
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f18.f64));
	// lfs f18,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f18.f64 = double(temp.f32);
	// lfs f25,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// stfs f14,-256(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f6,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f6.f64 = double(temp.f32);
	// fadds f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// stfs f6,-232(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// lfs f31,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f31.f64 = double(temp.f32);
	// lfs f6,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f6.f64 = double(temp.f32);
	// fadds f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// lfs f31,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f31,f20
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// lfs f18,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f18,f29
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f29.f64));
	// fadds f14,f14,f29
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f29.f64));
	// lfs f29,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f18,f29,f9,f23
	ctx.f18.f64 = double(float(-(ctx.f29.f64 * ctx.f9.f64 - ctx.f23.f64)));
	// fadds f29,f18,f30
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// fsubs f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 - ctx.f30.f64));
	// fadds f18,f6,f15
	ctx.f18.f64 = double(float(ctx.f6.f64 + ctx.f15.f64));
	// stfs f18,-264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fmuls f18,f17,f10
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// stfs f18,-260(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f18,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// fsubs f6,f6,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f15.f64));
	// lfs f15,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f15,f15,f9,f22
	ctx.f15.f64 = double(float(-(ctx.f15.f64 * ctx.f9.f64 - ctx.f22.f64)));
	// stfs f15,-248(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fnmsubs f15,f14,f9,f16
	ctx.f15.f64 = double(float(-(ctx.f14.f64 * ctx.f9.f64 - ctx.f16.f64)));
	// stfs f15,-252(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmuls f18,f1,f13
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f23,0(r5)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmuls f23,f27,f13
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// fmuls f17,f25,f13
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f15,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// mulli r30,r8,20
	ctx.r30.s64 = ctx.r8.s64 * 20;
	// fsubs f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// lfs f24,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// stfs f6,-268(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f6,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmsubs f1,f1,f0,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 - ctx.f17.f64));
	// mulli r29,r8,56
	ctx.r29.s64 = ctx.r8.s64 * 56;
	// fmadds f6,f27,f0,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fsubs f27,f29,f19
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// stfsx f27,r11,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f19.f64));
	// stfsx f29,r10,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmadds f29,f25,f0,f18
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f18.f64));
	// lfs f27,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f25,f30,f26
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// stfsx f25,r9,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfsx f30,r31,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fmsubs f27,f27,f0,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 - ctx.f23.f64));
	// stfs f22,0(r6)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f23,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f23.f64 = double(temp.f32);
	// mulli r28,r8,44
	ctx.r28.s64 = ctx.r8.s64 * 44;
	// fadds f19,f14,f16
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r8,5,0,26
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f26,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f26.f64 = double(temp.f32);
	// fadds f30,f26,f21
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// lfs f22,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// fadds f25,f22,f23
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fsubs f22,f30,f6
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// stfsx f22,r10,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f30,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// stfsx f6,r11,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// stfsx f6,r31,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfsx f6,r9,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f25,f29
	ctx.f6.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// stfsx f19,r30,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f6,r29,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f25,f29
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// stfsx f6,r28,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f23,f1
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f1.f64));
	// stfsx f6,r27,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f23,f1
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// stfsx f6,r26,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f25,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f25.f64 = double(temp.f32);
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// fadds f1,f25,f3
	ctx.f1.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// lfs f26,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f25.f64));
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// lfs f23,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// mulli r10,r8,28
	ctx.r10.s64 = ctx.r8.s64 * 28;
	// fadds f30,f31,f6
	ctx.f30.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// fsubs f25,f31,f6
	ctx.f25.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// lfs f6,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f6.f64 = double(temp.f32);
	// fadds f29,f23,f1
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// fsubs f6,f20,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 - ctx.f6.f64));
	// fsubs f24,f23,f1
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f1.f64));
	// lfs f31,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f31.f64 = double(temp.f32);
	// fnmsubs f4,f31,f9,f7
	ctx.f4.f64 = double(float(-(ctx.f31.f64 * ctx.f9.f64 - ctx.f7.f64)));
	// lfs f23,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f23.f64 = double(temp.f32);
	// fadds f7,f31,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// stfsx f7,r30,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fmuls f22,f27,f13
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// mulli r9,r8,52
	ctx.r9.s64 = ctx.r8.s64 * 52;
	// fnmsubs f31,f30,f9,f28
	ctx.f31.f64 = double(float(-(ctx.f30.f64 * ctx.f9.f64 - ctx.f28.f64)));
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f1,f25,f10
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f21,f26,f13
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f20,f3,f13
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f19,f6,f13
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fnmsubs f25,f29,f9,f8
	ctx.f25.f64 = double(float(-(ctx.f29.f64 * ctx.f9.f64 - ctx.f8.f64)));
	// fmuls f7,f24,f10
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f24,f2,f13
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f29,f29,f8
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// add r3,r25,r3
	ctx.r3.u64 = ctx.r25.u64 + ctx.r3.u64;
	// fmsubs f2,f2,f0,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f22.f64));
	// add r4,r25,r4
	ctx.r4.u64 = ctx.r25.u64 + ctx.r4.u64;
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fmsubs f3,f3,f0,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f21.f64));
	// fmadds f26,f26,f0,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f20.f64));
	// fmadds f27,f27,f0,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fadds f24,f4,f23
	ctx.f24.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// fsubs f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f23.f64));
	// fmuls f23,f5,f13
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmsubs f5,f5,f0,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fsubs f28,f24,f27
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfsx f28,r28,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f28,f24,f27
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// stfsx f28,r29,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmadds f8,f6,f0,f23
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f23.f64));
	// fsubs f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f31,f25,f7
	ctx.f31.f64 = double(float(ctx.f25.f64 - ctx.f7.f64));
	// fadds f28,f4,f2
	ctx.f28.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// stfsx f28,r27,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// stfsx f4,r26,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// stfsx f30,r11,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 + ctx.f7.f64));
	// fadds f4,f6,f3
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// stfsx f4,r10,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// stfsx f6,r9,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f1,f26
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// stfsx f6,r31,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f1,f26
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// stfsx f6,r30,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f29,r11,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f31,f5
	ctx.f6.f64 = double(float(ctx.f31.f64 - ctx.f5.f64));
	// stfsx f6,r10,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f31,f5
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// stfsx f6,r9,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f7,f8
	ctx.f6.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// stfsx f6,r30,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 3532);
	// add r5,r24,r5
	ctx.r5.u64 = ctx.r24.u64 + ctx.r5.u64;
	// add r6,r24,r6
	ctx.r6.u64 = ctx.r24.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d751cc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D751CC;
loc_82D757E8:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82e28f2c
	ctx.lr = 0x82D757F0;
	__restfpr_14(ctx, base);
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D757F8"))) PPC_WEAK_FUNC(sub_82D757F8);
PPC_FUNC_IMPL(__imp__sub_82D757F8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2632
	ctx.r5.s64 = ctx.r11.s64 + 2632;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,20848
	ctx.r4.s64 = ctx.r11.s64 + 20848;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D75810"))) PPC_WEAK_FUNC(sub_82D75810);
PPC_FUNC_IMPL(__imp__sub_82D75810) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D75818;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28ee0
	ctx.lr = 0x82D75820;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d75d50
	if (!ctx.cr6.gt) goto loc_82D75D50;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r24,r10,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f9,-4940(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -4940);
	ctx.f9.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f10,-4944(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -4944);
	ctx.f10.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f11,-4948(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -4948);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-4960(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -4960);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-4952(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4952);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-4956(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4956);
	ctx.f0.f64 = double(temp.f32);
loc_82D7586C:
	// mulli r9,r7,48
	ctx.r9.s64 = ctx.r7.s64 * 48;
	// lfs f7,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// lfs f5,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f2,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f16,f2,f31
	ctx.f16.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f31,f1,f30
	ctx.f31.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// mulli r29,r7,44
	ctx.r29.s64 = ctx.r7.s64 * 44;
	// fadds f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f4,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f29,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f28,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r10,r7,36
	ctx.r10.s64 = ctx.r7.s64 * 36;
	// lfsx f27,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f26,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f14,f29,f28
	ctx.f14.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f29,f27,f26
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f3,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f19,f6,f8
	ctx.f19.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// mulli r28,r7,40
	ctx.r28.s64 = ctx.r7.s64 * 40;
	// fsubs f20,f8,f6
	ctx.f20.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fadds f17,f3,f4
	ctx.f17.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f18,f4,f3
	ctx.f18.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfsx f25,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r27,r7,12
	ctx.r27.s64 = ctx.r7.s64 * 12;
	// lfsx f23,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f27,f25,f23
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// mulli r26,r7,24
	ctx.r26.s64 = ctx.r7.s64 * 24;
	// fadds f26,f23,f25
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f25,f24,f22
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f23,f2,f19
	ctx.f23.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// lfsx f21,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r7,52
	ctx.r11.s64 = ctx.r7.s64 * 52;
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f22,f21,f8
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// rlwinm r10,r7,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f8,-276(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// mulli r25,r7,28
	ctx.r25.s64 = ctx.r7.s64 * 28;
	// fsubs f21,f18,f31
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f31.f64));
	// stfs f21,-260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f4,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f8,f6,f4
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// stfs f8,-280(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfsx f3,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f8,f4,f6
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfs f8,-272(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f8,f7,f3
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// lfsx f15,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f3,f2,f19
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// fsubs f2,f17,f1
	ctx.f2.f64 = double(float(ctx.f17.f64 - ctx.f1.f64));
	// stfs f2,-236(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fadds f2,f31,f18
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f18.f64));
	// fadds f4,f16,f20
	ctx.f4.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fadds f31,f27,f14
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// fsubs f19,f30,f26
	ctx.f19.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// stfs f19,-248(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fsubs f6,f5,f15
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f15.f64));
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f20,-264(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fsubs f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f14.f64));
	// stfs f27,-284(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fadds f5,f15,f5
	ctx.f5.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fadds f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f17.f64));
	// fadds f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fsubs f27,f29,f25
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// stfs f27,-288(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f27,f24,f28
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f28.f64));
	// lfs f26,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f26.f64 = double(temp.f32);
	// fadds f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// lfs f24,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f24.f64 = double(temp.f32);
	// fadds f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f25,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f19,f26,f24
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfs f18,-272(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmuls f18,f31,f10
	ctx.f18.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// stfs f19,-252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fsubs f19,f25,f22
	ctx.f19.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfs f27,-240(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fadds f27,f25,f22
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfs f19,-280(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fmuls f14,f21,f13
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfsx f24,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f25,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fmuls f17,f29,f10
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fnmadds f18,f4,f11,f18
	ctx.f18.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmadds f16,f27,f9,f8
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fadds f15,f26,f30
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fnmadds f17,f2,f11,f17
	ctx.f17.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 + ctx.f17.f64)));
	// mulli r9,r8,36
	ctx.r9.s64 = ctx.r8.s64 * 36;
	// fmsubs f20,f20,f0,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fadds f19,f27,f31
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,-276(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f18,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f20,f18,f12,f20
	ctx.f20.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f20.f64)));
	// stfs f20,-268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f20,f19,f4
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// fmuls f18,f27,f10
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fadds f19,f15,f3
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// fadds f15,f20,f8
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f8.f64));
	// stfsx f15,r11,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fnmadds f20,f31,f11,f18
	ctx.f20.f64 = double(float(-(ctx.f31.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// stfs f20,-256(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fsubs f20,f25,f24
	ctx.f20.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// lfs f16,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f0,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f14.f64));
	// fadds f14,f19,f7
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f7.f64));
	// fadds f19,f24,f25
	ctx.f19.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfs f24,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f25,f22,f24
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f18,f24,f22
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// fsubs f22,f20,f25
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// fadds f24,f18,f19
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f20,-244(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// fmuls f20,f22,f13
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fadds f19,f25,f29
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fadds f18,f24,f28
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fmadds f16,f22,f12,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f16,-272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f16,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f21,f21,f0,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 - ctx.f20.f64));
	// fadds f19,f19,f2
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// fadds f18,f18,f1
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f1.f64));
	// fmadds f20,f25,f9,f6
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f6.f64));
	// fnmsubs f21,f16,f12,f21
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f21.f64)));
	// fadds f19,f19,f6
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f6.f64));
	// stfsx f19,r11,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// stfs f14,0(r5)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f19,f18,f5
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f5.f64));
	// stfs f19,0(r6)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f19,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f19,f21
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfsx f18,r10,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfsx f21,r9,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// lfs f21,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfsx f19,r10,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfsx f21,r9,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f21,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f25,f10
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f20,f21,f13
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f17,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f4,f10
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f15,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// mulli r11,r8,52
	ctx.r11.s64 = ctx.r8.s64 * 52;
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f16,f2,f10
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmadds f4,f4,f9,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmadds f2,f2,f9,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f6.f64));
	// fmadds f6,f29,f9,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f6.f64));
	// fmadds f14,f3,f9,f7
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fnmadds f19,f29,f11,f19
	ctx.f19.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 + ctx.f19.f64)));
	// fmadds f20,f15,f0,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f20.f64));
	// lfs f15,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f15.f64 = double(temp.f32);
	// fnmadds f27,f27,f11,f18
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// mulli r9,r8,44
	ctx.r9.s64 = ctx.r8.s64 * 44;
	// fmadds f18,f31,f9,f8
	ctx.f18.f64 = double(float(ctx.f31.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmadds f21,f21,f12,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmadds f22,f15,f12,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f22.f64));
	// fnmadds f17,f25,f11,f16
	ctx.f17.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 + ctx.f16.f64)));
	// lfs f16,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f16.f64 = double(temp.f32);
	// fadds f8,f16,f4
	ctx.f8.f64 = double(float(ctx.f16.f64 + ctx.f4.f64));
	// lfs f4,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f4.f64 = double(temp.f32);
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// fadds f31,f19,f2
	ctx.f31.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// lfs f2,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f4,f4,f12,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f20.f64));
	// lfs f20,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f20.f64 = double(temp.f32);
	// fadds f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// fnmsubs f29,f2,f13,f22
	ctx.f29.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f22.f64)));
	// lfs f2,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f2.f64 = double(temp.f32);
	// fadds f22,f17,f6
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f6.f64));
	// fsubs f18,f8,f20
	ctx.f18.f64 = double(float(ctx.f8.f64 - ctx.f20.f64));
	// stfsx f18,r11,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fnmsubs f25,f2,f13,f21
	ctx.f25.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f21.f64)));
	// lfs f2,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f6,f24,f10
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fadds f8,f8,f20
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f20.f64));
	// stfsx f8,r10,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f31,f4
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fmuls f21,f2,f12
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// rlwinm r10,r8,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f8,f31,f4
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f4.f64));
	// stfsx f8,r11,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f31,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f31.f64 = double(temp.f32);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fsubs f8,f27,f29
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfsx f8,r9,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f27,f29
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fmuls f29,f31,f12
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f4,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f4.f64 = double(temp.f32);
	// fadds f8,f22,f25
	ctx.f8.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfsx f8,r31,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fnmadds f19,f28,f11,f6
	ctx.f19.f64 = double(float(-(ctx.f28.f64 * ctx.f11.f64 + ctx.f6.f64)));
	// lfs f6,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f8,f22,f25
	ctx.f8.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfsx f8,r9,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fmuls f27,f26,f10
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f8,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f21,f23,f13,f21
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f21.f64));
	// rlwinm r9,r8,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f25,f6,f13
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// mulli r31,r8,40
	ctx.r31.s64 = ctx.r8.s64 * 40;
	// fmuls f22,f1,f10
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f20,f4,f13
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f18,f3,f10
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmsubs f16,f8,f13,f29
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 - ctx.f29.f64));
	// fmadds f17,f1,f9,f5
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f5.f64));
	// fnmadds f15,f30,f11,f27
	ctx.f15.f64 = double(float(-(ctx.f30.f64 * ctx.f11.f64 + ctx.f27.f64)));
	// fnmsubs f21,f6,f0,f21
	ctx.f21.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f21.f64)));
	// fmadds f29,f23,f12,f25
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f25.f64));
	// stfs f29,-236(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fnmadds f27,f24,f11,f22
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f11.f64 + ctx.f22.f64)));
	// stfs f27,-240(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fmadds f25,f28,f9,f5
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 + ctx.f5.f64));
	// stfs f25,-244(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// fadds f29,f19,f17
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fmadds f22,f8,f12,f20
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f20.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fmadds f20,f30,f9,f7
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f7.f64));
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fnmadds f18,f26,f11,f18
	ctx.f18.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// fnmsubs f27,f4,f0,f16
	ctx.f27.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f16.f64)));
	// fadds f25,f15,f14
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fmuls f28,f28,f10
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// fmadds f5,f24,f9,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f5.f64));
	// fmuls f30,f30,f10
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fnmadds f1,f1,f11,f28
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 + ctx.f28.f64)));
	// lfs f19,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f19.f64 = double(temp.f32);
	// stfs f22,-236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fnmsubs f22,f2,f0,f19
	ctx.f22.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f19.f64)));
	// lfs f19,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f19.f64 = double(temp.f32);
	// stfs f20,-240(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfs f17,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f19,f17
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fmuls f17,f23,f0
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmadds f6,f6,f12,f17
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmadds f6,f2,f13,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f6.f64));
	// fsubs f2,f29,f21
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f21.f64));
	// stfsx f2,r11,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f2,f29,f21
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// stfsx f2,r10,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f2,f25,f27
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// stfsx f2,r11,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f2,f25,f27
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfsx f2,r10,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f2,f20,f22
	ctx.f2.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfsx f2,r9,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f2,f20,f22
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfsx f2,r31,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r10,r8,48
	ctx.r10.s64 = ctx.r8.s64 * 48;
	// lfs f19,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f19,f31,f0,f19
	ctx.f19.f64 = double(float(-(ctx.f31.f64 * ctx.f0.f64 - ctx.f19.f64)));
	// lfs f16,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f18,f16
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// fsubs f2,f23,f19
	ctx.f2.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfsx f2,r9,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f2,f23,f19
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// stfsx f2,r31,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fmuls f2,f8,f0
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fadds f8,f1,f5
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fmadds f5,f4,f12,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f2.f64));
	// fnmadds f4,f3,f11,f30
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f30.f64)));
	// fmadds f3,f26,f9,f7
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fmadds f7,f31,f13,f5
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f13.f64 + ctx.f5.f64));
	// fadds f5,f4,f3
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// fadds f4,f8,f6
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfsx f4,r11,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// add r6,r23,r6
	ctx.r6.u64 = ctx.r23.u64 + ctx.r6.u64;
	// fsubs f8,f5,f7
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfsx f8,r10,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f5,f7
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// stfsx f8,r11,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 3532);
	// add r5,r23,r5
	ctx.r5.u64 = ctx.r23.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d7586c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D7586C;
loc_82D75D50:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28f2c
	ctx.lr = 0x82D75D58;
	__restfpr_14(ctx, base);
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D75D60"))) PPC_WEAK_FUNC(sub_82D75D60);
PPC_FUNC_IMPL(__imp__sub_82D75D60) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2696
	ctx.r5.s64 = ctx.r11.s64 + 2696;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,22544
	ctx.r4.s64 = ctx.r11.s64 + 22544;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D75D78"))) PPC_WEAK_FUNC(sub_82D75D78);
PPC_FUNC_IMPL(__imp__sub_82D75D78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D75D80;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82D75D88;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d764ec
	if (!ctx.cr6.gt) goto loc_82D764EC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r21,r10,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r20,r11,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f13,-48(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -48);
	ctx.f13.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// stfs f13,-364(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// stw r11,-360(r1)
	PPC_STORE_U32(ctx.r1.u32 + -360, ctx.r11.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f13,-44(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -44);
	ctx.f13.f64 = double(temp.f32);
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// stfs f13,-328(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// lfs f13,-4268(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -4268);
	ctx.f13.f64 = double(temp.f32);
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// stfs f13,-336(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// stw r11,-340(r1)
	PPC_STORE_U32(ctx.r1.u32 + -340, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,-32(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -32);
	ctx.f13.f64 = double(temp.f32);
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// stfs f13,-324(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f13,-4264(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -4264);
	ctx.f13.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// stfs f13,-332(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f13,-56(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -56);
	ctx.f13.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// stfs f13,-348(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f13,-52(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -52);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// stfs f13,-356(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f13,-36(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -36);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,-344(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f13,-40(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -40);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,-352(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f12,-7656(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7656);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,-64(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -64);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,-60(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -60);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,-4308(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -4308);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,-4312(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -4312);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,-4320(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -4320);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,-4316(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -4316);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,-6320(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -6320);
	ctx.f5.f64 = double(temp.f32);
	// lwz r11,-340(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	// lfs f13,-152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -152);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-360(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	// stfs f13,-340(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f13,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f13.f64 = double(temp.f32);
loc_82D75E7C:
	// mulli r9,r7,12
	ctx.r9.s64 = ctx.r7.s64 * 12;
	// lfs f4,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// mulli r31,r7,36
	ctx.r31.s64 = ctx.r7.s64 * 36;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f30,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f29,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f17,f29,f30
	ctx.f17.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// mulli r11,r7,40
	ctx.r11.s64 = ctx.r7.s64 * 40;
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfsx f2,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r30,r7,44
	ctx.r30.s64 = ctx.r7.s64 * 44;
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f28,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f19,f31,f2
	ctx.f19.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// mulli r29,r7,24
	ctx.r29.s64 = ctx.r7.s64 * 24;
	// lfsx f27,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f27,f28
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// mulli r28,r7,28
	ctx.r28.s64 = ctx.r7.s64 * 28;
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fsubs f15,f30,f2
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// fadds f2,f30,f2
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// lfsx f26,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// rlwinm r27,r7,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r7,5,0,26
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r25,r7,20
	ctx.r25.s64 = ctx.r7.s64 * 20;
	// fmuls f30,f15,f12
	ctx.f30.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfsx f25,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfsx f24,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfsx f21,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// mulli r11,r7,48
	ctx.r11.s64 = ctx.r7.s64 * 48;
	// lfsx f22,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfsx f20,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// rlwinm r24,r7,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmsubs f20,f19,f0,f20
	ctx.f20.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f20.f64)));
	// fadds f19,f27,f29
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fsubs f27,f29,f27
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fsubs f29,f28,f26
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// lfsx f31,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f16,f17,f31
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f31.f64));
	// fnmsubs f31,f17,f0,f31
	ctx.f31.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f31.f64)));
	// fadds f17,f26,f28
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fmuls f28,f27,f12
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fsubs f15,f2,f29
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fadds f27,f16,f21
	ctx.f27.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// fsubs f26,f16,f21
	ctx.f26.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// fsubs f21,f31,f20
	ctx.f21.f64 = double(float(ctx.f31.f64 - ctx.f20.f64));
	// fadds f31,f31,f20
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// fadds f20,f19,f25
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// fnmsubs f29,f17,f0,f24
	ctx.f29.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fadds f16,f17,f24
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// fnmsubs f25,f19,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fadds f24,f28,f21
	ctx.f24.f64 = double(float(ctx.f28.f64 + ctx.f21.f64));
	// fsubs f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// fsubs f21,f27,f20
	ctx.f21.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// lfs f20,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64));
	// fsubs f20,f30,f29
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f29,f31,f25
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f25.f64));
	// fadds f31,f25,f31
	ctx.f31.f64 = double(float(ctx.f25.f64 + ctx.f31.f64));
	// lfsx f25,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-368(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfsx f25,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-372(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfsx f25,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-400(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfsx f25,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-388(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmuls f17,f20,f6
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfsx f25,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fadds f14,f27,f4
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// stfs f25,-396(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fmuls f19,f30,f8
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// lfsx f25,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-320(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfsx f25,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-392(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfsx f25,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f14,0(r5)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfs f25,-376(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f25,f16,f10
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmadds f17,f24,f7,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f17.f64));
	// stfs f17,-360(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f17,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f17,f1
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// lfs f14,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f19,f28,f9,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 - ctx.f19.f64));
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-400(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmadds f25,f26,f11,f25
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 + ctx.f25.f64));
	// lfs f17,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-388(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f14,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-316(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f17,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-396(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f17,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f17,-320(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// stfs f17,-312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f17,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-372(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f17,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f1,f17
	ctx.f17.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// lfs f1,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f14.f64));
	// stfs f1,-368(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// lfs f1,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f14,f14,f1
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f1.f64));
	// stfs f14,-400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// fadds f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// stfs f1,-392(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f1,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f1.f64 = double(temp.f32);
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f1,f14
	ctx.f14.f64 = double(float(ctx.f1.f64 - ctx.f14.f64));
	// lfs f1,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f1,f0,f18
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f18.f64)));
	// stfs f1,-384(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f18,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f18.f64 = double(temp.f32);
	// lfs f1,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f1,f0,f18
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f18.f64)));
	// fmuls f18,f17,f12
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f17,f14,f12
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f17,-376(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f17,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r8,48
	ctx.r10.s64 = ctx.r8.s64 * 48;
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f17,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f14,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f14,-372(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// mulli r9,r8,20
	ctx.r9.s64 = ctx.r8.s64 * 20;
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-396(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f1,f14
	ctx.f14.f64 = double(float(ctx.f1.f64 + ctx.f14.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f14.f64));
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f23,f14,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f22,f14,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// stfs f22,-312(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// rlwinm r31,r8,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f22,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f1.f64));
	// stfs f22,-388(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f1,f1,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f22.f64));
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfs f22,-368(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f23,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f23.f64 = double(temp.f32);
	// stfs f22,-316(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fmuls f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f23.f64));
	// stfs f23,-372(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f23,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f14,f23,f18
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f14,-312(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f23,-376(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f18,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f23,0(r6)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f23,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f18,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f23,f14,f18,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f18.f64 + ctx.f23.f64));
	// lfs f18,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f17,f18,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 + ctx.f22.f64));
	// fadds f18,f22,f23
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fmuls f22,f20,f7
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fmuls f20,f30,f9
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// lfs f30,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// lfs f30,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fmsubs f30,f24,f6,f22
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 - ctx.f22.f64));
	// lfs f24,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f8,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f8.f64 + ctx.f20.f64));
	// fmsubs f24,f24,f22,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f14,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f26,f10
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fmsubs f22,f22,f14,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f14.f64 - ctx.f17.f64));
	// lfs f17,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// mulli r29,r8,40
	ctx.r29.s64 = ctx.r8.s64 * 40;
	// fnmsubs f3,f17,f14,f3
	ctx.f3.f64 = double(float(-(ctx.f17.f64 * ctx.f14.f64 - ctx.f3.f64)));
	// lfs f17,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f28,f30
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lfs f26,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// mulli r28,r8,12
	ctx.r28.s64 = ctx.r8.s64 * 12;
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f17,f30,f28
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f30,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// fmsubs f20,f16,f11,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f20.f64));
	// fsubs f16,f3,f22
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// fmuls f14,f14,f5
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// stfs f14,-360(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f3,f22,f13,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f3.f64));
	// fmadds f24,f24,f13,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f14.f64));
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// mulli r27,r8,36
	ctx.r27.s64 = ctx.r8.s64 * 36;
	// fadds f28,f26,f25
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fmsubs f26,f26,f13,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f25.f64));
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fmadds f20,f17,f13,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f20.f64));
	// fadds f14,f16,f30
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// fsubs f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// mulli r26,r8,24
	ctx.r26.s64 = ctx.r8.s64 * 24;
	// fadds f17,f3,f24
	ctx.f17.f64 = double(float(ctx.f3.f64 + ctx.f24.f64));
	// fsubs f3,f3,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f24.f64));
	// fadds f25,f19,f23
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// fadds f19,f28,f18
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// fsubs f24,f14,f22
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// mulli r25,r8,44
	ctx.r25.s64 = ctx.r8.s64 * 44;
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// fadds f14,f17,f20
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfsx f14,r11,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfsx f20,r10,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f20,f3,f26
	ctx.f20.f64 = double(float(ctx.f3.f64 + ctx.f26.f64));
	// stfsx f20,r9,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f3,f3,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// stfsx f3,r31,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f26,f20,f9
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// rlwinm r24,r8,3,0,28
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r23,r8,28
	ctx.r23.s64 = ctx.r8.s64 * 28;
	// fsubs f3,f24,f25
	ctx.f3.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// stfsx f3,r30,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f3,f25,f24
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfsx f3,r29,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f3,f22,f23
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f3,r28,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f3,f22,f23
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f3,r27,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fmuls f25,f1,f6
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f22,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f11
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// lfs f16,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f30,f16
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// fsubs f3,f16,f19
	ctx.f3.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfsx f3,r26,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f24,f15,f3
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// lfs f3,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f2,f3
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmadds f3,f22,f8,f26
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f8.f64 + ctx.f26.f64));
	// lfs f26,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f7,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f25.f64));
	// lfs f25,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f25,f29,f25,f24
	ctx.f25.f64 = double(float(ctx.f29.f64 * ctx.f25.f64 - ctx.f24.f64));
	// lfs f24,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f31,f24,f17
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f24.f64 + ctx.f17.f64));
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fnmsubs f4,f27,f17,f4
	ctx.f4.f64 = double(float(-(ctx.f27.f64 * ctx.f17.f64 - ctx.f4.f64)));
	// lfs f27,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f1,f7
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// add r3,r21,r3
	ctx.r3.u64 = ctx.r21.u64 + ctx.r3.u64;
	// fmsubs f1,f27,f10,f14
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f14.f64));
	// lfs f14,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f29,f14
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f14.f64));
	// lfs f29,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// add r4,r21,r4
	ctx.r4.u64 = ctx.r21.u64 + ctx.r4.u64;
	// fmsubs f29,f29,f6,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f17,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f31,f17
	ctx.f17.f64 = double(float(ctx.f31.f64 * ctx.f17.f64));
	// fmsubs f31,f22,f9,f20
	ctx.f31.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 - ctx.f20.f64));
	// fmuls f22,f27,f11
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f27,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f27.f64 = double(temp.f32);
	// fadds f20,f19,f16
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfsx f20,r25,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// lfs f19,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f26,f3
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// lfs f27,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f15,f27,f14
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f27.f64 + ctx.f14.f64));
	// fmsubs f2,f2,f19,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64 - ctx.f17.f64));
	// fmadds f23,f23,f10,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f22.f64));
	// fsubs f22,f3,f26
	ctx.f22.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// fsubs f26,f4,f24
	ctx.f26.f64 = double(float(ctx.f4.f64 - ctx.f24.f64));
	// fmadds f4,f24,f13,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f4.f64));
	// fadds f24,f31,f29
	ctx.f24.f64 = double(float(ctx.f31.f64 + ctx.f29.f64));
	// fsubs f29,f29,f31
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// fsubs f3,f21,f25
	ctx.f3.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// fmadds f25,f25,f13,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f21.f64));
	// fadds f31,f30,f28
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// stfsx f31,r24,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fsubs f31,f30,f28
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfsx f31,r23,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fadds f31,f2,f27
	ctx.f31.f64 = double(float(ctx.f2.f64 + ctx.f27.f64));
	// add r6,r20,r6
	ctx.r6.u64 = ctx.r20.u64 + ctx.r6.u64;
	// fsubs f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 - ctx.f2.f64));
	// fmuls f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// fmuls f30,f29,f5
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// fsubs f29,f1,f22
	ctx.f29.f64 = double(float(ctx.f1.f64 - ctx.f22.f64));
	// fadds f27,f4,f25
	ctx.f27.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// fmadds f1,f22,f13,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fsubs f28,f26,f3
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fadds f26,f24,f23
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// fsubs f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// fsubs f21,f31,f30
	ctx.f21.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// fadds f31,f30,f31
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fmsubs f30,f24,f13,f23
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f23.f64));
	// fsubs f22,f27,f1
	ctx.f22.f64 = double(float(ctx.f27.f64 - ctx.f1.f64));
	// stfsx f22,r10,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f25,f28,f20
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// fsubs f22,f3,f29
	ctx.f22.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fsubs f19,f26,f2
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f2.f64));
	// fadds f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f20.f64));
	// fadds f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// fadds f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// stfsx f1,r11,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// fsubs f26,f4,f30
	ctx.f26.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// fsubs f1,f22,f21
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfsx f1,r29,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f1,f21,f22
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f1,r30,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f26,r9,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f1,f25,f19
	ctx.f1.f64 = double(float(ctx.f25.f64 - ctx.f19.f64));
	// stfsx f4,r31,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f19,f25
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// stfsx f1,r25,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fsubs f27,f28,f2
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f2.f64));
	// stfsx f29,r26,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// stfsx f27,r23,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f3,f31
	ctx.f28.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// stfsx f2,r24,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f31,f3
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfsx f28,r28,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// stfsx f4,r27,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 3532);
	// add r5,r20,r5
	ctx.r5.u64 = ctx.r20.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d75e7c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D75E7C;
loc_82D764EC:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82D764F4;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D764F8"))) PPC_WEAK_FUNC(sub_82D764F8);
PPC_FUNC_IMPL(__imp__sub_82D764F8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2760
	ctx.r5.s64 = ctx.r11.s64 + 2760;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,23928
	ctx.r4.s64 = ctx.r11.s64 + 23928;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D76510"))) PPC_WEAK_FUNC(sub_82D76510);
PPC_FUNC_IMPL(__imp__sub_82D76510) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D76518;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28ee0
	ctx.lr = 0x82D76520;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d76834
	if (!ctx.cr6.gt) goto loc_82D76834;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r23,r10,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f13,-7656(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D7654C:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r7,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f12,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r9,r7,40
	ctx.r9.s64 = ctx.r7.s64 * 40;
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f22,f9,f10
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfsx f7,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f21,f9,f10
	ctx.f21.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// rlwinm r31,r7,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f6,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// mulli r30,r7,28
	ctx.r30.s64 = ctx.r7.s64 * 28;
	// fadds f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f5,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f20,f8,f7
	ctx.f20.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f9,f4,f6
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfsx f2,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// mulli r29,r7,44
	ctx.r29.s64 = ctx.r7.s64 * 44;
	// lfsx f1,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f19,f4,f6
	ctx.f19.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fsubs f18,f5,f3
	ctx.f18.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fmuls f7,f21,f13
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fadds f21,f10,f11
	ctx.f21.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fnmsubs f11,f10,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfsx f31,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f6,f20,f13
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfsx f30,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f5,f31,f2
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// rlwinm r28,r7,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f4,f30,f1
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// mulli r27,r7,20
	ctx.r27.s64 = ctx.r7.s64 * 20;
	// fsubs f30,f1,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fsubs f31,f31,f2
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// fmuls f3,f19,f13
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f2,f18,f13
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfsx f29,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f28,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f20,f11,f7
	ctx.f20.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// fadds f1,f28,f29
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// mulli r26,r7,24
	ctx.r26.s64 = ctx.r7.s64 * 24;
	// fsubs f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fadds f28,f22,f12
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fnmsubs f12,f22,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fmuls f31,f31,f13
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// fmuls f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfsx f27,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f26,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f10,f9,f27
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// mulli r25,r7,12
	ctx.r25.s64 = ctx.r7.s64 * 12;
	// fnmsubs f9,f9,f0,f27
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// fadds f22,f8,f26
	ctx.f22.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// fnmsubs f8,f8,f0,f26
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// fmuls f29,f29,f13
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fadds f15,f6,f12
	ctx.f15.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// lfsx f25,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f5,f25
	ctx.f27.f64 = double(float(ctx.f5.f64 + ctx.f25.f64));
	// mulli r24,r7,36
	ctx.r24.s64 = ctx.r7.s64 * 36;
	// fnmsubs f5,f5,f0,f25
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fadds f26,f4,f24
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// fnmsubs f4,f4,f0,f24
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// lfsx f24,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f14,f10,f28
	ctx.f14.f64 = double(float(ctx.f10.f64 + ctx.f28.f64));
	// stfs f14,-256(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fadds f18,f8,f3
	ctx.f18.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// lfsx f23,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f25,f1,f23
	ctx.f25.f64 = double(float(ctx.f1.f64 + ctx.f23.f64));
	// lfsx f19,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f1,f1,f0,f23
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfsx f23,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fadds f17,f30,f5
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// fadds f16,f4,f31
	ctx.f16.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fadds f14,f25,f27
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f14,-252(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// mulli r9,r8,36
	ctx.r9.s64 = ctx.r8.s64 * 36;
	// fsubs f25,f21,f22
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fsubs f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// fadds f14,f22,f21
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f22,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f22.f64 = double(temp.f32);
	// fadds f3,f23,f24
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f21,f24,f23
	ctx.f21.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f23,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f10.f64));
	// fsubs f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// mulli r30,r8,28
	ctx.r30.s64 = ctx.r8.s64 * 28;
	// fsubs f31,f20,f18
	ctx.f31.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// fadds f28,f18,f20
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fsubs f20,f23,f22
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfsx f20,r11,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f20,f25,f27
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f18,f25,f27
	ctx.f18.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fsubs f27,f7,f8
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fadds f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,0(r5)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f7,f3,f19
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// mulli r29,r8,40
	ctx.r29.s64 = ctx.r8.s64 * 40;
	// fmuls f23,f21,f13
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fnmsubs f3,f3,f0,f19
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f19.f64)));
	// fadds f11,f2,f9
	ctx.f11.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// fsubs f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f6.f64));
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// rlwinm r28,r8,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// add r3,r23,r3
	ctx.r3.u64 = ctx.r23.u64 + ctx.r3.u64;
	// add r4,r23,r4
	ctx.r4.u64 = ctx.r23.u64 + ctx.r4.u64;
	// fadds f22,f7,f26
	ctx.f22.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// fadds f25,f23,f1
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// fsubs f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 - ctx.f7.f64));
	// fadds f26,f3,f29
	ctx.f26.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// fsubs f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fsubs f24,f15,f11
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f11.f64));
	// fadds f11,f11,f15
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f15.f64));
	// fsubs f29,f14,f22
	ctx.f29.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfsx f29,r11,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f21,f17,f25
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fadds f29,f22,f14
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f29,0(r6)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// stfsx f20,r10,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfsx f18,r9,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f10,f7
	ctx.f29.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// stfsx f29,r10,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfsx f10,r9,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f16,f26
	ctx.f10.f64 = double(float(ctx.f16.f64 - ctx.f26.f64));
	// fadds f7,f26,f16
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// mulli r10,r8,44
	ctx.r10.s64 = ctx.r8.s64 * 44;
	// fsubs f29,f31,f21
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f21.f64));
	// stfsx f29,r31,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f31,f21,f31
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f31.f64));
	// fsubs f29,f11,f25
	ctx.f29.f64 = double(float(ctx.f11.f64 - ctx.f25.f64));
	// fadds f26,f11,f25
	ctx.f26.f64 = double(float(ctx.f11.f64 + ctx.f25.f64));
	// fsubs f11,f4,f3
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f3,f24,f10
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f10.f64));
	// stfsx f3,r31,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// stfsx f31,r30,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f24,f10
	ctx.f10.f64 = double(float(ctx.f24.f64 - ctx.f10.f64));
	// stfsx f10,r30,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f28,f7
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f7.f64));
	// stfsx f29,r29,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f28.f64));
	// stfsx f10,r29,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f5,f30
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// stfsx f26,r28,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r31,r8,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// stfsx f7,r28,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f1,f23
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// fsubs f6,f8,f4
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// fadds f5,f4,f8
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fsubs f8,f10,f7
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fsubs f7,f12,f9
	ctx.f7.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// fadds f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fsubs f9,f27,f8
	ctx.f9.f64 = double(float(ctx.f27.f64 - ctx.f8.f64));
	// stfsx f9,r11,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f9,f8,f27
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f27.f64));
	// fadds f8,f7,f11
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f8,r11,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// stfsx f9,r10,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 - ctx.f11.f64));
	// stfsx f11,r10,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f12,f10
	ctx.f11.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfsx f11,r9,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// stfsx f6,r9,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// stfsx f12,r31,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// add r5,r22,r5
	ctx.r5.u64 = ctx.r22.u64 + ctx.r5.u64;
	// stfsx f5,r31,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 3532);
	// add r6,r22,r6
	ctx.r6.u64 = ctx.r22.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d7654c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D7654C;
loc_82D76834:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82e28f2c
	ctx.lr = 0x82D7683C;
	__restfpr_14(ctx, base);
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D76840"))) PPC_WEAK_FUNC(sub_82D76840);
PPC_FUNC_IMPL(__imp__sub_82D76840) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2824
	ctx.r5.s64 = ctx.r11.s64 + 2824;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,25872
	ctx.r4.s64 = ctx.r11.s64 + 25872;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D76858"))) PPC_WEAK_FUNC(sub_82D76858);
PPC_FUNC_IMPL(__imp__sub_82D76858) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D76860;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28ee0
	ctx.lr = 0x82D76868;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d76df8
	if (!ctx.cr6.gt) goto loc_82D76DF8;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r24,r10,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f5,108(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f6,104(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lfs f7,100(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 100);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f8,96(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 96);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f9,92(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 92);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,88(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f11,84(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,80(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,76(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 76);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f0.f64 = double(temp.f32);
loc_82D768D4:
	// rlwinm r26,r7,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f4,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// mulli r25,r7,36
	ctx.r25.s64 = ctx.r7.s64 * 36;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,-284(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfsx f2,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// stfs f2,-272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// mulli r10,r7,28
	ctx.r10.s64 = ctx.r7.s64 * 28;
	// lfsx f15,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f1,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// mulli r9,r7,20
	ctx.r9.s64 = ctx.r7.s64 * 20;
	// lfsx f29,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f22,f31,f1
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfs f22,-268(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fsubs f31,f30,f29
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// stfs f31,-304(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fadds f1,f29,f30
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfsx f27,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f28,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r31,r7,24
	ctx.r31.s64 = ctx.r7.s64 * 24;
	// lfsx f25,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f29,f27,f25
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfs f29,-292(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// fadds f30,f25,f27
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfsx f26,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f31,f26,f28
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f29,f26,f28
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfs f29,-288(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f23,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f24,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// rlwinm r29,r7,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r28,r7,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r27,r7,40
	ctx.r27.s64 = ctx.r7.s64 * 40;
	// lfsx f21,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f23,f21
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f27,-296(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfsx f19,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f28,f21,f23
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfsx f18,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f14,f15
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fsubs f26,f19,f18
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f23,-280(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fadds f27,f18,f19
	ctx.f27.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfsx f20,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f29,f20,f24
	ctx.f29.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// lfsx f17,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f20,f24
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// fadds f21,f16,f17
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f26,-260(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f19,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f25,f16,f17
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fadds f24,f14,f15
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f21,-248(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f18,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f30,f1
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f23,f18,f19
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f25,-264(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f20,-276(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// fadds f18,f31,f2
	ctx.f18.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f24,-300(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// stfs f23,-272(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// stfs f19,-284(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fmuls f14,f21,f8
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// fadds f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// lfs f15,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f18,f29
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// fadds f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// lfs f16,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f11
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// fmsubs f16,f15,f12,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f16.f64));
	// lfs f15,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fadds f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fmadds f15,f26,f0,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f15.f64));
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fnmadds f24,f24,f9,f14
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f9.f64 + ctx.f14.f64)));
	// fmuls f14,f23,f8
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fmuls f23,f1,f9
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// stfs f23,-256(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r31,r8,36
	ctx.r31.s64 = ctx.r8.s64 * 36;
	// fadds f18,f17,f27
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f27.f64));
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fmuls f16,f22,f10
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f15,f25,f11
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// fadds f21,f21,f4
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f4.f64));
	// stfs f21,0(r5)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmadds f20,f25,f0,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f20.f64));
	// fadds f21,f18,f3
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// stfs f21,0(r6)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fnmsubs f21,f19,f10,f17
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f10.f64 - ctx.f17.f64)));
	// lfs f19,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// stfs f21,-252(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmuls f18,f27,f8
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmuls f17,f1,f6
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f21,f2,f6
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmsubs f22,f22,f12,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f19.f64));
	// lfs f19,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f19.f64 = double(temp.f32);
	// fnmadds f19,f19,f9,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f9.f64 + ctx.f18.f64)));
	// fmsubs f18,f30,f7,f17
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 - ctx.f17.f64));
	// lfs f17,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f17.f64 = double(temp.f32);
	// fnmadds f17,f17,f13,f16
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64)));
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// fmr f23,f16
	ctx.f23.f64 = ctx.f16.f64;
	// fmsubs f21,f31,f7,f21
	ctx.f21.f64 = double(float(ctx.f31.f64 * ctx.f7.f64 - ctx.f21.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fadds f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// fmadds f19,f28,f5,f3
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fmadds f16,f23,f0,f15
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f15.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// fnmadds f15,f28,f6,f14
	ctx.f15.f64 = double(float(-(ctx.f28.f64 * ctx.f6.f64 + ctx.f14.f64)));
	// fmadds f21,f29,f5,f4
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f5.f64 + ctx.f4.f64));
	// fnmsubs f23,f23,f10,f22
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f10.f64 - ctx.f22.f64)));
	// lfs f14,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// fmsubs f14,f30,f5,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f5.f64 - ctx.f14.f64));
	// lfs f19,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f19.f64 = double(temp.f32);
	// fadds f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fmadds f16,f27,f7,f3
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f3.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// lfs f21,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fmuls f15,f21,f10
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fnmsubs f21,f19,f12,f18
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f12.f64 - ctx.f18.f64)));
	// lfs f18,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f17,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fnmadds f15,f18,f13,f15
	ctx.f15.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 + ctx.f15.f64)));
	// lfs f18,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f24,f18
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfsx f16,r11,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f18.f64));
	// stfsx f24,r10,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f24,r10,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f24,r11,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f26,f11
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// fmuls f23,f2,f9
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fmuls f22,f22,f10
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fadds f24,f20,f21
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfsx f24,r9,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f20,f21
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfsx f24,r31,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f24,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f8
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f24,f29,f6,f24
	ctx.f24.f64 = double(float(-(ctx.f29.f64 * ctx.f6.f64 + ctx.f24.f64)));
	// lfs f16,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f23,f31,f5,f23
	ctx.f23.f64 = double(float(ctx.f31.f64 * ctx.f5.f64 - ctx.f23.f64));
	// fmadds f17,f16,f0,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f17.f64));
	// lfs f16,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f16,f0,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f22.f64));
	// lfs f16,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f16,f11,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f26.f64));
	// lfs f16,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f31,f6
	ctx.f20.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f21,f2,f8
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fmuls f19,f19,f10
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f18,f1,f8
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmuls f14,f30,f6
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// lfs f23,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f23.f64 = double(temp.f32);
	// stfs f26,-248(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fmr f26,f23
	ctx.f26.f64 = ctx.f23.f64;
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fmsubs f20,f16,f7,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 - ctx.f20.f64));
	// lfs f16,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f16.f64 = double(temp.f32);
	// fnmadds f21,f29,f9,f21
	ctx.f21.f64 = double(float(-(ctx.f29.f64 * ctx.f9.f64 + ctx.f21.f64)));
	// fmadds f19,f16,f0,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f19.f64));
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f25,f16,f11,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f25.f64));
	// lfs f16,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f16.f64 = double(temp.f32);
	// fnmadds f18,f28,f9,f18
	ctx.f18.f64 = double(float(-(ctx.f28.f64 * ctx.f9.f64 + ctx.f18.f64)));
	// fmsubs f14,f16,f7,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 - ctx.f14.f64));
	// fmadds f15,f26,f7,f4
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fadds f25,f19,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// lfs f19,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f19.f64 = double(temp.f32);
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// lfs f23,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,-248(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fadds f22,f21,f20
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f22,-252(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmadds f21,f26,f5,f4
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f4.f64));
	// stfs f21,-256(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fadds f21,f24,f15
	ctx.f21.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// lfs f24,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f24.f64 = double(temp.f32);
	// stfs f25,-292(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmr f25,f24
	ctx.f25.f64 = ctx.f24.f64;
	// fmadds f20,f27,f5,f3
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fmr f23,f19
	ctx.f23.f64 = ctx.f19.f64;
	// fnmsubs f22,f23,f12,f17
	ctx.f22.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f17.f64)));
	// fsubs f15,f21,f22
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfsx f15,r31,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f22,r9,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// mulli r9,r8,12
	ctx.r9.s64 = ctx.r8.s64 * 12;
	// fmuls f21,f23,f11
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// lfs f24,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f24.f64 = double(temp.f32);
	// stfs f20,-248(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fmadds f20,f25,f12,f24
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 + ctx.f24.f64));
	// lfs f24,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f24,f19
	ctx.f19.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// lfs f18,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f18,f24,f12,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f18.f64));
	// fsubs f22,f19,f20
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f22,f19,f20
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfsx f22,r10,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f20,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f31,f8
	ctx.f19.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f17,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fadds f22,f17,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfsx f22,r10,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f17,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfsx f22,r11,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r10,r8,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f18,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f22,f10
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f17,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fmuls f17,f17,f10
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f22,f14,f13,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f22.f64));
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fmsubs f14,f2,f5,f19
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f5.f64 - ctx.f19.f64));
	// lfs f19,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f21,f25,f0,f21
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 - ctx.f21.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fnmadds f20,f26,f9,f20
	ctx.f20.f64 = double(float(-(ctx.f26.f64 * ctx.f9.f64 + ctx.f20.f64)));
	// fmsubs f18,f24,f0,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 - ctx.f18.f64));
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fmuls f15,f30,f8
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// fmuls f30,f30,f9
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fmuls f31,f31,f9
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f9.f64));
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fmadds f17,f19,f13,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fadds f21,f20,f14
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// fmadds f20,f29,f7,f4
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fnmadds f16,f27,f9,f16
	ctx.f16.f64 = double(float(-(ctx.f27.f64 * ctx.f9.f64 + ctx.f16.f64)));
	// fmsubs f15,f1,f5,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 - ctx.f15.f64));
	// fmsubs f30,f1,f7,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 - ctx.f30.f64));
	// fmuls f29,f29,f8
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fadds f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f18,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f18,-248(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f17,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f2,f2,f7,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 - ctx.f31.f64));
	// fnmsubs f22,f17,f12,f22
	ctx.f22.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f22.f64)));
	// lfs f31,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f31.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f20.f64 = double(temp.f32);
	// fmr f18,f20
	ctx.f18.f64 = ctx.f20.f64;
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// fmadds f15,f28,f7,f3
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f7.f64 + ctx.f3.f64));
	// fmuls f28,f28,f8
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fnmadds f29,f26,f6,f29
	ctx.f29.f64 = double(float(-(ctx.f26.f64 * ctx.f6.f64 + ctx.f29.f64)));
	// fmadds f3,f31,f5,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fnmsubs f20,f18,f12,f14
	ctx.f20.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f14.f64)));
	// fmuls f14,f19,f11
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fadds f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f16,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f16.f64 = double(temp.f32);
	// fnmadds f28,f27,f6,f28
	ctx.f28.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 + ctx.f28.f64)));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fmsubs f24,f24,f10,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f14.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lfs f28,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f5,f4
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f5.f64 + ctx.f4.f64));
	// fadds f4,f30,f3
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fadds f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// lfs f15,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f16,f0,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f15.f64));
	// fadds f27,f16,f24
	ctx.f27.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// lfs f24,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// fnmsubs f1,f18,f13,f27
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f27.f64)));
	// fsubs f27,f21,f22
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfsx f27,r10,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f21,f22
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f27,r9,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f19,f20
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfsx f27,r9,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f19,f20
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfsx f27,r10,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f25,f25,f10,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f24.f64));
	// fmuls f27,f27,f12
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fmadds f27,f23,f0,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f27.f64));
	// fadds f31,f27,f25
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// fnmsubs f3,f17,f13,f31
	ctx.f3.f64 = double(float(-(ctx.f17.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// fadds f31,f4,f1
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// stfsx f31,r11,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f1.f64));
	// stfsx f4,r10,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// add r6,r23,r6
	ctx.r6.u64 = ctx.r23.u64 + ctx.r6.u64;
	// fsubs f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// stfsx f4,r10,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfsx f4,r11,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 3532);
	// add r5,r23,r5
	ctx.r5.u64 = ctx.r23.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d768d4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D768D4;
loc_82D76DF8:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28f2c
	ctx.lr = 0x82D76E00;
	__restfpr_14(ctx, base);
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D76E08"))) PPC_WEAK_FUNC(sub_82D76E08);
PPC_FUNC_IMPL(__imp__sub_82D76E08) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2888
	ctx.r5.s64 = ctx.r11.s64 + 2888;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,26712
	ctx.r4.s64 = ctx.r11.s64 + 26712;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D76E20"))) PPC_WEAK_FUNC(sub_82D76E20);
PPC_FUNC_IMPL(__imp__sub_82D76E20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D76E28;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28ee4
	ctx.lr = 0x82D76E30;
	__savefpr_15(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d770f4
	if (!ctx.cr6.gt) goto loc_82D770F4;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r24,r10,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32255
	ctx.r31.s64 = -2113863680;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f11,-12288(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -12288);
	ctx.f11.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f12,-7592(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7592);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-7588(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7584(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
loc_82D76E6C:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f10,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r10,r7,28
	ctx.r10.s64 = ctx.r7.s64 * 28;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// mulli r9,r7,24
	ctx.r9.s64 = ctx.r7.s64 * 24;
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fsubs f7,f6,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfsx f4,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r30,r7,5,0,26
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r29,r7,12
	ctx.r29.s64 = ctx.r7.s64 * 12;
	// lfsx f2,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f5,f4,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfsx f31,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// lfsx f30,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f2,f1,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// rlwinm r28,r7,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f29,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r27,r7,36
	ctx.r27.s64 = ctx.r7.s64 * 36;
	// lfsx f28,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f20,f3,f30
	ctx.f20.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f31,f29,f28
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f3,f30,f3
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// lfsx f27,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// lfsx f26,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f29,f27,f26
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// mulli r26,r7,20
	ctx.r26.s64 = ctx.r7.s64 * 20;
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f25,f24
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fadds f26,f24,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfsx f23,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f25,f10,f23
	ctx.f25.f64 = double(float(ctx.f10.f64 - ctx.f23.f64));
	// fadds f10,f23,f10
	ctx.f10.f64 = double(float(ctx.f23.f64 + ctx.f10.f64));
	// mulli r25,r8,20
	ctx.r25.s64 = ctx.r8.s64 * 20;
	// fadds f23,f2,f21
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f21.f64));
	// fsubs f24,f9,f22
	ctx.f24.f64 = double(float(ctx.f9.f64 - ctx.f22.f64));
	// fadds f9,f22,f9
	ctx.f9.f64 = double(float(ctx.f22.f64 + ctx.f9.f64));
	// fsubs f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// fadds f22,f1,f8
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// fadds f21,f31,f7
	ctx.f21.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// fsubs f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// fadds f31,f30,f6
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// fadds f1,f29,f5
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// fadds f19,f27,f20
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// fadds f30,f28,f4
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// fadds f18,f26,f3
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fsubs f5,f29,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// fsubs f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fsubs f4,f28,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 - ctx.f4.f64));
	// fsubs f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// fadds f29,f1,f23
	ctx.f29.f64 = double(float(ctx.f1.f64 + ctx.f23.f64));
	// fadds f26,f19,f21
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f1,f23,f1
	ctx.f1.f64 = double(float(ctx.f23.f64 - ctx.f1.f64));
	// fadds f28,f30,f22
	ctx.f28.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fadds f20,f18,f31
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f31.f64));
	// fmuls f17,f27,f13
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fadds f16,f29,f25
	ctx.f16.f64 = double(float(ctx.f29.f64 + ctx.f25.f64));
	// stfsx f16,r25,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f15,f26,f24
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// stfsx f15,r25,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fadds f16,f28,f10
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// stfs f16,0(r5)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f16,f20,f9
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f9.f64));
	// stfs f16,0(r6)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fsubs f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fnmsubs f30,f29,f11,f25
	ctx.f30.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f25,f7,f13
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fsubs f23,f21,f19
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fnmsubs f26,f26,f11,f24
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f24.f64)));
	// fmuls f24,f5,f13
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fnmsubs f10,f28,f11,f10
	ctx.f10.f64 = double(float(-(ctx.f28.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// fmadds f7,f7,f0,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f17.f64));
	// mulli r31,r8,28
	ctx.r31.s64 = ctx.r8.s64 * 28;
	// fmuls f21,f3,f13
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f28,f22,f12
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f22,f6,f13
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmsubs f27,f27,f0,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fmuls f25,f8,f13
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmuls f29,f23,f12
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f23,f2,f13
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmadds f2,f2,f0,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f24.f64));
	// rlwinm r30,r8,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f24,f4,f13
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// mulli r29,r8,24
	ctx.r29.s64 = ctx.r8.s64 * 24;
	// fnmsubs f9,f20,f11,f9
	ctx.f9.f64 = double(float(-(ctx.f20.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// fmadds f6,f6,f0,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fmsubs f3,f3,f0,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f22.f64));
	// fmsubs f4,f4,f0,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fadds f25,f30,f1
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fsubs f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// rlwinm r28,r8,5,0,26
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f30,f26,f29
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// rlwinm r27,r8,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fsubs f26,f10,f28
	ctx.f26.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fmsubs f5,f5,f0,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f23.f64));
	// fadds f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fsubs f28,f25,f7
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f7.f64));
	// stfsx f28,r11,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f28,f1,f27
	ctx.f28.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// stfsx f28,r10,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 + ctx.f7.f64));
	// stfsx f7,r9,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f1,f27
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// stfsx f7,r31,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f30,f2
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// stfsx f7,r9,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f29,f5
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// stfsx f7,r31,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f30,f2
	ctx.f7.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// stfsx f7,r11,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f29,f5
	ctx.f7.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// stfsx f7,r10,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f26,f3
	ctx.f7.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// stfsx f7,r30,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f10,f6
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// stfsx f7,r29,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f26,f3
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// stfsx f7,r28,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f31,f18
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f18.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// stfsx f10,r27,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fmadds f10,f8,f0,f24
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f24.f64));
	// add r5,r23,r5
	ctx.r5.u64 = ctx.r23.u64 + ctx.r5.u64;
	// fmuls f8,f7,f12
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fsubs f7,f9,f8
	ctx.f7.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fadds f8,f7,f4
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// stfsx f8,r30,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f9,f10
	ctx.f8.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// stfsx f8,r29,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f7,f4
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// stfsx f8,r28,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfsx f10,r27,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 3532);
	// add r6,r23,r6
	ctx.r6.u64 = ctx.r23.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d76e6c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D76E6C;
loc_82D770F4:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28f30
	ctx.lr = 0x82D770FC;
	__restfpr_15(ctx, base);
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77100"))) PPC_WEAK_FUNC(sub_82D77100);
PPC_FUNC_IMPL(__imp__sub_82D77100) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,2952
	ctx.r5.s64 = ctx.r11.s64 + 2952;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,28192
	ctx.r4.s64 = ctx.r11.s64 + 28192;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77118"))) PPC_WEAK_FUNC(sub_82D77118);
PPC_FUNC_IMPL(__imp__sub_82D77118) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D77120;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ee0
	ctx.lr = 0x82D77128;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d77404
	if (!ctx.cr6.gt) goto loc_82D77404;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r26,r10,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f17,-5080(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -5080);
	ctx.f17.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f18,-5076(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -5076);
	ctx.f18.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f11,-6160(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -6160);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-6156(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -6156);
	ctx.f12.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f19,-6144(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -6144);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,-6140(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -6140);
	ctx.f20.f64 = double(temp.f32);
	// lfs f13,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7656(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7656);
	ctx.f0.f64 = double(temp.f32);
loc_82D77184:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f10,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r10,r7,28
	ctx.r10.s64 = ctx.r7.s64 * 28;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f23,f7,f8
	ctx.f23.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// mulli r9,r7,20
	ctx.r9.s64 = ctx.r7.s64 * 20;
	// lfsx f6,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f7,f7,f8
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fadds f8,f5,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfsx f4,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r31,r7,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r28,r7,12
	ctx.r28.s64 = ctx.r7.s64 * 12;
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// lfsx f2,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f5,f2,f4
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fadds f22,f1,f3
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// lfsx f29,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r27,r7,24
	ctx.r27.s64 = ctx.r7.s64 * 24;
	// fsubs f1,f3,f1
	ctx.f1.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// lfsx f28,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// lfsx f25,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f4,f25,f29
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f3,f24,f28
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// fsubs f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfsx f27,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f31,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f24,f8,f27
	ctx.f24.f64 = double(float(ctx.f8.f64 + ctx.f27.f64));
	// lfsx f30,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f25,f23,f31
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fnmsubs f31,f23,f13,f31
	ctx.f31.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// lfsx f26,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f8,f8,f13,f27
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f27.f64)));
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fadds f27,f5,f30
	ctx.f27.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// fnmsubs f5,f5,f13,f30
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fadds f23,f22,f26
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fnmsubs f30,f22,f13,f26
	ctx.f30.f64 = double(float(-(ctx.f22.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fadds f26,f4,f10
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fnmsubs f10,f4,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fadds f22,f3,f9
	ctx.f22.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// fnmsubs f9,f3,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f4,f31,f6
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// mulli r31,r8,28
	ctx.r31.s64 = ctx.r8.s64 * 28;
	// fadds f3,f8,f7
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fsubs f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// fadds f21,f5,f1
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fadds f1,f30,f2
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// fsubs f2,f30,f2
	ctx.f2.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// fsubs f31,f24,f23
	ctx.f31.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fmuls f29,f29,f0
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f30,f4,f19
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f15,f4,f20
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fmuls f16,f21,f11
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fmuls f14,f21,f12
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fadds f7,f27,f25
	ctx.f7.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fadds f21,f9,f29
	ctx.f21.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// fmadds f4,f3,f20,f30
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f20.f64 + ctx.f30.f64));
	// fadds f30,f23,f24
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fadds f24,f28,f10
	ctx.f24.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fmadds f23,f1,f12,f16
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f16.f64));
	// fmsubs f3,f3,f19,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f19.f64 - ctx.f15.f64));
	// fmuls f16,f6,f11
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmsubs f1,f1,f11,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 - ctx.f14.f64));
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fsubs f14,f27,f25
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// fmuls f15,f5,f17
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// fsubs f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// fadds f28,f23,f4
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// fsubs f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// fnmsubs f27,f7,f13,f26
	ctx.f27.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fsubs f9,f9,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f29.f64));
	// fadds f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// stfs f7,0(r5)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmadds f25,f8,f12,f16
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f16.f64));
	// fadds f4,f1,f3
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fsubs f16,f3,f1
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fnmsubs f3,f30,f13,f22
	ctx.f3.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f22.f64)));
	// fmuls f29,f14,f0
	ctx.f29.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmsubs f7,f2,f18,f15
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f18.f64 - ctx.f15.f64));
	// fadds f26,f30,f22
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fadds f30,f27,f31
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// stfsx f30,r11,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fmuls f1,f23,f0
	ctx.f1.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f5,f5,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// fsubs f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// stfsx f31,r10,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f31,f16,f0
	ctx.f31.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f27,f28,f24
	ctx.f27.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// fadds f23,f3,f29
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// stfsx f23,r11,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f3,f29
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// stfs f26,0(r6)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fsubs f30,f7,f25
	ctx.f30.f64 = double(float(ctx.f7.f64 - ctx.f25.f64));
	// stfsx f29,r10,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f3,f28,f13,f24
	ctx.f3.f64 = double(float(-(ctx.f28.f64 * ctx.f13.f64 - ctx.f24.f64)));
	// stfsx f27,r9,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f25,f4,f21
	ctx.f25.f64 = double(float(ctx.f4.f64 + ctx.f21.f64));
	// stfsx f25,r9,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f4,f4,f13,f21
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f21.f64)));
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fmsubs f8,f8,f11,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 - ctx.f6.f64));
	// fmadds f6,f2,f17,f5
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f17.f64 + ctx.f5.f64));
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f29,f3,f31
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f31.f64));
	// stfsx f3,r30,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r9,r8,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// stfsx f3,r30,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f1.f64));
	// stfsx f4,r31,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f4,f7,f10
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfsx f4,r11,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fnmsubs f10,f7,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fsubs f7,f8,f6
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fadds f6,f7,f9
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// stfsx f6,r11,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f9,f7,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fsubs f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fadds f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// fadds f8,f9,f30
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// stfsx f9,r9,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// stfsx f7,r9,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// stfsx f10,r10,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d77184
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D77184;
loc_82D77404:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f2c
	ctx.lr = 0x82D7740C;
	__restfpr_14(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77410"))) PPC_WEAK_FUNC(sub_82D77410);
PPC_FUNC_IMPL(__imp__sub_82D77410) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,3016
	ctx.r5.s64 = ctx.r11.s64 + 3016;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,28952
	ctx.r4.s64 = ctx.r11.s64 + 28952;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77428"))) PPC_WEAK_FUNC(sub_82D77428);
PPC_FUNC_IMPL(__imp__sub_82D77428) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82D77430;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28f08
	ctx.lr = 0x82D77438;
	__savefpr_24(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d77614
	if (!ctx.cr6.gt) goto loc_82D77614;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r22,r10,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// rlwinm r21,r11,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f0,140(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
loc_82D7745C:
	// mulli r11,r7,28
	ctx.r11.s64 = ctx.r7.s64 * 28;
	// lfs f13,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 * 12;
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f28,f11,f9
	ctx.f28.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f27,f10,f8
	ctx.f27.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// lfsx f7,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f4,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f9,f7,f6
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f7,f5,f4
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// mulli r28,r7,24
	ctx.r28.s64 = ctx.r7.s64 * 24;
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfsx f3,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f31,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f5,f3,f13
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f13.f64));
	// fsubs f13,f13,f3
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f3.f64));
	// lfsx f1,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f29,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f3,f31,f12
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f12.f64));
	// lfsx f2,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f31.f64));
	// lfsx f30,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fadds f31,f29,f30
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// rlwinm r27,r8,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// rlwinm r26,r8,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// mulli r25,r8,24
	ctx.r25.s64 = ctx.r8.s64 * 24;
	// fsubs f1,f28,f27
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f29,f27,f28
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f27,f7,f9
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f28,f8,f11
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fadds f26,f6,f10
	ctx.f26.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fadds f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// mulli r24,r8,20
	ctx.r24.s64 = ctx.r8.s64 * 20;
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fsubs f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// fsubs f7,f5,f4
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fsubs f5,f3,f31
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f6,f31,f3
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fadds f31,f27,f1
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fadds f4,f30,f13
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f13.f64));
	// rlwinm r23,r8,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f3,f12,f2
	ctx.f3.f64 = double(float(ctx.f12.f64 - ctx.f2.f64));
	// fsubs f24,f8,f28
	ctx.f24.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// stfsx f24,r27,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f28,f8
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f25,f9,f29
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// fsubs f28,f7,f10
	ctx.f28.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fmuls f8,f31,f0
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fsubs f31,f6,f26
	ctx.f31.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// stfsx f31,r27,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// stfs f6,0(r6)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f6,f5,f11
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// stfsx f6,r26,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fsubs f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// stfsx f11,r25,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// stfsx f28,r25,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f10,f7
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// stfsx f11,r26,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f4,f8
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// stfsx f11,r24,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f8,f4
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// stfsx f11,r23,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f1,f27
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fsubs f9,f9,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f29.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fmuls f11,f25,f0
	ctx.f11.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fadds f12,f2,f12
	ctx.f12.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// fsubs f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f30.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fsubs f8,f3,f11
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// stfsx f8,r24,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fadds f11,f11,f3
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// stfsx f11,r23,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// add r3,r22,r3
	ctx.r3.u64 = ctx.r22.u64 + ctx.r3.u64;
	// add r4,r22,r4
	ctx.r4.u64 = ctx.r22.u64 + ctx.r4.u64;
	// fsubs f11,f12,f10
	ctx.f11.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfsx f11,r11,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfsx f12,r10,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f12,f13,f9
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// stfsx f12,r11,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfsx f13,r10,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 3532);
	// add r5,r21,r5
	ctx.r5.u64 = ctx.r21.u64 + ctx.r5.u64;
	// add r6,r21,r6
	ctx.r6.u64 = ctx.r21.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d7745c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D7745C;
loc_82D77614:
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82e28f54
	ctx.lr = 0x82D7761C;
	__restfpr_24(ctx, base);
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77620"))) PPC_WEAK_FUNC(sub_82D77620);
PPC_FUNC_IMPL(__imp__sub_82D77620) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,3080
	ctx.r5.s64 = ctx.r11.s64 + 3080;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,29736
	ctx.r4.s64 = ctx.r11.s64 + 29736;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77638"))) PPC_WEAK_FUNC(sub_82D77638);
PPC_FUNC_IMPL(__imp__sub_82D77638) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D77640;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28ef0
	ctx.lr = 0x82D77648;
	__savefpr_18(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d77874
	if (!ctx.cr6.gt) goto loc_82D77874;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r26,r10,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f9,-4940(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -4940);
	ctx.f9.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f10,-4944(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -4944);
	ctx.f10.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f11,-4948(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -4948);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-4960(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -4960);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-4952(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4952);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-4956(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4956);
	ctx.f0.f64 = double(temp.f32);
loc_82D77694:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f8,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// mulli r10,r7,24
	ctx.r10.s64 = ctx.r7.s64 * 24;
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f5,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// fsubs f31,f4,f5
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f30,f3,f2
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfsx f28,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f3,f27,f28
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfsx f1,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// lfsx f29,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f4,f29,f1
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// fsubs f29,f29,f1
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// lfsx f26,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// rlwinm r29,r7,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r28,r8,20
	ctx.r28.s64 = ctx.r8.s64 * 20;
	// lfsx f24,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f2,f24,f26
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfsx f23,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fmuls f24,f3,f10
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f27,f25,f23
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fadds f1,f23,f25
	ctx.f1.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fmuls f25,f4,f10
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fadds f21,f2,f4
	ctx.f21.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fmuls f22,f26,f13
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f23,f5,f11,f24
	ctx.f23.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 + ctx.f24.f64)));
	// rlwinm r9,r8,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f24,f27,f13
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// fadds f20,f1,f3
	ctx.f20.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fnmadds f25,f6,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 + ctx.f25.f64)));
	// fmadds f19,f2,f9,f8
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmadds f18,f1,f9,f7
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fadds f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// fmsubs f22,f31,f0,f22
	ctx.f22.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 - ctx.f22.f64));
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// fmsubs f24,f30,f0,f24
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f24.f64));
	// fadds f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f5.f64));
	// fadds f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// fmuls f19,f26,f0
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f18,f5,f10
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fadds f21,f21,f8
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// stfs f21,0(r5)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fnmsubs f22,f29,f12,f22
	ctx.f22.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f22.f64)));
	// fnmsubs f24,f28,f12,f24
	ctx.f24.f64 = double(float(-(ctx.f28.f64 * ctx.f12.f64 - ctx.f24.f64)));
	// fadds f21,f20,f7
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f7.f64));
	// stfs f21,0(r6)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmuls f20,f6,f10
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmadds f6,f6,f9,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fsubs f21,f25,f24
	ctx.f21.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfsx f21,r28,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfsx f25,r27,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f25,f23,f22
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfsx f25,r27,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f25,f23,f22
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfsx f25,r28,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fmuls f25,f30,f13
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f24,f2,f10
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f23,f31,f13
	ctx.f23.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// fmuls f22,f1,f10
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f21,f27,f0
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmadds f25,f28,f0,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 + ctx.f25.f64));
	// fnmadds f24,f4,f11,f24
	ctx.f24.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f24.f64)));
	// fnmadds f22,f3,f11,f22
	ctx.f22.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f22.f64)));
	// fmadds f5,f5,f9,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fmadds f23,f29,f0,f23
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f23.f64));
	// fmadds f30,f30,f12,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f21.f64));
	// fmadds f21,f4,f9,f8
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fnmadds f2,f2,f11,f20
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 + ctx.f20.f64)));
	// fmadds f20,f3,f9,f7
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fmadds f31,f31,f12,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 + ctx.f19.f64));
	// fadds f7,f24,f6
	ctx.f7.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// fmadds f8,f27,f12,f25
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 + ctx.f25.f64));
	// fnmadds f1,f1,f11,f18
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// fadds f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// fmadds f6,f26,f12,f23
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f23.f64));
	// fnmsubs f4,f28,f13,f30
	ctx.f4.f64 = double(float(-(ctx.f28.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fadds f3,f2,f21
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f21.f64));
	// fnmsubs f2,f29,f13,f31
	ctx.f2.f64 = double(float(-(ctx.f29.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// fsubs f31,f7,f8
	ctx.f31.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// stfsx f31,r11,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f20.f64));
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfsx f8,r10,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f5,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f5,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f6.f64));
	// stfsx f8,r11,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f3,f4
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// stfsx f8,r9,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f3,f4
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// fadds f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfsx f8,r31,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfsx f8,r9,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d77694
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D77694;
loc_82D77874:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f3c
	ctx.lr = 0x82D7787C;
	__restfpr_18(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77880"))) PPC_WEAK_FUNC(sub_82D77880);
PPC_FUNC_IMPL(__imp__sub_82D77880) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,3144
	ctx.r5.s64 = ctx.r11.s64 + 3144;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,30264
	ctx.r4.s64 = ctx.r11.s64 + 30264;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77898"))) PPC_WEAK_FUNC(sub_82D77898);
PPC_FUNC_IMPL(__imp__sub_82D77898) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82D778A0;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28f18
	ctx.lr = 0x82D778A8;
	__savefpr_28(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d77a1c
	if (!ctx.cr6.gt) goto loc_82D77A1C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r24,r10,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f13,-7656(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7656);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
loc_82D778D4:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r10,r7,20
	ctx.r10.s64 = ctx.r7.s64 * 20;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f31,f10,f9
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// rlwinm r9,r7,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f7,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f9,f8,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f6,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f3,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f7,f6,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfsx f4,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f5,f4,f3
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfsx f2,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f3,f12,f2
	ctx.f3.f64 = double(float(ctx.f12.f64 - ctx.f2.f64));
	// mulli r29,r8,12
	ctx.r29.s64 = ctx.r8.s64 * 12;
	// fadds f12,f2,f12
	ctx.f12.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// fsubs f30,f11,f1
	ctx.f30.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// fadds f11,f1,f11
	ctx.f11.f64 = double(float(ctx.f1.f64 + ctx.f11.f64));
	// fadds f2,f7,f31
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// fadds f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// mulli r28,r8,20
	ctx.r28.s64 = ctx.r8.s64 * 20;
	// fadds f29,f5,f9
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f5.f64));
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// fsubs f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// fadds f28,f4,f8
	ctx.f28.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r8,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r25,r8,4,0,27
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fnmsubs f5,f29,f0,f30
	ctx.f5.f64 = double(float(-(ctx.f29.f64 * ctx.f0.f64 - ctx.f30.f64)));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fmuls f10,f9,f13
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fmuls f9,f7,f13
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f7,f6,f13
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fadds f6,f2,f3
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfsx f6,r29,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f29,f30
	ctx.f6.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// stfsx f6,r29,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f1,f12
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f12.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f6,f28,f11
	ctx.f6.f64 = double(float(ctx.f28.f64 + ctx.f11.f64));
	// stfs f6,0(r6)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fnmsubs f6,f2,f0,f3
	ctx.f6.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// fnmsubs f12,f1,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fnmsubs f11,f28,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f28.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// fsubs f4,f6,f10
	ctx.f4.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// stfsx f4,r28,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// stfsx f10,r27,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f5,f9
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// stfsx f10,r27,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f5,f9
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// stfsx f10,r28,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f12,f8
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// stfsx f10,r26,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// stfsx f12,r25,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f11,f7
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfsx f12,r26,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f7,f11
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f12,r25,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 3532);
	// add r5,r23,r5
	ctx.r5.u64 = ctx.r23.u64 + ctx.r5.u64;
	// add r6,r23,r6
	ctx.r6.u64 = ctx.r23.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d778d4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D778D4;
loc_82D77A1C:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82e28f64
	ctx.lr = 0x82D77A24;
	__restfpr_28(ctx, base);
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77A28"))) PPC_WEAK_FUNC(sub_82D77A28);
PPC_FUNC_IMPL(__imp__sub_82D77A28) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,3208
	ctx.r5.s64 = ctx.r11.s64 + 3208;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,30872
	ctx.r4.s64 = ctx.r11.s64 + 30872;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77A40"))) PPC_WEAK_FUNC(sub_82D77A40);
PPC_FUNC_IMPL(__imp__sub_82D77A40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D77A48;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f14
	ctx.lr = 0x82D77A50;
	__savefpr_27(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d77bb4
	if (!ctx.cr6.gt) goto loc_82D77BB4;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r26,r10,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32255
	ctx.r31.s64 = -2113863680;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f31,-12288(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -12288);
	ctx.f31.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f13,-7588(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -7588);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-7584(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -7584);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,-7592(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7592);
	ctx.f1.f64 = double(temp.f32);
loc_82D77A8C:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f2,f9,f10
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfsx f7,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f9,f7,f8
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f6,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfsx f3,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f7,f5,f6
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfsx f4,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f5,f3,f4
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// mulli r29,r8,12
	ctx.r29.s64 = ctx.r8.s64 * 12;
	// fmuls f27,f10,f13
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fadds f3,f9,f2
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fsubs f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// fmuls f30,f8,f13
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// rlwinm r28,r8,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f28,f6,f13
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f9,f5,f7
	ctx.f9.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fsubs f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// fmuls f29,f4,f13
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmsubs f8,f8,f0,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f27.f64));
	// fmuls f7,f2,f1
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// fadds f2,f3,f12
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f12.f64));
	// stfs f2,0(r5)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fnmsubs f12,f3,f31,f12
	ctx.f12.f64 = double(float(-(ctx.f3.f64 * ctx.f31.f64 - ctx.f12.f64)));
	// fadds f2,f9,f11
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfs f2,0(r6)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmuls f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fnmsubs f11,f9,f31,f11
	ctx.f11.f64 = double(float(-(ctx.f9.f64 * ctx.f31.f64 - ctx.f11.f64)));
	// fmadds f6,f6,f0,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f29.f64));
	// fmsubs f4,f4,f0,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f28.f64));
	// fmadds f10,f10,f0,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f30.f64));
	// fadds f9,f12,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f7.f64));
	// fsubs f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fadds f7,f11,f5
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fsubs f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// fsubs f5,f9,f6
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// stfsx f5,r30,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f12,f4
	ctx.f5.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// stfsx f5,r29,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// stfsx f9,r28,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f4.f64));
	// stfsx f12,r27,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f7,f10
	ctx.f12.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// stfsx f12,r28,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f12,f11,f8
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// stfsx f12,r29,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f7,f10
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfsx f12,r30,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f11,f8
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// stfsx f12,r27,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 3532);
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d77a8c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D77A8C;
loc_82D77BB4:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82e28f60
	ctx.lr = 0x82D77BBC;
	__restfpr_27(ctx, base);
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77BC0"))) PPC_WEAK_FUNC(sub_82D77BC0);
PPC_FUNC_IMPL(__imp__sub_82D77BC0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,3272
	ctx.r5.s64 = ctx.r11.s64 + 3272;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,31296
	ctx.r4.s64 = ctx.r11.s64 + 31296;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77BD8"))) PPC_WEAK_FUNC(sub_82D77BD8);
PPC_FUNC_IMPL(__imp__sub_82D77BD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D77BE0;
	__savegprlr_26(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d77cb4
	if (!ctx.cr6.gt) goto loc_82D77CB4;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r28,r10,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D77BFC:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r9,r7,12
	ctx.r9.s64 = ctx.r7.s64 * 12;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f6,f12,f0
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// lfsx f10,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// lfsx f11,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// fadds f5,f9,f13
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// lfsx f7,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// fadds f9,f7,f8
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// rlwinm r31,r8,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f10,f8,f7
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// mulli r29,r8,12
	ctx.r29.s64 = ctx.r8.s64 * 12;
	// fsubs f8,f6,f12
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fsubs f8,f5,f9
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// stfsx f8,r31,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f12,f9,f5
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fsubs f12,f13,f11
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfsx f12,r30,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f10,f0
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f0.f64));
	// stfsx f12,r30,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfsx f13,r29,r6
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f10.f64));
	// stfsx f0,r29,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,3532(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 3532);
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// add r6,r27,r6
	ctx.r6.u64 = ctx.r27.u64 + ctx.r6.u64;
	// add r5,r27,r5
	ctx.r5.u64 = ctx.r27.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d77bfc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D77BFC;
loc_82D77CB4:
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77CB8"))) PPC_WEAK_FUNC(sub_82D77CB8);
PPC_FUNC_IMPL(__imp__sub_82D77CB8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,3336
	ctx.r5.s64 = ctx.r11.s64 + 3336;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,31704
	ctx.r4.s64 = ctx.r11.s64 + 31704;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77CD0"))) PPC_WEAK_FUNC(sub_82D77CD0);
PPC_FUNC_IMPL(__imp__sub_82D77CD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D77CD8;
	__savegprlr_28(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d77d9c
	if (!ctx.cr6.gt) goto loc_82D77D9C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r30,r10,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f6,-28552(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,-7656(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7656);
	ctx.f7.f64 = double(temp.f32);
loc_82D77D04:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfsx f9,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fadds f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f9,f8,f0
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// stfs f9,0(r5)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fnmsubs f0,f8,f6,f0
	ctx.f0.f64 = double(float(-(ctx.f8.f64 * ctx.f6.f64 - ctx.f0.f64)));
	// fadds f9,f12,f13
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f9,0(r6)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmuls f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fnmsubs f13,f12,f6,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f6.f64 - ctx.f13.f64)));
	// fmuls f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fsubs f12,f0,f10
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f10.f64));
	// stfsx f12,r9,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f10.f64));
	// stfsx f0,r31,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f13,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// stfsx f0,r31,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f0,f13,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfsx f0,r9,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,3532(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 3532);
	// add r5,r29,r5
	ctx.r5.u64 = ctx.r29.u64 + ctx.r5.u64;
	// add r6,r29,r6
	ctx.r6.u64 = ctx.r29.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d77d04
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D77D04;
loc_82D77D9C:
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77DA0"))) PPC_WEAK_FUNC(sub_82D77DA0);
PPC_FUNC_IMPL(__imp__sub_82D77DA0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,3400
	ctx.r5.s64 = ctx.r11.s64 + 3400;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,31952
	ctx.r4.s64 = ctx.r11.s64 + 31952;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77DB8"))) PPC_WEAK_FUNC(sub_82D77DB8);
PPC_FUNC_IMPL(__imp__sub_82D77DB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82d77e34
	if (!ctx.cr6.gt) goto loc_82D77E34;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D77DDC:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f12,r10,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfsx f13,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f13.f64 = double(temp.f32);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// lfs f0,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// add r4,r9,r4
	ctx.r4.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f12,r10,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r11,3532(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3532);
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82d77ddc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82D77DDC;
loc_82D77E34:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D77E40"))) PPC_WEAK_FUNC(sub_82D77E40);
PPC_FUNC_IMPL(__imp__sub_82D77E40) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,3464
	ctx.r5.s64 = ctx.r11.s64 + 3464;
	// lis r11,-32041
	ctx.r11.s64 = -2099838976;
	// addi r4,r11,32184
	ctx.r4.s64 = ctx.r11.s64 + 32184;
	// b 0x82d77fe0
	sub_82D77FE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77E58"))) PPC_WEAK_FUNC(sub_82D77E58);
PPC_FUNC_IMPL(__imp__sub_82D77E58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// bl 0x82d78258
	ctx.lr = 0x82D77E78;
	sub_82D78258(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d0e6f0
	ctx.lr = 0x82D77E84;
	sub_82D0E6F0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D77E98"))) PPC_WEAK_FUNC(sub_82D77E98);
PPC_FUNC_IMPL(__imp__sub_82D77E98) {
	PPC_FUNC_PROLOGUE();
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D77EA0"))) PPC_WEAK_FUNC(sub_82D77EA0);
PPC_FUNC_IMPL(__imp__sub_82D77EA0) {
	PPC_FUNC_PROLOGUE();
	// b 0x82d79020
	sub_82D79020(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77EA8"))) PPC_WEAK_FUNC(sub_82D77EA8);
PPC_FUNC_IMPL(__imp__sub_82D77EA8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D77EB0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d79d38
	ctx.lr = 0x82D77ECC;
	sub_82D79D38(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d0e6f0
	ctx.lr = 0x82D77ED8;
	sub_82D0E6F0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d79d90
	ctx.lr = 0x82D77EE4;
	sub_82D79D90(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d0e6f0
	ctx.lr = 0x82D77EF0;
	sub_82D0E6F0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d79418
	ctx.lr = 0x82D77EFC;
	sub_82D79418(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d0e6f0
	ctx.lr = 0x82D77F08;
	sub_82D0E6F0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77F10"))) PPC_WEAK_FUNC(sub_82D77F10);
PPC_FUNC_IMPL(__imp__sub_82D77F10) {
	PPC_FUNC_PROLOGUE();
	// b 0x82d7a698
	sub_82D7A698(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77F18"))) PPC_WEAK_FUNC(sub_82D77F18);
PPC_FUNC_IMPL(__imp__sub_82D77F18) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,48(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d77f2c
	if (ctx.cr0.eq) goto loc_82D77F2C;
	// cmpw cr6,r11,r6
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r6.s32, ctx.xer);
	// bne cr6,0x82d77f58
	if (!ctx.cr6.eq) goto loc_82D77F58;
loc_82D77F2C:
	// lwz r11,52(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d77f40
	if (ctx.cr0.eq) goto loc_82D77F40;
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// bne cr6,0x82d77f58
	if (!ctx.cr6.eq) goto loc_82D77F58;
loc_82D77F40:
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d77f60
	if (ctx.cr0.eq) goto loc_82D77F60;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// beq cr6,0x82d77f60
	if (ctx.cr6.eq) goto loc_82D77F60;
loc_82D77F58:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82D77F60:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D77F68"))) PPC_WEAK_FUNC(sub_82D77F68);
PPC_FUNC_IMPL(__imp__sub_82D77F68) {
	PPC_FUNC_PROLOGUE();
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82d7aa10
	sub_82D7AA10(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77F70"))) PPC_WEAK_FUNC(sub_82D77F70);
PPC_FUNC_IMPL(__imp__sub_82D77F70) {
	PPC_FUNC_PROLOGUE();
	// li r6,1
	ctx.r6.s64 = 1;
	// b 0x82d7b418
	sub_82D7B418(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D77F78"))) PPC_WEAK_FUNC(sub_82D77F78);
PPC_FUNC_IMPL(__imp__sub_82D77F78) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,44(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d77f8c
	if (ctx.cr0.eq) goto loc_82D77F8C;
	// cmpw cr6,r11,r8
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x82d77fd0
	if (!ctx.cr6.eq) goto loc_82D77FD0;
loc_82D77F8C:
	// lwz r11,48(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d77fa0
	if (ctx.cr0.eq) goto loc_82D77FA0;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82d77fd0
	if (!ctx.cr6.eq) goto loc_82D77FD0;
loc_82D77FA0:
	// lwz r11,52(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d77fb8
	if (ctx.cr0.eq) goto loc_82D77FB8;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82d77fd0
	if (!ctx.cr6.eq) goto loc_82D77FD0;
loc_82D77FB8:
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d77fd8
	if (ctx.cr0.eq) goto loc_82D77FD8;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// beq cr6,0x82d77fd8
	if (ctx.cr6.eq) goto loc_82D77FD8;
loc_82D77FD0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82D77FD8:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D77FE0"))) PPC_WEAK_FUNC(sub_82D77FE0);
PPC_FUNC_IMPL(__imp__sub_82D77FE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D77FE8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d7bce0
	ctx.lr = 0x82D78004;
	sub_82D7BCE0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d0e6f0
	ctx.lr = 0x82D78010;
	sub_82D0E6F0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d7bd38
	ctx.lr = 0x82D7801C;
	sub_82D7BD38(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d0e6f0
	ctx.lr = 0x82D78028;
	sub_82D0E6F0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D78030"))) PPC_WEAK_FUNC(sub_82D78030);
PPC_FUNC_IMPL(__imp__sub_82D78030) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// lwz r8,68(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r7,64(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// lwz r6,80(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	// lwz r5,76(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// lwz r11,84(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_82D78060"))) PPC_WEAK_FUNC(sub_82D78060);
PPC_FUNC_IMPL(__imp__sub_82D78060) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D78068"))) PPC_WEAK_FUNC(sub_82D78068);
PPC_FUNC_IMPL(__imp__sub_82D78068) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D78070;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,88(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 88);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r30,64(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 64);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r29,4(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r28,0(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r3,44(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	// bl 0x82d1fc50
	ctx.lr = 0x82D78094;
	sub_82D1FC50(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r11,22124
	ctx.r4.s64 = ctx.r11.s64 + 22124;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D780BC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D780C8"))) PPC_WEAK_FUNC(sub_82D780C8);
PPC_FUNC_IMPL(__imp__sub_82D780C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82d78174
	if (!ctx.cr6.eq) goto loc_82D78174;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bgt cr6,0x82d78174
	if (ctx.cr6.gt) goto loc_82D78174;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82d78174
	if (!ctx.cr6.eq) goto loc_82D78174;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r11,44(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d78174
	if (!ctx.cr6.eq) goto loc_82D78174;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82d1f0d0
	ctx.lr = 0x82D78134;
	sub_82D1F0D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d78174
	if (ctx.cr0.eq) goto loc_82D78174;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82d7816c
	if (!ctx.cr6.eq) goto loc_82D7816C;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82d7816c
	if (ctx.cr6.eq) goto loc_82D7816C;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82d21b28
	ctx.lr = 0x82D78164;
	sub_82D21B28(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d78174
	if (ctx.cr0.eq) goto loc_82D78174;
loc_82D7816C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82d78178
	goto loc_82D78178;
loc_82D78174:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82D78178:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D78190"))) PPC_WEAK_FUNC(sub_82D78190);
PPC_FUNC_IMPL(__imp__sub_82D78190) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D78198;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// bl 0x82d780c8
	ctx.lr = 0x82D781A8;
	sub_82D780C8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d78250
	if (ctx.cr0.eq) goto loc_82D78250;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r5,r11,-32720
	ctx.r5.s64 = ctx.r11.s64 + -32720;
	// addi r4,r10,3624
	ctx.r4.s64 = ctx.r10.s64 + 3624;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82d20138
	ctx.lr = 0x82D781C8;
	sub_82D20138(ctx, base);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// addi r29,r31,64
	ctx.r29.s64 = ctx.r31.s64 + 64;
	// addi r6,r31,72
	ctx.r6.s64 = ctx.r31.s64 + 72;
	// addi r5,r31,68
	ctx.r5.s64 = ctx.r31.s64 + 68;
	// stw r10,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r10.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r10,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r10.u32);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// lwz r3,8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// bl 0x82d1f0d0
	ctx.lr = 0x82D78200;
	sub_82D1F0D0(ctx, base);
	// addi r28,r31,8
	ctx.r28.s64 = ctx.r31.s64 + 8;
	// stw r30,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r30.u32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82d0c680
	ctx.lr = 0x82D78210;
	sub_82D0C680(ctx, base);
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r4,r11,8
	ctx.r4.s64 = ctx.r11.s64 + 8;
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// lwz r8,40(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lwz r11,0(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// andc r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// divw r3,r9,r11
	ctx.r3.s32 = ctx.r9.s32 / ctx.r11.s32;
	// twllei r11,0
	// twlgei r10,-1
	// bl 0x82d0c7e0
	ctx.lr = 0x82D78244;
	sub_82D0C7E0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r11.u32);
loc_82D78250:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D78258"))) PPC_WEAK_FUNC(sub_82D78258);
PPC_FUNC_IMPL(__imp__sub_82D78258) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,3640
	ctx.r4.s64 = ctx.r11.s64 + 3640;
	// li r3,16
	ctx.r3.s64 = 16;
	// bl 0x82d0e650
	ctx.lr = 0x82D78284;
	sub_82D0E650(ctx, base);
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D782A8"))) PPC_WEAK_FUNC(sub_82D782A8);
PPC_FUNC_IMPL(__imp__sub_82D782A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D782B0;
	__savegprlr_19(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r27,84(r29)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r29.u32 + 84);
	// lwz r22,68(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 68);
	// lwz r21,72(r29)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r29.u32 + 72);
	// cmpwi r27,0
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// lwz r11,80(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 80);
	// lwz r28,92(r29)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r29.u32 + 92);
	// lwz r10,96(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 96);
	// ble 0x82d78394
	if (!ctx.cr0.gt) goto loc_82D78394;
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// srawi r9,r9,1
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 1;
	// mullw r8,r8,r28
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r28.s32);
	// addze r20,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r20.s64 = temp.s64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// rlwinm r26,r8,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// rlwinm r25,r28,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// rlwinm r24,r11,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r10,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D78310:
	// lwz r11,56(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 56);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D78330;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,108(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 108);
	// lwz r8,100(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 100);
	// mr r10,r20
	ctx.r10.u64 = ctx.r20.u64;
	// lwz r19,64(r29)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r29.u32 + 64);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// add r6,r26,r30
	ctx.r6.u64 = ctx.r26.u64 + ctx.r30.u64;
	// add r5,r26,r31
	ctx.r5.u64 = ctx.r26.u64 + ctx.r31.u64;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r4,r25,r30
	ctx.r4.u64 = ctx.r25.u64 + ctx.r30.u64;
	// add r3,r25,r31
	ctx.r3.u64 = ctx.r25.u64 + ctx.r31.u64;
	// mtctr r19
	ctx.ctr.u64 = ctx.r19.u64;
	// bctrl 
	ctx.lr = 0x82D78364;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// add r7,r24,r30
	ctx.r7.u64 = ctx.r24.u64 + ctx.r30.u64;
	// add r6,r24,r31
	ctx.r6.u64 = ctx.r24.u64 + ctx.r31.u64;
	// lwz r11,56(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 56);
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D78384;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addic. r27,r27,-1
	ctx.xer.ca = ctx.r27.u32 > 0;
	ctx.r27.s64 = ctx.r27.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// add r31,r23,r31
	ctx.r31.u64 = ctx.r23.u64 + ctx.r31.u64;
	// add r30,r23,r30
	ctx.r30.u64 = ctx.r23.u64 + ctx.r30.u64;
	// bne 0x82d78310
	if (!ctx.cr0.eq) goto loc_82D78310;
loc_82D78394:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D783A0"))) PPC_WEAK_FUNC(sub_82D783A0);
PPC_FUNC_IMPL(__imp__sub_82D783A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e38
	ctx.lr = 0x82D783A8;
	__savegprlr_16(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r26,84(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// lwz r18,68(r31)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r17,72(r31)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// cmpwi r26,0
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// srawi r8,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r8.s64 = ctx.r10.s32 >> 1;
	// lwz r28,92(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r9,96(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// addze r27,r8
	temp.s64 = ctx.r8.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r8.u32;
	ctx.r27.s64 = temp.s64;
	// ble 0x82d784d8
	if (!ctx.cr0.gt) goto loc_82D784D8;
	// srawi r8,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r8.s64 = ctx.r11.s32 >> 1;
	// subf r11,r27,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r27.s64;
	// addze r8,r8
	temp.s64 = ctx.r8.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r8.u32;
	ctx.r8.s64 = temp.s64;
	// mullw r10,r10,r28
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// mullw r7,r27,r28
	ctx.r7.s64 = int64_t(ctx.r27.s32) * int64_t(ctx.r28.s32);
	// mullw r8,r8,r28
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r28.s32);
	// rlwinm r25,r10,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r24,r28,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r19,r27,2
	ctx.r19.s64 = ctx.r27.s64 + 2;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r22,r7,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r21,r8,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r20,r9,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D7841C:
	// lwz r11,56(r18)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r18.u32 + 56);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7843C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// lwz r8,100(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// lwz r16,64(r31)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// add r6,r25,r29
	ctx.r6.u64 = ctx.r25.u64 + ctx.r29.u64;
	// add r5,r25,r30
	ctx.r5.u64 = ctx.r25.u64 + ctx.r30.u64;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r4,r24,r29
	ctx.r4.u64 = ctx.r24.u64 + ctx.r29.u64;
	// add r3,r24,r30
	ctx.r3.u64 = ctx.r24.u64 + ctx.r30.u64;
	// mtctr r16
	ctx.ctr.u64 = ctx.r16.u64;
	// bctrl 
	ctx.lr = 0x82D78470;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// mr r10,r19
	ctx.r10.u64 = ctx.r19.u64;
	// lwz r8,100(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// lwz r16,64(r31)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// add r6,r23,r29
	ctx.r6.u64 = ctx.r23.u64 + ctx.r29.u64;
	// add r5,r23,r30
	ctx.r5.u64 = ctx.r23.u64 + ctx.r30.u64;
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// add r3,r22,r30
	ctx.r3.u64 = ctx.r22.u64 + ctx.r30.u64;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r4,r22,r29
	ctx.r4.u64 = ctx.r22.u64 + ctx.r29.u64;
	// mtctr r16
	ctx.ctr.u64 = ctx.r16.u64;
	// bctrl 
	ctx.lr = 0x82D784A8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// add r7,r21,r29
	ctx.r7.u64 = ctx.r21.u64 + ctx.r29.u64;
	// lwz r11,56(r17)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r17.u32 + 56);
	// add r6,r21,r30
	ctx.r6.u64 = ctx.r21.u64 + ctx.r30.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D784C8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addic. r26,r26,-1
	ctx.xer.ca = ctx.r26.u32 > 0;
	ctx.r26.s64 = ctx.r26.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// add r30,r20,r30
	ctx.r30.u64 = ctx.r20.u64 + ctx.r30.u64;
	// add r29,r20,r29
	ctx.r29.u64 = ctx.r20.u64 + ctx.r29.u64;
	// bne 0x82d7841c
	if (!ctx.cr0.eq) goto loc_82D7841C;
loc_82D784D8:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82e28e88
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D784E0"))) PPC_WEAK_FUNC(sub_82D784E0);
PPC_FUNC_IMPL(__imp__sub_82D784E0) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D784F0"))) PPC_WEAK_FUNC(sub_82D784F0);
PPC_FUNC_IMPL(__imp__sub_82D784F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D784F8;
	__savegprlr_14(ctx, base);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r26,340(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r23,r8
	ctx.r23.u64 = ctx.r8.u64;
	// mr r14,r10
	ctx.r14.u64 = ctx.r10.u64;
	// mr r20,r9
	ctx.r20.u64 = ctx.r9.u64;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// lwz r29,92(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// li r15,2
	ctx.r15.s64 = 2;
	// lwz r30,104(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// subf r27,r23,r20
	ctx.r27.s64 = ctx.r20.s64 - ctx.r23.s64;
	// mullw r10,r29,r23
	ctx.r10.s64 = int64_t(ctx.r29.s32) * int64_t(ctx.r23.s32);
	// lwz r9,76(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r28,100(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// stw r15,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r15.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// addi r3,r30,-2
	ctx.r3.s64 = ctx.r30.s64 + -2;
	// rlwinm r25,r10,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// srawi r9,r9,1
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 1;
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// add r18,r25,r4
	ctx.r18.u64 = ctx.r25.u64 + ctx.r4.u64;
	// add r19,r25,r11
	ctx.r19.u64 = ctx.r25.u64 + ctx.r11.u64;
	// addi r22,r26,4
	ctx.r22.s64 = ctx.r26.s64 + 4;
	// mr r17,r7
	ctx.r17.u64 = ctx.r7.u64;
	// mr r16,r6
	ctx.r16.u64 = ctx.r6.u64;
	// addze r7,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r7.s64 = temp.s64;
	// add r24,r3,r26
	ctx.r24.u64 = ctx.r3.u64 + ctx.r26.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r6,r22
	ctx.r6.u64 = ctx.r22.u64;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// bl 0x82d5f3b8
	ctx.lr = 0x82D78584;
	sub_82D5F3B8(ctx, base);
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// subf r17,r25,r17
	ctx.r17.s64 = ctx.r17.s64 - ctx.r25.s64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// subf r25,r25,r16
	ctx.r25.s64 = ctx.r16.s64 - ctx.r25.s64;
	// addze r7,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r7.s64 = temp.s64;
	// li r11,-2
	ctx.r11.s64 = -2;
	// neg r16,r29
	ctx.r16.s64 = -ctx.r29.s64;
	// addi r21,r24,4
	ctx.r21.s64 = ctx.r24.s64 + 4;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r16.u32);
	// mr r6,r21
	ctx.r6.u64 = ctx.r21.u64;
	// mr r4,r17
	ctx.r4.u64 = ctx.r17.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82d5f3b8
	ctx.lr = 0x82D785CC;
	sub_82D5F3B8(ctx, base);
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// mr r9,r23
	ctx.r9.u64 = ctx.r23.u64;
	// lwz r8,104(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// mr r6,r21
	ctx.r6.u64 = ctx.r21.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r15,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r15.u32);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r10,r20,r14
	ctx.r10.u64 = ctx.r20.u64 + ctx.r14.u64;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D78608;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// stw r15,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r15.u32);
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// addze r7,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r7.s64 = temp.s64;
	// mr r6,r19
	ctx.r6.u64 = ctx.r19.u64;
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82d5f448
	ctx.lr = 0x82D7863C;
	sub_82D5F448(ctx, base);
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// li r7,-2
	ctx.r7.s64 = -2;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r16.u32);
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// mr r6,r17
	ctx.r6.u64 = ctx.r17.u64;
	// addze r7,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r7.s64 = temp.s64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82d5f448
	ctx.lr = 0x82D78674;
	sub_82D5F448(ctx, base);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D78680"))) PPC_WEAK_FUNC(sub_82D78680);
PPC_FUNC_IMPL(__imp__sub_82D78680) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e38
	ctx.lr = 0x82D78688;
	__savegprlr_16(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r9,80(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// lwz r17,68(r31)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r19,72(r31)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r18,92(r31)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r28,84(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// addi r22,r10,2
	ctx.r22.s64 = ctx.r10.s64 + 2;
	// srawi r10,r9,1
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 1;
	// mullw r11,r11,r22
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r22.s32);
	// rlwinm r3,r11,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// addze r27,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r27.s64 = temp.s64;
	// bl 0x82d0c438
	ctx.lr = 0x82D786D4;
	sub_82D0C438(ctx, base);
	// mr r21,r3
	ctx.r21.u64 = ctx.r3.u64;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// ble cr6,0x82d787cc
	if (!ctx.cr6.gt) goto loc_82D787CC;
	// mullw r11,r27,r18
	ctx.r11.s64 = int64_t(ctx.r27.s32) * int64_t(ctx.r18.s32);
	// rlwinm r20,r11,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r16,r22,1
	ctx.r16.s64 = ctx.r22.s64 + 1;
	// mr r23,r28
	ctx.r23.u64 = ctx.r28.u64;
loc_82D786F0:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lwz r10,56(r17)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r17.u32 + 56);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mullw r11,r18,r11
	ctx.r11.s64 = int64_t(ctx.r18.s32) * int64_t(ctx.r11.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// add r25,r11,r30
	ctx.r25.u64 = ctx.r11.u64 + ctx.r30.u64;
	// add r24,r11,r29
	ctx.r24.u64 = ctx.r11.u64 + ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82D78724;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r28,1
	ctx.r28.s64 = 1;
	// cmpw cr6,r16,r27
	ctx.cr6.compare<int32_t>(ctx.r16.s32, ctx.r27.s32, ctx.xer);
	// bge cr6,0x82d7876c
	if (!ctx.cr6.lt) goto loc_82D7876C;
	// mr r26,r16
	ctx.r26.u64 = ctx.r16.u64;
loc_82D78734:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r21.u32);
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d784f0
	ctx.lr = 0x82D7875C;
	sub_82D784F0(ctx, base);
	// add r26,r26,r22
	ctx.r26.u64 = ctx.r26.u64 + ctx.r22.u64;
	// add r28,r28,r22
	ctx.r28.u64 = ctx.r28.u64 + ctx.r22.u64;
	// cmpw cr6,r26,r27
	ctx.cr6.compare<int32_t>(ctx.r26.s32, ctx.r27.s32, ctx.xer);
	// blt cr6,0x82d78734
	if (ctx.cr6.lt) goto loc_82D78734;
loc_82D7876C:
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// lwz r10,88(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r21.u32);
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d784f0
	ctx.lr = 0x82D78794;
	sub_82D784F0(ctx, base);
	// add r7,r20,r29
	ctx.r7.u64 = ctx.r20.u64 + ctx.r29.u64;
	// add r6,r20,r30
	ctx.r6.u64 = ctx.r20.u64 + ctx.r30.u64;
	// lwz r11,56(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 56);
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D787B4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,96(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// bne 0x82d786f0
	if (!ctx.cr0.eq) goto loc_82D786F0;
loc_82D787CC:
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x82d0c490
	ctx.lr = 0x82D787D4;
	sub_82D0C490(ctx, base);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82e28e88
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D787E0"))) PPC_WEAK_FUNC(sub_82D787E0);
PPC_FUNC_IMPL(__imp__sub_82D787E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82d0c350
	ctx.lr = 0x82D78804;
	sub_82D0C350(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// bl 0x82d0c350
	ctx.lr = 0x82D78810;
	sub_82D0C350(ctx, base);
	// lwz r9,112(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// addi r4,r31,108
	ctx.r4.s64 = ctx.r31.s64 + 108;
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r10,88(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mullw r6,r7,r11
	ctx.r6.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r11.s32);
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r5,8(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// addi r9,r11,-1
	ctx.r9.s64 = ctx.r11.s64 + -1;
	// srawi r9,r9,1
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 1;
	// addze r11,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r11.s64 = temp.s64;
	// add r8,r11,r10
	ctx.r8.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82d20798
	ctx.lr = 0x82D78848;
	sub_82D20798(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D78860"))) PPC_WEAK_FUNC(sub_82D78860);
PPC_FUNC_IMPL(__imp__sub_82D78860) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82d0c300
	ctx.lr = 0x82D7887C;
	sub_82D0C300(ctx, base);
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// bl 0x82d0c300
	ctx.lr = 0x82D78884;
	sub_82D0C300(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D78898"))) PPC_WEAK_FUNC(sub_82D78898);
PPC_FUNC_IMPL(__imp__sub_82D78898) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82D788A0;
	__savegprlr_24(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r3,76(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// beq cr6,0x82d78924
	if (ctx.cr6.eq) goto loc_82D78924;
	// lwz r26,4(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// lwz r28,72(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r27,68(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// rlwinm r29,r11,0,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r25,84(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r24,88(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// bl 0x82d20388
	ctx.lr = 0x82D788E8;
	sub_82D20388(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r27.u32);
	// addi r4,r11,22156
	ctx.r4.s64 = ctx.r11.s64 + 22156;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r5,r29,2
	ctx.r5.s64 = ctx.r29.s64 + 2;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r28.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// mr r10,r26
	ctx.r10.u64 = ctx.r26.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D78920;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82d78974
	goto loc_82D78974;
loc_82D78924:
	// lwz r29,72(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r28,68(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r27,4(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r26,84(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r25,88(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// bl 0x82d20388
	ctx.lr = 0x82D7893C;
	sub_82D20388(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// lwz r5,76(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// addi r11,r11,22156
	ctx.r11.s64 = ctx.r11.s64 + 22156;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r4,r11,48
	ctx.r4.s64 = ctx.r11.s64 + 48;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D78974;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82D78974:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D78980"))) PPC_WEAK_FUNC(sub_82D78980);
PPC_FUNC_IMPL(__imp__sub_82D78980) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e38
	ctx.lr = 0x82D78988;
	__savegprlr_16(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,20(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r31,r8
	ctx.r31.u64 = ctx.r8.u64;
	// mr r16,r10
	ctx.r16.u64 = ctx.r10.u64;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpw cr6,r5,r11
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d78b10
	if (!ctx.cr6.eq) goto loc_82D78B10;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d78b10
	if (!ctx.cr6.eq) goto loc_82D78B10;
	// addi r11,r7,1
	ctx.r11.s64 = ctx.r7.s64 + 1;
	// lwz r20,332(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// addi r21,r7,-1
	ctx.r21.s64 = ctx.r7.s64 + -1;
	// lwz r18,316(r1)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// lwz r17,308(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// mullw r9,r21,r31
	ctx.r9.s64 = int64_t(ctx.r21.s32) * int64_t(ctx.r31.s32);
	// lwz r22,324(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// addze r19,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r19.s64 = temp.s64;
	// li r11,0
	ctx.r11.s64 = 0;
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r29,r31,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// add r24,r28,r18
	ctx.r24.u64 = ctx.r28.u64 + ctx.r18.u64;
	// add r26,r29,r18
	ctx.r26.u64 = ctx.r29.u64 + ctx.r18.u64;
	// add r25,r29,r17
	ctx.r25.u64 = ctx.r29.u64 + ctx.r17.u64;
	// stw r11,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r11.u32);
	// add r23,r28,r17
	ctx.r23.u64 = ctx.r28.u64 + ctx.r17.u64;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r9,r19
	ctx.r9.u64 = ctx.r19.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D78A30;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d78ac0
	if (!ctx.cr0.eq) goto loc_82D78AC0;
	// srawi r11,r21,1
	ctx.xer.ca = (ctx.r21.s32 < 0) & ((ctx.r21.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r21.s32 >> 1;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// addze r21,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r21.s64 = temp.s64;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// stw r11,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r11.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D78A7C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d78b10
	if (ctx.cr0.eq) goto loc_82D78B10;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// addi r9,r21,2
	ctx.r9.s64 = ctx.r21.s64 + 2;
	// mr r8,r21
	ctx.r8.u64 = ctx.r21.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D78AB8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d78b10
	if (ctx.cr0.eq) goto loc_82D78B10;
loc_82D78AC0:
	// lwz r6,12(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// rlwinm r11,r16,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r16.u32 | (ctx.r16.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r20)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// add r3,r11,r17
	ctx.r3.u64 = ctx.r11.u64 + ctx.r17.u64;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// add r11,r11,r18
	ctx.r11.u64 = ctx.r11.u64 + ctx.r18.u64;
	// add r5,r28,r3
	ctx.r5.u64 = ctx.r28.u64 + ctx.r3.u64;
	// lwz r31,0(r6)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// li r8,1
	ctx.r8.s64 = 1;
	// subf r9,r9,r19
	ctx.r9.s64 = ctx.r19.s64 - ctx.r9.s64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// add r6,r28,r11
	ctx.r6.u64 = ctx.r28.u64 + ctx.r11.u64;
	// add r4,r29,r11
	ctx.r4.u64 = ctx.r29.u64 + ctx.r11.u64;
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82D78B04;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne 0x82d78b14
	if (!ctx.cr0.eq) goto loc_82D78B14;
loc_82D78B10:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82D78B14:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82e28e88
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D78B20"))) PPC_WEAK_FUNC(sub_82D78B20);
PPC_FUNC_IMPL(__imp__sub_82D78B20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D78B28;
	__savegprlr_23(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r25,20(r3)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmpw cr6,r5,r11
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d78c64
	if (!ctx.cr6.eq) goto loc_82D78C64;
	// lwz r11,12(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpw cr6,r4,r10
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82d78c64
	if (!ctx.cr6.eq) goto loc_82D78C64;
	// addi r9,r5,3
	ctx.r9.s64 = ctx.r5.s64 + 3;
	// lwz r24,0(r11)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r26,276(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// li r10,2
	ctx.r10.s64 = 2;
	// rlwinm r11,r9,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r31,r11,2
	ctx.r31.s64 = ctx.r11.s64 + 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// rlwinm r30,r31,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r11,r30,-2
	ctx.r11.s64 = ctx.r30.s64 + -2;
	// addi r9,r31,1
	ctx.r9.s64 = ctx.r31.s64 + 1;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// addi r28,r29,4
	ctx.r28.s64 = ctx.r29.s64 + 4;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mtctr r24
	ctx.ctr.u64 = ctx.r24.u64;
	// bctrl 
	ctx.lr = 0x82D78BA0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d78c64
	if (ctx.cr0.eq) goto loc_82D78C64;
	// addi r11,r27,-1
	ctx.r11.s64 = ctx.r27.s64 + -1;
	// lwz r24,284(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// li r10,2
	ctx.r10.s64 = 2;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// li r8,1
	ctx.r8.s64 = 1;
	// addze r9,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r9.s64 = temp.s64;
	// li r11,0
	ctx.r11.s64 = 0;
	// divw r7,r9,r31
	ctx.r7.s32 = ctx.r9.s32 / ctx.r31.s32;
	// twllei r31,0
	// mullw r7,r7,r31
	ctx.r7.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r31.s32);
	// stw r11,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r11.u32);
	// lwz r6,12(r25)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// lwz r23,0(r6)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rotlwi r11,r9,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// subf r27,r7,r9
	ctx.r27.s64 = ctx.r9.s64 - ctx.r7.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// andc r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 & ~ctx.r11.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// twlgei r11,-1
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r9,r27,1
	ctx.r9.s64 = ctx.r27.s64 + 1;
	// mtctr r23
	ctx.ctr.u64 = ctx.r23.u64;
	// bctrl 
	ctx.lr = 0x82D78C14;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d78c5c
	if (!ctx.cr0.eq) goto loc_82D78C5C;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r9,r27,2
	ctx.r9.s64 = ctx.r27.s64 + 2;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// stw r11,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r11.u32);
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// lwz r11,12(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D78C54;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d78c64
	if (ctx.cr0.eq) goto loc_82D78C64;
loc_82D78C5C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82d78c68
	goto loc_82D78C68;
loc_82D78C64:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82D78C68:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D78C70"))) PPC_WEAK_FUNC(sub_82D78C70);
PPC_FUNC_IMPL(__imp__sub_82D78C70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D78C78;
	__savegprlr_28(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r28,260(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lwz r11,268(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// beq cr6,0x82d78cc4
	if (ctx.cr6.eq) goto loc_82D78CC4;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,252(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r28.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r11,244(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82d78b20
	ctx.lr = 0x82D78CB8;
	sub_82D78B20(ctx, base);
loc_82D78CB8:
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d78ce4
	if (!ctx.cr0.eq) goto loc_82D78CE4;
	// b 0x82d78d20
	goto loc_82D78D20;
loc_82D78CC4:
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,252(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r28.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r11,244(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82d78980
	ctx.lr = 0x82D78CE0;
	sub_82D78980(ctx, base);
	// b 0x82d78cb8
	goto loc_82D78CB8;
loc_82D78CE4:
	// lwz r11,152(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 152);
	// rlwinm. r11,r11,0,3,3
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d78d1c
	if (ctx.cr0.eq) goto loc_82D78D1C;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mullw r4,r30,r29
	ctx.r4.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r29.s32);
	// subfic r11,r11,0
	ctx.xer.ca = ctx.r11.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,23,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1F0;
	// addi r3,r11,16
	ctx.r3.s64 = ctx.r11.s64 + 16;
	// bl 0x82d7bd90
	ctx.lr = 0x82D78D10;
	sub_82D7BD90(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// bne 0x82d78d20
	if (!ctx.cr0.eq) goto loc_82D78D20;
loc_82D78D1C:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82D78D20:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D78D28"))) PPC_WEAK_FUNC(sub_82D78D28);
PPC_FUNC_IMPL(__imp__sub_82D78D28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e3c
	ctx.lr = 0x82D78D30;
	__savegprlr_17(ctx, base);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r6
	ctx.r24.u64 = ctx.r6.u64;
	// lwz r22,356(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// mr r25,r7
	ctx.r25.u64 = ctx.r7.u64;
	// lwz r30,348(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// lwz r23,340(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// srawi r11,r25,1
	ctx.xer.ca = (ctx.r25.s32 < 0) & ((ctx.r25.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r25.s32 >> 1;
	// mr r21,r8
	ctx.r21.u64 = ctx.r8.u64;
	// stw r22,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r22.u32);
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// stw r6,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r6.u32);
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// lwz r18,20(r28)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r23.u32);
	// mr r29,r9
	ctx.r29.u64 = ctx.r9.u64;
	// mr r17,r10
	ctx.r17.u64 = ctx.r10.u64;
	// li r27,0
	ctx.r27.s64 = 0;
	// mullw r19,r11,r21
	ctx.r19.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r21.s32);
	// bl 0x82d78c70
	ctx.lr = 0x82D78D90;
	sub_82D78C70(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d78da0
	if (!ctx.cr0.eq) goto loc_82D78DA0;
loc_82D78D98:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82d78fc0
	goto loc_82D78FC0;
loc_82D78DA0:
	// bl 0x82d0f148
	ctx.lr = 0x82D78DA4;
	sub_82D0F148(ctx, base);
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82d0f150
	ctx.lr = 0x82D78DB8;
	sub_82D0F150(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = ctx.r20.u64;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r7,r23
	ctx.r7.u64 = ctx.r23.u64;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// bl 0x82d216b0
	ctx.lr = 0x82D78DD4;
	sub_82D216B0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82d0e108
	ctx.lr = 0x82D78DE0;
	sub_82D0E108(ctx, base);
	// mr. r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// beq 0x82d78e6c
	if (ctx.cr0.eq) goto loc_82D78E6C;
	// srawi r11,r25,1
	ctx.xer.ca = (ctx.r25.s32 < 0) & ((ctx.r25.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r25.s32 >> 1;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// subf. r11,r11,r25
	ctx.r11.s64 = ctx.r25.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d78e04
	if (ctx.cr0.eq) goto loc_82D78E04;
	// bl 0x82d0f148
	ctx.lr = 0x82D78E00;
	sub_82D0F148(ctx, base);
	// b 0x82d78e14
	goto loc_82D78E14;
loc_82D78E04:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82d0f150
	ctx.lr = 0x82D78E14;
	sub_82D0F150(ctx, base);
loc_82D78E14:
	// subfic r10,r31,0
	ctx.xer.ca = ctx.r31.u32 <= 0;
	ctx.r10.s64 = 0 - ctx.r31.s64;
	// rlwinm r11,r19,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 2) & 0xFFFFFFFC;
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// add r31,r11,r30
	ctx.r31.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// add r30,r11,r23
	ctx.r30.u64 = ctx.r11.u64 + ctx.r23.u64;
	// andi. r10,r10,5
	ctx.r10.u64 = ctx.r10.u64 & 5;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r19,r10,1
	ctx.r19.s64 = ctx.r10.s64 + 1;
	// bl 0x82d0f148
	ctx.lr = 0x82D78E38;
	sub_82D0F148(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r8,r31
	ctx.r8.u64 = ctx.r31.u64;
	// mr r9,r19
	ctx.r9.u64 = ctx.r19.u64;
	// bl 0x82d216b0
	ctx.lr = 0x82D78E58;
	sub_82D216B0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82d0e108
	ctx.lr = 0x82D78E64;
	sub_82D0E108(ctx, base);
	// mr. r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// bne 0x82d78e80
	if (!ctx.cr0.eq) goto loc_82D78E80;
loc_82D78E6C:
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82d0c300
	ctx.lr = 0x82D78E74;
	sub_82D0C300(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82d0c300
	ctx.lr = 0x82D78E7C;
	sub_82D0C300(ctx, base);
	// b 0x82d78d98
	goto loc_82D78D98;
loc_82D78E80:
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r23,112(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d78ea4
	if (ctx.cr6.eq) goto loc_82D78EA4;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r5,r11,-31104
	ctx.r5.s64 = ctx.r11.s64 + -31104;
	// addi r4,r10,3652
	ctx.r4.s64 = ctx.r10.s64 + 3652;
	// b 0x82d78ec8
	goto loc_82D78EC8;
loc_82D78EA4:
	// cmpwi cr6,r23,0
	ctx.cr6.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq cr6,0x82d78eb8
	if (ctx.cr6.eq) goto loc_82D78EB8;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-31840
	ctx.r5.s64 = ctx.r11.s64 + -31840;
	// b 0x82d78ec0
	goto loc_82D78EC0;
loc_82D78EB8:
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-32088
	ctx.r5.s64 = ctx.r11.s64 + -32088;
loc_82D78EC0:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r4,r11,3652
	ctx.r4.s64 = ctx.r11.s64 + 3652;
loc_82D78EC8:
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82d7c538
	ctx.lr = 0x82D78ED0;
	sub_82D7C538(ctx, base);
	// addi r11,r26,3
	ctx.r11.s64 = ctx.r26.s64 + 3;
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r30,r31,8
	ctx.r30.s64 = ctx.r31.s64 + 8;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r10,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r26,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r26.u32);
	// stw r24,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r24.u32);
	// stw r25,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r25.u32);
	// stw r21,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r21.u32);
	// stw r29,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r29.u32);
	// stw r10,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r10.u32);
	// stw r17,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r17.u32);
	// stw r28,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r28.u32);
	// stw r11,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r11.u32);
	// stw r20,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r20.u32);
	// stw r27,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r27.u32);
	// stw r23,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r23.u32);
	// bl 0x82d0c680
	ctx.lr = 0x82D78F2C;
	sub_82D0C680(ctx, base);
	// addi r11,r25,-1
	ctx.r11.s64 = ctx.r25.s64 + -1;
	// lwz r10,12(r18)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r18.u32 + 12);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// addi r4,r18,16
	ctx.r4.s64 = ctx.r18.s64 + 16;
	// addze r9,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r9.s64 = temp.s64;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rotlwi r11,r9,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r9,r9,r10
	ctx.r9.s32 = ctx.r9.s32 / ctx.r10.s32;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mullw r3,r9,r29
	ctx.r3.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r29.s32);
	// andc r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// twllei r10,0
	// twlgei r11,-1
	// bl 0x82d0c7e0
	ctx.lr = 0x82D78F68;
	sub_82D0C7E0(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r20,8
	ctx.r4.s64 = ctx.r20.s64 + 8;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82d0c7e0
	ctx.lr = 0x82D78F78;
	sub_82D0C7E0(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r27,8
	ctx.r4.s64 = ctx.r27.s64 + 8;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82d0c7e0
	ctx.lr = 0x82D78F88;
	sub_82D0C7E0(ctx, base);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d78fbc
	if (ctx.cr6.eq) goto loc_82D78FBC;
	// mullw r11,r26,r25
	ctx.r11.s64 = int64_t(ctx.r26.s32) * int64_t(ctx.r25.s32);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// mullw r11,r11,r29
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r29.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r11.u64);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82D78FBC:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82D78FC0:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82e28e8c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D78FC8"))) PPC_WEAK_FUNC(sub_82D78FC8);
PPC_FUNC_IMPL(__imp__sub_82D78FC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D78FD0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// addi r6,r11,-29400
	ctx.r6.s64 = ctx.r11.s64 + -29400;
	// li r3,32
	ctx.r3.s64 = 32;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// bl 0x82d7c500
	ctx.lr = 0x82D78FFC;
	sub_82D7C500(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, ctx.r29.u32);
	// stw r31,20(r4)
	PPC_STORE_U32(ctx.r4.u32 + 20, ctx.r31.u32);
	// stw r28,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r28.u32);
	// bl 0x82d0e6f0
	ctx.lr = 0x82D79014;
	sub_82D0E6F0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79020"))) PPC_WEAK_FUNC(sub_82D79020);
PPC_FUNC_IMPL(__imp__sub_82D79020) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D79028;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// bl 0x82d78fc8
	ctx.lr = 0x82D79044;
	sub_82D78FC8(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d78fc8
	ctx.lr = 0x82D7905C;
	sub_82D78FC8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79068"))) PPC_WEAK_FUNC(sub_82D79068);
PPC_FUNC_IMPL(__imp__sub_82D79068) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// lwz r8,80(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	// lwz r31,76(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// lwz r9,68(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// lwz r7,64(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// stw r8,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r8.u32);
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// lwz r11,84(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D790B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D790D0"))) PPC_WEAK_FUNC(sub_82D790D0);
PPC_FUNC_IMPL(__imp__sub_82D790D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D790D8;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// lwz r28,80(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r9,68(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r30,72(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r7,64(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// lwz r27,84(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r28.u32);
	// mtctr r27
	ctx.ctr.u64 = ctx.r27.u64;
	// bctrl 
	ctx.lr = 0x82D79124;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82d79154
	if (!ctx.cr6.gt) goto loc_82D79154;
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// rlwinm r11,r28,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,-13892(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
loc_82D79138:
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stfsx f0,r10,r29
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r29.u32, temp.u32);
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// bne 0x82d79138
	if (!ctx.cr0.eq) goto loc_82D79138;
loc_82D79154:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79160"))) PPC_WEAK_FUNC(sub_82D79160);
PPC_FUNC_IMPL(__imp__sub_82D79160) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79168"))) PPC_WEAK_FUNC(sub_82D79168);
PPC_FUNC_IMPL(__imp__sub_82D79168) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D79170;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,88(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 88);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r30,72(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 72);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// lwz r29,4(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r28,0(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// bl 0x82d1fc50
	ctx.lr = 0x82D79198;
	sub_82D1FC50(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r11,22248
	ctx.r4.s64 = ctx.r11.s64 + 22248;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D791C0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D791C8"))) PPC_WEAK_FUNC(sub_82D791C8);
PPC_FUNC_IMPL(__imp__sub_82D791C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82d7927c
	if (!ctx.cr6.eq) goto loc_82D7927C;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bgt cr6,0x82d7927c
	if (ctx.cr6.gt) goto loc_82D7927C;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82d7927c
	if (!ctx.cr6.eq) goto loc_82D7927C;
	// lwz r11,40(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d7927c
	if (!ctx.cr6.eq) goto loc_82D7927C;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// bl 0x82d1f0d0
	ctx.lr = 0x82D79234;
	sub_82D1F0D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d7927c
	if (ctx.cr0.eq) goto loc_82D7927C;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82d79274
	if (!ctx.cr6.eq) goto loc_82D79274;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d79274
	if (ctx.cr6.eq) goto loc_82D79274;
	// lis r4,32767
	ctx.r4.s64 = 2147418112;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// ori r4,r4,65535
	ctx.r4.u64 = ctx.r4.u64 | 65535;
	// bl 0x82d20e70
	ctx.lr = 0x82D7926C;
	sub_82D20E70(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d7927c
	if (ctx.cr0.eq) goto loc_82D7927C;
loc_82D79274:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82d79280
	goto loc_82D79280;
loc_82D7927C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82D79280:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79298"))) PPC_WEAK_FUNC(sub_82D79298);
PPC_FUNC_IMPL(__imp__sub_82D79298) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D792A0;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// bl 0x82d791c8
	ctx.lr = 0x82D792B0;
	sub_82D791C8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d7940c
	if (ctx.cr0.eq) goto loc_82D7940C;
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt 0x82d792d0
	if (ctx.cr0.lt) goto loc_82D792D0;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// li r29,1
	ctx.r29.s64 = 1;
	// ble cr6,0x82d792d4
	if (!ctx.cr6.gt) goto loc_82D792D4;
loc_82D792D0:
	// li r29,0
	ctx.r29.s64 = 0;
loc_82D792D4:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82d792e8
	if (!ctx.cr6.eq) goto loc_82D792E8;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-28464
	ctx.r5.s64 = ctx.r11.s64 + -28464;
	// b 0x82d792f0
	goto loc_82D792F0;
loc_82D792E8:
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-28568
	ctx.r5.s64 = ctx.r11.s64 + -28568;
loc_82D792F0:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r3,96
	ctx.r3.s64 = 96;
	// addi r4,r11,3668
	ctx.r4.s64 = ctx.r11.s64 + 3668;
	// bl 0x82d21140
	ctx.lr = 0x82D79300;
	sub_82D21140(ctx, base);
	// lwz r11,12(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r30,4(r28)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// beq cr6,0x82d79320
	if (ctx.cr6.eq) goto loc_82D79320;
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82d79324
	goto loc_82D79324;
loc_82D79320:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
loc_82D79324:
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// beq cr6,0x82d79338
	if (ctx.cr6.eq) goto loc_82D79338;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// b 0x82d7933c
	goto loc_82D7933C;
loc_82D79338:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
loc_82D7933C:
	// addi r29,r31,72
	ctx.r29.s64 = ctx.r31.s64 + 72;
	// stw r11,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r11.u32);
	// addi r6,r31,80
	ctx.r6.s64 = ctx.r31.s64 + 80;
	// lwz r3,8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// addi r5,r31,76
	ctx.r5.s64 = ctx.r31.s64 + 76;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82d1f0d0
	ctx.lr = 0x82D79358;
	sub_82D1F0D0(ctx, base);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// srawi r10,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 1;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// subf. r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82d79378
	if (ctx.cr0.eq) goto loc_82D79378;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82d79388
	goto loc_82D79388;
loc_82D79378:
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
loc_82D79388:
	// addi r30,r31,8
	ctx.r30.s64 = ctx.r31.s64 + 8;
	// stw r11,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r11.u32);
	// stw r27,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r27.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d0c680
	ctx.lr = 0x82D7939C;
	sub_82D0C680(ctx, base);
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r11,8
	ctx.r4.s64 = ctx.r11.s64 + 8;
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// lwz r8,40(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lwz r11,4(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// andc r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// divw r3,r9,r11
	ctx.r3.s32 = ctx.r9.s32 / ctx.r11.s32;
	// twllei r11,0
	// twlgei r10,-1
	// bl 0x82d0c7e0
	ctx.lr = 0x82D793D0;
	sub_82D0C7E0(ctx, base);
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82d79400
	if (!ctx.cr6.eq) goto loc_82D79400;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82D79400:
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r11.u32);
loc_82D7940C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79418"))) PPC_WEAK_FUNC(sub_82D79418);
PPC_FUNC_IMPL(__imp__sub_82D79418) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,3684
	ctx.r4.s64 = ctx.r11.s64 + 3684;
	// li r3,16
	ctx.r3.s64 = 16;
	// bl 0x82d0e650
	ctx.lr = 0x82D79444;
	sub_82D0E650(ctx, base);
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79468"))) PPC_WEAK_FUNC(sub_82D79468);
PPC_FUNC_IMPL(__imp__sub_82D79468) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D79470;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	// lwz r9,96(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// lwz r30,104(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r29,100(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	// rlwinm r31,r9,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r7,r5
	ctx.r6.u64 = ctx.r7.u64 + ctx.r5.u64;
	// lwz r10,92(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// lwz r8,68(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r7,64(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// lwz r11,116(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D794C0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D794C8"))) PPC_WEAK_FUNC(sub_82D794C8);
PPC_FUNC_IMPL(__imp__sub_82D794C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D794D0;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	// lwz r9,96(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// lwz r30,104(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r29,100(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	// rlwinm r31,r9,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r7,r4
	ctx.r6.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lwz r10,92(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// add r4,r31,r3
	ctx.r4.u64 = ctx.r31.u64 + ctx.r3.u64;
	// lwz r8,68(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r7,64(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// lwz r11,116(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D79524;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79530"))) PPC_WEAK_FUNC(sub_82D79530);
PPC_FUNC_IMPL(__imp__sub_82D79530) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79540"))) PPC_WEAK_FUNC(sub_82D79540);
PPC_FUNC_IMPL(__imp__sub_82D79540) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D79548;
	__savegprlr_26(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r29,1
	ctx.r29.s64 = 1;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r9,100(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// lwz r6,96(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r7,80(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// bl 0x82d226b0
	ctx.lr = 0x82D79588;
	sub_82D226B0(ctx, base);
	// lwz r8,68(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// neg r10,r8
	ctx.r10.s64 = -ctx.r8.s64;
	// blt 0x82d7959c
	if (ctx.cr0.lt) goto loc_82D7959C;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_82D7959C:
	// lwz r5,104(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// cmpwi r5,0
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// neg r11,r5
	ctx.r11.s64 = -ctx.r5.s64;
	// blt 0x82d795b0
	if (ctx.cr0.lt) goto loc_82D795B0;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
loc_82D795B0:
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bge cr6,0x82d795fc
	if (!ctx.cr6.lt) goto loc_82D795FC;
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// lwz r10,80(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// rlwinm r6,r11,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,72(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// rlwinm r11,r10,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r5,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r5.u32);
	// lwz r31,116(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// add r6,r6,r27
	ctx.r6.u64 = ctx.r6.u64 + ctx.r27.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// add r4,r11,r30
	ctx.r4.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82D795F8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82d7965c
	goto loc_82D7965C;
loc_82D795FC:
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// lwz r8,80(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,84(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r26,116(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// add r6,r11,r30
	ctx.r6.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// add r4,r11,r30
	ctx.r4.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mtctr r26
	ctx.ctr.u64 = ctx.r26.u64;
	// bctrl 
	ctx.lr = 0x82D79634;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// lwz r10,104(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r7,68(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r6,80(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// bl 0x82d22750
	ctx.lr = 0x82D7965C;
	sub_82D22750(ctx, base);
loc_82D7965C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79668"))) PPC_WEAK_FUNC(sub_82D79668);
PPC_FUNC_IMPL(__imp__sub_82D79668) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D79670;
	__savegprlr_26(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// lwz r6,68(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// cmpwi r6,0
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// neg r9,r6
	ctx.r9.s64 = -ctx.r6.s64;
	// blt 0x82d7969c
	if (ctx.cr0.lt) goto loc_82D7969C;
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
loc_82D7969C:
	// lwz r11,100(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// neg r10,r11
	ctx.r10.s64 = -ctx.r11.s64;
	// blt 0x82d796b0
	if (ctx.cr0.lt) goto loc_82D796B0;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82D796B0:
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// li r29,1
	ctx.r29.s64 = 1;
	// bge cr6,0x82d79704
	if (!ctx.cr6.lt) goto loc_82D79704;
	// lwz r8,108(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// rlwinm r5,r8,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// lwz r9,72(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// add r6,r5,r3
	ctx.r6.u64 = ctx.r5.u64 + ctx.r3.u64;
	// lwz r26,116(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// add r4,r11,r30
	ctx.r4.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mtctr r26
	ctx.ctr.u64 = ctx.r26.u64;
	// bctrl 
	ctx.lr = 0x82D79700;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82d79764
	goto loc_82D79764;
loc_82D79704:
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r7,80(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82d226b0
	ctx.lr = 0x82D79724;
	sub_82D226B0(ctx, base);
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r8,80(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,84(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// add r6,r11,r30
	ctx.r6.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r26,116(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// add r4,r11,r30
	ctx.r4.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mtctr r26
	ctx.ctr.u64 = ctx.r26.u64;
	// bctrl 
	ctx.lr = 0x82D79764;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82D79764:
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r10,104(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// lwz r7,96(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r6,80(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// bl 0x82d22750
	ctx.lr = 0x82D7978C;
	sub_82D22750(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79798"))) PPC_WEAK_FUNC(sub_82D79798);
PPC_FUNC_IMPL(__imp__sub_82D79798) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82D797A0;
	__savegprlr_23(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r24,r6
	ctx.r24.u64 = ctx.r6.u64;
	// lwz r11,88(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// lwz r23,92(r30)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r31,r10,2
	ctx.r31.s64 = ctx.r10.s64 + 2;
	// mullw r11,r31,r11
	ctx.r11.s64 = int64_t(ctx.r31.s32) * int64_t(ctx.r11.s32);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82d0c438
	ctx.lr = 0x82D797D4;
	sub_82D0C438(ctx, base);
	// subf. r25,r31,r23
	ctx.r25.s64 = ctx.r23.s64 - ctx.r31.s64;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r29,0
	ctx.r29.s64 = 0;
	// ble 0x82d7982c
	if (!ctx.cr0.gt) goto loc_82D7982C;
loc_82D797E4:
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r24
	ctx.ctr.u64 = ctx.r24.u64;
	// bctrl 
	ctx.lr = 0x82D79800;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,100(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	// lwz r10,104(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 104);
	// add r29,r29,r31
	ctx.r29.u64 = ctx.r29.u64 + ctx.r31.u64;
	// mullw r11,r11,r31
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r31.s32);
	// mullw r9,r10,r31
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r31.s32);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpw cr6,r29,r25
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r25.s32, ctx.xer);
	// add r28,r10,r28
	ctx.r28.u64 = ctx.r10.u64 + ctx.r28.u64;
	// add r27,r11,r27
	ctx.r27.u64 = ctx.r11.u64 + ctx.r27.u64;
	// blt cr6,0x82d797e4
	if (ctx.cr6.lt) goto loc_82D797E4;
loc_82D7982C:
	// subf r7,r29,r23
	ctx.r7.s64 = ctx.r23.s64 - ctx.r29.s64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r24
	ctx.ctr.u64 = ctx.r24.u64;
	// bctrl 
	ctx.lr = 0x82D79848;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82d0c490
	ctx.lr = 0x82D79850;
	sub_82D0C490(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79858"))) PPC_WEAK_FUNC(sub_82D79858);
PPC_FUNC_IMPL(__imp__sub_82D79858) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r6,r11,-27328
	ctx.r6.s64 = ctx.r11.s64 + -27328;
	// b 0x82d79798
	sub_82D79798(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79868"))) PPC_WEAK_FUNC(sub_82D79868);
PPC_FUNC_IMPL(__imp__sub_82D79868) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r6,r11,-27032
	ctx.r6.s64 = ctx.r11.s64 + -27032;
	// b 0x82d79798
	sub_82D79798(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79878"))) PPC_WEAK_FUNC(sub_82D79878);
PPC_FUNC_IMPL(__imp__sub_82D79878) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79880"))) PPC_WEAK_FUNC(sub_82D79880);
PPC_FUNC_IMPL(__imp__sub_82D79880) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D79888;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,120(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r30,92(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 92);
	// lwz r29,88(r3)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 88);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// beq cr6,0x82d798f0
	if (ctx.cr6.eq) goto loc_82D798F0;
	// lwz r28,80(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 80);
	// lwz r27,4(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// bl 0x82d1fc50
	ctx.lr = 0x82D798C0;
	sub_82D1FC50(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r11,22276
	ctx.r4.s64 = ctx.r11.s64 + 22276;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D798EC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82d79928
	goto loc_82D79928;
loc_82D798F0:
	// lwz r28,4(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// bl 0x82d1fc50
	ctx.lr = 0x82D798FC;
	sub_82D1FC50(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r11,r11,22276
	ctx.r11.s64 = ctx.r11.s64 + 22276;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,40
	ctx.r4.s64 = ctx.r11.s64 + 40;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D79928;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82D79928:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79930"))) PPC_WEAK_FUNC(sub_82D79930);
PPC_FUNC_IMPL(__imp__sub_82D79930) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82d79948
	if (ctx.cr6.eq) goto loc_82D79948;
	// cmpwi cr6,r3,4
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 4, ctx.xer);
	// beq cr6,0x82d79948
	if (ctx.cr6.eq) goto loc_82D79948;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
loc_82D79948:
	// mullw r3,r11,r5
	ctx.r3.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r5.s32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79950"))) PPC_WEAK_FUNC(sub_82D79950);
PPC_FUNC_IMPL(__imp__sub_82D79950) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82d799fc
	if (!ctx.cr6.eq) goto loc_82D799FC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bgt cr6,0x82d799fc
	if (ctx.cr6.gt) goto loc_82D799FC;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82d799fc
	if (!ctx.cr6.eq) goto loc_82D799FC;
	// lwz r11,40(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d799fc
	if (!ctx.cr6.eq) goto loc_82D799FC;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82d1f0d0
	ctx.lr = 0x82D799BC;
	sub_82D1F0D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d799fc
	if (ctx.cr0.eq) goto loc_82D799FC;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82d799f4
	if (!ctx.cr6.eq) goto loc_82D799F4;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82d799f4
	if (ctx.cr6.eq) goto loc_82D799F4;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82d21b28
	ctx.lr = 0x82D799EC;
	sub_82D21B28(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d799fc
	if (ctx.cr0.eq) goto loc_82D799FC;
loc_82D799F4:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82d79a00
	goto loc_82D79A00;
loc_82D799FC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82D79A00:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79A18"))) PPC_WEAK_FUNC(sub_82D79A18);
PPC_FUNC_IMPL(__imp__sub_82D79A18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r30,8(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82d79ad8
	if (!ctx.cr6.eq) goto loc_82D79AD8;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bgt cr6,0x82d79ad8
	if (ctx.cr6.gt) goto loc_82D79AD8;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82d79ad8
	if (!ctx.cr6.eq) goto loc_82D79AD8;
	// lwz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d79ad8
	if (!ctx.cr6.eq) goto loc_82D79AD8;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82d1f0d0
	ctx.lr = 0x82D79A88;
	sub_82D1F0D0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d79ad8
	if (ctx.cr0.eq) goto loc_82D79AD8;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// rlwinm r30,r11,0,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82d79ad0
	if (!ctx.cr6.eq) goto loc_82D79AD0;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82d21b28
	ctx.lr = 0x82D79AB8;
	sub_82D21B28(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d79ad0
	if (!ctx.cr0.eq) goto loc_82D79AD0;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r30,2
	ctx.r11.s64 = ctx.r30.s64 + 2;
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bgt cr6,0x82d79ad8
	if (ctx.cr6.gt) goto loc_82D79AD8;
loc_82D79AD0:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82d79adc
	goto loc_82D79ADC;
loc_82D79AD8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82D79ADC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79AF8"))) PPC_WEAK_FUNC(sub_82D79AF8);
PPC_FUNC_IMPL(__imp__sub_82D79AF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D79B00;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d79b28
	if (ctx.cr6.eq) goto loc_82D79B28;
	// bl 0x82d79a18
	ctx.lr = 0x82D79B1C;
	sub_82D79A18(ctx, base);
loc_82D79B1C:
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d79b30
	if (!ctx.cr0.eq) goto loc_82D79B30;
	// b 0x82d79cec
	goto loc_82D79CEC;
loc_82D79B28:
	// bl 0x82d79950
	ctx.lr = 0x82D79B2C;
	sub_82D79950(ctx, base);
	// b 0x82d79b1c
	goto loc_82D79B1C;
loc_82D79B30:
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt 0x82d79b74
	if (ctx.cr0.lt) goto loc_82D79B74;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bgt cr6,0x82d79b74
	if (ctx.cr6.gt) goto loc_82D79B74;
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r26,8(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r30,12(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// beq cr6,0x82d79b68
	if (ctx.cr6.eq) goto loc_82D79B68;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-26536
	ctx.r5.s64 = ctx.r11.s64 + -26536;
	// b 0x82d79ba0
	goto loc_82D79BA0;
loc_82D79B68:
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-27544
	ctx.r5.s64 = ctx.r11.s64 + -27544;
	// b 0x82d79ba0
	goto loc_82D79BA0;
loc_82D79B74:
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r26,12(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r30,8(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// beq cr6,0x82d79b98
	if (ctx.cr6.eq) goto loc_82D79B98;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-26520
	ctx.r5.s64 = ctx.r11.s64 + -26520;
	// b 0x82d79ba0
	goto loc_82D79BA0;
loc_82D79B98:
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-27448
	ctx.r5.s64 = ctx.r11.s64 + -27448;
loc_82D79BA0:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r3,128
	ctx.r3.s64 = 128;
	// addi r4,r11,3696
	ctx.r4.s64 = ctx.r11.s64 + 3696;
	// bl 0x82d20138
	ctx.lr = 0x82D79BB0;
	sub_82D20138(ctx, base);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r10,12(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// rlwinm r9,r26,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 1) & 0xFFFFFFFE;
	// neg r8,r30
	ctx.r8.s64 = -ctx.r30.s64;
	// lwz r28,4(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r10.u32);
	// stw r26,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r26.u32);
	// stw r9,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r9.u32);
	// stw r30,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r30.u32);
	// stw r8,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r8.u32);
	// stw r28,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r28.u32);
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d79bf8
	if (ctx.cr0.eq) goto loc_82D79BF8;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// addi r11,r28,-1
	ctx.r11.s64 = ctx.r28.s64 + -1;
	// bne cr6,0x82d79bfc
	if (!ctx.cr6.eq) goto loc_82D79BFC;
loc_82D79BF8:
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
loc_82D79BFC:
	// mullw r11,r11,r30
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// addi r10,r28,3
	ctx.r10.s64 = ctx.r28.s64 + 3;
	// stw r11,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r11.u32);
	// rlwinm r11,r10,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// neg r9,r11
	ctx.r9.s64 = -ctx.r11.s64;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// stw r10,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r10.u32);
	// stw r9,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r9.u32);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82d79c3c
	if (ctx.cr0.eq) goto loc_82D79C3C;
	// cmpwi cr6,r10,4
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 4, ctx.xer);
	// addi r10,r28,-1
	ctx.r10.s64 = ctx.r28.s64 + -1;
	// bne cr6,0x82d79c40
	if (!ctx.cr6.eq) goto loc_82D79C40;
loc_82D79C3C:
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
loc_82D79C40:
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// addi r30,r31,92
	ctx.r30.s64 = ctx.r31.s64 + 92;
	// stw r11,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r11.u32);
	// lwz r3,8(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// addi r6,r31,104
	ctx.r6.s64 = ctx.r31.s64 + 104;
	// addi r5,r31,100
	ctx.r5.s64 = ctx.r31.s64 + 100;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82d1f0d0
	ctx.lr = 0x82D79C60;
	sub_82D1F0D0(ctx, base);
	// addi r29,r31,8
	ctx.r29.s64 = ctx.r31.s64 + 8;
	// stw r27,120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 120, ctx.r27.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82d0c680
	ctx.lr = 0x82D79C70;
	sub_82D0C680(ctx, base);
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r4,r11,8
	ctx.r4.s64 = ctx.r11.s64 + 8;
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// lwz r8,40(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lwz r11,4(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// andc r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// divw r3,r9,r11
	ctx.r3.s32 = ctx.r9.s32 / ctx.r11.s32;
	// twllei r11,0
	// twlgei r10,-1
	// bl 0x82d0c7e0
	ctx.lr = 0x82D79CA4;
	sub_82D0C7E0(ctx, base);
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d79cd8
	if (ctx.cr6.eq) goto loc_82D79CD8;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82D79CD8:
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// stw r11,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r11.u32);
loc_82D79CEC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79CF8"))) PPC_WEAK_FUNC(sub_82D79CF8);
PPC_FUNC_IMPL(__imp__sub_82D79CF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D79D00;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,3712
	ctx.r4.s64 = ctx.r11.s64 + 3712;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82d0e650
	ctx.lr = 0x82D79D20;
	sub_82D0E650(ctx, base);
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// stw r29,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r29.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79D38"))) PPC_WEAK_FUNC(sub_82D79D38);
PPC_FUNC_IMPL(__imp__sub_82D79D38) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,3712
	ctx.r4.s64 = ctx.r11.s64 + 3712;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82d0e650
	ctx.lr = 0x82D79D64;
	sub_82D0E650(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79D90"))) PPC_WEAK_FUNC(sub_82D79D90);
PPC_FUNC_IMPL(__imp__sub_82D79D90) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,3712
	ctx.r4.s64 = ctx.r11.s64 + 3712;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82d0e650
	ctx.lr = 0x82D79DBC;
	sub_82D0E650(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79DE8"))) PPC_WEAK_FUNC(sub_82D79DE8);
PPC_FUNC_IMPL(__imp__sub_82D79DE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82D79DF0;
	__savegprlr_20(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r28,84(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r26,68(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r25,72(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// cmpwi r28,0
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r27,96(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r20,100(r31)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// lwz r29,88(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// ble 0x82d79eb4
	if (!ctx.cr0.gt) goto loc_82D79EB4;
	// srawi r9,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r11.s32 >> 1;
	// subf r11,r27,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r27.s64;
	// addze r9,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r9.s64 = temp.s64;
	// mullw r11,r11,r29
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r29.s32);
	// mullw r8,r29,r27
	ctx.r8.s64 = int64_t(ctx.r29.s32) * int64_t(ctx.r27.s32);
	// mullw r9,r9,r29
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r29.s32);
	// rlwinm r24,r11,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r8,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r22,r9,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r21,r10,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D79E4C:
	// lwz r11,56(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 56);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D79E64;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r6,104(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r8,r20
	ctx.r8.u64 = ctx.r20.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// add r4,r24,r30
	ctx.r4.u64 = ctx.r24.u64 + ctx.r30.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r3,r23,r30
	ctx.r3.u64 = ctx.r23.u64 + ctx.r30.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82D79E90;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// add r5,r22,r30
	ctx.r5.u64 = ctx.r22.u64 + ctx.r30.u64;
	// lwz r11,56(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 56);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D79EA8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// add r30,r21,r30
	ctx.r30.u64 = ctx.r21.u64 + ctx.r30.u64;
	// bne 0x82d79e4c
	if (!ctx.cr0.eq) goto loc_82D79E4C;
loc_82D79EB4:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D79EC0"))) PPC_WEAK_FUNC(sub_82D79EC0);
PPC_FUNC_IMPL(__imp__sub_82D79EC0) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D79ED0"))) PPC_WEAK_FUNC(sub_82D79ED0);
PPC_FUNC_IMPL(__imp__sub_82D79ED0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e3c
	ctx.lr = 0x82D79ED8;
	__savegprlr_17(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r24,r6
	ctx.r24.u64 = ctx.r6.u64;
	// mr r29,r8
	ctx.r29.u64 = ctx.r8.u64;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r21,r7
	ctx.r21.u64 = ctx.r7.u64;
	// lwz r28,88(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// li r22,1
	ctx.r22.s64 = 1;
	// lwz r30,108(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// subf r26,r24,r21
	ctx.r26.s64 = ctx.r21.s64 - ctx.r24.s64;
	// mullw r9,r28,r24
	ctx.r9.s64 = int64_t(ctx.r28.s32) * int64_t(ctx.r24.s32);
	// lwz r27,104(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// lwz r25,76(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// rlwinm r3,r30,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r20,r9,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r3,r29
	ctx.r3.u64 = ctx.r3.u64 + ctx.r29.u64;
	// add r19,r20,r11
	ctx.r19.u64 = ctx.r20.u64 + ctx.r11.u64;
	// mr r17,r5
	ctx.r17.u64 = ctx.r5.u64;
	// addi r23,r3,-4
	ctx.r23.s64 = ctx.r3.s64 + -4;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82d226b0
	ctx.lr = 0x82D79F4C;
	sub_82D226B0(ctx, base);
	// neg r18,r28
	ctx.r18.s64 = -ctx.r28.s64;
	// subf r20,r20,r17
	ctx.r20.s64 = ctx.r17.s64 - ctx.r20.s64;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r9,r18
	ctx.r9.u64 = ctx.r18.u64;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82d226b0
	ctx.lr = 0x82D79F7C;
	sub_82D226B0(ctx, base);
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r6,108(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r8,r21
	ctx.r8.u64 = ctx.r21.u64;
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82D79FA8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82d22750
	ctx.lr = 0x82D79FD0;
	sub_82D22750(ctx, base);
	// mr r10,r18
	ctx.r10.u64 = ctx.r18.u64;
	// li r9,-1
	ctx.r9.s64 = -1;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r20
	ctx.r4.u64 = ctx.r20.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82d22750
	ctx.lr = 0x82D79FF8;
	sub_82D22750(ctx, base);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82e28e8c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7A000"))) PPC_WEAK_FUNC(sub_82D7A000);
PPC_FUNC_IMPL(__imp__sub_82D7A000) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e3c
	ctx.lr = 0x82D7A008;
	__savegprlr_17(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r18,68(r31)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// lwz r21,72(r31)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r28,80(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r29,84(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r22,96(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// addi r26,r10,2
	ctx.r26.s64 = ctx.r10.s64 + 2;
	// lwz r25,100(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// lwz r27,88(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mullw r11,r26,r11
	ctx.r11.s64 = int64_t(ctx.r26.s32) * int64_t(ctx.r11.s32);
	// rlwinm r3,r11,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x82d0c438
	ctx.lr = 0x82D7A04C;
	sub_82D0C438(ctx, base);
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// ble cr6,0x82d7a118
	if (!ctx.cr6.gt) goto loc_82D7A118;
	// srawi r11,r28,1
	ctx.xer.ca = (ctx.r28.s32 < 0) & ((ctx.r28.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r28.s32 >> 1;
	// mullw r10,r27,r28
	ctx.r10.s64 = int64_t(ctx.r27.s32) * int64_t(ctx.r28.s32);
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// rlwinm r17,r10,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mullw r11,r11,r27
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r27.s32);
	// add r19,r26,r22
	ctx.r19.u64 = ctx.r26.u64 + ctx.r22.u64;
	// rlwinm r20,r11,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r24,r29
	ctx.r24.u64 = ctx.r29.u64;
loc_82D7A078:
	// lwz r11,56(r18)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r18.u32 + 56);
	// add r27,r17,r30
	ctx.r27.u64 = ctx.r17.u64 + ctx.r30.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7A094;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r29,r22
	ctx.r29.u64 = ctx.r22.u64;
	// cmpw cr6,r19,r25
	ctx.cr6.compare<int32_t>(ctx.r19.s32, ctx.r25.s32, ctx.xer);
	// bge cr6,0x82d7a0d0
	if (!ctx.cr6.lt) goto loc_82D7A0D0;
	// mr r28,r19
	ctx.r28.u64 = ctx.r19.u64;
loc_82D7A0A4:
	// mr r8,r23
	ctx.r8.u64 = ctx.r23.u64;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d79ed0
	ctx.lr = 0x82D7A0C0;
	sub_82D79ED0(ctx, base);
	// add r28,r28,r26
	ctx.r28.u64 = ctx.r28.u64 + ctx.r26.u64;
	// add r29,r29,r26
	ctx.r29.u64 = ctx.r29.u64 + ctx.r26.u64;
	// cmpw cr6,r28,r25
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r25.s32, ctx.xer);
	// blt cr6,0x82d7a0a4
	if (ctx.cr6.lt) goto loc_82D7A0A4;
loc_82D7A0D0:
	// mr r8,r23
	ctx.r8.u64 = ctx.r23.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d79ed0
	ctx.lr = 0x82D7A0EC;
	sub_82D79ED0(ctx, base);
	// add r5,r20,r30
	ctx.r5.u64 = ctx.r20.u64 + ctx.r30.u64;
	// lwz r11,56(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 56);
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7A104;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addic. r24,r24,-1
	ctx.xer.ca = ctx.r24.u32 > 0;
	ctx.r24.s64 = ctx.r24.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// bne 0x82d7a078
	if (!ctx.cr0.eq) goto loc_82D7A078;
loc_82D7A118:
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82d0c490
	ctx.lr = 0x82D7A120;
	sub_82D0C490(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82e28e8c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7A128"))) PPC_WEAK_FUNC(sub_82D7A128);
PPC_FUNC_IMPL(__imp__sub_82D7A128) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82d0c350
	ctx.lr = 0x82D7A14C;
	sub_82D0C350(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// bl 0x82d0c350
	ctx.lr = 0x82D7A158;
	sub_82D0C350(ctx, base);
	// lwz r10,116(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// addi r4,r31,112
	ctx.r4.s64 = ctx.r31.s64 + 112;
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mullw r6,r7,r11
	ctx.r6.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r11.s32);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r5,8(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// addze r8,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r8.s64 = temp.s64;
	// bl 0x82d20798
	ctx.lr = 0x82D7A188;
	sub_82D20798(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D7A1A0"))) PPC_WEAK_FUNC(sub_82D7A1A0);
PPC_FUNC_IMPL(__imp__sub_82D7A1A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82d0c300
	ctx.lr = 0x82D7A1BC;
	sub_82D0C300(ctx, base);
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// bl 0x82d0c300
	ctx.lr = 0x82D7A1C4;
	sub_82D0C300(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D7A1D8"))) PPC_WEAK_FUNC(sub_82D7A1D8);
PPC_FUNC_IMPL(__imp__sub_82D7A1D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82D7A1E0;
	__savegprlr_25(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// lwz r3,76(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r10,r3,3
	ctx.r10.s64 = ctx.r3.s64 + 3;
	// rlwinm r29,r10,0,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// beq cr6,0x82d7a25c
	if (ctx.cr6.eq) goto loc_82D7A25C;
	// lwz r28,72(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r27,68(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r26,4(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r25,84(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// bl 0x82d20388
	ctx.lr = 0x82D7A224;
	sub_82D20388(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// addi r4,r11,22348
	ctx.r4.s64 = ctx.r11.s64 + 22348;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r5,r29,2
	ctx.r5.s64 = ctx.r29.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7A258;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82d7a2a4
	goto loc_82D7A2A4;
loc_82D7A25C:
	// lwz r29,72(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r28,68(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r27,4(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r26,84(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// bl 0x82d20388
	ctx.lr = 0x82D7A270;
	sub_82D20388(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// lwz r5,76(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r11,r11,22348
	ctx.r11.s64 = ctx.r11.s64 + 22348;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r4,r11,48
	ctx.r4.s64 = ctx.r11.s64 + 48;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7A2A4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82D7A2A4:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7A2B0"))) PPC_WEAK_FUNC(sub_82D7A2B0);
PPC_FUNC_IMPL(__imp__sub_82D7A2B0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r5,r10
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82d7a2d4
	if (!ctx.cr6.eq) goto loc_82D7A2D4;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82D7A2D4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D7A2E0"))) PPC_WEAK_FUNC(sub_82D7A2E0);
PPC_FUNC_IMPL(__imp__sub_82D7A2E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r5,r10
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82d7a30c
	if (!ctx.cr6.eq) goto loc_82D7A30C;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82d7a314
	if (ctx.cr6.eq) goto loc_82D7A314;
loc_82D7A30C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82d7a34c
	goto loc_82D7A34C;
loc_82D7A314:
	// lwz r11,152(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 152);
	// rlwinm. r11,r11,0,3,3
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d7a348
	if (ctx.cr0.eq) goto loc_82D7A348;
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mullw r4,r5,r6
	ctx.r4.s64 = int64_t(ctx.r5.s32) * int64_t(ctx.r6.s32);
	// subfic r11,r11,0
	ctx.xer.ca = ctx.r11.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,23,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1F0;
	// addi r3,r11,16
	ctx.r3.s64 = ctx.r11.s64 + 16;
	// bl 0x82d7bd90
	ctx.lr = 0x82D7A33C;
	sub_82D7BD90(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// bne 0x82d7a34c
	if (!ctx.cr0.eq) goto loc_82D7A34C;
loc_82D7A348:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82D7A34C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D7A360"))) PPC_WEAK_FUNC(sub_82D7A360);
PPC_FUNC_IMPL(__imp__sub_82D7A360) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82D7A368;
	__savegprlr_14(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r6
	ctx.r25.u64 = ctx.r6.u64;
	// lwz r18,340(r1)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// srawi r11,r25,1
	ctx.xer.ca = (ctx.r25.s32 < 0) & ((ctx.r25.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r25.s32 >> 1;
	// mr r23,r7
	ctx.r23.u64 = ctx.r7.u64;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// mr r7,r18
	ctx.r7.u64 = ctx.r18.u64;
	// lwz r22,16(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// mr r15,r9
	ctx.r15.u64 = ctx.r9.u64;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// li r27,0
	ctx.r27.s64 = 0;
	// mullw r14,r11,r23
	ctx.r14.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r23.s32);
	// mullw r21,r25,r23
	ctx.r21.s64 = int64_t(ctx.r25.s32) * int64_t(ctx.r23.s32);
	// bl 0x82d7a2e0
	ctx.lr = 0x82D7A3B0;
	sub_82D7A2E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d7a3c0
	if (!ctx.cr0.eq) goto loc_82D7A3C0;
loc_82D7A3B8:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82d7a5f8
	goto loc_82D7A5F8;
loc_82D7A3C0:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82d7a3dc
	if (!ctx.cr6.eq) goto loc_82D7A3DC;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82d0f150
	ctx.lr = 0x82D7A3D8;
	sub_82D0F150(ctx, base);
	// b 0x82d7a3e0
	goto loc_82D7A3E0;
loc_82D7A3DC:
	// bl 0x82d0f148
	ctx.lr = 0x82D7A3E0;
	sub_82D0F148(ctx, base);
loc_82D7A3E0:
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// bl 0x82d0f148
	ctx.lr = 0x82D7A3E8;
	sub_82D0F148(ctx, base);
	// lwz r16,332(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// mr r6,r16
	ctx.r6.u64 = ctx.r16.u64;
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// bl 0x82d200a8
	ctx.lr = 0x82D7A404;
	sub_82D200A8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// bl 0x82d0e108
	ctx.lr = 0x82D7A410;
	sub_82D0E108(ctx, base);
	// mr. r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// beq 0x82d7a494
	if (ctx.cr0.eq) goto loc_82D7A494;
	// lwz r17,324(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// addi r20,r25,2
	ctx.r20.s64 = ctx.r25.s64 + 2;
	// add r11,r30,r17
	ctx.r11.u64 = ctx.r30.u64 + ctx.r17.u64;
	// rlwinm r19,r11,1,0,30
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpw cr6,r19,r20
	ctx.cr6.compare<int32_t>(ctx.r19.s32, ctx.r20.s32, ctx.xer);
	// bne cr6,0x82d7a444
	if (!ctx.cr6.eq) goto loc_82D7A444;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82d0f150
	ctx.lr = 0x82D7A440;
	sub_82D0F150(ctx, base);
	// b 0x82d7a448
	goto loc_82D7A448;
loc_82D7A444:
	// bl 0x82d0f148
	ctx.lr = 0x82D7A448;
	sub_82D0F148(ctx, base);
loc_82D7A448:
	// subfic r10,r31,0
	ctx.xer.ca = ctx.r31.u32 <= 0;
	ctx.r10.s64 = 0 - ctx.r31.s64;
	// rlwinm r11,r14,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// add r31,r11,r16
	ctx.r31.u64 = ctx.r11.u64 + ctx.r16.u64;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// andi. r11,r10,5
	ctx.r11.u64 = ctx.r10.u64 & 5;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// addi r16,r11,1
	ctx.r16.s64 = ctx.r11.s64 + 1;
	// bl 0x82d0f148
	ctx.lr = 0x82D7A468;
	sub_82D0F148(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r7,r16
	ctx.r7.u64 = ctx.r16.u64;
	// bl 0x82d200a8
	ctx.lr = 0x82D7A480;
	sub_82D200A8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// bl 0x82d0e108
	ctx.lr = 0x82D7A48C;
	sub_82D0E108(ctx, base);
	// mr. r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// bne 0x82d7a4a8
	if (!ctx.cr0.eq) goto loc_82D7A4A8;
loc_82D7A494:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82d0c300
	ctx.lr = 0x82D7A49C;
	sub_82D0C300(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82d0c300
	ctx.lr = 0x82D7A4A4;
	sub_82D0C300(ctx, base);
	// b 0x82d7a3b8
	goto loc_82D7A3B8;
loc_82D7A4A8:
	// lwz r11,24(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d7a4c0
	if (ctx.cr6.eq) goto loc_82D7A4C0;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-24576
	ctx.r5.s64 = ctx.r11.s64 + -24576;
	// b 0x82d7a4c8
	goto loc_82D7A4C8;
loc_82D7A4C0:
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-25112
	ctx.r5.s64 = ctx.r11.s64 + -25112;
loc_82D7A4C8:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r3,120
	ctx.r3.s64 = 120;
	// addi r4,r11,3724
	ctx.r4.s64 = ctx.r11.s64 + 3724;
	// bl 0x82d20d08
	ctx.lr = 0x82D7A4D8;
	sub_82D20D08(ctx, base);
	// subf r11,r19,r20
	ctx.r11.s64 = ctx.r20.s64 - ctx.r19.s64;
	// addi r10,r26,3
	ctx.r10.s64 = ctx.r26.s64 + 3;
	// lwz r9,20(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// cntlzw r8,r11
	ctx.r8.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// rlwinm r11,r10,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// cntlzw r10,r30
	ctx.r10.u64 = ctx.r30.u32 == 0 ? 32 : __builtin_clz(ctx.r30.u32);
	// addi r7,r11,2
	ctx.r7.s64 = ctx.r11.s64 + 2;
	// subf r11,r8,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r8.s64;
	// stw r9,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r9.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// stw r26,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r26.u32);
	// rlwinm r8,r7,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r21,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r21.u32);
	// add r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 + ctx.r30.u64;
	// stw r25,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r25.u32);
	// add r11,r11,r17
	ctx.r11.u64 = ctx.r11.u64 + ctx.r17.u64;
	// stw r23,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r23.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r28,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r28.u32);
	// addi r30,r31,8
	ctx.r30.s64 = ctx.r31.s64 + 8;
	// stw r15,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r15.u32);
	// stw r29,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r29.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r8,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r8.u32);
	// stw r24,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r24.u32);
	// stw r9,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r9.u32);
	// stw r27,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r27.u32);
	// stw r10,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r10.u32);
	// stw r11,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r11.u32);
	// bl 0x82d0c680
	ctx.lr = 0x82D7A558;
	sub_82D0C680(ctx, base);
	// lwz r11,100(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r10,96(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// addi r4,r22,16
	ctx.r4.s64 = ctx.r22.s64 + 16;
	// lwz r9,12(r22)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r22.u32 + 12);
	// subf r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rotlwi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 1);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// divw r10,r10,r9
	ctx.r10.s32 = ctx.r10.s32 / ctx.r9.s32;
	// andc r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 & ~ctx.r11.u64;
	// mullw r3,r10,r28
	ctx.r3.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	// twllei r9,0
	// twlgei r11,-1
	// bl 0x82d0c7e0
	ctx.lr = 0x82D7A594;
	sub_82D0C7E0(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r24,8
	ctx.r4.s64 = ctx.r24.s64 + 8;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82d0c7e0
	ctx.lr = 0x82D7A5A4;
	sub_82D0C7E0(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r27,8
	ctx.r4.s64 = ctx.r27.s64 + 8;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82d0c7e0
	ctx.lr = 0x82D7A5B4;
	sub_82D0C7E0(ctx, base);
	// lwz r11,24(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d7a5f4
	if (ctx.cr6.eq) goto loc_82D7A5F4;
	// lwz r11,100(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// lwz r10,96(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// mullw r11,r11,r26
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r26.s32);
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82D7A5F4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82D7A5F8:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7A600"))) PPC_WEAK_FUNC(sub_82D7A600);
PPC_FUNC_IMPL(__imp__sub_82D7A600) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D7A608;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r3,28
	ctx.r3.s64 = 28;
	// addi r5,r11,-23712
	ctx.r5.s64 = ctx.r11.s64 + -23712;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// bl 0x82d20cc0
	ctx.lr = 0x82D7A630;
	sub_82D20CC0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,20(r4)
	PPC_STORE_U32(ctx.r4.u32 + 20, ctx.r29.u32);
	// stw r31,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r31.u32);
	// stw r28,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r28.u32);
	// bl 0x82d0e6f0
	ctx.lr = 0x82D7A648;
	sub_82D0E6F0(ctx, base);
	// lis r11,-31966
	ctx.r11.s64 = -2094923776;
	// lwz r10,-25300(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -25300);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82d7a68c
	if (ctx.cr6.eq) goto loc_82D7A68C;
	// lis r10,-32040
	ctx.r10.s64 = -2099773440;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,-25300(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -25300);
	// li r3,28
	ctx.r3.s64 = 28;
	// addi r5,r10,-23712
	ctx.r5.s64 = ctx.r10.s64 + -23712;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7A674;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,20(r4)
	PPC_STORE_U32(ctx.r4.u32 + 20, ctx.r29.u32);
	// stw r31,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r31.u32);
	// stw r28,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r28.u32);
	// bl 0x82d0e6f0
	ctx.lr = 0x82D7A68C;
	sub_82D0E6F0(ctx, base);
loc_82D7A68C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7A698"))) PPC_WEAK_FUNC(sub_82D7A698);
PPC_FUNC_IMPL(__imp__sub_82D7A698) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82D7A6A0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82d7a600
	ctx.lr = 0x82D7A6B8;
	sub_82D7A600(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d7a600
	ctx.lr = 0x82D7A6CC;
	sub_82D7A600(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7A6D8"))) PPC_WEAK_FUNC(sub_82D7A6D8);
PPC_FUNC_IMPL(__imp__sub_82D7A6D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,100(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 100);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r8,92(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 92);
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// lwz r10,84(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 84);
	// lwz r9,96(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 96);
	// lwz r7,76(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 76);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mullw r11,r10,r8
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
	// lwz r6,72(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 72);
	// lwz r30,64(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 64);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// add r3,r11,r31
	ctx.r3.u64 = ctx.r11.u64 + ctx.r31.u64;
	// mtctr r30
	ctx.ctr.u64 = ctx.r30.u64;
	// bctrl 
	ctx.lr = 0x82D7A72C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D7A748"))) PPC_WEAK_FUNC(sub_82D7A748);
PPC_FUNC_IMPL(__imp__sub_82D7A748) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r4,r11,100
	ctx.r4.s64 = ctx.r11.s64 + 100;
	// lwz r8,80(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	// lwz r7,68(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r11,104(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// mullw r6,r7,r8
	ctx.r6.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r8.s32);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// b 0x82d20798
	sub_82D20798(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7A770"))) PPC_WEAK_FUNC(sub_82D7A770);
PPC_FUNC_IMPL(__imp__sub_82D7A770) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D7A778"))) PPC_WEAK_FUNC(sub_82D7A778);
PPC_FUNC_IMPL(__imp__sub_82D7A778) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D7A780;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,104(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// lwz r29,88(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r28,4(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82d20388
	ctx.lr = 0x82D7A7A8;
	sub_82D20388(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// lwz r5,68(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r4,r11,22436
	ctx.r4.s64 = ctx.r11.s64 + 22436;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7A7D0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7A7D8"))) PPC_WEAK_FUNC(sub_82D7A7D8);
PPC_FUNC_IMPL(__imp__sub_82D7A7D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,24(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpw cr6,r4,r10
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82d7a858
	if (!ctx.cr6.eq) goto loc_82D7A858;
	// cmpw cr6,r4,r9
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82d7a858
	if (!ctx.cr6.eq) goto loc_82D7A858;
	// lwz r10,196(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// cmpw cr6,r5,r10
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82d7a858
	if (!ctx.cr6.eq) goto loc_82D7A858;
	// cmpw cr6,r11,r6
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r6.s32, ctx.xer);
	// bne cr6,0x82d7a858
	if (!ctx.cr6.eq) goto loc_82D7A858;
	// lwz r6,12(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r10,236(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// lwz r9,204(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// lwz r4,220(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// lwz r10,212(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// lwz r5,228(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7A84C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne 0x82d7a85c
	if (!ctx.cr0.eq) goto loc_82D7A85C;
loc_82D7A858:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82D7A85C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D7A870"))) PPC_WEAK_FUNC(sub_82D7A870);
PPC_FUNC_IMPL(__imp__sub_82D7A870) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82D7A878;
	__savegprlr_19(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,364(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r20,332(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// lwz r28,340(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// mr r24,r7
	ctx.r24.u64 = ctx.r7.u64;
	// add r19,r20,r28
	ctx.r19.u64 = ctx.r20.u64 + ctx.r28.u64;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r11.u32);
	// mr r23,r8
	ctx.r23.u64 = ctx.r8.u64;
	// lwz r11,356(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// mr r22,r9
	ctx.r22.u64 = ctx.r9.u64;
	// lwz r27,24(r30)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// mr r21,r10
	ctx.r21.u64 = ctx.r10.u64;
	// stw r20,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r20.u32);
	// stw r19,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r19.u32);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// lwz r11,348(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,324(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82d7a7d8
	ctx.lr = 0x82D7A8D4;
	sub_82D7A7D8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d7a968
	if (ctx.cr0.eq) goto loc_82D7A968;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r5,r11,-22824
	ctx.r5.s64 = ctx.r11.s64 + -22824;
	// addi r4,r10,3740
	ctx.r4.s64 = ctx.r10.s64 + 3740;
	// li r3,112
	ctx.r3.s64 = 112;
	// bl 0x82d5fac8
	ctx.lr = 0x82D7A8F4;
	sub_82D5FAC8(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r29,r31,8
	ctx.r29.s64 = ctx.r31.s64 + 8;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r25,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r25.u32);
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// stw r21,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r21.u32);
	// stw r10,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r10.u32);
	// stw r26,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r26.u32);
	// stw r24,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r24.u32);
	// stw r23,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r23.u32);
	// stw r22,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r22.u32);
	// stw r20,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r20.u32);
	// stw r19,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r19.u32);
	// stw r30,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r30.u32);
	// bl 0x82d0c680
	ctx.lr = 0x82D7A938;
	sub_82D0C680(ctx, base);
	// lwz r10,12(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// rotlwi r11,r28,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r28.u32, 1);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r4,r27,16
	ctx.r4.s64 = ctx.r27.s64 + 16;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// andc r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// divw r3,r28,r10
	ctx.r3.s32 = ctx.r28.s32 / ctx.r10.s32;
	// twllei r10,0
	// twlgei r11,-1
	// bl 0x82d0c7e0
	ctx.lr = 0x82D7A964;
	sub_82D0C7E0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82D7A968:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7A970"))) PPC_WEAK_FUNC(sub_82D7A970);
PPC_FUNC_IMPL(__imp__sub_82D7A970) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D7A978;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-22416
	ctx.r6.s64 = ctx.r11.s64 + -22416;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r3,32
	ctx.r3.s64 = 32;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82d5fa88
	ctx.lr = 0x82D7A9A8;
	sub_82D5FA88(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, ctx.r29.u32);
	// stw r31,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r31.u32);
	// bl 0x82d0e6f0
	ctx.lr = 0x82D7A9BC;
	sub_82D0E6F0(ctx, base);
	// lis r11,-31966
	ctx.r11.s64 = -2094923776;
	// lwz r10,-25296(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -25296);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82d7aa04
	if (ctx.cr6.eq) goto loc_82D7AA04;
	// lis r10,-32040
	ctx.r10.s64 = -2099773440;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,-25296(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -25296);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r10,-22416
	ctx.r6.s64 = ctx.r10.s64 + -22416;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r3,32
	ctx.r3.s64 = 32;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7A9F0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, ctx.r29.u32);
	// stw r31,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r31.u32);
	// bl 0x82d0e6f0
	ctx.lr = 0x82D7AA04;
	sub_82D0E6F0(ctx, base);
loc_82D7AA04:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7AA10"))) PPC_WEAK_FUNC(sub_82D7AA10);
PPC_FUNC_IMPL(__imp__sub_82D7AA10) {
	PPC_FUNC_PROLOGUE();
	// addi r6,r6,2
	ctx.r6.s64 = ctx.r6.s64 + 2;
	// b 0x82d7a970
	sub_82D7A970(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7AA18"))) PPC_WEAK_FUNC(sub_82D7AA18);
PPC_FUNC_IMPL(__imp__sub_82D7AA18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D7AA20;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82d7aa94
	if (!ctx.cr6.gt) goto loc_82D7AA94;
loc_82D7AA40:
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// lwz r7,92(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r9,80(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r8,96(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r6,72(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mullw r11,r9,r7
	ctx.r11.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r7.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// add r4,r11,r28
	ctx.r4.u64 = ctx.r11.u64 + ctx.r28.u64;
	// add r3,r11,r29
	ctx.r3.u64 = ctx.r11.u64 + ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82D7AA74;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// lwz r10,84(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpw cr6,r30,r10
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r10.s32, ctx.xer);
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// add r28,r11,r28
	ctx.r28.u64 = ctx.r11.u64 + ctx.r28.u64;
	// blt cr6,0x82d7aa40
	if (ctx.cr6.lt) goto loc_82D7AA40;
loc_82D7AA94:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7AAA0"))) PPC_WEAK_FUNC(sub_82D7AAA0);
PPC_FUNC_IMPL(__imp__sub_82D7AAA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D7AAA8;
	__savegprlr_21(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r29,84(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r10,96(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmpwi r29,0
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// lwz r22,92(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addi r30,r10,-1
	ctx.r30.s64 = ctx.r10.s64 + -1;
	// lwz r26,80(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// ble 0x82d7ab58
	if (!ctx.cr0.gt) goto loc_82D7AB58;
	// mullw r10,r26,r22
	ctx.r10.s64 = int64_t(ctx.r26.s32) * int64_t(ctx.r22.s32);
	// mullw r9,r26,r30
	ctx.r9.s64 = int64_t(ctx.r26.s32) * int64_t(ctx.r30.s32);
	// rlwinm r25,r10,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r21,r30,2
	ctx.r21.s64 = ctx.r30.s64 + 2;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82D7AAF0:
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
	// lwz r6,72(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// add r4,r25,r27
	ctx.r4.u64 = ctx.r25.u64 + ctx.r27.u64;
	// add r3,r25,r28
	ctx.r3.u64 = ctx.r25.u64 + ctx.r28.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82D7AB1C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// lwz r6,72(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r8,r21
	ctx.r8.u64 = ctx.r21.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// add r4,r24,r27
	ctx.r4.u64 = ctx.r24.u64 + ctx.r27.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r3,r24,r28
	ctx.r3.u64 = ctx.r24.u64 + ctx.r28.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82D7AB48;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// add r28,r23,r28
	ctx.r28.u64 = ctx.r23.u64 + ctx.r28.u64;
	// add r27,r23,r27
	ctx.r27.u64 = ctx.r23.u64 + ctx.r27.u64;
	// bne 0x82d7aaf0
	if (!ctx.cr0.eq) goto loc_82D7AAF0;
loc_82D7AB58:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7AB60"))) PPC_WEAK_FUNC(sub_82D7AB60);
PPC_FUNC_IMPL(__imp__sub_82D7AB60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82D7AB68;
	__savegprlr_20(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r8
	ctx.r30.u64 = ctx.r8.u64;
	// mr r26,r7
	ctx.r26.u64 = ctx.r7.u64;
	// lwz r28,80(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// li r20,2
	ctx.r20.s64 = 2;
	// lwz r25,72(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// subf r24,r29,r26
	ctx.r24.s64 = ctx.r26.s64 - ctx.r29.s64;
	// mullw r11,r28,r29
	ctx.r11.s64 = int64_t(ctx.r28.s32) * int64_t(ctx.r29.s32);
	// lwz r23,104(r31)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// lwz r7,68(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// stw r20,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r20.u32);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r27,r30,4
	ctx.r27.s64 = ctx.r30.s64 + 4;
	// add r22,r11,r3
	ctx.r22.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r21,r11,r4
	ctx.r21.u64 = ctx.r11.u64 + ctx.r4.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r9,r23
	ctx.r9.u64 = ctx.r23.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x82d5f3b8
	ctx.lr = 0x82D7ABD4;
	sub_82D5F3B8(ctx, base);
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// lwz r6,104(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// li r9,2
	ctx.r9.s64 = 2;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82D7AC00;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// lwz r7,68(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r28.u32);
	// mr r8,r23
	ctx.r8.u64 = ctx.r23.u64;
	// stw r20,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r20.u32);
	// mr r6,r22
	ctx.r6.u64 = ctx.r22.u64;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82d5f448
	ctx.lr = 0x82D7AC2C;
	sub_82D5F448(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7AC38"))) PPC_WEAK_FUNC(sub_82D7AC38);
PPC_FUNC_IMPL(__imp__sub_82D7AC38) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D7AC48"))) PPC_WEAK_FUNC(sub_82D7AC48);
PPC_FUNC_IMPL(__imp__sub_82D7AC48) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D7AC50;
	__savegprlr_21(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r30,84(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// lwz r22,92(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r25,96(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r26,r10,2
	ctx.r26.s64 = ctx.r10.s64 + 2;
	// mullw r11,r26,r11
	ctx.r11.s64 = int64_t(ctx.r26.s32) * int64_t(ctx.r11.s32);
	// rlwinm r3,r11,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x82d0c438
	ctx.lr = 0x82D7AC88;
	sub_82D0C438(ctx, base);
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82d7ad0c
	if (!ctx.cr6.gt) goto loc_82D7AD0C;
	// add r21,r22,r26
	ctx.r21.u64 = ctx.r22.u64 + ctx.r26.u64;
	// mr r23,r30
	ctx.r23.u64 = ctx.r30.u64;
loc_82D7AC9C:
	// mr r29,r22
	ctx.r29.u64 = ctx.r22.u64;
	// cmpw cr6,r21,r25
	ctx.cr6.compare<int32_t>(ctx.r21.s32, ctx.r25.s32, ctx.xer);
	// bge cr6,0x82d7acd8
	if (!ctx.cr6.lt) goto loc_82D7ACD8;
	// mr r30,r21
	ctx.r30.u64 = ctx.r21.u64;
loc_82D7ACAC:
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d7ab60
	ctx.lr = 0x82D7ACC8;
	sub_82D7AB60(ctx, base);
	// add r30,r30,r26
	ctx.r30.u64 = ctx.r30.u64 + ctx.r26.u64;
	// add r29,r29,r26
	ctx.r29.u64 = ctx.r29.u64 + ctx.r26.u64;
	// cmpw cr6,r30,r25
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r25.s32, ctx.xer);
	// blt cr6,0x82d7acac
	if (ctx.cr6.lt) goto loc_82D7ACAC;
loc_82D7ACD8:
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d7ab60
	ctx.lr = 0x82D7ACF4;
	sub_82D7AB60(ctx, base);
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r11,r28
	ctx.r28.u64 = ctx.r11.u64 + ctx.r28.u64;
	// add r27,r11,r27
	ctx.r27.u64 = ctx.r11.u64 + ctx.r27.u64;
	// bne 0x82d7ac9c
	if (!ctx.cr0.eq) goto loc_82D7AC9C;
loc_82D7AD0C:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82d0c490
	ctx.lr = 0x82D7AD14;
	sub_82D0C490(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7AD20"))) PPC_WEAK_FUNC(sub_82D7AD20);
PPC_FUNC_IMPL(__imp__sub_82D7AD20) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r4,r11,108
	ctx.r4.s64 = ctx.r11.s64 + 108;
	// lwz r9,112(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	// lwz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// lwz r7,68(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r11,100(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	// mullw r6,r7,r10
	ctx.r6.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r10.s32);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// lwz r5,8(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// add r8,r11,r10
	ctx.r8.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82d20798
	sub_82D20798(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7AD50"))) PPC_WEAK_FUNC(sub_82D7AD50);
PPC_FUNC_IMPL(__imp__sub_82D7AD50) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82D7AD58"))) PPC_WEAK_FUNC(sub_82D7AD58);
PPC_FUNC_IMPL(__imp__sub_82D7AD58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82D7AD60;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// beq cr6,0x82d7adcc
	if (ctx.cr6.eq) goto loc_82D7ADCC;
	// lwz r28,4(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// lwz r27,84(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// rlwinm r29,r11,0,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x82d20388
	ctx.lr = 0x82D7AD9C;
	sub_82D20388(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// lwz r6,68(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// addi r4,r11,22468
	ctx.r4.s64 = ctx.r11.s64 + 22468;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r5,r29,2
	ctx.r5.s64 = ctx.r29.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7ADC8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82d7ae04
	goto loc_82D7AE04;
loc_82D7ADCC:
	// lwz r29,4(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r28,84(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// bl 0x82d20388
	ctx.lr = 0x82D7ADD8;
	sub_82D20388(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// lwz r5,68(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r11,r11,22468
	ctx.r11.s64 = ctx.r11.s64 + 22468;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r4,r11,36
	ctx.r4.s64 = ctx.r11.s64 + 36;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7AE04;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82D7AE04:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7AE10"))) PPC_WEAK_FUNC(sub_82D7AE10);
PPC_FUNC_IMPL(__imp__sub_82D7AE10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82D7AE18;
	__savegprlr_21(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,24(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d7af94
	if (!ctx.cr6.eq) goto loc_82D7AF94;
	// cmpw cr6,r5,r6
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r6.s32, ctx.xer);
	// bne cr6,0x82d7af94
	if (!ctx.cr6.eq) goto loc_82D7AF94;
	// lwz r11,276(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d7af94
	if (!ctx.cr6.eq) goto loc_82D7AF94;
	// lwz r21,324(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r26,316(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// lwz r27,292(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r22,284(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lwz r25,308(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// stw r11,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r11.u32);
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// lwz r24,300(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7AEA4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d7af48
	if (!ctx.cr0.eq) goto loc_82D7AF48;
	// li r11,1
	ctx.r11.s64 = 1;
	// cmpwi cr6,r22,0
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// stw r11,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r11.u32);
	// bne cr6,0x82d7af94
	if (!ctx.cr6.eq) goto loc_82D7AF94;
	// cmpw cr6,r27,r29
	ctx.cr6.compare<int32_t>(ctx.r27.s32, ctx.r29.s32, ctx.xer);
	// bne cr6,0x82d7af94
	if (!ctx.cr6.eq) goto loc_82D7AF94;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r23,r27,-1
	ctx.r23.s64 = ctx.r27.s64 + -1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7AF00;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d7af94
	if (ctx.cr0.eq) goto loc_82D7AF94;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r10,r27,1
	ctx.r10.s64 = ctx.r27.s64 + 1;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// mr r9,r23
	ctx.r9.u64 = ctx.r23.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7AF40;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d7af94
	if (ctx.cr0.eq) goto loc_82D7AF94;
loc_82D7AF48:
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// rlwinm r11,r30,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// subf r10,r10,r27
	ctx.r10.s64 = ctx.r27.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r29,0(r6)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// add r5,r11,r25
	ctx.r5.u64 = ctx.r11.u64 + ctx.r25.u64;
	// add r4,r11,r24
	ctx.r4.u64 = ctx.r11.u64 + ctx.r24.u64;
	// mtctr r29
	ctx.ctr.u64 = ctx.r29.u64;
	// bctrl 
	ctx.lr = 0x82D7AF88;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne 0x82d7af98
	if (!ctx.cr0.eq) goto loc_82D7AF98;
loc_82D7AF94:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82D7AF98:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7AFA0"))) PPC_WEAK_FUNC(sub_82D7AFA0);
PPC_FUNC_IMPL(__imp__sub_82D7AFA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82D7AFA8;
	__savegprlr_26(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,24(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d7b074
	if (!ctx.cr6.eq) goto loc_82D7B074;
	// cmpw cr6,r5,r6
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r6.s32, ctx.xer);
	// bne cr6,0x82d7b074
	if (!ctx.cr6.eq) goto loc_82D7B074;
	// lwz r11,244(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82d7b074
	if (!ctx.cr6.eq) goto loc_82D7B074;
	// addi r11,r4,3
	ctx.r11.s64 = ctx.r4.s64 + 3;
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r27,284(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// li r26,2
	ctx.r26.s64 = 2;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r30,252(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// rlwinm r29,r11,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// add r10,r11,r30
	ctx.r10.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7B028;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d7b074
	if (ctx.cr0.eq) goto loc_82D7B074;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// lwz r10,260(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82D7B068;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne 0x82d7b078
	if (!ctx.cr0.eq) goto loc_82D7B078;
loc_82D7B074:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82D7B078:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7B080"))) PPC_WEAK_FUNC(sub_82D7B080);
PPC_FUNC_IMPL(__imp__sub_82D7B080) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82D7B088;
	__savegprlr_28(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r28,300(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d7b0fc
	if (ctx.cr6.eq) goto loc_82D7B0FC;
	// lwz r4,276(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r7,292(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r28.u32);
	// stw r4,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r4.u32);
	// lwz r4,308(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// stw r7,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r7.u32);
	// lwz r7,284(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,268(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// stw r7,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r7.u32);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r11,260(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82d7afa0
	ctx.lr = 0x82D7B0EC;
	sub_82D7AFA0(ctx, base);
loc_82D7B0EC:
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d7b140
	if (!ctx.cr0.eq) goto loc_82D7B140;
loc_82D7B0F4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82d7b198
	goto loc_82D7B198;
loc_82D7B0FC:
	// lwz r11,308(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r28.u32);
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// lwz r11,292(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// lwz r11,284(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,276(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// lwz r11,268(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r11,260(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82d7ae10
	ctx.lr = 0x82D7B13C;
	sub_82D7AE10(ctx, base);
	// b 0x82d7b0ec
	goto loc_82D7B0EC;
loc_82D7B140:
	// lwz r11,152(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 152);
	// rlwinm. r11,r11,0,3,3
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82d7b174
	if (ctx.cr0.eq) goto loc_82D7B174;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mullw r4,r30,r29
	ctx.r4.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r29.s32);
	// subfic r11,r11,0
	ctx.xer.ca = ctx.r11.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,23,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1F0;
	// addi r3,r11,16
	ctx.r3.s64 = ctx.r11.s64 + 16;
	// bl 0x82d7bd90
	ctx.lr = 0x82D7B16C;
	sub_82D7BD90(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82d7b0f4
	if (!ctx.cr0.eq) goto loc_82D7B0F4;
loc_82D7B174:
	// mullw r11,r30,r29
	ctx.r11.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r29.s32);
	// lis r10,4
	ctx.r10.s64 = 262144;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82d7b194
	if (!ctx.cr6.gt) goto loc_82D7B194;
	// lwz r11,152(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 152);
	// li r3,0
	ctx.r3.s64 = 0;
	// rlwinm. r11,r11,0,8,8
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x800000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82d7b198
	if (!ctx.cr0.eq) goto loc_82D7B198;
loc_82D7B194:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82D7B198:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82D7B1A0"))) PPC_WEAK_FUNC(sub_82D7B1A0);
PPC_FUNC_IMPL(__imp__sub_82D7B1A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e40
	ctx.lr = 0x82D7B1A8;
	__savegprlr_18(ctx, base);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r5
	ctx.r24.u64 = ctx.r5.u64;
	// lwz r21,364(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// mr r23,r8
	ctx.r23.u64 = ctx.r8.u64;
	// lwz r5,356(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// mr r27,r9
	ctx.r27.u64 = ctx.r9.u64;
	// lwz r8,380(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// mr r22,r10
	ctx.r22.u64 = ctx.r10.u64;
	// lwz r9,388(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// lwz r10,396(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r26,372(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// add r20,r21,r26
	ctx.r20.u64 = ctx.r21.u64 + ctx.r26.u64;
	// stw r8,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r8.u32);
	// stw r9,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r9.u32);
	// mr r8,r23
	ctx.r8.u64 = ctx.r23.u64;
	// stw r10,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r10.u32);
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
	// lwz r25,24(r30)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// stw r21,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r21.u32);
	// mr r19,r7
	ctx.r19.u64 = ctx.r7.u64;
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// stw r20,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r20.u32);
	// bl 0x82d7b080
	ctx.lr = 0x82D7B21C;
	sub_82D7B080(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82d7b364
	if (ctx.cr0.eq) goto loc_82D7B364;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// lwz r18,144(r1)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d7b248
	if (ctx.cr6.eq) goto loc_82D7B248;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r5,r11,-21432
	ctx.r5.s64 = ctx.r11.s64 + -21432;
	// addi r4,r10,3756
	ctx.r4.s64 = ctx.r10.s64 + 3756;
	// b 0x82d7b26c
	goto loc_82D7B26C;
loc_82D7B248:
	// cmpwi cr6,r18,0
	ctx.cr6.compare<int32_t>(ctx.r18.s32, 0, ctx.xer);
	// beq cr6,0x82d7b25c
	if (ctx.cr6.eq) goto loc_82D7B25C;
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-21856
	ctx.r5.s64 = ctx.r11.s64 + -21856;
	// b 0x82d7b264
	goto loc_82D7B264;
loc_82D7B25C:
	// lis r11,-32040
	ctx.r11.s64 = -2099773440;
	// addi r5,r11,-21992
	ctx.r5.s64 = ctx.r11.s64 + -21992;
loc_82D7B264:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r4,r11,3756
	ctx.r4.s64 = ctx.r11.s64 + 3756;
loc_82D7B26C:
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82d5fac8
	ctx.lr = 0x82D7B274;
	sub_82D5FAC8(ctx, base);
	// addi r11,r28,3
	ctx.r11.s64 = ctx.r28.s64 + 3;
	// lwz r10,32(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r29,r31,8
	ctx.r29.s64 = ctx.r31.s64 + 8;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r10,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r10.u32);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r24,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r24.u32);
	// stw r28,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r28.u32);
	// stw r19,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r19.u32);
	// stw r23,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r23.u32);
	// stw r27,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r27.u32);
	// stw r10,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r10.u32);
	// stw r22,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r22.u32);
	// stw r21,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r21.u32);
	// stw r20,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r20.u32);
	// stw r30,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r30.u32);
	// stw r11,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r11.u32);
	// stw r18,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r18.u32);
	// bl 0x82d0c680
	ctx.lr = 0x82D7B2D0;
	sub_82D0C680(ctx, base);
	// lwz r10,12(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// rotlwi r11,r26,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r26.u32, 1);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r4,r25,16
	ctx.r4.s64 = ctx.r25.s64 + 16;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// divw r9,r26,r10
	ctx.r9.s32 = ctx.r26.s32 / ctx.r10.s32;
	// andc r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// mullw r3,r9,r27
	ctx.r3.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r27.s32);
	// twllei r10,0
	// twlgei r11,-1
	// bl 0x82d0c7e0
	ctx.lr = 0x82D7B300;
	sub_82D0C7E0(ctx, base);
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82d7b334
	if (ctx.cr6.eq) goto loc_82D7B334;
	// mullw r11,r28,r27
	ctx.r11.s64 = int64_t(ctx.r28.s32) * int64_t(ctx.r27.s32);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// mullw r11,r11,r26
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r26.s32);
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r11.u64);
	// lfd f13,144(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82D7B334:
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82d7b358
	if (!ctx.cr6.eq) goto loc_82D7B358;
	// addi r11,r28,-5
	ctx.r11.s64 = ctx.r28.s64 + -5;
	// cmplwi cr6,r11,58
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 58, ctx.xer);
	// bgt cr6,0x82d7b358
	if (ctx.cr6.gt) goto loc_82D7B358;
	// cmpw cr6,r19,r28
	ctx.cr6.compare<int32_t>(ctx.r19.s32, ctx.r28.s32, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bge cr6,0x82d7b35c
	if (!ctx.cr6.lt) goto loc_82D7B35C;
loc_82D7B358:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82D7B35C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r11.u32);
loc_82D7B364:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x82e28e90
	__restgprlr_18(ctx, base);
	return;
}

