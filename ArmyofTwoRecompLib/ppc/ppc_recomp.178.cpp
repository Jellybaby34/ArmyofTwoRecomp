#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82C90B60"))) PPC_WEAK_FUNC(sub_82C90B60);
PPC_FUNC_IMPL(__imp__sub_82C90B60) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-30112
	ctx.r5.s64 = ctx.r11.s64 + -30112;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,-1912
	ctx.r4.s64 = ctx.r11.s64 + -1912;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C90B78"))) PPC_WEAK_FUNC(sub_82C90B78);
PPC_FUNC_IMPL(__imp__sub_82C90B78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c498
	ctx.lr = 0x82C90B80;
	__savegprlr_16(ctx, base);
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82d5c540
	ctx.lr = 0x82C90B88;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c9120c
	if (!ctx.cr6.gt) goto loc_82C9120C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r27,-32235
	ctx.r27.s64 = -2112552960;
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// rlwinm r21,r11,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lfs f8,27788(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 27788);
	ctx.f8.f64 = double(temp.f32);
	// lis r31,-32236
	ctx.r31.s64 = -2112618496;
	// lfs f9,27792(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 27792);
	ctx.f9.f64 = double(temp.f32);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f10,27784(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 27784);
	ctx.f10.f64 = double(temp.f32);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lfs f11,27780(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 27780);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-29656(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -29656);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,27776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27776);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29652(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82C90BE0:
	// mulli r11,r7,60
	ctx.r11.s64 = ctx.r7.s64 * 60;
	// lfs f7,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r10,r7,28
	ctx.r10.s64 = ctx.r7.s64 * 28;
	// lfsx f6,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f23,f6,f4
	ctx.f23.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// lfsx f3,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f4,f5,f3
	ctx.f4.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f2,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// mulli r30,r7,44
	ctx.r30.s64 = ctx.r7.s64 * 44;
	// lfsx f31,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f21,f2,f31
	ctx.f21.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// lfsx f30,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// mulli r28,r7,40
	ctx.r28.s64 = ctx.r7.s64 * 40;
	// lfsx f29,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f28,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f18,f29,f28
	ctx.f18.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// mulli r27,r7,56
	ctx.r27.s64 = ctx.r7.s64 * 56;
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fmuls f17,f21,f12
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f16,f21,f13
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfsx f27,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// mulli r26,r7,24
	ctx.r26.s64 = ctx.r7.s64 * 24;
	// lfsx f26,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f28,f27,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// mulli r25,r7,36
	ctx.r25.s64 = ctx.r7.s64 * 36;
	// lfsx f25,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f26,f25,f24
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// mulli r31,r7,52
	ctx.r31.s64 = ctx.r7.s64 * 52;
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r7,20
	ctx.r10.s64 = ctx.r7.s64 * 20;
	// stfs f14,-336(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfsx f3,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f24,f3,f22
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// rlwinm r30,r7,5,0,26
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f3,f22,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// rlwinm r24,r7,4,0,27
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f22,f2,f6
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// mulli r23,r7,48
	ctx.r23.s64 = ctx.r7.s64 * 48;
	// fsubs f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// lfsx f31,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f20,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f2,f31,f7
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// lfsx f19,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// fadds f31,f19,f20
	ctx.f31.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f19,f28,f18
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// fsubs f18,f28,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// fadds f28,f27,f29
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fsubs f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// fmadds f20,f23,f13,f17
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmsubs f23,f23,f12,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 - ctx.f16.f64));
	// fmuls f16,f24,f12
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f17,f26,f12
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmuls f27,f19,f0
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmuls f19,f18,f0
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fadds f18,f3,f25
	ctx.f18.f64 = double(float(ctx.f3.f64 + ctx.f25.f64));
	// fsubs f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 - ctx.f3.f64));
	// fadds f25,f31,f2
	ctx.f25.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fmsubs f31,f26,f13,f16
	ctx.f31.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f16.f64));
	// lfsx f16,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f24,f13,f17
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f17.f64));
	// lfsx f24,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f17,f30,f1
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f14,-316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fadds f15,f28,f25
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// fsubs f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// lfsx f30,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-320(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfsx f30,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// stfs f30,-324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfsx f30,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r31,r8,6,0,25
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// stfs f30,-304(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// mulli r29,r9,48
	ctx.r29.s64 = ctx.r9.s64 * 48;
	// lfsx f30,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-332(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfsx f30,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-300(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfsx f30,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-328(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fadds f30,f17,f5
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f5.f64));
	// stfs f30,-308(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fadds f30,f16,f24
	ctx.f30.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// fsubs f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// lfsx f14,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f5,f5,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f17.f64));
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,-312(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f16,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r10,r9,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfsx f18,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f25,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// mulli r30,r8,48
	ctx.r30.s64 = ctx.r8.s64 * 48;
	// stfs f16,-296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fadds f16,f18,f25
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// stfs f16,-292(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// lfs f16,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,-288(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f18,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-336(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-304(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f18,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,-332(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,-300(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// lfs f14,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfsx f15,r11,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f15,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f24
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// lfs f17,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f15,f24
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// lfs f24,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f24.f64 = double(temp.f32);
	// fadds f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// fsubs f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// stfs f30,-324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f30,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f30.f64 = double(temp.f32);
	// fadds f24,f16,f30
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// stfs f24,-312(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fsubs f30,f30,f16
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// stfs f30,-320(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f30,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f30.f64 = double(temp.f32);
	// lfs f24,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f24.f64 = double(temp.f32);
	// fadds f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// stfs f30,-296(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f24,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f24.f64 = double(temp.f32);
	// lfs f30,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f16,f24,f30
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// fadds f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// stfs f30,-292(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmuls f24,f15,f0
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f24,-316(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fmuls f30,f14,f0
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f15,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f15.f64 = double(temp.f32);
	// stfs f14,-292(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,-308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f17,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,-296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f14,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// fsubs f14,f30,f1
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// fadds f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// lfs f30,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f4
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f30,-328(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f30,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// fsubs f30,f16,f18
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fadds f16,f15,f25
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfs f16,-312(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,-300(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f25,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f25,f16
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,-292(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfsx f17,r10,r6
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f16,-296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f25,-308(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f25,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f25,f17
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// stfsx f15,r31,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// stfs f25,0(r5)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f25,f28,f16
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// stfsx f25,r30,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f24,f12
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// mulli r31,r8,56
	ctx.r31.s64 = ctx.r8.s64 * 56;
	// lfs f25,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfsx f25,r29,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f25,f3,f6
	ctx.f25.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f3,f6,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// lfs f6,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f15,f6,f12
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// mulli r30,r9,56
	ctx.r30.s64 = ctx.r9.s64 * 56;
	// fmuls f6,f5,f12
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f6,-288(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmsubs f5,f5,f13,f16
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 - ctx.f16.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f25,-292(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f25,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f6,f25,f13,f17
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmsubs f25,f24,f13,f15
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f24,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f24,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f16,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f16.f64 = double(temp.f32);
	// lfs f24,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f30,f10
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fmadds f24,f24,f13,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f24,-288(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmuls f16,f14,f11
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f11.f64));
	// rlwinm r29,r8,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f14,f14,f10
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// rlwinm r28,r9,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// mulli r27,r9,24
	ctx.r27.s64 = ctx.r9.s64 * 24;
	// fadds f24,f31,f20
	ctx.f24.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// fmsubs f30,f30,f11,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64 - ctx.f17.f64));
	// lfs f17,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f17.f64 = double(temp.f32);
	// mulli r26,r8,24
	ctx.r26.s64 = ctx.r8.s64 * 24;
	// fmadds f17,f17,f10,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f16.f64));
	// lfs f16,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f16.f64 = double(temp.f32);
	// fadds f28,f16,f28
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f28.f64));
	// stfsx f28,r11,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f28,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// stfsx f28,r10,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f28,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f11,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 + ctx.f15.f64));
	// lfs f15,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f22,f22,f11,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f14.f64));
	// fadds f14,f3,f29
	ctx.f14.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// mulli r25,r9,40
	ctx.r25.s64 = ctx.r9.s64 * 40;
	// fadds f16,f15,f2
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fsubs f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fsubs f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f15.f64));
	// fadds f15,f5,f6
	ctx.f15.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f6.f64));
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// mulli r10,r9,60
	ctx.r10.s64 = ctx.r9.s64 * 60;
	// lfs f29,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f29.f64 = double(temp.f32);
	// fadds f5,f29,f25
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f25.f64));
	// fsubs f29,f29,f25
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fadds f25,f27,f7
	ctx.f25.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// stfs f25,-288(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f25,-292(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f25,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fadds f24,f17,f30
	ctx.f24.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// fsubs f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// fadds f17,f22,f28
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f17,-288(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfsx f17,r31,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f16,f6,f3
	ctx.f16.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fsubs f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// fsubs f3,f5,f14
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f14.f64));
	// stfsx f3,r30,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f17,r29,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f14.f64));
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f29,f2
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// stfsx f16,r27,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f3,f2,f29
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// stfsx f5,r26,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fmuls f29,f1,f8
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// stfsx f6,r25,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fmuls f16,f1,f9
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// lfs f6,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f5,f19,f21
	ctx.f5.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// fmuls f2,f6,f9
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// stfsx f3,r11,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fmuls f17,f6,f8
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// mulli r11,r8,60
	ctx.r11.s64 = ctx.r8.s64 * 60;
	// fsubs f6,f23,f26
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fadds f3,f26,f23
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// rlwinm r30,r9,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f2,f18,f8,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f2.f64));
	// lfs f26,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// lfs f23,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f1,f4,f9,f29
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 - ctx.f29.f64));
	// fsubs f22,f26,f23
	ctx.f22.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f22,f30,f25
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// mulli r29,r9,28
	ctx.r29.s64 = ctx.r9.s64 * 28;
	// fmsubs f29,f18,f9,f17
	ctx.f29.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 - ctx.f17.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fsubs f31,f20,f31
	ctx.f31.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// fadds f27,f19,f21
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fmadds f4,f4,f8,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f16.f64));
	// fsubs f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fadds f30,f5,f6
	ctx.f30.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f5,f3,f7
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// fsubs f7,f7,f3
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fadds f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// fadds f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fadds f1,f27,f31
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fadds f26,f4,f29
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fsubs f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f29.f64));
	// mulli r28,r9,36
	ctx.r28.s64 = ctx.r9.s64 * 36;
	// fsubs f29,f24,f30
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// stfsx f29,r10,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfsx f23,r31,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// stfsx f30,r30,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f31,f31,f27
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fadds f30,f6,f28
	ctx.f30.f64 = double(float(ctx.f6.f64 + ctx.f28.f64));
	// stfsx f30,r29,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f28,f6
	ctx.f6.f64 = double(float(ctx.f28.f64 - ctx.f6.f64));
	// stfsx f6,r28,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f3,f5
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f30,f5,f3
	ctx.f30.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// mulli r27,r8,36
	ctx.r27.s64 = ctx.r8.s64 * 36;
	// fsubs f5,f26,f1
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f1.f64));
	// stfsx f25,r27,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// mulli r26,r8,52
	ctx.r26.s64 = ctx.r8.s64 * 52;
	// stfsx f30,r26,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// mulli r25,r9,52
	ctx.r25.s64 = ctx.r9.s64 * 52;
	// stfsx f5,r25,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// mulli r24,r8,12
	ctx.r24.s64 = ctx.r8.s64 * 12;
	// stfsx f6,r24,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f1,f26
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// mulli r23,r9,12
	ctx.r23.s64 = ctx.r9.s64 * 12;
	// stfsx f6,r23,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f31,f2
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// mulli r19,r9,20
	ctx.r19.s64 = ctx.r9.s64 * 20;
	// stfsx f6,r19,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f4,f7
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fsubs f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// mulli r18,r8,20
	ctx.r18.s64 = ctx.r8.s64 * 20;
	// stfsx f6,r18,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f2,f31
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// mulli r17,r9,44
	ctx.r17.s64 = ctx.r9.s64 * 44;
	// stfsx f6,r17,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r6.u32, temp.u32);
	// mulli r16,r8,44
	ctx.r16.s64 = ctx.r8.s64 * 44;
	// stfsx f7,r16,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + -26212);
	// add r3,r22,r3
	ctx.r3.u64 = ctx.r22.u64 + ctx.r3.u64;
	// add r4,r22,r4
	ctx.r4.u64 = ctx.r22.u64 + ctx.r4.u64;
	// add r5,r21,r5
	ctx.r5.u64 = ctx.r21.u64 + ctx.r5.u64;
	// add r6,r21,r6
	ctx.r6.u64 = ctx.r21.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c90be0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C90BE0;
loc_82C9120C:
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x82d5c58c
	ctx.lr = 0x82C91214;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e8
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C91218"))) PPC_WEAK_FUNC(sub_82C91218);
PPC_FUNC_IMPL(__imp__sub_82C91218) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-30064
	ctx.r5.s64 = ctx.r11.s64 + -30064;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,2936
	ctx.r4.s64 = ctx.r11.s64 + 2936;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C91230"))) PPC_WEAK_FUNC(sub_82C91230);
PPC_FUNC_IMPL(__imp__sub_82C91230) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a8
	ctx.lr = 0x82C91238;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82d5c558
	ctx.lr = 0x82C91240;
	__savefpr_20(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c9147c
	if (!ctx.cr6.gt) goto loc_82C9147C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f12,27776(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 27776);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-29656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29656);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29652(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82C91278:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r31,r7,24
	ctx.r31.s64 = ctx.r7.s64 * 24;
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f26,f11,f9
	ctx.f26.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// lfsx f7,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f9,f8,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfsx f6,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f5,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// mulli r29,r7,20
	ctx.r29.s64 = ctx.r7.s64 * 20;
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fadds f25,f6,f10
	ctx.f25.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fadds f7,f4,f5
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// lfsx f3,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f2,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f26,f13
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfsx f1,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f6,f3,f2
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// mulli r28,r7,28
	ctx.r28.s64 = ctx.r7.s64 * 28;
	// lfsx f31,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f3,f1,f31
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmuls f23,f9,f13
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfsx f30,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f29,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r27,r7,12
	ctx.r27.s64 = ctx.r7.s64 * 12;
	// fmadds f9,f9,f12,f24
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 + ctx.f24.f64));
	// fmuls f24,f3,f12
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fmuls f22,f3,f13
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfsx f28,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f1,f30,f28
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfsx f27,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// rlwinm r23,r8,4,0,27
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f28,f8,f11
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// rlwinm r22,r9,4,0,27
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f31,f29,f27
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// rlwinm r21,r9,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// mulli r20,r9,28
	ctx.r20.s64 = ctx.r9.s64 * 28;
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fmsubs f8,f26,f12,f23
	ctx.f8.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 - ctx.f23.f64));
	// fadds f27,f7,f25
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// fsubs f26,f1,f6
	ctx.f26.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// fadds f23,f1,f6
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fadds f6,f30,f4
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fadds f3,f2,f29
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f29.f64));
	// fsubs f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f2.f64));
	// fmsubs f29,f31,f13,f24
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f13.f64 - ctx.f24.f64));
	// fmadds f31,f31,f12,f22
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 + ctx.f22.f64));
	// fmuls f1,f26,f0
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f26,f23,f0
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fsubs f24,f27,f6
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// stfsx f24,r23,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f3,f28
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// stfsx f24,r22,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fsubs f23,f29,f9
	ctx.f23.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// fadds f21,f8,f31
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f31.f64));
	// fsubs f8,f31,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f8.f64));
	// fsubs f24,f1,f5
	ctx.f24.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fadds f22,f26,f10
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f10.f64));
	// fadds f20,f23,f24
	ctx.f20.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfsx f20,r21,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// stfsx f24,r20,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// fadds f24,f11,f2
	ctx.f24.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fsubs f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f11.f64));
	// fsubs f11,f10,f26
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f26.f64));
	// fadds f10,f9,f29
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// fadds f9,f1,f5
	ctx.f9.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f5,f30,f4
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// mulli r31,r8,20
	ctx.r31.s64 = ctx.r8.s64 * 20;
	// fadds f4,f28,f3
	ctx.f4.f64 = double(float(ctx.f28.f64 + ctx.f3.f64));
	// mulli r30,r9,20
	ctx.r30.s64 = ctx.r9.s64 * 20;
	// fsubs f1,f22,f21
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfsx f1,r11,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 - ctx.f7.f64));
	// fmuls f3,f24,f0
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fadds f1,f21,f22
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f1,r10,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fsubs f1,f11,f10
	ctx.f1.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// stfsx f1,r31,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fadds f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f10,f7,f3
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// stfsx f11,r11,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f8,f9
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// mulli r10,r9,12
	ctx.r10.s64 = ctx.r9.s64 * 12;
	// stfsx f11,r10,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f11,f8,f9
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// stfsx f11,r30,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f11,f6,f4
	ctx.f11.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// mulli r29,r8,24
	ctx.r29.s64 = ctx.r8.s64 * 24;
	// stfsx f10,r29,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f3,f7
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r27,r9,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r23,r9,24
	ctx.r23.s64 = ctx.r9.s64 * 24;
	// stfsx f10,r28,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f2,f5
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// stfsx f10,r27,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f2,f5
	ctx.f10.f64 = double(float(ctx.f2.f64 - ctx.f5.f64));
	// stfsx f10,r23,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// stfsx f11,r11,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f4,f6
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfs f11,0(r5)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,-26212(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + -26212);
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c91278
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C91278;
loc_82C9147C:
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82d5c5a4
	ctx.lr = 0x82C91484;
	__restfpr_20(ctx, base);
	// b 0x82d5c4f8
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C91488"))) PPC_WEAK_FUNC(sub_82C91488);
PPC_FUNC_IMPL(__imp__sub_82C91488) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-30016
	ctx.r5.s64 = ctx.r11.s64 + -30016;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,4656
	ctx.r4.s64 = ctx.r11.s64 + 4656;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C914A0"))) PPC_WEAK_FUNC(sub_82C914A0);
PPC_FUNC_IMPL(__imp__sub_82C914A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a4
	ctx.lr = 0x82C914A8;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82d5c540
	ctx.lr = 0x82C914B0;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c9173c
	if (!ctx.cr6.gt) goto loc_82C9173C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r23,-32235
	ctx.r23.s64 = -2112552960;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r24,-32235
	ctx.r24.s64 = -2112552960;
	// lfs f15,-29908(r21)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -29908);
	ctx.f15.f64 = double(temp.f32);
	// lis r28,-32255
	ctx.r28.s64 = -2113863680;
	// lfs f16,-29912(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -29912);
	ctx.f16.f64 = double(temp.f32);
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f12,28204(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 28204);
	ctx.f12.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f13,28208(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 28208);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f17,-12748(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -12748);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,28200(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 28200);
	ctx.f18.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f19,-29916(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -29916);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,-29920(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -29920);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,28136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f21.f64 = double(temp.f32);
	// lfs f0,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f0.f64 = double(temp.f32);
loc_82C91520:
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// lfs f11,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f8,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f27,f8,f11
	ctx.f27.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// lfsx f7,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// mulli r24,r7,28
	ctx.r24.s64 = ctx.r7.s64 * 28;
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f9,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f8,f6,f9
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// lfsx f1,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f5,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfsx f2,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r29,r7,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// mulli r28,r7,24
	ctx.r28.s64 = ctx.r7.s64 * 24;
	// fadds f4,f1,f7
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fsubs f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// lfsx f3,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f26,f9,f11
	ctx.f26.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fadds f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// lfsx f30,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f31,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f1,f30,f31
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// lfsx f29,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f31,f31,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// lfsx f28,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f9,f8,f29
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f29.f64));
	// mulli r24,r9,20
	ctx.r24.s64 = ctx.r9.s64 * 20;
	// fnmsubs f8,f8,f0,f29
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f29.f64)));
	// fadds f30,f27,f2
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// fadds f25,f4,f10
	ctx.f25.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fnmsubs f2,f27,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fadds f27,f6,f28
	ctx.f27.f64 = double(float(ctx.f6.f64 + ctx.f28.f64));
	// fnmsubs f10,f4,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fnmsubs f6,f6,f0,f28
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f28.f64)));
	// mulli r23,r8,20
	ctx.r23.s64 = ctx.r8.s64 * 20;
	// fnmsubs f4,f1,f0,f3
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// fadds f29,f5,f31
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f31.f64));
	// fsubs f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 - ctx.f5.f64));
	// fadds f31,f1,f3
	ctx.f31.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fadds f3,f9,f30
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// fsubs f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// fadds f1,f8,f2
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fsubs f8,f2,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r10,r8,28
	ctx.r10.s64 = ctx.r8.s64 * 28;
	// fadds f24,f6,f4
	ctx.f24.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// fsubs f28,f26,f29
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fmuls f23,f5,f19
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmuls f22,f5,f20
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fadds f5,f27,f31
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fsubs f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fmuls f4,f7,f21
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f2,f29,f26
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r29,r9,12
	ctx.r29.s64 = ctx.r9.s64 * 12;
	// fsubs f14,f28,f7
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f7.f64));
	// fmadds f23,f11,f20,f23
	ctx.f23.f64 = double(float(ctx.f11.f64 * ctx.f20.f64 + ctx.f23.f64));
	// fmsubs f11,f11,f19,f22
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64 - ctx.f22.f64));
	// fadds f22,f24,f1
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// fsubs f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// fsubs f7,f31,f27
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fsubs f31,f5,f3
	ctx.f31.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fmuls f24,f14,f21
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f21.f64));
	// stfsx f24,r24,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fadds f24,f5,f3
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fadds f14,f22,f10
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f10.f64));
	// stfsx f14,r23,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fmuls f1,f1,f18
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// fnmsubs f10,f22,f17,f10
	ctx.f10.f64 = double(float(-(ctx.f22.f64 * ctx.f17.f64 - ctx.f10.f64)));
	// fsubs f5,f10,f1
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f1.f64));
	// fadds f10,f10,f1
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f1.f64));
	// fmuls f3,f2,f15
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// mulli r28,r9,24
	ctx.r28.s64 = ctx.r9.s64 * 24;
	// fmuls f2,f31,f18
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f18.f64));
	// mulli r24,r8,12
	ctx.r24.s64 = ctx.r8.s64 * 12;
	// fmuls f31,f8,f12
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmadds f4,f28,f16,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 + ctx.f4.f64));
	// fmuls f30,f6,f12
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fmuls f28,f7,f12
	ctx.f28.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f27,f7,f13
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fnmsubs f1,f24,f17,f25
	ctx.f1.f64 = double(float(-(ctx.f24.f64 * ctx.f17.f64 - ctx.f25.f64)));
	// fadds f29,f24,f25
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fmadds f7,f6,f13,f31
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f31.f64));
	// fadds f6,f5,f11
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// stfsx f6,r11,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// stfsx f11,r10,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f10,f23
	ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f23.f64));
	// stfsx f5,r31,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f3,f4
	ctx.f11.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// mulli r23,r8,24
	ctx.r23.s64 = ctx.r8.s64 * 24;
	// fsubs f10,f10,f23
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f23.f64));
	// stfsx f10,r30,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fmsubs f8,f8,f13,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 - ctx.f30.f64));
	// fsubs f6,f3,f4
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// fmadds f10,f9,f13,f28
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f28.f64));
	// stfsx f10,r29,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f10,f9,f12,f27
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f27.f64));
	// stfsx f10,r28,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f1,f2
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfsx f10,r24,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r22,r9,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f29,0(r5)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// mulli r21,r9,28
	ctx.r21.s64 = ctx.r9.s64 * 28;
	// fadds f10,f1,f2
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfsx f10,r23,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f11,f7
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f10,r22,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f8,f6
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfsx f10,r21,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r20,r9,4,0,27
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r19,r9,3,0,28
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// stfsx f11,r20,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// fadds f11,f8,f6
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfsx f11,r19,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,-26212(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + -26212);
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c91520
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C91520;
loc_82C9173C:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82d5c58c
	ctx.lr = 0x82C91744;
	__restfpr_14(ctx, base);
	// b 0x82d5c4f4
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C91748"))) PPC_WEAK_FUNC(sub_82C91748);
PPC_FUNC_IMPL(__imp__sub_82C91748) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29968
	ctx.r5.s64 = ctx.r11.s64 + -29968;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,5280
	ctx.r4.s64 = ctx.r11.s64 + 5280;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C91760"))) PPC_WEAK_FUNC(sub_82C91760);
PPC_FUNC_IMPL(__imp__sub_82C91760) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a8
	ctx.lr = 0x82C91768;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82d5c554
	ctx.lr = 0x82C91770;
	__savefpr_19(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c919c8
	if (!ctx.cr6.gt) goto loc_82C919C8;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// rlwinm r26,r11,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lfs f9,30852(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 30852);
	ctx.f9.f64 = double(temp.f32);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f10,30848(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 30848);
	ctx.f10.f64 = double(temp.f32);
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f11,30844(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 30844);
	ctx.f11.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lfs f12,30832(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 30832);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,30840(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 30840);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,30836(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 30836);
	ctx.f0.f64 = double(temp.f32);
loc_82C917C0:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f6,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// mulli r10,r7,20
	ctx.r10.s64 = ctx.r7.s64 * 20;
	// lfs f7,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f25,f8,f5
	ctx.f25.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// mulli r31,r7,24
	ctx.r31.s64 = ctx.r7.s64 * 24;
	// fadds f24,f5,f8
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// lfsx f3,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f5,f2,f4
	ctx.f5.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f23,f4,f2
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// rlwinm r29,r7,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r28,r7,12
	ctx.r28.s64 = ctx.r7.s64 * 12;
	// lfsx f31,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f28,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f4,f31,f30
	ctx.f4.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// lfsx f27,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f21,f28,f1
	ctx.f21.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fsubs f20,f27,f6
	ctx.f20.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// lfsx f29,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f22,f3,f29
	ctx.f22.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// lfsx f26,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f19,f29,f3
	ctx.f19.f64 = double(float(ctx.f29.f64 + ctx.f3.f64));
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f28,f1,f28
	ctx.f28.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// mulli r23,r9,20
	ctx.r23.s64 = ctx.r9.s64 * 20;
	// fsubs f8,f7,f26
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// fadds f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// fadds f26,f30,f31
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fadds f27,f6,f27
	ctx.f27.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f3,f5,f4
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f1,f20,f21
	ctx.f1.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// mulli r22,r9,12
	ctx.r22.s64 = ctx.r9.s64 * 12;
	// fsubs f2,f22,f25
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fadds f4,f20,f21
	ctx.f4.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f6,f22,f25
	ctx.f6.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fmuls f31,f3,f13
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// mulli r21,r8,12
	ctx.r21.s64 = ctx.r8.s64 * 12;
	// fmuls f25,f5,f10
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fmuls f30,f1,f13
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f29,f1,f0
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fadds f22,f4,f5
	ctx.f22.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fmadds f21,f6,f9,f8
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f8.f64));
	// mulli r20,r8,28
	ctx.r20.s64 = ctx.r8.s64 * 28;
	// fmadds f31,f2,f0,f31
	ctx.f31.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f31.f64));
	// fnmadds f25,f4,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f25.f64)));
	// fmadds f30,f2,f12,f30
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 + ctx.f30.f64));
	// fmadds f29,f3,f12,f29
	ctx.f29.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f29.f64));
	// fadds f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f6.f64));
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fmadds f1,f1,f12,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f31.f64));
	// stfsx f1,r24,r6
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fadds f1,f27,f28
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fnmsubs f3,f3,f0,f30
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f30.f64)));
	// stfsx f3,r23,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f3,f2,f13,f29
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// stfsx f3,r22,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f28,f27
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fmuls f28,f4,f10
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// rlwinm r31,r9,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f3,f25,f21
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// stfsx f3,r21,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f22,f8
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f8.f64));
	// stfsx f3,r20,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// fmuls f27,f6,f10
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// mulli r30,r9,24
	ctx.r30.s64 = ctx.r9.s64 * 24;
	// fsubs f31,f23,f26
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fsubs f30,f24,f19
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f19.f64));
	// fadds f3,f26,f23
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// fadds f2,f19,f24
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f24.f64));
	// fnmadds f6,f6,f11,f28
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 + ctx.f28.f64)));
	// rlwinm r29,r9,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r28,r8,24
	ctx.r28.s64 = ctx.r8.s64 * 24;
	// fmadds f28,f5,f9,f8
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f8.f64));
	// rlwinm r24,r8,3,0,28
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f8,f4,f9,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f8.f64));
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fnmadds f5,f5,f11,f27
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 + ctx.f27.f64)));
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fmuls f4,f1,f10
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmadds f27,f1,f9,f7
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fmuls f26,f3,f10
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fadds f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f28.f64));
	// stfsx f6,r11,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fmuls f6,f30,f0
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// stfsx f8,r10,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f8,f31,f0
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f5,f30,f13
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f28,f2,f10
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fnmadds f4,f2,f11,f4
	ctx.f4.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 + ctx.f4.f64)));
	// fmadds f6,f29,f12,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fmadds f8,f30,f12,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f8.f64));
	// fmsubs f5,f29,f0,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fmadds f30,f3,f9,f7
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fnmadds f28,f3,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f28.f64)));
	// fmadds f8,f29,f13,f8
	ctx.f8.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f8.f64));
	// stfsx f8,r31,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f8,f31,f13,f6
	ctx.f8.f64 = double(float(-(ctx.f31.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// stfsx f8,r30,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f8,f31,f12,f5
	ctx.f8.f64 = double(float(-(ctx.f31.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// stfsx f8,r29,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f8,f4,f30
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// stfsx f8,r28,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f28,f27
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfsx f8,r24,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fnmadds f8,f1,f11,f26
	ctx.f8.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 + ctx.f26.f64)));
	// add r6,r26,r6
	ctx.r6.u64 = ctx.r26.u64 + ctx.r6.u64;
	// fmadds f6,f2,f9,f7
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fadds f5,f1,f2
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfsx f8,r11,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f5,f3
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fadds f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,-26212(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + -26212);
	// add r5,r26,r5
	ctx.r5.u64 = ctx.r26.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c917c0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C917C0;
loc_82C919C8:
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82d5c5a0
	ctx.lr = 0x82C919D0;
	__restfpr_19(ctx, base);
	// b 0x82d5c4f8
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C919D8"))) PPC_WEAK_FUNC(sub_82C919D8);
PPC_FUNC_IMPL(__imp__sub_82C919D8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29904
	ctx.r5.s64 = ctx.r11.s64 + -29904;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,5984
	ctx.r4.s64 = ctx.r11.s64 + 5984;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C919F0"))) PPC_WEAK_FUNC(sub_82C919F0);
PPC_FUNC_IMPL(__imp__sub_82C919F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82C919F8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82C91A00;
	__savefpr_14(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c91d48
	if (!ctx.cr6.gt) goto loc_82C91D48;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r19,-32235
	ctx.r19.s64 = -2112552960;
	// lis r18,-32234
	ctx.r18.s64 = -2112487424;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r17,-32235
	ctx.r17.s64 = -2112552960;
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// lfs f12,31524(r19)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 31524);
	ctx.f12.f64 = double(temp.f32);
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// stfs f12,-320(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lis r27,-32235
	ctx.r27.s64 = -2112552960;
	// stw r11,-332(r1)
	PPC_STORE_U32(ctx.r1.u32 + -332, ctx.r11.u32);
	// lfs f12,-29776(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -29776);
	ctx.f12.f64 = double(temp.f32);
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stfs f12,-308(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f12,31528(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 31528);
	ctx.f12.f64 = double(temp.f32);
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f12,-312(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lfs f12,-29780(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -29780);
	ctx.f12.f64 = double(temp.f32);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// stfs f12,-324(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f12,-29784(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -29784);
	ctx.f12.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// stfs f12,-328(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// stw r11,-336(r1)
	PPC_STORE_U32(ctx.r1.u32 + -336, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r24,-32230
	ctx.r24.s64 = -2112225280;
	// lfs f23,31480(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 31480);
	ctx.f23.f64 = double(temp.f32);
	// lis r25,-32235
	ctx.r25.s64 = -2112552960;
	// lfs f22,31476(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 31476);
	ctx.f22.f64 = double(temp.f32);
	// lis r26,-32235
	ctx.r26.s64 = -2112552960;
	// lfs f18,-29796(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -29796);
	ctx.f18.f64 = double(temp.f32);
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// lfs f19,-29800(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -29800);
	ctx.f19.f64 = double(temp.f32);
	// lfs f0,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f13,21356(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 21356);
	ctx.f13.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f20,29472(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 29472);
	ctx.f20.f64 = double(temp.f32);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f21,31472(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 31472);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,31484(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 31484);
	ctx.f24.f64 = double(temp.f32);
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// lfs f12,-29912(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29912);
	ctx.f12.f64 = double(temp.f32);
	// lfs f25,-29804(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -29804);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,-29808(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -29808);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,28136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,-29792(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -29792);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-29788(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -29788);
	ctx.f16.f64 = double(temp.f32);
	// stfs f12,-316(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lwz r28,-332(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	// lwz r27,-336(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + -336);
loc_82C91AE8:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r30,r7,20
	ctx.r30.s64 = ctx.r7.s64 * 20;
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f30,f9,f7
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fadds f29,f8,f6
	ctx.f29.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// lfsx f3,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// mulli r29,r7,12
	ctx.r29.s64 = ctx.r7.s64 * 12;
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f5,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fsubs f7,f3,f2
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fadds f6,f2,f3
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfsx f1,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f3,f5,f1
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fsubs f2,f31,f4
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f4.f64));
	// mulli r26,r7,24
	ctx.r26.s64 = ctx.r7.s64 * 24;
	// fadds f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f1,f30,f12
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f12.f64));
	// fsubs f28,f9,f8
	ctx.f28.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// lfsx f10,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f12,f30,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fadds f31,f29,f10
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f10.f64));
	// fnmsubs f10,f29,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f29.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// fadds f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fadds f30,f4,f5
	ctx.f30.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f29,f5,f4
	ctx.f29.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fsubs f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fmuls f5,f28,f27
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f27.f64));
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// rlwinm r31,r9,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// mulli r30,r9,12
	ctx.r30.s64 = ctx.r9.s64 * 12;
	// fadds f31,f8,f7
	ctx.f31.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fnmsubs f8,f8,f0,f7
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fadds f28,f30,f6
	ctx.f28.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// fmuls f3,f29,f27
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f27.f64));
	// fsubs f29,f12,f10
	ctx.f29.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fnmsubs f7,f30,f0,f6
	ctx.f7.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// rlwinm r29,r9,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f10,f9,f4
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// mulli r26,r9,24
	ctx.r26.s64 = ctx.r9.s64 * 24;
	// fmuls f15,f1,f25
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fadds f9,f4,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// fmuls f14,f31,f25
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// fadds f30,f8,f5
	ctx.f30.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fadds f4,f28,f2
	ctx.f4.f64 = double(float(ctx.f28.f64 + ctx.f2.f64));
	// fsubs f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// fsubs f6,f29,f3
	ctx.f6.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// fadds f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// fsubs f28,f2,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// lfs f2,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmsubs f5,f1,f26,f14
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f26.f64 - ctx.f14.f64));
	// fsubs f1,f12,f7
	ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fmadds f7,f31,f26,f15
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f26.f64 + ctx.f15.f64));
	// fadds f31,f4,f11
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// stfs f31,0(r5)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmuls f31,f30,f23
	ctx.f31.f64 = double(float(ctx.f30.f64 * ctx.f23.f64));
	// fmuls f29,f8,f21
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// fmuls f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f24.f64));
	// fmuls f15,f3,f21
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// fmuls f14,f10,f18
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f18.f64));
	// fmsubs f31,f6,f24,f31
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f31.f64));
	// fmadds f3,f3,f22,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f29.f64));
	// fmadds f6,f6,f23,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64 + ctx.f30.f64));
	// stfs f2,-332(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f30,f28,f17
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f29,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f2,f1,f19,f14
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f19.f64 - ctx.f14.f64));
	// fmsubs f8,f8,f22,f15
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f22.f64 - ctx.f15.f64));
	// rlwinm r25,r8,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r24,r8,20
	ctx.r24.s64 = ctx.r8.s64 * 20;
	// rlwinm r23,r8,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// lfs f28,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f29,f12,f29,f28
	ctx.f29.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 + ctx.f28.f64));
	// lfs f28,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f28,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f11,f4,f28,f11
	ctx.f11.f64 = double(float(-(ctx.f4.f64 * ctx.f28.f64 - ctx.f11.f64)));
	// lfs f4,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f12,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmadds f12,f10,f16,f1
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f16.f64 + ctx.f1.f64));
	// lfs f10,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f1,f8,f31
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f31.f64));
	// fmsubs f10,f9,f10,f4
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 - ctx.f4.f64));
	// fadds f4,f8,f31
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f31.f64));
	// fadds f31,f6,f3
	ctx.f31.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// fsubs f9,f3,f6
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fsubs f8,f30,f2
	ctx.f8.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// fsubs f6,f11,f29
	ctx.f6.f64 = double(float(ctx.f11.f64 - ctx.f29.f64));
	// fmadds f2,f2,f13,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f30.f64));
	// fmadds f11,f29,f13,f11
	ctx.f11.f64 = double(float(ctx.f29.f64 * ctx.f13.f64 + ctx.f11.f64));
	// fmuls f3,f1,f20
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// fsubs f30,f5,f4
	ctx.f30.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fmuls f1,f31,f20
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f20.f64));
	// fsubs f31,f12,f10
	ctx.f31.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f10,f7,f9
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fmadds f5,f4,f13,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f5.f64));
	// stfsx f5,r11,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmadds f9,f9,f13,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f7.f64));
	// stfsx f9,r10,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f6,f8
	ctx.f29.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fadds f9,f11,f2
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fsubs f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f2.f64));
	// fsubs f7,f3,f10
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// stfsx f7,r31,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f10,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// stfsx f10,r30,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f30,f1
	ctx.f10.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// stfsx f10,r29,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f30,f1
	ctx.f10.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// stfsx f10,r26,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// stfsx f9,r25,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f29,f31
	ctx.f10.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// stfsx f11,r24,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f6,f8
	ctx.f11.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfsx f10,r23,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f29,f31
	ctx.f10.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// stfsx f10,r11,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f10,f11,f12
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// stfsx f10,r10,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// add r6,r27,r6
	ctx.r6.u64 = ctx.r27.u64 + ctx.r6.u64;
	// stfsx f12,r11,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r14)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r14.u32 + -26212);
	// add r5,r27,r5
	ctx.r5.u64 = ctx.r27.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c91ae8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C91AE8;
loc_82C91D48:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82C91D50;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C91D58"))) PPC_WEAK_FUNC(sub_82C91D58);
PPC_FUNC_IMPL(__imp__sub_82C91D58) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29856
	ctx.r5.s64 = ctx.r11.s64 + -29856;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,6640
	ctx.r4.s64 = ctx.r11.s64 + 6640;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C91D70"))) PPC_WEAK_FUNC(sub_82C91D70);
PPC_FUNC_IMPL(__imp__sub_82C91D70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a4
	ctx.lr = 0x82C91D78;
	__savegprlr_19(ctx, base);
	// stfd f29,-136(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -136, ctx.f29.u64);
	// stfd f30,-128(r1)
	PPC_STORE_U64(ctx.r1.u32 + -128, ctx.f30.u64);
	// stfd f31,-120(r1)
	PPC_STORE_U64(ctx.r1.u32 + -120, ctx.f31.u64);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c91f20
	if (!ctx.cr6.gt) goto loc_82C91F20;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r28,r11,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,28136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f0.f64 = double(temp.f32);
loc_82C91DB4:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 * 12;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f31,f10,f12
	ctx.f31.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f10,f6,f9
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// lfsx f5,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// rlwinm r29,r7,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r25,r8,12
	ctx.r25.s64 = ctx.r8.s64 * 12;
	// lfsx f4,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f6,f4,f8
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fadds f30,f3,f5
	ctx.f30.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f1,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f8,f4,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// lfsx f2,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// mulli r24,r9,12
	ctx.r24.s64 = ctx.r9.s64 * 12;
	// fnmsubs f3,f31,f0,f1
	ctx.f3.f64 = double(float(-(ctx.f31.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fadds f4,f31,f1
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fadds f1,f10,f2
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f2.f64));
	// fsubs f31,f9,f12
	ctx.f31.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// fnmsubs f10,f10,f0,f2
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fadds f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// fadds f9,f6,f11
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f11.f64));
	// fadds f2,f30,f7
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f7.f64));
	// rlwinm r23,r9,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmsubs f11,f6,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// mulli r22,r9,20
	ctx.r22.s64 = ctx.r9.s64 * 20;
	// fsubs f29,f8,f5
	ctx.f29.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// fnmsubs f7,f30,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f30.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fadds f30,f4,f1
	ctx.f30.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fsubs f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fsubs f4,f3,f10
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fadds f10,f3,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f10.f64));
	// fmuls f31,f31,f13
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// mulli r21,r8,20
	ctx.r21.s64 = ctx.r8.s64 * 20;
	// fadds f3,f2,f9
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfsx f9,r25,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fmuls f6,f29,f13
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// stfsx f1,r24,r6
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f11,f7
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// rlwinm r20,r8,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r19,r8,24
	ctx.r19.s64 = ctx.r8.s64 * 24;
	// fadds f7,f4,f6
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfsx f7,r23,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f4,f6
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// stfsx f7,r22,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f9,f31
	ctx.f4.f64 = double(float(ctx.f9.f64 - ctx.f31.f64));
	// stfsx f4,r21,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f31,f9
	ctx.f9.f64 = double(float(ctx.f31.f64 + ctx.f9.f64));
	// stfsx f9,r20,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f7,f3,f30
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// stfsx f7,r19,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f30,f3
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f9,f11,f10
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// stfsx f9,r11,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// stfsx f11,r10,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f5,f8
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// add r5,r27,r5
	ctx.r5.u64 = ctx.r27.u64 + ctx.r5.u64;
	// fsubs f10,f12,f11
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// fmuls f11,f10,f13
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// stfsx f11,r11,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfsx f12,r10,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,-26212(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + -26212);
	// add r6,r27,r6
	ctx.r6.u64 = ctx.r27.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c91db4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C91DB4;
loc_82C91F20:
	// lfd f29,-136(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -136);
	// lfd f30,-128(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -128);
	// lfd f31,-120(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x82d5c4f4
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C91F30"))) PPC_WEAK_FUNC(sub_82C91F30);
PPC_FUNC_IMPL(__imp__sub_82C91F30) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29768
	ctx.r5.s64 = ctx.r11.s64 + -29768;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,7536
	ctx.r4.s64 = ctx.r11.s64 + 7536;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C91F48"))) PPC_WEAK_FUNC(sub_82C91F48);
PPC_FUNC_IMPL(__imp__sub_82C91F48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82C91F50;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82d5c544
	ctx.lr = 0x82C91F58;
	__savefpr_15(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c921c0
	if (!ctx.cr6.gt) goto loc_82C921C0;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// rlwinm r21,r11,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f25,-29636(r23)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -29636);
	ctx.f25.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f26,-29640(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -29640);
	ctx.f26.f64 = double(temp.f32);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f27,-29644(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -29644);
	ctx.f27.f64 = double(temp.f32);
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f28,-29648(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -29648);
	ctx.f28.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f29,-29652(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -29652);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,-29656(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -29656);
	ctx.f30.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f31,-29660(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -29660);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,-29664(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -29664);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,-29668(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29668);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,-29672(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29672);
	ctx.f3.f64 = double(temp.f32);
loc_82C91FC8:
	// mulli r28,r7,20
	ctx.r28.s64 = ctx.r7.s64 * 20;
	// lfs f13,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfsx f12,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f8,f12,f13
	ctx.f8.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r31,r7,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// lfsx f11,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// lfsx f5,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f6,f5,f9
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// lfsx f24,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f11,f5,f9
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fadds f10,f24,f4
	ctx.f10.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// lfsx f23,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f5,f24,f4
	ctx.f5.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f9,f22,f23
	ctx.f9.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// rlwinm r28,r9,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f24,f13,f28
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// rlwinm r27,r8,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f4,f22,f23
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// rlwinm r26,r9,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f23,f8,f31
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// mulli r11,r9,20
	ctx.r11.s64 = ctx.r9.s64 * 20;
	// fmuls f21,f7,f2
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f2.f64));
	// fmuls f22,f8,f1
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmuls f20,f6,f31
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f18,f6,f2
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// fmuls f19,f10,f26
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fmuls f17,f5,f31
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmadds f16,f12,f25,f0
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f25.f64 + ctx.f0.f64));
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f24,f9,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f9.f64 * ctx.f29.f64 + ctx.f24.f64)));
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// fmuls f15,f10,f29
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// fmadds f23,f4,f3,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f23.f64));
	// fmadds f21,f8,f3,f21
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 + ctx.f21.f64));
	// fmadds f22,f7,f3,f22
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f3.f64 + ctx.f22.f64));
	// fmsubs f20,f5,f1,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 - ctx.f20.f64));
	// fnmadds f18,f5,f30,f18
	ctx.f18.f64 = double(float(-(ctx.f5.f64 * ctx.f30.f64 + ctx.f18.f64)));
	// fmsubs f19,f11,f27,f19
	ctx.f19.f64 = double(float(ctx.f11.f64 * ctx.f27.f64 - ctx.f19.f64));
	// fmsubs f17,f6,f30,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f30.f64 - ctx.f17.f64));
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// fadds f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// fmuls f20,f9,f26
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmuls f19,f11,f28
	ctx.f19.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// fmuls f18,f10,f28
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f17,f11,f26
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f26.f64));
	// fnmsubs f21,f4,f30,f21
	ctx.f21.f64 = double(float(-(ctx.f4.f64 * ctx.f30.f64 - ctx.f21.f64)));
	// stfsx f21,r28,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fmuls f21,f8,f30
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// rlwinm r28,r8,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// stfsx f24,r27,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fnmsubs f24,f7,f1,f23
	ctx.f24.f64 = double(float(-(ctx.f7.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// stfsx f24,r26,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f24,f4,f2,f22
	ctx.f24.f64 = double(float(-(ctx.f4.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// stfsx f24,r11,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f22,f7,f30
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// fmuls f24,f4,f31
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fadds f23,f10,f11
	ctx.f23.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f16,f9,f28
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmadds f22,f5,f3,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 + ctx.f22.f64));
	// fmadds f8,f8,f2,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 + ctx.f24.f64));
	// fadds f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f12.f64));
	// fmsubs f7,f6,f3,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 - ctx.f7.f64));
	// fmadds f5,f5,f2,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f2.f64 + ctx.f21.f64));
	// fnmadds f24,f13,f29,f20
	ctx.f24.f64 = double(float(-(ctx.f13.f64 * ctx.f29.f64 + ctx.f20.f64)));
	// fmsubs f21,f10,f25,f19
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 - ctx.f19.f64));
	// add r3,r22,r3
	ctx.r3.u64 = ctx.r22.u64 + ctx.r3.u64;
	// fadds f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// add r4,r22,r4
	ctx.r4.u64 = ctx.r22.u64 + ctx.r4.u64;
	// fnmadds f20,f12,f29,f18
	ctx.f20.f64 = double(float(-(ctx.f12.f64 * ctx.f29.f64 + ctx.f18.f64)));
	// fmsubs f19,f9,f27,f17
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f17.f64));
	// fnmadds f18,f12,f26,f16
	ctx.f18.f64 = double(float(-(ctx.f12.f64 * ctx.f26.f64 + ctx.f16.f64)));
	// fadds f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f13.f64));
	// fmsubs f17,f11,f25,f15
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f25.f64 - ctx.f15.f64));
	// fmuls f11,f11,f29
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// fadds f8,f22,f8
	ctx.f8.f64 = double(float(ctx.f22.f64 + ctx.f8.f64));
	// fadds f5,f24,f21
	ctx.f5.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// fmadds f24,f12,f27,f0
	ctx.f24.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 + ctx.f0.f64));
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fmadds f21,f13,f25,f0
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f25.f64 + ctx.f0.f64));
	// fadds f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// fmadds f19,f13,f27,f0
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f27.f64 + ctx.f0.f64));
	// fadds f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// fadds f20,f18,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// fmadds f8,f6,f1,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f8.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f8,f4,f1,f7
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f1.f64 - ctx.f7.f64)));
	// stfsx f8,r11,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fadds f8,f5,f24
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fnmadds f13,f13,f26,f12
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f26.f64 + ctx.f12.f64)));
	// fmsubs f12,f10,f27,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 - ctx.f11.f64));
	// fadds f8,f22,f21
	ctx.f8.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfsx f8,r30,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f23,f0
	ctx.f8.f64 = double(float(ctx.f23.f64 + ctx.f0.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmadds f0,f9,f25,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f25.f64 + ctx.f0.f64));
	// add r6,r21,r6
	ctx.r6.u64 = ctx.r21.u64 + ctx.r6.u64;
	// fadds f8,f20,f19
	ctx.f8.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfsx f8,r28,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfsx f0,r11,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + -26212);
	// add r5,r21,r5
	ctx.r5.u64 = ctx.r21.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c91fc8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C91FC8;
loc_82C921C0:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82d5c590
	ctx.lr = 0x82C921C8;
	__restfpr_15(ctx, base);
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C921D0"))) PPC_WEAK_FUNC(sub_82C921D0);
PPC_FUNC_IMPL(__imp__sub_82C921D0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29720
	ctx.r5.s64 = ctx.r11.s64 + -29720;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,8008
	ctx.r4.s64 = ctx.r11.s64 + 8008;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C921E8"))) PPC_WEAK_FUNC(sub_82C921E8);
PPC_FUNC_IMPL(__imp__sub_82C921E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a4
	ctx.lr = 0x82C921F0;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82d5c578
	ctx.lr = 0x82C921F8;
	__savefpr_28(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c92380
	if (!ctx.cr6.gt) goto loc_82C92380;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r30,-32255
	ctx.r30.s64 = -2113863680;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// rlwinm r28,r11,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f30,-12748(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -12748);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,28200(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 28200);
	ctx.f31.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f13,28208(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28208);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28204);
	ctx.f0.f64 = double(temp.f32);
loc_82C92238:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f2,f10,f9
	ctx.f2.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfsx f5,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f1,f8,f12
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfsx f7,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f9,f11,f5
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// fadds f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// rlwinm r26,r9,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r25,r9,12
	ctx.r25.s64 = ctx.r9.s64 * 12;
	// lfsx f4,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f8,f4,f7
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f7.f64));
	// fsubs f5,f6,f3
	ctx.f5.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// fadds f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fadds f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// rlwinm r24,r8,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// mulli r23,r8,20
	ctx.r23.s64 = ctx.r8.s64 * 20;
	// fadds f2,f12,f10
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// fsubs f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// fadds f10,f5,f8
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// fsubs f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// fadds f5,f6,f7
	ctx.f5.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// mulli r22,r8,12
	ctx.r22.s64 = ctx.r8.s64 * 12;
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fadds f6,f10,f4
	ctx.f6.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// rlwinm r21,r9,3,0,28
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f4,f10,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// rlwinm r20,r9,4,0,27
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f10,f5,f2
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f2.f64));
	// rlwinm r19,r8,3,0,28
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f5,f5,f2
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f2,f8,f13
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fmuls f29,f8,f0
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// add r4,r29,r4
	ctx.r4.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fmuls f28,f7,f0
	ctx.f28.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmadds f7,f7,f13,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fmuls f8,f4,f31
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmsubs f4,f3,f0,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f2.f64));
	// stfsx f4,r26,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fmadds f4,f3,f13,f29
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f29.f64));
	// stfsx f4,r25,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fmsubs f4,f12,f13,f28
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f28.f64));
	// fnmsubs f12,f6,f30,f9
	ctx.f12.f64 = double(float(-(ctx.f6.f64 * ctx.f30.f64 - ctx.f9.f64)));
	// fadds f2,f10,f11
	ctx.f2.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fnmsubs f11,f10,f30,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f30.f64 - ctx.f11.f64)));
	// fadds f3,f6,f9
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// fadds f10,f12,f8
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// stfsx f10,r24,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// stfsx f3,r23,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// stfsx f12,r22,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f11,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// stfsx f4,r21,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r6.u32, temp.u32);
	// stfsx f7,r20,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r6.u32, temp.u32);
	// add r6,r28,r6
	ctx.r6.u64 = ctx.r28.u64 + ctx.r6.u64;
	// stfsx f12,r19,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f11,f5
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// stfs f2,0(r5)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfsx f12,r11,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + -26212);
	// add r5,r28,r5
	ctx.r5.u64 = ctx.r28.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c92238
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C92238;
loc_82C92380:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82d5c5c4
	ctx.lr = 0x82C92388;
	__restfpr_28(ctx, base);
	// b 0x82d5c4f4
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92390"))) PPC_WEAK_FUNC(sub_82C92390);
PPC_FUNC_IMPL(__imp__sub_82C92390) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29632
	ctx.r5.s64 = ctx.r11.s64 + -29632;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,8680
	ctx.r4.s64 = ctx.r11.s64 + 8680;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C923A8"))) PPC_WEAK_FUNC(sub_82C923A8);
PPC_FUNC_IMPL(__imp__sub_82C923A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c49c
	ctx.lr = 0x82C923B0;
	__savegprlr_17(ctx, base);
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82d5c550
	ctx.lr = 0x82C923B8;
	__savefpr_18(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c925a4
	if (!ctx.cr6.gt) goto loc_82C925A4;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// lis r21,-32235
	ctx.r21.s64 = -2112552960;
	// rlwinm r18,r11,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r22,-32235
	ctx.r22.s64 = -2112552960;
	// rlwinm r17,r11,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f19,-31576(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -31576);
	ctx.f19.f64 = double(temp.f32);
	// lis r24,-32235
	ctx.r24.s64 = -2112552960;
	// lfs f20,30712(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 30712);
	ctx.f20.f64 = double(temp.f32);
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// lis r26,-32235
	ctx.r26.s64 = -2112552960;
	// lfs f21,30716(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 30716);
	ctx.f21.f64 = double(temp.f32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// lfs f22,-31572(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -31572);
	ctx.f22.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f27,29636(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 29636);
	ctx.f27.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f28,-31568(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -31568);
	ctx.f28.f64 = double(temp.f32);
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lfs f23,29652(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 29652);
	ctx.f23.f64 = double(temp.f32);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f24,-31556(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -31556);
	ctx.f24.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f29,29632(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 29632);
	ctx.f29.f64 = double(temp.f32);
	// lfs f30,-31564(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -31564);
	ctx.f30.f64 = double(temp.f32);
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f25,-31560(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -31560);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,29648(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 29648);
	ctx.f26.f64 = double(temp.f32);
	// lfs f9,28136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f9.f64 = double(temp.f32);
	// lfs f0,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f0.f64 = double(temp.f32);
loc_82C92448:
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// lfs f11,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f13,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r29,r9,12
	ctx.r29.s64 = ctx.r9.s64 * 12;
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f3,f13,f7
	ctx.f3.f64 = double(float(ctx.f13.f64 + ctx.f7.f64));
	// lfsx f12,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// fadds f2,f12,f6
	ctx.f2.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// lfsx f4,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f5,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f7,f10,f4
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// fsubs f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f6.f64));
	// mulli r30,r8,12
	ctx.r30.s64 = ctx.r8.s64 * 12;
	// fsubs f6,f10,f4
	ctx.f6.f64 = double(float(ctx.f10.f64 - ctx.f4.f64));
	// fadds f4,f3,f11
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f11.f64));
	// fnmsubs f11,f3,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// fadds f1,f2,f5
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// rlwinm r28,r8,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmsubs f10,f2,f0,f5
	ctx.f10.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f5.f64)));
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f31,f7,f8
	ctx.f31.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// rlwinm r26,r8,4,0,27
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fnmsubs f8,f7,f0,f8
	ctx.f8.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f18,f13,f25
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// rlwinm r10,r9,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f5,f6,f9
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// rlwinm r31,r8,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r18,r3
	ctx.r3.u64 = ctx.r18.u64 + ctx.r3.u64;
	// add r4,r18,r4
	ctx.r4.u64 = ctx.r18.u64 + ctx.r4.u64;
	// fmuls f2,f11,f23
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// fadds f7,f1,f4
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fmuls f3,f10,f29
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// fmuls f1,f10,f27
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fmsubs f2,f13,f24,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f24.f64 - ctx.f2.f64));
	// fmuls f4,f4,f9
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// stfsx f4,r29,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmadds f4,f11,f26,f18
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f26.f64 + ctx.f18.f64));
	// fmadds f3,f12,f30,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 + ctx.f3.f64));
	// fmsubs f1,f12,f28,f1
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f28.f64 - ctx.f1.f64));
	// fadds f18,f7,f31
	ctx.f18.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// fnmsubs f7,f7,f0,f31
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f31.f64)));
	// stfsx f7,r30,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfs f18,0(r5)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f7,f3,f4
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f3,f3,f4
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fmadds f3,f2,f9,f8
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fadds f2,f7,f8
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfsx f2,r28,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fmuls f2,f4,f0
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fadds f4,f4,f5
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfsx f4,r27,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fmuls f4,f10,f21
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// fnmsubs f7,f7,f0,f3
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// stfsx f7,r26,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fmsubs f7,f6,f9,f2
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 - ctx.f2.f64));
	// stfsx f7,r11,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f6,f11,f27
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// fmuls f7,f12,f19
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f19.f64));
	// fmsubs f12,f12,f22,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f22.f64 - ctx.f4.f64));
	// fmadds f11,f11,f29,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 + ctx.f8.f64));
	// fnmadds f6,f13,f28,f6
	ctx.f6.f64 = double(float(-(ctx.f13.f64 * ctx.f28.f64 + ctx.f6.f64)));
	// fnmadds f10,f10,f20,f7
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f20.f64 + ctx.f7.f64)));
	// fadds f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fsubs f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f5.f64));
	// stfsx f12,r10,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f13,f13,f30,f11
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f30.f64 - ctx.f11.f64)));
	// add r6,r17,r6
	ctx.r6.u64 = ctx.r17.u64 + ctx.r6.u64;
	// stfsx f13,r31,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + -26212);
	// add r5,r17,r5
	ctx.r5.u64 = ctx.r17.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c92448
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C92448;
loc_82C925A4:
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82d5c59c
	ctx.lr = 0x82C925AC;
	__restfpr_18(ctx, base);
	// b 0x82d5c4ec
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C925B0"))) PPC_WEAK_FUNC(sub_82C925B0);
PPC_FUNC_IMPL(__imp__sub_82C925B0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29584
	ctx.r5.s64 = ctx.r11.s64 + -29584;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,9128
	ctx.r4.s64 = ctx.r11.s64 + 9128;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C925C8"))) PPC_WEAK_FUNC(sub_82C925C8);
PPC_FUNC_IMPL(__imp__sub_82C925C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82C925D0;
	__savegprlr_21(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c926dc
	if (!ctx.cr6.gt) goto loc_82C926DC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f5,-29652(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29652);
	ctx.f5.f64 = double(temp.f32);
loc_82C925F8:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mulli r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 * 12;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f12,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f6,f0,f12
	ctx.f6.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fadds f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// lfsx f11,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f12,f10,f13
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// fsubs f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r9,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r25,r8,12
	ctx.r25.s64 = ctx.r8.s64 * 12;
	// lfsx f8,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f10,f11,f8
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// lfsx f7,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fadds f8,f9,f7
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// rlwinm r24,r8,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r9,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r22,r9,12
	ctx.r22.s64 = ctx.r9.s64 * 12;
	// fadds f4,f6,f10
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f6,f10,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f10,f8,f12
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fadds f7,f0,f11
	ctx.f7.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// stfsx f12,r27,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfsx f0,r26,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r21,r8,4,0,27
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fmuls f0,f4,f5
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f12,f6,f5
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fsubs f11,f10,f7
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fsubs f8,f13,f0
	ctx.f8.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// stfsx f8,r25,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// stfsx f0,r24,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f12,f9
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// stfsx f0,r23,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fadds f0,f12,f9
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// stfsx f0,r22,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r6.u32, temp.u32);
	// stfsx f11,r21,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r5.u32, temp.u32);
	// add r6,r29,r6
	ctx.r6.u64 = ctx.r29.u64 + ctx.r6.u64;
	// stfs f10,0(r5)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,-26212(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + -26212);
	// add r5,r29,r5
	ctx.r5.u64 = ctx.r29.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c925f8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C925F8;
loc_82C926DC:
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C926E0"))) PPC_WEAK_FUNC(sub_82C926E0);
PPC_FUNC_IMPL(__imp__sub_82C926E0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29536
	ctx.r5.s64 = ctx.r11.s64 + -29536;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,9672
	ctx.r4.s64 = ctx.r11.s64 + 9672;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C926F8"))) PPC_WEAK_FUNC(sub_82C926F8);
PPC_FUNC_IMPL(__imp__sub_82C926F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b4
	ctx.lr = 0x82C92700;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c568
	ctx.lr = 0x82C92708;
	__savefpr_24(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c92850
	if (!ctx.cr6.gt) goto loc_82C92850;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r25,-32235
	ctx.r25.s64 = -2112552960;
	// lis r26,-32235
	ctx.r26.s64 = -2112552960;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r27,-32235
	ctx.r27.s64 = -2112552960;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// lfs f2,30852(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 30852);
	ctx.f2.f64 = double(temp.f32);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f3,30848(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 30848);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f4,30844(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 30844);
	ctx.f4.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f5,30832(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 30832);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,30840(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 30840);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,30836(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 30836);
	ctx.f7.f64 = double(temp.f32);
loc_82C92758:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mulli r28,r7,12
	ctx.r28.s64 = ctx.r7.s64 * 12;
	// lfsx f11,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f8,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f12,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f9,f8,f11
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// fsubs f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// lfsx f1,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fadds f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// rlwinm r28,r9,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f11,f31,f1
	ctx.f11.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f8,f31,f1
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// rlwinm r26,r8,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r25,r9,12
	ctx.r25.s64 = ctx.r9.s64 * 12;
	// fmuls f29,f9,f6
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f1,f10,f6
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// fmuls f31,f13,f3
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f27,f9,f7
	ctx.f27.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// mulli r24,r8,12
	ctx.r24.s64 = ctx.r8.s64 * 12;
	// fmuls f28,f11,f3
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f26,f12,f3
	ctx.f26.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fadds f25,f12,f11
	ctx.f25.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// fmadds f24,f12,f2,f0
	ctx.f24.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 + ctx.f0.f64));
	// fmadds f30,f13,f2,f0
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f0.f64));
	// fmsubs f29,f10,f7,f29
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 - ctx.f29.f64));
	// fmadds f1,f8,f7,f1
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 + ctx.f1.f64));
	// rlwinm r23,r8,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f12,f12,f4,f31
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f4.f64 + ctx.f31.f64)));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fmadds f10,f10,f5,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 + ctx.f27.f64));
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fnmadds f28,f13,f4,f28
	ctx.f28.f64 = double(float(-(ctx.f13.f64 * ctx.f4.f64 + ctx.f28.f64)));
	// fmadds f31,f11,f2,f0
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f0.f64));
	// fnmadds f11,f11,f4,f26
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f4.f64 + ctx.f26.f64)));
	// fadds f13,f25,f13
	ctx.f13.f64 = double(float(ctx.f25.f64 + ctx.f13.f64));
	// fnmsubs f29,f8,f5,f29
	ctx.f29.f64 = double(float(-(ctx.f8.f64 * ctx.f5.f64 - ctx.f29.f64)));
	// stfsx f29,r28,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fmadds f9,f9,f5,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64 + ctx.f1.f64));
	// stfsx f9,r27,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f10,f8,f6,f10
	ctx.f10.f64 = double(float(-(ctx.f8.f64 * ctx.f6.f64 - ctx.f10.f64)));
	// fadds f9,f28,f24
	ctx.f9.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// stfsx f9,r26,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// stfsx f10,r25,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f31.f64));
	// stfsx f12,r24,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f11,f30
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f30.f64));
	// stfsx f12,r23,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,-26212(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + -26212);
	// add r6,r30,r6
	ctx.r6.u64 = ctx.r30.u64 + ctx.r6.u64;
	// add r5,r30,r5
	ctx.r5.u64 = ctx.r30.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c92758
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C92758;
loc_82C92850:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c5b4
	ctx.lr = 0x82C92858;
	__restfpr_24(ctx, base);
	// b 0x82d5c504
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92860"))) PPC_WEAK_FUNC(sub_82C92860);
PPC_FUNC_IMPL(__imp__sub_82C92860) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29488
	ctx.r5.s64 = ctx.r11.s64 + -29488;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,9976
	ctx.r4.s64 = ctx.r11.s64 + 9976;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92878"))) PPC_WEAK_FUNC(sub_82C92878);
PPC_FUNC_IMPL(__imp__sub_82C92878) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82C92880;
	__savegprlr_24(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c92960
	if (!ctx.cr6.gt) goto loc_82C92960;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f5,-29000(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29000);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,28136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28136);
	ctx.f6.f64 = double(temp.f32);
loc_82C928B0:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r26,r8,12
	ctx.r26.s64 = ctx.r8.s64 * 12;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f8,f11,f0
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// fsubs f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f11,f13,f9
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// rlwinm r25,r9,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// rlwinm r24,r8,3,0,28
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fadds f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fadds f9,f12,f0
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fmuls f12,f8,f6
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// stfsx f12,r28,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fnmsubs f11,f10,f5,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f5.f64 - ctx.f11.f64)));
	// stfsx f11,r27,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// stfsx f12,r26,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fmuls f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfsx f0,r25,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f0,f9,f5,f13
	ctx.f0.f64 = double(float(-(ctx.f9.f64 * ctx.f5.f64 - ctx.f13.f64)));
	// stfsx f0,r24,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f9,f13
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,-26212(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + -26212);
	// add r6,r30,r6
	ctx.r6.u64 = ctx.r30.u64 + ctx.r6.u64;
	// add r5,r30,r5
	ctx.r5.u64 = ctx.r30.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c928b0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C928B0;
loc_82C92960:
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92968"))) PPC_WEAK_FUNC(sub_82C92968);
PPC_FUNC_IMPL(__imp__sub_82C92968) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29440
	ctx.r5.s64 = ctx.r11.s64 + -29440;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,10360
	ctx.r4.s64 = ctx.r11.s64 + 10360;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92980"))) PPC_WEAK_FUNC(sub_82C92980);
PPC_FUNC_IMPL(__imp__sub_82C92980) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82C92988;
	__savegprlr_25(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c92a68
	if (!ctx.cr6.gt) goto loc_82C92A68;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r27,-32255
	ctx.r27.s64 = -2113863680;
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f5,-12748(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -12748);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,28200(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 28200);
	ctx.f6.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f7,28204(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 28204);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,28208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28208);
	ctx.f8.f64 = double(temp.f32);
loc_82C929C8:
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r9,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r8,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f12,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r25,r8,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f9,f0,f12
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// lfsx f11,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fadds f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fmuls f4,f0,f7
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fadds f10,f12,f9
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// fsubs f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// fmuls f9,f11,f7
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmuls f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// fmsubs f0,f0,f8,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f0,r28,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fmadds f0,f11,f8,f4
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + ctx.f4.f64));
	// fadds f11,f10,f13
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// stfs f11,0(r5)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfsx f0,r27,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f0,f10,f5,f13
	ctx.f0.f64 = double(float(-(ctx.f10.f64 * ctx.f5.f64 - ctx.f13.f64)));
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// fadds f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// stfsx f13,r26,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// stfsx f0,r25,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -26212);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c929c8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C929C8;
loc_82C92A68:
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92A70"))) PPC_WEAK_FUNC(sub_82C92A70);
PPC_FUNC_IMPL(__imp__sub_82C92A70) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29392
	ctx.r5.s64 = ctx.r11.s64 + -29392;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,10624
	ctx.r4.s64 = ctx.r11.s64 + 10624;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92A88"))) PPC_WEAK_FUNC(sub_82C92A88);
PPC_FUNC_IMPL(__imp__sub_82C92A88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82C92A90;
	__savegprlr_27(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c92b1c
	if (!ctx.cr6.gt) goto loc_82C92B1C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82C92AB0:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfsx f11,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// fadds f10,f12,f0
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// stfsx f0,r29,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fsubs f0,f11,f13
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// stfsx f0,r28,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// fsubs f0,f10,f9
	ctx.f0.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfsx f0,r27,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f9,f10
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,-26212(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -26212);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c92ab0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C92AB0;
loc_82C92B1C:
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92B20"))) PPC_WEAK_FUNC(sub_82C92B20);
PPC_FUNC_IMPL(__imp__sub_82C92B20) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29344
	ctx.r5.s64 = ctx.r11.s64 + -29344;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,10888
	ctx.r4.s64 = ctx.r11.s64 + 10888;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92B38"))) PPC_WEAK_FUNC(sub_82C92B38);
PPC_FUNC_IMPL(__imp__sub_82C92B38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82C92B40;
	__savegprlr_28(ctx, base);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c92bcc
	if (!ctx.cr6.gt) goto loc_82C92BCC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f9,28136(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 28136);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f10.f64 = double(temp.f32);
loc_82C92B70:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fadds f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fadds f12,f11,f13
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fnmsubs f13,f11,f10,f13
	ctx.f13.f64 = double(float(-(ctx.f11.f64 * ctx.f10.f64 - ctx.f13.f64)));
	// stfsx f13,r29,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fmuls f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// stfsx f0,r28,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r11,-26212(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -26212);
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// xor r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
	// bdnz 0x82c92b70
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C92B70;
loc_82C92BCC:
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92BD0"))) PPC_WEAK_FUNC(sub_82C92BD0);
PPC_FUNC_IMPL(__imp__sub_82C92BD0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29296
	ctx.r5.s64 = ctx.r11.s64 + -29296;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,11064
	ctx.r4.s64 = ctx.r11.s64 + 11064;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92BE8"))) PPC_WEAK_FUNC(sub_82C92BE8);
PPC_FUNC_IMPL(__imp__sub_82C92BE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lis r7,-32234
	ctx.r7.s64 = -2112487424;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82C92C08:
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfsx f12,r10,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r10,-26212(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + -26212);
	// add r5,r9,r5
	ctx.r5.u64 = ctx.r9.u64 + ctx.r5.u64;
	// xor r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 ^ ctx.r8.u64;
	// bdnz 0x82c92c08
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C92C08;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92C40"))) PPC_WEAK_FUNC(sub_82C92C40);
PPC_FUNC_IMPL(__imp__sub_82C92C40) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29248
	ctx.r5.s64 = ctx.r11.s64 + -29248;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,11240
	ctx.r4.s64 = ctx.r11.s64 + 11240;
	// b 0x82cab7d0
	sub_82CAB7D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92C58"))) PPC_WEAK_FUNC(sub_82C92C58);
PPC_FUNC_IMPL(__imp__sub_82C92C58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82C92C60;
	__savegprlr_22(ctx, base);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x82c92cd8
	if (!ctx.cr6.gt) goto loc_82C92CD8;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82C92C84:
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// ble cr6,0x82c92cc8
	if (!ctx.cr6.gt) goto loc_82C92CC8;
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// subf r26,r3,r4
	ctx.r26.s64 = ctx.r4.s64 - ctx.r3.s64;
	// subf r25,r6,r5
	ctx.r25.s64 = ctx.r5.s64 - ctx.r6.s64;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
loc_82C92CA8:
	// lfsx f0,r26,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r11,r27,r11
	ctx.r11.u64 = ctx.r27.u64 + ctx.r11.u64;
	// stfsx f13,r25,r10
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r10.u32, temp.u32);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// add r10,r28,r10
	ctx.r10.u64 = ctx.r28.u64 + ctx.r10.u64;
	// bne 0x82c92ca8
	if (!ctx.cr0.eq) goto loc_82C92CA8;
loc_82C92CC8:
	// addic. r24,r24,-1
	ctx.xer.ca = ctx.r24.u32 > 0;
	ctx.r24.s64 = ctx.r24.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// add r30,r22,r30
	ctx.r30.u64 = ctx.r22.u64 + ctx.r30.u64;
	// add r29,r23,r29
	ctx.r29.u64 = ctx.r23.u64 + ctx.r29.u64;
	// bne 0x82c92c84
	if (!ctx.cr0.eq) goto loc_82C92C84;
loc_82C92CD8:
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92CE0"))) PPC_WEAK_FUNC(sub_82C92CE0);
PPC_FUNC_IMPL(__imp__sub_82C92CE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r10
	ctx.r31.u64 = ctx.r10.u64;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// neg r30,r8
	ctx.r30.s64 = -ctx.r8.s64;
	// blt cr6,0x82c92d08
	if (ctx.cr6.lt) goto loc_82C92D08;
	// mr r30,r8
	ctx.r30.u64 = ctx.r8.u64;
loc_82C92D08:
	// lwz r11,212(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// neg r10,r11
	ctx.r10.s64 = -ctx.r11.s64;
	// blt cr6,0x82c92d1c
	if (ctx.cr6.lt) goto loc_82C92D1C;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82C92D1C:
	// cmpw cr6,r30,r10
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82c92d3c
	if (!ctx.cr6.lt) goto loc_82C92D3C;
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// lwz r31,220(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// bl 0x82c92c58
	ctx.lr = 0x82C92D38;
	sub_82C92C58(ctx, base);
	// b 0x82c92d58
	goto loc_82C92D58;
loc_82C92D3C:
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// stw r9,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r9.u32);
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// lwz r9,220(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// bl 0x82c92c58
	ctx.lr = 0x82C92D58;
	sub_82C92C58(ctx, base);
loc_82C92D58:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92D70"))) PPC_WEAK_FUNC(sub_82C92D70);
PPC_FUNC_IMPL(__imp__sub_82C92D70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r10
	ctx.r31.u64 = ctx.r10.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// neg r30,r9
	ctx.r30.s64 = -ctx.r9.s64;
	// blt cr6,0x82c92d98
	if (ctx.cr6.lt) goto loc_82C92D98;
	// mr r30,r9
	ctx.r30.u64 = ctx.r9.u64;
loc_82C92D98:
	// lwz r11,220(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// neg r10,r11
	ctx.r10.s64 = -ctx.r11.s64;
	// blt cr6,0x82c92dac
	if (ctx.cr6.lt) goto loc_82C92DAC;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82C92DAC:
	// cmpw cr6,r30,r10
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82c92dcc
	if (!ctx.cr6.lt) goto loc_82C92DCC;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// lwz r11,212(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82c92c58
	ctx.lr = 0x82C92DC8;
	sub_82C92C58(ctx, base);
	// b 0x82c92de8
	goto loc_82C92DE8;
loc_82C92DCC:
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// stw r9,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r9.u32);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// lwz r8,212(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// bl 0x82c92c58
	ctx.lr = 0x82C92DE8;
	sub_82C92C58(ctx, base);
loc_82C92DE8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92E00"))) PPC_WEAK_FUNC(sub_82C92E00);
PPC_FUNC_IMPL(__imp__sub_82C92E00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82C92E08;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C92E28;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C92E40;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92E48"))) PPC_WEAK_FUNC(sub_82C92E48);
PPC_FUNC_IMPL(__imp__sub_82C92E48) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82C92E50;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C92E78;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C92E98;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C92EA0"))) PPC_WEAK_FUNC(sub_82C92EA0);
PPC_FUNC_IMPL(__imp__sub_82C92EA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// bl 0x82c3fc78
	ctx.lr = 0x82C92EC4;
	sub_82C3FC78(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82c3fc78
	ctx.lr = 0x82C92ED0;
	sub_82C3FC78(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92EE8"))) PPC_WEAK_FUNC(sub_82C92EE8);
PPC_FUNC_IMPL(__imp__sub_82C92EE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82c3fc28
	ctx.lr = 0x82C92F04;
	sub_82C3FC28(ctx, base);
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// bl 0x82c3fc28
	ctx.lr = 0x82C92F0C;
	sub_82C3FC28(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92F20"))) PPC_WEAK_FUNC(sub_82C92F20);
PPC_FUNC_IMPL(__imp__sub_82C92F20) {
	PPC_FUNC_PROLOGUE();
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r11,r11,11776
	ctx.r11.s64 = ctx.r11.s64 + 11776;
	// lwz r9,56(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// addi r11,r11,19976
	ctx.r11.s64 = ctx.r11.s64 + 19976;
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// beq cr6,0x82c92f4c
	if (ctx.cr6.eq) goto loc_82C92F4C;
	// addi r5,r11,4
	ctx.r5.s64 = ctx.r11.s64 + 4;
loc_82C92F4C:
	// addi r4,r11,8
	ctx.r4.s64 = ctx.r11.s64 + 8;
	// lwz r8,64(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// lwz r7,68(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 68);
	// lwz r6,72(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_82C92F68"))) PPC_WEAK_FUNC(sub_82C92F68);
PPC_FUNC_IMPL(__imp__sub_82C92F68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82c92fec
	if (!ctx.cr6.eq) goto loc_82C92FEC;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bgt cr6,0x82c92fec
	if (ctx.cr6.gt) goto loc_82C92FEC;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// beq cr6,0x82c92fc4
	if (ctx.cr6.eq) goto loc_82C92FC4;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82c92fc4
	if (ctx.cr6.eq) goto loc_82C92FC4;
	// lwz r10,152(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 152);
	// rlwinm. r10,r10,0,7,7
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000000;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82c92fec
	if (!ctx.cr0.eq) goto loc_82C92FEC;
loc_82C92FC4:
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// bl 0x82c424e0
	ctx.lr = 0x82C92FD0;
	sub_82C424E0(ctx, base);
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// ble cr6,0x82c92fec
	if (!ctx.cr6.gt) goto loc_82C92FEC;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpw cr6,r11,r3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r3.s32, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bgt cr6,0x82c92ff0
	if (ctx.cr6.gt) goto loc_82C92FF0;
loc_82C92FEC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C92FF0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C93008"))) PPC_WEAK_FUNC(sub_82C93008);
PPC_FUNC_IMPL(__imp__sub_82C93008) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82C93010;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82c92f68
	ctx.lr = 0x82C93024;
	sub_82C92F68(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82c93034
	if (!ctx.cr0.eq) goto loc_82C93034;
loc_82C9302C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c93084
	goto loc_82C93084;
loc_82C93034:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c93080
	if (ctx.cr6.eq) goto loc_82C93080;
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c93080
	if (ctx.cr6.eq) goto loc_82C93080;
	// lwz r11,152(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 152);
	// rlwinm. r11,r11,0,15,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82c93080
	if (ctx.cr0.eq) goto loc_82C93080;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82c9302c
	if (ctx.cr0.eq) goto loc_82C9302C;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C93078;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82c9302c
	if (ctx.cr0.eq) goto loc_82C9302C;
loc_82C93080:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82C93084:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C93090"))) PPC_WEAK_FUNC(sub_82C93090);
PPC_FUNC_IMPL(__imp__sub_82C93090) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82C93098;
	__savegprlr_22(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r5
	ctx.r24.u64 = ctx.r5.u64;
	// li r23,0
	ctx.r23.s64 = 0;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r26,r23
	ctx.r26.u64 = ctx.r23.u64;
	// lwz r11,152(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 152);
	// mr r22,r23
	ctx.r22.u64 = ctx.r23.u64;
	// rlwinm. r11,r11,0,10,10
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x200000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82c930cc
	if (ctx.cr0.eq) goto loc_82C930CC;
	// lwz r11,148(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 148);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bgt cr6,0x82c930e4
	if (ctx.cr6.gt) goto loc_82C930E4;
loc_82C930CC:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c93008
	ctx.lr = 0x82C930DC;
	sub_82C93008(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82c930ec
	if (!ctx.cr0.eq) goto loc_82C930EC;
loc_82C930E4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c933a4
	goto loc_82C933A4;
loc_82C930EC:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// addi r29,r11,4
	ctx.r29.s64 = ctx.r11.s64 + 4;
	// lwz r30,0(r29)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c424e0
	ctx.lr = 0x82C93104;
	sub_82C424E0(ctx, base);
	// rotlwi r11,r30,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r30.u32, 1);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// andc r11,r28,r11
	ctx.r11.u64 = ctx.r28.u64 & ~ctx.r11.u64;
	// addi r5,r1,136
	ctx.r5.s64 = ctx.r1.s64 + 136;
	// addi r4,r1,132
	ctx.r4.s64 = ctx.r1.s64 + 132;
	// divw r30,r30,r28
	ctx.r30.s32 = ctx.r30.s32 / ctx.r28.s32;
	// twllei r28,0
	// twlgei r11,-1
	// bl 0x82c529f8
	ctx.lr = 0x82C93134;
	sub_82C529F8(ctx, base);
	// lwz r11,12(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82c9314c
	if (ctx.cr6.lt) goto loc_82C9314C;
	// beq cr6,0x82c931b4
	if (ctx.cr6.eq) goto loc_82C931B4;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bge cr6,0x82c9337c
	if (!ctx.cr6.lt) goto loc_82C9337C;
loc_82C9314C:
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// lwz r9,132(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// bne cr6,0x82c93288
	if (!ctx.cr6.eq) goto loc_82C93288;
	// mr r25,r10
	ctx.r25.u64 = ctx.r10.u64;
	// cmpw cr6,r28,r9
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r9.s32, ctx.xer);
	// mullw r26,r11,r30
	ctx.r26.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// bne cr6,0x82c9334c
	if (!ctx.cr6.eq) goto loc_82C9334C;
	// mullw r8,r10,r28
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	// cmpw cr6,r11,r8
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x82c9334c
	if (!ctx.cr6.eq) goto loc_82C9334C;
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// bne cr6,0x82c9334c
	if (!ctx.cr6.eq) goto loc_82C9334C;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mullw r7,r8,r28
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r28.s32);
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// bne cr6,0x82c9334c
	if (!ctx.cr6.eq) goto loc_82C9334C;
	// cmpw cr6,r10,r8
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x82c9334c
	if (!ctx.cr6.eq) goto loc_82C9334C;
	// lwz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmpw cr6,r26,r11
	ctx.cr6.compare<int32_t>(ctx.r26.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82c93290
	if (ctx.cr6.eq) goto loc_82C93290;
	// b 0x82c9334c
	goto loc_82C9334C;
loc_82C931B4:
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// stw r6,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r6.u32);
	// mullw r6,r8,r30
	ctx.r6.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r30.s32);
	// stw r5,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r5.u32);
	// lwz r9,132(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// stw r24,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r24.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// stw r23,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r23.u32);
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C93200;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq 0x82c9334c
	if (ctx.cr0.eq) goto loc_82C9334C;
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r27,24(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mullw r5,r11,r30
	ctx.r5.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// lwz r26,20(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r25,16(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r8,128(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r7,136(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r6,132(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r4,4(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// bl 0x82c54660
	ctx.lr = 0x82C93238;
	sub_82C54660(ctx, base);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r5,8(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mullw r4,r11,r28
	ctx.r4.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// bl 0x82c42a78
	ctx.lr = 0x82C93250;
	sub_82C42A78(ctx, base);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// bl 0x82c428e0
	ctx.lr = 0x82C93268;
	sub_82C428E0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c41a30
	ctx.lr = 0x82C93274;
	sub_82C41A30(ctx, base);
	// mr. r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// beq 0x82c9334c
	if (ctx.cr0.eq) goto loc_82C9334C;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r5,r11,11776
	ctx.r5.s64 = ctx.r11.s64 + 11776;
	// b 0x82c93368
	goto loc_82C93368;
loc_82C93288:
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
	// mullw r25,r11,r30
	ctx.r25.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
loc_82C93290:
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stw r23,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r23.u32);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// lwz r27,16(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// lwz r23,12(r31)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r8,4(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// stw r24,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r24.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// mullw r5,r8,r30
	ctx.r5.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r30.s32);
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// stw r27,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r27.u32);
	// stw r23,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r23.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C932D4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq 0x82c9334c
	if (ctx.cr0.eq) goto loc_82C9334C;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// lwz r27,24(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// lwz r26,20(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r22,16(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r8,128(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r6,132(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r5,8(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// bl 0x82c54660
	ctx.lr = 0x82C93308;
	sub_82C54660(ctx, base);
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,4(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// mullw r5,r11,r28
	ctx.r5.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// bl 0x82c42a78
	ctx.lr = 0x82C93320;
	sub_82C42A78(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r6,r22
	ctx.r6.u64 = ctx.r22.u64;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// bl 0x82c428e0
	ctx.lr = 0x82C93338;
	sub_82C428E0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c41a30
	ctx.lr = 0x82C93344;
	sub_82C41A30(ctx, base);
	// mr. r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// bne 0x82c93360
	if (!ctx.cr0.eq) goto loc_82C93360;
loc_82C9334C:
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82c3fc28
	ctx.lr = 0x82C93354;
	sub_82C3FC28(ctx, base);
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82c3fc28
	ctx.lr = 0x82C9335C;
	sub_82C3FC28(ctx, base);
	// b 0x82c930e4
	goto loc_82C930E4;
loc_82C93360:
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r5,r11,11848
	ctx.r5.s64 = ctx.r11.s64 + 11848;
loc_82C93368:
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// li r3,80
	ctx.r3.s64 = 80;
	// addi r4,r10,-29200
	ctx.r4.s64 = ctx.r10.s64 + -29200;
	// bl 0x82c55cf0
	ctx.lr = 0x82C93378;
	sub_82C55CF0(ctx, base);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
loc_82C9337C:
	// addi r5,r26,8
	ctx.r5.s64 = ctx.r26.s64 + 8;
	// stw r22,64(r26)
	PPC_STORE_U32(ctx.r26.u32 + 64, ctx.r22.u32);
	// addi r4,r23,8
	ctx.r4.s64 = ctx.r23.s64 + 8;
	// stw r23,68(r26)
	PPC_STORE_U32(ctx.r26.u32 + 68, ctx.r23.u32);
	// addi r3,r22,8
	ctx.r3.s64 = ctx.r22.s64 + 8;
	// stw r28,72(r26)
	PPC_STORE_U32(ctx.r26.u32 + 72, ctx.r28.u32);
	// bl 0x82c40078
	ctx.lr = 0x82C93398;
	sub_82C40078(ctx, base);
	// lwz r11,52(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 52);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stw r11,52(r26)
	PPC_STORE_U32(ctx.r26.u32 + 52, ctx.r11.u32);
loc_82C933A4:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C933B0"))) PPC_WEAK_FUNC(sub_82C933B0);
PPC_FUNC_IMPL(__imp__sub_82C933B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82C933B8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// addi r4,r11,-29184
	ctx.r4.s64 = ctx.r11.s64 + -29184;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// bl 0x82c41f78
	ctx.lr = 0x82C933D8;
	sub_82C41F78(ctx, base);
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// stw r30,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r30.u32);
	// stw r29,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r29.u32);
	// stw r28,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r28.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C933F0"))) PPC_WEAK_FUNC(sub_82C933F0);
PPC_FUNC_IMPL(__imp__sub_82C933F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82c3fbc8
	ctx.lr = 0x82C93408;
	sub_82C3FBC8(ctx, base);
	// stw r31,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r31.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C93420"))) PPC_WEAK_FUNC(sub_82C93420);
PPC_FUNC_IMPL(__imp__sub_82C93420) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82C93428;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82C93430;
	__savefpr_14(ctx, base);
	// stwu r1,-624(r1)
	ea = -624 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82c94290
	if (!ctx.cr6.lt) goto loc_82C94290;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r10,288(r1)
	PPC_STORE_U32(ctx.r1.u32 + 288, ctx.r10.u32);
	// subf r10,r8,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r8.s64;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// stw r10,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r10.u32);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f13,-29000(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29000);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f0.f64 = double(temp.f32);
loc_82C93464:
	// mulli r8,r6,3
	ctx.r8.s64 = ctx.r6.s64 * 3;
	// lfs f12,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// add r5,r8,r7
	ctx.r5.u64 = ctx.r8.u64 + ctx.r7.u64;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f27,f10,f12
	ctx.f27.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// rlwinm r24,r5,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// rlwinm r26,r7,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f10,f11,f9
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// rlwinm r31,r7,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// add r23,r31,r10
	ctx.r23.u64 = ctx.r31.u64 + ctx.r10.u64;
	// add r22,r30,r10
	ctx.r22.u64 = ctx.r30.u64 + ctx.r10.u64;
	// lfsx f29,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// add r27,r6,r7
	ctx.r27.u64 = ctx.r6.u64 + ctx.r7.u64;
	// lfsx f2,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// mulli r8,r7,12
	ctx.r8.s64 = ctx.r7.s64 * 12;
	// lfsx f28,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f20,f29,f2
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// lfsx f1,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f2,f2,f29
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// lfsx f8,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f29,f1,f28
	ctx.f29.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// lfsx f9,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// lfsx f26,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f28,f8,f9
	ctx.f28.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// lfsx f7,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// lfsx f25,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fadds f8,f26,f7
	ctx.f8.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// mulli r20,r27,12
	ctx.r20.s64 = ctx.r27.s64 * 12;
	// lfsx f6,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// lfsx f24,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f5,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f26,f25,f6
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// fsubs f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f25.f64));
	// lfsx f31,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f25,f5,f24
	ctx.f25.f64 = double(float(ctx.f5.f64 - ctx.f24.f64));
	// lfsx f30,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f5,f24,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// lfsx f22,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f24,f22,f31
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f31.f64));
	// lfsx f21,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r9,r7,20
	ctx.r9.s64 = ctx.r7.s64 * 20;
	// fsubs f31,f31,f22
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f22.f64));
	// stfs f31,140(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fsubs f31,f30,f21
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f31,f21,f30
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f31,188(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfsx f4,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// add r21,r9,r10
	ctx.r21.u64 = ctx.r9.u64 + ctx.r10.u64;
	// mulli r5,r6,5
	ctx.r5.s64 = ctx.r6.s64 * 5;
	// lfsx f23,r4,r21
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r21.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f31,f4,f23
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f23.f64));
	// fadds f4,f23,f4
	ctx.f4.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// stfs f4,56(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// add r19,r5,r7
	ctx.r19.u64 = ctx.r5.u64 + ctx.r7.u64;
	// lfsx f4,r3,r21
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r21.u32);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r25,r6,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f30,f4,f3
	ctx.f30.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// rlwinm r17,r27,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// rlwinm r29,r6,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// stfs f30,136(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// rlwinm r16,r19,2,0,29
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f4,116(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// add r19,r25,r7
	ctx.r19.u64 = ctx.r25.u64 + ctx.r7.u64;
	// add r15,r29,r7
	ctx.r15.u64 = ctx.r29.u64 + ctx.r7.u64;
	// rlwinm r29,r6,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r17,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r17.u32);
	// mulli r5,r6,20
	ctx.r5.s64 = ctx.r6.s64 * 20;
	// rlwinm r28,r6,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r19,r19,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f14,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// rlwinm r18,r15,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r15.u32 | (ctx.r15.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// add r14,r16,r3
	ctx.r14.u64 = ctx.r16.u64 + ctx.r3.u64;
	// lfsx f14,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r16,r16,r4
	ctx.r16.u64 = ctx.r16.u64 + ctx.r4.u64;
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f23,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f14,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// stw r14,312(r1)
	PPC_STORE_U32(ctx.r1.u32 + 312, ctx.r14.u32);
	// stw r16,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r16.u32);
	// lfsx f30,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f14,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r16,r17,r4
	ctx.r16.u64 = ctx.r17.u64 + ctx.r4.u64;
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f14,f23,f30
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// lfsx f21,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// lfsx f22,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f4,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfsx f19,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfsx f18,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f21,f4,f19
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f19.f64));
	// lfsx f3,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f4.f64));
	// fsubs f4,f18,f3
	ctx.f4.f64 = double(float(ctx.f18.f64 - ctx.f3.f64));
	// stfs f4,16(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f18.f64));
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// stw r16,296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 296, ctx.r16.u32);
	// lfs f4,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f4.f64 = double(temp.f32);
	// fadds f18,f16,f4
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f4.f64));
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f16.f64));
	// stfs f4,76(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f4,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f4
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f4.f64));
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r17,112(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// fadds f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,72(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f18,f15
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f18,f21,f14
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f19,f30
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// fsubs f15,f22,f3
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f3.f64));
	// fsubs f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f16.f64));
	// fadds f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// stfs f3,192(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f3,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f3.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fadds f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f23.f64));
	// stfs f3,124(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fadds f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// stfs f21,128(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f30,152(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f3,f18,f0
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f3,224(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f3,f17,f0
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f3,220(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f3,f16,f0
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f3,200(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f3,f15,f0
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f3,216(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f3,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f30.f64 = double(temp.f32);
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f21,f3,f23
	ctx.f21.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// rlwinm r16,r7,1,0,30
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r15,r15,3,0,28
	ctx.r15.u64 = __builtin_rotateleft64(ctx.r15.u32 | (ctx.r15.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f19,f30,f22
	ctx.f19.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// add r16,r16,r6
	ctx.r16.u64 = ctx.r16.u64 + ctx.r6.u64;
	// fadds f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f23.f64));
	// stfs f3,120(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f3,f30,f22
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// stfs f3,72(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmuls f3,f21,f0
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// stfs f3,308(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// mulli r17,r7,3
	ctx.r17.s64 = ctx.r7.s64 * 3;
	// stw r15,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r15.u32);
	// lfs f30,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f30.f64 = double(temp.f32);
	// stw r16,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r16.u32);
	// fmuls f3,f19,f0
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f3,272(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// add r15,r8,r29
	ctx.r15.u64 = ctx.r8.u64 + ctx.r29.u64;
	// lfs f3,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f3.f64 = double(temp.f32);
	// add r14,r17,r6
	ctx.r14.u64 = ctx.r17.u64 + ctx.r6.u64;
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfs f3,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f3.f64 = double(temp.f32);
	// add r16,r31,r5
	ctx.r16.u64 = ctx.r31.u64 + ctx.r5.u64;
	// rlwinm r14,r14,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f23,f30,f3
	ctx.f23.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// fadds f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// stfs f3,76(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// rlwinm r17,r27,3,0,28
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r15,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r15.u32);
	// add r15,r8,r5
	ctx.r15.u64 = ctx.r8.u64 + ctx.r5.u64;
	// lfsx f22,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stw r16,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r16.u32);
	// stw r14,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r14.u32);
	// stw r15,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r15.u32);
	// add r15,r8,r28
	ctx.r15.u64 = ctx.r8.u64 + ctx.r28.u64;
	// fmuls f3,f23,f0
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f3,264(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f3,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f30,f3,f4
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// lfsx f23,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfsx f3,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,196(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// stw r15,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r15.u32);
	// lfsx f17,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// stfs f4,244(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfsx f4,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// rlwinm r14,r14,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r14,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r14.u32);
	// lwz r14,168(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lwz r16,184(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// lfsx f30,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f21,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f19,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lwz r14,96(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfsx f15,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r16,96(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,104(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfsx f14,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r16,160(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lfsx f14,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f14,f4,f3
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fadds f3,f22,f23
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f22,f18,f19
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f18,f16,f17
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r16,r7,5
	ctx.r16.s64 = ctx.r7.s64 * 5;
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// add r14,r16,r6
	ctx.r14.u64 = ctx.r16.u64 + ctx.r6.u64;
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f30.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f21
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lwz r16,20(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fsubs f21,f18,f22
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// fsubs f15,f17,f19
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// add r15,r26,r6
	ctx.r15.u64 = ctx.r26.u64 + ctx.r6.u64;
	// rlwinm r16,r16,3,0,28
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r16.u32 | (ctx.r16.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,180(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f22,f17,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f22,132(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// rlwinm r15,r15,2,0,29
	ctx.r15.u64 = __builtin_rotateleft64(ctx.r15.u32 | (ctx.r15.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f18,f4,f30
	ctx.f18.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// stw r16,40(r1)
	PPC_STORE_U32(ctx.r1.u32 + 40, ctx.r16.u32);
	// rlwinm r16,r27,4,0,27
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r27,r27,20
	ctx.r27.s64 = ctx.r27.s64 * 20;
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f4,164(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stw r15,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r15.u32);
	// fmuls f22,f21,f0
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// stfs f22,276(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f22,228(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// add r15,r9,r29
	ctx.r15.u64 = ctx.r9.u64 + ctx.r29.u64;
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// stw r27,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r27.u32);
	// add r27,r9,r28
	ctx.r27.u64 = ctx.r9.u64 + ctx.r28.u64;
	// fadds f4,f22,f14
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f4,68(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fsubs f19,f14,f22
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f4,f21,f3
	ctx.f4.f64 = double(float(ctx.f21.f64 + ctx.f3.f64));
	// stfs f4,156(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f21,f3
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f3.f64));
	// lfs f4,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// stw r27,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r27.u32);
	// rlwinm r27,r14,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// fadds f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// stfs f4,64(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f23,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// stw r27,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r27.u32);
	// fmuls f4,f19,f0
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f4,232(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f4,f18,f0
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f4,88(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f4,f17,f0
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f4,172(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f4,f15,f0
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f4,240(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lwz r27,24(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// add r14,r27,r4
	ctx.r14.u64 = ctx.r27.u64 + ctx.r4.u64;
	// add r27,r27,r3
	ctx.r27.u64 = ctx.r27.u64 + ctx.r3.u64;
	// stw r14,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r14.u32);
	// stw r27,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r27.u32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lwz r27,144(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// add r27,r27,r4
	ctx.r27.u64 = ctx.r27.u64 + ctx.r4.u64;
	// lfsx f22,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stw r27,44(r1)
	PPC_STORE_U32(ctx.r1.u32 + 44, ctx.r27.u32);
	// lwz r27,104(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfsx f4,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lwz r27,40(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lfsx f3,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// add r27,r30,r5
	ctx.r27.u64 = ctx.r30.u64 + ctx.r5.u64;
	// lfsx f30,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lwz r14,40(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lfsx f15,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f19,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f18,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f14,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f21,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,24(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f4.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f4,f4,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f15.f64));
	// fadds f15,f30,f3
	ctx.f15.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fsubs f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fadds f30,f22,f23
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fsubs f22,f21,f19
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lwz r14,32(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,44(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,100(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// fsubs f14,f16,f4
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// fadds f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f16.f64));
	// stfs f4,60(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// lfs f4,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f16.f64));
	// stfs f4,48(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f16,f23,f3
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f3.f64));
	// fadds f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f3,52(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fadds f3,f18,f21
	ctx.f3.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// stfs f3,284(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmuls f4,f17,f0
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f4,268(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f4,f14,f0
	ctx.f4.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f4,236(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fadds f4,f30,f15
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// stfs f4,252(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f17,f30,f15
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// fadds f30,f19,f22
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f30,36(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f15,f22,f19
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fsubs f14,f21,f18
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f19,f23,f22
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f30,f21
	ctx.f18.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,20(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lwz r14,144(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f17,208(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f17,256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f17,248(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f17,f14,f0
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stw r14,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r14.u32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f30,300(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// stfs f23,304(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fmuls f23,f18,f0
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f23,108(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f14,f4,f26
	ctx.f14.f64 = double(float(ctx.f4.f64 + ctx.f26.f64));
	// lfs f23,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f23,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f11.f64));
	// lfs f19,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f18,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f1.f64));
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fadds f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f8.f64));
	// fadds f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f9.f64));
	// lfs f4,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfsx f4,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,84(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lwz r14,92(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lfs f4,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// stfs f23,0(r3)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f22,0(r4)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfsx f21,r25,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// stfsx f19,r25,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// stfsx f18,r10,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f17,r29,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// stfsx f16,r29,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f3,r28,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r5,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f22.f64 = double(temp.f32);
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fadds f3,f4,f30
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// fsubs f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// fadds f30,f3,f22
	ctx.f30.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// fadds f23,f4,f21
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f21.f64));
	// fsubs f4,f4,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f21.f64));
	// fsubs f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// fmuls f22,f4,f0
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f4,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfsx f4,r5,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fadds f21,f23,f4
	ctx.f21.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// lfs f4,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// stfsx f14,r28,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f19,f4
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fmuls f16,f18,f4
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// lfs f4,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// fadds f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fmadds f18,f18,f4,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f17.f64));
	// stfsx f18,r10,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f19,f4,f16
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 - ctx.f16.f64));
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfs f19,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f4,f21
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// fmuls f17,f19,f21
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f19,f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 + ctx.f18.f64));
	// stfsx f19,r10,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f4,f21,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f21.f64 - ctx.f17.f64));
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,292(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// fadds f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f12.f64));
	// lfs f21,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f21,f4
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f4.f64));
	// fmuls f17,f19,f4
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f4,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fmadds f19,f19,f4,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 + ctx.f18.f64));
	// stfsx f19,r8,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f21,f4,f17
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 - ctx.f17.f64));
	// stfsx f4,r8,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f4.f64 = double(temp.f32);
	// fadds f19,f4,f25
	ctx.f19.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// lfs f4,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f4.f64 = double(temp.f32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f4,f17
	ctx.f17.f64 = double(float(ctx.f4.f64 + ctx.f17.f64));
	// lfs f4,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f4.f64 = double(temp.f32);
	// fadds f16,f4,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 + ctx.f16.f64));
	// lfs f4,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// fadds f15,f4,f7
	ctx.f15.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// lfs f4,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f4.f64 = double(temp.f32);
	// fadds f14,f4,f28
	ctx.f14.f64 = double(float(ctx.f4.f64 + ctx.f28.f64));
	// lfs f4,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f30,f13,f4
	ctx.f4.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// stfs f4,100(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f30,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f30.f64 = double(temp.f32);
	// lfs f4,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f4,f13,f30
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// stfs f4,56(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f4,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f6
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f21,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f30,f21,f4
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f4.f64));
	// fmuls f4,f18,f4
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// fmadds f30,f18,f19,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 + ctx.f30.f64));
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f21,f19,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f19.f64 - ctx.f4.f64));
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f30,f18,f19
	ctx.f30.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f3.f64));
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fadds f3,f18,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// fmuls f18,f4,f17
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// fmuls f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// fmadds f21,f21,f16,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64 + ctx.f18.f64));
	// stfsx f21,r20,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f4,f16,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f16.f64 - ctx.f17.f64));
	// stfsx f4,r20,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f4,f15
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f15.f64));
	// lfs f21,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f21,f15
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f15.f64));
	// fmadds f21,f21,f14,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f14.f64 + ctx.f18.f64));
	// lwz r10,184(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// fmsubs f4,f4,f14,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f14.f64 - ctx.f17.f64));
	// lfs f16,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f16.f64 = double(temp.f32);
	// addi r8,r11,32
	ctx.r8.s64 = ctx.r11.s64 + 32;
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// addi r5,r11,36
	ctx.r5.s64 = ctx.r11.s64 + 36;
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,212(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// lfs f4,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f4,f30
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmuls f17,f21,f30
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f21,f21,f30,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 + ctx.f18.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f4,f30,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 - ctx.f17.f64));
	// stfsx f4,r10,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f4.f64 = double(temp.f32);
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// lfs f30,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f4,f19
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f19,f30,f19
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f30,f30,f3,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f3.f64 + ctx.f21.f64));
	// stfsx f30,r27,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f4,f3,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 - ctx.f19.f64));
	// lfs f3,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f12,f3,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// lfs f3,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f10,f3,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// lfs f30,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f30.f64 = double(temp.f32);
	// lfs f3,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f3,f3,f13,f30
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// lfs f21,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f21.f64 = double(temp.f32);
	// lfs f30,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f30,f30,f13,f21
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f21.f64)));
	// lfs f21,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f8,f21,f13,f8
	ctx.f8.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// lfs f21,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f9,f21,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// stfsx f4,r27,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f12,f18
	ctx.f19.f64 = double(float(ctx.f12.f64 + ctx.f18.f64));
	// fsubs f12,f12,f18
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f18.f64));
	// fadds f18,f10,f17
	ctx.f18.f64 = double(float(ctx.f10.f64 + ctx.f17.f64));
	// fsubs f10,f10,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f17.f64));
	// fadds f17,f3,f16
	ctx.f17.f64 = double(float(ctx.f3.f64 + ctx.f16.f64));
	// fsubs f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f16.f64));
	// fadds f16,f30,f15
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// fsubs f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f15.f64));
	// fsubs f15,f8,f14
	ctx.f15.f64 = double(float(ctx.f8.f64 - ctx.f14.f64));
	// fadds f8,f8,f14
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 - ctx.f14.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fadds f9,f9,f14
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f14.f64));
	// fmuls f14,f4,f19
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// fmadds f21,f21,f18,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f18.f64 + ctx.f14.f64));
	// stfsx f21,r26,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f4,f4,f18,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f18.f64 - ctx.f19.f64));
	// stfsx f4,r26,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f4,f12
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmuls f12,f21,f12
	ctx.f12.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmadds f21,f21,f10,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f19.f64));
	// stfsx f21,r9,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f4,f10,f12
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 - ctx.f12.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f12,f17
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// lfs f10,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f21,f10,f17
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// fmadds f10,f10,f16,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f16.f64 + ctx.f4.f64));
	// stfsx f10,r24,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f16,f21
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f16.f64 - ctx.f21.f64));
	// stfsx f12,r24,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,40(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lfs f10,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f12,f3
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f3,f10,f3
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f21,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f10,f10,f30,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 + ctx.f4.f64));
	// stfsx f10,r3,r21
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + ctx.r21.u32, temp.u32);
	// fmsubs f12,f12,f30,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f3.f64));
	// stfsx f12,r4,r21
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + ctx.r21.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f12,f15
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f15.f64));
	// fmuls f30,f10,f15
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f15.f64));
	// lfs f4,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f10,f10,f4,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f3.f64));
	// lfs f3,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f12,f12,f4,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 - ctx.f30.f64));
	// lfs f4,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f4,f13,f24
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f24.f64)));
	// lfs f30,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f10,r17,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fnmsubs f3,f3,f13,f30
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// stfsx f12,r17,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f30.f64 = double(temp.f32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f30,f30,f13,f20
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f20.f64)));
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f19,f12,f8
	ctx.f19.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmuls f18,f10,f8
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f24,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f1,f24,f13,f1
	ctx.f1.f64 = double(float(-(ctx.f24.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// lfs f20,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f8,f4,f20
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f20.f64));
	// fadds f4,f4,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f20.f64));
	// lfs f20,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f24,f3,f21
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f21.f64));
	// fadds f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f21.f64));
	// fsubs f21,f30,f20
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// fadds f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f20.f64));
	// lfs f20,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f10,f10,f9,f19
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 + ctx.f19.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f9,f18
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 - ctx.f18.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f10,f1,f20
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f20.f64));
	// fadds f9,f1,f20
	ctx.f9.f64 = double(float(ctx.f1.f64 + ctx.f20.f64));
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f12,f8
	ctx.f20.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lwz r9,160(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// fmuls f8,f1,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmadds f1,f1,f24,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64 + ctx.f20.f64));
	// stfsx f1,r23,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f24,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f24.f64 - ctx.f8.f64));
	// stfsx f12,r23,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f1,f12,f4
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmuls f4,f8,f4
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmadds f8,f8,f3,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 + ctx.f1.f64));
	// stfsx f8,r22,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f3,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 - ctx.f4.f64));
	// stfsx f12,r22,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f12,f21
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// fmuls f3,f8,f21
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// lfs f1,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f8,f8,f10,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 + ctx.f4.f64));
	// stfsx f8,r9,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f10,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f3.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f12,f30
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f8,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f10,f30
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fnmsubs f8,f8,f13,f26
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// lwz r9,28(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// fmadds f12,f12,f9,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f4.f64));
	// lfs f4,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f5,f1,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fnmsubs f11,f4,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// lfs f4,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f7,f4,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f1,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f1.f64 = double(temp.f32);
	// lfs f30,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f10,f9,f3
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f3.f64));
	// lfs f3,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f4,f8,f3
	ctx.f4.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fadds f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// lwz r9,168(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lfs f9,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f3,f5,f1
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// lfs f26,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f9,f9,f13,f27
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f27.f64)));
	// lfs f27,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f27.f64 = double(temp.f32);
	// fadds f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f24,f12,f4
	ctx.f24.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmuls f4,f10,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// fsubs f1,f9,f30
	ctx.f1.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// fadds f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// fsubs f30,f11,f27
	ctx.f30.f64 = double(float(ctx.f11.f64 - ctx.f27.f64));
	// fadds f11,f11,f27
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f27.f64));
	// fadds f27,f7,f26
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// fmadds f10,f10,f3,f24
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f24.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f3,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 - ctx.f4.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f12,f8
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmuls f8,f10,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f3,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f10,f10,f5,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f5.f64 + ctx.f4.f64));
	// stfsx f10,r16,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f5,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 - ctx.f8.f64));
	// stfsx f12,r16,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f12,f1
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// fmuls f5,f10,f1
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f10,f10,f30,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 + ctx.f8.f64));
	// stfsx f10,r31,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f30,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f5.f64));
	// stfsx f12,r31,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f12,f9
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmuls f9,f10,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f5,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f5,f5,f13,f29
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// fmadds f10,f10,f11,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f8.f64));
	// lfs f8,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f12,f12,f11,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f9.f64));
	// lfs f9,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f9,f9,f13,f28
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f28.f64)));
	// stfsx f10,r30,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fnmsubs f8,f8,f13,f6
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// lfs f6,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f6.f64 = double(temp.f32);
	// stfsx f12,r30,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fnmsubs f6,f6,f13,f2
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// lfs f2,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f10,f7,f26
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f28,f12,f27
	ctx.f28.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// lfs f7,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f11,f27
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// fnmsubs f7,f7,f13,f25
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// fadds f4,f9,f3
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// fsubs f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f3.f64));
	// fadds f3,f8,f2
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fsubs f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// fmadds f11,f11,f4,f28
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f4.f64 + ctx.f28.f64));
	// stfsx f11,r18,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f4,f27
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 - ctx.f27.f64));
	// stfsx f12,r18,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fadds f2,f7,f1
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f12,f10
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fmuls f10,f11,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f30,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f1.f64));
	// lwz r9,16(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fadds f1,f6,f30
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// lfs f29,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// lwz r31,288(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	// fadds f30,f5,f29
	ctx.f30.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fsubs f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f29.f64));
	// fmadds f11,f11,f9,f4
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f4.f64));
	// stfsx f11,r15,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 - ctx.f10.f64));
	// stfsx f12,r15,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f3
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f9,f11,f3
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmadds f11,f11,f2,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f10.f64));
	// stfsx f11,r19,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f2,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 - ctx.f9.f64));
	// stfsx f12,r19,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f8
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmuls f9,f11,f8
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// fmadds f11,f11,f7,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f10.f64));
	// stfsx f11,r9,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f7,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 - ctx.f9.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,280(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// fmuls f10,f12,f1
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// lfs f9,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f9,f9,f13,f31
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// fmadds f10,f11,f30,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f10.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmuls f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// lwz r31,296(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// lfs f10,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f10,f23,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// lwz r9,176(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// fadds f7,f9,f22
	ctx.f7.f64 = double(float(ctx.f9.f64 + ctx.f22.f64));
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// fsubs f9,f9,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f22.f64));
	// stw r9,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r9.u32);
	// fmsubs f12,f12,f30,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f11.f64));
	// stfs f12,0(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,44(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f12,f6
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// fmuls f3,f11,f6
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f6,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f6.f64 = double(temp.f32);
	// fadds f8,f10,f6
	ctx.f8.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fmadds f11,f11,f5,f4
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64 + ctx.f4.f64));
	// stfs f11,0(r14)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fmsubs f12,f12,f5,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 - ctx.f3.f64));
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f12,f8
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmuls f8,f11,f8
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lwz r10,312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	// fmadds f11,f11,f7,f6
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f6.f64));
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// fmsubs f12,f12,f7,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 - ctx.f8.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,32(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f11,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// fmadds f11,f11,f9,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f8.f64));
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,24(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// fmsubs f12,f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 - ctx.f10.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,-26212(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// xor r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// bne 0x82c93464
	if (!ctx.cr0.eq) goto loc_82C93464;
loc_82C94290:
	// addi r1,r1,624
	ctx.r1.s64 = ctx.r1.s64 + 624;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82C9429C;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C942A0"))) PPC_WEAK_FUNC(sub_82C942A0);
PPC_FUNC_IMPL(__imp__sub_82C942A0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29160
	ctx.r5.s64 = ctx.r11.s64 + -29160;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,13344
	ctx.r4.s64 = ctx.r11.s64 + 13344;
	// b 0x82cab890
	sub_82CAB890(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C942B8"))) PPC_WEAK_FUNC(sub_82C942B8);
PPC_FUNC_IMPL(__imp__sub_82C942B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82C942C0;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82C942C8;
	__savefpr_14(ctx, base);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82c94d1c
	if (!ctx.cr6.lt) goto loc_82C94D1C;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r5,-32255
	ctx.r5.s64 = -2113863680;
	// stw r10,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r10.u32);
	// subf r10,r8,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r8.s64;
	// lis r8,-32235
	ctx.r8.s64 = -2112552960;
	// lfs f11,-12748(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -12748);
	ctx.f11.f64 = double(temp.f32);
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// stw r10,-352(r1)
	PPC_STORE_U32(ctx.r1.u32 + -352, ctx.r10.u32);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f13,28204(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 28204);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28208(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28208);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,28200(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28200);
	ctx.f12.f64 = double(temp.f32);
loc_82C94308:
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfs f10,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r5,r6,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f4,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r31,r6,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// add r27,r6,r7
	ctx.r27.u64 = ctx.r6.u64 + ctx.r7.u64;
	// rlwinm r9,r6,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// mulli r30,r6,3
	ctx.r30.s64 = ctx.r6.s64 * 3;
	// lfsx f7,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f29,f6,f7
	ctx.f29.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfsx f8,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// lfsx f2,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f28,f2,f8
	ctx.f28.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// lfsx f1,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f5,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// lfsx f3,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f27,f1,f3
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// rlwinm r28,r27,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// add r30,r30,r7
	ctx.r30.u64 = ctx.r30.u64 + ctx.r7.u64;
	// add r29,r8,r7
	ctx.r29.u64 = ctx.r8.u64 + ctx.r7.u64;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f24,f7,f13
	ctx.f24.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// rlwinm r26,r30,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r25,r29,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f26,f28,f29
	ctx.f26.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// add r16,r28,r3
	ctx.r16.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fsubs f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fmuls f28,f8,f13
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// rlwinm r23,r7,1,0,30
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// fadds f25,f27,f6
	ctx.f25.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// rlwinm r22,r9,3,0,28
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f2,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f6.f64));
	// lfsx f31,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f23,f5,f13
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfsx f4,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f31,f2
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// lfs f1,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fmuls f22,f3,f13
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// add r20,r23,r6
	ctx.r20.u64 = ctx.r23.u64 + ctx.r6.u64;
	// fmadds f8,f8,f0,f24
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f24.f64));
	// add r15,r28,r4
	ctx.r15.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fadds f24,f4,f1
	ctx.f24.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// rlwinm r9,r20,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r9,r3
	ctx.r28.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmuls f31,f29,f12
	ctx.f31.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fmsubs f7,f7,f0,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 - ctx.f28.f64));
	// fmuls f29,f27,f12
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// rlwinm r23,r27,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f3,f3,f0,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f23.f64));
	// lfs f23,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f30,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f28,f26,f11,f10
	ctx.f28.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// fmuls f19,f2,f13
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfsx f21,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f5,f5,f0,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f22.f64));
	// lfsx f22,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f27,f25,f11,f9
	ctx.f27.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// add r21,r29,r10
	ctx.r21.u64 = ctx.r29.u64 + ctx.r10.u64;
	// fsubs f20,f24,f6
	ctx.f20.f64 = double(float(ctx.f24.f64 - ctx.f6.f64));
	// stw r28,-328(r1)
	PPC_STORE_U32(ctx.r1.u32 + -328, ctx.r28.u32);
	// fmuls f18,f4,f13
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fadds f1,f24,f6
	ctx.f1.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// lfsx f6,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f24,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f4,f4,f0,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f19.f64));
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmsubs f2,f2,f0,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f18.f64));
	// fadds f16,f24,f6
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// lfsx f18,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f6,f6,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f24.f64));
	// lfsx f19,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// add r19,r30,r6
	ctx.r19.u64 = ctx.r30.u64 + ctx.r6.u64;
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// rlwinm r20,r20,3,0,28
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 3) & 0xFFFFFFF8;
	// fnmsubs f22,f1,f11,f30
	ctx.f22.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f30.f64)));
	// stfs f22,-340(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f22,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r18,r19,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f22,-392(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfsx f17,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// add r14,r18,r4
	ctx.r14.u64 = ctx.r18.u64 + ctx.r4.u64;
	// rlwinm r17,r27,4,0,27
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f15,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// add r18,r18,r3
	ctx.r18.u64 = ctx.r18.u64 + ctx.r3.u64;
	// fmuls f22,f6,f13
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// stw r9,-320(r1)
	PPC_STORE_U32(ctx.r1.u32 + -320, ctx.r9.u32);
	// fadds f14,f24,f16
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmuls f14,f23,f13
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fsubs f16,f24,f16
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// stw r18,-312(r1)
	PPC_STORE_U32(ctx.r1.u32 + -312, ctx.r18.u32);
	// fmadds f24,f23,f0,f22
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f22.f64));
	// fmsubs f23,f6,f0,f14
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 - ctx.f14.f64));
	// fmuls f6,f16,f12
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f6,-332(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f6,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r28,r7,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f16,f18,f6
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f6.f64));
	// fsubs f6,f6,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f18.f64));
	// add r19,r28,r10
	ctx.r19.u64 = ctx.r28.u64 + ctx.r10.u64;
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,-392(r1)
	PPC_STORE_U32(ctx.r1.u32 + -392, ctx.r14.u32);
	// fadds f22,f14,f19
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// add r14,r17,r4
	ctx.r14.u64 = ctx.r17.u64 + ctx.r4.u64;
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f18,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f18.f64 = double(temp.f32);
	// stw r14,-336(r1)
	PPC_STORE_U32(ctx.r1.u32 + -336, ctx.r14.u32);
	// fnmsubs f18,f18,f11,f21
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// stfs f18,-348(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f18,f16,f22
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f18,-444(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// fmuls f14,f19,f13
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f16,f6,f13
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f22,-368(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fmadds f6,f6,f0,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f14.f64));
	// stfs f6,-324(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmsubs f22,f19,f0,f16
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 - ctx.f16.f64));
	// stfs f22,-360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fnmsubs f6,f18,f11,f17
	ctx.f6.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f17.f64)));
	// stfs f6,-356(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfsx f6,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f22,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f14,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fadds f14,f22,f6
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f6.f64));
	// lfs f19,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f22.f64));
	// lfsx f18,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// add r9,r17,r3
	ctx.r9.u64 = ctx.r17.u64 + ctx.r3.u64;
	// stfs f6,-424(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fadds f6,f18,f19
	ctx.f6.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f6,-404(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfsx f6,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,-400(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfsx f16,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stw r9,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r9.u32);
	// lfsx f6,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// stfs f16,-380(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// stfs f14,-416(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// stfs f6,-388(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfsx f16,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f6,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lwz r9,-392(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	// stfs f6,-396(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f22,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fadds f25,f25,f9
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f9.f64));
	// lfs f9,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f9.f64 = double(temp.f32);
	// fadds f26,f26,f10
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f10.f64));
	// fadds f21,f9,f21
	ctx.f21.f64 = double(float(ctx.f9.f64 + ctx.f21.f64));
	// lfs f9,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f9.f64 = double(temp.f32);
	// fadds f10,f1,f30
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// lfs f6,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fadds f17,f9,f17
	ctx.f17.f64 = double(float(ctx.f9.f64 + ctx.f17.f64));
	// fadds f18,f22,f6
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f6.f64));
	// stfs f18,-432(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fsubs f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f22.f64));
	// stfs f6,-436(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f6,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// mulli r9,r7,12
	ctx.r9.s64 = ctx.r7.s64 * 12;
	// fsubs f22,f6,f14
	ctx.f22.f64 = double(float(ctx.f6.f64 - ctx.f14.f64));
	// stfs f22,-420(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f22,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f22.f64 = double(temp.f32);
	// fadds f6,f14,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 + ctx.f6.f64));
	// lfs f18,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f18.f64 = double(temp.f32);
	// mulli r18,r7,3
	ctx.r18.s64 = ctx.r7.s64 * 3;
	// fadds f18,f18,f22
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f18,-448(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// stfs f6,-440(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmuls f18,f19,f13
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f6,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// fmadds f6,f19,f0,f6
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f6.f64));
	// stfs f6,-372(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f6,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f6,f6,f0,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 - ctx.f18.f64));
	// stfs f6,-408(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fmuls f6,f22,f12
	ctx.f6.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f22.f64 = double(temp.f32);
	// stfs f6,-364(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fadds f6,f22,f16
	ctx.f6.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// fsubs f19,f16,f22
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// lfs f22,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f22.f64 = double(temp.f32);
	// stfs f19,-416(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f16,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f16,f22
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f18,-412(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f22,-424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f22,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f16,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f14,f14,f11,f15
	ctx.f14.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f15.f64)));
	// stfs f14,-396(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f6.f64));
	// stfs f14,-404(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f6.f64));
	// lfs f6,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 - ctx.f18.f64));
	// lfs f6,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f6,f6,f0,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f19.f64));
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// lfs f19,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f19,f0,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 - ctx.f22.f64));
	// fmuls f19,f14,f12
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f14,f0,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 - ctx.f16.f64));
	// stfs f16,-384(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f16,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f16,f14,f11,f16
	ctx.f16.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f16.f64)));
	// stfs f16,-388(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f14,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// add r18,r18,r6
	ctx.r18.u64 = ctx.r18.u64 + ctx.r6.u64;
	// lfs f9,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f9.f64 = double(temp.f32);
	// mulli r27,r27,12
	ctx.r27.s64 = ctx.r27.s64 * 12;
	// stfs f10,-432(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fmadds f10,f9,f0,f14
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f14.f64));
	// lfs f9,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f1,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f14,f9,f15
	ctx.f14.f64 = double(float(ctx.f9.f64 + ctx.f15.f64));
	// stfs f1,-424(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfsx f1,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f30,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-440(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// rlwinm r14,r18,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r18.u32 | (ctx.r18.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f1,-412(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// add r18,r9,r5
	ctx.r18.u64 = ctx.r9.u64 + ctx.r5.u64;
	// lfsx f1,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// add r17,r9,r31
	ctx.r17.u64 = ctx.r9.u64 + ctx.r31.u64;
	// lfs f9,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f9,f16,f11,f9
	ctx.f9.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// stw r14,-444(r1)
	PPC_STORE_U32(ctx.r1.u32 + -444, ctx.r14.u32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,-416(r1)
	PPC_STORE_U32(ctx.r1.u32 + -416, ctx.r14.u32);
	// lwz r14,-444(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,-444(r1)
	PPC_STORE_U32(ctx.r1.u32 + -444, ctx.r14.u32);
	// lwz r14,-416(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	// lfs f30,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-448(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lwz r14,-444(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	// lfs f30,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-436(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfsx f30,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-444(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfsx f30,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-420(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfsx f30,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,-428(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfsx f30,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f26,0(r3)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f25,0(r4)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f26,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f26,r8,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f21,r8,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// stfsx f17,r5,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f15.f64 = double(temp.f32);
	// fadds f26,f1,f15
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f15.f64));
	// fsubs f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 - ctx.f1.f64));
	// stfs f1,-432(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// lfs f1,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// stfs f1,-448(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f21,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f21.f64 = double(temp.f32);
	// fadds f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// lfs f21,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// lfs f1,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f30,f17
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// fsubs f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f30.f64));
	// stfs f1,-376(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// stfs f30,-444(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fadds f15,f25,f26
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f15,-420(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f1,-440(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fadds f25,f17,f21
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f25,-428(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmuls f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fsubs f17,f17,f21
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// fmuls f1,f26,f12
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f15,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// lfs f25,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// stfs f30,-436(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f26,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f26.f64 = double(temp.f32);
	// addi r8,r11,4
	ctx.r8.s64 = ctx.r11.s64 + 4;
	// fmsubs f30,f26,f0,f25
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 - ctx.f25.f64));
	// lfs f26,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f0,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f15.f64));
	// lfs f15,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f25,f0,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f15.f64));
	// lfs f21,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f21.f64 = double(temp.f32);
	// stfs f17,-432(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f17,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f14,r5,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// addi r5,r11,28
	ctx.r5.s64 = ctx.r11.s64 + 28;
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f21,f21,f0,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 - ctx.f15.f64));
	// lfs f15,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f17,f15,f11,f17
	ctx.f17.f64 = double(float(-(ctx.f15.f64 * ctx.f11.f64 - ctx.f17.f64)));
	// stfs f17,-436(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f17,f17,f11,f15
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f15.f64)));
	// fadds f15,f28,f31
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// stfs f15,-448(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// fadds f15,f27,f29
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfs f15,-440(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r31,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfsx f16,r31,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f27,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f16,r10,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f15,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f15.f64 = double(temp.f32);
	// lfs f27,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfsx f16,r10,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f16,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// addi r10,r11,24
	ctx.r10.s64 = ctx.r11.s64 + 24;
	// lfs f15,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f3.f64));
	// stfs f14,-376(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f8
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// stfs f14,-444(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f3,f14,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 - ctx.f3.f64));
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// fadds f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 + ctx.f8.f64));
	// fsubs f14,f31,f5
	ctx.f14.f64 = double(float(ctx.f31.f64 - ctx.f5.f64));
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fadds f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// lfs f31,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f31.f64 = double(temp.f32);
	// fadds f14,f29,f7
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fsubs f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 - ctx.f7.f64));
	// fsubs f29,f28,f31
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// stfs f29,-408(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// stfs f31,-380(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f31,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// stfs f31,-400(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f31,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f29,f16,f31
	ctx.f29.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fmuls f28,f15,f31
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// lfs f31,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f29,f15,f31,f29
	ctx.f29.f64 = double(float(ctx.f15.f64 * ctx.f31.f64 + ctx.f29.f64));
	// stfsx f29,r30,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f31,f16,f31,f28
	ctx.f31.f64 = double(float(ctx.f16.f64 * ctx.f31.f64 - ctx.f28.f64));
	// stfsx f31,r30,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f31,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f29,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f3
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// fmuls f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f29,f29,f8,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f28.f64));
	// stfsx f29,r28,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f31,f8,f3
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 - ctx.f3.f64));
	// stfsx f8,r28,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f31,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f31.f64 = double(temp.f32);
	// lfs f3,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f29,f8,f31
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f31,f3,f31
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f28,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f3,f3,f14,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f14.f64 + ctx.f29.f64));
	// stfsx f3,r29,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f14,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f14.f64 - ctx.f31.f64));
	// stfsx f8,r29,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f31,f8,f5
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// lfs f3,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f29,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// lfs f28,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f3,f3,f7,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 + ctx.f31.f64));
	// stfsx f3,r9,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f3,f9,f18
	ctx.f3.f64 = double(float(ctx.f9.f64 - ctx.f18.f64));
	// lfs f31,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f8,f8,f7,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f5.f64));
	// lfs f5,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f31,f31,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f19.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 - ctx.f5.f64));
	// lfs f27,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f27.f64 = double(temp.f32);
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f8,f27
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f14,f7,f27
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// fsubs f27,f3,f22
	ctx.f27.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// fadds f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// lfs f22,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f22.f64 = double(temp.f32);
	// fadds f16,f31,f16
	ctx.f16.f64 = double(float(ctx.f31.f64 + ctx.f16.f64));
	// fsubs f31,f31,f22
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f22.f64));
	// lfs f22,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f29,f22
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f22.f64));
	// stfs f22,-408(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f22,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f7,f22,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f22.f64 + ctx.f15.f64));
	// lfs f15,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f7,r23,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f22,f14
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f22,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f7,f28,f15
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfsx f8,r23,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fadds f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f29,f29,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f22.f64));
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f8,f15
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f15.f64));
	// fmuls f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// fmadds f22,f22,f5,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 + ctx.f14.f64));
	// stfsx f22,r18,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f5,f15
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 - ctx.f15.f64));
	// stfsx f8,r18,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f8,f27
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// fmadds f5,f5,f16,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f16.f64 + ctx.f22.f64));
	// stfsx f5,r22,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f16,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f16.f64 - ctx.f27.f64));
	// stfsx f8,r22,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f8,f3
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fadds f9,f9,f18
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f18.f64));
	// fmadds f5,f5,f31,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 + ctx.f27.f64));
	// stfsx f5,r17,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f31,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f31.f64 - ctx.f3.f64));
	// stfsx f8,r17,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f3,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f3.f64 = double(temp.f32);
	// lfs f5,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f31,f8,f3
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// fmuls f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f27,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f5,f5,f7,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f31.f64));
	// stfsx f5,r24,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f7,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f3.f64));
	// stfsx f8,r24,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f8,f29
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f29,f7,f29
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// lfs f31,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f31.f64 = double(temp.f32);
	// fadds f3,f17,f31
	ctx.f3.f64 = double(float(ctx.f17.f64 + ctx.f31.f64));
	// fmadds f5,f7,f28,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 + ctx.f5.f64));
	// stfsx f5,r20,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f27,f1
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fsubs f7,f27,f1
	ctx.f7.f64 = double(float(ctx.f27.f64 - ctx.f1.f64));
	// fsubs f1,f17,f31
	ctx.f1.f64 = double(float(ctx.f17.f64 - ctx.f31.f64));
	// lfs f31,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f8,f8,f28,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 - ctx.f29.f64));
	// stfsx f8,r20,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fadds f31,f31,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f19.f64));
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f29,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f27,f3,f26
	ctx.f27.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// fadds f3,f3,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f26.f64));
	// fadds f28,f5,f25
	ctx.f28.f64 = double(float(ctx.f5.f64 + ctx.f25.f64));
	// fsubs f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f25.f64));
	// fadds f25,f1,f30
	ctx.f25.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fsubs f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fadds f30,f9,f6
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// fsubs f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fsubs f22,f31,f10
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f10.f64));
	// fadds f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f26,f7,f21
	ctx.f26.f64 = double(float(ctx.f7.f64 - ctx.f21.f64));
	// fadds f7,f7,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f21.f64));
	// fmuls f6,f8,f28
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// fmuls f31,f29,f28
	ctx.f31.f64 = double(float(ctx.f29.f64 * ctx.f28.f64));
	// fmadds f6,f29,f27,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f27.f64 + ctx.f6.f64));
	// stfsx f6,r26,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f27,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 - ctx.f31.f64));
	// stfsx f8,r26,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f31,f8,f5
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f5,f6,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmadds f6,f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 + ctx.f31.f64));
	// stfsx f6,r19,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 - ctx.f5.f64));
	// stfsx f8,r19,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f8,f26
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmuls f3,f6,f26
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmadds f6,f6,f25,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f5.f64));
	// stfsx f6,r21,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f25,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f25.f64 - ctx.f3.f64));
	// stfsx f8,r21,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f8,f7
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmadds f6,f6,f1,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f5.f64));
	// stfsx f6,r27,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f1,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f1.f64 - ctx.f7.f64));
	// stfsx f8,r27,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f8,f30
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f5,f7,f30
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmadds f7,f7,f22,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f22.f64 + ctx.f6.f64));
	// stfsx f7,r25,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f8,f8,f22,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f22.f64 - ctx.f5.f64));
	// lwz r9,-352(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	// stfsx f8,r25,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lwz r31,-316(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// lfs f7,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f3,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f29,f7,f9
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fsubs f8,f3,f20
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f20.f64));
	// lfs f5,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f28,f5,f9
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f31,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f1.f64 = double(temp.f32);
	// fadds f3,f3,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f20.f64));
	// stw r9,-352(r1)
	PPC_STORE_U32(ctx.r1.u32 + -352, ctx.r9.u32);
	// fsubs f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// lwz r9,-344(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmadds f5,f5,f10,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f29.f64));
	// stfs f5,0(r9)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fsubs f31,f8,f23
	ctx.f31.f64 = double(float(ctx.f8.f64 - ctx.f23.f64));
	// lwz r9,-336(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	// fmsubs f10,f7,f10,f28
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f10.f64 - ctx.f28.f64));
	// fadds f8,f8,f23
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f23.f64));
	// fadds f9,f6,f2
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fsubs f30,f1,f4
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// stfs f10,0(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r9,-328(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fadds f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// lfs f7,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// fadds f2,f3,f24
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f24.f64));
	// fsubs f3,f3,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f24.f64));
	// fmuls f5,f10,f31
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f1,f7,f31
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmadds f7,f7,f9,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 + ctx.f5.f64));
	// stfs f7,0(r9)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r9,-320(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	// fmsubs f10,f10,f9,f1
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f1.f64));
	// stfs f10,0(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r9,-416(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f8,f9,f8
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmadds f9,f9,f6,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f6.f64 + ctx.f7.f64));
	// stfs f9,0(r9)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fmsubs f10,f10,f6,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f6.f64 - ctx.f8.f64));
	// stfs f10,0(r14)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// lfs f9,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f10,f2
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmuls f7,f9,f2
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmadds f9,f9,f30,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f8.f64));
	// stfs f9,0(r16)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fmsubs f10,f10,f30,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 - ctx.f7.f64));
	// stfs f10,0(r15)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// lfs f10,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,-312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	// fmuls f8,f10,f3
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f9,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f9,f3
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmadds f9,f9,f4,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64 + ctx.f8.f64));
	// stfs f9,0(r10)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-392(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	// fmsubs f10,f10,f4,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 - ctx.f7.f64));
	// stfs f10,0(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,-26212(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// xor r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// bne 0x82c94308
	if (!ctx.cr0.eq) goto loc_82C94308;
loc_82C94D1C:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82C94D24;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C94D28"))) PPC_WEAK_FUNC(sub_82C94D28);
PPC_FUNC_IMPL(__imp__sub_82C94D28) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29088
	ctx.r5.s64 = ctx.r11.s64 + -29088;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,17080
	ctx.r4.s64 = ctx.r11.s64 + 17080;
	// b 0x82cab890
	sub_82CAB890(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C94D40"))) PPC_WEAK_FUNC(sub_82C94D40);
PPC_FUNC_IMPL(__imp__sub_82C94D40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b4
	ctx.lr = 0x82C94D48;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c554
	ctx.lr = 0x82C94D50;
	__savefpr_19(ctx, base);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82c94fac
	if (!ctx.cr6.lt) goto loc_82C94FAC;
	// rlwinm r24,r10,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r28,r8,r9
	ctx.r28.s64 = ctx.r9.s64 - ctx.r8.s64;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f13,28136(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29000(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29000);
	ctx.f0.f64 = double(temp.f32);
loc_82C94D7C:
	// rlwinm r9,r6,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f12,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r7,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// add r8,r9,r7
	ctx.r8.u64 = ctx.r9.u64 + ctx.r7.u64;
	// add r5,r10,r6
	ctx.r5.u64 = ctx.r10.u64 + ctx.r6.u64;
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r30,r6,r7
	ctx.r30.u64 = ctx.r6.u64 + ctx.r7.u64;
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r31,r30,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f10,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// add r26,r29,r4
	ctx.r26.u64 = ctx.r29.u64 + ctx.r4.u64;
	// lfsx f9,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r8,r5,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f25,f9,f10
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfsx f7,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r30,r30,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// rlwinm r27,r7,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f29,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f6,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfsx f28,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f7,f6,f29
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// lfs f5,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// add r25,r27,r4
	ctx.r25.u64 = ctx.r27.u64 + ctx.r4.u64;
	// rlwinm r5,r7,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f4,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// add r27,r27,r3
	ctx.r27.u64 = ctx.r27.u64 + ctx.r3.u64;
	// lfsx f27,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f24,f5,f28
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f28.f64));
	// lfsx f3,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f26,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f23,f27,f4
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// fsubs f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// lfs f31,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 - ctx.f5.f64));
	// lfsx f2,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f22,f26,f3
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// lfsx f1,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f29,f4,f27
	ctx.f29.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// lfs f30,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f4,f25,f0,f12
	ctx.f4.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fadds f12,f25,f12
	ctx.f12.f64 = double(float(ctx.f25.f64 + ctx.f12.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f12,f7,f2
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f24,f1
	ctx.f12.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fnmsubs f27,f7,f0,f2
	ctx.f27.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// addi r10,r11,8
	ctx.r10.s64 = ctx.r11.s64 + 8;
	// fadds f12,f23,f31
	ctx.f12.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fnmsubs f21,f24,f0,f1
	ctx.f21.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f5,f5,f13
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fnmsubs f20,f23,f0,f31
	ctx.f20.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f31.f64)));
	// fmuls f29,f29,f13
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fnmsubs f28,f10,f0,f11
	ctx.f28.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// fnmsubs f19,f22,f0,f30
	ctx.f19.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f30.f64)));
	// fsubs f31,f26,f3
	ctx.f31.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fmuls f9,f9,f13
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fadds f12,f22,f30
	ctx.f12.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f2,f21,f6
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f6.f64));
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f3,f27,f5
	ctx.f3.f64 = double(float(ctx.f27.f64 - ctx.f5.f64));
	// addi r9,r11,12
	ctx.r9.s64 = ctx.r11.s64 + 12;
	// fadds f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f27.f64));
	// fadds f6,f21,f6
	ctx.f6.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// fsubs f7,f19,f29
	ctx.f7.f64 = double(float(ctx.f19.f64 - ctx.f29.f64));
	// fadds f1,f19,f29
	ctx.f1.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// fadds f10,f28,f9
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f9.f64));
	// fadds f12,f8,f4
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// fmuls f31,f31,f13
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// lfs f30,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f11,f12
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmuls f12,f30,f12
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// fsubs f29,f20,f31
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// fadds f31,f31,f20
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// fmadds f30,f30,f10,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 + ctx.f27.f64));
	// stfsx f30,r5,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f11,f10,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 - ctx.f12.f64));
	// stfsx f12,r5,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f7
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// fmuls f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmadds f11,f11,f29,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 + ctx.f10.f64));
	// stfsx f11,r30,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f29,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 - ctx.f7.f64));
	// stfsx f12,r30,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f3
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f7,f11,f3
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmadds f11,f11,f2,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f2.f64 + ctx.f10.f64));
	// stfsx f11,r8,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f2,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 - ctx.f7.f64));
	// stfsx f12,r8,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f5
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// fmuls f7,f11,f5
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmadds f11,f11,f6,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f6.f64 + ctx.f10.f64));
	// stfsx f11,r31,r3
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f6,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f6.f64 - ctx.f7.f64));
	// stfsx f12,r31,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fmuls f10,f12,f1
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f11,f1
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// fmadds f10,f11,f31,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f31.f64 + ctx.f10.f64));
	// stfsx f10,r29,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f11,f4,f8
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fmsubs f12,f12,f31,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 - ctx.f7.f64));
	// stfs f12,0(r26)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f10,f28,f9
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f9.f64));
	// lfs f9,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f12,f11
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmuls f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// fmadds f9,f9,f10,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 + ctx.f8.f64));
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fmsubs f12,f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f11.f64));
	// stfs f12,0(r25)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// lwz r10,-26212(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// xor r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// bne 0x82c94d7c
	if (!ctx.cr0.eq) goto loc_82C94D7C;
loc_82C94FAC:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c5a0
	ctx.lr = 0x82C94FB4;
	__restfpr_19(ctx, base);
	// b 0x82d5c504
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C94FB8"))) PPC_WEAK_FUNC(sub_82C94FB8);
PPC_FUNC_IMPL(__imp__sub_82C94FB8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-29016
	ctx.r5.s64 = ctx.r11.s64 + -29016;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,19776
	ctx.r4.s64 = ctx.r11.s64 + 19776;
	// b 0x82cab890
	sub_82CAB890(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C94FD0"))) PPC_WEAK_FUNC(sub_82C94FD0);
PPC_FUNC_IMPL(__imp__sub_82C94FD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82C94FD8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82C94FE0;
	__savefpr_14(ctx, base);
	// stwu r1,-944(r1)
	ea = -944 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r8,56
	ctx.r11.s64 = ctx.r8.s64 * 56;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82c96a08
	if (!ctx.cr6.lt) goto loc_82C96A08;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r10,612(r1)
	PPC_STORE_U32(ctx.r1.u32 + 612, ctx.r10.u32);
	// subf r10,r8,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r8.s64;
	// stw r10,364(r1)
	PPC_STORE_U32(ctx.r1.u32 + 364, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f0,-29652(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82C9500C:
	// rlwinm r31,r6,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r8,r6,5
	ctx.r8.s64 = ctx.r6.s64 * 5;
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f27,f11,f13
	ctx.f27.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// mulli r10,r6,3
	ctx.r10.s64 = ctx.r6.s64 * 3;
	// fsubs f11,f12,f10
	ctx.f11.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// mulli r9,r6,7
	ctx.r9.s64 = ctx.r6.s64 * 7;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// add r27,r6,r7
	ctx.r27.u64 = ctx.r6.u64 + ctx.r7.u64;
	// rlwinm r26,r6,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r25,r6,24
	ctx.r25.s64 = ctx.r6.s64 * 24;
	// lfsx f9,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f6,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f10,f8,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
	// lfsx f7,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// rlwinm r20,r8,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f8,f7,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// rlwinm r17,r27,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// rlwinm r19,r9,2,0,29
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r18,r10,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r8,r7,3
	ctx.r8.s64 = ctx.r7.s64 * 3;
	// stw r10,44(r1)
	PPC_STORE_U32(ctx.r1.u32 + 44, ctx.r10.u32);
	// lfsx f5,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f30,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f3,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f26,f5,f30
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// lfsx f31,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// lfsx f29,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f6,f31,f3
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// lfsx f4,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// lfsx f28,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f30,f29,f4
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// lfsx f2,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// add r28,r8,r6
	ctx.r28.u64 = ctx.r8.u64 + ctx.r6.u64;
	// fsubs f31,f2,f28
	ctx.f31.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// mulli r8,r7,7
	ctx.r8.s64 = ctx.r7.s64 * 7;
	// fadds f4,f4,f29
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fadds f2,f28,f2
	ctx.f2.f64 = double(float(ctx.f28.f64 + ctx.f2.f64));
	// fadds f29,f10,f27
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f27.f64));
	// fadds f28,f9,f11
	ctx.f28.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stw r28,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r28.u32);
	// fsubs f25,f13,f8
	ctx.f25.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// fsubs f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 - ctx.f10.f64));
	// mulli r24,r7,24
	ctx.r24.s64 = ctx.r7.s64 * 24;
	// fadds f27,f7,f12
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fadds f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fsubs f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fadds f9,f6,f26
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f26.f64));
	// fsubs f8,f6,f26
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// fadds f7,f30,f5
	ctx.f7.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// lfsx f1,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f6,f30,f5
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// add r8,r8,r6
	ctx.r8.u64 = ctx.r8.u64 + ctx.r6.u64;
	// fsubs f5,f3,f31
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// add r16,r24,r31
	ctx.r16.u64 = ctx.r24.u64 + ctx.r31.u64;
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// mulli r5,r27,28
	ctx.r5.s64 = ctx.r27.s64 * 28;
	// stfs f3,492(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// fsubs f30,f4,f2
	ctx.f30.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// lfsx f3,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// stw r5,548(r1)
	PPC_STORE_U32(ctx.r1.u32 + 548, ctx.r5.u32);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r10,r6,20
	ctx.r10.s64 = ctx.r6.s64 * 20;
	// stw r8,564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 564, ctx.r8.u32);
	// mulli r9,r7,28
	ctx.r9.s64 = ctx.r7.s64 * 28;
	// mulli r30,r6,12
	ctx.r30.s64 = ctx.r6.s64 * 12;
	// mulli r15,r27,24
	ctx.r15.s64 = ctx.r27.s64 * 24;
	// rlwinm r28,r28,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f2,f3,f1
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// add r23,r30,r9
	ctx.r23.u64 = ctx.r30.u64 + ctx.r9.u64;
	// fsubs f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// rlwinm r22,r6,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f31,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// add r29,r9,r10
	ctx.r29.u64 = ctx.r9.u64 + ctx.r10.u64;
	// lfsx f1,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f18,f1,f31
	ctx.f18.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f26,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stw r28,536(r1)
	PPC_STORE_U32(ctx.r1.u32 + 536, ctx.r28.u32);
	// lfsx f14,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stw r23,604(r1)
	PPC_STORE_U32(ctx.r1.u32 + 604, ctx.r23.u32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stw r29,556(r1)
	PPC_STORE_U32(ctx.r1.u32 + 556, ctx.r29.u32);
	// lfsx f14,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f17,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f22,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f26,f17
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfsx f31,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f31,f22
	ctx.f17.f64 = double(float(ctx.f31.f64 + ctx.f22.f64));
	// lfsx f21,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f31,f22,f31
	ctx.f31.f64 = double(float(ctx.f22.f64 - ctx.f31.f64));
	// lfsx f15,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f21,f16
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// lfsx f24,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// fadds f16,f24,f15
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// lfsx f23,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// lfsx f20,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// fadds f15,f22,f31
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f31.f64));
	// stfs f15,600(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// fsubs f31,f22,f31
	ctx.f31.f64 = double(float(ctx.f22.f64 - ctx.f31.f64));
	// stfs f31,568(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// fadds f31,f16,f2
	ctx.f31.f64 = double(float(ctx.f16.f64 + ctx.f2.f64));
	// stfs f31,288(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fsubs f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f16.f64));
	// stfs f2,380(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fadds f2,f24,f18
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f18.f64));
	// stfs f2,452(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// fadds f2,f23,f1
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// stfs f2,348(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fsubs f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// stfs f1,340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f31,f3,f2
	ctx.f31.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f31,460(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f3,620(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// lfs f3,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f31,f18,f24
	ctx.f31.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// fadds f2,f3,f17
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f17.f64));
	// stfs f2,52(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f2,f21,f19
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f2,308(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fadds f2,f19,f21
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f31,628(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// stfs f2,60(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// mulli r8,r6,6
	ctx.r8.s64 = ctx.r6.s64 * 6;
	// lfs f2,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f2.f64 = double(temp.f32);
	// add r28,r8,r7
	ctx.r28.u64 = ctx.r8.u64 + ctx.r7.u64;
	// fsubs f1,f20,f2
	ctx.f1.f64 = double(float(ctx.f20.f64 - ctx.f2.f64));
	// fadds f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// stfs f2,504(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fsubs f3,f3,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f17.f64));
	// stfs f3,292(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f3,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// stfs f1,496(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// lfsx f1,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r5,r6,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// lfsx f31,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// rlwinm r28,r28,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r5,r7
	ctx.r5.u64 = ctx.r5.u64 + ctx.r7.u64;
	// add r29,r22,r7
	ctx.r29.u64 = ctx.r22.u64 + ctx.r7.u64;
	// rlwinm r14,r5,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r29,r29,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r8,r6,28
	ctx.r8.s64 = ctx.r6.s64 * 28;
	// stw r28,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r28.u32);
	// stw r5,48(r1)
	PPC_STORE_U32(ctx.r1.u32 + 48, ctx.r5.u32);
	// stw r14,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r14.u32);
	// lfsx f21,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// stw r29,428(r1)
	PPC_STORE_U32(ctx.r1.u32 + 428, ctx.r29.u32);
	// lfsx f19,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f24,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r28,r7,6
	ctx.r28.s64 = ctx.r7.s64 * 6;
	// lfsx f23,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// add r23,r28,r6
	ctx.r23.u64 = ctx.r28.u64 + ctx.r6.u64;
	// rlwinm r21,r7,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r23,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r23.u32 | (ctx.r23.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r10,r24
	ctx.r28.u64 = ctx.r10.u64 + ctx.r24.u64;
	// lfsx f22,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f15,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stw r23,424(r1)
	PPC_STORE_U32(ctx.r1.u32 + 424, ctx.r23.u32);
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f15,f3,f2
	ctx.f15.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfsx f20,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f16,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stw r28,472(r1)
	PPC_STORE_U32(ctx.r1.u32 + 472, ctx.r28.u32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r14.u32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f15,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// lfs f17,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// stw r14,636(r1)
	PPC_STORE_U32(ctx.r1.u32 + 636, ctx.r14.u32);
	// lwz r29,84(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lfs f18,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lwz r29,96(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfsx f2,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,24(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f2,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,32(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f2,f1,f24
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// fsubs f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// fsubs f24,f23,f31
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// fadds f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f19,88(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// stfs f19,560(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// stfs f26,488(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f26,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fadds f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// rlwinm r23,r7,1,0,30
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r5,r5,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// add r14,r23,r6
	ctx.r14.u64 = ctx.r23.u64 + ctx.r6.u64;
	// fadds f16,f2,f14
	ctx.f16.f64 = double(float(ctx.f2.f64 + ctx.f14.f64));
	// add r23,r9,r26
	ctx.r23.u64 = ctx.r9.u64 + ctx.r26.u64;
	// stfs f16,180(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f16,f1,f24
	ctx.f16.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// stfs f16,480(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// fsubs f16,f3,f31
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// add r29,r8,r24
	ctx.r29.u64 = ctx.r8.u64 + ctx.r24.u64;
	// stw r5,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r5.u32);
	// rlwinm r5,r27,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f3,188(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// stw r23,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, ctx.r23.u32);
	// add r23,r9,r25
	ctx.r23.u64 = ctx.r9.u64 + ctx.r25.u64;
	// fadds f3,f24,f1
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// stfs f3,196(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fsubs f3,f2,f14
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f3,164(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stw r5,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r5.u32);
	// fadds f3,f19,f23
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// stfs f3,324(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fsubs f3,f23,f19
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stw r23,304(r1)
	PPC_STORE_U32(ctx.r1.u32 + 304, ctx.r23.u32);
	// stfs f3,388(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fadds f3,f18,f21
	ctx.f3.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f3,532(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// fadds f3,f17,f20
	ctx.f3.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f3,280(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// stw r29,584(r1)
	PPC_STORE_U32(ctx.r1.u32 + 584, ctx.r29.u32);
	// rlwinm r23,r7,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r5,44(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// stfs f16,172(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfsx f1,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// stw r14,64(r1)
	PPC_STORE_U32(ctx.r1.u32 + 64, ctx.r14.u32);
	// rlwinm r5,r5,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f31,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// stw r5,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r5.u32);
	// mulli r5,r14,12
	ctx.r5.s64 = ctx.r14.s64 * 12;
	// stw r5,464(r1)
	PPC_STORE_U32(ctx.r1.u32 + 464, ctx.r5.u32);
	// lfs f3,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f2,f22,f3
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f3.f64));
	// stfs f2,540(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// fsubs f2,f21,f18
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f2,508(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fadds f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// stfs f3,500(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// lfsx f3,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f2,f20,f17
	ctx.f2.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f2,168(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fsubs f2,f15,f3
	ctx.f2.f64 = double(float(ctx.f15.f64 - ctx.f3.f64));
	// add r28,r9,r31
	ctx.r28.u64 = ctx.r9.u64 + ctx.r31.u64;
	// fadds f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f15.f64));
	// lfsx f18,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f15,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f23,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// stw r28,576(r1)
	PPC_STORE_U32(ctx.r1.u32 + 576, ctx.r28.u32);
	// fadds f24,f2,f26
	ctx.f24.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// stfs f24,436(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fsubs f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// stfs f2,444(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// lfsx f24,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f2,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lwz r29,352(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// lfsx f26,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lwz r28,304(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// lfsx f22,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f20,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r29,264(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// lfsx f21,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f19,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f17,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r29,112(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f16,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r14,r14,3,0,28
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 3) & 0xFFFFFFF8;
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r29,r7,12
	ctx.r29.s64 = ctx.r7.s64 * 12;
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r5,124(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f16,f26,f1
	ctx.f16.f64 = double(float(ctx.f26.f64 + ctx.f1.f64));
	// fsubs f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// fsubs f26,f31,f23
	ctx.f26.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// stw r14,336(r1)
	PPC_STORE_U32(ctx.r1.u32 + 336, ctx.r14.u32);
	// fadds f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// add r14,r29,r10
	ctx.r14.u64 = ctx.r29.u64 + ctx.r10.u64;
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// rlwinm r28,r7,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fadds f19,f17,f18
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fsubs f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stw r14,252(r1)
	PPC_STORE_U32(ctx.r1.u32 + 252, ctx.r14.u32);
	// add r14,r29,r8
	ctx.r14.u64 = ctx.r29.u64 + ctx.r8.u64;
	// stw r14,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r14.u32);
	// add r14,r28,r25
	ctx.r14.u64 = ctx.r28.u64 + ctx.r25.u64;
	// stw r14,384(r1)
	PPC_STORE_U32(ctx.r1.u32 + 384, ctx.r14.u32);
	// lwz r14,112(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f24
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// fadds f14,f23,f16
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// stfs f23,300(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fadds f23,f22,f26
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f23,516(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// fadds f23,f20,f31
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f31.f64));
	// stfs f23,56(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f23,f1,f21
	ctx.f23.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfs f23,524(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// fadds f1,f21,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// stfs f1,512(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// fsubs f31,f31,f20
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f20.f64));
	// stfs f31,236(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f26,376(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f31,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f31.f64 = double(temp.f32);
	// fadds f26,f31,f1
	ctx.f26.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfs f26,332(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfs f1,316(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f1,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f31,f24,f1
	ctx.f31.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// stfs f31,160(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f31,f3,f2
	ctx.f31.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfs f31,356(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f3,372(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fadds f3,f1,f24
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// stfs f3,24(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f3,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lwz r5,28(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lfs f1,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f2,f3,f1
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// fsubs f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// lfsx f1,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// stw r5,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r5.u32);
	// mulli r5,r27,12
	ctx.r5.s64 = ctx.r27.s64 * 12;
	// stw r5,44(r1)
	PPC_STORE_U32(ctx.r1.u32 + 44, ctx.r5.u32);
	// rlwinm r5,r27,4,0,27
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 4) & 0xFFFFFFF0;
	// stw r5,552(r1)
	PPC_STORE_U32(ctx.r1.u32 + 552, ctx.r5.u32);
	// lfsx f21,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r14,124(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lfsx f20,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r5,336(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	// fadds f26,f2,f19
	ctx.f26.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// lfsx f23,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// stfs f2,432(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fadds f2,f3,f17
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f17.f64));
	// lfsx f22,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f31,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f3,f17,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 - ctx.f3.f64));
	// lfsx f19,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f1,f31
	ctx.f17.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r5,252(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// lwz r14,88(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stfs f3,596(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// stfs f2,520(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// stfs f26,200(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfsx f31,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f14,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r5,244(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f3,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lwz r14,44(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// lfsx f14,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r5,384(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f26,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f24,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f14,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f14,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f14,f21,f23
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fsubs f21,f18,f17
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f21,608(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// fadds f21,f1,f15
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f15.f64));
	// stfs f21,208(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fsubs f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 - ctx.f1.f64));
	// stfs f1,400(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// fadds f1,f17,f18
	ctx.f1.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f1,588(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// fsubs f1,f22,f20
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fadds f20,f31,f3
	ctx.f20.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f31,f2,f21
	ctx.f31.f64 = double(float(ctx.f2.f64 - ctx.f21.f64));
	// fadds f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f2.f64));
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fadds f18,f26,f21
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f21,f24
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// lfs f21,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f21.f64 = double(temp.f32);
	// fadds f15,f21,f19
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f19,f31,f3
	ctx.f19.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f19,268(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fsubs f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// stfs f3,276(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fadds f3,f18,f20
	ctx.f3.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f3,176(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f3,f18,f20
	ctx.f3.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f3,440(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fsubs f3,f26,f17
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// stfs f3,260(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fsubs f3,f2,f24
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// stfs f3,624(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// fadds f3,f24,f2
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// mulli r14,r7,5
	ctx.r14.s64 = ctx.r7.s64 * 5;
	// stfs f3,396(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// add r14,r14,r6
	ctx.r14.u64 = ctx.r14.u64 + ctx.r6.u64;
	// fadds f3,f17,f26
	ctx.f3.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f3,284(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fadds f2,f15,f14
	ctx.f2.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f3,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f16.f64));
	// stfs f2,184(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f2,f14,f15
	ctx.f2.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f2,248(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f2,f21,f1
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// stfs f2,616(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// lfs f2,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// mulli r27,r27,20
	ctx.r27.s64 = ctx.r27.s64 * 20;
	// fsubs f31,f23,f2
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f2.f64));
	// fadds f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f23.f64));
	// stfs f2,528(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// stfs f31,632(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 632, temp.u32);
	// stfs f1,420(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// fadds f2,f3,f22
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f22.f64));
	// stfs f2,404(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fsubs f3,f22,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f3.f64));
	// stfs f3,240(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// rlwinm r14,r14,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f3,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stw r27,476(r1)
	PPC_STORE_U32(ctx.r1.u32 + 476, ctx.r27.u32);
	// mulli r5,r7,20
	ctx.r5.s64 = ctx.r7.s64 * 20;
	// stw r14,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r14.u32);
	// lwz r14,64(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	// rlwinm r14,r14,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r14,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r14.u32);
	// add r14,r23,r10
	ctx.r14.u64 = ctx.r23.u64 + ctx.r10.u64;
	// stw r14,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r14.u32);
	// add r14,r23,r8
	ctx.r14.u64 = ctx.r23.u64 + ctx.r8.u64;
	// stw r14,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r14.u32);
	// add r14,r23,r30
	ctx.r14.u64 = ctx.r23.u64 + ctx.r30.u64;
	// stw r14,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r14.u32);
	// add r14,r5,r8
	ctx.r14.u64 = ctx.r5.u64 + ctx.r8.u64;
	// stw r14,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r14.u32);
	// add r14,r5,r30
	ctx.r14.u64 = ctx.r5.u64 + ctx.r30.u64;
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,484(r1)
	PPC_STORE_U32(ctx.r1.u32 + 484, ctx.r14.u32);
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r27,204(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// lfsx f1,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f19,f3,f1
	ctx.f19.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// fsubs f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// fsubs f1,f31,f2
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// lwz r27,152(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// fadds f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// lfsx f26,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lwz r27,136(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lfsx f24,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lwz r27,152(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// fadds f31,f24,f26
	ctx.f31.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f31,36(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// lfsx f23,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r27,136(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lfsx f22,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r27,116(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// fadds f31,f22,f23
	ctx.f31.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f24,f23,f22
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfsx f21,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r27,104(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfsx f20,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r27,116(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// fadds f23,f20,f21
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfsx f18,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r27,104(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lfsx f17,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r27,272(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// fadds f22,f17,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfsx f16,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,48(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// add r27,r21,r6
	ctx.r27.u64 = ctx.r21.u64 + ctx.r6.u64;
	// fsubs f20,f18,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// mulli r14,r14,12
	ctx.r14.s64 = ctx.r14.s64 * 12;
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f1,f3
	ctx.f14.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// stfs f14,220(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// stw r14,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r14.u32);
	// fsubs f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// stfs f3,228(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fadds f3,f24,f26
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// add r14,r29,r26
	ctx.r14.u64 = ctx.r29.u64 + ctx.r26.u64;
	// stfs f3,68(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// rlwinm r27,r27,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f3,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// fadds f1,f23,f3
	ctx.f1.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f1,360(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fsubs f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 - ctx.f3.f64));
	// stfs f3,216(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fsubs f3,f24,f26
	ctx.f3.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfs f3,36(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f1,f31,f22
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f22.f64));
	// stfs f1,224(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stw r14,296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 296, ctx.r14.u32);
	// lfsx f24,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// stw r27,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r27.u32);
	// add r27,r28,r10
	ctx.r27.u64 = ctx.r28.u64 + ctx.r10.u64;
	// fadds f1,f22,f31
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f31.f64));
	// stfs f1,312(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fsubs f1,f21,f20
	ctx.f1.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f1,76(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f1,f18,f19
	ctx.f1.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f1,192(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fsubs f1,f18,f19
	ctx.f1.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f1,320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// stw r27,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r27.u32);
	// add r27,r28,r8
	ctx.r27.u64 = ctx.r28.u64 + ctx.r8.u64;
	// fsubs f1,f17,f16
	ctx.f1.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f1,212(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fsubs f1,f2,f15
	ctx.f1.f64 = double(float(ctx.f2.f64 - ctx.f15.f64));
	// stfs f1,232(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fadds f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// stfs f2,412(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fadds f2,f16,f17
	ctx.f2.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f2,64(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// stw r27,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r27.u32);
	// add r27,r28,r30
	ctx.r27.u64 = ctx.r28.u64 + ctx.r30.u64;
	// fadds f2,f20,f21
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f2,28(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f3,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// stw r27,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r27.u32);
	// add r27,r5,r31
	ctx.r27.u64 = ctx.r5.u64 + ctx.r31.u64;
	// stw r27,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r27.u32);
	// add r27,r29,r31
	ctx.r27.u64 = ctx.r29.u64 + ctx.r31.u64;
	// lfsx f31,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f26,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// lfsx f23,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,296(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// lfsx f21,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lwz r14,108(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfsx f20,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lwz r14,108(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,120(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,100(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,120(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,100(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,32(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r5,r26
	ctx.r14.u64 = ctx.r5.u64 + ctx.r26.u64;
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f14,f31,f3
	ctx.f14.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fsubs f31,f2,f26
	ctx.f31.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// fadds f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// fadds f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,92(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r14.u32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// add r14,r5,r25
	ctx.r14.u64 = ctx.r5.u64 + ctx.r25.u64;
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f1
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f1.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f15,f26,f14
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfs f15,448(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// fsubs f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfs f26,256(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fadds f26,f24,f31
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f31.f64));
	// stfs f26,572(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// fadds f26,f22,f2
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// stfs f26,544(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fsubs f14,f3,f23
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// stfs f14,580(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// fsubs f31,f31,f24
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f24.f64));
	// stfs f31,48(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f22.f64));
	// stfs f2,392(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fadds f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f3,468(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fadds f3,f19,f20
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfs f3,344(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fsubs f2,f17,f21
	ctx.f2.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f2,368(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fsubs f3,f19,f20
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f3,408(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f31,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f31.f64 = double(temp.f32);
	// fadds f3,f17,f21
	ctx.f3.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// lfs f23,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// lfs f21,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f4
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// lfs f20,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// lfs f19,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f19.f64 = double(temp.f32);
	// stfs f3,456(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfs f24,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f2,f31,f24
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f24.f64));
	// stfs f2,92(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f31,f24,f31
	ctx.f31.f64 = double(float(ctx.f24.f64 + ctx.f31.f64));
	// stfs f31,80(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f2,f18,f16
	ctx.f2.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f31,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f31.f64 = double(temp.f32);
	// lfs f24,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f24.f64 = double(temp.f32);
	// fadds f31,f31,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f29.f64));
	// stfs f2,328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fadds f2,f16,f18
	ctx.f2.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f2,592(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// fadds f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f18,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f19.f64 = double(temp.f32);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// lfs f17,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f16,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f2,f16
	ctx.f16.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// lfs f2,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f2.f64 = double(temp.f32);
	// fadds f15,f3,f2
	ctx.f15.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// lfs f2,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f3.f64 = double(temp.f32);
	// fadds f14,f2,f3
	ctx.f14.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f2,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f2,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfs f2,148(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f2,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfs f2,52(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f2,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f2.f64 = double(temp.f32);
	// stw r14,56(r1)
	PPC_STORE_U32(ctx.r1.u32 + 56, ctx.r14.u32);
	// add r14,r5,r25
	ctx.r14.u64 = ctx.r5.u64 + ctx.r25.u64;
	// lfs f1,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfs f2,416(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stfs f3,144(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfsx f3,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// stw r14,40(r1)
	PPC_STORE_U32(ctx.r1.u32 + 40, ctx.r14.u32);
	// lwz r14,32(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfsx f2,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f2,60(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f2,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lwz r14,56(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// lfs f2,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f2,72(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f2,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lwz r14,40(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// stfs f2,140(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f2,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,40(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// stfs f31,0(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f24,0(r4)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfsx f23,r22,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// stfsx f22,r22,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// stfsx f21,r30,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// stfsx f20,r26,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f2,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f2.f64 = double(temp.f32);
	// stfsx f19,r26,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fadds f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f1,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f1.f64 = double(temp.f32);
	// stfsx f26,r30,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// lfs f31,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f31.f64 = double(temp.f32);
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f18,r25,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f17,r25,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f26.f64 = double(temp.f32);
	// fadds f1,f26,f31
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f31.f64));
	// fsubs f31,f31,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// fadds f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f23,f1,f2
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f22,f19,f31
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f31.f64));
	// fadds f21,f26,f20
	ctx.f21.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// fadds f20,f24,f3
	ctx.f20.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// fsubs f24,f3,f24
	ctx.f24.f64 = double(float(ctx.f3.f64 - ctx.f24.f64));
	// lfs f3,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f3,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f31,f31,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f19.f64));
	// fadds f3,f21,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 + ctx.f3.f64));
	// stfsx f3,r10,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f3,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f3.f64 = double(temp.f32);
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// fsubs f2,f10,f3
	ctx.f2.f64 = double(float(ctx.f10.f64 - ctx.f3.f64));
	// lfs f3,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f3.f64 = double(temp.f32);
	// stfsx f16,r31,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 - ctx.f3.f64));
	// stfsx f15,r31,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfsx f14,r8,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfsx f18,r8,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// stfs f16,156(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f18,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f18,f2
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,144(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f14,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f19,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f9,f14,f9
	ctx.f9.f64 = double(float(ctx.f14.f64 - ctx.f9.f64));
	// stfs f9,140(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmsubs f3,f19,f3,f17
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 - ctx.f17.f64));
	// stfsx f3,r24,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f3,f19,f2,f18
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 + ctx.f18.f64));
	// stfsx f3,r24,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f3,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// lfs f2,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f2.f64 = double(temp.f32);
	// stfs f9,132(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f15,f3,f2
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f9,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f4,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f4.f64 = double(temp.f32);
	// lfs f19,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f9,f4
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// lfs f2,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// lfs f18,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f4,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f4.f64 = double(temp.f32);
	// lfs f18,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f8.f64));
	// fmadds f9,f9,f4,f15
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64 + ctx.f15.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// fmsubs f9,f3,f4,f14
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 - ctx.f14.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// lfs f9,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f4,f19
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmsubs f3,f9,f2,f3
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f2.f64 - ctx.f3.f64));
	// stfsx f3,r15,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f19,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f19.f64 + ctx.f4.f64));
	// stfsx f9,r15,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f9.f64 = double(temp.f32);
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,424(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	// fmuls f3,f4,f17
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f4,f4,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// lfs f15,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f3,f9,f18,f3
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f18.f64 - ctx.f3.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f17,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f17.f64 + ctx.f4.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,584(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	// lfs f3,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f4,f2
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f9,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f9.f64 = double(temp.f32);
	// lfs f18,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f3,f9,f3,f19
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 - ctx.f19.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f2,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f2.f64 + ctx.f4.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,384(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	// lfs f3,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f4,f16
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f3,f9,f3,f2
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 + ctx.f2.f64));
	// stfsx f3,r10,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f9,f9,f16,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f16.f64 - ctx.f4.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// lwz r10,108(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfs f3,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f9,f3
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmuls f19,f4,f3
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f4,f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f2.f64));
	// stfsx f4,r10,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f9,f9,f3,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 - ctx.f19.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lfs f9,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// lfs f3,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfs f2,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// lfs f19,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f19.f64 = double(temp.f32);
	// lfs f2,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// lfs f19,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fadds f12,f19,f12
	ctx.f12.f64 = double(float(ctx.f19.f64 + ctx.f12.f64));
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fadds f10,f19,f10
	ctx.f10.f64 = double(float(ctx.f19.f64 + ctx.f10.f64));
	// lfs f16,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// lfs f19,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f16,f4
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// lfs f17,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fadds f8,f19,f8
	ctx.f8.f64 = double(float(ctx.f19.f64 + ctx.f8.f64));
	// lfs f19,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f19.f64 = double(temp.f32);
	// fadds f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// lfs f19,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// fmsubs f9,f17,f9,f14
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 - ctx.f14.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f17,f4,f16
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f16.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f4,f2
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// lwz r10,124(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f16,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f3,f9,f3,f17
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 - ctx.f17.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f9,f9,f2,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f2.f64 + ctx.f4.f64));
	// stfsx f9,r10,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// fmuls f3,f4,f10
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f17,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f17.f64 = double(temp.f32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f12,f9,f12,f3
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f3.f64));
	// stfsx f12,r23,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f9,f10,f4
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 + ctx.f4.f64));
	// stfsx f12,r23,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f29
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f29.f64));
	// fmuls f4,f10,f29
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfs f3,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f3.f64 = double(temp.f32);
	// lfs f29,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fmadds f10,f10,f27,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 + ctx.f9.f64));
	// stfsx f10,r28,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f27,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f4.f64));
	// stfsx f12,r28,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f30
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f27,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 - ctx.f27.f64));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f14,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f14.f64 = double(temp.f32);
	// lfs f4,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// fmsubs f9,f12,f8,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f30,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 + ctx.f10.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,536(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	// fmuls f9,f10,f18
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f18.f64));
	// lfs f12,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// lfs f4,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfs f3,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfs f30,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f30.f64 = double(temp.f32);
	// lfs f2,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f30.f64));
	// lfs f30,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f1,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fmsubs f9,f12,f19,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f19.f64 - ctx.f9.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmuls f19,f10,f19
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// lfs f9,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f9,f9,f16
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f16.f64));
	// fsubs f10,f10,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f17.f64));
	// fmadds f12,f12,f18,f19
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// lfs f18,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lwz r10,464(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	// fmuls f14,f18,f9
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// lfs f12,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// fmsubs f10,f12,f10,f14
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f14.f64));
	// stfsx f10,r10,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f9,f18
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f18.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f8
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmuls f8,f10,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmadds f10,f10,f4,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f9.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f4,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 - ctx.f8.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lwz r10,552(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	// lfs f10,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f3
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f8,f10,f3
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f4,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f10,f10,f2,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f2.f64 + ctx.f9.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f2,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 - ctx.f8.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f10,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,472(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	// fmuls f9,f10,f29
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfs f12,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f8,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f8.f64 = double(temp.f32);
	// lfs f2,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// lfs f1,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f26,f1
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f1.f64));
	// lfs f26,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// fmsubs f9,f12,f30,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f9.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f29,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 + ctx.f10.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fmuls f9,f10,f19
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// lfs f12,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fmsubs f9,f12,f27,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f9.f64));
	// stfsx f9,r16,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f19,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f19.f64 + ctx.f10.f64));
	// stfsx f12,r16,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f30,f10,f21
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// fmuls f29,f12,f21
	ctx.f29.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// lfs f9,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// lfs f8,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// lfs f27,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f27.f64 = double(temp.f32);
	// lfs f4,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// lfs f3,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f15.f64));
	// fmadds f12,f12,f23,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f23.f64 + ctx.f30.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f10,f10,f23,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f23.f64 - ctx.f29.f64));
	// lfs f23,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f10,r10,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,336(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	// fmuls f21,f10,f9
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f30,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f30.f64 = double(temp.f32);
	// lfs f12,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f12.f64 = double(temp.f32);
	// fadds f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f30.f64));
	// lfs f30,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// lfs f27,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f9,f27,f9
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fadds f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f17.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmadds f27,f27,f8,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f8.f64 + ctx.f21.f64));
	// stfsx f27,r10,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f10,f10,f8,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f10,r10,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// fmuls f8,f9,f3
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// lfs f15,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f18.f64 = double(temp.f32);
	// lfs f27,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f27.f64 = double(temp.f32);
	// lfs f14,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f8,f10,f4,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 - ctx.f8.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f10,f3,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f9.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// fmuls f8,f9,f1
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f4,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f16,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// fmsubs f8,f10,f2,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f2.f64 - ctx.f8.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f10,f10,f1,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f1.f64 + ctx.f9.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// lwz r10,264(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// fmuls f8,f9,f30
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fadds f2,f21,f18
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmsubs f12,f10,f12,f8
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f8.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f10,f30,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 + ctx.f9.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// fmuls f9,f10,f26
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// fsubs f8,f15,f17
	ctx.f8.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmsubs f9,f12,f29,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 - ctx.f9.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f26,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 + ctx.f10.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f10,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f26,f25,f4
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// fsubs f9,f10,f12
	ctx.f9.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// lfs f10,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f12,f10,f23
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f23.f64));
	// lfs f30,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f30.f64 = double(temp.f32);
	// fadds f10,f23,f10
	ctx.f10.f64 = double(float(ctx.f23.f64 + ctx.f10.f64));
	// lfs f23,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f23.f64 = double(temp.f32);
	// fadds f3,f23,f19
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// lfs f1,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// fadds f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// lfs f25,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f2.f64));
	// lwz r10,576(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fsubs f29,f27,f9
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// fadds f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// fsubs f27,f28,f8
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f8.f64));
	// fadds f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fsubs f28,f14,f3
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f3.f64));
	// fadds f3,f3,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f14.f64));
	// lfs f14,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f14.f64 = double(temp.f32);
	// fadds f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// fmuls f14,f30,f12
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f29.f64));
	// fmsubs f12,f1,f12,f30
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 - ctx.f30.f64));
	// stfsx f12,r10,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f1,f29,f14
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f14.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// lfs f1,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f30,f1,f9
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmsubs f10,f12,f10,f30
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f30.f64));
	// stfsx f10,r27,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f9,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f1.f64));
	// stfsx f12,r27,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f26
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// lfs f12,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// lfs f30,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f9,f12,f27,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f9.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f26,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 + ctx.f10.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// lwz r9,272(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// fmuls f9,f10,f4
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f27,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f9,f12,f8,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f9,r29,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f4,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 + ctx.f10.f64));
	// stfsx f12,r29,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f9,f12,f28
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f10,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f10,f28
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f4,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// lfs f28,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f10,f10,f25,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64 + ctx.f9.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f12,f12,f25,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64 - ctx.f8.f64));
	// lfs f10,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfs f9,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// lfs f4,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,352(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// fmuls f14,f12,f3
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// lfs f25,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f8,f4,f0
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f4,f1,f0
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f1,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// fmadds f1,f1,f2,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f14.f64));
	// stfsx f1,r19,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fsubs f30,f28,f10
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f10.f64));
	// fsubs f29,f27,f9
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// fadds f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fadds f9,f27,f9
	ctx.f9.f64 = double(float(ctx.f27.f64 + ctx.f9.f64));
	// fmsubs f12,f12,f2,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 - ctx.f3.f64));
	// stfsx f12,r19,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// lfs f3,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f28,f25,f8
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f8.f64));
	// lfs f12,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f27,f26,f4
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f4.f64));
	// fadds f4,f26,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 + ctx.f4.f64));
	// fadds f8,f25,f8
	ctx.f8.f64 = double(float(ctx.f25.f64 + ctx.f8.f64));
	// fmuls f2,f3,f29
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmsubs f2,f12,f30,f2
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f2.f64));
	// stfsx f2,r9,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f29,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 + ctx.f3.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lwz r9,296(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// lfs f3,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f3,f9
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f25,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f25.f64 = double(temp.f32);
	// lfs f14,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f29.f64 = double(temp.f32);
	// lfs f26,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f10,f12,f10,f2
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f2.f64));
	// stfsx f10,r9,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f9,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f3.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,32(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfs f10,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f28
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fmuls f3,f10,f28
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f2,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f10,f10,f27,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64 + ctx.f9.f64));
	// stfsx f10,r9,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f27,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64 - ctx.f3.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,428(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// fmuls f9,f12,f8
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f10,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f3,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f8,f10,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f27,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f9,f10,f4,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f9.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f12,f12,f4,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 - ctx.f8.f64));
	// fadds f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// lfs f3,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f10.f64 = double(temp.f32);
	// fadds f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// fsubs f2,f10,f25
	ctx.f2.f64 = double(float(ctx.f10.f64 - ctx.f25.f64));
	// lfs f10,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f1,f14,f10
	ctx.f1.f64 = double(float(ctx.f14.f64 - ctx.f10.f64));
	// lfs f10,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f10.f64 = double(temp.f32);
	// fadds f30,f10,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 + ctx.f30.f64));
	// lfs f10,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f10.f64 = double(temp.f32);
	// fadds f29,f10,f29
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f29.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,476(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// lfs f4,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f10,f9,f0
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f9,f3,f0
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f8,f2,f0
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f2,f30,f0
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f1,f29,f0
	ctx.f1.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fsubs f30,f31,f10
	ctx.f30.f64 = double(float(ctx.f31.f64 - ctx.f10.f64));
	// fsubs f29,f24,f9
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f9.f64));
	// fadds f9,f24,f9
	ctx.f9.f64 = double(float(ctx.f24.f64 + ctx.f9.f64));
	// lfs f24,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f24.f64 = double(temp.f32);
	// fadds f10,f31,f10
	ctx.f10.f64 = double(float(ctx.f31.f64 + ctx.f10.f64));
	// fsubs f31,f27,f8
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f8.f64));
	// fsubs f28,f26,f3
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fadds f8,f8,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f27.f64));
	// fsubs f27,f24,f2
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// fadds f3,f3,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f26.f64));
	// lfs f26,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f26.f64 = double(temp.f32);
	// fadds f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// lfs f24,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f26,f26,f1
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f1.f64));
	// fadds f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// fmuls f24,f12,f30
	ctx.f24.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f30,f4,f30
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmadds f4,f4,f29,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 + ctx.f24.f64));
	// stfsx f4,r9,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f29,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f29.f64 - ctx.f30.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f30,f12,f10
	ctx.f30.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fmuls f10,f4,f10
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lwz r9,304(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// fmadds f4,f4,f9,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f30.f64));
	// stfsx f4,r20,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f30.f64 = double(temp.f32);
	// fadds f4,f7,f5
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// lfs f29,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f12,f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 - ctx.f10.f64));
	// stfsx f12,r20,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f10,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f28
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f12,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmsubs f9,f12,f31,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 - ctx.f9.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f28,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64 + ctx.f10.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// lwz r9,20(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fmuls f9,f10,f3
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f28,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f9,f12,f8,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f12,f12,f3,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f10.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,484(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	// fmuls f9,f12,f27
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// lfs f10,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// fadds f3,f6,f30
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// fadds f8,f16,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 + ctx.f8.f64));
	// fmadds f9,f10,f26,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f26.f64 + ctx.f9.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fadds f9,f17,f15
	ctx.f9.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmsubs f12,f12,f26,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 - ctx.f10.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmuls f10,f9,f0
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f9,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f27,f12,f2
	ctx.f27.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmuls f26,f9,f2
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fsubs f31,f11,f8
	ctx.f31.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fadds f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fsubs f8,f29,f3
	ctx.f8.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// fsubs f2,f13,f10
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// fmadds f9,f9,f1,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64 + ctx.f27.f64));
	// stfsx f9,r18,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f1,f26
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f1.f64 - ctx.f26.f64));
	// stfsx f12,r18,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fadds f9,f3,f29
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// lfs f3,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// fadds f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// fsubs f10,f28,f4
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f4.f64));
	// fadds f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f28.f64));
	// fmuls f1,f12,f2
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmadds f3,f3,f31,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f1.f64));
	// stfsx f3,r5,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f12,f12,f31,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 - ctx.f2.f64));
	// stfsx f12,r5,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f3,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f12,f13
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f13,f3,f13
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmadds f3,f3,f11,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 + ctx.f2.f64));
	// stfsx f3,r21,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f13,f12,f11,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f13.f64));
	// stfsx f13,r21,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f10
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f12,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f12,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fmadds f12,f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 + ctx.f11.f64));
	// lwz r9,204(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// fmsubs f13,f13,f8,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 - ctx.f10.f64));
	// fsubs f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// lfs f8,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f8.f64 = double(temp.f32);
	// lfs f2,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// lfs f3,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f30.f64 = double(temp.f32);
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lwz r9,548(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f12,f4
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmuls f11,f13,f4
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// lfs f4,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// lfs f29,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmsubs f13,f13,f9,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f10.f64));
	// fmadds f12,f12,f9,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f11.f64));
	// lfs f9,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f10,f21,f18
	ctx.f10.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfsx f12,r17,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fsubs f11,f19,f23
	ctx.f11.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// stfsx f13,r17,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// lfs f8,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// lfs f12,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f1,f30,f7
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// lfs f13,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fadds f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// fsubs f31,f29,f6
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f6.f64));
	// fadds f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f4,f2,f10
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f10.f64));
	// fsubs f5,f3,f11
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// fadds f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 + ctx.f10.f64));
	// fadds f11,f3,f11
	ctx.f11.f64 = double(float(ctx.f3.f64 + ctx.f11.f64));
	// fsubs f2,f22,f8
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f8.f64));
	// fsubs f3,f20,f9
	ctx.f3.f64 = double(float(ctx.f20.f64 - ctx.f9.f64));
	// fadds f8,f22,f8
	ctx.f8.f64 = double(float(ctx.f22.f64 + ctx.f8.f64));
	// fadds f9,f20,f9
	ctx.f9.f64 = double(float(ctx.f20.f64 + ctx.f9.f64));
	// fmuls f30,f12,f4
	ctx.f30.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmuls f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
	// fmsubs f5,f13,f5,f30
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 - ctx.f30.f64));
	// stfsx f5,r9,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f4,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f4.f64 + ctx.f12.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,244(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// fmuls f5,f12,f10
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmsubs f11,f13,f11,f5
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f5.f64));
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f10,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,556(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	// lfs f13,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f12,f2
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmuls f10,f13,f2
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmsubs f13,f13,f3,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f11.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f12,f3,f10
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f10.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f12,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,252(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// fmuls f11,f12,f8
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmsubs f11,f13,f9,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f11.f64));
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f8,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f12.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f13,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,564(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	// fmuls f11,f12,f31
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// lfs f10,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f12,f12,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// lfs f8,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f11,f13,f1,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 - ctx.f11.f64));
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f11,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f13,f13,f31,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f12.f64));
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f10,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfs f9,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f9.f64 = double(temp.f32);
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// lfs f8,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f8.f64 = double(temp.f32);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// fadds f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// lfs f5,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f5.f64 = double(temp.f32);
	// fadds f30,f25,f5
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// lfs f1,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f12,f11,f0
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f31,f11,f6
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmuls f29,f11,f7
	ctx.f29.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f11,f4,f12
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f12.f64));
	// fsubs f5,f3,f10
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fmsubs f7,f13,f7,f31
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64 - ctx.f31.f64));
	// stfsx f7,r9,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f6,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f6.f64 + ctx.f29.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f7,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f7.f64 = double(temp.f32);
	// fadds f10,f3,f10
	ctx.f10.f64 = double(float(ctx.f3.f64 + ctx.f10.f64));
	// fadds f12,f4,f12
	ctx.f12.f64 = double(float(ctx.f4.f64 + ctx.f12.f64));
	// lwz r9,604(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	// lfs f13,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f4,f1,f9
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f9.f64));
	// fsubs f3,f2,f8
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fadds f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fmuls f6,f7,f5
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// fmuls f7,f7,f11
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fmsubs f11,f13,f11,f6
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f6.f64));
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f5,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f7.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// lwz r9,44(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	// fmuls f7,f11,f10
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmsubs f12,f13,f12,f7
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 - ctx.f7.f64));
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmadds f13,f13,f10,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 + ctx.f11.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f13,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// lwz r9,16(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// lfs f12,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f13,f4
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmuls f10,f12,f4
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// fmadds f12,f12,f3,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f11.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f13,f13,f3,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f10.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// fmuls f11,f13,f9
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f12,f9
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmadds f12,f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 + ctx.f11.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f13,f13,f8,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 - ctx.f10.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f30,f0
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fadds f10,f14,f13
	ctx.f10.f64 = double(float(ctx.f14.f64 + ctx.f13.f64));
	// lfs f8,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f7.f64 = double(temp.f32);
	// lwz r9,364(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// lfs f13,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// lwz r8,612(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	// lfs f11,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f11.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// add r3,r8,r3
	ctx.r3.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r4,r8,r4
	ctx.r4.u64 = ctx.r8.u64 + ctx.r4.u64;
	// stw r9,364(r1)
	PPC_STORE_U32(ctx.r1.u32 + 364, ctx.r9.u32);
	// fsubs f9,f8,f12
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// lwz r9,56(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// fsubs f8,f7,f10
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fadds f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fmuls f7,f13,f9
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmuls f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// fmadds f11,f11,f8,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + ctx.f7.f64));
	// stfs f11,0(r14)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fmsubs f13,f13,f8,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 - ctx.f9.f64));
	// stfs f13,0(r9)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fmuls f9,f13,f12
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// fmuls f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmadds f11,f11,f10,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 + ctx.f9.f64));
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,636(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	// fmsubs f13,f13,f10,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 - ctx.f12.f64));
	// stfs f13,0(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,-26212(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// xor r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// bne 0x82c9500c
	if (!ctx.cr0.eq) goto loc_82C9500C;
loc_82C96A08:
	// addi r1,r1,944
	ctx.r1.s64 = ctx.r1.s64 + 944;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82C96A14;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C96A18"))) PPC_WEAK_FUNC(sub_82C96A18);
PPC_FUNC_IMPL(__imp__sub_82C96A18) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28944
	ctx.r5.s64 = ctx.r11.s64 + -28944;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,20432
	ctx.r4.s64 = ctx.r11.s64 + 20432;
	// b 0x82cab890
	sub_82CAB890(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C96A30"))) PPC_WEAK_FUNC(sub_82C96A30);
PPC_FUNC_IMPL(__imp__sub_82C96A30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82C96A38;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82C96A40;
	__savefpr_14(ctx, base);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// bge cr6,0x82c96ec4
	if (!ctx.cr6.lt) goto loc_82C96EC4;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r23,r8,r9
	ctx.r23.s64 = ctx.r9.s64 - ctx.r8.s64;
	// stw r10,-304(r1)
	PPC_STORE_U32(ctx.r1.u32 + -304, ctx.r10.u32);
loc_82C96A5C:
	// rlwinm r8,r7,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r31,r6,1,0,30
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r27,r8,r6
	ctx.r27.u64 = ctx.r8.u64 + ctx.r6.u64;
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r5,r6,3
	ctx.r5.s64 = ctx.r6.s64 * 3;
	// lfsx f8,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f23,f8,f0
	ctx.f23.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// fsubs f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// add r29,r31,r7
	ctx.r29.u64 = ctx.r31.u64 + ctx.r7.u64;
	// fsubs f8,f13,f7
	ctx.f8.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
	// add r28,r5,r7
	ctx.r28.u64 = ctx.r5.u64 + ctx.r7.u64;
	// fadds f13,f7,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 + ctx.f13.f64));
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfsx f12,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r31,r6,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r29,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// add r26,r6,r7
	ctx.r26.u64 = ctx.r6.u64 + ctx.r7.u64;
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r22,r5,r3
	ctx.r22.u64 = ctx.r5.u64 + ctx.r3.u64;
	// rlwinm r25,r26,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f6,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// add r21,r5,r4
	ctx.r21.u64 = ctx.r5.u64 + ctx.r4.u64;
	// lfsx f5,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f7,f12,f6
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// rlwinm r29,r28,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f12,f6,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// add r20,r25,r3
	ctx.r20.u64 = ctx.r25.u64 + ctx.r3.u64;
	// lfsx f4,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r24,r26,3,0,28
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f3,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// add r19,r25,r4
	ctx.r19.u64 = ctx.r25.u64 + ctx.r4.u64;
	// fsubs f6,f5,f11
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// fadds f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// lfs f1,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f2,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f5,f3,f4
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// add r18,r24,r3
	ctx.r18.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfs f28,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f31,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f3,f2,f1
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// add r17,r24,r4
	ctx.r17.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// rlwinm r28,r27,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f27,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f30,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f1,f31,f28
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f28.f64));
	// add r27,r9,r10
	ctx.r27.u64 = ctx.r9.u64 + ctx.r10.u64;
	// fsubs f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// lfs f26,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f28,f27,f30
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// lfsx f10,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// lfs f25,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fadds f27,f26,f10
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f10.f64));
	// lfsx f9,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f10,f10,f26
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f26.f64));
	// lfsx f29,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f26,f9,f25
	ctx.f26.f64 = double(float(ctx.f9.f64 - ctx.f25.f64));
	// lfsx f24,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f9,f25,f9
	ctx.f9.f64 = double(float(ctx.f25.f64 + ctx.f9.f64));
	// fadds f25,f24,f29
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// mulli r25,r7,3
	ctx.r25.s64 = ctx.r7.s64 * 3;
	// fadds f18,f7,f23
	ctx.f18.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// fadds f17,f11,f13
	ctx.f17.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fadds f16,f1,f5
	ctx.f16.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fadds f22,f12,f8
	ctx.f22.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// fadds f15,f30,f2
	ctx.f15.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// fsubs f21,f0,f6
	ctx.f21.f64 = double(float(ctx.f0.f64 - ctx.f6.f64));
	// add r25,r25,r6
	ctx.r25.u64 = ctx.r25.u64 + ctx.r6.u64;
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// mulli r16,r26,12
	ctx.r16.s64 = ctx.r26.s64 * 12;
	// fadds f14,f25,f27
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// mulli r5,r7,12
	ctx.r5.s64 = ctx.r7.s64 * 12;
	// rlwinm r15,r25,2,0,29
	ctx.r15.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r26,r11,16
	ctx.r26.s64 = ctx.r11.s64 + 16;
	// add r14,r16,r4
	ctx.r14.u64 = ctx.r16.u64 + ctx.r4.u64;
	// lfsx f19,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// add r16,r16,r3
	ctx.r16.u64 = ctx.r16.u64 + ctx.r3.u64;
	// stfs f19,-320(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfsx f19,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// add r24,r5,r8
	ctx.r24.u64 = ctx.r5.u64 + ctx.r8.u64;
	// stfs f19,-328(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// addi r25,r11,20
	ctx.r25.s64 = ctx.r11.s64 + 20;
	// lfsx f20,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// stw r16,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r16.u32);
	// add r16,r15,r4
	ctx.r16.u64 = ctx.r15.u64 + ctx.r4.u64;
	// add r15,r15,r3
	ctx.r15.u64 = ctx.r15.u64 + ctx.r3.u64;
	// stfs f19,-312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfsx f24,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// stw r15,-324(r1)
	PPC_STORE_U32(ctx.r1.u32 + -324, ctx.r15.u32);
	// lwz r15,-316(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// lfs f19,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lwz r15,-324(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	// stfs f19,-308(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f19,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-332(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f19,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,-336(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f19,f20,f24
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fsubs f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// lfsx f20,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-324(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfsx f20,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f18,0(r3)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f17,0(r4)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfsx f16,r31,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfsx f15,r31,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// stfsx f14,r8,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f19,f9
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f9.f64));
	// stfsx f14,r8,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-336(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f14,-332(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f20,-328(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// fadds f14,f18,f15
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfsx f14,r10,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f18,-312(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f14,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f14,f21
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f21.f64));
	// fmuls f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f22.f64));
	// lfs f18,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f18,f22,f15
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfsx f22,r5,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fmadds f22,f18,f21,f14
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 + ctx.f14.f64));
	// stfsx f22,r5,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f22,f17
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmuls f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// fadds f0,f6,f0
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// lfs f15,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fmadds f18,f21,f15,f18
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f15.f64 + ctx.f18.f64));
	// stfsx f18,r27,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// lfs f21,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f30.f64));
	// lfs f18,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f18.f64 = double(temp.f32);
	// fadds f11,f29,f26
	ctx.f11.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// fsubs f30,f26,f29
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fsubs f8,f23,f7
	ctx.f8.f64 = double(float(ctx.f23.f64 - ctx.f7.f64));
	// fmsubs f1,f22,f15,f17
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f15.f64 - ctx.f17.f64));
	// stfsx f1,r27,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f29,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f7,f10,f24
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f24.f64));
	// fmuls f26,f29,f0
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// lfs f1,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fadds f23,f21,f18
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// fsubs f6,f20,f16
	ctx.f6.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// fadds f10,f24,f10
	ctx.f10.f64 = double(float(ctx.f24.f64 + ctx.f10.f64));
	// fmsubs f12,f1,f12,f26
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 - ctx.f26.f64));
	// stfsx f12,r30,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fmadds f0,f1,f0,f29
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f29.f64));
	// stfsx f0,r30,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f0,f8
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// fmuls f8,f12,f8
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// fmadds f12,f12,f13,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f1.f64));
	// stfsx f12,r9,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f0,f0,f13,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - ctx.f8.f64));
	// stfsx f0,r9,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r9,-304(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	// fmuls f12,f13,f7
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f0,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fsubs f8,f3,f31
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fmsubs f12,f0,f11,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f11.f64 - ctx.f12.f64));
	// stfsx f12,r24,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fmadds f0,f0,f7,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 + ctx.f13.f64));
	// stfsx f0,r24,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fadds f7,f28,f4
	ctx.f7.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// fmuls f12,f13,f23
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmsubs f12,f0,f6,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f6.f64 - ctx.f12.f64));
	// stfsx f12,r29,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fmadds f0,f0,f23,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64 + ctx.f13.f64));
	// stfsx f0,r29,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f5
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f11,f13,f5
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fsubs f5,f4,f28
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f28.f64));
	// fmadds f13,f13,f2,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f12.f64));
	// stfsx f13,r28,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f0,f0,f2,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f2.f64 - ctx.f11.f64));
	// stfsx f0,r28,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f9,f19
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f19.f64));
	// fmuls f6,f13,f10
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f13,f30
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r4,r9,r4
	ctx.r4.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fsubs f13,f27,f25
	ctx.f13.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f11,f16,f20
	ctx.f11.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fsubs f9,f18,f21
	ctx.f9.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// fmsubs f6,f0,f30,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f30.f64 - ctx.f6.f64));
	// stfs f6,0(r21)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fmadds f0,f0,f10,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 + ctx.f2.f64));
	// stfs f0,0(r22)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fadds f6,f31,f3
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lwz r9,-316(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f0,f13
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fmuls f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmadds f10,f10,f12,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f4.f64));
	// stfs f10,0(r18)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fmsubs f0,f0,f12,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64 - ctx.f13.f64));
	// stfs f0,0(r17)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// lfs f13,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f9
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f0,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmsubs f12,f0,f11,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f11.f64 - ctx.f12.f64));
	// stfs f12,0(r14)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fmadds f0,f0,f9,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 + ctx.f13.f64));
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// fmuls f12,f13,f7
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fmsubs f12,f0,f8,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f8.f64 - ctx.f12.f64));
	// stfs f12,0(r19)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fmadds f0,f0,f7,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 + ctx.f13.f64));
	// stfs f0,0(r20)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// lfs f13,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f5
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// lfs f0,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f6
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmsubs f12,f0,f6,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f6.f64 - ctx.f12.f64));
	// stfs f12,0(r16)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fmadds f0,f0,f5,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f5.f64 + ctx.f13.f64));
	// stfs f0,0(r15)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// lwz r10,-26212(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// xor r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 ^ ctx.r7.u64;
	// bne 0x82c96a5c
	if (!ctx.cr0.eq) goto loc_82C96A5C;
loc_82C96EC4:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82C96ECC;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C96ED0"))) PPC_WEAK_FUNC(sub_82C96ED0);
PPC_FUNC_IMPL(__imp__sub_82C96ED0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28872
	ctx.r5.s64 = ctx.r11.s64 + -28872;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,27184
	ctx.r4.s64 = ctx.r11.s64 + 27184;
	// b 0x82cab890
	sub_82CAB890(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C96EE8"))) PPC_WEAK_FUNC(sub_82C96EE8);
PPC_FUNC_IMPL(__imp__sub_82C96EE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82C96EF0;
	__savegprlr_26(ctx, base);
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82c96fe8
	if (!ctx.cr6.lt) goto loc_82C96FE8;
	// rlwinm r27,r10,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r8.s64;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
loc_82C96F0C:
	// add r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 + ctx.r7.u64;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r8,r7,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r30,r9,r3
	ctx.r30.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r29,r8,r3
	ctx.r29.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r28,r5,r3
	ctx.r28.u64 = ctx.r5.u64 + ctx.r3.u64;
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fadds f6,f12,f0
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// lfs f9,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// lfs f11,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fadds f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfs f8,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// addi r31,r11,4
	ctx.r31.s64 = ctx.r11.s64 + 4;
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stfs f6,0(r3)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f6,f11,f13
	ctx.f6.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfs f6,0(r4)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfs f12,0(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fsubs f12,f10,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f10,0(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f9,f8,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfs f8,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fmuls f11,f10,f12
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmuls f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmadds f11,f8,f9,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f11.f64));
	// stfs f11,0(r28)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fmsubs f12,f10,f9,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 - ctx.f12.f64));
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// lfs f11,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f0
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmuls f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmadds f11,f11,f13,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f10.f64));
	// stfs f11,0(r29)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fmsubs f0,f12,f13,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f0.f64));
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lwz r9,-26212(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + -26212);
	// xor r6,r9,r6
	ctx.r6.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// xor r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 ^ ctx.r7.u64;
	// bne 0x82c96f0c
	if (!ctx.cr0.eq) goto loc_82C96F0C;
loc_82C96FE8:
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C96FF0"))) PPC_WEAK_FUNC(sub_82C96FF0);
PPC_FUNC_IMPL(__imp__sub_82C96FF0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28800
	ctx.r5.s64 = ctx.r11.s64 + -28800;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,28392
	ctx.r4.s64 = ctx.r11.s64 + 28392;
	// b 0x82cab890
	sub_82CAB890(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C97008"))) PPC_WEAK_FUNC(sub_82C97008);
PPC_FUNC_IMPL(__imp__sub_82C97008) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82C97010;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82C97018;
	__savefpr_14(ctx, base);
	// stwu r1,-960(r1)
	ea = -960 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r7,40
	ctx.r11.s64 = ctx.r7.s64 * 40;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82c9ad20
	if (!ctx.cr6.lt) goto loc_82C9AD20;
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// lis r27,-32235
	ctx.r27.s64 = -2112552960;
	// lis r26,-32235
	ctx.r26.s64 = -2112552960;
	// lfs f0,30372(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 30372);
	ctx.f0.f64 = double(temp.f32);
	// lis r25,-32235
	ctx.r25.s64 = -2112552960;
	// stfs f0,632(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 632, temp.u32);
	// stw r10,652(r1)
	PPC_STORE_U32(ctx.r1.u32 + 652, ctx.r10.u32);
	// lfs f0,30368(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 30368);
	ctx.f0.f64 = double(temp.f32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// stfs f0,620(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// lis r24,-32235
	ctx.r24.s64 = -2112552960;
	// lfs f0,30364(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 30364);
	ctx.f0.f64 = double(temp.f32);
	// lis r23,-32235
	ctx.r23.s64 = -2112552960;
	// stfs f0,648(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 648, temp.u32);
	// lis r22,-32235
	ctx.r22.s64 = -2112552960;
	// lfs f0,30360(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 30360);
	ctx.f0.f64 = double(temp.f32);
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// stfs f0,640(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 640, temp.u32);
	// stw r10,588(r1)
	PPC_STORE_U32(ctx.r1.u32 + 588, ctx.r10.u32);
	// lfs f0,30348(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 30348);
	ctx.f0.f64 = double(temp.f32);
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// stfs f0,628(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// lis r5,-32235
	ctx.r5.s64 = -2112552960;
	// lis r7,-32235
	ctx.r7.s64 = -2112552960;
	// lfs f0,30344(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 30344);
	ctx.f0.f64 = double(temp.f32);
	// lis r8,-32235
	ctx.r8.s64 = -2112552960;
	// stfs f0,624(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// lfs f0,30352(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 30352);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// stfs f0,644(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 644, temp.u32);
	// lfs f0,30356(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 30356);
	ctx.f0.f64 = double(temp.f32);
	// lfs f7,27784(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 27784);
	ctx.f7.f64 = double(temp.f32);
	// lfs f10,27776(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 27776);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-29656(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29656);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-29652(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29652);
	ctx.f12.f64 = double(temp.f32);
	// lfs f6,27780(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 27780);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,27792(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 27792);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,27788(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 27788);
	ctx.f4.f64 = double(temp.f32);
	// stfs f0,636(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 636, temp.u32);
loc_82C970D4:
	// lfs f1,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfs f9,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f31,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f23,f9,f1
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// stfs f23,24(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f23,f9,f31
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f3,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f3.f64 = double(temp.f32);
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f27,f3,f31
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// stfs f23,40(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f23,f8,f3
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// stfs f23,16(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f30,f3,f1
	ctx.f30.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f2,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f14,f9,f3
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmuls f23,f8,f2
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// lfs f0,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f28,f2,f31
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f23,20(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f26,f13,f31
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f25,f0,f31
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f31,f8,f31
	ctx.f31.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// stfs f31,344(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fmuls f21,f13,f1
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmuls f24,f0,f1
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmuls f15,f9,f2
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmuls f29,f2,f1
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// fmuls f18,f0,f3
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmuls f17,f13,f2
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f16,f13,f3
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f19,f0,f2
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f1,f8,f1
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// stfs f1,248(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fsubs f1,f30,f28
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfs f1,204(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fadds f22,f21,f25
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfs f22,232(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fsubs f21,f21,f25
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// stfs f21,456(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,408(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// fsubs f28,f24,f26
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfs f28,412(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fadds f23,f24,f26
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f23,268(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fadds f31,f27,f29
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfs f31,468(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fsubs f20,f18,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f20,208(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fadds f26,f17,f18
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f26,464(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfs f29,384(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fsubs f27,f16,f19
	ctx.f27.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfs f27,472(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f19,424(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f25.f64 = double(temp.f32);
	// fadds f24,f25,f15
	ctx.f24.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f24,292(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,188(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f25,f9,f13
	ctx.f25.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f24,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f24.f64 = double(temp.f32);
	// fadds f18,f24,f14
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f18,496(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// fmuls f18,f8,f0
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f24,316(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fmuls f24,f9,f0
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fadds f17,f18,f25
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f17,f8,f13
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fsubs f15,f17,f24
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fadds f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,532(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f24,452(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// fmuls f14,f9,f30
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f14,f8,f29
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f14,f1,f13
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f14,f31,f0
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f14,f1,f0
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f14,f30,f13
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// stfs f25,388(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fmuls f24,f8,f30
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// stfs f15,500(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f0,f29,f0
	ctx.f0.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// stfs f0,92(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmuls f30,f31,f13
	ctx.f30.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// stfs f30,248(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f25,f8,f1
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f15,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f9,f31
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f17,f9,f29
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f16,f9,f1
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// fmuls f15,f8,f31
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f30,f29,f13
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fsubs f13,f25,f18
	ctx.f13.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// stfs f13,196(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fadds f13,f18,f25
	ctx.f13.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f13,f17,f24
	ctx.f13.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// stfs f13,76(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f13,f24,f17
	ctx.f13.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// stfs f13,68(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fadds f13,f15,f16
	ctx.f13.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f13,320(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fsubs f13,f16,f15
	ctx.f13.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f13,104(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f13,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// lfs f29,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f25,f13,f29
	ctx.f25.f64 = double(float(ctx.f13.f64 - ctx.f29.f64));
	// stfs f25,144(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fadds f13,f29,f13
	ctx.f13.f64 = double(float(ctx.f29.f64 + ctx.f13.f64));
	// stfs f13,128(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fadds f29,f0,f14
	ctx.f29.f64 = double(float(ctx.f0.f64 + ctx.f14.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f13,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f13.f64 = double(temp.f32);
	// fadds f18,f13,f15
	ctx.f18.f64 = double(float(ctx.f13.f64 + ctx.f15.f64));
	// lfs f0,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f0.f64 = double(temp.f32);
	// lfs f24,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f24.f64 = double(temp.f32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f25,f24,f30
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// fadds f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// lfs f24,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f24.f64 = double(temp.f32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f24,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f13,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// stfs f18,276(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// stfs f29,448(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// stfs f25,436(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// stfs f30,192(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// stfs f17,432(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f24,344(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// stfs f15,264(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f14,f18,f8
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f18,f9,f21
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f18,f8,f23
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f23.f64));
	// stfs f18,348(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmuls f23,f9,f23
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// stfs f23,416(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f23,f9,f19
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f19.f64));
	// stfs f23,332(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmuls f23,f8,f20
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f20.f64));
	// stfs f23,340(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f23,f8,f19
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// stfs f23,352(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fmuls f23,f9,f20
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f20.f64));
	// stfs f23,356(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fmuls f21,f8,f21
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// stfs f21,428(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// fmuls f23,f9,f22
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f22.f64));
	// stfs f23,260(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f23,f8,f28
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// stfs f23,20(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f23,f8,f22
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// stfs f23,24(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f23,f9,f28
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// stfs f23,364(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fmuls f22,f30,f9
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// stfs f22,60(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f22,f30,f8
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// stfs f22,376(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmuls f22,f17,f9
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// stfs f22,404(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fmuls f22,f16,f8
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f8.f64));
	// stfs f22,420(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// fmuls f22,f16,f9
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// stfs f22,372(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fmuls f22,f24,f8
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmuls f22,f15,f8
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// stfs f22,380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fmuls f22,f15,f9
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// stfs f22,400(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// fmuls f20,f9,f26
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmuls f21,f8,f27
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f19,f9,f27
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmuls f18,f8,f26
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmuls f17,f17,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// fadds f23,f20,f21
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f23,444(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,328(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fsubs f23,f19,f18
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f23,284(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f22,440(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// lfs f15,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f22,460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f15,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f15,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// lfs f20,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f21
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f22,396(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// stfs f20,160(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f22,308(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// stfs f20,304(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fadds f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f20,216(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f20,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f29,f9
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,164(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f20,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f25,f9
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// lfs f21,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f31,f0,f31
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,212(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f21,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// stfs f21,272(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f20,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f25,f8
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// lfs f21,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f21,220(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f20,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f21,280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fmuls f20,f29,f8
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fsubs f15,f19,f16
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f15,332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f15,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f0,f15
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f15.f64));
	// fadds f21,f18,f20
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f21,36(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,100(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f20,f16,f19
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f20,520(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// lfs f20,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// stfs f20,428(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// fadds f20,f17,f18
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f20,416(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f20,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f16,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,336(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f19,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f20,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f20,352(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fmuls f20,f24,f9
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// stfs f18,356(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f17,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f14.f64 = double(temp.f32);
	// stfs f19,260(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// stfs f18,364(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fsubs f16,f16,f20
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f16,540(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,348(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f20.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f20,340(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmadds f20,f13,f23,f15
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f23.f64 + ctx.f15.f64));
	// stfs f20,380(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f20,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f0,f20
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f20.f64));
	// fmsubs f20,f13,f21,f20
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f21.f64 - ctx.f20.f64));
	// stfs f20,172(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f20,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f0,f18
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f18.f64));
	// fmuls f20,f0,f20
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f20.f64));
	// fmuls f14,f0,f3
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmuls f3,f0,f1
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// stfs f3,16(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmsubs f1,f13,f1,f31
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 - ctx.f31.f64));
	// stfs f1,48(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmuls f29,f0,f29
	ctx.f29.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// lfs f1,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f24,f13,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// fmuls f19,f0,f19
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmuls f21,f0,f21
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f21.f64));
	// fmuls f23,f0,f23
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmuls f2,f0,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// stfs f2,20(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmsubs f31,f13,f1,f20
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 - ctx.f20.f64));
	// stfs f31,180(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f31,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f17,f0,f22
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f22.f64));
	// fmsubs f31,f13,f31,f18
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f18.f64));
	// stfs f31,244(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f31,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f22,f13,f22
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// fmadds f31,f13,f31,f29
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f29.f64));
	// lfs f29,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f29.f64 = double(temp.f32);
	// stfs f31,372(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fmadds f31,f0,f29,f24
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f29.f64 + ctx.f24.f64));
	// stfs f31,120(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f16,f13,f28
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f31,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f27,f0,f27
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fmadds f31,f13,f31,f19
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f19.f64));
	// stfs f31,124(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f31,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f25,f0,f25
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmadds f31,f13,f31,f21
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f21.f64));
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f31,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f15,f0,f30
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmsubs f31,f13,f31,f23
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f23.f64));
	// stfs f31,400(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// lfs f31,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f30,f13,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fmr f3,f31
	ctx.f3.f64 = ctx.f31.f64;
	// fmuls f28,f0,f28
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// fmuls f26,f0,f26
	ctx.f26.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// fmsubs f31,f13,f3,f17
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f17.f64));
	// stfs f31,492(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// fmadds f3,f0,f3,f22
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f3.f64 + ctx.f22.f64));
	// stfs f3,528(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// lfs f3,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f3.f64 = double(temp.f32);
	// fmr f2,f3
	ctx.f2.f64 = ctx.f3.f64;
	// lfs f31,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f3,f0,f2,f16
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f2.f64 + ctx.f16.f64));
	// stfs f3,224(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f3,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f3,f13,f3,f27
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 + ctx.f27.f64));
	// stfs f3,28(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f3,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f13,f3,f25
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f25.f64));
	// stfs f3,376(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmsubs f3,f13,f31,f15
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f15.f64));
	// stfs f3,508(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// lfs f3,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f3,f13,f3,f14
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 + ctx.f14.f64));
	// stfs f3,420(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f3,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f3.f64 = double(temp.f32);
	// lfs f27,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f3,f13,f3,f27
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 + ctx.f27.f64));
	// stfs f3,156(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmadds f3,f0,f31,f30
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f31.f64 + ctx.f30.f64));
	// stfs f3,524(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// fmsubs f3,f13,f2,f28
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 - ctx.f28.f64));
	// stfs f3,324(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f3,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f3,f13,f3,f30
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f30.f64));
	// stfs f3,404(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// lfs f3,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f13,f3,f26
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f26.f64));
	// stfs f3,52(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f3,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f31,f0,f3
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f23,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f0,f23
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// stfs f23,24(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f25,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f0,f25
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// lfs f25,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f25.f64 = double(temp.f32);
	// lfs f3,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f0,f25
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f30,f0,f3
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f25,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f25.f64 = double(temp.f32);
	// lfs f3,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f25,f0,f25
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f28,f0,f3
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// stfs f25,20(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f0,f3
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f31,f13,f29,f31
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f29.f64 - ctx.f31.f64));
	// stfs f31,140(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f31,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f24,f0,f3
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmr f23,f31
	ctx.f23.f64 = ctx.f31.f64;
	// lfs f2,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f19,f13,f3
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// lfs f3,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f0,f3
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f0,f3
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f0,f2
	ctx.f26.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f15,f0,f3
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f0,f3
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f0,f3
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// stfs f3,16(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f20,f13,f2
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// lfs f3,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f1,f13,f23,f1
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f23.f64 + ctx.f1.f64));
	// stfs f1,288(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f1,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f0,f2
	ctx.f16.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmr f25,f1
	ctx.f25.f64 = ctx.f1.f64;
	// fmuls f2,f13,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmadds f1,f13,f25,f30
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f25.f64 + ctx.f30.f64));
	// stfs f1,84(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f1,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f13,f1,f28
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f28.f64));
	// stfs f1,228(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f1,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f13,f1,f27
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f27,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f27.f64 = double(temp.f32);
	// stfs f1,176(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmsubs f1,f13,f27,f26
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f27.f64 - ctx.f26.f64));
	// stfs f1,512(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// fmsubs f1,f13,f3,f24
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 - ctx.f24.f64));
	// stfs f1,72(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f1,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f1,f13,f1,f22
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 - ctx.f22.f64));
	// lfs f26,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f26.f64 = double(temp.f32);
	// stfs f1,368(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fmsubs f1,f13,f26,f21
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f26.f64 - ctx.f21.f64));
	// stfs f1,184(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmadds f1,f0,f27,f20
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f27.f64 + ctx.f20.f64));
	// stfs f1,504(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fmadds f1,f0,f3,f19
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f3.f64 + ctx.f19.f64));
	// lfs f28,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f28.f64 = double(temp.f32);
	// stfs f1,116(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmsubs f1,f13,f28,f18
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f28.f64 - ctx.f18.f64));
	// stfs f1,516(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// lfs f1,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f1.f64 = double(temp.f32);
	// lfs f30,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f1,f13,f1,f17
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 - ctx.f17.f64));
	// stfs f1,200(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmsubs f1,f13,f30,f16
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f30.f64 - ctx.f16.f64));
	// stfs f1,240(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// stfs f2,40(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// rlwinm r9,r6,6,0,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f1,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f1.f64 = double(temp.f32);
	// mulli r8,r6,192
	ctx.r8.s64 = ctx.r6.s64 * 192;
	// fmadds f1,f13,f1,f15
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f15.f64));
	// stfs f1,384(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f1,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f31,f13,f1,f14
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f14.f64));
	// stfs f31,112(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f31,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f31.f64 = double(temp.f32);
	// lfs f2,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f31,f13,f2,f31
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 - ctx.f31.f64));
	// stfs f31,388(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f31,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f31.f64 = double(temp.f32);
	// rlwinm r7,r6,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f24,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f24.f64 = double(temp.f32);
	// mulli r5,r6,160
	ctx.r5.s64 = ctx.r6.s64 * 160;
	// fmsubs f24,f13,f31,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f24.f64));
	// stfs f24,360(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f13,f22,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f22.f64 - ctx.f24.f64));
	// stfs f24,456(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// rlwinm r10,r6,7,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 7) & 0xFFFFFF80;
	// lfsx f17,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f19,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f15.f64));
	// lfsx f18,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f0,f30,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f30.f64 + ctx.f24.f64));
	// stfs f24,132(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f24,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f21,f13,f24
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// lfs f24,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f24.f64 = double(temp.f32);
	// stfs f17,268(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f20,f13,f24
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// lfsx f17,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,276(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfsx f17,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f17,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f17,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f21,f0,f28,f21
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f28.f64 + ctx.f21.f64));
	// stfs f21,536(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// fmadds f21,f0,f31,f20
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f31.f64 + ctx.f20.f64));
	// stfs f21,256(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfsx f21,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// lfsx f20,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f19,f16
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f19,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f19,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f18,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmadds f19,f20,f18,f17
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 + ctx.f17.f64));
	// lfs f18,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f20,f18,f21
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 - ctx.f21.f64));
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f21,f20,f16
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f16.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f20,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f20.f64));
	// lfs f17,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f21,f17,f15
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f16,f21,f16,f14
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,408(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f16,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f16.f64 = double(temp.f32);
	// mulli r30,r6,96
	ctx.r30.s64 = ctx.r6.s64 * 96;
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f21,f16,f15
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f21,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f15,f15,f21,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f20.f64 = double(temp.f32);
	// mulli r28,r6,144
	ctx.r28.s64 = ctx.r6.s64 * 144;
	// fmsubs f21,f20,f21,f14
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,24(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f21,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fadds f20,f19,f21
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f20,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fsubs f14,f20,f18
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfs f18,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f18,232(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f18,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f18.f64 = double(temp.f32);
	// mulli r31,r6,224
	ctx.r31.s64 = ctx.r6.s64 * 224;
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fsubs f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,408(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f16,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fsubs f16,f14,f19
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,392(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fsubs f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f19,616(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f21,592(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f19,416(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// lfs f19,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// stfs f21,296(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fmuls f18,f20,f19
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f21,f19
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// lfs f19,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f21,f19,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f19,f15,f21
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfs f21,412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fsubs f21,f18,f20
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// lfsx f15,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f20,60(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f20,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f18,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f21,f19
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfs f21,264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfsx f21,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,20(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f21,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f21,268(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfsx f21,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f14,232(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stfs f21,276(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// mulli r27,r6,80
	ctx.r27.s64 = ctx.r6.s64 * 80;
	// lfs f21,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f21.f64 = double(temp.f32);
	// mulli r26,r6,208
	ctx.r26.s64 = ctx.r6.s64 * 208;
	// fmuls f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64));
	// lfs f19,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// lfs f19,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f14,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f21,f18,f14,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f18,f14,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f14.f64 - ctx.f20.f64));
	// stfs f20,24(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f19,f20,f14,f19
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f19,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f14.f64));
	// lfs f19,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f15.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f19,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f19
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f19,f20,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64 + ctx.f18.f64));
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfs f19,396(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f15.f64));
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f15,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfs f14,400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// fadds f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,300(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f21,f15
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfs f18,364(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfs f21,376(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f21,f14
	ctx.f18.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// fadds f15,f14,f21
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// lfs f21,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f19,f21
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// fmuls f19,f18,f12
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f19,584(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// fmuls f19,f15,f12
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfs f19,488(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f19,f14,f12
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f19,548(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// stfs f21,556(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 556, temp.u32);
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f20,f21
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f21,460(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// mulli r25,r6,240
	ctx.r25.s64 = ctx.r6.s64 * 240;
	// lfs f21,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f21.f64 = double(temp.f32);
	// mulli r24,r6,112
	ctx.r24.s64 = ctx.r6.s64 * 112;
	// fmsubs f21,f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 - ctx.f19.f64));
	// lfs f20,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// stfs f18,92(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f15,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f15,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f18,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f19,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f15,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,396(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// lfsx f15,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,424(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// stfs f21,264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfsx f21,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f14.f64));
	// fmuls f15,f21,f15
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f15.f64));
	// lfs f21,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// lfsx f20,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f21,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f20,f21,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 + ctx.f15.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f20,f15,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 - ctx.f14.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f15.f64));
	// lfs f20,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f14,f20,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f20.f64 + ctx.f18.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f14,f20,f19
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f19,f14,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f19,f15,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64 - ctx.f18.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fsubs f18,f15,f20
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f19,f15
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// stfs f19,44(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fsubs f19,f15,f18
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// lfs f14,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f18,f14,f20
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// lfs f15,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f18,f15,f21
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfs f21,380(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fadds f21,f20,f14
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f21,412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmuls f20,f19,f10
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fmuls f15,f21,f11
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f21,f11
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// rlwinm r21,r6,3,0,28
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f21,468(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// mulli r22,r6,176
	ctx.r22.s64 = ctx.r6.s64 * 176;
	// fmsubs f20,f21,f11,f20
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 - ctx.f20.f64));
	// stfs f20,552(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// fmadds f21,f21,f10,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f19.f64));
	// stfs f21,596(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f10,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 - ctx.f15.f64));
	// stfs f21,480(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f19,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f19.f64 = double(temp.f32);
	// mulli r23,r6,48
	ctx.r23.s64 = ctx.r6.s64 * 48;
	// lfs f20,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f19,f20
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// fmadds f21,f21,f10,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f14.f64));
	// stfs f21,564(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// lfs f21,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f19,f21
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f19,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f21,f19,f21,f18
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 + ctx.f18.f64));
	// fmsubs f20,f19,f20,f15
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64 - ctx.f15.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f15,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f15,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f19,f21
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfs f18,92(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f21,264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f21,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f19,f21,f20
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f19,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// stfs f21,44(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f21,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f14.f64));
	// fmuls f15,f21,f15
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f15.f64));
	// lfs f21,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f18,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f19,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// lfsx f20,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f20,f21,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 + ctx.f15.f64));
	// lfs f15,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f20,f15,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 - ctx.f14.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f26
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f20,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f14,f20,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f20.f64 + ctx.f18.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f25
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f14,f20,f19
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f20.f64 - ctx.f19.f64));
	// lfs f19,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f25,f19,f25,f15
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f25.f64 + ctx.f15.f64));
	// fmsubs f26,f19,f26,f18
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 - ctx.f18.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f21,f18
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// mulli r19,r6,72
	ctx.r19.s64 = ctx.r6.s64 * 72;
	// fsubs f18,f15,f20
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// mulli r18,r6,200
	ctx.r18.s64 = ctx.r6.s64 * 200;
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f19,f15
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f18
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// mulli r17,r6,40
	ctx.r17.s64 = ctx.r6.s64 * 40;
	// fsubs f18,f15,f21
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfs f21,276(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfs f21,268(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f15,f19,f10
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// mulli r16,r6,168
	ctx.r16.s64 = ctx.r6.s64 * 168;
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// mulli r15,r6,232
	ctx.r15.s64 = ctx.r6.s64 * 232;
	// mulli r20,r6,136
	ctx.r20.s64 = ctx.r6.s64 * 136;
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f10
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,428(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f18,f11,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f20.f64));
	// stfs f20,612(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f21,f20,f11,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 - ctx.f21.f64));
	// stfs f21,604(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// lfs f21,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f18,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f21,f11,f15
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f15.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmsubs f21,f21,f10,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 - ctx.f19.f64));
	// lfsx f18,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f18,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f18,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f18,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f18,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f18,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,204(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfsx f18,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,292(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfsx f18,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f21,600(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// stfs f18,316(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfsx f21,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f21,f18
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// lfs f18,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f21,f18
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// lfsx f19,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// stfs f20,572(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// lfsx f20,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// stfs f21,24(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmadds f21,f20,f18,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f20,f20,f18,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfs f20,100(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f20,f18
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f18.f64));
	// fmuls f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f15.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f23,f20,f23,f14
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 + ctx.f14.f64));
	// lfs f14,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f20,f14,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f14.f64 - ctx.f19.f64));
	// stfs f20,232(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f20,f24
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f24.f64));
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f24
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f24.f64));
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f20,f24,f18
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f20,f20,f18,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 - ctx.f15.f64));
	// stfs f20,140(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f20,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f20.f64));
	// fmuls f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f31,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64 + ctx.f19.f64));
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f31,f19,f31,f14
	ctx.f31.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 - ctx.f14.f64));
	// stfs f31,16(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f31,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f31.f64 = double(temp.f32);
	// lfs f19,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f31,f19
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f19.f64));
	// lfs f19,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f19.f64 = double(temp.f32);
	// lfs f31,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f31.f64 = double(temp.f32);
	// fmadds f31,f31,f19,f18
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f18,f19,f15
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f15.f64));
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f18,f24,f23
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fadds f15,f31,f20
	ctx.f15.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// fsubs f31,f20,f31
	ctx.f31.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// stfs f31,20(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f31,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f31.f64 = double(temp.f32);
	// fadds f20,f19,f31
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f31.f64));
	// stfs f20,56(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f31,f31,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f19.f64));
	// stfs f31,120(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f31,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f31.f64 = double(temp.f32);
	// lfs f20,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64));
	// lfs f19,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f19.f64 = double(temp.f32);
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f20,f19,f31,f14
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 + ctx.f14.f64));
	// lfs f31,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f31.f64 = double(temp.f32);
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f31.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f31.f64));
	// lfs f31,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f26,f26,f31
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f31.f64));
	// fsubs f31,f23,f24
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// stfs f31,20(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f31,f21,f25
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// lfs f24,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f31,f24
	ctx.f24.f64 = double(float(ctx.f31.f64 - ctx.f24.f64));
	// stfs f24,100(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f24,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfs f24,204(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,104
	ctx.r14.s64 = ctx.r6.s64 * 104;
	// lfs f23,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f23,f24,f14
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64 - ctx.f14.f64));
	// lfs f21,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// lfs f21,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f21.f64 = double(temp.f32);
	// fadds f31,f21,f31
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f31.f64));
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f18,f26
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// stfs f14,484(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// fsubs f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f18.f64));
	// stfs f26,580(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// fsubs f26,f25,f23
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfs f26,576(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// fadds f26,f23,f25
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfs f26,476(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfsx f26,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f23,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r14,r6,248
	ctx.r14.s64 = ctx.r6.s64 * 248;
	// stfs f23,20(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f25,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r14,r6,120
	ctx.r14.s64 = ctx.r6.s64 * 120;
	// stfs f25,24(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f25,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,120(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfsx f25,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,36(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f25,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f23,f25
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// fmuls f14,f26,f25
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f18,f25
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// lfs f25,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f26,f25,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f25.f64 + ctx.f23.f64));
	// stfs f26,40(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f23,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f26,f23
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f26,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f26,f26,f25,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f25.f64 - ctx.f14.f64));
	// stfs f26,140(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f25,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f25.f64 = double(temp.f32);
	// lfs f14,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f26,f25
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f26,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f26,f14,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f26,f26,f18,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 - ctx.f23.f64));
	// lfs f23,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f25,f23,f18,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f18.f64 + ctx.f25.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f20,f18
	ctx.f23.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f24,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfs f18,112(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fadds f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// fsubs f18,f20,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f23,f18
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,292(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// fadds f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// stfs f24,316(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f20,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f20.f64 = double(temp.f32);
	// mulli r14,r6,184
	ctx.r14.s64 = ctx.r6.s64 * 184;
	// lfs f24,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// stfs f24,152(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f24,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f24.f64 = double(temp.f32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f20,f24
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stw r14,420(r1)
	PPC_STORE_U32(ctx.r1.u32 + 420, ctx.r14.u32);
	// fadds f20,f24,f20
	ctx.f20.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// mulli r14,r6,56
	ctx.r14.s64 = ctx.r6.s64 * 56;
	// fsubs f24,f19,f23
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// stfs f24,16(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// stfs f20,560(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stfs f23,332(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f23,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f31,f19
	ctx.f19.f64 = double(float(ctx.f31.f64 - ctx.f19.f64));
	// stfs f19,384(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f19,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfs f19,232(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f19,312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,236(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f19,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fadds f24,f19,f18
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// stfs f20,608(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f15,f12
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmsubs f23,f23,f20,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64 - ctx.f14.f64));
	// stfs f23,60(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f20,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f19,568(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// lfs f14,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f23,204(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfsx f23,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lwz r14,420(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// fmuls f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f14.f64));
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,24
	ctx.r14.s64 = ctx.r6.s64 * 24;
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,152
	ctx.r14.s64 = ctx.r6.s64 * 152;
	// stfs f15,112(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,136(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,216
	ctx.r14.s64 = ctx.r6.s64 * 216;
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,140(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,88
	ctx.r14.s64 = ctx.r6.s64 * 88;
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// lfs f23,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f19,f23
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// fmuls f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// lfs f23,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f20,f23,f15
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 + ctx.f15.f64));
	// stfs f23,36(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f23,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f20,f23,f14
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 - ctx.f14.f64));
	// stfs f23,56(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f23,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f23
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f23
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// lfs f23,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f23,f23,f20,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64 + ctx.f18.f64));
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f20,f18,f20,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f20.f64 - ctx.f19.f64));
	// stfs f20,208(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f20,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f19,f19,f20
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f30,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 + ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f30,f15,f30,f14
	ctx.f30.f64 = double(float(ctx.f15.f64 * ctx.f30.f64 - ctx.f14.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f30,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f30.f64 = double(temp.f32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f15.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f19,f14,f30,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f30.f64 + ctx.f19.f64));
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f19,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f19.f64));
	// lfs f19,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f30,f19,f30,f18
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 - ctx.f18.f64));
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f15,f18,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,112(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f15,f20
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f30,f15
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f15.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f30,f15,f30
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f30.f64));
	// stfs f30,72(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f30,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f30.f64 = double(temp.f32);
	// lfs f15,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f30,f15
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f15.f64));
	// fmuls f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f14.f64));
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f20.f64));
	// stfs f30,20(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// stfs f30,24(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f30,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f20,f30,f15
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 + ctx.f15.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// lfs f15,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,252
	ctx.r14.s64 = ctx.r6.s64 * 252;
	// fmsubs f20,f20,f15,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f25,f15
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,92(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfs f25,72(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// lfs f25,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// stfs f25,108(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f25,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f25.f64 = double(temp.f32);
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfs f25,56(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// fsubs f14,f19,f30
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// fadds f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f19.f64));
	// fadds f19,f23,f26
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f19,536(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// fsubs f19,f18,f20
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// lfs f18,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// stfs f18,516(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// lfs f18,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,452(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// lfsx f23,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,124
	ctx.r14.s64 = ctx.r6.s64 * 124;
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,60
	ctx.r14.s64 = ctx.r6.s64 * 60;
	// stfs f18,60(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f30,f18
	ctx.f18.f64 = double(float(ctx.f30.f64 - ctx.f18.f64));
	// stfs f18,264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fadds f30,f30,f18
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f18.f64));
	// stfs f30,44(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fsubs f30,f14,f19
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f19,f20
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f18,72(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f20,204(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmuls f19,f23,f13
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfsx f20,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f20,f23,f0
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,208(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f18,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f23,f18
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// fmuls f14,f23,f14
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f14.f64));
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f0,f23,f0,f19
	ctx.f0.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 - ctx.f19.f64));
	// stfs f0,140(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f0,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f13,f23,f13,f20
	ctx.f13.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f13,188(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f23,f30,f0
	ctx.f23.f64 = double(float(ctx.f30.f64 - ctx.f0.f64));
	// fadds f20,f0,f30
	ctx.f20.f64 = double(float(ctx.f0.f64 + ctx.f30.f64));
	// lfs f13,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// mulli r14,r6,188
	ctx.r14.s64 = ctx.r6.s64 * 188;
	// fsubs f19,f0,f13
	ctx.f19.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f30,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f30.f64 = double(temp.f32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f13,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
	// lfs f13,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// stw r14,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, ctx.r14.u32);
	// rotlwi r14,r14,0
	ctx.r14.u64 = __builtin_rotateleft32(ctx.r14.u32, 0);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmadds f13,f0,f13,f18
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f13,112(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f13,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f18,f13,f30
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f0,f0,f13,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f30,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f30.f64 = double(temp.f32);
	// lfs f13,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f30.f64));
	// stfs f13,388(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// lfs f13,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f25,f13
	ctx.f13.f64 = double(float(ctx.f25.f64 - ctx.f13.f64));
	// stfs f13,372(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f13,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 - ctx.f30.f64));
	// stfs f30,404(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f13.f64));
	// fmuls f13,f19,f12
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f13,532(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// lfs f19,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f13,f19,f12
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f13,356(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f13,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f19,f15,f13
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f13.f64));
	// stfs f19,252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f13,f13,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f15.f64));
	// stfs f13,464(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// lfs f13,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f18,f19,f13,f18
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f18,100(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,120(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f13,f18,f13
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f18,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f13,f19,f18,f13
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f13.f64));
	// stfs f13,208(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f13,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// mulli r14,r6,28
	ctx.r14.s64 = ctx.r6.s64 * 28;
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r14,r6,156
	ctx.r14.s64 = ctx.r6.s64 * 156;
	// stfs f19,108(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f15,284(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,196(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,220
	ctx.r14.s64 = ctx.r6.s64 * 220;
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,320(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,92
	ctx.r14.s64 = ctx.r6.s64 * 92;
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,72(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// fmuls f14,f13,f19
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// lfs f19,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// lfs f19,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f13,f13,f19,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64 + ctx.f18.f64));
	// stfs f13,36(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f13,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f13.f64 = double(temp.f32);
	// lfs f18,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f13,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// lfs f13,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f13,f13,f19,f14
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64 - ctx.f14.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// lfs f19,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f13,f19
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// lfs f14,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f14.f64 = double(temp.f32);
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f15,f13,f14,f15
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,124(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f14,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f13,f13,f14,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f14.f64 - ctx.f18.f64));
	// stfs f13,244(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f13,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f13.f64 = double(temp.f32);
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f13,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// lfs f13,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f19,f13,f14,f19
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,216(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f14.f64));
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f13,f13,f14,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f14.f64 - ctx.f15.f64));
	// stfs f13,328(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f13,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f13.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f13,f15
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// lfs f13,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f18,f13,f14,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,324(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f18,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f13,f13,f18,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f18.f64 - ctx.f19.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f18,f19,f15
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 + ctx.f15.f64));
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f18,f15,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,320(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,196(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f14,224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fadds f14,f18,f13
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f13.f64));
	// fsubs f13,f13,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f18.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// lfs f13,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f18.f64));
	// stfs f13,244(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f13,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f13.f64 = double(temp.f32);
	// lfs f18,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f18.f64 = double(temp.f32);
	// fadds f13,f13,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f18.f64));
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f18,284(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f19
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f18,116(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f0,f18
	ctx.f18.f64 = double(float(ctx.f0.f64 + ctx.f18.f64));
	// stfs f18,124(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,80(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,104(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f18,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,124(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,224(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f0,f18,f0
	ctx.f0.f64 = double(float(ctx.f18.f64 - ctx.f0.f64));
	// stfs f0,92(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f0,f18
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f18.f64));
	// stfs f0,60(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f0,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f0.f64 = double(temp.f32);
	// fadds f18,f13,f0
	ctx.f18.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f18,424(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f0,320(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f0,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f18,f0,f13
	ctx.f18.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f0,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f15,f19,f0
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f0.f64));
	// fadds f19,f0,f19
	ctx.f19.f64 = double(float(ctx.f0.f64 + ctx.f19.f64));
	// lfs f0,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f0.f64));
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f0,f0,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f14.f64));
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r14,r6,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f0.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fadds f0,f0,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f14.f64));
	// stfs f0,64(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f0,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f0.f64));
	// stfs f14,544(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// fadds f0,f0,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f14.f64));
	// stfs f0,444(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fmuls f0,f18,f12
	ctx.f0.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f0,492(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// fmuls f0,f13,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f0,340(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f0,f15,f12
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfs f0,540(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// fmuls f0,f19,f12
	ctx.f0.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f0,348(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f13,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f19,f0,f13
	ctx.f19.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f19,188(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,168(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f13,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// fadds f19,f13,f0
	ctx.f19.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f19,508(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfsx f13,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,124(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f0,336(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// mulli r14,r6,132
	ctx.r14.s64 = ctx.r6.s64 * 132;
	// fmuls f15,f1,f0
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfsx f13,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,68
	ctx.r14.s64 = ctx.r6.s64 * 68;
	// stfs f19,244(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,80(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,196
	ctx.r14.s64 = ctx.r6.s64 * 196;
	// stfs f19,116(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f18,f2,f0
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f0,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f14,f0,f13
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// stfs f13,284(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f19,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f19.f64 = double(temp.f32);
	// stfs f0,124(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmr f0,f19
	ctx.f0.f64 = ctx.f19.f64;
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f13,f1,f0,f18
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f18.f64));
	// fmsubs f2,f2,f0,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f15.f64));
	// lfs f0,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f0,f1
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f0,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f0,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f14.f64));
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f19,f0,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 - ctx.f15.f64));
	// lfs f0,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// lfs f15,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f0,f28,f0,f15
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 + ctx.f15.f64));
	// stfs f0,328(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f28,f0,f18
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 - ctx.f18.f64));
	// stfs f0,196(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fadds f28,f19,f2
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// stfs f28,216(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f18,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,36
	ctx.r14.s64 = ctx.r6.s64 * 36;
	// lfs f28,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f28.f64 = double(temp.f32);
	// fadds f0,f1,f13
	ctx.f0.f64 = double(float(ctx.f1.f64 + ctx.f13.f64));
	// fmuls f15,f28,f18
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f28,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f18
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f28,f28,f18,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f15,f18,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f15,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f15.f64 = double(temp.f32);
	// stfs f28,284(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// stfs f18,108(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,228(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,164
	ctx.r14.s64 = ctx.r6.s64 * 164;
	// stfs f18,212(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,368(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fadds f14,f28,f0
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// mulli r14,r6,228
	ctx.r14.s64 = ctx.r6.s64 * 228;
	// stfs f0,224(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f0,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f0.f64 = double(temp.f32);
	// fadds f0,f15,f0
	ctx.f0.f64 = double(float(ctx.f15.f64 + ctx.f0.f64));
	// stfs f0,324(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,220(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfsx f0,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f0.f64 = double(temp.f32);
	// mulli r14,r6,100
	ctx.r14.s64 = ctx.r6.s64 * 100;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,124(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfsx f0,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,244(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f0,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// lfs f28,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f0,f15,f0
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f18
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f18.f64));
	// fmuls f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f18.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f28,f14,f3,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f3.f64 + ctx.f28.f64));
	// stfs f28,228(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f28,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f0,f28,f3,f0
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f3.f64 - ctx.f0.f64));
	// stfs f0,212(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f0,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f0.f64 = double(temp.f32);
	// lfs f3,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f28,f0,f3
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f0,f3
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f3,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f3.f64 = double(temp.f32);
	// lfs f0,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f3,f3,f0,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f15.f64));
	// stfs f3,200(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f3,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f0,f3,f0,f18
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f18.f64));
	// stfs f0,176(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// lfs f3,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f0
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f3,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f0,f3,f0
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f3,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// lfs f18,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f18.f64 = double(temp.f32);
	// stfs f0,132(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmadds f0,f3,f18,f28
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f18.f64 + ctx.f28.f64));
	// lfs f28,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// fmsubs f3,f3,f28,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64 - ctx.f14.f64));
	// lfs f18,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,148
	ctx.r14.s64 = ctx.r6.s64 * 148;
	// fmadds f28,f28,f18,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f15,f18,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,220(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r14.u32);
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f13,368(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fadds f14,f28,f0
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// lfs f1,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fadds f28,f18,f3
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// fsubs f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f18.f64));
	// fsubs f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// stfs f13,124(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f18,132(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f18,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// stfs f28,240(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f28,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f28,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f18,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f28,208(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// stfs f28,32(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f28,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f28.f64 = double(temp.f32);
	// lfs f18,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f18,224(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f18,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// fsubs f18,f0,f3
	ctx.f18.f64 = double(float(ctx.f0.f64 - ctx.f3.f64));
	// stfs f18,132(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// fadds f0,f3,f0
	ctx.f0.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// stfs f18,240(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fsubs f3,f2,f19
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// lfs f19,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f18.f64 = double(temp.f32);
	// lfs f2,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// fsubs f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f13,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// lfs f1,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f14,f13,f1
	ctx.f14.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f13,f1,f13
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f13.f64));
	// mulli r14,r6,20
	ctx.r14.s64 = ctx.r6.s64 * 20;
	// fsubs f1,f18,f0
	ctx.f1.f64 = double(float(ctx.f18.f64 - ctx.f0.f64));
	// fadds f0,f0,f18
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f18.f64));
	// fadds f18,f2,f3
	ctx.f18.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f14,f3,f2
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f13,f1,f12
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// stfs f13,496(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// stfs f0,440(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fadds f0,f15,f19
	ctx.f0.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f0,216(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f13,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f2,f0,f13
	ctx.f2.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f2,504(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,36(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// lfsx f13,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,140(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lfsx f2,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// mulli r14,r6,52
	ctx.r14.s64 = ctx.r6.s64 * 52;
	// stfs f1,240(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f3,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// stfs f3,512(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// fsubs f3,f19,f15
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,76(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,180
	ctx.r14.s64 = ctx.r6.s64 * 180;
	// stfs f19,144(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f2,132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f15,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f0,f15
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f15.f64));
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,176(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfsx f19,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,200(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f19,f0,f22
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f22.f64));
	// lfs f0,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmuls f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// stfs f0,272(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f2,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f0,f13,f2,f19
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f19.f64));
	// fmsubs f13,f13,f22,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f22.f64 - ctx.f15.f64));
	// lfs f22,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f22.f64 = double(temp.f32);
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// lfs f2,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f2.f64 = double(temp.f32);
	// lfs f19,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f1,f2,f19,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f19.f64 + ctx.f1.f64));
	// stfs f1,280(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f19,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f19.f64 = double(temp.f32);
	// lfs f1,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f19,f1
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f19,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f2,f2,f19,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f22,f15,f29,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f29.f64 + ctx.f22.f64));
	// stfs f22,272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f1,f22,f29,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 - ctx.f1.f64));
	// lfs f22,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f22.f64 = double(temp.f32);
	// lfs f29,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f29,f22,f29,f19
	ctx.f29.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 + ctx.f19.f64));
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,244
	ctx.r14.s64 = ctx.r6.s64 * 244;
	// fmsubs f22,f22,f19,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f15,f0
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f0.f64));
	// fsubs f0,f0,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f15.f64));
	// fadds f15,f2,f13
	ctx.f15.f64 = double(float(ctx.f2.f64 + ctx.f13.f64));
	// stfs f15,200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stw r14,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r14.u32);
	// mulli r14,r6,116
	ctx.r14.s64 = ctx.r6.s64 * 116;
	// fsubs f13,f13,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// stfs f13,228(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f13,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f13.f64 = double(temp.f32);
	// fadds f2,f29,f13
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f13.f64));
	// stfs f2,80(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f29.f64));
	// stfs f13,220(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fsubs f2,f1,f22
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f22.f64));
	// stfs f2,212(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fadds f13,f22,f1
	ctx.f13.f64 = double(float(ctx.f22.f64 + ctx.f1.f64));
	// stfs f13,104(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f22,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f22.f64 = double(temp.f32);
	// stw r14,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r14.u32);
	// lwz r14,196(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lfsx f13,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f2,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lwz r14,120(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lfsx f1,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f29,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r14,r6,84
	ctx.r14.s64 = ctx.r6.s64 * 84;
	// stfs f29,288(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfsx f29,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,180(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfsx f29,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r14,r6,212
	ctx.r14.s64 = ctx.r6.s64 * 212;
	// stfs f29,76(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f29,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,144(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfsx f29,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,176(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f29,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f13
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// lfs f13,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f15,f1,f13
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f13,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f13,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f2,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f29.f64));
	// lfs f29,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f2,f29,f2,f22
	ctx.f2.f64 = double(float(ctx.f29.f64 * ctx.f2.f64 - ctx.f22.f64));
	// stfs f2,84(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f29,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f29.f64 = double(temp.f32);
	// lfs f22,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f22.f64 = double(temp.f32);
	// lfs f2,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f29,f2,f29
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f29.f64));
	// lfs f2,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f22,f2,f22,f15
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f15,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f22.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f2,f2,f15,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64 - ctx.f1.f64));
	// stfs f2,280(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f2,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f2,f1
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,360(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f1,f27,f29
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 + ctx.f29.f64));
	// lfs f1,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f1.f64 = double(temp.f32);
	// lfs f29,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f1,f1,f27,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 - ctx.f22.f64));
	// lfs f27,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f27.f64 = double(temp.f32);
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f29,f27,f29,f15
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f15.f64));
	// lfs f15,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f27,f27,f22,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64 - ctx.f15.f64));
	// lfs f15,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f13,f15
	ctx.f22.f64 = double(float(ctx.f13.f64 - ctx.f15.f64));
	// mulli r14,r6,12
	ctx.r14.s64 = ctx.r6.s64 * 12;
	// fadds f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 + ctx.f13.f64));
	// stfs f13,76(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// lfs f13,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f13.f64));
	// stfs f15,180(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fadds f13,f13,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f15.f64));
	// fadds f15,f29,f2
	ctx.f15.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fsubs f2,f2,f29
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fadds f29,f27,f1
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fsubs f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// stfs f1,184(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f27,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f27.f64 = double(temp.f32);
	// lfs f1,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// stfs f1,68(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f27,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f27.f64 = double(temp.f32);
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// fadds f27,f15,f19
	ctx.f27.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f29
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f29.f64));
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fadds f29,f29,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f15.f64));
	// stfs f29,84(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f29,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// stfs f29,256(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f15,f1,f10
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmsubs f29,f29,f11,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f11.f64 - ctx.f15.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f27.f64));
	// stfs f15,368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,68(r1)
	PPC_STORE_U32(ctx.r1.u32 + 68, ctx.r14.u32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// mulli r14,r6,140
	ctx.r14.s64 = ctx.r6.s64 * 140;
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,324(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r14.u32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,328(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f13,f19
	ctx.f19.f64 = double(float(ctx.f13.f64 + ctx.f19.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f15,176(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f0,f15
	ctx.f15.f64 = double(float(ctx.f0.f64 - ctx.f15.f64));
	// stfs f19,240(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// stfs f15,360(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f19,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f2,f19
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// fsubs f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fadds f0,f15,f0
	ctx.f0.f64 = double(float(ctx.f15.f64 + ctx.f0.f64));
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,184(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f22,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f22.f64 = double(temp.f32);
	// stfs f2,132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fsubs f13,f13,f22
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f22.f64));
	// stfs f0,272(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// stfs f13,280(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fmuls f22,f0,f11
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f15,f0,f11
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f1,f11
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// stfs f0,256(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stw r14,396(r1)
	PPC_STORE_U32(ctx.r1.u32 + 396, ctx.r14.u32);
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,60(r1)
	PPC_STORE_U32(ctx.r1.u32 + 60, ctx.r14.u32);
	// fmadds f13,f1,f10,f13
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f13.f64));
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// stfs f13,528(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// lfs f13,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f13.f64 = double(temp.f32);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fmuls f1,f13,f11
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmuls f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stw r14,40(r1)
	PPC_STORE_U32(ctx.r1.u32 + 40, ctx.r14.u32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmadds f1,f19,f10,f1
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f1.f64));
	// stfs f1,432(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fmsubs f13,f19,f11,f13
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f13.f64));
	// stfs f13,520(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// lfs f13,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f13.f64 = double(temp.f32);
	// stw r14,344(r1)
	PPC_STORE_U32(ctx.r1.u32 + 344, ctx.r14.u32);
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,448(r1)
	PPC_STORE_U32(ctx.r1.u32 + 448, ctx.r14.u32);
	// lfs f13,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f1,f0,f13
	ctx.f1.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f1,200(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f0,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f0,f10,f22
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 - ctx.f22.f64));
	// stfs f0,104(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f1,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f1.f64 = double(temp.f32);
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f2,f1,f10,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f2.f64));
	// fmsubs f0,f0,f10,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 - ctx.f15.f64));
	// stfs f0,212(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f2,220(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f2,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f0,f10,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 + ctx.f2.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,60(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	// lfs f2,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f2,f13
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lwz r14,40(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// lfs f0,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,256(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lwz r14,344(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// lfs f1,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lwz r14,448(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	// lfs f22,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,396(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,68(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f0,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,128(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f19,f2,f0
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f2,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,304(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmr f2,f1
	ctx.f2.f64 = ctx.f1.f64;
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f13,f2,f13,f19
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f19.f64));
	// fmsubs f0,f2,f0,f15
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f15.f64));
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// lwz r14,344(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// fmuls f19,f2,f1
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lwz r14,448(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	// fmadds f1,f1,f2,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f22.f64));
	// stfs f1,164(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f1
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// lfs f22,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f22.f64 = double(temp.f32);
	// lfs f1,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// mulli r14,r6,172
	ctx.r14.s64 = ctx.r6.s64 * 172;
	// fmsubs f2,f1,f2,f22
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f22.f64));
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// lfs f1,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f22,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f19.f64));
	// lfs f19,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,460(r1)
	PPC_STORE_U32(ctx.r1.u32 + 460, ctx.r14.u32);
	// mulli r14,r6,76
	ctx.r14.s64 = ctx.r6.s64 * 76;
	// fmsubs f22,f19,f22,f15
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stw r14,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r14.u32);
	// mulli r14,r6,204
	ctx.r14.s64 = ctx.r6.s64 * 204;
	// stw r14,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r14.u32);
	// mulli r14,r6,236
	ctx.r14.s64 = ctx.r6.s64 * 236;
	// stw r14,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, ctx.r14.u32);
	// mulli r14,r6,108
	ctx.r14.s64 = ctx.r6.s64 * 108;
	// stw r14,68(r1)
	PPC_STORE_U32(ctx.r1.u32 + 68, ctx.r14.u32);
	// lfs f19,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f19,f13
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f13.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f19.f64));
	// stfs f13,180(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fadds f13,f2,f0
	ctx.f13.f64 = double(float(ctx.f2.f64 + ctx.f0.f64));
	// stfs f13,76(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f2.f64));
	// stfs f0,184(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lwz r14,96(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r14.u32);
	// lwz r14,96(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,436(r1)
	PPC_STORE_U32(ctx.r1.u32 + 436, ctx.r14.u32);
	// lwz r14,192(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r14.u32);
	// lwz r14,192(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r14.u32);
	// lwz r14,248(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r14.u32);
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r14.u32);
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r14.u32);
	// lwz r14,460(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	// lfsx f2,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f0,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// stfs f2,164(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f13,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,436(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f19,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lwz r14,248(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// lfsx f13,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,192(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lwz r14,264(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// lfs f13,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,68(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lwz r14,92(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lfs f13,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f13,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f15,f0,f13
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f13,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,24(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// fmadds f0,f0,f13,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f2.f64));
	// stfs f0,148(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f0,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// lfs f0,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f0,f13,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f0,172(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f0,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f15,f0,f13
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f19.f64));
	// stfs f13,164(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f13,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,436(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f13,f19
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// lfs f13,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fmsubs f0,f13,f0,f2
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 - ctx.f2.f64));
	// stfs f0,304(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f13,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fmuls f2,f0,f13
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fmadds f13,f0,f13,f15
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f13,52(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f13,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f13.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f13,f15
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// lfs f13,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f0,f0,f13,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - ctx.f19.f64));
	// stfs f0,28(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f19,f0,f9
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f13,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f0,f13,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f2.f64));
	// lfs f2,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f9,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f13,f9,f13,f15
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f9,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f9,f8,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f19.f64));
	// lfs f19,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f8,f19,f8,f2
	ctx.f8.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 - ctx.f2.f64));
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// fadds f2,f19,f1
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f1.f64));
	// fsubs f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f19.f64));
	// lfs f15,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f15,f22
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f22,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,308(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f22,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,160(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// fadds f15,f9,f0
	ctx.f15.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// fsubs f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// fadds f9,f8,f13
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// stfs f13,28(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f8,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f8.f64 = double(temp.f32);
	// lfs f13,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fadds f8,f15,f2
	ctx.f8.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// stfs f8,156(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// stfs f8,148(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f8,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// stfs f13,68(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f8,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fadds f13,f9,f19
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f19.f64));
	// stfs f13,192(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f13,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f9,f9,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f19.f64));
	// lfs f8,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f8.f64 = double(temp.f32);
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// lfs f8,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f22.f64));
	// stfs f8,156(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f8,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// fadds f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f1.f64));
	// stfs f8,172(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f0,f8
	ctx.f8.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// stfs f8,164(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f8,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// lfs f1,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// fadds f0,f0,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// stfs f0,48(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f0,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// lfs f0,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f0.f64 = double(temp.f32);
	// fadds f0,f22,f0
	ctx.f0.f64 = double(float(ctx.f22.f64 + ctx.f0.f64));
	// stfs f0,52(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// stfs f9,28(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f0,f15,f2
	ctx.f0.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// lfs f2,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfs f9,304(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f2,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfs f9,256(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f2,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// stfs f9,280(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f2,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// lfs f22,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// stfs f9,288(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f9,f22,f28
	ctx.f9.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f9,108(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f2,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// stfs f9,132(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f2,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// stfs f9,272(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f9,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// stfs f9,124(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f2,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f2.f64 = double(temp.f32);
	// lfs f9,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f9.f64 = double(temp.f32);
	// fadds f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// lfs f31,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f31.f64 = double(temp.f32);
	// lfs f2,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f2.f64 = double(temp.f32);
	// stfs f9,240(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fadds f9,f31,f2
	ctx.f9.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f9,368(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f9,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f9.f64 = double(temp.f32);
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// stfs f1,360(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fadds f15,f9,f19
	ctx.f15.f64 = double(float(ctx.f9.f64 + ctx.f19.f64));
	// fsubs f9,f9,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f19.f64));
	// stfs f9,160(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// lfs f9,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f9.f64 = double(temp.f32);
	// stfs f2,284(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fadds f9,f9,f21
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f21.f64));
	// fsubs f2,f28,f22
	ctx.f2.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f9,84(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f2,244(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fmuls f21,f8,f11
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f9,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f1,f11
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f2,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f2.f64 = double(temp.f32);
	// fadds f9,f2,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// stfs f9,116(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f15,148(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f9,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f9.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f2,f9,f10
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fadds f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f0.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f31,f9,f11
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f0,f0,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f15.f64));
	// stfs f0,180(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f28,f9,f11
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fsubs f0,f0,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f15.f64));
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f0,f13,f11,f2
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 - ctx.f2.f64));
	// stfs f0,424(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// lfs f2,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f0,f13,f10,f31
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 + ctx.f31.f64));
	// stfs f0,524(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f0,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f13,f0,f10,f28
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 + ctx.f28.f64));
	// stfs f13,456(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// fmsubs f0,f0,f11,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64 - ctx.f9.f64));
	// stfs f0,500(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// lfs f13,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f8,f10,f22
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 + ctx.f22.f64));
	// stfs f0,316(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f0,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f0,f10,f21
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 - ctx.f21.f64));
	// stfs f0,44(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f0,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f9,f0,f13
	ctx.f9.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfs f9,76(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,184(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f0,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f0,f10,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 - ctx.f19.f64));
	// stfs f0,292(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f0,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f0,f0,f10,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 + ctx.f1.f64));
	// lfs f13,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,56(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fadds f0,f9,f13
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// fsubs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// stfs f13,256(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f9,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// fadds f8,f9,f13
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfs f8,304(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f8,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// lfs f1,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f1.f64 = double(temp.f32);
	// fadds f9,f2,f8
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fsubs f8,f2,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// lfs f31,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f31.f64 = double(temp.f32);
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfs f1,360(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f28,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f28.f64 = double(temp.f32);
	// lfs f31,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f31.f64 = double(temp.f32);
	// fadds f1,f28,f31
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f31,f28,f31
	ctx.f31.f64 = double(float(ctx.f28.f64 - ctx.f31.f64));
	// fadds f28,f22,f21
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fsubs f21,f19,f28
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// fadds f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// lfs f19,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// stfs f28,308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fsubs f28,f19,f22
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fadds f25,f19,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// stfs f25,64(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f25,f9,f0
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// fsubs f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// lfs f9,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f9.f64 = double(temp.f32);
	// fadds f19,f28,f1
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f28,f28,f1
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// lfs f1,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f1.f64 = double(temp.f32);
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// stfs f9,172(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f1,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f1.f64 = double(temp.f32);
	// fadds f15,f22,f31
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f31.f64));
	// lfs f9,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f22,f31,f22
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f22.f64));
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// lfs f31,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfs f1,156(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f31,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfs f1,148(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f28,f28,f12
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fsubs f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// stfs f1,128(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f31,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfs f22,280(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fadds f31,f8,f13
	ctx.f31.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// lfs f22,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// lfs f8,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f22.f64));
	// stfs f8,28(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f22.f64 = double(temp.f32);
	// lfs f8,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f8.f64 = double(temp.f32);
	// stfs f1,192(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fsubs f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f22.f64));
	// fmuls f1,f19,f12
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f19,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f22,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// stfs f1,288(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fmuls f1,f15,f12
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f19,f22
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,160(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f22,f25,f2
	ctx.f22.f64 = double(float(ctx.f25.f64 - ctx.f2.f64));
	// stfsx f22,r10,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// stfs f2,0(r3)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f25,f0,f21
	ctx.f25.f64 = double(float(ctx.f0.f64 - ctx.f21.f64));
	// fadds f22,f0,f21
	ctx.f22.f64 = double(float(ctx.f0.f64 + ctx.f21.f64));
	// fmuls f2,f9,f11
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f0,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f21,f9,f10
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f9,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f19,f0,f9
	ctx.f19.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// fadds f15,f9,f0
	ctx.f15.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// stfs f0,64(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f9,f31,f1
	ctx.f9.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfs f9,272(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// fadds f31,f13,f28
	ctx.f31.f64 = double(float(ctx.f13.f64 + ctx.f28.f64));
	// fsubs f28,f13,f28
	ctx.f28.f64 = double(float(ctx.f13.f64 - ctx.f28.f64));
	// lfs f13,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// stfs f13,132(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f13,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f8,f13
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// lfs f13,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f13.f64 = double(temp.f32);
	// fmr f9,f13
	ctx.f9.f64 = ctx.f13.f64;
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f13,f9,f10,f2
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 - ctx.f2.f64));
	// fmadds f9,f9,f11,f21
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f11.f64 + ctx.f21.f64));
	// stfs f9,84(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f9,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f15,f12
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fadds f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// stfs f8,28(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// lfs f21,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f8,f19,f12
	ctx.f8.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// stfs f1,164(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f21,f11,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f19.f64));
	// stfs f21,240(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f21,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f21.f64 = double(temp.f32);
	// fmr f1,f21
	ctx.f1.f64 = ctx.f21.f64;
	// lfs f21,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// stfs f21,64(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f21,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfs f1,156(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// lfs f21,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// stfs f21,148(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f21,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfs f1,172(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f21,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f21.f64 = double(temp.f32);
	// lfs f1,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f1.f64 = double(temp.f32);
	// fadds f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f21.f64));
	// stfs f21,0(r4)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f21,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfsx f1,r10,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f25,r8,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f25.f64 = double(temp.f32);
	// stfs f31,64(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmr f31,f25
	ctx.f31.f64 = ctx.f25.f64;
	// lfs f1,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f1.f64 = double(temp.f32);
	// stfsx f22,r9,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f25,f31,f1
	ctx.f25.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f31,f1
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// lfs f1,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f1.f64 = double(temp.f32);
	// lfs f31,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f31.f64 = double(temp.f32);
	// stfsx f22,r8,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f31,f1
	ctx.f25.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// fadds f22,f1,f31
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f31.f64));
	// lfs f1,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f1.f64 = double(temp.f32);
	// lfs f31,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f31.f64 = double(temp.f32);
	// stfsx f25,r5,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fsubs f25,f31,f1
	ctx.f25.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfsx f22,r7,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f31.f64));
	// lfs f22,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f22,r7,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f22,r5,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// stfsx f25,r31,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfsx f1,r30,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f25.f64 = double(temp.f32);
	// lfs f31,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f1.f64 = double(temp.f32);
	// stfsx f25,r30,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// stfsx f28,r31,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f28.f64 = double(temp.f32);
	// lfs f31,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f31,f28
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// lfs f25,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f25.f64 = double(temp.f32);
	// lfs f28,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// lfs f22,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// lfs f22,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f22.f64 = double(temp.f32);
	// fadds f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f22.f64));
	// lfs f21,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f21,f10
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fadds f21,f8,f19
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f19.f64));
	// fsubs f8,f19,f8
	ctx.f8.f64 = double(float(ctx.f19.f64 - ctx.f8.f64));
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f2,f19
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// stfs f19,148(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// stfs f2,172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f19,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// lfs f2,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 - ctx.f2.f64));
	// lfs f19,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f11,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f15.f64));
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f15,f1,f10
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fsubs f19,f25,f28
	ctx.f19.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fmuls f25,f22,f10
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,48(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmuls f2,f31,f10
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// fmadds f31,f31,f11,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f11.f64 + ctx.f15.f64));
	// fmuls f28,f28,f12
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmadds f25,f27,f11,f25
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f25.f64));
	// fmsubs f27,f27,f10,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f22.f64));
	// fmsubs f2,f1,f11,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 - ctx.f2.f64));
	// fmuls f1,f19,f12
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f2,f19
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// fsubs f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// fadds f19,f1,f9
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f9.f64));
	// fsubs f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f1.f64));
	// fadds f1,f28,f0
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// fsubs f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f31,f15
	ctx.f15.f64 = double(float(ctx.f31.f64 + ctx.f15.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f31,f15,f31
	ctx.f31.f64 = double(float(ctx.f15.f64 - ctx.f31.f64));
	// fadds f15,f25,f13
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f13.f64));
	// stfs f15,156(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f25.f64));
	// fadds f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f15.f64));
	// fsubs f27,f21,f22
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfsx f27,r22,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f27,f22,f21
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfsx f27,r23,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// lfs f27,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f27.f64 = double(temp.f32);
	// fadds f25,f19,f27
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f27.f64));
	// stfsx f25,r23,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// stfsx f27,r22,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// fsubs f27,f8,f31
	ctx.f27.f64 = double(float(ctx.f8.f64 - ctx.f31.f64));
	// stfsx f27,r25,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f31,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f8.f64));
	// stfsx f8,r24,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f9,f2
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// stfsx f8,r24,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// stfsx f9,r25,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f9,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f1,f9
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f9.f64));
	// stfsx f8,r28,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// stfsx f9,r29,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f9,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f9.f64 = double(temp.f32);
	// fadds f8,f9,f15
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f15.f64));
	// stfsx f8,r29,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f9,f15
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f15.f64));
	// stfsx f9,r28,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f0,f28
	ctx.f9.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// stfsx f9,r26,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f28,f0
	ctx.f0.f64 = double(float(ctx.f28.f64 + ctx.f0.f64));
	// stfsx f0,r27,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f0,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f0.f64 = double(temp.f32);
	// fadds f9,f0,f13
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// stfsx f9,r27,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f0,r26,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f13,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f9,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// lfs f8,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// lfs f27,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f27.f64 = double(temp.f32);
	// lfs f2,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f31,f27,f11
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f8,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f27,f10
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f25,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f8,f8,f2
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// fmuls f2,f25,f10
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f19,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// lfs f19,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f19.f64 = double(temp.f32);
	// lfs f28,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f1,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f21,f17,f1
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f1.f64));
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f1,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f31,f19,f10,f31
	ctx.f31.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f31.f64));
	// fmuls f19,f28,f10
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmsubs f2,f28,f11,f2
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 - ctx.f2.f64));
	// lfs f28,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// fmuls f27,f22,f12
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f11,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f13.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f1,f21,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 - ctx.f1.f64));
	// fsubs f15,f3,f9
	ctx.f15.f64 = double(float(ctx.f3.f64 - ctx.f9.f64));
	// fmadds f25,f25,f11,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 + ctx.f19.f64));
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f15,f15,f8
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f8.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f0.f64));
	// fadds f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// lfs f3,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f3.f64 = double(temp.f32);
	// fadds f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f2,f31
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// lwz r9,420(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// mulli r10,r6,56
	ctx.r10.s64 = ctx.r6.s64 * 56;
	// fadds f31,f28,f27
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfs f28,160(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f28,f22,f25
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f28,96(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fsubs f28,f22,f25
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfs f28,308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f28,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f19,f6
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// fmuls f28,f28,f6
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f6.f64));
	// lfs f27,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fadds f0,f0,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f15.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 + ctx.f13.f64));
	// fmsubs f28,f19,f7,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 - ctx.f28.f64));
	// stfs f28,252(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f28,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f27,f28,f7,f27
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f7.f64 + ctx.f27.f64));
	// stfs f27,52(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmuls f19,f28,f6
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f6.f64));
	// fmuls f28,f9,f4
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// stfs f28,152(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f25,f0,f4
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fmuls f15,f13,f4
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmuls f27,f8,f4
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmadds f13,f13,f5,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f25.f64));
	// lfs f25,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f28,f25,f7,f22
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f22.f64));
	// fmsubs f9,f9,f5,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64 - ctx.f27.f64));
	// lfs f27,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f27,f27,f7,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 - ctx.f19.f64));
	// fmsubs f0,f0,f5,f15
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f5.f64 - ctx.f15.f64));
	// lfs f22,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f8,f8,f5,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 + ctx.f25.f64));
	// stfs f8,28(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f8,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f8.f64 = double(temp.f32);
	// fadds f25,f3,f1
	ctx.f25.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// fadds f8,f8,f22
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f22.f64));
	// fsubs f19,f25,f8
	ctx.f19.f64 = double(float(ctx.f25.f64 - ctx.f8.f64));
	// stfsx f19,r9,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f8,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f25.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f8,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f8.f64 = double(temp.f32);
	// lfs f25,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f8,f25
	ctx.f25.f64 = double(float(ctx.f8.f64 + ctx.f25.f64));
	// lfs f19,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f19.f64 = double(temp.f32);
	// fadds f8,f27,f28
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// stfs f8,252(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f8,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fadds f8,f19,f8
	ctx.f8.f64 = double(float(ctx.f19.f64 + ctx.f8.f64));
	// stfs f8,152(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f8,f1,f3
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// stfs f8,312(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fsubs f8,f27,f28
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// stfs f8,64(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f8,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f27,f30,f11
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// lfs f3,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f3.f64 = double(temp.f32);
	// fadds f1,f8,f3
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// lfs f8,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f28,f8,f11
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmuls f3,f25,f12
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// stfs f3,156(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f19,f8,f10
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f3,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f3.f64 = double(temp.f32);
	// lfs f8,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f8.f64 = double(temp.f32);
	// lfs f25,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f8,f11
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fadds f25,f3,f25
	ctx.f25.f64 = double(float(ctx.f3.f64 + ctx.f25.f64));
	// lfs f8,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// lfs f3,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f3.f64 = double(temp.f32);
	// fadds f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// stfs f8,236(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f3,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f30,f30,f10,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 - ctx.f15.f64));
	// fsubs f3,f22,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f3.f64));
	// stfs f3,148(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f3,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f8,f3,f22
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// lfs f3,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f21.f64));
	// stfs f3,172(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f3,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// stfs f3,164(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f3,f9,f13
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfs f3,256(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fadds f3,f31,f2
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f3,304(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// lfs f9,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// lfs f22,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f9,f31,f2
	ctx.f9.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// lfs f3,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f31,f24,f10,f28
	ctx.f31.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f28.f64));
	// lfs f28,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f10,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 + ctx.f27.f64));
	// lfs f2,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f27,f25,f12
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f25,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f24,f24,f11,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f19.f64));
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// fsubs f3,f21,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 - ctx.f3.f64));
	// lfs f21,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f21.f64 = double(temp.f32);
	// fadds f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f17.f64));
	// lfs f19,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f19,f12
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f19,f21
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// mulli r10,r6,248
	ctx.r10.s64 = ctx.r6.s64 * 248;
	// stfsx f21,r9,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,120
	ctx.r9.s64 = ctx.r6.s64 * 120;
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f21,f19
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// stfsx f21,r9,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f21,f19,f17
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// lfs f17,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f8,f17
	ctx.f15.f64 = double(float(ctx.f8.f64 + ctx.f17.f64));
	// stfsx f15,r9,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f8,f17
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f17.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,152
	ctx.r9.s64 = ctx.r6.s64 * 152;
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// lfs f8,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f15,f8,f17
	ctx.f15.f64 = double(float(ctx.f8.f64 - ctx.f17.f64));
	// fadds f8,f17,f8
	ctx.f8.f64 = double(float(ctx.f17.f64 + ctx.f8.f64));
	// lfs f17,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f15,r9,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// mulli r10,r6,24
	ctx.r10.s64 = ctx.r6.s64 * 24;
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f8,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f8.f64 = double(temp.f32);
	// fadds f15,f17,f8
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f8.f64));
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f17,f8
	ctx.f8.f64 = double(float(ctx.f17.f64 - ctx.f8.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,216
	ctx.r10.s64 = ctx.r6.s64 * 216;
	// fsubs f8,f3,f13
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f13.f64));
	// fadds f13,f13,f3
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f3.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// mulli r9,r6,88
	ctx.r9.s64 = ctx.r6.s64 * 88;
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f9,f0
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f9,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// stfsx f0,r10,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f31,f28
	ctx.f9.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// mulli r10,r6,104
	ctx.r10.s64 = ctx.r6.s64 * 104;
	// fadds f8,f28,f31
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f31.f64));
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f0,f2,f1
	ctx.f0.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f13,f1,f2
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fadds f1,f30,f24
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// fsubs f31,f30,f24
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// lfs f24,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f30,f28,f22
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fsubs f2,f25,f27
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f3,f25,f27
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfs f25,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f27.f64 = double(temp.f32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// fadds f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// lfs f25,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmuls f15,f19,f7
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// fmuls f24,f30,f5
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fmuls f22,f30,f4
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// fmuls f17,f28,f7
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// fmuls f30,f27,f12
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmuls f27,f25,f12
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fmsubs f25,f21,f4,f24
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 - ctx.f24.f64));
	// fmadds f24,f21,f5,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 + ctx.f22.f64));
	// fadds f22,f9,f0
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f0.f64));
	// fsubs f0,f0,f9
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f9.f64));
	// fadds f21,f31,f2
	ctx.f21.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fsubs f9,f2,f31
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fmadds f31,f28,f6,f15
	ctx.f31.f64 = double(float(ctx.f28.f64 * ctx.f6.f64 + ctx.f15.f64));
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f19,f19,f6,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f2,f1,f13
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f13.f64));
	// fsubs f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// fsubs f1,f17,f30
	ctx.f1.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// fadds f30,f30,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// fadds f27,f27,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f17.f64));
	// stfs f27,88(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f28,f3,f8
	ctx.f28.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// fmuls f27,f15,f5
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// fmuls f17,f1,f5
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f15,f30,f6
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fmuls f30,f30,f7
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// fmadds f1,f1,f4,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f27,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f27.f64 = double(temp.f32);
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmsubs f30,f27,f4,f17
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f17.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f27,f17,f7,f15
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f17,f6,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 - ctx.f15.f64));
	// fadds f15,f1,f25
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f25.f64));
	// fsubs f1,f25,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 - ctx.f1.f64));
	// fadds f25,f30,f24
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// fadds f24,f17,f31
	ctx.f24.f64 = double(float(ctx.f17.f64 + ctx.f31.f64));
	// fsubs f31,f17,f31
	ctx.f31.f64 = double(float(ctx.f17.f64 - ctx.f31.f64));
	// fsubs f17,f22,f15
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfsx f17,r16,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfsx f22,r17,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f21,f25
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfsx f22,r17,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// stfsx f25,r16,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f0,f30
	ctx.f25.f64 = double(float(ctx.f0.f64 - ctx.f30.f64));
	// stfsx f25,r15,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f30,f0
	ctx.f0.f64 = double(float(ctx.f30.f64 + ctx.f0.f64));
	// stfsx f0,r10,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f9,f1
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// stfsx f0,r10,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f9,f1
	ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f1.f64));
	// stfsx f0,r15,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fadds f0,f27,f19
	ctx.f0.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// lfs f30,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// lfs f25,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f8.f64));
	// lfs f22,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f21.f64 = double(temp.f32);
	// lfs f1,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f19.f64 = double(temp.f32);
	// lfs f3,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// lfs f19,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f9,f2,f0
	ctx.f9.f64 = double(float(ctx.f2.f64 - ctx.f0.f64));
	// stfsx f9,r20,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f2.f64));
	// stfsx f0,r21,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f28,f24
	ctx.f0.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// stfsx f0,r21,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f28,f24
	ctx.f0.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// lfs f28,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// lfs f28,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// lfs f24,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f0,r20,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fsubs f0,f13,f31
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// lfs f24,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f0,r18,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f31,f13
	ctx.f0.f64 = double(float(ctx.f31.f64 + ctx.f13.f64));
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// lfs f22,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f0,r19,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f13,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lfs f21,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// lfs f9,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// lfs f13,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f13.f64 = double(temp.f32);
	// lfs f1,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// lfs f31,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 - ctx.f1.f64));
	// lfs f17,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfs f19,88(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f17,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f9,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f9.f64 = double(temp.f32);
	// stfs f19,236(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fsubs f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f23.f64));
	// lfs f17,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f0,f6
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f19,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfs f19,168(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f17,f13,f6
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fsubs f19,f1,f31
	ctx.f19.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f31,f30,f28
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,296(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fsubs f30,f25,f24
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f30,152(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmuls f30,f9,f7
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f28,f24,f25
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f30,f22,f21
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f25,f21,f22
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fmuls f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmsubs f24,f0,f7,f17
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 - ctx.f17.f64));
	// fmadds f22,f13,f7,f15
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f7.f64 + ctx.f15.f64));
	// fadds f0,f8,f27
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f27.f64));
	// stfsx f0,r19,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f8,f27
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f27.f64));
	// stfsx f0,r18,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f13,f3,f0
	ctx.f13.f64 = double(float(ctx.f3.f64 - ctx.f0.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f0,f0,f3
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f3.f64));
	// stfs f0,48(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmsubs f0,f2,f7,f9
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 - ctx.f9.f64));
	// stfs f0,32(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// stfs f13,300(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmadds f27,f2,f6,f17
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f17.f64));
	// lfs f13,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f0.f64 = double(temp.f32);
	// fadds f9,f13,f0
	ctx.f9.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f8,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// stfs f0,28(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f0,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f3,f28,f8
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f13,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f0,f8
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// fmuls f0,f30,f13
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f3,168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fmuls f21,f31,f13
	ctx.f21.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// lfs f15,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f1,f8
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// stfs f9,52(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmr f0,f15
	ctx.f0.f64 = ctx.f15.f64;
	// fmuls f9,f19,f13
	ctx.f9.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f3,f31,f0,f9
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f9,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f2,f1,f9,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 - ctx.f2.f64));
	// fsubs f1,f24,f27
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// fadds f31,f27,f24
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fmsubs f27,f19,f0,f21
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 - ctx.f21.f64));
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f24,f21,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f9,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f17.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f19,f15,f0,f17
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 - ctx.f17.f64));
	// lfs f17,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f25,f9,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f17.f64));
	// fmuls f25,f25,f8
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// stfs f25,32(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmadds f30,f30,f0,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f15.f64));
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f1,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f15.f64));
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f15,f19,f3
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f3.f64));
	// stfs f15,168(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f3.f64));
	// fadds f15,f24,f15
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 - ctx.f1.f64));
	// stfs f1,312(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f15,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f15.f64 = double(temp.f32);
	// lfs f1,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 - ctx.f1.f64));
	// stfs f1,160(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f15,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f15.f64 = double(temp.f32);
	// lfs f1,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f1.f64 = double(temp.f32);
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 - ctx.f1.f64));
	// lfs f15,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f25,f26,f15
	ctx.f25.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// fadds f19,f22,f19
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f19,156(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f19,f17,f2
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f28,f28,f9,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 - ctx.f15.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// fadds f15,f31,f15
	ctx.f15.f64 = double(float(ctx.f31.f64 + ctx.f15.f64));
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f31,f17,f31
	ctx.f31.f64 = double(float(ctx.f17.f64 - ctx.f31.f64));
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lwz r9,352(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// lfs f17,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f17.f64 = double(temp.f32);
	// mulli r10,r6,60
	ctx.r10.s64 = ctx.r6.s64 * 60;
	// lfs f31,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f17,f31
	ctx.f31.f64 = double(float(ctx.f17.f64 - ctx.f31.f64));
	// stfs f31,296(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f31,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f31,f17
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f17.f64));
	// lfs f15,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,236(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f17,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,300(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fadds f17,f30,f27
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// stfs f17,252(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f30.f64));
	// stfs f30,64(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f27,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f17,f30,f27
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfsx f17,r9,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f1,f5
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmuls f17,f30,f5
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// fadds f30,f28,f21
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f21.f64));
	// stfs f30,88(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f30,f28,f21
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f21.f64));
	// stfs f30,168(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f30,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f30.f64 = double(temp.f32);
	// fadds f21,f24,f3
	ctx.f21.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// fsubs f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f3.f64));
	// fmuls f28,f25,f5
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// fmadds f1,f1,f4,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f17.f64));
	// fmuls f30,f30,f5
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// lfs f3,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f15,f3,f19
	ctx.f15.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// fsubs f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 - ctx.f19.f64));
	// fsubs f3,f22,f2
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f2.f64));
	// stfs f3,32(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fadds f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// lfs f2,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfs f2,172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f2,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f2,28(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f31,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f31.f64 = double(temp.f32);
	// fmr f3,f31
	ctx.f3.f64 = ctx.f31.f64;
	// fmadds f31,f25,f4,f30
	ctx.f31.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f30.f64));
	// lfs f30,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// lfs f2,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f2,52(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f2,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// lfs f2,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f30,f30,f4,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f4.f64 - ctx.f28.f64));
	// lfs f28,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f2,f2,f4,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 - ctx.f27.f64));
	// lfs f27,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f27.f64 = double(temp.f32);
	// fadds f25,f28,f27
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfsx f25,r10,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfsx f28,r9,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f28.f64 = double(temp.f32);
	// mulli r10,r6,252
	ctx.r10.s64 = ctx.r6.s64 * 252;
	// lfs f27,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f27.f64 = double(temp.f32);
	// mulli r9,r6,124
	ctx.r9.s64 = ctx.r6.s64 * 124;
	// fsubs f25,f28,f27
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f21,r9,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f24,r10,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,156
	ctx.r9.s64 = ctx.r6.s64 * 156;
	// lfs f28,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f25,f28,f27
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f24,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfs f27,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f27.f64 = double(temp.f32);
	// lfs f21,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f25,r9,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// mulli r10,r6,28
	ctx.r10.s64 = ctx.r6.s64 * 28;
	// stfsx f28,r10,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfsx f19,r9,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,220
	ctx.r10.s64 = ctx.r6.s64 * 220;
	// lfs f28,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f28,f27
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// lfs f19,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// lfs f27,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f24,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f24.f64 = double(temp.f32);
	// mulli r9,r6,92
	ctx.r9.s64 = ctx.r6.s64 * 92;
	// stfsx f22,r9,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// lfs f22,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// lfs f22,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f21,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f19,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f15,f2,f31
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f28,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f15,f30,f1
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f2,48(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f30,f30,f1
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fsubs f31,f25,f24
	ctx.f31.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fadds f2,f21,f22
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f2,168(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f2,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f1,f28,f27
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f27,f24,f25
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f25,f22,f21
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f17,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f22,88(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f24,f19,f17
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f19,f21,f2
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f2.f64));
	// stfs f19,296(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fsubs f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f21.f64));
	// stfs f2,312(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// fadds f19,f15,f3
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// fsubs f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f15.f64));
	// stfs f19,252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// stfs f3,64(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmuls f21,f31,f2
	ctx.f21.f64 = double(float(ctx.f31.f64 * ctx.f2.f64));
	// lfs f3,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f24,f2
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmuls f19,f31,f3
	ctx.f19.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// lfs f31,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f17,f24,f3
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// mulli r9,r6,180
	ctx.r9.s64 = ctx.r6.s64 * 180;
	// fmuls f24,f28,f31
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// stfs f24,32(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f22,f22,f31
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// stfs f22,236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmadds f24,f1,f3,f21
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f3.f64 + ctx.f21.f64));
	// mulli r10,r6,52
	ctx.r10.s64 = ctx.r6.s64 * 52;
	// fmsubs f22,f1,f2,f19
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 - ctx.f19.f64));
	// lfs f19,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f1,f27,f31
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// stfs f1,152(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmr f1,f19
	ctx.f1.f64 = ctx.f19.f64;
	// fmsubs f21,f25,f2,f17
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 - ctx.f17.f64));
	// fmadds f25,f25,f3,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f15.f64));
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f27,f27,f1,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f19.f64));
	// stfs f27,300(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f27,f1
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f27,f19,f1,f15
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 - ctx.f15.f64));
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f28,f28,f1,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f1.f64 - ctx.f15.f64));
	// fadds f15,f22,f25
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fmadds f19,f19,f31,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 + ctx.f17.f64));
	// fadds f17,f24,f21
	ctx.f17.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfsx f21,r9,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f21,f15
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfsx f21,r9,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,196(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lfs f21,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f21.f64 = double(temp.f32);
	// lwz r9,120(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// fsubs f17,f21,f25
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// fadds f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f25,r9,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f25.f64 = double(temp.f32);
	// fadds f21,f25,f24
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfsx f21,r9,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfsx f25,r10,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f25,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f25.f64 = double(temp.f32);
	// lwz r9,140(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// fadds f25,f30,f25
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// mulli r10,r6,20
	ctx.r10.s64 = ctx.r6.s64 * 20;
	// lfs f21,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f21.f64 = double(temp.f32);
	// fadds f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// lfs f21,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// fsubs f24,f25,f22
	ctx.f24.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfsx f24,r9,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f22,f25
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// lfs f22,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f22.f64 = double(temp.f32);
	// lfs f25,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// lfs f22,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f20,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f17,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,476(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// fadds f15,f28,f19
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f19,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f19.f64));
	// fsubs f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f19,88(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,168(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f14,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,236(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f14,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f19,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f25,f7
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,152(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f19,64(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,480(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f16,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfs f19,156(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f16,f24,f7
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fsubs f19,f21,f20
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fmadds f24,f24,f6,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f14.f64));
	// fmsubs f25,f25,f6,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 - ctx.f16.f64));
	// lfs f20,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,336(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f20,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,488(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f26,f7
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmr f20,f16
	ctx.f20.f64 = ctx.f16.f64;
	// fmuls f17,f22,f7
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// fadds f16,f15,f20
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfsx f16,r10,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfsx f20,r9,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,212
	ctx.r9.s64 = ctx.r6.s64 * 212;
	// fsubs f20,f30,f28
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// mulli r10,r6,84
	ctx.r10.s64 = ctx.r6.s64 * 84;
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f20,r9,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f30,f28,f27
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f30,f26,f6,f17
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f17.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// stfsx f28,r9,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmsubs f28,f22,f6,f17
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f22,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f19,f9
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// fsubs f27,f26,f22
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f20.f64 = double(temp.f32);
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f16,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,88(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f15,f21,f0
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// stfs f21,32(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f16,f19,f8
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// lfs f19,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f19,f9,f16
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 + ctx.f16.f64));
	// lfs f19,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f16,f25,f30
	ctx.f16.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// fadds f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// fsubs f25,f28,f24
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// fadds f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// lfs f24,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f24,f24,f8,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 - ctx.f14.f64));
	// fmsubs f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f15,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f0,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f14.f64));
	// stfs f15,336(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f14,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f16,f27
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f27.f64));
	// stfs f14,252(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f16.f64));
	// stfs f27,312(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f16,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f25,f20
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// lfs f27,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// fadds f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// stfs f27,484(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// lfs f16,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f28,f26
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// lfs f27,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// fadds f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// lfs f26,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f26.f64 = double(temp.f32);
	// fadds f16,f30,f22
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fsubs f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// stfs f30,64(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f30,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,168(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f26,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,236(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f26,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,152(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f26,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,392(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f26,f30,f9
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fmuls f30,f30,f8
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// mulli r9,r6,164
	ctx.r9.s64 = ctx.r6.s64 * 164;
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// mulli r10,r6,36
	ctx.r10.s64 = ctx.r6.s64 * 36;
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmsubs f8,f17,f8,f26
	ctx.f8.f64 = double(float(ctx.f17.f64 * ctx.f8.f64 - ctx.f26.f64));
	// lfs f26,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f9,f17,f9,f30
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f30.f64));
	// lfs f30,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f13,f30,f13,f22
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f22.f64));
	// lfs f22,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f0,f30,f0,f15
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f15.f64));
	// lfs f15,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f30,f26,f22
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// fmuls f17,f27,f4
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// lfs f22,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f15,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f15,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f15,f5,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 - ctx.f17.f64));
	// fadds f15,f8,f21
	ctx.f15.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f15,392(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fadds f15,f9,f24
	ctx.f15.f64 = double(float(ctx.f9.f64 + ctx.f24.f64));
	// fsubs f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f21.f64));
	// fadds f21,f0,f19
	ctx.f21.f64 = double(float(ctx.f0.f64 + ctx.f19.f64));
	// fsubs f9,f24,f9
	ctx.f9.f64 = double(float(ctx.f24.f64 - ctx.f9.f64));
	// lfs f24,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f0,f19,f0
	ctx.f0.f64 = double(float(ctx.f19.f64 - ctx.f0.f64));
	// lfs f19,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f19.f64 = double(temp.f32);
	// fadds f24,f13,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 + ctx.f24.f64));
	// fsubs f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f19.f64));
	// stfs f13,32(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f13,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f13.f64 = double(temp.f32);
	// lfs f19,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f13,f19
	ctx.f19.f64 = double(float(ctx.f13.f64 - ctx.f19.f64));
	// stfsx f19,r9,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f19,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f19.f64 = double(temp.f32);
	// fadds f13,f19,f13
	ctx.f13.f64 = double(float(ctx.f19.f64 + ctx.f13.f64));
	// stfsx f13,r10,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f14,f15
	ctx.f13.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f13,r10,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f14,f15
	ctx.f13.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,228
	ctx.r10.s64 = ctx.r6.s64 * 228;
	// lfs f13,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f19,f13,f9
	ctx.f19.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// fadds f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfsx f19,r10,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// mulli r9,r6,100
	ctx.r9.s64 = ctx.r6.s64 * 100;
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f25,f8
	ctx.f13.f64 = double(float(ctx.f25.f64 + ctx.f8.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f25,f8
	ctx.f13.f64 = double(float(ctx.f25.f64 - ctx.f8.f64));
	// mulli r9,r6,132
	ctx.r9.s64 = ctx.r6.s64 * 132;
	// stfsx f13,r10,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f20,f24
	ctx.f13.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f24,f20
	ctx.f13.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stfsx f13,r10,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f16,f21
	ctx.f13.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfsx f13,r10,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f16,f21
	ctx.f13.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// stfsx f13,r9,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,196
	ctx.r9.s64 = ctx.r6.s64 * 196;
	// fsubs f13,f28,f0
	ctx.f13.f64 = double(float(ctx.f28.f64 - ctx.f0.f64));
	// fadds f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f28.f64));
	// stfsx f13,r9,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f13,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// mulli r10,r6,68
	ctx.r10.s64 = ctx.r6.s64 * 68;
	// stfsx f0,r10,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f0,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f0.f64 = double(temp.f32);
	// fadds f9,f0,f13
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f0,r9,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f0,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f0.f64 = double(temp.f32);
	// fadds f0,f23,f0
	ctx.f0.f64 = double(float(ctx.f23.f64 + ctx.f0.f64));
	// lfs f9,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f27,f27,f5
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f25,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f0,f5
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f13,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f13.f64 = double(temp.f32);
	// lwz r9,460(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	// lfs f28,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f28.f64 = double(temp.f32);
	// fadds f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// lfs f8,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f8.f64 = double(temp.f32);
	// lfs f24,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f24.f64 = double(temp.f32);
	// lwz r10,396(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// lfs f9,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f9.f64 = double(temp.f32);
	// lfs f25,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f25.f64 = double(temp.f32);
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f23,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f23.f64 = double(temp.f32);
	// lfs f8,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f8.f64 = double(temp.f32);
	// lfs f24,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f24.f64 = double(temp.f32);
	// fadds f8,f8,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f29.f64));
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// lfs f21,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f21.f64 = double(temp.f32);
	// lfs f29,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f29.f64 = double(temp.f32);
	// lfs f23,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f23.f64 = double(temp.f32);
	// fadds f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// lfs f20,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f0,f4
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f27,f20,f4,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fsubs f20,f9,f8
	ctx.f20.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f8,f25,f24
	ctx.f8.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fsubs f0,f29,f28
	ctx.f0.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// fsubs f28,f23,f21
	ctx.f28.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fmadds f24,f13,f4,f19
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f4.f64 + ctx.f19.f64));
	// fmsubs f13,f13,f5,f18
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 - ctx.f18.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fmuls f19,f20,f1
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// fmuls f14,f9,f2
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmuls f16,f8,f1
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// fmuls f18,f0,f1
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmuls f15,f28,f1
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// fsubs f1,f17,f24
	ctx.f1.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// fsubs f21,f13,f27
	ctx.f21.f64 = double(float(ctx.f13.f64 - ctx.f27.f64));
	// fadds f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f27.f64));
	// fmsubs f0,f0,f31,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64 - ctx.f19.f64));
	// fmuls f19,f9,f3
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmadds f20,f20,f31,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64 + ctx.f18.f64));
	// fmuls f18,f23,f3
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fmuls f23,f23,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fmsubs f9,f8,f31,f15
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f31.f64 - ctx.f15.f64));
	// fmadds f8,f28,f31,f16
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f31.f64 + ctx.f16.f64));
	// fmsubs f28,f29,f3,f14
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f3.f64 - ctx.f14.f64));
	// fadds f27,f1,f30
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fsubs f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// fmadds f29,f29,f2,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f2.f64 + ctx.f19.f64));
	// fadds f31,f24,f17
	ctx.f31.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// fadds f30,f21,f22
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fmadds f2,f25,f2,f18
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f18.f64));
	// fmsubs f3,f25,f3,f23
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 - ctx.f23.f64));
	// fadds f25,f9,f20
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f20.f64));
	// fadds f24,f8,f0
	ctx.f24.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// fsubs f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f8.f64));
	// fsubs f9,f9,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f20.f64));
	// fsubs f8,f27,f25
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfsx f8,r9,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f25,f27
	ctx.f8.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f30,f24
	ctx.f8.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// stfsx f8,r10,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,248(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// fsubs f8,f30,f24
	ctx.f8.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f1,f0
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// stfsx f8,r10,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,588(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lwz r9,652(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	// fsubs f8,f22,f21
	ctx.f8.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f23,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f23.f64 = double(temp.f32);
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fadds f30,f13,f26
	ctx.f30.f64 = double(float(ctx.f13.f64 + ctx.f26.f64));
	// add r4,r9,r4
	ctx.r4.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lwz r9,264(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// fadds f27,f3,f29
	ctx.f27.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// stw r10,588(r1)
	PPC_STORE_U32(ctx.r1.u32 + 588, ctx.r10.u32);
	// fadds f0,f0,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fadds f25,f2,f28
	ctx.f25.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// fadds f24,f31,f23
	ctx.f24.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fsubs f13,f26,f13
	ctx.f13.f64 = double(float(ctx.f26.f64 - ctx.f13.f64));
	// fsubs f2,f28,f2
	ctx.f2.f64 = double(float(ctx.f28.f64 - ctx.f2.f64));
	// fsubs f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fadds f0,f8,f9
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,344(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// fsubs f0,f8,f9
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// stfs f0,0(r14)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fsubs f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// fsubs f0,f30,f27
	ctx.f0.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,60(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	// fadds f0,f27,f30
	ctx.f0.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,40(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	// fadds f0,f24,f25
	ctx.f0.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,448(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	// fsubs f0,f24,f25
	ctx.f0.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,24(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// fsubs f0,f13,f2
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,20(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fadds f0,f2,f13
	ctx.f0.f64 = double(float(ctx.f2.f64 + ctx.f13.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,436(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	// fadds f0,f31,f3
	ctx.f0.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,16(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fsubs f0,f31,f3
	ctx.f0.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,-26212(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82c970d4
	if (!ctx.cr0.eq) goto loc_82C970D4;
loc_82C9AD20:
	// addi r1,r1,960
	ctx.r1.s64 = ctx.r1.s64 + 960;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82C9AD2C;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9AD30"))) PPC_WEAK_FUNC(sub_82C9AD30);
PPC_FUNC_IMPL(__imp__sub_82C9AD30) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28712
	ctx.r5.s64 = ctx.r11.s64 + -28712;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r4,r11,28680
	ctx.r4.s64 = ctx.r11.s64 + 28680;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9AD48"))) PPC_WEAK_FUNC(sub_82C9AD48);
PPC_FUNC_IMPL(__imp__sub_82C9AD48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82C9AD50;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82C9AD58;
	__savefpr_14(ctx, base);
	// stwu r1,-624(r1)
	ea = -624 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82c9c450
	if (!ctx.cr6.lt) goto loc_82C9C450;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lis r5,-32235
	ctx.r5.s64 = -2112552960;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// stw r10,300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 300, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32235
	ctx.r7.s64 = -2112552960;
	// lfs f31,27780(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 27780);
	ctx.f31.f64 = double(temp.f32);
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lfs f1,27784(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 27784);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,27788(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 27788);
	ctx.f2.f64 = double(temp.f32);
	// lfs f11,27776(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27776);
	ctx.f11.f64 = double(temp.f32);
	// stw r10,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f3,27792(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 27792);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,-29656(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29656);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,-29652(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29652);
	ctx.f12.f64 = double(temp.f32);
loc_82C9ADB4:
	// lfs f0,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f30,f0,f9
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f7,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f0,f8
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f9,f7
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f8,f6
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f29,f5,f7
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmuls f28,f4,f6
	ctx.f28.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f13,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f26,f4,f7
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// fmuls f27,f5,f6
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f20,f0,f5
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f16,f13,f4
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmadds f30,f13,f8,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f30.f64));
	// stfs f30,124(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmuls f19,f0,f6
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// fmuls f15,f13,f7
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmsubs f30,f13,f9,f25
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f25.f64));
	// stfs f30,136(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f16,f20
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f22,152(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fadds f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f23,f9,f6
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f18,f0,f4
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fmuls f22,f13,f5
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmuls f17,f0,f7
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fsubs f25,f21,f23
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fsubs f21,f22,f18
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f21,160(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f21,f13,f6
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fsubs f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f22,212(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmuls f19,f13,f27
	ctx.f19.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// fmuls f18,f0,f27
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fmuls f15,f25,f0
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fsubs f22,f17,f21
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f22,56(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f22,f20,f16
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fmuls f16,f26,f0
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fadds f14,f21,f17
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfs f14,208(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmuls f14,f24,f0
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f22,f0,f30
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f21,f13,f30
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fmuls f20,f0,f29
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f29.f64));
	// fmuls f17,f13,f28
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmadds f16,f25,f13,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmsubs f16,f26,f13,f15
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmadds f16,f23,f13,f14
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f16,140(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f16,f19,f22
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f16,196(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f22,f21,f18
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f22,200(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f22,f18,f21
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f22,120(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmuls f21,f0,f28
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// rlwinm r10,r6,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// fmuls f22,f13,f29
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// fmuls f18,f8,f5
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f19,f9,f4
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f16,f9,f30
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f15,f8,f27
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmuls f17,f8,f4
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fmuls f14,f8,f30
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fadds f20,f21,f22
	ctx.f20.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f20,108(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,112(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fmuls f22,f9,f27
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f21,f18,f19
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmuls f18,f23,f0
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f20,f9,f5
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmsubs f18,f24,f13,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f18,188(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fsubs f18,f16,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f18,168(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f18,100(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f16,f8,f28
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,176(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f17,f9,f29
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmuls f14,f19,f0
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f15,220(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,172(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f16,f9,f28
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f17,f8,f29
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,216(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,144(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f15,f20,f0
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmsubs f20,f20,f13,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f20,16(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f20,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f22,f0
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f16,f21,f0
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmadds f19,f19,f13,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f19,64(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f19,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,180(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f19,f18,f0
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmadds f17,f21,f13,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 + ctx.f17.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmsubs f17,f22,f13,f16
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f17,88(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmadds f20,f18,f13,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f20,96(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmsubs f20,f20,f13,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f19.f64));
	// stfs f20,184(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f20,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f18,f19,f0
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f19,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f17,f19,f13,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f17,164(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// mulli r8,r6,96
	ctx.r8.s64 = ctx.r6.s64 * 96;
	// fmadds f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f17,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f17,f13,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f20.f64));
	// stfs f20,132(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f20,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r9,r6,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fmadds f20,f20,f13,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f18.f64));
	// stfs f20,28(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// add r30,r7,r3
	ctx.r30.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfs f17,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f17.f64 = double(temp.f32);
	// mulli r5,r6,100
	ctx.r5.s64 = ctx.r6.s64 * 100;
	// fmuls f16,f20,f17
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f17.f64));
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f20,f18
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f18.f64));
	// lfs f20,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// stw r30,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r30.u32);
	// mulli r31,r6,68
	ctx.r31.s64 = ctx.r6.s64 * 68;
	// fmadds f18,f20,f18,f16
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f18.f64 + ctx.f16.f64));
	// fmsubs f17,f20,f17,f15
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f20,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// add r29,r5,r3
	ctx.r29.u64 = ctx.r5.u64 + ctx.r3.u64;
	// add r28,r31,r3
	ctx.r28.u64 = ctx.r31.u64 + ctx.r3.u64;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fadds f16,f18,f20
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f16,100(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfsx f16,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stw r7,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r7.u32);
	// lfs f16,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// stw r29,288(r1)
	PPC_STORE_U32(ctx.r1.u32 + 288, ctx.r29.u32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stw r5,312(r1)
	PPC_STORE_U32(ctx.r1.u32 + 312, ctx.r5.u32);
	// stfs f20,128(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stw r28,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, ctx.r28.u32);
	// lfs f20,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// stw r31,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r31.u32);
	// fsubs f18,f20,f17
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f18,192(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,116(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f20,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f20,f26
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfsx f17,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// fmadds f25,f18,f25,f16
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f16.f64));
	// fmsubs f20,f18,f26,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 - ctx.f20.f64));
	// lfs f26,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f6
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f18,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f26,f18,f15
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f26,f26,f15,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f15.f64 - ctx.f17.f64));
	// stfs f26,20(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f7.f64));
	// lfs f26,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f26,f17
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f26,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f15.f64));
	// lfs f26,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f6,f26,f6,f14
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f14.f64));
	// stfs f6,96(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmsubs f26,f26,f7,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 - ctx.f16.f64));
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f16,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f16.f64 = double(temp.f32);
	// mulli r7,r6,124
	ctx.r7.s64 = ctx.r6.s64 * 124;
	// lfs f6,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// mulli r29,r6,36
	ctx.r29.s64 = ctx.r6.s64 * 36;
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fmadds f17,f7,f16,f17
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f7,f16,f15
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f7,f18,f25
	ctx.f7.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fsubs f18,f20,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// mulli r5,r6,92
	ctx.r5.s64 = ctx.r6.s64 * 92;
	// fadds f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 + ctx.f15.f64));
	// stfs f15,196(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f7
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f7.f64));
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f25.f64));
	// stfs f7,260(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// fadds f25,f25,f7
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f7.f64));
	// lfs f7,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f7,f18
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f18.f64));
	// stfs f7,228(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f7,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f7.f64 = double(temp.f32);
	// add r28,r29,r3
	ctx.r28.u64 = ctx.r29.u64 + ctx.r3.u64;
	// fadds f18,f18,f7
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f7.f64));
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// fadds f7,f7,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f20.f64));
	// stfs f7,192(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// add r29,r29,r4
	ctx.r29.u64 = ctx.r29.u64 + ctx.r4.u64;
	// fsubs f7,f7,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f20.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// stfs f7,200(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f7,f6,f20
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// stfs f7,20(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// mulli r30,r6,28
	ctx.r30.s64 = ctx.r6.s64 * 28;
	// lfs f7,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// stw r28,296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 296, ctx.r28.u32);
	// fmadds f6,f7,f20,f14
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f20.f64 + ctx.f14.f64));
	// lfs f20,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f20.f64 = double(temp.f32);
	// stw r29,304(r1)
	PPC_STORE_U32(ctx.r1.u32 + 304, ctx.r29.u32);
	// mulli r31,r6,60
	ctx.r31.s64 = ctx.r6.s64 * 60;
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f7,f7,f20,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f20.f64 - ctx.f14.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f6,f14
	ctx.f20.f64 = double(float(ctx.f6.f64 + ctx.f14.f64));
	// fsubs f6,f14,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 - ctx.f6.f64));
	// stfs f6,156(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f6,f7,f26
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// stfs f6,100(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 - ctx.f7.f64));
	// lfsx f26,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,180(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfsx f26,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,184(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfsx f26,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,152(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f6,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f26,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f6,20(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// stfs f26,188(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfsx f6,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f26,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f7,116(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f7,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// stfs f6,96(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f26,160(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfsx f26,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f7,f8
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// stfs f26,128(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f26,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// mulli r28,r6,48
	ctx.r28.s64 = ctx.r6.s64 * 48;
	// stfs f26,148(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f26,f7,f9
	ctx.f26.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f6,f7
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// mulli r27,r6,80
	ctx.r27.s64 = ctx.r6.s64 * 80;
	// fmsubs f9,f7,f9,f14
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 - ctx.f14.f64));
	// stfs f9,140(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f9,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f9.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f8,f7,f8,f26
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f26.f64));
	// stfs f8,20(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f8,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// lfs f7,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f9,f7
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f9,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f8,f9,f8,f6
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,108(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f8,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f9,f9,f8,f26
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 - ctx.f26.f64));
	// stfs f9,120(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f9,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f9,f8
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f8,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f26,f9,f8
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f8,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f8,f9,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f7.f64));
	// lfs f7,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f8,f8,f7,f14
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f14.f64));
	// stfs f8,72(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f7,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f14,f8,f19
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// lfs f8,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f7,f8,f6
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f6.f64));
	// lfs f6,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f7,f7,f6,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 - ctx.f26.f64));
	// lfs f26,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// fadds f6,f26,f17
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// fsubs f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f16,f6,f20
	ctx.f16.f64 = double(float(ctx.f6.f64 + ctx.f20.f64));
	// fsubs f6,f20,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 - ctx.f6.f64));
	// stfs f6,160(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f6,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f6.f64 = double(temp.f32);
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 - ctx.f20.f64));
	// stfs f20,152(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// fadds f6,f20,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// stfs f20,268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// stfs f26,204(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f26,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f20,f26,f17
	ctx.f20.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// stfs f20,252(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f26,308(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f26,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f26.f64 = double(temp.f32);
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f20,f26
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f20,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f26,f20,f26,f14
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f26.f64 + ctx.f14.f64));
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f20,f19,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 - ctx.f17.f64));
	// fadds f19,f8,f14
	ctx.f19.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// lfs f17,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f7,f17
	ctx.f17.f64 = double(float(ctx.f7.f64 + ctx.f17.f64));
	// mulli r26,r6,112
	ctx.r26.s64 = ctx.r6.s64 * 112;
	// fsubs f7,f14,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 - ctx.f7.f64));
	// fadds f14,f26,f9
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f9.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f9,f26,f9
	ctx.f9.f64 = double(float(ctx.f26.f64 - ctx.f9.f64));
	// lfsx f26,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,148(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fsubs f17,f8,f20
	ctx.f17.f64 = double(float(ctx.f8.f64 - ctx.f20.f64));
	// stfs f17,284(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fadds f8,f20,f8
	ctx.f8.f64 = double(float(ctx.f20.f64 + ctx.f8.f64));
	// stfs f8,184(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfsx f8,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,20(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f8,f9,f7
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// stfs f8,224(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// lfsx f8,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f26,f29
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// stfs f8,24(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f9,96(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f9,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f20,f9,f22
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f22.f64));
	// lfs f8,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f17,f9,f21
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// lfs f9,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f14,f8,f9
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f8,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// stfs f9,164(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f8,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f9,f8,f28,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 + ctx.f7.f64));
	// lfs f28,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f8,f8,f29,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f29.f64 - ctx.f26.f64));
	// lfs f29,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f7,f28,f21,f20
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfs f26,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f29
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// fmuls f29,f20,f29
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f29.f64));
	// stfs f29,104(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmsubs f29,f28,f22,f17
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 - ctx.f17.f64));
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// stfs f26,52(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmr f26,f28
	ctx.f26.f64 = ctx.f28.f64;
	// lfs f28,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f28,f28,f26,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f26.f64 + ctx.f14.f64));
	// fmsubs f26,f22,f26,f17
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f26.f64 - ctx.f17.f64));
	// lfs f21,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// rlwinm r25,r6,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f22,f20,f21,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 + ctx.f17.f64));
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// mulli r24,r6,104
	ctx.r24.s64 = ctx.r6.s64 * 104;
	// fmsubs f21,f20,f21,f17
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64 - ctx.f17.f64));
	// fadds f20,f28,f9
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f9.f64));
	// fsubs f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f28.f64));
	// fadds f17,f26,f8
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f8.f64));
	// mulli r23,r6,72
	ctx.r23.s64 = ctx.r6.s64 * 72;
	// fsubs f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f26.f64));
	// fadds f14,f22,f7
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f7.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f7,f22,f7
	ctx.f7.f64 = double(float(ctx.f22.f64 - ctx.f7.f64));
	// fadds f14,f21,f29
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f29,f21,f29
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// lfsx f26,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,164(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// mulli r22,r6,40
	ctx.r22.s64 = ctx.r6.s64 * 40;
	// fsubs f28,f8,f9
	ctx.f28.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// fadds f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// lfsx f26,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f8,f29,f7
	ctx.f8.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// stfs f8,176(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f8,f7,f29
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// lfsx f7,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,56(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// mulli r21,r6,120
	ctx.r21.s64 = ctx.r6.s64 * 120;
	// lfsx f29,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,52(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// stfs f26,104(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfsx f26,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,156(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfsx f26,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f8,100(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f26,20(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f8,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f26,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f8,f27
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// stfs f26,108(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f26,f8,f30
	ctx.f26.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// lfsx f7,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f21,f7,f8
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f29,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fmuls f14,f7,f8
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f8,f29,f8
	ctx.f8.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fmuls f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f7.f64));
	// stfs f7,148(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f29,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f29.f64 = double(temp.f32);
	// fmr f7,f29
	ctx.f7.f64 = ctx.f29.f64;
	// stfs f8,56(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f29,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f8,f7,f27,f26
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f27.f64 + ctx.f26.f64));
	// lfs f27,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f7,f7,f30,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f22.f64));
	// lfs f30,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f29,f30,f29,f21
	ctx.f29.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 + ctx.f21.f64));
	// stfs f29,52(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f29,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f26,f29,f24
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// fmuls f21,f29,f23
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f23.f64));
	// lfs f29,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f30,f30,f29,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 - ctx.f14.f64));
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// mulli r20,r6,88
	ctx.r20.s64 = ctx.r6.s64 * 88;
	// lfs f29,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// mulli r19,r6,56
	ctx.r19.s64 = ctx.r6.s64 * 56;
	// fmadds f29,f27,f29,f22
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f22.f64));
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f27,f22,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f26,f22,f23,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f26.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f24,f22,f24,f21
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f21.f64));
	// fadds f23,f29,f8
	ctx.f23.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// fsubs f8,f8,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f29.f64));
	// fadds f22,f27,f7
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// lfs f27,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f26,f27
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// mulli r18,r6,24
	ctx.r18.s64 = ctx.r6.s64 * 24;
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f26,f24,f30
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fsubs f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// mulli r17,r6,20
	ctx.r17.s64 = ctx.r6.s64 * 20;
	// fadds f24,f29,f23
	ctx.f24.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// fsubs f23,f22,f26
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fadds f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// fadds f22,f27,f7
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// stfs f7,188(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f7,f8,f30
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f30.f64));
	// stfs f7,112(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f8,f30,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 + ctx.f8.f64));
	// stfs f8,180(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f8,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f8.f64 = double(temp.f32);
	// mulli r16,r6,84
	ctx.r16.s64 = ctx.r6.s64 * 84;
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f30,f8
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// lfs f7,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f21,f7,f8
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// add r15,r17,r3
	ctx.r15.u64 = ctx.r17.u64 + ctx.r3.u64;
	// add r14,r16,r3
	ctx.r14.u64 = ctx.r16.u64 + ctx.r3.u64;
	// add r17,r17,r4
	ctx.r17.u64 = ctx.r17.u64 + ctx.r4.u64;
	// add r16,r16,r4
	ctx.r16.u64 = ctx.r16.u64 + ctx.r4.u64;
	// fmadds f7,f7,f8,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f27.f64));
	// lfsx f27,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f8,f30,f8,f21
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f21.f64));
	// stfs f27,48(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f30,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stw r15,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r15.u32);
	// stfs f30,56(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// stw r17,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, ctx.r17.u32);
	// lfsx f30,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// stw r14,240(r1)
	PPC_STORE_U32(ctx.r1.u32 + 240, ctx.r14.u32);
	// stfs f30,68(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// stw r16,244(r1)
	PPC_STORE_U32(ctx.r1.u32 + 244, ctx.r16.u32);
	// lfsx f30,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,52(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f8,104(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfsx f8,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f30,f8,f30
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// stfs f7,124(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfsx f7,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f7,f14
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f14.f64));
	// fmuls f21,f7,f21
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// lfs f7,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f8,f8,f7,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 + ctx.f27.f64));
	// stfs f8,28(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f8,f8,f7,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 - ctx.f30.f64));
	// stfs f8,136(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f7,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f30,f8,f7
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f8,f7
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f7,f8,f21
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 + ctx.f21.f64));
	// lfs f21,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f7,f7,f21,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 - ctx.f14.f64));
	// stfs f7,92(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f7,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f21,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f7,f21
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f7,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f30,f7,f14,f30
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f14.f64 + ctx.f30.f64));
	// stfs f30,60(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f30,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// mulli r15,r6,116
	ctx.r15.s64 = ctx.r6.s64 * 116;
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f14.f64));
	// lfs f30,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f7,f7,f30,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f27.f64));
	// lfs f27,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f27,f30,f21
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f27,f27,f21,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f21.f64 - ctx.f14.f64));
	// lfs f21,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f8,f21
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f21,84(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f21,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// stfs f8,48(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f8,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f8
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f8.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f7,f14
	ctx.f14.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f14.f64));
	// stfs f7,68(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f7,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f7.f64));
	// stfs f14,124(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f14.f64));
	// stfs f7,208(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f7,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f7.f64));
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fadds f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// stfs f7,132(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f7,f8,f21
	ctx.f7.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f7,148(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f8,f21,f8
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// stfs f8,108(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f7,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfs f21,164(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f8,232(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f8,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f7.f64 = double(temp.f32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f8,f7
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// stfs f8,16(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f7,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f8,f7,f21,f14
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 + ctx.f14.f64));
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r15,r3
	ctx.r14.u64 = ctx.r15.u64 + ctx.r3.u64;
	// fmsubs f7,f7,f21,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 - ctx.f14.f64));
	// add r15,r15,r4
	ctx.r15.u64 = ctx.r15.u64 + ctx.r4.u64;
	// fsubs f21,f30,f8
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f8.f64));
	// fadds f8,f8,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f30.f64));
	// stfs f8,40(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// mulli r17,r6,12
	ctx.r17.s64 = ctx.r6.s64 * 12;
	// stw r14,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r14.u32);
	// stw r15,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r15.u32);
	// fsubs f8,f27,f7
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f7.f64));
	// mulli r15,r6,52
	ctx.r15.s64 = ctx.r6.s64 * 52;
	// fadds f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f27.f64));
	// stfs f7,48(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// add r14,r15,r3
	ctx.r14.u64 = ctx.r15.u64 + ctx.r3.u64;
	// add r15,r15,r4
	ctx.r15.u64 = ctx.r15.u64 + ctx.r4.u64;
	// fadds f14,f8,f21
	ctx.f14.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f14,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r16,r6,76
	ctx.r16.s64 = ctx.r6.s64 * 76;
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f21.f64));
	// stfs f8,56(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f8,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// stw r14,248(r1)
	PPC_STORE_U32(ctx.r1.u32 + 248, ctx.r14.u32);
	// stw r15,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r15.u32);
	// stfs f8,16(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f8,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,60(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f8,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,92(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f8,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f8.f64 = double(temp.f32);
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// lfs f27,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// lfs f14,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// lwz r15,172(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lfs f7,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lwz r15,20(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fmuls f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmuls f7,f7,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// lfs f21,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f27,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fmuls f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f8,f30,f14,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f14.f64 + ctx.f8.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f7,f30,f14,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f14.f64 - ctx.f7.f64));
	// stfs f7,84(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f7,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f7,f5
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// lfs f30,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f30.f64 = double(temp.f32);
	// lwz r15,144(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lfs f7,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f30,f7,f30,f21
	ctx.f30.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 + ctx.f21.f64));
	// stfs f30,28(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f30,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f30,f4
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f4.f64));
	// lfs f30,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f7,f7,f30,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64 - ctx.f27.f64));
	// lfs f30,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f30.f64 = double(temp.f32);
	// lfs f27,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f30,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// lfs f30,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f4,f30,f4,f14
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f4.f64 + ctx.f14.f64));
	// fmsubs f5,f30,f5,f21
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f5.f64 - ctx.f21.f64));
	// lfs f21,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f21.f64 = double(temp.f32);
	// lfs f30,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f21,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f21.f64 + ctx.f27.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f8,f21
	ctx.f27.f64 = double(float(ctx.f8.f64 - ctx.f21.f64));
	// fadds f8,f21,f8
	ctx.f8.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// fsubs f21,f14,f7
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f7.f64));
	// fadds f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f14,f27,f21
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f21.f64));
	// stfs f8,212(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// mulli r15,r6,108
	ctx.r15.s64 = ctx.r6.s64 * 108;
	// lfs f8,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// fsubs f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfs f21,88(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f8,64(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f8,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f8.f64 = double(temp.f32);
	// fadds f21,f8,f14
	ctx.f21.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// fsubs f7,f14,f8
	ctx.f7.f64 = double(float(ctx.f14.f64 - ctx.f8.f64));
	// lfs f8,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f14,f8,f27
	ctx.f14.f64 = double(float(ctx.f8.f64 - ctx.f27.f64));
	// fadds f8,f27,f8
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f8.f64));
	// stfs f8,16(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f8,f7,f12
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f7,f21,f12
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f27,f14,f12
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// stfs f21,156(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f21,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f14.f64));
	// fadds f14,f30,f4
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f30,16(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f30,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f24.f64));
	// stfs f30,44(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f30,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfs f30,28(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f30,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// stfs f30,32(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f30,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f30.f64 = double(temp.f32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f30,f14,f30,f21
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f30.f64 - ctx.f21.f64));
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,40(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f21,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f14,f30,f5
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fsubs f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// lfs f30,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// lfsx f21,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,16(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// stfs f30,60(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f30,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f21,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f14,f5,f4
	ctx.f14.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f5,56(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// lfs f5,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f14,f21,f5
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f5,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f5,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f13,f5,f13,f4
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f4.f64));
	// fmsubs f0,f5,f0,f30
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f30.f64));
	// lfs f4,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f4,f5,f14
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfs f30,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f4,f4,f30,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64 - ctx.f21.f64));
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f5,f13
	ctx.f30.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// fsubs f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f5.f64));
	// fadds f5,f4,f0
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f0.f64));
	// fsubs f0,f0,f4
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f4.f64));
	// fadds f4,f30,f21
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f21,f5,f14
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f14.f64));
	// stfs f21,44(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f21,f0,f13
	ctx.f21.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// fsubs f13,f14,f5
	ctx.f13.f64 = double(float(ctx.f14.f64 - ctx.f5.f64));
	// stfs f13,92(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f13,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// lfs f5,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f5.f64 = double(temp.f32);
	// fadds f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// stfs f13,36(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f13,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f5,f13,f21
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f21.f64));
	// fadds f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f13.f64));
	// lfs f13,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f14,f0,f13
	ctx.f14.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,16(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f0,f5,f12
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f13,f21,f12
	ctx.f13.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f5,f14,f12
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f5,128(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f5,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f5,168(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fadds f21,f5,f16
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f16.f64));
	// lfs f5,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f5.f64 = double(temp.f32);
	// fadds f14,f4,f5
	ctx.f14.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f5,f14,f21
	ctx.f5.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// fsubs f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfs f21,32(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f21,36(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f21,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f14,f21,f5
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f5.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f21.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// lfs f5,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f14,f14,f5
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f5.f64));
	// stfsx f14,r10,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfs f21,0(r3)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// fadds f5,f5,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f21.f64));
	// stfs f5,0(r4)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// lfs f5,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f21,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f5.f64));
	// stfsx f5,r8,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// lfs f5,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f5,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f21.f64));
	// lfs f21,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f6,f6,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f21.f64));
	// stfsx f5,r8,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f21,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 - ctx.f4.f64));
	// fsubs f5,f16,f5
	ctx.f5.f64 = double(float(ctx.f16.f64 - ctx.f5.f64));
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f17,f23,f29
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f29,48(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f23,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f29,84(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f23,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f29,44(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f29,76(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// stfsx f29,r9,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f29,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f29.f64 = double(temp.f32);
	// lfs f23,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// lfs f23,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f20,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// stfs f23,40(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f23,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// lfs f20,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f29,r9,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f29,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f29.f64 = double(temp.f32);
	// stfs f20,80(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f29,f15,f29
	ctx.f29.f64 = double(float(ctx.f15.f64 - ctx.f29.f64));
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f6,f5
	ctx.f15.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fsubs f5,f4,f21
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f21.f64));
	// stfs f5,36(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f5,f21,f4
	ctx.f5.f64 = double(float(ctx.f21.f64 + ctx.f4.f64));
	// stfs f5,68(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// fadds f5,f26,f16
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// stfs f5,32(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f5,f16,f26
	ctx.f5.f64 = double(float(ctx.f16.f64 - ctx.f26.f64));
	// stfs f5,52(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fadds f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// fmuls f21,f14,f10
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// lfs f5,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f5,f24
	ctx.f4.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// stfs f4,56(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f24.f64));
	// stfs f5,104(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f5,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f26,f5,f17
	ctx.f26.f64 = double(float(ctx.f5.f64 - ctx.f17.f64));
	// fadds f24,f17,f5
	ctx.f24.f64 = double(float(ctx.f17.f64 + ctx.f5.f64));
	// lfs f4,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f14,f11
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f11.f64));
	// fadds f16,f4,f5
	ctx.f16.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f14,f4,f5
	ctx.f14.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// lfs f5,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// stfs f5,16(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f4,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f5,f26,f12
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmuls f26,f24,f12
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// stfs f4,28(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f24,f16,f12
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f26,64(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f26,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f4,f26,f11,f21
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 - ctx.f21.f64));
	// fmadds f26,f26,f10,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f17.f64));
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f10,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f16.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f14,f12
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f17,f10,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f16.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f17,f6
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f6.f64));
	// fsubs f6,f6,f17
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f17.f64));
	// stfs f6,16(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fmuls f6,f16,f12
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmuls f17,f14,f12
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fsubs f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f6.f64));
	// stfsx f14,r27,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f6,f6,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f14.f64));
	// stfsx f6,r29,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f6,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f6.f64 = double(temp.f32);
	// fadds f14,f17,f6
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f6.f64));
	// stfsx f14,r29,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f6,f17
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f17.f64));
	// stfsx f6,r27,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f6.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fsubs f17,f6,f16
	ctx.f17.f64 = double(float(ctx.f6.f64 - ctx.f16.f64));
	// stfsx f17,r26,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f16,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 + ctx.f6.f64));
	// stfsx f6,r28,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fadds f16,f21,f23
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fadds f17,f15,f6
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f6.f64));
	// stfsx f17,r28,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f6,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f15.f64));
	// stfsx f6,r26,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f6,f19,f6
	ctx.f6.f64 = double(float(ctx.f19.f64 - ctx.f6.f64));
	// lfs f19,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// lfs f17,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fadds f17,f5,f29
	ctx.f17.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fsubs f5,f29,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// lfs f29,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f15,f28,f29
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// lfs f29,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f14,f29,f9
	ctx.f14.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// fsubs f29,f23,f21
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f24,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// stfs f23,28(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfs f24,48(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// lfs f21,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fmuls f15,f14,f12
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fmsubs f21,f22,f10,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f21.f64));
	// stfs f21,32(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fmuls f21,f30,f11
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fmuls f15,f6,f11
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f14,f19,f11
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fmuls f19,f19,f10
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fmsubs f6,f6,f10,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 - ctx.f21.f64));
	// fmadds f30,f30,f10,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 + ctx.f15.f64));
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f20,f10,f14
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f20,f20,f11,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 - ctx.f19.f64));
	// fsubs f19,f15,f14
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 + ctx.f14.f64));
	// stfs f14,228(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f6,f6,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f14.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// fadds f14,f21,f4
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f4.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f4,f4,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f21.f64));
	// fadds f14,f20,f26
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// lfs f21,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f20,f17,f21
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfsx f20,r20,r3
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfsx f21,r18,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fadds f20,f16,f21
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfsx f20,r18,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// stfsx f21,r20,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f5,f30
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// stfsx f21,r21,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfsx f5,r19,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f29,f6
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// stfsx f5,r19,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f29,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 - ctx.f6.f64));
	// stfsx f6,r21,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// lfs f5,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f30,f6,f5
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// stfsx f30,r23,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfsx f6,r25,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f23,f14
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfsx f6,r25,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f23,f14
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// stfsx f6,r23,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f6,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f5,f6,f26
	ctx.f5.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// stfsx f5,r24,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// stfsx f6,r22,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f24,f4
	ctx.f6.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// stfsx f6,r22,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f24,f4
	ctx.f6.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// lfs f26,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f24.f64 = double(temp.f32);
	// lfs f29,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f5,f24,f27
	ctx.f5.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfsx f6,r24,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f29,f0
	ctx.f4.f64 = double(float(ctx.f29.f64 - ctx.f0.f64));
	// lfs f23,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f6,f26,f8
	ctx.f6.f64 = double(float(ctx.f26.f64 - ctx.f8.f64));
	// lfs f30,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f30.f64 = double(temp.f32);
	// lfs f21,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f21.f64 = double(temp.f32);
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f16,f21,f10
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f21,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f21,f11
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f29,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f29.f64 = double(temp.f32);
	// lfs f20,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// fmuls f17,f20,f11
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fadds f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fadds f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// fmadds f24,f22,f11,f16
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fmsubs f23,f20,f10,f14
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 - ctx.f14.f64));
	// stfs f23,224(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f22,f6,f31
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f23,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f5,f31
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmadds f26,f21,f10,f17
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f17.f64));
	// fmuls f21,f30,f31
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fmuls f17,f4,f31
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f14,f27,f3
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fmuls f27,f27,f2
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// fmuls f16,f29,f2
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f2.f64));
	// fmadds f5,f5,f1,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f22.f64));
	// fmsubs f6,f6,f1,f20
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 - ctx.f20.f64));
	// fsubs f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// fmsubs f4,f4,f1,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f1.f64 - ctx.f21.f64));
	// fmadds f30,f30,f1,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 + ctx.f17.f64));
	// fmuls f17,f29,f3
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// lfs f29,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f20,f8,f2,f14
	ctx.f20.f64 = double(float(ctx.f8.f64 * ctx.f2.f64 + ctx.f14.f64));
	// fmsubs f8,f8,f3,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f3.f64 - ctx.f27.f64));
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f26,f19,f23
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f23.f64));
	// fadds f27,f23,f19
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// fadds f23,f4,f5
	ctx.f23.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fadds f4,f30,f6
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// lfs f21,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f21,f24
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// fadds f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fmsubs f21,f0,f3,f16
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f3.f64 - ctx.f16.f64));
	// fmadds f0,f0,f2,f17
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f2.f64 + ctx.f17.f64));
	// fsubs f17,f27,f23
	ctx.f17.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfsx f17,r5,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfsx f27,r30,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f23,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f23.f64 = double(temp.f32);
	// fadds f19,f22,f25
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// fsubs f30,f25,f22
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fadds f25,f24,f15
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// fadds f22,f20,f21
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f27,f19,f4
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// stfsx f27,r30,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f19,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 - ctx.f4.f64));
	// stfsx f4,r5,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fsubs f4,f26,f6
	ctx.f4.f64 = double(float(ctx.f26.f64 - ctx.f6.f64));
	// stfsx f4,r7,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f26.f64));
	// stfsx f6,r31,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f30,f5
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfsx f6,r31,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f30,f5
	ctx.f6.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfsx f6,r7,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f4,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f5,f25,f22
	ctx.f5.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// lfs f6,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f6.f64 = double(temp.f32);
	// lfs f26,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f26.f64 = double(temp.f32);
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f27,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f4,f26,f7
	ctx.f4.f64 = double(float(ctx.f26.f64 - ctx.f7.f64));
	// stfsx f5,r16,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// lfs f5,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f30,f27,f23
	ctx.f30.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fadds f5,f13,f5
	ctx.f5.f64 = double(float(ctx.f13.f64 + ctx.f5.f64));
	// fadds f23,f26,f9
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f9.f64));
	// lfs f9,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f26,f15,f24
	ctx.f26.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// fadds f19,f9,f28
	ctx.f19.f64 = double(float(ctx.f9.f64 + ctx.f28.f64));
	// lfs f9,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f17,f9,f10
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f9,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f16,f9,f11
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f28,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// stfs f9,204(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmuls f14,f28,f10
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// lfs f28,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f28.f64 = double(temp.f32);
	// fadds f9,f8,f0
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// lfs f24,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f0.f64));
	// lwz r10,236(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// fadds f28,f29,f28
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// lwz r9,300(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// fsubs f8,f21,f20
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f21,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f21.f64 = double(temp.f32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfsx f25,r17,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// lfs f22,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f24,f23,f12
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f25,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f19,f12
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f21,f21,f11,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 - ctx.f17.f64));
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f19,f19,f11,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f14.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fmadds f20,f17,f10,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f16.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fmuls f14,f7,f31
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fsubs f13,f22,f13
	ctx.f13.f64 = double(float(ctx.f22.f64 - ctx.f13.f64));
	// fmuls f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// stfs f7,232(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f22,f6,f1
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// stw r10,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, ctx.r10.u32);
	// fmuls f15,f4,f3
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fmadds f7,f5,f31,f22
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f31.f64 + ctx.f22.f64));
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// stfs f13,204(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmsubs f17,f17,f11,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f16.f64));
	// fmuls f13,f5,f1
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmuls f16,f30,f3
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmsubs f5,f30,f2,f15
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f2.f64 - ctx.f15.f64));
	// fadds f30,f28,f9
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f9.f64));
	// stfsx f30,r17,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f28,f9
	ctx.f9.f64 = double(float(ctx.f28.f64 - ctx.f9.f64));
	// stfsx f9,r16,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f26,f0
	ctx.f9.f64 = double(float(ctx.f26.f64 - ctx.f0.f64));
	// stfsx f9,r15,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f0,f26
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f26.f64));
	// stfsx f0,r14,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f29,f8
	ctx.f0.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// stfsx f0,r14,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f29,f8
	ctx.f0.f64 = double(float(ctx.f29.f64 - ctx.f8.f64));
	// stfsx f0,r15,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f18,f24
	ctx.f0.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// lfs f30,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f30.f64 = double(temp.f32);
	// fadds f9,f24,f18
	ctx.f9.f64 = double(float(ctx.f24.f64 + ctx.f18.f64));
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmsubs f13,f6,f31,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f31.f64 - ctx.f13.f64));
	// add r4,r9,r4
	ctx.r4.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fadds f26,f17,f19
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f24,f17,f19
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f22,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f6,f4,f2,f16
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f2.f64 + ctx.f16.f64));
	// fmadds f4,f27,f1,f14
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f14.f64));
	// fadds f8,f23,f30
	ctx.f8.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// fsubs f29,f21,f20
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f28,f20,f21
	ctx.f28.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fsubs f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// fmsubs f27,f27,f31,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64 - ctx.f22.f64));
	// fmuls f18,f25,f3
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f19,f3
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmsubs f25,f25,f2,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 - ctx.f21.f64));
	// lwz r10,240(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	// fadds f23,f29,f0
	ctx.f23.f64 = double(float(ctx.f29.f64 + ctx.f0.f64));
	// fadds f22,f24,f30
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fsubs f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f29.f64));
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// fadds f24,f4,f13
	ctx.f24.f64 = double(float(ctx.f4.f64 + ctx.f13.f64));
	// fadds f29,f26,f9
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f9.f64));
	// fadds f21,f27,f7
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f27,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 - ctx.f7.f64));
	// fsubs f9,f9,f26
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f26.f64));
	// fadds f20,f28,f8
	ctx.f20.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// fsubs f13,f13,f4
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f4.f64));
	// fsubs f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// fadds f4,f25,f6
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// fmadds f19,f19,f2,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 + ctx.f18.f64));
	// fsubs f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 - ctx.f6.f64));
	// fsubs f28,f29,f24
	ctx.f28.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// fadds f27,f24,f29
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// fsubs f24,f9,f7
	ctx.f24.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f26,f20,f21
	ctx.f26.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f7,f8,f13
	ctx.f7.f64 = double(float(ctx.f8.f64 + ctx.f13.f64));
	// fsubs f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fsubs f8,f23,f4
	ctx.f8.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,292(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// fadds f29,f19,f5
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f5.f64));
	// fadds f8,f4,f23
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// fsubs f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f19.f64));
	// fsubs f25,f20,f21
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,276(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// fadds f8,f30,f6
	ctx.f8.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// fadds f4,f22,f29
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// stfs f4,0(r10)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,244(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// fsubs f4,f22,f29
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// stfs f4,0(r10)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// fsubs f4,f0,f5
	ctx.f4.f64 = double(float(ctx.f0.f64 - ctx.f5.f64));
	// fadds f0,f5,f0
	ctx.f0.f64 = double(float(ctx.f5.f64 + ctx.f0.f64));
	// stfs f4,0(r10)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,248(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,144(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// fsubs f0,f30,f6
	ctx.f0.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,20(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,256(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	// stfs f28,0(r10)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,264(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// stfs f27,0(r10)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,272(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// stfs f26,0(r10)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,280(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// stfs f25,0(r10)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,288(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	// stfs f24,0(r10)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,296(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// stfs f9,0(r10)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,304(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// stfs f7,0(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,312(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	// stfs f13,0(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,-26212(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82c9adb4
	if (!ctx.cr0.eq) goto loc_82C9ADB4;
loc_82C9C450:
	// addi r1,r1,624
	ctx.r1.s64 = ctx.r1.s64 + 624;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82C9C45C;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9C460"))) PPC_WEAK_FUNC(sub_82C9C460);
PPC_FUNC_IMPL(__imp__sub_82C9C460) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28624
	ctx.r5.s64 = ctx.r11.s64 + -28624;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,-21176
	ctx.r4.s64 = ctx.r11.s64 + -21176;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9C478"))) PPC_WEAK_FUNC(sub_82C9C478);
PPC_FUNC_IMPL(__imp__sub_82C9C478) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c49c
	ctx.lr = 0x82C9C480;
	__savegprlr_17(ctx, base);
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82d5c540
	ctx.lr = 0x82C9C488;
	__savefpr_14(ctx, base);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82c9cd40
	if (!ctx.cr6.lt) goto loc_82C9CD40;
	// rlwinm r18,r9,2,0,29
	ctx.r18.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r22,r7,r8
	ctx.r22.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// lfs f8,-29656(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29656);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,27776(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27776);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-29652(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29652);
	ctx.f10.f64 = double(temp.f32);
loc_82C9C4BC:
	// lfs f0,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r6,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r9,r6,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f13,f12
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f2,f0,f11
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f31,f13,f11
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f0,f12
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f7,f12
	ctx.f28.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f27,f7,f11
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f5,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f6,f11
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// add r21,r9,r4
	ctx.r21.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fmuls f25,f6,f12
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// add r20,r9,r3
	ctx.r20.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmuls f24,f0,f7
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f30,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f13,f6
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// lfs f29,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f0,f6
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f4,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f4.f64 = double(temp.f32);
	// fadds f14,f1,f2
	ctx.f14.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfs f14,-352(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fmuls f21,f13,f7
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f16,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f3,f31
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// lfs f15,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfs f3,-316(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f3,f1,f2
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfs f3,-332(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f3,f28,f26
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f2,f25,f27
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f1,f25,f27
	ctx.f1.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fadds f31,f26,f28
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f28,f24,f22
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f25,f22,f24
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f27,f21,f23
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fadds f26,f21,f23
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// fmuls f20,f5,f12
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f19,f5,f11
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f23,f13,f2
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f22,f0,f1
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmadds f20,f4,f11,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f20.f64));
	// fmsubs f19,f4,f12,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 - ctx.f19.f64));
	// lfs f24,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f21,f18,f24
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// fmuls f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// fmuls f24,f0,f3
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmadds f21,f17,f14,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f17,f14,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 - ctx.f18.f64));
	// fsubs f17,f24,f23
	ctx.f17.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-296(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmuls f23,f0,f2
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// fmuls f24,f13,f3
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fadds f14,f23,f24
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f14,-288(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f24,-292(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmuls f23,f13,f1
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmuls f24,f0,f31
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfs f24,-304(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmuls f24,f13,f31
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fadds f23,f22,f24
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f21,f30
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f22,-320(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f22,f29,f18
	ctx.f22.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// mulli r31,r6,48
	ctx.r31.s64 = ctx.r6.s64 * 48;
	// fmuls f21,f15,f3
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// add r23,r31,r3
	ctx.r23.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fmuls f18,f15,f2
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// mulli r7,r6,56
	ctx.r7.s64 = ctx.r6.s64 * 56;
	// fmadds f2,f16,f2,f21
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f21.f64));
	// lfsx f21,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,-328(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmsubs f3,f16,f3,f18
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f18.f64));
	// stfs f3,-308(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// lfs f15,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-324(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfsx f15,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r5,r6,24
	ctx.r5.s64 = ctx.r6.s64 * 24;
	// stfs f15,-352(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f15,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-312(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfsx f3,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f15,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// mulli r8,r6,40
	ctx.r8.s64 = ctx.r6.s64 * 40;
	// lfsx f15,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-344(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmuls f15,f3,f1
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f1,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f18,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f16,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-340(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fmuls f16,f16,f1
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// stfs f18,-336(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fmuls f18,f18,f1
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// add r19,r31,r4
	ctx.r19.u64 = ctx.r31.u64 + ctx.r4.u64;
	// mulli r31,r6,60
	ctx.r31.s64 = ctx.r6.s64 * 60;
	// mulli r30,r6,44
	ctx.r30.s64 = ctx.r6.s64 * 44;
	// lfs f1,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,-316(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fmadds f1,f3,f31,f21
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f21.f64));
	// lfs f3,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f3,f31,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 - ctx.f15.f64));
	// stfs f3,-324(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f3,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f25
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f3,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f3.f64 = double(temp.f32);
	// lfs f21,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f21.f64 = double(temp.f32);
	// lfs f31,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f21,f21,f3,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 - ctx.f18.f64));
	// fmadds f31,f31,f3,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f3.f64 + ctx.f16.f64));
	// lfs f3,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f20
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// lfs f3,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f25,f3,f25,f16
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64 + ctx.f16.f64));
	// lfs f16,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f3,f3,f27,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64 - ctx.f15.f64));
	// lfs f27,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f28
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f27,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f27,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f27.f64 = double(temp.f32);
	// stfs f28,-312(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f16,f16,f19
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f19.f64));
	// fmadds f28,f27,f19,f18
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f19,f1,f31
	ctx.f19.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f31,f18,f21
	ctx.f31.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// fadds f18,f25,f2
	ctx.f18.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fsubs f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// fmsubs f27,f27,f20,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f16.f64));
	// lfs f16,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f25,f16,f3
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f3.f64));
	// lfs f20,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f20.f64 = double(temp.f32);
	// fadds f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f16.f64));
	// fmadds f20,f20,f26,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64 + ctx.f15.f64));
	// fsubs f16,f31,f19
	ctx.f16.f64 = double(float(ctx.f31.f64 - ctx.f19.f64));
	// fadds f31,f19,f31
	ctx.f31.f64 = double(float(ctx.f19.f64 + ctx.f31.f64));
	// lfs f19,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f26,f19,f26,f15
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 - ctx.f15.f64));
	// mulli r29,r6,28
	ctx.r29.s64 = ctx.r6.s64 * 28;
	// fsubs f19,f28,f20
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// mulli r28,r6,12
	ctx.r28.s64 = ctx.r6.s64 * 12;
	// fadds f28,f20,f28
	ctx.f28.f64 = double(float(ctx.f20.f64 + ctx.f28.f64));
	// fsubs f20,f27,f26
	ctx.f20.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfsx f26,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-308(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfsx f26,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-332(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// rlwinm r27,r6,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f27,-316(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfsx f27,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// mulli r26,r6,52
	ctx.r26.s64 = ctx.r6.s64 * 52;
	// fadds f15,f20,f19
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f15,-324(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fsubs f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfs f20,-328(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfsx f20,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f27,f4
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// stfs f20,-312(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfsx f20,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r25,r6,36
	ctx.r25.s64 = ctx.r6.s64 * 36;
	// stfs f20,-344(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfsx f15,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-336(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfsx f20,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-340(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfsx f20,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-352(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f20,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-348(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfsx f20,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-300(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmuls f20,f27,f5
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f27,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f15,f27
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f27.f64));
	// fmuls f26,f26,f27
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f27,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f4,f27,f4,f20
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 + ctx.f20.f64));
	// fmsubs f5,f27,f5,f19
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f19.f64));
	// lfs f20,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f20.f64 = double(temp.f32);
	// lfs f27,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f27,f14
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// lfs f27,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f24,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f24.f64 + ctx.f15.f64));
	// lfs f15,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f26,f15,f24,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f24.f64 - ctx.f26.f64));
	// lfs f24,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// fmuls f15,f24,f7
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// stfs f24,-304(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmadds f24,f20,f23,f19
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 + ctx.f19.f64));
	// lfs f20,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f23,f20,f23,f14
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f23.f64 - ctx.f14.f64));
	// lfs f20,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f20,f12
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// lfs f20,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f6,f20,f6,f15
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f15.f64));
	// lfs f19,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f7,f20,f7,f19
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 - ctx.f19.f64));
	// fsubs f20,f4,f24
	ctx.f20.f64 = double(float(ctx.f4.f64 - ctx.f24.f64));
	// fadds f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// fsubs f24,f6,f27
	ctx.f24.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fadds f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f19,f5,f23
	ctx.f19.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// fadds f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// fsubs f27,f7,f26
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f26.f64));
	// fadds f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// fsubs f23,f4,f6
	ctx.f23.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fadds f26,f24,f19
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// fsubs f15,f20,f27
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// stfs f15,-332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fadds f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// lfs f20,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f20,f11
	ctx.f19.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f20,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f5,f7
	ctx.f15.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// fmadds f11,f20,f11,f14
	ctx.f11.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f14.f64));
	// stfs f11,-352(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f11,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f11.f64 = double(temp.f32);
	// fmsubs f12,f20,f12,f19
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 - ctx.f19.f64));
	// fsubs f14,f16,f11
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f11.f64));
	// lfs f11,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f31.f64));
	// stfs f11,-300(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmuls f19,f26,f9
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// stfs f12,-340(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f12,f30,f25
	ctx.f12.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// mulli r24,r6,20
	ctx.r24.s64 = ctx.r6.s64 * 20;
	// fadds f11,f2,f22
	ctx.f11.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// fmuls f20,f14,f10
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// lfs f14,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f10
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// stfs f14,-300(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f14,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f14,f8,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f8.f64 - ctx.f19.f64));
	// stfs f19,-336(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f19,f20,f12
	ctx.f19.f64 = double(float(ctx.f20.f64 + ctx.f12.f64));
	// stfs f19,-312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fsubs f12,f12,f20
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f20.f64));
	// stfs f12,-276(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfsx f19,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f14,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f19,-304(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f0,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f12.f64 = double(temp.f32);
	// fadds f20,f11,f12
	ctx.f20.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// stfs f20,-280(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// lfsx f11,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,-344(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfsx f11,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,-348(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfsx f20,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f11,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f11.f64 = double(temp.f32);
	// stfs f12,-284(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfsx f12,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// stfs f20,-300(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fmuls f11,f12,f11
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// stfs f11,-292(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmr f11,f0
	ctx.f11.f64 = ctx.f0.f64;
	// fmadds f0,f12,f11,f20
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f20.f64));
	// lfs f12,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f12.f64 = double(temp.f32);
	// lfs f20,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f12,f12,f11,f20
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f20.f64));
	// lfs f11,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f20,f11,f17
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// lfs f11,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f17,f11,f17
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// lfs f11,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f11,f11,f13,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f13,f14,f13,f19
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 - ctx.f19.f64));
	// lfs f14,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f14,f19,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 + ctx.f20.f64));
	// lfs f14,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f14,f19,f17
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 - ctx.f17.f64));
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f13.f64));
	// stfs f14,-344(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f11.f64));
	// fadds f11,f11,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f14.f64));
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f13,f13,f14
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f14.f64));
	// fsubs f14,f20,f0
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f0.f64));
	// fadds f0,f20,f0
	ctx.f0.f64 = double(float(ctx.f20.f64 + ctx.f0.f64));
	// fsubs f20,f19,f12
	ctx.f20.f64 = double(float(ctx.f19.f64 - ctx.f12.f64));
	// fadds f12,f19,f12
	ctx.f12.f64 = double(float(ctx.f19.f64 + ctx.f12.f64));
	// lfs f19,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,-340(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f19,f17,f20
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f19,-288(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// lfs f19,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f19.f64 = double(temp.f32);
	// stfs f20,-344(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// fsubs f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 - ctx.f2.f64));
	// lfs f20,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f20,f8
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// stfs f26,-288(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmuls f14,f20,f9
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// lfs f20,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f26,f11,f0
	ctx.f26.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// fmadds f20,f20,f9,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 + ctx.f17.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f17,-292(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,-296(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fsubs f20,f13,f12
	ctx.f20.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f17,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// fadds f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// stfs f20,-304(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fsubs f20,f23,f15
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfs f20,-300(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fsubs f20,f13,f12
	ctx.f20.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// lfs f15,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// lfs f20,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f20,f20,f8,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f14,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f9,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64 + ctx.f14.f64));
	// stfs f15,-332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f15,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f19,f8
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// fadds f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f31.f64));
	// lfs f31,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f31.f64 = double(temp.f32);
	// fadds f16,f31,f16
	ctx.f16.f64 = double(float(ctx.f31.f64 + ctx.f16.f64));
	// fmuls f31,f24,f8
	ctx.f31.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// stfs f31,-288(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fadds f31,f25,f30
	ctx.f31.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// fmuls f30,f15,f10
	ctx.f30.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// stfs f30,-324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fmuls f30,f16,f10
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// stfs f30,-328(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f30,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f30.f64 = double(temp.f32);
	// lfs f25,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f22,f30,f25
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// stfsx f22,r30,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f16,f25,f30
	ctx.f16.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// lfs f30,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f9,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f14.f64));
	// stfs f30,-308(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f30,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f30.f64 = double(temp.f32);
	// lfs f25,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f15,f30,f25
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// fadds f14,f25,f30
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// lfs f25,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f25.f64 = double(temp.f32);
	// lfs f30,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f30,f27,f9,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f30.f64));
	// stfs f30,-336(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f30,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f30.f64 = double(temp.f32);
	// fadds f22,f25,f30
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// fsubs f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f30.f64));
	// stfs f30,-292(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fadds f25,f23,f26
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// lfs f23,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f30,f21,f23
	ctx.f30.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfs f30,-284(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// stfs f26,-288(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f26,f28,f1
	ctx.f26.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fadds f30,f30,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// stfs f30,-296(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f30,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// stfs f30,-304(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// stfs f25,-284(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fsubs f30,f29,f3
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// fmuls f23,f22,f10
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// stfs f23,-300(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f17,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f28,f1
	ctx.f23.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fadds f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f31.f64));
	// addic. r22,r22,-1
	ctx.xer.ca = ctx.r22.u32 > 0;
	ctx.r22.s64 = ctx.r22.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// fsubs f25,f29,f3
	ctx.f25.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// fmuls f27,f27,f8
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fadds f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fadds f11,f6,f4
	ctx.f11.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// lfs f26,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// stfs f26,-340(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f26,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// lfs f20,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fmuls f20,f20,f10
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// lfs f22,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f22.f64 = double(temp.f32);
	// stfs f17,-284(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fmuls f23,f22,f10
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f17,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f31,f31,f17
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f17.f64));
	// lfs f17,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f2,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 + ctx.f17.f64));
	// stfs f17,-312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f17,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// stfs f2,-292(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f2,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// lfs f22,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f22.f64 = double(temp.f32);
	// stfs f17,-288(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmuls f22,f22,f10
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f2,f17,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 - ctx.f2.f64));
	// stfs f2,-308(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f2,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f2,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// stfsx f17,r30,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f16,r28,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f17,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// stfsx f2,r28,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f2,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f17,f2,f26
	ctx.f17.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// stfsx f17,r31,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f17,f26,f2
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// stfsx f15,r31,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f2,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f2.f64 = double(temp.f32);
	// lfs f26,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f17,r29,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fsubs f16,f2,f26
	ctx.f16.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// stfsx f14,r29,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fadds f26,f26,f2
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// stfsx f16,r8,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fsubs f17,f30,f23
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f23.f64));
	// stfsx f17,r8,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// lfs f2,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f2.f64 = double(temp.f32);
	// stfsx f26,r9,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f23,f2,f22
	ctx.f23.f64 = double(float(ctx.f2.f64 - ctx.f22.f64));
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f26,f25,f20
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// stfsx f23,r7,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// stfsx f26,r7,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f30,f20,f25
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfsx f2,r5,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// lfs f2,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f2.f64 = double(temp.f32);
	// stfsx f30,r5,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fmuls f30,f2,f8
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f2,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f18,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 + ctx.f2.f64));
	// fadds f4,f3,f29
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// lfs f6,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f6.f64 = double(temp.f32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fadds f12,f7,f5
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// lfs f5,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f3,f19,f9,f30
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 - ctx.f30.f64));
	// lfs f30,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f30.f64 = double(temp.f32);
	// fadds f6,f6,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f21.f64));
	// fsubs f29,f5,f30
	ctx.f29.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// stfsx f29,r25,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f29,f30,f5
	ctx.f29.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// lfs f5,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f5.f64 = double(temp.f32);
	// lfs f30,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f7,f24,f9,f27
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f27.f64));
	// fsubs f28,f5,f30
	ctx.f28.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// fadds f27,f30,f5
	ctx.f27.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// fadds f5,f1,f2
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// fadds f1,f11,f0
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fsubs f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// fadds f11,f4,f6
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fadds f4,f12,f13
	ctx.f4.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fadds f30,f7,f3
	ctx.f30.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fsubs f12,f5,f1
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f3,f6,f0
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f0.f64));
	// fadds f6,f0,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 + ctx.f6.f64));
	// lfs f0,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f26,f0,f30
	ctx.f26.f64 = double(float(ctx.f0.f64 - ctx.f30.f64));
	// stfsx f26,r25,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// stfsx f29,r27,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f30,f0
	ctx.f0.f64 = double(float(ctx.f30.f64 + ctx.f0.f64));
	// stfsx f0,r27,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f31,f7
	ctx.f0.f64 = double(float(ctx.f31.f64 - ctx.f7.f64));
	// stfsx f0,r26,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f0,f7,f31
	ctx.f0.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// stfsx f28,r26,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fsubs f1,f11,f4
	ctx.f1.f64 = double(float(ctx.f11.f64 - ctx.f4.f64));
	// stfsx f0,r24,r3
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f11,f4,f11
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// stfsx f27,r24,r4
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// fsubs f0,f2,f13
	ctx.f0.f64 = double(float(ctx.f2.f64 - ctx.f13.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f13,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f2.f64));
	// stfsx f1,r10,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfs f5,0(r3)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// add r3,r18,r3
	ctx.r3.u64 = ctx.r18.u64 + ctx.r3.u64;
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// add r4,r18,r4
	ctx.r4.u64 = ctx.r18.u64 + ctx.r4.u64;
	// stfs f0,0(r23)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// stfs f3,0(r19)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// stfs f13,0(r20)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// stfs f6,0(r21)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// lwz r10,-26212(r17)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r17.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82c9c4bc
	if (!ctx.cr0.eq) goto loc_82C9C4BC;
loc_82C9CD40:
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82d5c58c
	ctx.lr = 0x82C9CD48;
	__restfpr_14(ctx, base);
	// b 0x82d5c4ec
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9CD50"))) PPC_WEAK_FUNC(sub_82C9CD50);
PPC_FUNC_IMPL(__imp__sub_82C9CD50) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28536
	ctx.r5.s64 = ctx.r11.s64 + -28536;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,-15240
	ctx.r4.s64 = ctx.r11.s64 + -15240;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9CD68"))) PPC_WEAK_FUNC(sub_82C9CD68);
PPC_FUNC_IMPL(__imp__sub_82C9CD68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b4
	ctx.lr = 0x82C9CD70;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c554
	ctx.lr = 0x82C9CD78;
	__savefpr_19(ctx, base);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82c9d01c
	if (!ctx.cr6.lt) goto loc_82C9D01C;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f6,-29652(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29652);
	ctx.f6.f64 = double(temp.f32);
loc_82C9CD9C:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// mulli r8,r6,28
	ctx.r8.s64 = ctx.r6.s64 * 28;
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f10,f0
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f10,f13
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f3,f9,f13
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f9,f0
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f5,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f31,f12,f13
	ctx.f31.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f4,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// mulli r5,r6,12
	ctx.r5.s64 = ctx.r6.s64 * 12;
	// lfsx f30,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f26,f8,f3
	ctx.f26.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// lfsx f29,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f25,f2,f7
	ctx.f25.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// add r31,r8,r3
	ctx.r31.u64 = ctx.r8.u64 + ctx.r3.u64;
	// fadds f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// add r29,r5,r3
	ctx.r29.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fsubs f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// add r30,r8,r4
	ctx.r30.u64 = ctx.r8.u64 + ctx.r4.u64;
	// fmadds f1,f11,f13,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f1.f64));
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmsubs f31,f11,f0,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f31.f64));
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r27,r6,20
	ctx.r27.s64 = ctx.r6.s64 * 20;
	// lfs f28,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f3,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f28,f12
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f24,f30,f26
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// lfs f27,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f2,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f28,f28,f11
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmuls f22,f3,f10
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f21,f3,f9
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// rlwinm r28,r6,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r8,r6,24
	ctx.r8.s64 = ctx.r6.s64 * 24;
	// fmadds f3,f29,f25,f24
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f25.f64 + ctx.f24.f64));
	// fmsubs f30,f29,f26,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f26.f64 - ctx.f30.f64));
	// fmsubs f28,f27,f12,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 - ctx.f28.f64));
	// fmadds f29,f27,f11,f23
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f23.f64));
	// fmadds f9,f2,f9,f22
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f22.f64));
	// add r25,r27,r3
	ctx.r25.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fmuls f26,f12,f7
	ctx.f26.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// add r26,r28,r3
	ctx.r26.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fmuls f27,f12,f8
	ctx.f27.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// add r27,r27,r4
	ctx.r27.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fmsubs f12,f2,f10,f21
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 - ctx.f21.f64));
	// add r28,r28,r4
	ctx.r28.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fadds f2,f3,f5
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfs f23,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// lfs f25,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f3,f4,f30
	ctx.f3.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// lfs f22,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// lfs f24,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fadds f30,f9,f29
	ctx.f30.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// fsubs f9,f29,f9
	ctx.f9.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// fmsubs f10,f11,f8,f26
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 - ctx.f26.f64));
	// lfsx f26,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f29,f12,f28
	ctx.f29.f64 = double(float(ctx.f12.f64 + ctx.f28.f64));
	// fsubs f12,f28,f12
	ctx.f12.f64 = double(float(ctx.f28.f64 - ctx.f12.f64));
	// lfsx f28,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f21,f28,f8
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmuls f20,f28,f7
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// lfsx f28,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f11,f11,f7,f27
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfsx f27,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f7,f28,f7,f21
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f7.f64 + ctx.f21.f64));
	// fmsubs f8,f28,f8,f20
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f8.f64 - ctx.f20.f64));
	// fmuls f28,f27,f1
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f21,f25,f0
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f20,f22,f10
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// fmuls f19,f23,f10
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// fmadds f10,f26,f31,f28
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f31.f64 + ctx.f28.f64));
	// fmadds f31,f23,f11,f20
	ctx.f31.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f20.f64));
	// fmadds f13,f24,f13,f21
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f21.f64));
	// fmsubs f1,f26,f1,f27
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 - ctx.f27.f64));
	// fmsubs f0,f24,f0,f25
	ctx.f0.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fmsubs f11,f22,f11,f19
	ctx.f11.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f19.f64));
	// fadds f28,f10,f7
	ctx.f28.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// fsubs f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fadds f7,f31,f13
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f13.f64));
	// fadds f27,f1,f8
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// fsubs f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// fsubs f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f31.f64));
	// fadds f1,f11,f0
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fsubs f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// fadds f11,f28,f2
	ctx.f11.f64 = double(float(ctx.f28.f64 + ctx.f2.f64));
	// fsubs f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// fadds f28,f7,f30
	ctx.f28.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// fadds f31,f27,f4
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// fsubs f7,f30,f7
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f7.f64));
	// fsubs f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f27.f64));
	// fadds f30,f1,f29
	ctx.f30.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// fsubs f1,f1,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// fsubs f29,f11,f28
	ctx.f29.f64 = double(float(ctx.f11.f64 - ctx.f28.f64));
	// stfsx f29,r10,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f11,f28,f11
	ctx.f11.f64 = double(float(ctx.f28.f64 + ctx.f11.f64));
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f11,f4,f7
	ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// fsubs f4,f4,f7
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f7.f64));
	// fadds f7,f31,f30
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f30.f64));
	// stfs f7,0(r4)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f7,f31,f30
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// stfsx f7,r10,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f2,f1
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfsx f7,r8,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f1,f2
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfsx f7,r9,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// fadds f7,f12,f9
	ctx.f7.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// stfsx f4,r8,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fsubs f13,f9,f12
	ctx.f13.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fsubs f12,f5,f8
	ctx.f12.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// fadds f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fsubs f9,f3,f10
	ctx.f9.f64 = double(float(ctx.f3.f64 - ctx.f10.f64));
	// fadds f10,f10,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f3.f64));
	// fsubs f5,f11,f7
	ctx.f5.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fadds f7,f13,f0
	ctx.f7.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// fsubs f4,f13,f0
	ctx.f4.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// fmuls f0,f5,f6
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f13,f11,f6
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmuls f11,f7,f6
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmuls f7,f4,f6
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// fsubs f5,f12,f0
	ctx.f5.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// stfs f5,0(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fsubs f5,f9,f13
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// stfs f5,0(r27)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f0,f13,f9
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// stfs f0,0(r28)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fsubs f0,f8,f11
	ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// stfs f0,0(r25)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f0,f10,f7
	ctx.f0.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fadds f0,f11,f8
	ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// stfs f0,0(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fadds f0,f7,f10
	ctx.f0.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r10,-26212(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82c9cd9c
	if (!ctx.cr0.eq) goto loc_82C9CD9C;
loc_82C9D01C:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c5a0
	ctx.lr = 0x82C9D024;
	__restfpr_19(ctx, base);
	// b 0x82d5c504
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9D028"))) PPC_WEAK_FUNC(sub_82C9D028);
PPC_FUNC_IMPL(__imp__sub_82C9D028) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28456
	ctx.r5.s64 = ctx.r11.s64 + -28456;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,-12952
	ctx.r4.s64 = ctx.r11.s64 + -12952;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9D040"))) PPC_WEAK_FUNC(sub_82C9D040);
PPC_FUNC_IMPL(__imp__sub_82C9D040) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82C9D048;
	__savegprlr_29(ctx, base);
	// stfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f29.u64);
	// stfd f30,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f31.u64);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82c9d174
	if (!ctx.cr6.lt) goto loc_82C9D174;
	// rlwinm r30,r9,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
loc_82C9D070:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// fmuls f8,f12,f0
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f3,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r31,r7,r3
	ctx.r31.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r5,r9,r3
	ctx.r5.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmadds f8,f11,f13,f8
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f8.f64));
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// fmsubs f7,f11,f0,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f7.f64));
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f29,f2,f12
	ctx.f29.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f30,f4,f0
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f1,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f31,f6,f8
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f6,f6,f7
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmadds f11,f1,f11,f29
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f29.f64));
	// fmadds f13,f3,f13,f30
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f30.f64));
	// fmsubs f12,f1,f12,f2
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 - ctx.f2.f64));
	// fmsubs f0,f3,f0,f4
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f4.f64));
	// fmadds f7,f5,f7,f31
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f31.f64));
	// fmsubs f8,f5,f8,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 - ctx.f6.f64));
	// fadds f6,f7,f10
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fsubs f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f7,f11,f13
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fadds f11,f8,f9
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f8,f12,f0
	ctx.f8.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fsubs f12,f6,f7
	ctx.f12.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// stfsx f12,r10,r3
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f12,f7,f6
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fsubs f12,f9,f13
	ctx.f12.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
	// fadds f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// fadds f9,f11,f8
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// stfs f9,0(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// stfsx f11,r10,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f10,f0
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f0.f64));
	// stfs f11,0(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f10.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfsx f12,r9,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// stfs f13,0(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lwz r10,-26212(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82c9d070
	if (!ctx.cr0.eq) goto loc_82C9D070;
loc_82C9D174:
	// lfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f30,-48(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9D188"))) PPC_WEAK_FUNC(sub_82C9D188);
PPC_FUNC_IMPL(__imp__sub_82C9D188) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28376
	ctx.r5.s64 = ctx.r11.s64 + -28376;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,-12224
	ctx.r4.s64 = ctx.r11.s64 + -12224;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9D1A0"))) PPC_WEAK_FUNC(sub_82C9D1A0);
PPC_FUNC_IMPL(__imp__sub_82C9D1A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82C9D1A8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82C9D1B0;
	__savefpr_14(ctx, base);
	// stwu r1,-928(r1)
	ea = -928 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mulli r11,r7,504
	ctx.r11.s64 = ctx.r7.s64 * 504;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82ca0aec
	if (!ctx.cr6.lt) goto loc_82CA0AEC;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r22,-32235
	ctx.r22.s64 = -2112552960;
	// lis r23,-32235
	ctx.r23.s64 = -2112552960;
	// lis r24,-32235
	ctx.r24.s64 = -2112552960;
	// lis r25,-32235
	ctx.r25.s64 = -2112552960;
	// stw r10,628(r1)
	PPC_STORE_U32(ctx.r1.u32 + 628, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r26,-32235
	ctx.r26.s64 = -2112552960;
	// lfs f31,30356(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 30356);
	ctx.f31.f64 = double(temp.f32);
	// lis r27,-32235
	ctx.r27.s64 = -2112552960;
	// lfs f1,30352(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 30352);
	ctx.f1.f64 = double(temp.f32);
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// lfs f2,30344(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 30344);
	ctx.f2.f64 = double(temp.f32);
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// lfs f3,30348(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 30348);
	ctx.f3.f64 = double(temp.f32);
	// stw r10,384(r1)
	PPC_STORE_U32(ctx.r1.u32 + 384, ctx.r10.u32);
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lfs f4,30360(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 30360);
	ctx.f4.f64 = double(temp.f32);
	// lis r5,-32235
	ctx.r5.s64 = -2112552960;
	// lfs f5,30364(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 30364);
	ctx.f5.f64 = double(temp.f32);
	// lis r7,-32235
	ctx.r7.s64 = -2112552960;
	// lfs f6,30372(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 30372);
	ctx.f6.f64 = double(temp.f32);
	// lis r8,-32235
	ctx.r8.s64 = -2112552960;
	// lfs f7,30368(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 30368);
	ctx.f7.f64 = double(temp.f32);
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// lfs f8,27792(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 27792);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f9,27788(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 27788);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,27780(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 27780);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,27784(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 27784);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,27776(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 27776);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-29656(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29656);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29652(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82C9D24C:
	// mulli r8,r6,192
	ctx.r8.s64 = ctx.r6.s64 * 192;
	// lfs f30,248(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 248);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r7,r6,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f29,252(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 252);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,376(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 376);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f16,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f25,380(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 380);
	ctx.f25.f64 = double(temp.f32);
	// rlwinm r9,r6,6,0,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f22,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// mulli r5,r6,160
	ctx.r5.s64 = ctx.r6.s64 * 160;
	// lfs f21,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f16,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f17,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r10,r6,7,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 7) & 0xFFFFFF80;
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r31,r6,224
	ctx.r31.s64 = ctx.r6.s64 * 224;
	// lfsx f16,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f18,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f28,f18
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfsx f17,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f20,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f16,f30,f20
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// lfsx f19,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f29,f20
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f20.f64));
	// fmuls f14,f26,f17
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// mulli r30,r6,96
	ctx.r30.s64 = ctx.r6.s64 * 96;
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// fmadds f29,f29,f19,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64 + ctx.f16.f64));
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmsubs f30,f30,f19,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f19.f64 - ctx.f20.f64));
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f21,f19
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// fmadds f27,f27,f20,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 + ctx.f15.f64));
	// fmsubs f28,f28,f20,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f20.f64 - ctx.f18.f64));
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f25,f25,f20,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f20.f64 + ctx.f14.f64));
	// lfs f18,440(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 440);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f26,f26,f20,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 - ctx.f17.f64));
	// lfs f20,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,444(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 444);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f21,f21,f20,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f16.f64));
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f20.f64 - ctx.f19.f64));
	// fadds f20,f29,f24
	ctx.f20.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// fadds f24,f25,f27
	ctx.f24.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fsubs f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fsubs f19,f23,f30
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f30.f64));
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fadds f30,f30,f23
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f23.f64));
	// fadds f26,f24,f20
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// fsubs f20,f29,f25
	ctx.f20.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fadds f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fsubs f23,f19,f27
	ctx.f23.f64 = double(float(ctx.f19.f64 - ctx.f27.f64));
	// fadds f25,f30,f28
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fadds f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// lfs f19,316(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 316);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f28,312(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 312);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f16
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// fmuls f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f16,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,92(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f28,f28,f16,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f19,f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f15.f64));
	// fmuls f16,f18,f28
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// stfs f19,72(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmuls f15,f17,f28
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// lfs f28,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f28.f64 = double(temp.f32);
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fmr f28,f19
	ctx.f28.f64 = ctx.f19.f64;
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f17,f17,f28,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 + ctx.f16.f64));
	// lfs f16,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f28,f18,f28,f15
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,20(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f28,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f19
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f19,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f18,f19,f16,f14
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f19,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f19,f16,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f21,f16
	ctx.f16.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f16,92(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f19,f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f28,f28,f16,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 - ctx.f14.f64));
	// fsubs f16,f17,f18
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fadds f14,f18,f21
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fadds f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f16,176(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f22,f14
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// mulli r28,r6,144
	ctx.r28.s64 = ctx.r6.s64 * 144;
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,340(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f22,f16,f0
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f22,332(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmuls f22,f17,f0
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f16,280(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 280);
	ctx.f16.f64 = double(temp.f32);
	// mulli r27,r6,80
	ctx.r27.s64 = ctx.r6.s64 * 80;
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfsx f17,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f18,464(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// lfsx f18,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f16,f18
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f18.f64));
	// stfs f22,592(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// lfs f22,284(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 284);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r26,r6,208
	ctx.r26.s64 = ctx.r6.s64 * 208;
	// lfsx f17,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// lfsx f14,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r25,r6,240
	ctx.r25.s64 = ctx.r6.s64 * 240;
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fmuls f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f18,f17
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f22,f18,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f16.f64));
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f18,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f22,408(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 408);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f22,412(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 412);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f18,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f15,f18,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,412(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 412);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,408(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 408);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// lfs f14,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// fsubs f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// fsubs f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fsubs f15,f28,f18
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fsubs f15,f19,f22
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f22,236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f28,284(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmuls f22,f14,f12
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// fmuls f19,f14,f13
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f28,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,276(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmuls f18,f17,f13
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f28,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f16,f13
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// mulli r24,r6,112
	ctx.r24.s64 = ctx.r6.s64 * 112;
	// fadds f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f28,232(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// mulli r23,r6,48
	ctx.r23.s64 = ctx.r6.s64 * 48;
	// fmsubs f22,f28,f13,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f22.f64));
	// stfs f22,480(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f22,472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 472);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f12,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f19.f64));
	// stfs f28,472(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// lfs f19,476(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 476);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f28,f16,f12,f18
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f18.f64));
	// stfs f28,468(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fmadds f28,f17,f12,f14
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f28,452(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// lfsx f28,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f22,f28
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// lfs f18,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f19,f28
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// lfsx f28,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f28,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r22,r6,176
	ctx.r22.s64 = ctx.r6.s64 * 176;
	// stfs f28,20(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f28,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,48(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f28,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,32(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f28,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,68(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f28,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,56(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f28,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,128(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f17,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f19,f19,f28,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 + ctx.f15.f64));
	// stfs f19,148(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmsubs f28,f22,f28,f14
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 - ctx.f14.f64));
	// stfs f28,92(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f19,f18,f28
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// fmuls f15,f17,f28
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// lfs f28,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f14,f16,f22
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f22.f64));
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fmr f28,f22
	ctx.f28.f64 = ctx.f22.f64;
	// fmadds f22,f17,f28,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 + ctx.f19.f64));
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmsubs f28,f18,f28,f15
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,72(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f28,344(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 344);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 348);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// fmuls f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 348);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f14.f64));
	// fmadds f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f15.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f16,f19,f14
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f28,f28,f17,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// rlwinm r21,r6,3,0,28
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// mulli r19,r6,72
	ctx.r19.s64 = ctx.r6.s64 * 72;
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// mulli r18,r6,200
	ctx.r18.s64 = ctx.r6.s64 * 200;
	// fsubs f18,f19,f28
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// fadds f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// mulli r17,r6,40
	ctx.r17.s64 = ctx.r6.s64 * 40;
	// fadds f19,f14,f16
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// fsubs f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// mulli r20,r6,136
	ctx.r20.s64 = ctx.r6.s64 * 136;
	// fmuls f17,f19,f13
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f14,228(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fadds f14,f28,f15
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// stfs f14,224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f14,f19,f12
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// fsubs f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// fmuls f15,f18,f13
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f17,f19,f12,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f17,552(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// fmsubs f19,f19,f13,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f19,608(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// fmuls f14,f16,f13
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f17,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f16,460(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfsx f16,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f16,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f16,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,128(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfsx f16,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fmsubs f18,f18,f12,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f18,444(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fadds f18,f28,f22
	ctx.f18.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// lfsx f16,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// lfsx f22,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f28,352(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfsx f28,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f19,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f19.f64 = double(temp.f32);
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmuls f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmuls f16,f19,f28
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// lfsx f22,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f28,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f28.f64 = double(temp.f32);
	// stfs f18,240(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fmuls f14,f28,f22
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfsx f18,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// stfs f28,68(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f28,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmr f28,f22
	ctx.f28.f64 = ctx.f22.f64;
	// lfs f18,396(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 396);
	ctx.f18.f64 = double(temp.f32);
	// mulli r16,r6,168
	ctx.r16.s64 = ctx.r6.s64 * 168;
	// mulli r15,r6,232
	ctx.r15.s64 = ctx.r6.s64 * 232;
	// fmadds f22,f19,f28,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 + ctx.f17.f64));
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f28,f22,f28,f16
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 - ctx.f16.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f19,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f19.f64 = double(temp.f32);
	// lfs f28,268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f19,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64 + ctx.f15.f64));
	// stfs f28,24(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f28,392(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 392);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,104
	ctx.r14.s64 = ctx.r6.s64 * 104;
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f22,264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,396(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 396);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f28,f16,f15
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f15,f28
	ctx.f28.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f28,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f28,f17,f19
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f28,20(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f28,328(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 328);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,92(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f28,456(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 456);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,136(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f28,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f28,f15
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f15.f64));
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fsubs f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f22,304(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fadds f22,f16,f18
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// stfs f22,324(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f22,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f19,600(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f19.f64));
	// stfs f19,456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f14.f64));
	// stfs f22,132(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfsx f22,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f28,f28,f19,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64 - ctx.f17.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f28,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f19,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f28,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,32(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,20(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f28,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,48(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f28,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f22
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f28,332(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 332);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f22,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f19
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f22,460(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 460);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f22,f19
	ctx.f19.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f22,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f17.f64));
	// stfs f28,72(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f28,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f22,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfs f28,56(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f28,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f28,f22
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f28,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,460(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 460);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f22,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f14.f64));
	// fmsubs f22,f15,f22,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f22.f64 - ctx.f19.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f15,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64 + ctx.f17.f64));
	// lfs f17,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f17,f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,136(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fsubs f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// fadds f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// fsubs f19,f22,f17
	ctx.f19.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f19,92(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,44(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f19,f28,f15
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// stfs f19,88(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f17,132(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f22,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,104(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f19,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f19,f22,f19
	ctx.f19.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// lfs f22,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,120(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,120
	ctx.r14.s64 = ctx.r6.s64 * 120;
	// lfs f22,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,192(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f22,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// stfs f19,408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// stw r14,516(r1)
	PPC_STORE_U32(ctx.r1.u32 + 516, ctx.r14.u32);
	// lfs f19,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,24
	ctx.r14.s64 = ctx.r6.s64 * 24;
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f17,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f17.f64 = double(temp.f32);
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// stw r14,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r14.u32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f16,f18
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,248
	ctx.r14.s64 = ctx.r6.s64 * 248;
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// lfs f15,364(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 364);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// lfs f17,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,624(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f22,f16
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f19,f16
	ctx.f16.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// stfs f16,356(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fadds f19,f16,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f19,40(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f19,f28,f18
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f19,520(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f28,544(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f28,f14,f0
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f28,416(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f28,f22,f0
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f28,512(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,516(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,56
	ctx.r14.s64 = ctx.r6.s64 * 56;
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,184
	ctx.r14.s64 = ctx.r6.s64 * 184;
	// stfs f18,128(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,148(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f18,488(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 488);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f18,f28
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f18,492(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 492);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f28,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,56(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f22,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f16.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,152
	ctx.r14.s64 = ctx.r6.s64 * 152;
	// fmsubs f28,f28,f22,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 - ctx.f18.f64));
	// stfs f28,172(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f22
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f17,f22
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f22.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// stw r14,568(r1)
	PPC_STORE_U32(ctx.r1.u32 + 568, ctx.r14.u32);
	// lfs f28,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,92(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fmadds f28,f28,f22,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f14.f64));
	// fmsubs f22,f18,f22,f19
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,360(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 360);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f19
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f18,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f15,f19
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fmadds f22,f17,f18,f16
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 + ctx.f16.f64));
	// lfs f19,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,360(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 360);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f19,f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f18,f15,f16,f14
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f17,f16,f14
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,132(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f16,f18,f22
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fadds f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// lfs f18,300(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 300);
	ctx.f18.f64 = double(temp.f32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f15,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,296(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fsubs f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f14,424(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 424);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,208(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f16,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// lfs f16,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f16,f22,f15
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f16,424(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f22,508(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,568(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// mulli r14,r6,216
	ctx.r14.s64 = ctx.r6.s64 * 216;
	// fmuls f15,f18,f17
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,88
	ctx.r14.s64 = ctx.r6.s64 * 88;
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,48(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f22,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f14.f64));
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f16,f22,f14
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,108(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f17
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// lfs f22,428(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f18,f18,f22,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 + ctx.f16.f64));
	// stfs f18,96(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f18,f22,f15
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f22,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f22,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,428(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f18,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f14.f64));
	// fmsubs f18,f15,f18,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,136(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f17,f16,f18
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,220(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,328(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fsubs f17,f22,f18
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,252(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,124
	ctx.r14.s64 = ctx.r6.s64 * 124;
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,296(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f16,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// stfs f17,292(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// stw r14,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r14.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,252
	ctx.r14.s64 = ctx.r6.s64 * 252;
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f18,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f17,152(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f17,496(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 496);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f28,48(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f28,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// stfs f28,56(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f22,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f28,f19
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// fadds f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f14,f16,f28
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// fadds f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f16,348(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f22,264(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f22,f18,f0
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f22,576(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// fmuls f22,f19,f0
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f22,364(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// stfs f28,380(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fmuls f22,f14,f0
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f22,432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f19,f28,f22
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f19,528(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,484(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,180(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,60
	ctx.r14.s64 = ctx.r6.s64 * 60;
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,188
	ctx.r14.s64 = ctx.r6.s64 * 188;
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,500(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 500);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f17,f28
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f28,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,28
	ctx.r14.s64 = ctx.r6.s64 * 28;
	// fmuls f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f28,f19,f22,f16
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f16.f64));
	// fmsubs f22,f17,f22,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 - ctx.f18.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f18,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 + ctx.f14.f64));
	// stfs f22,132(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f19,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f15,f19
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// fmuls f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f19,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f14.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,368(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 368);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f18,372(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 372);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fmr f19,f18
	ctx.f19.f64 = ctx.f18.f64;
	// lfs f18,372(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 372);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f17.f64));
	// fmsubs f17,f15,f19,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f19.f64 - ctx.f16.f64));
	// lfs f19,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f16,f18,f19,f14
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 + ctx.f14.f64));
	// lfs f18,368(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 368);
	ctx.f18.f64 = double(temp.f32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// stfs f17,172(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fadds f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f18,f19,f14
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfs f19,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// stfs f19,136(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f15,212(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f18,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,304(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// stfs f18,24(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,432(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,108(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f16,156(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,156
	ctx.r14.s64 = ctx.r6.s64 * 156;
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,220
	ctx.r14.s64 = ctx.r6.s64 * 220;
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,92
	ctx.r14.s64 = ctx.r6.s64 * 92;
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,56(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f15,f18,f19
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// stfs f16,128(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f19
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f19.f64));
	// lfs f19,308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 308);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f18,f18,f19,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 + ctx.f16.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f19,f18,f19,f15
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,148(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f18
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f19,436(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 436);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f18
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 308);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f14.f64));
	// stfs f19,96(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f17.f64));
	// stfs f19,24(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f19,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f19,f18
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f19,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,436(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 436);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f16.f64));
	// lfs f16,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f18,f17,f18,f15
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,52(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fadds f14,f17,f19
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// fadds f17,f16,f18
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f14,160(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,200(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,168(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// mulli r14,r6,132
	ctx.r14.s64 = ctx.r6.s64 * 132;
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stw r14,496(r1)
	PPC_STORE_U32(ctx.r1.u32 + 496, ctx.r14.u32);
	// rlwinm r14,r6,2,0,29
	ctx.r14.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f14,f18,f19
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f16,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,56(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,140(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f17,f19,f18
	ctx.f17.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f28,f18
	ctx.f18.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f18,560(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f28,620(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// lfs f28,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f18,f15,f28
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fadds f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// stfs f28,196(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fmuls f28,f14,f0
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f28,488(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f28,f22,f0
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f28,268(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f28,f17,f0
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f28,396(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// fmuls f28,f19,f0
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f28,612(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f28.f64 = double(temp.f32);
	// fadds f19,f22,f28
	ctx.f19.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f19,388(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,344(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,496(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// mulli r14,r6,68
	ctx.r14.s64 = ctx.r6.s64 * 68;
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f16,f28
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,196
	ctx.r14.s64 = ctx.r6.s64 * 196;
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// stfs f18,20(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,128(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfsx f17,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r14,r6,164
	ctx.r14.s64 = ctx.r6.s64 * 164;
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// lfs f28,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// stfs f28,48(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f28,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f28.f64 = double(temp.f32);
	// stw r14,400(r1)
	PPC_STORE_U32(ctx.r1.u32 + 400, ctx.r14.u32);
	// fmuls f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// mulli r14,r6,36
	ctx.r14.s64 = ctx.r6.s64 * 36;
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f28,f19,f22,f15
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f15.f64));
	// lfs f19,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f16,f22,f17
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 - ctx.f17.f64));
	// fmuls f16,f19,f18
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 260);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f15.f64));
	// fmadds f19,f19,f17,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f14.f64));
	// stfs f18,132(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f15.f64));
	// stfs f18,136(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f18,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f16.f64));
	// stfs f18,72(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f19,f28
	ctx.f18.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// lfs f17,384(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f17,324(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 324);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f17,448(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 448);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f17,452(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 452);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f17,388(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 388);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,108(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f16,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,96(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f16,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f15,f17,f16,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f17,384(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmsubs f16,f17,f16,f14
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,44(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,400(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// mulli r14,r6,228
	ctx.r14.s64 = ctx.r6.s64 * 228;
	// stfs f18,172(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,60(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,100
	ctx.r14.s64 = ctx.r6.s64 * 100;
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,52(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f18,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,48(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f18,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f18,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f18,320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 320);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f15,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 + ctx.f17.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f18,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 - ctx.f16.f64));
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f18,f17
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f15.f64));
	// lfs f18,320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 320);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f14.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f18,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f18,f17
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f16,f14,f18,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f18.f64 + ctx.f16.f64));
	// stfs f16,60(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f18,f16,f18,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f15,f16,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 + ctx.f17.f64));
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f15,f16,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// fadds f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// mulli r14,r6,148
	ctx.r14.s64 = ctx.r6.s64 * 148;
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// stfs f28,308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f28,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f28.f64 = double(temp.f32);
	// stw r14,532(r1)
	PPC_STORE_U32(ctx.r1.u32 + 532, ctx.r14.u32);
	// mulli r14,r6,52
	ctx.r14.s64 = ctx.r6.s64 * 52;
	// fadds f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f16,256(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// stw r14,316(r1)
	PPC_STORE_U32(ctx.r1.u32 + 316, ctx.r14.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,180
	ctx.r14.s64 = ctx.r6.s64 * 180;
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,48(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// stw r14,320(r1)
	PPC_STORE_U32(ctx.r1.u32 + 320, ctx.r14.u32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,288(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f18,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,212(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,128(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,148(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f19,f28,f22
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fadds f15,f22,f28
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f28,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f14,f16,f28
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// fadds f16,f28,f16
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// lfs f28,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f22,f28,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,144(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f28,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f22,f17,f28
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// stfs f28,132(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f28.f64 = double(temp.f32);
	// fadds f17,f22,f28
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,588(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// fmuls f28,f19,f0
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// stfs f28,448(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// fmuls f28,f15,f0
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f28,556(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 556, temp.u32);
	// fmuls f28,f14,f0
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f28,440(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fmuls f28,f16,f0
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f28,580(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,20
	ctx.r14.s64 = ctx.r6.s64 * 20;
	// lfs f22,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f19,f28,f22
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f19,100(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,112(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f19,f28,f22
	ctx.f19.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f19,616(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,548(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// lfsx f28,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,532(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// stfs f17,584(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// fmuls f15,f18,f28
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfsx f19,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// lfsx f17,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,316(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// lfsx f16,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,84
	ctx.r14.s64 = ctx.r6.s64 * 84;
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmuls f16,f16,f28
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfs f28,288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 288);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f19
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,292(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 292);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// stw r14,540(r1)
	PPC_STORE_U32(ctx.r1.u32 + 540, ctx.r14.u32);
	// lwz r14,320(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	// lfs f19,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f19.f64 = double(temp.f32);
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmadds f28,f19,f22,f15
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f15.f64));
	// fmsubs f22,f18,f22,f16
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f16.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f19,292(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 292);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f14.f64));
	// fmuls f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f18,288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 288);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f16.f64));
	// lfs f16,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f15,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 - ctx.f14.f64));
	// fadds f15,f19,f28
	ctx.f15.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// stfs f15,128(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f19.f64));
	// stfs f28,96(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f19,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,28(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f19,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fadds f28,f18,f22
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f28,148(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fsubs f28,f22,f18
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f28,352(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 352);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 356);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f18,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f15,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,540(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,212
	ctx.r14.s64 = ctx.r6.s64 * 212;
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,244
	ctx.r14.s64 = ctx.r6.s64 * 244;
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,116
	ctx.r14.s64 = ctx.r6.s64 * 116;
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfsx f14,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f14,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fmuls f14,f28,f18
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// fmuls f18,f22,f18
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// fmadds f22,f22,f15,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64 + ctx.f14.f64));
	// stfs f22,68(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fmsubs f28,f28,f15,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f15.f64 - ctx.f18.f64));
	// stfs f28,24(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f22,f28
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// fmuls f15,f19,f28
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// lfs f28,416(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 416);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f28,f22
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// lfs f28,420(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 420);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f22.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f19,f22,f18
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f18.f64));
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f19,f22,f15
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 - ctx.f15.f64));
	// stfs f22,20(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f22,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f18,f22,f19
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f19,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,420(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 420);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 + ctx.f14.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,484(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// lfs f22,416(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 416);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f22,f22,f19,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 - ctx.f14.f64));
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f22,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f22,f19
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,484(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 484);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f22,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f18.f64));
	// stfs f19,32(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f18,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f19,480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 480);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f19,f22,f15
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 - ctx.f15.f64));
	// lfs f18,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f19,f19,f18,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 + ctx.f14.f64));
	// fadds f18,f15,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,172(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f15,60(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// mulli r14,r6,12
	ctx.r14.s64 = ctx.r6.s64 * 12;
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,28(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// stfs f28,36(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,52(r1)
	PPC_STORE_U32(ctx.r1.u32 + 52, ctx.r14.u32);
	// mulli r14,r6,140
	ctx.r14.s64 = ctx.r6.s64 * 140;
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f15,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f19
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,16(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stw r14,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r14.u32);
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,48(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f19,20(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,52(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,64(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// lfs f19,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,36(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f19,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// stw r14,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r14.u32);
	// fadds f14,f14,f19
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// lwz r14,52(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	// stfs f14,308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f19,32(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f19,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// stw r14,68(r1)
	PPC_STORE_U32(ctx.r1.u32 + 68, ctx.r14.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,108(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// fadds f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f19.f64));
	// stfs f19,60(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fsubs f19,f22,f28
	ctx.f19.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// stfs f28,212(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fsubs f28,f15,f16
	ctx.f28.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f28,368(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fadds f28,f16,f15
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f28,52(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f28,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f28.f64 = double(temp.f32);
	// stw r14,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r14.u32);
	// fadds f22,f18,f28
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// lwz r14,108(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// fsubs f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f28,24(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stfs f22,16(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stw r14,56(r1)
	PPC_STORE_U32(ctx.r1.u32 + 56, ctx.r14.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f28,f13
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f18,f28,f12
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// lfs f28,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f13
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f13
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// lwz r14,128(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fadds f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfs f14,436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// lfs f14,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// stfs f28,492(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// lfs f28,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f22,f28,f12,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f22.f64));
	// stfs f22,536(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// fmsubs f28,f28,f13,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f28,312(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f28,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// fadds f22,f17,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fmadds f28,f28,f12,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f16.f64));
	// lfs f16,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f18,f19,f17
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// lfs f17,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f28,572(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f28,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f28.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f28,f28,f12,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f15.f64));
	// fmuls f15,f17,f13
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f18,32(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,280(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// stfs f28,604(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// fmuls f17,f22,f12
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f16,f22,f13
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f14,f22,f28
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// lfs f22,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// lwz r14,68(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// fmuls f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// stfs f28,16(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f22,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f22,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// lfs f19,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f19.f64 = double(temp.f32);
	// fmr f28,f19
	ctx.f28.f64 = ctx.f19.f64;
	// fmsubs f19,f28,f13,f17
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f17.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f28,f28,f12,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f28,336(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f28,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f17,392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// stfs f28,476(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f12,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f18.f64));
	// stfs f28,564(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// lfs f28,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f12,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f28,596(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// lfs f18,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f18,f28,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 + ctx.f14.f64));
	// lfs f15,272(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fmsubs f17,f17,f28,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 - ctx.f16.f64));
	// stw r14,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r14.u32);
	// mulli r14,r6,172
	ctx.r14.s64 = ctx.r6.s64 * 172;
	// lfs f28,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,52(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f28,336(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 336);
	ctx.f28.f64 = double(temp.f32);
	// stfs f28,64(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f28,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// stw r14,36(r1)
	PPC_STORE_U32(ctx.r1.u32 + 36, ctx.r14.u32);
	// mulli r14,r6,76
	ctx.r14.s64 = ctx.r6.s64 * 76;
	// stfs f28,96(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f16,276(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 276);
	ctx.f16.f64 = double(temp.f32);
	// stw r14,60(r1)
	PPC_STORE_U32(ctx.r1.u32 + 60, ctx.r14.u32);
	// mulli r14,r6,204
	ctx.r14.s64 = ctx.r6.s64 * 204;
	// stw r14,24(r1)
	PPC_STORE_U32(ctx.r1.u32 + 24, ctx.r14.u32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,420(r1)
	PPC_STORE_U32(ctx.r1.u32 + 420, ctx.r14.u32);
	// lwz r14,148(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fmuls f14,f16,f28
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// stw r14,428(r1)
	PPC_STORE_U32(ctx.r1.u32 + 428, ctx.r14.u32);
	// lwz r14,36(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,412(r1)
	PPC_STORE_U32(ctx.r1.u32 + 412, ctx.r14.u32);
	// lwz r14,36(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,368(r1)
	PPC_STORE_U32(ctx.r1.u32 + 368, ctx.r14.u32);
	// lwz r14,56(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,60(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	// fmadds f16,f16,f28,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64 + ctx.f15.f64));
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmsubs f28,f15,f28,f14
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f28.f64 - ctx.f14.f64));
	// stw r14,32(r1)
	PPC_STORE_U32(ctx.r1.u32 + 32, ctx.r14.u32);
	// lwz r14,60(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fadds f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f14,212(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fadds f14,f28,f17
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// stfs f14,108(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f28,136(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f28,f18,f16
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f28,44(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// stw r14,20(r1)
	PPC_STORE_U32(ctx.r1.u32 + 20, ctx.r14.u32);
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,24(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// stw r14,48(r1)
	PPC_STORE_U32(ctx.r1.u32 + 48, ctx.r14.u32);
	// lwz r14,24(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stw r14,16(r1)
	PPC_STORE_U32(ctx.r1.u32 + 16, ctx.r14.u32);
	// lwz r14,420(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// lfs f15,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f15.f64 = double(temp.f32);
	// lwz r14,412(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	// fmuls f16,f28,f15
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f15.f64));
	// lfs f28,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f15
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f15.f64));
	// lfs f18,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,428(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// fmuls f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// lfs f17,340(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 340);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// lfs f18,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f28,f28,f18,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f16.f64));
	// stfs f28,28(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f28,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f18,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 - ctx.f15.f64));
	// stfs f28,60(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f18,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,32(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,368(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	// fmuls f16,f18,f28
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f18,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f18,f28
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f18,340(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 340);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,48(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// fmadds f18,f18,f28,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 + ctx.f14.f64));
	// stfs f18,36(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f18,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f28,f18,f28,f17
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 - ctx.f17.f64));
	// stfs f28,24(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f18,400(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 400);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,20(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fmuls f14,f18,f28
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f18,404(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 404);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// stfs f28,172(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f28,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// lfs f17,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lwz r14,16(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// fmadds f28,f28,f18,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f18.f64 + ctx.f16.f64));
	// fmsubs f18,f17,f18,f15
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f17,404(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 404);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,400(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 400);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,236
	ctx.r14.s64 = ctx.r6.s64 * 236;
	// fmadds f17,f17,f16,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f15,f16,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,184(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,28(r1)
	PPC_STORE_U32(ctx.r1.u32 + 28, ctx.r14.u32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// mulli r14,r6,108
	ctx.r14.s64 = ctx.r6.s64 * 108;
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,376(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fadds f15,f17,f28
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// fsubs f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// stfs f28,52(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// stw r14,36(r1)
	PPC_STORE_U32(ctx.r1.u32 + 36, ctx.r14.u32);
	// fadds f28,f16,f18
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,464(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f17,468(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 468);
	ctx.f17.f64 = double(temp.f32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f16,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f16.f64 = double(temp.f32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stw r14,308(r1)
	PPC_STORE_U32(ctx.r1.u32 + 308, ctx.r14.u32);
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lwz r14,28(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// lfs f14,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// stw r14,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r14.u32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lwz r14,36(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fsubs f14,f28,f16
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// stw r14,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r14.u32);
	// stfs f14,524(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lwz r14,36(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	// fadds f28,f16,f28
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f28.f64));
	// stfs f28,500(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fmuls f14,f15,f12
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stw r14,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r14.u32);
	// lwz r14,308(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// fmsubs f14,f18,f13,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f14,404(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fmadds f18,f18,f12,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f18,504(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// lfs f28,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lwz r14,172(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lfs f18,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f17,f28
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// fmuls f15,f18,f28
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f28,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lwz r14,212(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// stfs f16,300(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// stfs f28,372(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f28,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// lwz r14,216(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	// lfs f16,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f18.f64 = double(temp.f32);
	// stfs f28,300(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmadds f28,f17,f18,f15
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 + ctx.f15.f64));
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f17,f18,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f17,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f17,f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f15,f16,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 - ctx.f14.f64));
	// fsubs f15,f28,f17
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// fadds f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// fsubs f17,f18,f16
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f16,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// stfs f14,124(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fadds f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f17,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f28,f17
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// stfs f28,300(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f28,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fsubs f17,f18,f28
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// stfs f28,184(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f16,f13
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f28,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f13
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// stfs f28,116(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmr f28,f17
	ctx.f28.f64 = ctx.f17.f64;
	// fadds f17,f15,f28
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fmr f17,f15
	ctx.f17.f64 = ctx.f15.f64;
	// fsubs f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f28,108(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f28,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f28.f64 = double(temp.f32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// stfs f17,372(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f17.f64));
	// stfs f28,376(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f28,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f28.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f17,96(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f18,f17,f12,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f18.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f17,300(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f12,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f14.f64));
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// stfs f17,216(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// stfs f15,124(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,88(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,204(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,220(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f14,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f16,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f16.f64 = double(temp.f32);
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmsubs f17,f17,f12,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f16.f64));
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,208(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f14,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// stfs f15,184(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f22
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfs f28,188(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfs f28,304(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f14,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f16,328(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f17,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,140(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,360(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f16,88(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,324(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,160(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f17,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f15,f17
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f16,116(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f17,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f16,208(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,188(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f22,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f28,f13
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f16,f22,f13
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmsubs f22,f22,f12,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f17.f64));
	// stfs f22,304(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fmadds f28,f28,f12,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f28,220(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f28,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f28.f64 = double(temp.f32);
	// fadds f17,f28,f14
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f28.f64 = double(temp.f32);
	// fadds f16,f22,f28
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// fsubs f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// lfs f28,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f22,124(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,184(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f28,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f28.f64 = double(temp.f32);
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f22,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f22.f64 = double(temp.f32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// stfs f28,60(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f22,140(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,88(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f28.f64 = double(temp.f32);
	// stfs f17,36(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,256(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f22,160(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f16,r10,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,0(r3)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f17,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// fadds f15,f17,f22
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f22,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f17,0(r4)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f22,r10,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// stfsx f16,r8,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f16,f17,f22
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f15,r9,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f16,r9,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// stfsx f17,r8,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f16,f28,f22
	ctx.f16.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fadds f17,f22,f28
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f22,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f28.f64 = double(temp.f32);
	// stfsx f16,r5,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f16,f28,f22
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfsx f17,r7,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// stfsx f16,r7,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f28,r5,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f28,f16,f17
	ctx.f28.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfsx f22,r31,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// stfs f28,208(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f22,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,140(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f28.f64 = double(temp.f32);
	// stfs f17,204(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// lfs f16,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f17.f64 = double(temp.f32);
	// stfs f28,104(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f22,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// stfs f26,260(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f16,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f16.f64 = double(temp.f32);
	// lfs f26,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f26.f64 = double(temp.f32);
	// stfs f22,120(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f22.f64 = double(temp.f32);
	// stfs f26,224(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f26,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f26.f64 = double(temp.f32);
	// lfs f16,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f16.f64 = double(temp.f32);
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// stfs f26,228(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f26,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f26,236(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f25,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfs f25,272(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f25,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfs f25,248(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f26,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f28,f12
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// lfs f16,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfs f25,280(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfs f25,288(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f16,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfs f25,164(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f25,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f22,f12
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// stfs f26,88(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f26,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stfsx f26,r30,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f14,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f25,f28,f13
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// lfs f28,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfs f28,116(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fmuls f28,f26,f0
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// stfs f28,124(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f28,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f26,f28,f12,f25
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f25.f64));
	// stfs f26,104(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmsubs f28,f28,f13,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f28,284(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmuls f28,f17,f0
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f17,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// lfs f25,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f26,160(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f26,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f25,f26,f13,f16
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f25,252(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f25,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f25.f64 = double(temp.f32);
	// stfs f28,140(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmadds f28,f26,f12,f22
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f22.f64));
	// stfs f28,292(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f28,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f28,f13
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f28,f13
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 + ctx.f17.f64));
	// lfs f28,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// fmuls f16,f28,f13
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f13
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fadds f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfsx f14,r30,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// stfsx f28,r31,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// lfs f28,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// stfs f28,164(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f28,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f12,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f26.f64));
	// stfs f28,224(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f28,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f12,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f22.f64));
	// stfs f28,248(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f26,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// stfs f28,228(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f28,f25,f0
	ctx.f28.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f28,260(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f28,f17,f0
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f28,272(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f28,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f12,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f28,236(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f28,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f28,f28,f12,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f25.f64 = double(temp.f32);
	// fadds f26,f26,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f15.f64));
	// stfs f28,288(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// fadds f28,f16,f17
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f14,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// fsubs f14,f28,f26
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfsx f14,r22,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfsx f28,r23,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f25,f22
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfsx f28,r23,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f25,f22
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfsx f28,r22,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// lfs f28,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f28,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f22,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f17,f16
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f28,280(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f28,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,104(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f28,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f12
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// stfs f26,284(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmuls f28,f28,f13
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f26,f25,f0
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f26,292(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f26,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f12
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f25,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f14,f25,f26
	ctx.f14.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f25,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,120(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f25,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f15.f64 = double(temp.f32);
	// stfs f28,84(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f26,80(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f25,252(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f15,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f25,140(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f25,88(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f25,124(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f15,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfs f25,160(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f25,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,164(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,116(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f15,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfs f25,184(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f25,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f28,f25,f15
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// lfs f25,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f26,f24,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// lfs f15,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f25,f22,f0
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f25,188(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f25,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f25.f64 = double(temp.f32);
	// lfs f22,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f25,f25,f13,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 - ctx.f17.f64));
	// fmuls f17,f14,f0
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmadds f22,f22,f13,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f16.f64));
	// lfs f16,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f14.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r25,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r24,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,296(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,244(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f14,r24,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f15,r25,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r28,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r29,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f14,r29,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f15,r28,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r26,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r27,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f28,f15
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// stfsx f14,r27,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// lfs f15,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f28,r26,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f26,f15
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f15.f64));
	// fadds f26,f15,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// lfs f14,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f25,f22
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f25,88(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f25,f30,f21
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f22,f25,f17
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// stfs f22,120(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// stfs f25,104(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f25,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f25.f64 = double(temp.f32);
	// fadds f22,f25,f16
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// stfs f22,348(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fsubs f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// stfs f25,356(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f25,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f25,f10
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f25,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f25,f8
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// lfs f25,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f25,f11,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f22.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f22,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// lfs f16,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// fmuls f14,f25,f10
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f25,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f9
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// stfs f25,84(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f25,f22,f0
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f22,f16,f0
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f22,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f9,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 + ctx.f17.f64));
	// lfs f17,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f11,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f14.f64));
	// stfs f17,296(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fadds f17,f15,f28
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f28.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f28,f28,f15
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f15.f64));
	// lfs f15,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f8,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f8.f64 - ctx.f14.f64));
	// stfs f15,244(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f15,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,84(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f26
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f26.f64));
	// stfs f16,104(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// mulli r9,r6,184
	ctx.r9.s64 = ctx.r6.s64 * 184;
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// mulli r10,r6,56
	ctx.r10.s64 = ctx.r6.s64 * 56;
	// fadds f14,f15,f16
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// stfs f26,88(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fsubs f26,f15,f16
	ctx.f26.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// stfs f26,116(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fsubs f26,f15,f25
	ctx.f26.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stfs f26,200(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// stfs f25,76(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f25,f16,f14
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fsubs f26,f16,f14
	ctx.f26.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// fmuls f14,f25,f8
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fmuls f25,f25,f9
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64));
	// stfs f25,100(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f15,f26,f10
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f16,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f10
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmadds f26,f26,f11,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 + ctx.f16.f64));
	// lfs f16,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f25,f16,f11,f15
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f15.f64));
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f15,f9,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f9.f64 + ctx.f14.f64));
	// lfs f14,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f8,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f26,f14
	ctx.f14.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfs f14,200(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f14,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f25,f14
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// lfs f14,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f16,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f14,100(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// fadds f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfsx f15,r9,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfsx f22,r10,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f17,f22
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f22,r9,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,248
	ctx.r10.s64 = ctx.r6.s64 * 248;
	// lwz r9,516(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// fsubs f22,f28,f25
	ctx.f22.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// stfsx f22,r10,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lwz r9,568(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfsx f25,r9,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f22,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// lfs f17,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfsx f28,r10,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f28.f64 = double(temp.f32);
	// fadds f26,f28,f14
	ctx.f26.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f28,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f14.f64));
	// stfsx f28,r9,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,216
	ctx.r10.s64 = ctx.r6.s64 * 216;
	// lfs f26,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f26.f64 = double(temp.f32);
	// mulli r9,r6,88
	ctx.r9.s64 = ctx.r6.s64 * 88;
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f14,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f25.f64 = double(temp.f32);
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f28.f64 = double(temp.f32);
	// fadds f26,f28,f16
	ctx.f26.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// stfsx f26,r9,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// stfsx f28,r10,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// lfs f26,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f25,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// lfs f22,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfs f16,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,176(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f16,f17,f12,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f16.f64));
	// stfs f16,232(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f16,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fmuls f14,f17,f13
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmuls f21,f16,f0
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f14.f64));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f12,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// stfs f14,192(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfs f14,152(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,264(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fadds f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// stfs f14,168(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// lfs f14,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fadds f17,f30,f21
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// stfs f17,232(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fsubs f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// stfs f30,276(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fadds f30,f15,f16
	ctx.f30.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f30,176(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f30,f15,f16
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f30,240(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f30,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f28,f11
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmuls f21,f30,f8
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// fmuls f15,f30,f9
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// lfs f30,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f26,f11
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// fmadds f26,f26,f10,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f16.f64));
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f30,f30,f9,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 - ctx.f21.f64));
	// stfs f30,144(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f21,f25,f11
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// lfs f30,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// stfs f25,40(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmadds f30,f30,f8,f17
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 + ctx.f17.f64));
	// stfs f30,196(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fmadds f25,f16,f8,f15
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f8.f64 + ctx.f15.f64));
	// lfs f16,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f28,f28,f10,f14
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f14.f64));
	// lfs f14,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f21,f22,f10,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f21.f64));
	// lfs f30,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f30.f64 = double(temp.f32);
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// fmsubs f17,f16,f9,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f9.f64 - ctx.f17.f64));
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f22,f11,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f16.f64));
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f15,f30,f16
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f16.f64));
	// lfs f16,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f15,r16,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// lfs f14,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,192(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f14,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fadds f15,f17,f25
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f17,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r6,104
	ctx.r10.s64 = ctx.r6.s64 * 104;
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,84(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f17,f22,f28
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f17,88(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f17,f21,f26
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfs f28,188(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// stfs f26,116(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f26,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfs f28,184(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f26,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfs f28,112(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f26,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfs f28,144(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f26,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfs f28,168(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f28,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f16,f10
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfsx f30,r17,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// lfs f30,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f30.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// fmuls f28,f30,f10
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// fmuls f14,f30,f11
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f30,f30,f10
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmr f30,f22
	ctx.f30.f64 = ctx.f22.f64;
	// lfs f22,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f30.f64));
	// stfsx f22,r17,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// stfsx f30,r16,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f15,f25
	ctx.f30.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// stfsx f30,r15,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f30,f16,f11,f28
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f28.f64));
	// fadds f28,f25,f15
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f15.f64));
	// stfsx f28,r10,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f11,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 + ctx.f26.f64));
	// lfs f25,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f25.f64 = double(temp.f32);
	// lfs f22,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// fadds f26,f21,f22
	ctx.f26.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fmadds f26,f25,f10,f14
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f14.f64));
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfsx f22,r15,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f25,f25,f11,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f14.f64));
	// fsubs f16,f22,f21
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfsx f16,r20,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f22,r21,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// fadds f21,f17,f22
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfsx f21,r21,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfsx f22,r20,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f22,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f24,f22
	ctx.f21.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfsx f21,r18,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfsx f24,r19,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f24.f64 = double(temp.f32);
	// fadds f21,f22,f24
	ctx.f21.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfsx f21,r19,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfsx f24,r18,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// lfs f24,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f22,f20,f24
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// lfs f21,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f21.f64 = double(temp.f32);
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f22,f21
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f27,f21
	ctx.f17.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f21,f17,f16
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f16,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f19,f16
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// fsubs f16,f14,f15
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fsubs f14,f30,f26
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// fadds f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// stfs f30,144(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f30,f25,f28
	ctx.f30.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// lfs f26,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f26.f64 = double(temp.f32);
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// lfs f25,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f26,40(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f25,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f26,76(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f25,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f26,100(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f26,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f18.f64));
	// stfs f26,84(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f25,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f26,80(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f25,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f25,f14,f24
	ctx.f25.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// stfs f25,112(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f25,f30,f17
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f17.f64));
	// stfs f25,104(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 - ctx.f30.f64));
	// stfs f30,88(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f30,f28,f22
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// stfs f30,124(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fsubs f25,f24,f14
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// stfs f25,120(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f30,f22,f28
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// stfs f30,116(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f28,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f30,f28,f25
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f22,f25,f24
	ctx.f22.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfs f24,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f30,f7
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// stfs f25,100(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f25,f24,f26
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fadds f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// mulli r9,r6,188
	ctx.r9.s64 = ctx.r6.s64 * 188;
	// fmuls f24,f30,f6
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// mulli r10,r6,60
	ctx.r10.s64 = ctx.r6.s64 * 60;
	// fmuls f30,f28,f5
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// stfs f30,76(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmuls f28,f28,f4
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// stfs f28,84(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmsubs f28,f16,f6,f22
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 - ctx.f22.f64));
	// fmuls f17,f25,f7
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fmuls f14,f25,f6
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fmadds f30,f16,f7,f24
	ctx.f30.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 + ctx.f24.f64));
	// fmuls f25,f26,f4
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmuls f26,f26,f5
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// stfs f26,80(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f24,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f24.f64 = double(temp.f32);
	// stfs f25,40(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmr f25,f24
	ctx.f25.f64 = ctx.f24.f64;
	// lfs f16,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f16.f64 = double(temp.f32);
	// lfs f24,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f15,f4,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f24.f64));
	// fmsubs f26,f25,f6,f17
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f25,f25,f7,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f14.f64));
	// fmsubs f17,f15,f5,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 - ctx.f17.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f26,f30
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fsubs f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f30.f64));
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f16,f5,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 - ctx.f22.f64));
	// fmadds f16,f16,f4,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 + ctx.f14.f64));
	// fadds f14,f25,f28
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f15.f64));
	// stfsx f25,r9,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// stfsx f25,r10,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f25,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f25.f64 = double(temp.f32);
	// fadds f26,f22,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fadds f15,f25,f14
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f14.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,252
	ctx.r10.s64 = ctx.r6.s64 * 252;
	// lwz r9,180(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lfs f25,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f15,f25,f28
	ctx.f15.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f28,f30
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,156
	ctx.r9.s64 = ctx.r6.s64 * 156;
	// lfs f30,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f28,f30,f26
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// fadds f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f16,f17
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// mulli r10,r6,28
	ctx.r10.s64 = ctx.r6.s64 * 28;
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// fadds f26,f30,f28
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f28,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// lfs f25,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f15,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f15.f64 = double(temp.f32);
	// lfs f25,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// lfs f14,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,168(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f14,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,196(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f14,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,180(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// stfs f17,112(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fmuls f17,f30,f8
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// stfs f24,104(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f24,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfs f24,80(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f22,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f28,f8
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f24,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfs f24,120(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f22,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfs f24,88(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f28,f28,f9,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 + ctx.f17.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f25,f8
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fmsubs f30,f30,f9,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 - ctx.f21.f64));
	// lfs f24,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f24,f22
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f16,152(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,144(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f24,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f24,f22
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,192(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f24,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f26,f8
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// lfs f22,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// mulli r10,r6,220
	ctx.r10.s64 = ctx.r6.s64 * 220;
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// mulli r9,r6,92
	ctx.r9.s64 = ctx.r6.s64 * 92;
	// fmadds f25,f25,f9,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f16.f64));
	// stfs f25,180(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmsubs f26,f26,f9,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 - ctx.f14.f64));
	// lfs f25,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f22,f3
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// stfsx f15,r10,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f26,112(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfsx f17,r9,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f25
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// stfsx f16,r9,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f26,f17,f25
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f29,f26
	ctx.f26.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// lfs f25,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f17,f26,f25
	ctx.f17.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f17,264(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f26,240(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f26,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fadds f17,f26,f25
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stfs f17,176(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f26,276(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f25,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f26,168(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f26,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f26,f2
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// lfs f17,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64));
	// fmuls f16,f26,f3
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f26,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f31
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// lfs f26,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f3,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64 + ctx.f25.f64));
	// lfs f25,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f25,f25,f1,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 - ctx.f17.f64));
	// lfs f17,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f30,f17
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f17.f64));
	// stfs f17,144(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f17,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfs f17,196(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f17,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f17.f64 = double(temp.f32);
	// fadds f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f2,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 - ctx.f16.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f17,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f21,f31
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// fmadds f17,f17,f1,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 + ctx.f15.f64));
	// stfs f17,152(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fmsubs f17,f24,f2,f14
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f2.f64 - ctx.f14.f64));
	// stfs f17,180(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f17,f22,f2
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// lfs f14,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f31
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,112(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f22,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f24,f24,f3,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f17.f64));
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,80(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f21,f21,f1,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f15.f64));
	// lfs f22,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f22.f64 = double(temp.f32);
	// lwz r9,320(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfs f14,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f17.f64 = double(temp.f32);
	// lwz r10,316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f14,f1,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f1.f64 - ctx.f16.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f14,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f28,f14,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 - ctx.f28.f64));
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f30,f14,f30
	ctx.f30.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// fadds f29,f14,f29
	ctx.f29.f64 = double(float(ctx.f14.f64 + ctx.f29.f64));
	// stfs f29,332(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f14,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f14.f64 = double(temp.f32);
	// lfs f29,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// stfs f29,100(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f14.f64 = double(temp.f32);
	// lfs f29,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// lfs f14,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f23,340(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f14,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,364(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfs f14,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// stfs f23,116(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f23.f64));
	// stfsx f14,r9,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f14.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// stfsx f23,r10,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f24,f14
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfs f24,40(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f24,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f17,f11
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f24,76(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f24,f21,f25
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// stfs f25,88(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f25,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f21,f22,f11
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fsubs f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// stfs f25,124(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fadds f16,f15,f26
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// fsubs f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f26.f64));
	// lfs f25,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f25,316(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// lfs f25,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f25.f64 = double(temp.f32);
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f25,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f29
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// stfs f25,320(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f25,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// fmsubs f25,f22,f10,f14
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f14.f64));
	// lfs f22,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f11
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmadds f22,f17,f10,f21
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f21.f64));
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f21,f23
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfsx f23,r9,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,244
	ctx.r10.s64 = ctx.r6.s64 * 244;
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// mulli r9,r6,116
	ctx.r9.s64 = ctx.r6.s64 * 116;
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f17,f23,f21
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfs f21,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f17,r10,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f23,r9,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f16,r9,r4
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lwz r9,532(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// stfsx f15,r10,r4
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,20
	ctx.r10.s64 = ctx.r6.s64 * 20;
	// lfs f23,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f17,f23,f21
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f16,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f16.f64 = double(temp.f32);
	// fadds f21,f21,f23
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfs f23,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f17,r9,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f17,f23,f24
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f23,f23,f24
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f24,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f21,f28,f24
	ctx.f21.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// stfsx f17,r10,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f24,f24,f28
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// stfsx f23,r9,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,212
	ctx.r10.s64 = ctx.r6.s64 * 212;
	// lwz r9,540(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// lfs f28,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f28.f64 = double(temp.f32);
	// fadds f23,f30,f28
	ctx.f23.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// lfs f17,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f28,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// stfsx f24,r9,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f23,r9,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f30.f64 = double(temp.f32);
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// lfs f24,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f24.f64 = double(temp.f32);
	// lfs f28,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// lfs f23,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// lfs f21,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// lfs f21,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,268(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f16,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f11
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// fmadds f16,f16,f10,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f14.f64));
	// lfs f14,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f14,f10,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 - ctx.f15.f64));
	// fsubs f14,f30,f28
	ctx.f14.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lwz r9,400(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	// fsubs f28,f24,f23
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// mulli r10,r6,36
	ctx.r10.s64 = ctx.r6.s64 * 36;
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f23,f21,f17
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f21,84(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f21,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f21
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f17,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f17.f64 = double(temp.f32);
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// stfs f21,100(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f21,f25,f16
	ctx.f21.f64 = double(float(ctx.f25.f64 - ctx.f16.f64));
	// fadds f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f25.f64));
	// stfs f25,344(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fsubs f25,f15,f22
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f25,76(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f25,f15,f22
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// stfs f25,268(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f22,f14,f4
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// fmuls f17,f14,f5
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// fmuls f14,f30,f6
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fmuls f30,f30,f7
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// fmadds f22,f28,f5,f22
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f5.f64 + ctx.f22.f64));
	// fmsubs f28,f28,f4,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f4.f64 - ctx.f17.f64));
	// lfs f25,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f25,f5
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f15,f25,f4
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f25,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfs f25,80(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f25,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f21.f64));
	// fadds f21,f17,f29
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// fsubs f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f17.f64));
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f30,f23,f4,f16
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 - ctx.f16.f64));
	// fmuls f16,f17,f7
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fmadds f23,f23,f5,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f15.f64));
	// fmsubs f17,f24,f7,f14
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 - ctx.f14.f64));
	// lfs f15,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f24,f24,f6,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f15.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f15,f6,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f6.f64 + ctx.f16.f64));
	// lfs f14,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f15,f15,f7,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 - ctx.f14.f64));
	// fadds f14,f30,f22
	ctx.f14.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// stfs f14,216(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fadds f14,f23,f28
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// lfs f23,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f30,f30,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f22.f64));
	// lfs f22,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfsx f22,r9,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f22,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f23,r10,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f23,f21,f14
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfsx f23,r10,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f23,f21,f14
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfsx f23,r9,r4
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r10,r6,228
	ctx.r10.s64 = ctx.r6.s64 * 228;
	// fsubs f23,f25,f28
	ctx.f23.f64 = double(float(ctx.f25.f64 - ctx.f28.f64));
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// stfsx f23,r10,r3
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// mulli r9,r6,100
	ctx.r9.s64 = ctx.r6.s64 * 100;
	// stfsx f28,r9,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f28,f29,f30
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f30.f64));
	// stfsx f28,r9,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f30,r10,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// lfs f30,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f29.f64 = double(temp.f32);
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfs f28,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f28.f64 = double(temp.f32);
	// lfs f29,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f29.f64 = double(temp.f32);
	// lwz r9,496(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// lfs f25,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f25.f64 = double(temp.f32);
	// lfs f28,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f28.f64 = double(temp.f32);
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f25.f64));
	// lfs f23,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// lfs f22,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfs f19,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// lfs f14,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f14.f64 = double(temp.f32);
	// lfs f19,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// stfs f19,336(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f19,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f26.f64));
	// stfs f19,312(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fadds f19,f15,f24
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// stfs f19,76(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f19,f16,f17
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f19,100(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f16.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// lfs f14,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// lfs f14,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f14,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f14.f64 = double(temp.f32);
	// fadds f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 + ctx.f27.f64));
	// stfs f27,80(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f14.f64 = double(temp.f32);
	// lfs f27,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// stfs f27,120(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f14,f29,f9
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// fmuls f29,f29,f8
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// stfs f29,40(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f29,f23,f22
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// fadds f27,f22,f23
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fmuls f22,f28,f8
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfs f23,104(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fmuls f21,f28,f9
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f9.f64));
	// fmsubs f28,f30,f8,f14
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f14,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f30,f30,f9,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f14.f64));
	// stfs f30,40(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f30,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f30.f64 = double(temp.f32);
	// lfs f14,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f30.f64));
	// stfsx f14,r9,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f30,f14
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f14.f64));
	// stfsx f30,r10,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f30,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f30.f64 = double(temp.f32);
	// fadds f14,f19,f30
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// stfsx f14,r10,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 - ctx.f30.f64));
	// stfsx f30,r9,r4
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// mulli r9,r6,196
	ctx.r9.s64 = ctx.r6.s64 * 196;
	// fsubs f30,f26,f17
	ctx.f30.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// mulli r10,r6,68
	ctx.r10.s64 = ctx.r6.s64 * 68;
	// fadds f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f19,f1
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// stfsx f30,r9,r3
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fmadds f30,f25,f9,f22
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f22.f64));
	// stfsx f26,r10,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f26,f25,f8,f21
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f21.f64));
	// fadds f25,f16,f24
	ctx.f25.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfsx f25,r10,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f16,f24
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// lfs f24,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f20,f24
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// fadds f24,f24,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// lfs f21,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f27,f2
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// lwz r10,384(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	// fmuls f16,f29,f1
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f1.f64));
	// lwz r9,628(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	// fadds f22,f21,f15
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fmuls f15,f23,f2
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// add r4,r9,r4
	ctx.r4.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fmadds f29,f29,f31,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f31.f64 + ctx.f17.f64));
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// addi r11,r11,504
	ctx.r11.s64 = ctx.r11.s64 + 504;
	// stw r10,384(r1)
	PPC_STORE_U32(ctx.r1.u32 + 384, ctx.r10.u32);
	// fmsubs f23,f23,f3,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 - ctx.f20.f64));
	// fsubs f20,f28,f30
	ctx.f20.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fsubs f28,f26,f17
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f17.f64));
	// fadds f26,f26,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f17.f64));
	// lfs f17,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f19,f19,f31,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 - ctx.f16.f64));
	// lfs f16,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f27,f3,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f15.f64));
	// lfs f15,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fadds f15,f20,f25
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// fsubs f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f20.f64));
	// fadds f20,f30,f22
	ctx.f20.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fadds f14,f28,f21
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f21.f64));
	// fsubs f30,f22,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// fadds f21,f26,f24
	ctx.f21.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fsubs f24,f22,f17
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fsubs f17,f16,f18
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,100(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f16,f24,f1
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmuls f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fmuls f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// fmuls f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// fmsubs f24,f24,f31,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f31.f64 - ctx.f17.f64));
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmadds f22,f17,f31,f16
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f31.f64 + ctx.f16.f64));
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f17,f3,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 - ctx.f18.f64));
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f3,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 + ctx.f16.f64));
	// fadds f16,f24,f29
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfs f16,40(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// lwz r10,412(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	// fadds f24,f18,f27
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f27.f64));
	// fadds f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// fsubs f27,f18,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// fsubs f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fadds f19,f17,f23
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// fsubs f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f17,f15,f18
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f17,0(r10)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,420(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// stfs f18,0(r10)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,428(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// fadds f18,f14,f16
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f18,0(r10)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,368(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	// fsubs f18,f14,f16
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f18,0(r10)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,308(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// fsubs f18,f25,f22
	ctx.f18.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfs f18,0(r10)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,212(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// stfs f25,0(r10)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// fadds f25,f28,f29
	ctx.f25.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// stfs f25,0(r14)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fsubs f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// fsubs f29,f21,f24
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fadds f29,f24,f21
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,68(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	// fadds f29,f20,f19
	ctx.f29.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,56(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	// fsubs f29,f20,f19
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,48(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	// fsubs f29,f26,f23
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,32(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	// fadds f29,f23,f26
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,20(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	// fadds f29,f30,f27
	ctx.f29.f64 = double(float(ctx.f30.f64 + ctx.f27.f64));
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f29,0(r10)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,16(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	// stfs f30,0(r10)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,-26212(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82c9d24c
	if (!ctx.cr0.eq) goto loc_82C9D24C;
loc_82CA0AEC:
	// addi r1,r1,928
	ctx.r1.s64 = ctx.r1.s64 + 928;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA0AF8;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA0B00"))) PPC_WEAK_FUNC(sub_82CA0B00);
PPC_FUNC_IMPL(__imp__sub_82CA0B00) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28304
	ctx.r5.s64 = ctx.r11.s64 + -28304;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,-11872
	ctx.r4.s64 = ctx.r11.s64 + -11872;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA0B18"))) PPC_WEAK_FUNC(sub_82CA0B18);
PPC_FUNC_IMPL(__imp__sub_82CA0B18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82CA0B20;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82CA0B28;
	__savefpr_14(ctx, base);
	// mulli r11,r7,248
	ctx.r11.s64 = ctx.r7.s64 * 248;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82ca201c
	if (!ctx.cr6.lt) goto loc_82CA201C;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lis r5,-32235
	ctx.r5.s64 = -2112552960;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// stw r10,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32235
	ctx.r7.s64 = -2112552960;
	// lfs f8,27780(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 27780);
	ctx.f8.f64 = double(temp.f32);
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lfs f9,27784(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 27784);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,27788(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 27788);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,27776(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27776);
	ctx.f13.f64 = double(temp.f32);
	// stw r10,-380(r1)
	PPC_STORE_U32(ctx.r1.u32 + -380, ctx.r10.u32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f11,27792(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 27792);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-29656(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29656);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,-29652(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82CA0B80:
	// rlwinm r10,r6,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f7,120(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// rlwinm r9,r6,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f6,124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 124);
	ctx.f6.f64 = double(temp.f32);
	// mulli r8,r6,96
	ctx.r8.s64 = ctx.r6.s64 * 96;
	// lfs f5,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 184);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f28,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f19,f7,f28
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfsx f26,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f28,f6,f28
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfsx f24,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f5,f26
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f2,188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f17,f3,f24
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fmuls f26,f4,f26
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// lfsx f27,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// lfs f30,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// add r31,r7,r3
	ctx.r31.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfsx f25,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f23,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lfs f29,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f29.f64 = double(temp.f32);
	// mulli r5,r6,100
	ctx.r5.s64 = ctx.r6.s64 * 100;
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f6,f6,f27,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f27.f64 + ctx.f19.f64));
	// lfs f31,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f22,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f7,f7,f27,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64 - ctx.f28.f64));
	// fmuls f28,f30,f22
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f22.f64));
	// lfs f21,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f4,f4,f25,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64 + ctx.f18.f64));
	// stw r31,-348(r1)
	PPC_STORE_U32(ctx.r1.u32 + -348, ctx.r31.u32);
	// fmadds f2,f2,f23,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64 + ctx.f17.f64));
	// stw r7,-340(r1)
	PPC_STORE_U32(ctx.r1.u32 + -340, ctx.r7.u32);
	// fmsubs f5,f5,f25,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 - ctx.f26.f64));
	// mulli r31,r6,68
	ctx.r31.s64 = ctx.r6.s64 * 68;
	// fmsubs f3,f3,f23,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64 - ctx.f24.f64));
	// lfs f26,128(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 128);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f29,f22
	ctx.f27.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// lfs f25,132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 132);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,240(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,180(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f29,f29,f21,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f21.f64 + ctx.f28.f64));
	// lfs f18,176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 176);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f6,f1
	ctx.f28.f64 = double(float(ctx.f6.f64 + ctx.f1.f64));
	// add r30,r5,r3
	ctx.r30.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fsubs f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// add r29,r5,r4
	ctx.r29.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fadds f1,f2,f4
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// add r28,r31,r3
	ctx.r28.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// mulli r7,r6,124
	ctx.r7.s64 = ctx.r6.s64 * 124;
	// fsubs f2,f5,f3
	ctx.f2.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fmsubs f30,f30,f21,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f21.f64 - ctx.f27.f64));
	// lfs f21,244(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 244);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f31,f7
	ctx.f27.f64 = double(float(ctx.f31.f64 - ctx.f7.f64));
	// lfs f20,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stw r30,-324(r1)
	PPC_STORE_U32(ctx.r1.u32 + -324, ctx.r30.u32);
	// fadds f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// stw r29,-300(r1)
	PPC_STORE_U32(ctx.r1.u32 + -300, ctx.r29.u32);
	// stw r28,-356(r1)
	PPC_STORE_U32(ctx.r1.u32 + -356, ctx.r28.u32);
	// mulli r30,r6,36
	ctx.r30.s64 = ctx.r6.s64 * 36;
	// fadds f3,f1,f28
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// fsubs f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// fsubs f28,f6,f2
	ctx.f28.f64 = double(float(ctx.f6.f64 - ctx.f2.f64));
	// fadds f6,f2,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// fsubs f31,f27,f4
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f4.f64));
	// fadds f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f27.f64));
	// lfs f27,196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 196);
	ctx.f27.f64 = double(temp.f32);
	// fadds f2,f7,f5
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// lfs f5,192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 192);
	ctx.f5.f64 = double(temp.f32);
	// mulli r5,r6,92
	ctx.r5.s64 = ctx.r6.s64 * 92;
	// fmuls f15,f5,f20
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// lfsx f16,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f27,f20
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// stfs f16,-560(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// add r27,r30,r3
	ctx.r27.u64 = ctx.r30.u64 + ctx.r3.u64;
	// lfsx f16,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// stfs f16,-532(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// add r30,r30,r4
	ctx.r30.u64 = ctx.r30.u64 + ctx.r4.u64;
	// lfs f20,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// rlwinm r29,r6,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmadds f27,f27,f20,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 + ctx.f15.f64));
	// lfsx f15,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-516(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// stw r27,-316(r1)
	PPC_STORE_U32(ctx.r1.u32 + -316, ctx.r27.u32);
	// lfs f17,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// mulli r28,r6,48
	ctx.r28.s64 = ctx.r6.s64 * 48;
	// lfsx f16,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stw r30,-308(r1)
	PPC_STORE_U32(ctx.r1.u32 + -308, ctx.r30.u32);
	// stw r31,-332(r1)
	PPC_STORE_U32(ctx.r1.u32 + -332, ctx.r31.u32);
	// fmsubs f5,f5,f20,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f20.f64 - ctx.f14.f64));
	// stfs f5,-528(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// fmuls f20,f26,f17
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// lfs f5,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// fmuls f15,f24,f5
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// fmuls f14,f23,f5
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lfs f5,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// mulli r31,r6,60
	ctx.r31.s64 = ctx.r6.s64 * 60;
	// fmadds f25,f25,f5,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f20.f64));
	// fmsubs f26,f26,f5,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 - ctx.f17.f64));
	// lfs f5,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f23,f23,f5,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f15.f64));
	// mulli r30,r6,28
	ctx.r30.s64 = ctx.r6.s64 * 28;
	// fmsubs f5,f24,f5,f14
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 - ctx.f14.f64));
	// fmuls f14,f19,f16
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f20,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f21,f20
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f20.f64));
	// fmuls f17,f22,f20
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// lfs f20,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f22,f22,f20,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f20.f64 - ctx.f15.f64));
	// fmadds f24,f21,f20,f17
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f17.f64));
	// lfs f17,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f26,f30
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fmuls f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f16,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// fadds f26,f23,f27
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fsubs f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// lfs f23,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f23.f64 = double(temp.f32);
	// fadds f21,f25,f29
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fsubs f29,f29,f25
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// fadds f25,f5,f23
	ctx.f25.f64 = double(float(ctx.f5.f64 + ctx.f23.f64));
	// fsubs f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// fmadds f19,f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f15.f64));
	// stfs f19,-468(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fmsubs f19,f18,f16,f14
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f26,f21
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// stfs f16,-532(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fsubs f26,f21,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 - ctx.f26.f64));
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f20,f25
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// stfs f16,-516(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// lfsx f16,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f27,f30
	ctx.f20.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// stfs f16,-552(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// stfs f19,-456(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fsubs f27,f29,f5
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// lfsx f18,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// lfsx f16,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f29,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f19,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f18,-560(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// stfs f16,-556(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// fmuls f16,f29,f19
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// lfsx f18,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f17,f19
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f19.f64));
	// lfs f19,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f18
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f19,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f18.f64 = double(temp.f32);
	// stfs f19,-560(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fmr f19,f18
	ctx.f19.f64 = ctx.f18.f64;
	// mulli r27,r6,80
	ctx.r27.s64 = ctx.r6.s64 * 80;
	// fmsubs f29,f29,f19,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64 - ctx.f15.f64));
	// stfs f29,-544(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// fmadds f18,f17,f19,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 + ctx.f16.f64));
	// stfs f18,-436(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f14.f64));
	// stfs f19,-548(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f18,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f18.f64 = double(temp.f32);
	// lfs f29,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f29.f64 = double(temp.f32);
	// lfs f19,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f29,f18
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f18.f64));
	// fmuls f15,f19,f18
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 - ctx.f14.f64));
	// stfs f18,-540(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f17,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f17,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f29,f17,f15
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f17.f64 - ctx.f15.f64));
	// lfs f29,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f29.f64 = double(temp.f32);
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f24
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// fmadds f16,f29,f16,f14
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-560(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f14,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f22,-528(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-544(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,-532(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-548(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f14,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-372(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,-444(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f15,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f14,-488(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,-428(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fsubs f15,f24,f22
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f15,-376(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f24,-404(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f22,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f24.f64 = double(temp.f32);
	// fadds f15,f22,f24
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f15,-368(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f24,-388(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f22,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f22.f64 = double(temp.f32);
	// mulli r26,r6,112
	ctx.r26.s64 = ctx.r6.s64 * 112;
	// fmuls f29,f29,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// lfs f22,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-560(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// rlwinm r25,r6,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f22,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-552(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f22,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-528(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// mulli r24,r6,104
	ctx.r24.s64 = ctx.r6.s64 * 104;
	// lfs f24,156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f29,f18,f22,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 * ctx.f22.f64 - ctx.f29.f64));
	// lfsx f22,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-532(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfsx f18,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-468(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// lfsx f18,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-516(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// mulli r23,r6,72
	ctx.r23.s64 = ctx.r6.s64 * 72;
	// lfsx f18,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-408(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfsx f18,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-456(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfsx f18,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f29,-508(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// stfs f18,-424(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfsx f29,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f18,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,-460(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fmuls f18,f15,f29
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f29.f64));
	// fmuls f15,f24,f29
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f29.f64));
	// lfsx f22,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f22.f64));
	// lfs f29,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// stfs f29,-560(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f22,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f22.f64 = double(temp.f32);
	// fmr f29,f22
	ctx.f29.f64 = ctx.f22.f64;
	// lfs f22,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f24,f24,f29,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f18.f64));
	// stfs f24,-540(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f24,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f29,f24,f29,f15
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 - ctx.f15.f64));
	// stfs f29,-556(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f24,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f24.f64 = double(temp.f32);
	// lfs f29,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f18,f29,f24
	ctx.f18.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// lfs f29,220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 220);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f29,f29,f22,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 + ctx.f14.f64));
	// stfs f29,-548(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f29,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f15,f29,f24
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// lfs f24,216(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 216);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f24,f24,f22,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f14.f64));
	// stfs f24,-544(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// lfs f24,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f22
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// lfs f24,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// stfs f24,-560(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f22,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f22.f64 = double(temp.f32);
	// fmr f24,f22
	ctx.f24.f64 = ctx.f22.f64;
	// lfs f22,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f29,f29,f24,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f18,200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f24,f22,f24,f15
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 - ctx.f15.f64));
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f15,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f18,f18,f15,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-532(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fadds f15,f15,f19
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// mulli r22,r6,40
	ctx.r22.s64 = ctx.r6.s64 * 40;
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f14.f64));
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,-560(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f14,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f14.f64 = double(temp.f32);
	// mulli r21,r6,120
	ctx.r21.s64 = ctx.r6.s64 * 120;
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f16,-516(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfs f16,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,-528(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f14,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// fsubs f14,f17,f19
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfs f14,-468(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -468, temp.u32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfs f19,-408(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// mulli r20,r6,88
	ctx.r20.s64 = ctx.r6.s64 * 88;
	// mulli r19,r6,56
	ctx.r19.s64 = ctx.r6.s64 * 56;
	// lfs f19,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f19,f15
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f15.f64));
	// stfs f17,-436(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fsubs f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f19,-484(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f19,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f19,f17
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f15,-492(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,-452(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f19,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f19.f64 = double(temp.f32);
	// fadds f17,f16,f19
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f19.f64));
	// stfs f17,-456(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fsubs f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f16.f64));
	// lfs f16,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-556(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// stfs f19,-424(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 136);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f19,f16
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// fmuls f14,f17,f16
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfsx f16,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-560(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfsx f16,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-532(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfsx f16,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-528(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfsx f16,r21,r3
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-552(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfsx f16,r21,r4
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-516(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -516, temp.u32);
	// lfsx f16,r20,r3
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-544(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f16,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f19,f19,f16,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 - ctx.f14.f64));
	// stfs f19,-540(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// fmadds f17,f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfsx f19,r19,r3
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f17,-548(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// stfs f19,-536(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfsx f17,r20,r4
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f19,r19,r4
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// stfs f17,-560(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// stfs f19,-524(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f17,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f19,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f17
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// lfs f17,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f16.f64));
	// stfs f19,-528(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -528, temp.u32);
	// lfs f19,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f19.f64 = double(temp.f32);
	// mulli r17,r6,20
	ctx.r17.s64 = ctx.r6.s64 * 20;
	// fmsubs f19,f19,f17,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 - ctx.f15.f64));
	// stfs f19,-508(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// lfs f19,236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 236);
	ctx.f19.f64 = double(temp.f32);
	// add r14,r17,r3
	ctx.r14.u64 = ctx.r17.u64 + ctx.r3.u64;
	// lfs f17,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f19,f17
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f17,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f29
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// stfs f17,-556(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// add r17,r17,r4
	ctx.r17.u64 = ctx.r17.u64 + ctx.r4.u64;
	// fadds f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// stfs f17,-460(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// mulli r16,r6,84
	ctx.r16.s64 = ctx.r6.s64 * 84;
	// fsubs f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f17.f64));
	// stfs f24,-432(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f24,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// stfs f29,-412(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f29,172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 172);
	ctx.f29.f64 = double(temp.f32);
	// stw r14,-364(r1)
	PPC_STORE_U32(ctx.r1.u32 + -364, ctx.r14.u32);
	// lfs f24,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f29,f24
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f24.f64));
	// stfs f24,-532(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// lfs f17,-516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	ctx.f17.f64 = double(temp.f32);
	// stw r17,-516(r1)
	PPC_STORE_U32(ctx.r1.u32 + -516, ctx.r17.u32);
	// lfs f24,232(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 232);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f19,f19,f17,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f14.f64));
	// fmsubs f17,f24,f17,f16
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 - ctx.f16.f64));
	// lfs f24,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f16,f29,f24,f15
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 + ctx.f15.f64));
	// lfs f29,168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 168);
	ctx.f29.f64 = double(temp.f32);
	// mulli r18,r6,24
	ctx.r18.s64 = ctx.r6.s64 * 24;
	// mulli r15,r6,116
	ctx.r15.s64 = ctx.r6.s64 * 116;
	// add r17,r16,r3
	ctx.r17.u64 = ctx.r16.u64 + ctx.r3.u64;
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f15,f29,f24,f15
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 - ctx.f15.f64));
	// lfs f24,-528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	ctx.f24.f64 = double(temp.f32);
	// fadds f29,f24,f22
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f14,f18
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f29,f14
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f14,f29
	ctx.f29.f64 = double(float(ctx.f14.f64 - ctx.f29.f64));
	// stfs f29,-512(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f29,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f14,f29,f22
	ctx.f14.f64 = double(float(ctx.f29.f64 - ctx.f22.f64));
	// stfs f14,-464(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// stfs f29,-440(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f29,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f29.f64 = double(temp.f32);
	// fadds f22,f24,f29
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfs f22,-460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fsubs f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// stfs f29,-384(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f29,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f24,f29,f18
	ctx.f24.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfs f24,-412(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f22,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f22.f64 = double(temp.f32);
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// lfs f24,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f24,f22
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// stfs f29,-312(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f29,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f14,f29,f22
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f22.f64));
	// lfs f22,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f29,f29,f22,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 + ctx.f18.f64));
	// fmsubs f24,f24,f22,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f14.f64));
	// fadds f22,f29,f19
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f19.f64));
	// fsubs f29,f19,f29
	ctx.f29.f64 = double(float(ctx.f19.f64 - ctx.f29.f64));
	// stfs f29,-536(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fadds f29,f24,f17
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f17.f64));
	// stfs f29,-552(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fsubs f29,f17,f24
	ctx.f29.f64 = double(float(ctx.f17.f64 - ctx.f24.f64));
	// stfs f29,-540(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfsx f29,r18,r3
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stw r17,-320(r1)
	PPC_STORE_U32(ctx.r1.u32 + -320, ctx.r17.u32);
	// lfs f18,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// add r16,r16,r4
	ctx.r16.u64 = ctx.r16.u64 + ctx.r4.u64;
	// fmuls f17,f18,f29
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f29.f64));
	// lfs f18,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f18,f29
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f29.f64));
	// lfs f19,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfs f29,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-532(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -532, temp.u32);
	// fmuls f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// stfs f29,-560(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// stw r16,-528(r1)
	PPC_STORE_U32(ctx.r1.u32 + -528, ctx.r16.u32);
	// lfsx f24,r18,r4
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// add r16,r15,r3
	ctx.r16.u64 = ctx.r15.u64 + ctx.r3.u64;
	// lfs f29,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f29.f64 = double(temp.f32);
	// add r15,r15,r4
	ctx.r15.u64 = ctx.r15.u64 + ctx.r4.u64;
	// fmadds f18,f18,f24,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f24.f64 + ctx.f17.f64));
	// stfs f18,-508(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f18,f29,f19
	ctx.f18.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// lfs f19,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f24,f19,f24,f14
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f24.f64 - ctx.f14.f64));
	// stfs f24,-556(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f24,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lwz r17,-516(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	// lfs f19,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// stw r16,-304(r1)
	PPC_STORE_U32(ctx.r1.u32 + -304, ctx.r16.u32);
	// fmuls f17,f19,f24
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// lfs f19,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f19,f24
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// stw r15,-360(r1)
	PPC_STORE_U32(ctx.r1.u32 + -360, ctx.r15.u32);
	// lfs f24,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f19.f64 = double(temp.f32);
	// lwz r17,-528(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	// fmadds f29,f29,f24,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 + ctx.f19.f64));
	// lfs f19,-532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f24,f19,f24,f18
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f24.f64 - ctx.f18.f64));
	// stfs f24,-548(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f19,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// stfs f24,-560(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f19,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 164);
	ctx.f24.f64 = double(temp.f32);
	// lfs f18,160(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 160);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f24,f24,f19,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f19.f64 + ctx.f17.f64));
	// fmsubs f19,f18,f19,f14
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64 - ctx.f14.f64));
	// lfs f17,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f14.f64));
	// lfs f14,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f16
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-560(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,-472(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f17,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f17,-480(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f17,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,-432(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f17,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-396(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f17,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f17,f15
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f16,-508(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// mulli r14,r6,52
	ctx.r14.s64 = ctx.r6.s64 * 52;
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,-336(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// mulli r17,r6,12
	ctx.r17.s64 = ctx.r6.s64 * 12;
	// lfs f17,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-556(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f16,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f16.f64 = double(temp.f32);
	// stw r14,-536(r1)
	PPC_STORE_U32(ctx.r1.u32 + -536, ctx.r14.u32);
	// lfs f17,228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 228);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f19
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfs f16,-560(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -560, temp.u32);
	// fsubs f17,f29,f24
	ctx.f17.f64 = double(float(ctx.f29.f64 - ctx.f24.f64));
	// fadds f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfs f29,-552(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f29,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f19,f29
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// stfs f29,-476(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f24,224(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 224);
	ctx.f24.f64 = double(temp.f32);
	// lfs f29,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmsubs f29,f24,f29,f15
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 - ctx.f15.f64));
	// stfs f29,-496(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// mulli r16,r6,76
	ctx.r16.s64 = ctx.r6.s64 * 76;
	// lfs f24,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f24.f64 = double(temp.f32);
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f16,-500(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// stw r14,-532(r1)
	PPC_STORE_U32(ctx.r1.u32 + -532, ctx.r14.u32);
	// mulli r15,r6,108
	ctx.r15.s64 = ctx.r6.s64 * 108;
	// lwz r14,-536(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// lfs f16,-560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,-504(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfsx f17,r17,r3
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-524(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// stw r14,-560(r1)
	PPC_STORE_U32(ctx.r1.u32 + -560, ctx.r14.u32);
	// lwz r14,-532(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	// lfs f19,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f24,f19
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// lwz r14,-560(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	// lfs f29,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-536(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfsx f29,r17,r4
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-420(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfsx f29,r16,r3
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-416(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfsx f29,r16,r4
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-540(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfsx f29,r15,r3
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-520(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfsx f29,r15,r4
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// stfs f29,-548(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f29,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f16,f29,f19
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// lfs f19,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f19,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f19,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f24,f24,f19,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f16,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f29,f29,f19,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64 - ctx.f15.f64));
	// stfs f29,-524(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f29,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f29.f64 = double(temp.f32);
	// lfs f19,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f29,f19
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// lfs f29,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// lfs f19,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f19.f64 = double(temp.f32);
	// stfs f29,-536(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fmr f29,f19
	ctx.f29.f64 = ctx.f19.f64;
	// stfs f24,-544(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f24,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f24,f16
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// fmadds f19,f24,f29,f17
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f17.f64));
	// lfs f24,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f17,f24,f29,f16
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 - ctx.f16.f64));
	// lfs f29,148(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 148);
	ctx.f29.f64 = double(temp.f32);
	// lfs f24,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f29,f29,f24,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 + ctx.f15.f64));
	// stfs f29,-556(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f16,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f16.f64 = double(temp.f32);
	// mulli r14,r6,44
	ctx.r14.s64 = ctx.r6.s64 * 44;
	// lfs f29,144(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 144);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f29,f29,f24,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f24.f64 - ctx.f16.f64));
	// stfs f29,-540(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f24,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f29,f18,f24
	ctx.f29.f64 = double(float(ctx.f18.f64 - ctx.f24.f64));
	// lfs f15,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f16.f64 = double(temp.f32);
	// fadds f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f18.f64));
	// fsubs f18,f16,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f19,f15
	ctx.f15.f64 = double(float(ctx.f19.f64 - ctx.f15.f64));
	// stfs f15,-496(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// lfs f15,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f15,-544(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f15,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f24,f15
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// stfs f15,-420(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// fsubs f15,f29,f18
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// lfs f18,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfs f24,-524(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f24,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f18,f24,f16
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// stfs f18,-536(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// fadds f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// stfs f24,-416(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f24,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f18,f15,f24
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f24.f64));
	// fadds f16,f24,f15
	ctx.f16.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// lfs f24,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f15,f24,f29
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// fadds f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// fmuls f24,f18,f0
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f24,-328(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmuls f24,f16,f0
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f24,-400(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmuls f24,f15,f0
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f24,-352(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fmuls f29,f29,f0
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// stfs f29,-392(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f18,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 208);
	ctx.f24.f64 = double(temp.f32);
	// lfs f29,212(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 212);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f16,f24,f18
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// fmuls f15,f29,f18
	ctx.f15.f64 = double(float(ctx.f29.f64 * ctx.f18.f64));
	// lfs f18,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfs f18,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f3.f64));
	// stfs f17,-520(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f17,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-556(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f17,-552(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// lfs f17,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f29,f29,f17,f16
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f24,f24,f16,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64 - ctx.f15.f64));
	// lfs f16,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// lfs f15,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,-500(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f15,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f3,f3,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f15.f64));
	// lfs f15,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f15,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-540(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -540, temp.u32);
	// lfs f15,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,-476(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f14,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-496(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fadds f17,f22,f3
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// stfs f17,-556(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -556, temp.u32);
	// fsubs f3,f3,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// stfs f3,-548(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -548, temp.u32);
	// lfs f17,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f3,r14,r3
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f17,f3
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// stfs f17,-520(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f17,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f17,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// stfs f3,-504(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfsx f22,r14,r4
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f3,f17,f22,f14
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 + ctx.f14.f64));
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f22,f17,f22,f14
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 - ctx.f14.f64));
	// fadds f17,f3,f29
	ctx.f17.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// fsubs f3,f29,f3
	ctx.f3.f64 = double(float(ctx.f29.f64 - ctx.f3.f64));
	// fadds f29,f22,f24
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f17,f19
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// fadds f17,f29,f18
	ctx.f17.f64 = double(float(ctx.f29.f64 + ctx.f18.f64));
	// fadds f14,f24,f3
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// fsubs f3,f3,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f24.f64));
	// lfs f24,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 - ctx.f29.f64));
	// fsubs f18,f24,f14
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f14.f64));
	// fadds f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f24.f64));
	// fsubs f14,f3,f16
	ctx.f14.f64 = double(float(ctx.f3.f64 - ctx.f16.f64));
	// fadds f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// fmuls f3,f18,f0
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f18,f14,f0
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f18,-552(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -552, temp.u32);
	// fmuls f18,f16,f0
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f18,-544(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -544, temp.u32);
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// fadds f16,f18,f23
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// fadds f18,f14,f16
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,-520(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// stfs f16,-500(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f16,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f25
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f25.f64));
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,-504(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// lfs f14,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,-440(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f16,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfsx f14,r10,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f16,f18,f16
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfsx f14,r10,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfs f16,0(r3)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f16,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f16.f64 = double(temp.f32);
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,0(r4)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f18,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfsx f18,r8,r3
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfsx f14,r8,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f15,r9,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfsx f18,r9,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f18,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// lfs f18,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f17.f64));
	// lfs f16,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,-512(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f14,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f14,-472(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f26,f14
	ctx.f14.f64 = double(float(ctx.f26.f64 - ctx.f14.f64));
	// stfs f14,-480(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// lfs f14,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f14,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 + ctx.f26.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f1,f14
	ctx.f14.f64 = double(float(ctx.f1.f64 - ctx.f14.f64));
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f7.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f14,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f14.f64));
	// lfs f14,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f14.f64 = double(temp.f32);
	// fadds f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// fadds f14,f25,f23
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// stfs f14,-504(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// stfs f25,-476(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// fsubs f25,f22,f18
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f25,-492(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// fadds f25,f18,f22
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f25,-500(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// lfs f25,-540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -540);
	ctx.f25.f64 = double(temp.f32);
	// fadds f23,f2,f25
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f25.f64));
	// stfs f23,-496(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fsubs f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// stfs f2,-464(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f2,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f25,f17,f16
	ctx.f25.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// fadds f23,f16,f17
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fmuls f22,f2,f12
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f18,f2,f13
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f2.f64 = double(temp.f32);
	// fadds f17,f15,f2
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f2.f64));
	// fsubs f16,f15,f2
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// lfs f2,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f2,f13
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f14,f2,f13
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f2,f26,f13
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f2,-512(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// stfs f26,-520(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fmuls f2,f25,f0
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f25,f23,f0
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f25,-524(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// lfs f25,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f17,f0
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f25,f29,f25
	ctx.f25.f64 = double(float(ctx.f29.f64 + ctx.f25.f64));
	// lfs f17,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f12,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f14.f64));
	// fmsubs f26,f25,f13,f22
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 - ctx.f22.f64));
	// fmadds f25,f25,f12,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 + ctx.f18.f64));
	// lfs f18,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f18.f64 = double(temp.f32);
	// stfs f17,-480(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -480, temp.u32);
	// fmadds f18,f18,f12,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f15.f64));
	// lfs f17,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f16,f0
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmadds f17,f21,f12,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f17,-536(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f16,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f21,f21,f13,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f17.f64));
	// stfs f21,-484(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// lfs f21,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f17,f21
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// lfs f17,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// fsubs f16,f17,f16
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// lfs f17,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// stfs f21,-512(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fmuls f21,f15,f0
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f17,f14,f0
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fsubs f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfsx f14,r27,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -556);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfsx f21,r29,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f17,f21
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfsx f14,r29,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfsx f21,r27,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,-548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -548);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f17,f21,f16
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfsx f17,r26,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// stfsx f21,r28,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// lfs f16,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fadds f17,f15,f21
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfsx f17,r28,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// fsubs f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfsx f21,r26,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f22,f7
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f7.f64));
	// fsubs f29,f21,f29
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// lfs f21,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// lfs f15,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f2,f16
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// fsubs f2,f16,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 - ctx.f2.f64));
	// stfs f2,-476(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -476, temp.u32);
	// lfs f2,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f7,f7,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f22.f64));
	// lfs f16,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f2
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f2.f64));
	// lfs f2,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f15,f15,f2
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// lfs f2,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f2.f64 = double(temp.f32);
	// stfs f7,-496(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -496, temp.u32);
	// fmuls f14,f2,f13
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f2.f64 = double(temp.f32);
	// fadds f7,f23,f1
	ctx.f7.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// stfs f7,-520(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f7,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f7.f64 = double(temp.f32);
	// stfs f2,-512(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// fadds f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// stfs f7,-504(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f2,f1,f23
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// lfs f7,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f16,f0
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f1,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f1.f64 = double(temp.f32);
	// fadds f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// fsubs f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f25.f64));
	// lfs f25,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f25.f64 = double(temp.f32);
	// stfs f7,-500(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f22,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f22.f64 = double(temp.f32);
	// lfs f7,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f7.f64 = double(temp.f32);
	// lfs f25,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f25.f64 = double(temp.f32);
	// fadds f7,f7,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f22.f64));
	// lfs f16,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f14.f64));
	// lfs f14,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f15,-488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f15,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f3,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 + ctx.f15.f64));
	// stfs f15,-464(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-484(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -484, temp.u32);
	// fmuls f15,f21,f13
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f14,f29,f13
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fmsubs f29,f29,f12,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64 - ctx.f15.f64));
	// stfs f29,-444(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fmadds f29,f21,f12,f14
	ctx.f29.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f29,-492(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -492, temp.u32);
	// lfs f29,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f29.f64 = double(temp.f32);
	// lfs f21,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f15,f29,f21
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f21.f64));
	// fadds f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// lfs f29,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f29.f64 = double(temp.f32);
	// fadds f14,f7,f29
	ctx.f14.f64 = double(float(ctx.f7.f64 + ctx.f29.f64));
	// fsubs f7,f7,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// stfs f7,-504(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -504, temp.u32);
	// fsubs f29,f2,f1
	ctx.f29.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// stfs f29,-500(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -500, temp.u32);
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfs f2,-524(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -524, temp.u32);
	// fsubs f7,f28,f23
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// fadds f2,f23,f28
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// fadds f1,f25,f26
	ctx.f1.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f1,-472(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -472, temp.u32);
	// fadds f1,f22,f4
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// fsubs f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// fsubs f4,f4,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f22.f64));
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f16,f28
	ctx.f28.f64 = double(float(ctx.f16.f64 - ctx.f28.f64));
	// stfs f28,-452(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f16.f64));
	// stfs f28,-536(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -536, temp.u32);
	// lfs f28,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f10
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// lfs f28,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// stfs f28,-488(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -488, temp.u32);
	// lfs f28,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// stfs f28,-520(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -520, temp.u32);
	// lfs f28,-480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -480);
	ctx.f28.f64 = double(temp.f32);
	// fmr f29,f28
	ctx.f29.f64 = ctx.f28.f64;
	// lfs f28,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f29
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// stfs f28,-512(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -512, temp.u32);
	// lfs f28,-492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -492);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f28.f64));
	// stfsx f28,r20,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,-488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -488);
	ctx.f28.f64 = double(temp.f32);
	// fadds f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// stfsx f28,r18,r3
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,-512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -512);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f17,f28
	ctx.f25.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// stfsx f25,r18,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r18.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f17,f28
	ctx.f28.f64 = double(float(ctx.f17.f64 - ctx.f28.f64));
	// stfsx f28,r20,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r20.u32 + ctx.r4.u32, temp.u32);
	// lfs f28,-476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -476);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f25,f28,f29
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// stfsx f25,r21,r3
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r3.u32, temp.u32);
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// stfsx f29,r19,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r3.u32, temp.u32);
	// lfs f28,-520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -520);
	ctx.f28.f64 = double(temp.f32);
	// lfs f29,-496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -496);
	ctx.f29.f64 = double(temp.f32);
	// fadds f25,f29,f28
	ctx.f25.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// stfsx f25,r19,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r19.u32 + ctx.r4.u32, temp.u32);
	// fsubs f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// stfsx f29,r21,r4
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r21.u32 + ctx.r4.u32, temp.u32);
	// stfsx f15,r23,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// stfsx f21,r25,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// stfsx f14,r25,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,-504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -504);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f21,r23,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// lfs f21,-500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -500);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f21,r24,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -524);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f21,r22,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -472);
	ctx.f21.f64 = double(temp.f32);
	// stfsx f21,r22,r4
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// stfsx f26,r24,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// lfs f26,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// lfs f22,-552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -552);
	ctx.f22.f64 = double(temp.f32);
	// lfs f26,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// lfs f22,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f21,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f23,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f28,f27,f23
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// lfs f25,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f25.f64 = double(temp.f32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// lfs f23,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f29,f20,f25
	ctx.f29.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// fadds f20,f19,f7
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f7.f64));
	// fsubs f7,f7,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f19.f64));
	// lfs f19,-484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -484);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f23,f13,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 + ctx.f22.f64));
	// lfs f22,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f22,f22,f12,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f21.f64));
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f21,f10
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fmsubs f21,f21,f11,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 - ctx.f16.f64));
	// fmuls f17,f28,f8
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmuls f16,f3,f8
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f15,f25,f10
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f14,f27,f10
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fmadds f19,f19,f11,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f18.f64));
	// stfs f19,-508(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -508, temp.u32);
	// fmuls f19,f29,f8
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fmuls f18,f26,f8
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fmsubs f29,f29,f9,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 - ctx.f17.f64));
	// fmadds f26,f26,f9,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 + ctx.f16.f64));
	// fmadds f27,f27,f11,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f15.f64));
	// fmsubs f25,f25,f11,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f14.f64));
	// fmadds f28,f28,f9,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 + ctx.f19.f64));
	// fmsubs f3,f3,f9,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 - ctx.f18.f64));
	// fsubs f19,f22,f23
	ctx.f19.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fadds f18,f27,f21
	ctx.f18.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// fadds f22,f3,f28
	ctx.f22.f64 = double(float(ctx.f3.f64 + ctx.f28.f64));
	// fsubs f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// fadds f28,f26,f29
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// fadds f26,f19,f4
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// fsubs f4,f4,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f19.f64));
	// fadds f19,f23,f2
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// lfs f17,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f20,f22
	ctx.f16.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfsx f16,r5,r3
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfsx f22,r30,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f20,f26,f28
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfsx f20,r30,r4
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfsx f28,r5,r4
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fsubs f22,f7,f29
	ctx.f22.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// stfsx f22,r7,r3
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// stfsx f7,r31,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f4,f3
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// stfsx f7,r31,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f4,f3
	ctx.f7.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfsx f7,r7,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f19,f18
	ctx.f7.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfsx f7,r16,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r3.u32, temp.u32);
	// fadds f7,f18,f19
	ctx.f7.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfsx f7,r17,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r3.u32, temp.u32);
	// lfs f7,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f7.f64 = double(temp.f32);
	// fadds f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// fadds f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// lfs f22,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f23.f64));
	// fmuls f14,f15,f12
	ctx.f14.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f26,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f26.f64 = double(temp.f32);
	// lfs f18,-544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -544);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f3,f5,f26
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// lfs f16,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f16.f64 = double(temp.f32);
	// fadds f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// lfs f20,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// lfs f19,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f28,f30,f20
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// fadds f30,f20,f30
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// lfs f23,-508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -508);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// lfs f23,-536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -536);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// fadds f4,f7,f17
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f17.f64));
	// stfsx f4,r17,r4
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r17.u32 + ctx.r4.u32, temp.u32);
	// fsubs f7,f7,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f17.f64));
	// stfsx f7,r16,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r16.u32 + ctx.r4.u32, temp.u32);
	// lfs f7,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f26,f16,f13,f14
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f4,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f17,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f17.f64 = double(temp.f32);
	// fadds f29,f7,f4
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fmuls f7,f17,f12
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// stfs f7,-404(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fadds f7,f18,f22
	ctx.f7.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f4,f24,f19
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// fsubs f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 - ctx.f24.f64));
	// lfs f19,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f15,f13,f16
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f21,-384(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fmuls f29,f29,f0
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f15,f5,f9
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f14,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f18,f13,f14
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,-468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -468);
	ctx.f14.f64 = double(temp.f32);
	// fadds f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f14.f64));
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// fmuls f14,f24,f11
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// fsubs f16,f26,f20
	ctx.f16.f64 = double(float(ctx.f26.f64 - ctx.f20.f64));
	// stfs f16,-400(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmuls f23,f19,f0
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmsubs f21,f17,f13,f18
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f21,-396(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f19,f6,f29
	ctx.f19.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// stfs f19,-388(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmuls f21,f4,f9
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// fmuls f19,f7,f9
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fmuls f18,f28,f11
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// fmuls f17,f3,f11
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmuls f16,f5,f8
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// fmuls f5,f22,f11
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// stfs f5,-392(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fadds f6,f29,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// lwz r10,-380(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	// fsubs f29,f2,f25
	ctx.f29.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// stfsx f29,r15,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// stfsx f2,r14,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f1,f27
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// stfsx f2,r14,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r14.u32 + ctx.r4.u32, temp.u32);
	// fsubs f2,f1,f27
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// stfsx f2,r15,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r15.u32 + ctx.r4.u32, temp.u32);
	// fadds f1,f20,f26
	ctx.f1.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// lfs f20,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f3,f3,f10,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f18.f64));
	// lfs f27,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f22,f10,f14
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f14.f64));
	// addic. r9,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r9.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// fmsubs f7,f7,f8,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 - ctx.f21.f64));
	// lwz r10,-344(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	// fmadds f4,f4,f8,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f19.f64));
	// lfs f19,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f19.f64 = double(temp.f32);
	// fadds f5,f23,f31
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f2,f31,f23
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f23.f64));
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fmsubs f31,f28,f10,f17
	ctx.f31.f64 = double(float(ctx.f28.f64 * ctx.f10.f64 - ctx.f17.f64));
	// lfs f28,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f28.f64 = double(temp.f32);
	// fadds f29,f27,f28
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lwz r10,-320(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	// fsubs f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// stw r9,-380(r1)
	PPC_STORE_U32(ctx.r1.u32 + -380, ctx.r9.u32);
	// fmadds f27,f30,f9,f16
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f16.f64));
	// addi r11,r11,248
	ctx.r11.s64 = ctx.r11.s64 + 248;
	// fmsubs f30,f30,f8,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f15.f64));
	// fadds f23,f26,f3
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fsubs f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fadds f26,f27,f7
	ctx.f26.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fsubs f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// lfs f21,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f25,f24,f10,f21
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f21.f64));
	// fadds f24,f19,f20
	ctx.f24.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fadds f19,f1,f5
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fadds f21,f28,f2
	ctx.f21.f64 = double(float(ctx.f28.f64 + ctx.f2.f64));
	// fsubs f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// fadds f28,f29,f6
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f6.f64));
	// fsubs f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// fadds f22,f25,f31
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f31.f64));
	// fsubs f1,f24,f23
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-364(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	// fadds f1,f23,f24
	ctx.f1.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f31,f31,f25
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f25.f64));
	// fadds f25,f30,f4
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// fsubs f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-516(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -516);
	// fadds f1,f21,f22
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-528(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -528);
	// fsubs f1,f21,f22
	ctx.f1.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-304(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	// fsubs f1,f20,f31
	ctx.f1.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-532(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -532);
	// fadds f1,f31,f20
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-560(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -560);
	// fadds f1,f2,f3
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// stfs f1,0(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-360(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-356(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	// fsubs f3,f28,f26
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-348(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	// fadds f3,f26,f28
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-340(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	// fadds f3,f19,f25
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-332(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	// fsubs f3,f19,f25
	ctx.f3.f64 = double(float(ctx.f19.f64 - ctx.f25.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	// fsubs f3,f6,f4
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfs f3,0(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-316(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	// stfs f6,0(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-308(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	// fadds f6,f5,f7
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fsubs f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfs f6,0(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,-300(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	// stfs f7,0(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lwz r10,-26212(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82ca0b80
	if (!ctx.cr0.eq) goto loc_82CA0B80;
loc_82CA201C:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA2024;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA2028"))) PPC_WEAK_FUNC(sub_82CA2028);
PPC_FUNC_IMPL(__imp__sub_82CA2028) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28232
	ctx.r5.s64 = ctx.r11.s64 + -28232;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,2840
	ctx.r4.s64 = ctx.r11.s64 + 2840;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA2040"))) PPC_WEAK_FUNC(sub_82CA2040);
PPC_FUNC_IMPL(__imp__sub_82CA2040) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a4
	ctx.lr = 0x82CA2048;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82d5c540
	ctx.lr = 0x82CA2050;
	__savefpr_14(ctx, base);
	// mulli r11,r7,120
	ctx.r11.s64 = ctx.r7.s64 * 120;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82ca274c
	if (!ctx.cr6.lt) goto loc_82CA274C;
	// rlwinm r20,r9,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r21,r7,r8
	ctx.r21.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32236
	ctx.r8.s64 = -2112618496;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r19,-32234
	ctx.r19.s64 = -2112487424;
	// lfs f12,-29656(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -29656);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,27776(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27776);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29652(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82CA2084:
	// rlwinm r10,r6,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f11,56(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r9,r6,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r7,r6,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f8,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// mulli r5,r6,40
	ctx.r5.s64 = ctx.r6.s64 * 40;
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f30,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f28,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f11,f30
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f19,f9,f28
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// lfsx f29,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f30,f10,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfsx f27,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f28,f8,f28
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfsx f24,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfs f3,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f3.f64 = double(temp.f32);
	// mulli r8,r6,48
	ctx.r8.s64 = ctx.r6.s64 * 48;
	// lfsx f22,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfs f2,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f23,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f10,f10,f29,f20
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64 + ctx.f20.f64));
	// lfsx f26,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f21,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f7,f26
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// fmsubs f11,f11,f29,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 - ctx.f30.f64));
	// lfs f6,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f9,f9,f27,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f28.f64));
	// lfsx f25,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f28,f3,f22
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// lfs f1,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f30,f5,f24
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// mulli r31,r6,56
	ctx.r31.s64 = ctx.r6.s64 * 56;
	// fmuls f29,f4,f24
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// lfs f31,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// fmuls f26,f6,f26
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmadds f8,f8,f27,f19
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 + ctx.f19.f64));
	// lfs f27,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f6,f6,f25,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f18.f64));
	// mulli r30,r6,24
	ctx.r30.s64 = ctx.r6.s64 * 24;
	// fmadds f4,f4,f23,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 + ctx.f30.f64));
	// fmadds f30,f2,f21,f28
	ctx.f30.f64 = double(float(ctx.f2.f64 * ctx.f21.f64 + ctx.f28.f64));
	// lfs f2,112(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f3,f3,f21,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f21.f64 - ctx.f22.f64));
	// lfsx f21,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f5,f5,f23,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f29.f64));
	// lfsx f20,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f7,f7,f25,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 - ctx.f26.f64));
	// lfs f23,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f23.f64 = double(temp.f32);
	// fadds f29,f10,f1
	ctx.f29.f64 = double(float(ctx.f10.f64 + ctx.f1.f64));
	// mulli r29,r6,60
	ctx.r29.s64 = ctx.r6.s64 * 60;
	// fsubs f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// lfs f26,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f26.f64 = double(temp.f32);
	// fadds f1,f6,f8
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// lfs f25,116(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// lfsx f19,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f28,f31,f11
	ctx.f28.f64 = double(float(ctx.f31.f64 - ctx.f11.f64));
	// fadds f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f31.f64));
	// lfs f31,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f24,f4,f30
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// lfsx f17,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// lfs f30,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f22,f5,f3
	ctx.f22.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// mulli r28,r6,44
	ctx.r28.s64 = ctx.r6.s64 * 44;
	// fsubs f6,f9,f7
	ctx.f6.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// lfs f7,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f7.f64 = double(temp.f32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f3,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f16,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// mulli r27,r6,28
	ctx.r27.s64 = ctx.r6.s64 * 28;
	// fsubs f18,f22,f24
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// lfsx f22,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f15,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f31,f3
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// stfs f15,-280(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// rlwinm r25,r6,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f15,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// mulli r24,r6,52
	ctx.r24.s64 = ctx.r6.s64 * 52;
	// stfs f15,-284(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfsx f15,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-288(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fmuls f15,f7,f3
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// fmuls f3,f27,f20
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// stfs f3,-276(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// fmuls f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// mulli r26,r6,12
	ctx.r26.s64 = ctx.r6.s64 * 12;
	// fmsubs f7,f7,f21,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64 - ctx.f14.f64));
	// fmadds f3,f31,f21,f15
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f21.f64 + ctx.f15.f64));
	// fmuls f21,f2,f22
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// fmsubs f27,f27,f19,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f19.f64 - ctx.f20.f64));
	// mulli r23,r6,36
	ctx.r23.s64 = ctx.r6.s64 * 36;
	// fmuls f20,f23,f16
	ctx.f20.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// fmuls f22,f25,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f22.f64));
	// fmsubs f2,f2,f17,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64 - ctx.f22.f64));
	// lfs f22,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f31,f26,f19,f15
	ctx.f31.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 + ctx.f15.f64));
	// fmuls f19,f30,f16
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f16.f64));
	// lfs f16,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f25,f17,f21
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f17.f64 + ctx.f21.f64));
	// lfs f25,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f30,f30,f25,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 + ctx.f20.f64));
	// lfs f21,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f22,f16
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f20,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f25,f23,f25,f19
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f25.f64 - ctx.f19.f64));
	// lfs f19,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f23,f3,f31
	ctx.f23.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f31,f7,f27
	ctx.f31.f64 = double(float(ctx.f7.f64 - ctx.f27.f64));
	// fadds f7,f27,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 + ctx.f7.f64));
	// fadds f27,f31,f23
	ctx.f27.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// fsubs f31,f23,f31
	ctx.f31.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// lfs f23,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f16
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f16,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f23,f23,f16,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 - ctx.f14.f64));
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-280(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfsx f14,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-292(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfsx f14,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-288(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f14,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-296(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmadds f22,f22,f16,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f15.f64));
	// lfsx f16,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f15,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f26,f22
	ctx.f14.f64 = double(float(ctx.f26.f64 - ctx.f22.f64));
	// stfs f14,-320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f26,-284(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fsubs f26,f2,f23
	ctx.f26.f64 = double(float(ctx.f2.f64 - ctx.f23.f64));
	// stfs f26,-316(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fmuls f26,f21,f16
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfsx f22,r23,r3
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f2.f64));
	// stfs f2,-276(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// fmuls f23,f20,f16
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// lfsx f2,r23,r4
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,-312(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// stfs f22,-272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmadds f26,f20,f15,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 + ctx.f26.f64));
	// stfs f26,-300(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f2,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f19,f2
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// fmuls f20,f17,f2
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmsubs f2,f21,f15,f23
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f15.f64 - ctx.f23.f64));
	// stfs f2,-304(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f2,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f2.f64 = double(temp.f32);
	// lfs f23,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f2,f23
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f26,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// mulli r22,r6,20
	ctx.r22.s64 = ctx.r6.s64 * 20;
	// fmuls f14,f26,f23
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f23,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// stfs f22,-280(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f21,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f22,f17,f21,f16
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f21.f64 + ctx.f16.f64));
	// fmsubs f21,f19,f21,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 - ctx.f20.f64));
	// lfs f20,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f26,f26,f20,f15
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f15.f64));
	// lfs f19,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f20,f2,f20,f14
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f20.f64 - ctx.f14.f64));
	// lfs f2,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f2.f64 = double(temp.f32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f19,f2,f19,f16
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f19.f64 + ctx.f16.f64));
	// lfs f16,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f30
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// fadds f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// fsubs f16,f15,f25
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f25.f64));
	// fadds f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f25.f64));
	// lfs f15,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f17,f15
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f15,-280(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,-308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,-292(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f16,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,-288(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f17,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// lfs f14,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// stfs f17,-316(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f17,f18,f27
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f27.f64));
	// fmuls f16,f15,f13
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fsubs f15,f31,f24
	ctx.f15.f64 = double(float(ctx.f31.f64 - ctx.f24.f64));
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f19,f29,f1
	ctx.f19.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// fmsubs f2,f23,f14,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f14.f64 - ctx.f2.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,-272(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f23,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f12
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// lfs f17,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f10,f6
	ctx.f23.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fmsubs f17,f17,f12,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f16.f64));
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f15,-312(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fsubs f15,f21,f2
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// stfs f15,-308(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fadds f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f21.f64));
	// stfs f2,-280(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfsx f15,r22,r4
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f2,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f2.f64 = double(temp.f32);
	// fadds f21,f2,f23
	ctx.f21.f64 = double(float(ctx.f2.f64 + ctx.f23.f64));
	// stfs f21,-320(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 - ctx.f2.f64));
	// stfs f2,-268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f2,f8,f28
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fsubs f21,f5,f7
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// fadds f23,f2,f16
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// stfs f23,-304(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fsubs f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f16.f64));
	// stfs f2,-300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// fadds f2,f21,f19
	ctx.f2.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f2,-264(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfsx f16,r22,r3
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f2,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f2.f64 = double(temp.f32);
	// lfs f23,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f2,f16
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// fmuls f16,f23,f16
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// fmadds f23,f23,f15,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64 + ctx.f14.f64));
	// fmsubs f2,f2,f15,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64 - ctx.f16.f64));
	// fsubs f16,f23,f26
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// lfs f14,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fsubs f26,f2,f20
	ctx.f26.f64 = double(float(ctx.f2.f64 - ctx.f20.f64));
	// fadds f20,f2,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 + ctx.f20.f64));
	// lfs f2,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f2.f64 = double(temp.f32);
	// fadds f31,f31,f24
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f24.f64));
	// fadds f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// fsubs f27,f3,f4
	ctx.f27.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// fadds f2,f16,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 + ctx.f2.f64));
	// fsubs f15,f22,f23
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fsubs f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfs f14,-272(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f14,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// lfs f14,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f14.f64 = double(temp.f32);
	// fadds f26,f26,f14
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f14.f64));
	// stfs f26,-296(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f26,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f12
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f26,-272(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmadds f26,f2,f13,f14
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f14,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f2,f2,f12,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f14.f64));
	// fadds f14,f17,f26
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f26.f64));
	// stfs f14,-308(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f14,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 - ctx.f26.f64));
	// fadds f14,f14,f2
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f2.f64));
	// stfs f14,-316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f14,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f14.f64));
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfsx f17,r28,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfsx f17,r28,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r4.u32, temp.u32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfsx f17,r26,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfsx f17,r26,r4
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r4.u32, temp.u32);
	// lfs f17,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f17,f2
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f2.f64));
	// stfsx f14,r29,r3
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// lfs f14,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f14.f64 = double(temp.f32);
	// fadds f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f17.f64));
	// fsubs f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f26.f64));
	// stfsx f14,r29,r4
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r4.u32, temp.u32);
	// stfsx f2,r27,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r3.u32, temp.u32);
	// lfs f2,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// stfsx f2,r27,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r4.u32, temp.u32);
	// lfs f2,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f17,f2,f20
	ctx.f17.f64 = double(float(ctx.f2.f64 - ctx.f20.f64));
	// lfs f26,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfs f27,-304(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fadds f2,f17,f15
	ctx.f2.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f2,-272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f2,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// fsubs f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f30.f64));
	// fsubs f14,f2,f26
	ctx.f14.f64 = double(float(ctx.f2.f64 - ctx.f26.f64));
	// fadds f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// stfs f2,-300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f2,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f26,f16,f12
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmuls f24,f2,f12
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f2,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f2,f12
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f2,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,-268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// lfs f27,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f6,f31,f0
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// lfs f31,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f31.f64 = double(temp.f32);
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// lfs f3,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f31,f31,f13,f26
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f13.f64 + ctx.f26.f64));
	// addic. r21,r21,-1
	ctx.xer.ca = ctx.r21.u32 > 0;
	ctx.r21.s64 = ctx.r21.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r21.s32, 0, ctx.xer);
	// fmsubs f27,f27,f13,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f24.f64));
	// lfs f24,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f26,f18,f0
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfs f18,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// addi r11,r11,120
	ctx.r11.s64 = ctx.r11.s64 + 120;
	// fadds f1,f1,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// fsubs f19,f14,f3
	ctx.f19.f64 = double(float(ctx.f14.f64 - ctx.f3.f64));
	// fadds f29,f14,f3
	ctx.f29.f64 = double(float(ctx.f14.f64 + ctx.f3.f64));
	// lfs f3,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f24,f24,f13,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f18.f64));
	// fadds f18,f3,f17
	ctx.f18.f64 = double(float(ctx.f3.f64 + ctx.f17.f64));
	// fsubs f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f3.f64));
	// fsubs f2,f11,f9
	ctx.f2.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fsubs f8,f28,f8
	ctx.f8.f64 = double(float(ctx.f28.f64 - ctx.f8.f64));
	// fmsubs f28,f16,f13,f15
	ctx.f28.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f15.f64));
	// lfs f16,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f16.f64 = double(temp.f32);
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// lfs f9,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f9.f64 = double(temp.f32);
	// fadds f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fadds f9,f20,f9
	ctx.f9.f64 = double(float(ctx.f20.f64 + ctx.f9.f64));
	// fmuls f3,f29,f0
	ctx.f3.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f29,f19,f0
	ctx.f29.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fmuls f19,f18,f0
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f18,f17,f0
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f17,f2,f16
	ctx.f17.f64 = double(float(ctx.f2.f64 + ctx.f16.f64));
	// fsubs f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f16.f64));
	// fadds f16,f6,f10
	ctx.f16.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// fadds f6,f27,f31
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fsubs f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// fadds f27,f8,f26
	ctx.f27.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// fsubs f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f26.f64));
	// fadds f26,f24,f28
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// lfs f24,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f15,f24,f3
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f3.f64));
	// stfsx f15,r5,r3
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f3,f3,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f24.f64));
	// fsubs f24,f21,f18
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fsubs f18,f17,f19
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f19.f64));
	// stfsx f18,r5,r4
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// stfsx f3,r7,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f3,f19,f17
	ctx.f3.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// stfsx f3,r7,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f2,f29
	ctx.f3.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// stfsx f24,r31,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// stfsx f3,r31,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f16,f6
	ctx.f3.f64 = double(float(ctx.f16.f64 - ctx.f6.f64));
	// stfsx f21,r30,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f6,f16
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f16.f64));
	// stfsx f2,r30,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// fsubs f2,f27,f26
	ctx.f2.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// stfsx f3,r23,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r3.u32, temp.u32);
	// fsubs f3,f8,f31
	ctx.f3.f64 = double(float(ctx.f8.f64 - ctx.f31.f64));
	// stfsx f2,r23,r4
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f31,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f8.f64));
	// stfsx f6,r25,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfsx f6,r25,r4
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r4.u32, temp.u32);
	// fsubs f6,f10,f28
	ctx.f6.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// stfsx f6,r24,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// stfsx f3,r24,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r4.u32, temp.u32);
	// stfsx f10,r22,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f23,f22
	ctx.f10.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfsx f8,r22,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r22.u32 + ctx.r4.u32, temp.u32);
	// lfs f8,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f6.f64 = double(temp.f32);
	// fadds f8,f30,f8
	ctx.f8.f64 = double(float(ctx.f30.f64 + ctx.f8.f64));
	// fadds f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// fadds f3,f8,f10
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// fadds f5,f4,f1
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f8,f11,f7
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// fsubs f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f7,f6,f9
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// fsubs f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fsubs f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfsx f6,r10,r3
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f6,f3,f5
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f5,f11,f10
	ctx.f5.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fsubs f3,f8,f7
	ctx.f3.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfs f6,0(r3)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f8,f4,f9
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f9.f64));
	// stfsx f8,r8,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f9,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f4.f64));
	// stfsx f5,r8,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// add r3,r20,r3
	ctx.r3.u64 = ctx.r20.u64 + ctx.r3.u64;
	// stfsx f11,r9,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// lwz r10,-26212(r19)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r19.u32 + -26212);
	// add r4,r20,r4
	ctx.r4.u64 = ctx.r20.u64 + ctx.r4.u64;
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82ca2084
	if (!ctx.cr0.eq) goto loc_82CA2084;
loc_82CA274C:
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA2754;
	__restfpr_14(ctx, base);
	// b 0x82d5c4f4
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA2758"))) PPC_WEAK_FUNC(sub_82CA2758);
PPC_FUNC_IMPL(__imp__sub_82CA2758) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28160
	ctx.r5.s64 = ctx.r11.s64 + -28160;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,8256
	ctx.r4.s64 = ctx.r11.s64 + 8256;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA2770"))) PPC_WEAK_FUNC(sub_82CA2770);
PPC_FUNC_IMPL(__imp__sub_82CA2770) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82CA2778;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82CA2780;
	__savefpr_14(ctx, base);
	// mulli r11,r7,112
	ctx.r11.s64 = ctx.r7.s64 * 112;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82ca2eac
	if (!ctx.cr6.lt) goto loc_82CA2EAC;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lis r5,-32235
	ctx.r5.s64 = -2112552960;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// stw r10,-324(r1)
	PPC_STORE_U32(ctx.r1.u32 + -324, ctx.r10.u32);
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lfs f13,28204(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 28204);
	ctx.f13.f64 = double(temp.f32);
	// lis r8,-32235
	ctx.r8.s64 = -2112552960;
	// lfs f0,28208(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 28208);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-29000(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29000);
	ctx.f11.f64 = double(temp.f32);
	// stw r10,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r10.u32);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f9,-12748(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -12748);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,28200(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 28200);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,28136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f12.f64 = double(temp.f32);
loc_82CA27D0:
	// mulli r8,r6,40
	ctx.r8.s64 = ctx.r6.s64 * 40;
	// lfs f8,32(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f8.f64 = double(temp.f32);
	// mulli r5,r6,20
	ctx.r5.s64 = ctx.r6.s64 * 20;
	// lfs f7,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f2,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f29,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f8,f29
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// add r26,r3,r8
	ctx.r26.u64 = ctx.r3.u64 + ctx.r8.u64;
	// fmuls f29,f7,f29
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// add r27,r5,r4
	ctx.r27.u64 = ctx.r5.u64 + ctx.r4.u64;
	// mulli r10,r6,24
	ctx.r10.s64 = ctx.r6.s64 * 24;
	// lfs f27,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f6,f27
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f28,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// lfsx f25,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f7,f7,f28,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 + ctx.f19.f64));
	// lfsx f24,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// add r25,r4,r8
	ctx.r25.u64 = ctx.r4.u64 + ctx.r8.u64;
	// fmsubs f8,f8,f28,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmuls f29,f4,f25
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// mulli r31,r6,44
	ctx.r31.s64 = ctx.r6.s64 * 44;
	// fmuls f28,f3,f25
	ctx.f28.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f25,104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f5,f5,f26,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64 + ctx.f18.f64));
	// lfsx f21,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f6,f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 - ctx.f27.f64));
	// mulli r9,r6,36
	ctx.r9.s64 = ctx.r6.s64 * 36;
	// fmadds f3,f3,f24,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 + ctx.f29.f64));
	// fmsubs f4,f4,f24,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f28.f64));
	// lfs f24,108(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f27,f2,f23
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfsx f22,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f29,f5,f7
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// add r24,r31,r4
	ctx.r24.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fadds f7,f6,f8
	ctx.f7.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// mulli r30,r6,56
	ctx.r30.s64 = ctx.r6.s64 * 56;
	// fsubs f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fmuls f26,f1,f23
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// lfs f23,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f1,f1,f22,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f27.f64));
	// lfs f27,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// rlwinm r7,r6,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f8,f5,f12
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// add r23,r8,r3
	ctx.r23.u64 = ctx.r8.u64 + ctx.r3.u64;
	// fadds f28,f7,f30
	ctx.f28.f64 = double(float(ctx.f7.f64 + ctx.f30.f64));
	// add r22,r8,r4
	ctx.r22.u64 = ctx.r8.u64 + ctx.r4.u64;
	// fadds f5,f29,f31
	ctx.f5.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// add r21,r30,r4
	ctx.r21.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fnmsubs f7,f7,f11,f30
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f11.f64 - ctx.f30.f64)));
	// lfs f30,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f31,f29,f11,f31
	ctx.f31.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f31.f64)));
	// lfs f29,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f30,f21
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// add r20,r7,r3
	ctx.r20.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fmuls f21,f29,f21
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f21.f64));
	// add r19,r7,r4
	ctx.r19.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmsubs f2,f2,f22,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f26.f64));
	// lfs f26,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f26.f64 = double(temp.f32);
	// lfs f22,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f18,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f29,f29,f20,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfsx f19,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f30,f30,f20,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f21,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f27,f21
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fmuls f21,f26,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// rlwinm r29,r6,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fmuls f15,f24,f19
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// mulli r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 * 12;
	// fmuls f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmuls f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// fmuls f17,f23,f17
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmadds f26,f26,f20,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f16.f64));
	// add r17,r29,r4
	ctx.r17.u64 = ctx.r29.u64 + ctx.r4.u64;
	// mulli r7,r6,48
	ctx.r7.s64 = ctx.r6.s64 * 48;
	// fmsubs f21,f27,f20,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f27,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f25,f25,f18,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f23,f23,f27,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 - ctx.f14.f64));
	// fmadds f24,f24,f18,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f19.f64));
	// fmadds f27,f22,f27,f17
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 + ctx.f17.f64));
	// fadds f22,f26,f29
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f26,f26,f29
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// mulli r18,r6,52
	ctx.r18.s64 = ctx.r6.s64 * 52;
	// fadds f29,f21,f30
	ctx.f29.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// fsubs f20,f30,f21
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// fadds f30,f23,f25
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f21,f27,f24
	ctx.f21.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fsubs f24,f27,f24
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// rlwinm r28,r6,3,0,28
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// add r16,r18,r3
	ctx.r16.u64 = ctx.r18.u64 + ctx.r3.u64;
	// add r18,r18,r4
	ctx.r18.u64 = ctx.r18.u64 + ctx.r4.u64;
	// add r15,r28,r4
	ctx.r15.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fadds f19,f29,f4
	ctx.f19.f64 = double(float(ctx.f29.f64 + ctx.f4.f64));
	// fnmsubs f4,f29,f11,f4
	ctx.f4.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f4.f64)));
	// fmuls f27,f20,f12
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmuls f29,f25,f12
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fadds f18,f21,f1
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fnmsubs f1,f21,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f21.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// fadds f20,f22,f3
	ctx.f20.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// fnmsubs f3,f22,f11,f3
	ctx.f3.f64 = double(float(-(ctx.f22.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// fadds f22,f30,f2
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fnmsubs f2,f30,f11,f2
	ctx.f2.f64 = double(float(-(ctx.f30.f64 * ctx.f11.f64 - ctx.f2.f64)));
	// fadds f25,f4,f26
	ctx.f25.f64 = double(float(ctx.f4.f64 + ctx.f26.f64));
	// stfs f25,-320(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fsubs f4,f4,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f26.f64));
	// stfs f4,-352(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f26,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,-360(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fsubs f4,f1,f29
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfs f4,-348(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fadds f4,f29,f1
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// lfs f1,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,-356(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fsubs f30,f3,f27
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f27.f64));
	// lfsx f1,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// stfs f1,-336(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f17,f22,f19
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f19.f64));
	// lfsx f1,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f16,f2,f24
	ctx.f16.f64 = double(float(ctx.f2.f64 + ctx.f24.f64));
	// stfs f1,-340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fsubs f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// lfsx f1,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f27,f18,f20
	ctx.f27.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f4,-312(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfsx f4,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfs f24,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f15,f4
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// stfs f1,-332(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f25,f24,f4
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// lfsx f1,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,-328(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f29,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfs f4,96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	ctx.f4.f64 = double(temp.f32);
	// lfs f1,100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f4,f29
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f14,f1,f29
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// lfs f29,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f26.f64));
	// lfs f26,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f26.f64 = double(temp.f32);
	// stfs f29,-356(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fmr f29,f26
	ctx.f29.f64 = ctx.f26.f64;
	// lfs f26,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// mulli r14,r6,28
	ctx.r14.s64 = ctx.r6.s64 * 28;
	// fsubs f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f22.f64));
	// fmadds f25,f15,f29,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f29.f64 + ctx.f25.f64));
	// fmsubs f24,f24,f29,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 - ctx.f23.f64));
	// lfs f29,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f29.f64));
	// lfs f29,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f1,f1,f29,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f21.f64));
	// stfs f1,-364(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fmsubs f4,f4,f29,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f14.f64));
	// stfs f4,-368(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f29,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f29.f64 = double(temp.f32);
	// lfs f1,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f1,f29
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// lfs f4,88(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f4,f29
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// lfs f23,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f29.f64 = double(temp.f32);
	// stw r14,-336(r1)
	PPC_STORE_U32(ctx.r1.u32 + -336, ctx.r14.u32);
	// fmadds f26,f26,f23,f29
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f23.f64 + ctx.f29.f64));
	// lfs f29,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f29.f64 = double(temp.f32);
	// add r14,r14,r3
	ctx.r14.u64 = ctx.r14.u64 + ctx.r3.u64;
	// fmsubs f23,f29,f23,f15
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f23.f64 - ctx.f15.f64));
	// lfs f29,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f29.f64 = double(temp.f32);
	// fmsubs f4,f4,f29,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f14.f64));
	// stfs f4,-340(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fmadds f21,f1,f29,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f21.f64));
	// lfs f29,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f29.f64 = double(temp.f32);
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// lfs f4,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f4.f64 = double(temp.f32);
	// fadds f15,f4,f25
	ctx.f15.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// lfs f4,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f4,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// stfs f4,-360(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f4,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f14,f4,f29
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// stfs f15,-332(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fmuls f29,f1,f29
	ctx.f29.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// stfs f29,-328(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f29,0(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fadds f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f26.f64));
	// stfs f15,-356(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fmadds f19,f1,f29,f14
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f14.f64));
	// lfs f1,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f1.f64));
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f15,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f29,f4,f29,f14
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f14.f64));
	// lfs f4,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f4.f64 = double(temp.f32);
	// stw r14,-364(r1)
	PPC_STORE_U32(ctx.r1.u32 + -364, ctx.r14.u32);
	// fsubs f25,f4,f25
	ctx.f25.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// lwz r14,-336(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	// lfs f4,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f4,f11,f26
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f26.f64)));
	// add r14,r14,r4
	ctx.r14.u64 = ctx.r14.u64 + ctx.r4.u64;
	// fmuls f14,f22,f13
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// stw r14,-328(r1)
	PPC_STORE_U32(ctx.r1.u32 + -328, ctx.r14.u32);
	// fmuls f26,f25,f12
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f25,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f23
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f23.f64)));
	// fsubs f24,f4,f1
	ctx.f24.f64 = double(float(ctx.f4.f64 - ctx.f1.f64));
	// fadds f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// stfs f4,-316(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f1,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f1.f64 = double(temp.f32);
	// fadds f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f4,-368(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// fsubs f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f4,-360(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f4,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f4.f64 = double(temp.f32);
	// lwz r14,-364(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	// lfs f26,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f4,f26
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// fmuls f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lwz r14,-328(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	// lfs f25,0(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f1,f1,f25,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64 + ctx.f23.f64));
	// fmsubs f4,f4,f25,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64 - ctx.f26.f64));
	// fsubs f25,f1,f19
	ctx.f25.f64 = double(float(ctx.f1.f64 - ctx.f19.f64));
	// fadds f26,f1,f19
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f19.f64));
	// lfs f19,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f19.f64 = double(temp.f32);
	// fadds f1,f4,f29
	ctx.f1.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fsubs f29,f29,f4
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// lfs f18,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f4,f25,f12
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fadds f25,f26,f21
	ctx.f25.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// fadds f23,f1,f19
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f19.f64));
	// fnmsubs f26,f26,f11,f21
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// lfs f21,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// fnmsubs f1,f1,f11,f19
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f19.f64)));
	// fadds f21,f25,f21
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f21.f64));
	// fsubs f19,f15,f23
	ctx.f19.f64 = double(float(ctx.f15.f64 - ctx.f23.f64));
	// fadds f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f15.f64));
	// fsubs f15,f26,f29
	ctx.f15.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// fadds f29,f29,f26
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f26.f64));
	// fadds f26,f1,f4
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// fsubs f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 - ctx.f4.f64));
	// fsubs f25,f18,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 - ctx.f25.f64));
	// fadds f1,f21,f27
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// fsubs f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f27.f64));
	// fmuls f21,f19,f13
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// stfs f21,-328(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fmadds f21,f19,f0,f14
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f14.f64));
	// fsubs f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f17.f64));
	// fadds f19,f1,f5
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// stfs f19,0(r3)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fnmsubs f5,f1,f9,f5
	ctx.f5.f64 = double(float(-(ctx.f1.f64 * ctx.f9.f64 - ctx.f5.f64)));
	// fmuls f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// fadds f1,f5,f27
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f27.f64));
	// fsubs f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f27.f64));
	// lfs f27,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f19,f1,f21
	ctx.f19.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// stfsx f19,r9,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f19,f23,f17
	ctx.f19.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// lfs f17,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f4.f64));
	// stfs f17,-356(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// fadds f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f21.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// lfs f21,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f21.f64 = double(temp.f32);
	// fadds f1,f15,f24
	ctx.f1.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// fadds f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// lfs f23,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f2.f64));
	// lfs f17,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fsubs f27,f24,f15
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f15.f64));
	// fmuls f24,f20,f13
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fadds f4,f17,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 + ctx.f4.f64));
	// lfs f17,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f17.f64 = double(temp.f32);
	// fadds f2,f17,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// fmuls f17,f23,f13
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// stfs f27,-328(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// fsubs f27,f7,f8
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// stfs f27,-340(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// fadds f27,f21,f1
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// fmsubs f22,f22,f0,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 - ctx.f14.f64));
	// stfs f27,-332(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f27,f1,f21
	ctx.f27.f64 = double(float(ctx.f1.f64 - ctx.f21.f64));
	// fmuls f21,f25,f13
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmadds f25,f25,f0,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fsubs f14,f31,f6
	ctx.f14.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// fsubs f24,f5,f22
	ctx.f24.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfsx f24,r7,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// stfs f27,-336(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f27,f2,f4
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fadds f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// lfs f1,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f1,f13
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f24,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f1,f19,f9,f28
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f9.f64 - ctx.f28.f64)));
	// fadds f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f28.f64));
	// fmsubs f28,f20,f0,f21
	ctx.f28.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 - ctx.f21.f64));
	// fmadds f24,f24,f0,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f17.f64));
	// stfsx f5,r8,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fmsubs f5,f23,f0,f15
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 - ctx.f15.f64));
	// lfs f23,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f30,f13
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f22,f23,f13
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// stfs f19,0(r4)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f19,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f19.f64 = double(temp.f32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fadds f7,f31,f6
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// addi r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 + 112;
	// fmadds f23,f23,f0,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fmsubs f30,f30,f0,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f22.f64));
	// lfs f22,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f22,f14
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// fnmsubs f22,f22,f9,f14
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f9.f64 - ctx.f14.f64)));
	// fadds f21,f1,f18
	ctx.f21.f64 = double(float(ctx.f1.f64 + ctx.f18.f64));
	// fsubs f1,f1,f18
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f18.f64));
	// fadds f20,f19,f22
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fsubs f19,f21,f25
	ctx.f19.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// stfsx f19,r10,r4
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// stfsx f25,r9,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f25,f1,f28
	ctx.f25.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// stfsx f25,r8,r4
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f28.f64));
	// stfsx f1,r7,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// stfsx f17,r5,r3
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fsubs f19,f4,f2
	ctx.f19.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfs f21,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f21.f64 = double(temp.f32);
	// lwz r10,-324(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	// fadds f28,f29,f21
	ctx.f28.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// fsubs f6,f21,f29
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// add r4,r10,r4
	ctx.r4.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fsubs f1,f20,f24
	ctx.f1.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stfsx f1,r30,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fadds f1,f20,f24
	ctx.f1.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// stfsx f1,r31,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f1,f22,f5
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f5.f64));
	// stfsx f1,r28,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// lfs f24,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f24.f64 = double(temp.f32);
	// lfs f20,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f20.f64 = double(temp.f32);
	// fadds f1,f24,f16
	ctx.f1.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// stfsx f5,r29,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f20,f26
	ctx.f5.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// lfs f22,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f29,f19,f10
	ctx.f29.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fadds f25,f22,f3
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// add r3,r10,r3
	ctx.r3.u64 = ctx.r10.u64 + ctx.r3.u64;
	// fsubs f4,f3,f22
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// fsubs f3,f20,f26
	ctx.f3.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// lfs f26,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f31,f27,f9,f26
	ctx.f31.f64 = double(float(-(ctx.f27.f64 * ctx.f9.f64 - ctx.f26.f64)));
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// stfs f27,0(r27)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f2,f24,f16
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f16.f64));
	// fadds f27,f1,f5
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fsubs f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fadds f5,f25,f28
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fmuls f25,f6,f13
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fadds f26,f29,f31
	ctx.f26.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// fmuls f24,f4,f13
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f22,f3,f13
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f21,f2,f13
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fsubs f31,f31,f29
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// fadds f29,f27,f8
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f8.f64));
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fnmsubs f8,f27,f9,f8
	ctx.f8.f64 = double(float(-(ctx.f27.f64 * ctx.f9.f64 - ctx.f8.f64)));
	// fmuls f28,f28,f10
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// fmsubs f4,f4,f0,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fadds f25,f5,f7
	ctx.f25.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fnmsubs f7,f5,f9,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f9.f64 - ctx.f7.f64)));
	// fsubs f5,f26,f23
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// stfs f5,0(r24)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fadds f5,f26,f23
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f23.f64));
	// stfs f5,0(r21)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fmadds f6,f6,f0,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fmsubs f2,f2,f0,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f22.f64));
	// fmadds f3,f3,f0,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fadds f5,f31,f30
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f30.f64));
	// stfs f5,0(r15)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r15.u32 + 0, temp.u32);
	// fsubs f5,f31,f30
	ctx.f5.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// stfs f5,0(r17)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// fsubs f5,f8,f1
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// stfs f29,0(r25)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fadds f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f1.f64));
	// lwz r10,-364(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	// fsubs f1,f7,f28
	ctx.f1.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// fadds f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f28.f64));
	// fadds f31,f5,f4
	ctx.f31.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// stfs f31,0(r14)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r14.u32 + 0, temp.u32);
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// stfs f5,0(r18)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// fsubs f5,f8,f6
	ctx.f5.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f5,0(r22)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fadds f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,0(r19)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// stfs f25,0(r26)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfs f8,0(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fadds f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// stfs f8,0(r16)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fsubs f8,f7,f3
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfs f8,0(r20)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fadds f8,f7,f3
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f3.f64));
	// stfs f8,0(r23)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// lwz r10,-26212(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// lwz r10,-344(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,-344(r1)
	PPC_STORE_U32(ctx.r1.u32 + -344, ctx.r10.u32);
	// bne 0x82ca27d0
	if (!ctx.cr0.eq) goto loc_82CA27D0;
loc_82CA2EAC:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA2EB4;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA2EB8"))) PPC_WEAK_FUNC(sub_82CA2EB8);
PPC_FUNC_IMPL(__imp__sub_82CA2EB8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28088
	ctx.r5.s64 = ctx.r11.s64 + -28088;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,10096
	ctx.r4.s64 = ctx.r11.s64 + 10096;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA2ED0"))) PPC_WEAK_FUNC(sub_82CA2ED0);
PPC_FUNC_IMPL(__imp__sub_82CA2ED0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82CA2ED8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82CA2EE0;
	__savefpr_14(ctx, base);
	// mulli r11,r7,88
	ctx.r11.s64 = ctx.r7.s64 * 88;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82ca331c
	if (!ctx.cr6.lt) goto loc_82CA331C;
	// rlwinm r15,r9,2,0,29
	ctx.r15.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// subf r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// lfs f13,-29000(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29000);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f0.f64 = double(temp.f32);
loc_82CA2F0C:
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f12,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r9,r6,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f11,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// add r30,r10,r3
	ctx.r30.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lfs f10,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// add r28,r9,r3
	ctx.r28.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f9,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f9.f64 = double(temp.f32);
	// mulli r5,r6,20
	ctx.r5.s64 = ctx.r6.s64 * 20;
	// lfs f6,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f5,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// lfs f31,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f21,f12,f31
	ctx.f21.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// lfs f29,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f31,f11,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f8,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f20,f10,f29
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfs f1,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// add r29,r10,r4
	ctx.r29.u64 = ctx.r10.u64 + ctx.r4.u64;
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// rlwinm r31,r6,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f7,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f7.f64 = double(temp.f32);
	// add r25,r5,r3
	ctx.r25.u64 = ctx.r5.u64 + ctx.r3.u64;
	// lfs f4,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// add r27,r9,r4
	ctx.r27.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// add r24,r31,r3
	ctx.r24.u64 = ctx.r31.u64 + ctx.r3.u64;
	// mulli r7,r6,36
	ctx.r7.s64 = ctx.r6.s64 * 36;
	// lfs f30,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f11,f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f25,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f12,f12,f30,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f31.f64));
	// lfs f28,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f31,f6,f25
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfs f23,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f9,f9,f28,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f20.f64));
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// lfs f29,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f21,f2,f23
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f28,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f28.f64 = double(temp.f32);
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmuls f30,f5,f25
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// add r26,r7,r3
	ctx.r26.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fmuls f23,f1,f23
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// lfs f25,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f25.f64 = double(temp.f32);
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// rlwinm r23,r6,3,0,28
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r22,r6,40
	ctx.r22.s64 = ctx.r6.s64 * 40;
	// lfs f24,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// lfs f27,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f5,f5,f24,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f31.f64));
	// lfs f22,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fadds f31,f9,f11
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fmuls f19,f8,f27
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// lfs f26,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f9,f9,f11
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fadds f11,f10,f12
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// fmadds f1,f1,f22,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f21.f64));
	// add r21,r23,r3
	ctx.r21.u64 = ctx.r23.u64 + ctx.r3.u64;
	// fsubs f10,f12,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// add r20,r22,r3
	ctx.r20.u64 = ctx.r22.u64 + ctx.r3.u64;
	// fmsubs f2,f2,f22,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f23.f64));
	// mulli r10,r6,24
	ctx.r10.s64 = ctx.r6.s64 * 24;
	// fmsubs f6,f6,f24,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f30.f64));
	// lfs f24,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f7,f7,f26,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f19.f64));
	// fmuls f12,f9,f0
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fnmsubs f9,f31,f13,f4
	ctx.f9.f64 = double(float(-(ctx.f31.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfs f27,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f27.f64 = double(temp.f32);
	// fadds f23,f1,f5
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// lfs f26,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// mulli r9,r6,12
	ctx.r9.s64 = ctx.r6.s64 * 12;
	// fnmsubs f30,f11,f13,f3
	ctx.f30.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// fsubs f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// add r23,r23,r4
	ctx.r23.u64 = ctx.r23.u64 + ctx.r4.u64;
	// add r22,r22,r4
	ctx.r22.u64 = ctx.r22.u64 + ctx.r4.u64;
	// fadds f5,f2,f6
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// lfsx f19,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f16,f23,f13,f7
	ctx.f16.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// stfs f16,-316(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fsubs f2,f2,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f6.f64));
	// lfs f21,0(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f6,f1,f0
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f1,0(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f28,f1
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// lfs f22,0(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f27,f21
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// lfs f20,0(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f26,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// lfsx f18,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f7,f23,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 + ctx.f7.f64));
	// lfs f23,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f17,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// fadds f11,f11,f3
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// mulli r19,r6,44
	ctx.r19.s64 = ctx.r6.s64 * 44;
	// fnmsubs f16,f5,f13,f8
	ctx.f16.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// stfs f16,-312(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f16,f29,f1
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f1.f64));
	// mulli r18,r6,28
	ctx.r18.s64 = ctx.r6.s64 * 28;
	// fmuls f1,f25,f19
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// stfs f1,-320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fadds f8,f5,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f8.f64));
	// lfs f31,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f31.f64 = double(temp.f32);
	// fmsubs f29,f29,f22,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f22.f64 - ctx.f15.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmsubs f27,f27,f20,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f21.f64));
	// fmadds f1,f28,f22,f16
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f22.f64 + ctx.f16.f64));
	// fmadds f28,f26,f20,f14
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f14.f64));
	// lfs f20,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f24,f19
	ctx.f22.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// lfs f19,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f19.f64 = double(temp.f32);
	// add r17,r19,r3
	ctx.r17.u64 = ctx.r19.u64 + ctx.r3.u64;
	// add r16,r18,r3
	ctx.r16.u64 = ctx.r18.u64 + ctx.r3.u64;
	// add r19,r19,r4
	ctx.r19.u64 = ctx.r19.u64 + ctx.r4.u64;
	// add r18,r18,r4
	ctx.r18.u64 = ctx.r18.u64 + ctx.r4.u64;
	// fmsubs f25,f25,f18,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 - ctx.f22.f64));
	// lfs f21,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f24,f18,f21
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f21.f64));
	// lfs f21,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f21.f64 = double(temp.f32);
	// fadds f24,f28,f1
	ctx.f24.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f28,f1,f28
	ctx.f28.f64 = double(float(ctx.f1.f64 - ctx.f28.f64));
	// fadds f1,f27,f29
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fsubs f27,f27,f29
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// fmuls f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmuls f29,f28,f0
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fnmsubs f22,f1,f13,f25
	ctx.f22.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// fmuls f28,f27,f0
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f25.f64));
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f27,f24,f13,f26
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfsx f24,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// fadds f3,f11,f1
	ctx.f3.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// fsubs f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// fadds f5,f26,f4
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f4.f64));
	// fsubs f4,f4,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f26.f64));
	// fmadds f1,f25,f24,f18
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f25,0(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f26,f23,f24,f17
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f24.f64 - ctx.f17.f64));
	// lfs f23,0(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f21,f25
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// lfs f24,0(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f19,f23
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfs f18,0(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f20,f25
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmuls f23,f31,f23
	ctx.f23.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// fmadds f25,f20,f24,f17
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f24.f64 + ctx.f17.f64));
	// fmadds f31,f31,f18,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f18.f64 + ctx.f15.f64));
	// fmsubs f24,f21,f24,f16
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 - ctx.f16.f64));
	// fmsubs f23,f19,f18,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f18.f64 - ctx.f23.f64));
	// fadds f21,f31,f25
	ctx.f21.f64 = double(float(ctx.f31.f64 + ctx.f25.f64));
	// fsubs f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f31.f64));
	// fadds f31,f23,f24
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fadds f23,f21,f1
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f1.f64));
	// lfs f17,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f31,f26
	ctx.f20.f64 = double(float(ctx.f31.f64 + ctx.f26.f64));
	// lfs f16,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f31,f31,f13,f26
	ctx.f31.f64 = double(float(-(ctx.f31.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// fnmsubs f1,f21,f13,f1
	ctx.f1.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// addi r11,r11,88
	ctx.r11.s64 = ctx.r11.s64 + 88;
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fadds f18,f16,f6
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f6.f64));
	// fsubs f6,f16,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 - ctx.f6.f64));
	// fadds f26,f7,f23
	ctx.f26.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// fsubs f7,f23,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 - ctx.f7.f64));
	// fadds f23,f8,f20
	ctx.f23.f64 = double(float(ctx.f8.f64 + ctx.f20.f64));
	// fsubs f8,f20,f8
	ctx.f8.f64 = double(float(ctx.f20.f64 - ctx.f8.f64));
	// fadds f19,f31,f25
	ctx.f19.f64 = double(float(ctx.f31.f64 + ctx.f25.f64));
	// fadds f20,f22,f29
	ctx.f20.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// fsubs f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// fsubs f31,f31,f25
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f25.f64));
	// fsubs f21,f5,f26
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// stfsx f21,r10,r3
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// fsubs f26,f3,f23
	ctx.f26.f64 = double(float(ctx.f3.f64 - ctx.f23.f64));
	// stfsx f26,r10,r4
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// stfs f5,0(r3)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f5,f23,f3
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f5,0(r4)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f5,f4,f8
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// stfsx f5,r9,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f5,f7,f11
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f5,r9,r4
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f5,f9,f10
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fadds f3,f27,f28
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// add r3,r15,r3
	ctx.r3.u64 = ctx.r15.u64 + ctx.r3.u64;
	// fadds f26,f1,f24
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// add r4,r15,r4
	ctx.r4.u64 = ctx.r15.u64 + ctx.r4.u64;
	// fadds f23,f17,f2
	ctx.f23.f64 = double(float(ctx.f17.f64 + ctx.f2.f64));
	// fadds f21,f30,f12
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f12.f64));
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fsubs f9,f27,f28
	ctx.f9.f64 = double(float(ctx.f27.f64 - ctx.f28.f64));
	// fsubs f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// fsubs f2,f17,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 - ctx.f2.f64));
	// fsubs f12,f30,f12
	ctx.f12.f64 = double(float(ctx.f30.f64 - ctx.f12.f64));
	// fadds f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// stfs f8,0(r26)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fsubs f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfs f11,0(r7)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fadds f11,f3,f5
	ctx.f11.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fadds f7,f23,f26
	ctx.f7.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fadds f4,f20,f21
	ctx.f4.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f30,f18,f19
	ctx.f30.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fadds f27,f9,f10
	ctx.f27.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f9,f2,f1
	ctx.f9.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// fsubs f8,f5,f3
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fsubs f28,f19,f18
	ctx.f28.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// fadds f1,f12,f29
	ctx.f1.f64 = double(float(ctx.f12.f64 + ctx.f29.f64));
	// fsubs f5,f26,f23
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// fsubs f3,f21,f20
	ctx.f3.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fsubs f12,f12,f29
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f29.f64));
	// fadds f29,f6,f31
	ctx.f29.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// fsubs f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// fsubs f31,f11,f7
	ctx.f31.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfs f31,0(r20)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// fsubs f31,f4,f30
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// stfs f31,0(r22)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// fadds f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfs f11,0(r30)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fadds f11,f30,f4
	ctx.f11.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// stfs f11,0(r29)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fsubs f11,f8,f28
	ctx.f11.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// stfs f11,0(r16)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r16.u32 + 0, temp.u32);
	// fadds f11,f28,f8
	ctx.f11.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// fadds f7,f5,f3
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// stfs f7,0(r18)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r18.u32 + 0, temp.u32);
	// stfs f11,0(r24)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fsubs f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fsubs f11,f27,f9
	ctx.f11.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// stfs f8,0(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// stfs f11,0(r21)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r21.u32 + 0, temp.u32);
	// fsubs f8,f1,f29
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfs f8,0(r23)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r23.u32 + 0, temp.u32);
	// fadds f11,f2,f12
	ctx.f11.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f9,f29,f1
	ctx.f9.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f9,f10,f6
	ctx.f9.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// stfs f9,0(r17)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r17.u32 + 0, temp.u32);
	// fadds f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// stfs f11,0(r19)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// fsubs f12,f12,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f2.f64));
	// stfs f10,0(r25)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lwz r10,-26212(r14)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r14.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82ca2f0c
	if (!ctx.cr0.eq) goto loc_82CA2F0C;
loc_82CA331C:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA3324;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA3328"))) PPC_WEAK_FUNC(sub_82CA3328);
PPC_FUNC_IMPL(__imp__sub_82CA3328) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-28016
	ctx.r5.s64 = ctx.r11.s64 + -28016;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,11984
	ctx.r4.s64 = ctx.r11.s64 + 11984;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA3340"))) PPC_WEAK_FUNC(sub_82CA3340);
PPC_FUNC_IMPL(__imp__sub_82CA3340) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82CA3348;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82d5c540
	ctx.lr = 0x82CA3350;
	__savefpr_14(ctx, base);
	// mulli r11,r7,72
	ctx.r11.s64 = ctx.r7.s64 * 72;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82ca3708
	if (!ctx.cr6.lt) goto loc_82CA3708;
	// subf r23,r7,r8
	ctx.r23.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r22,r9,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32235
	ctx.r7.s64 = -2112552960;
	// lis r8,-32235
	ctx.r8.s64 = -2112552960;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f13,28204(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 28204);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28208(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 28208);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,-12748(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -12748);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,28200(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28200);
	ctx.f12.f64 = double(temp.f32);
loc_82CA338C:
	// mulli r10,r6,20
	ctx.r10.s64 = ctx.r6.s64 * 20;
	// lfs f10,32(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f6,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f29,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f10,f29
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfsx f28,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// lfs f4,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r31,r6,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f2,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f2.f64 = double(temp.f32);
	// mulli r8,r6,36
	ctx.r8.s64 = ctx.r6.s64 * 36;
	// lfs f7,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f3,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f1.f64 = double(temp.f32);
	// lfs f31,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f25,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f27,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f23,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f8,f27
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmadds f9,f9,f28,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f19.f64));
	// lfsx f24,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r30,r6,24
	ctx.r30.s64 = ctx.r6.s64 * 24;
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmuls f29,f6,f25
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfsx f22,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f28,f5,f25
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// lfs f30,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f4,f23
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfsx f21,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f2,f21
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// fmuls f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// add r29,r31,r4
	ctx.r29.u64 = ctx.r31.u64 + ctx.r4.u64;
	// add r28,r30,r4
	ctx.r28.u64 = ctx.r30.u64 + ctx.r4.u64;
	// rlwinm r27,r6,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f5,f5,f24,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f29.f64));
	// rlwinm r26,r6,5,0,26
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// fmsubs f6,f6,f24,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f28.f64));
	// add r25,r27,r3
	ctx.r25.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fmadds f3,f3,f22,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f25.f64));
	// lfs f28,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f29,f31,f9
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f9.f64));
	// lfs f20,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// fmsubs f4,f4,f22,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f23.f64));
	// lfs f27,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f1,f1,f20,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfs f25,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f2,f2,f20,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f20.f64 - ctx.f21.f64));
	// lfs f23,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f7,f7,f26,f18
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f18.f64));
	// lfs f21,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// fadds f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// lfs f19,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f31,f30,f10
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f10.f64));
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// fadds f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f30.f64));
	// lfs f30,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fadds f22,f4,f8
	ctx.f22.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// fadds f20,f2,f6
	ctx.f20.f64 = double(float(ctx.f2.f64 + ctx.f6.f64));
	// mulli r5,r6,28
	ctx.r5.s64 = ctx.r6.s64 * 28;
	// fsubs f6,f2,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 - ctx.f6.f64));
	// fsubs f26,f7,f3
	ctx.f26.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fsubs f24,f1,f5
	ctx.f24.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// lfs f3,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// add r27,r27,r4
	ctx.r27.u64 = ctx.r27.u64 + ctx.r4.u64;
	// add r24,r26,r3
	ctx.r24.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fadds f2,f20,f22
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f2,-244(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// fadds f2,f6,f8
	ctx.f2.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// stfs f2,-248(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fadds f4,f24,f26
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfsx f17,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// add r26,r26,r4
	ctx.r26.u64 = ctx.r26.u64 + ctx.r4.u64;
	// stfs f17,-256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// lfs f2,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,-252(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmuls f16,f30,f2
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// fmuls f2,f28,f2
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// lfs f1,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f18,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f25,f18
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f18.f64));
	// fmuls f15,f27,f18
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f18,f23,f17
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fmuls f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// fmadds f28,f28,f1,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f1.f64 + ctx.f16.f64));
	// fmsubs f1,f30,f1,f2
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 - ctx.f2.f64));
	// lfs f2,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f2.f64 = double(temp.f32);
	// stfs f18,-256(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fmr f18,f2
	ctx.f18.f64 = ctx.f2.f64;
	// lfs f2,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f19,f2
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// fmadds f30,f25,f18,f15
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 + ctx.f15.f64));
	// fmuls f15,f3,f2
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f2,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f23,f23,f2,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f17.f64));
	// fmsubs f27,f27,f18,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 - ctx.f14.f64));
	// lfs f25,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f21,f2,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 + ctx.f25.f64));
	// lfs f2,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f3,f3,f2,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f2.f64 + ctx.f16.f64));
	// fmsubs f2,f19,f2,f15
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 - ctx.f15.f64));
	// fsubs f21,f28,f25
	ctx.f21.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// fsubs f19,f3,f30
	ctx.f19.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fadds f28,f25,f28
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// fadds f30,f3,f30
	ctx.f30.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// fadds f18,f2,f27
	ctx.f18.f64 = double(float(ctx.f2.f64 + ctx.f27.f64));
	// fadds f25,f23,f1
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// fsubs f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// fsubs f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f27.f64));
	// fadds f3,f5,f7
	ctx.f3.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fadds f17,f19,f21
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f6,f21,f19
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fadds f16,f30,f28
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fadds f15,f18,f25
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f25.f64));
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fadds f27,f17,f4
	ctx.f27.f64 = double(float(ctx.f17.f64 + ctx.f4.f64));
	// fsubs f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f4.f64));
	// fsubs f4,f26,f24
	ctx.f4.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// fsubs f26,f22,f20
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f2,f1
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// fadds f23,f16,f3
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f3.f64));
	// fsubs f24,f16,f3
	ctx.f24.f64 = double(float(ctx.f16.f64 - ctx.f3.f64));
	// fmuls f19,f6,f13
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f20,f8,f13
	ctx.f20.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fnmsubs f1,f27,f11,f29
	ctx.f1.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f29.f64)));
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f29,r10,r3
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fmuls f3,f17,f12
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f18,f4,f13
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f17,f26,f13
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f29,f25,f13
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fnmsubs f21,f23,f11,f9
	ctx.f21.f64 = double(float(-(ctx.f23.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// fadds f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f9.f64));
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmsubs f4,f4,f0,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fmadds f9,f6,f0,f18
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f18.f64));
	// fmadds f6,f25,f0,f17
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f17.f64));
	// fmsubs f29,f26,f0,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 - ctx.f29.f64));
	// lfs f26,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f2,f13
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fadds f27,f22,f26
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fmadds f2,f2,f0,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f20.f64));
	// fmsubs f8,f8,f0,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fsubs f25,f1,f3
	ctx.f25.f64 = double(float(ctx.f1.f64 - ctx.f3.f64));
	// fadds f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fadds f1,f21,f24
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f24.f64));
	// fadds f22,f27,f31
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// fnmsubs f31,f27,f11,f31
	ctx.f31.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f31.f64)));
	// addi r11,r11,72
	ctx.r11.s64 = ctx.r11.s64 + 72;
	// fsubs f27,f25,f8
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f8.f64));
	// stfsx f27,r5,r3
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f25,f8
	ctx.f8.f64 = double(float(ctx.f25.f64 + ctx.f8.f64));
	// stfsx f8,r7,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fsubs f8,f3,f2
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// stfsx f8,r8,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f8,f3,f2
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// stfsx f8,r9,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f3,f1,f6
	ctx.f3.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
	// stfsx f22,r10,r4
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f2,f1,f6
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fsubs f8,f31,f26
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f26.f64));
	// fadds f6,f31,f26
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f26.f64));
	// fsubs f1,f8,f4
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// stfsx f1,r7,r4
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fadds f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// stfsx f8,r5,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f6,f9
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f9.f64));
	// stfsx f8,r9,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// lfs f6,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f6.f64 = double(temp.f32);
	// stfsx f9,r8,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fsubs f8,f7,f5
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// fadds f9,f15,f6
	ctx.f9.f64 = double(float(ctx.f15.f64 + ctx.f6.f64));
	// stfs f23,0(r3)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f5,f15,f6
	ctx.f5.f64 = double(float(ctx.f15.f64 - ctx.f6.f64));
	// stfsx f3,r31,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f28,f30
	ctx.f7.f64 = double(float(ctx.f28.f64 - ctx.f30.f64));
	// stfsx f2,r30,r3
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r3.u32, temp.u32);
	// fsubs f6,f21,f24
	ctx.f6.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// add r3,r22,r3
	ctx.r3.u64 = ctx.r22.u64 + ctx.r3.u64;
	// fmuls f4,f8,f13
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fadds f2,f9,f10
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fnmsubs f10,f9,f11,f10
	ctx.f10.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f3,f7,f13
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fsubs f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 - ctx.f29.f64));
	// stfs f1,0(r25)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fadds f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// stfs f6,0(r24)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// stfs f2,0(r4)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// add r4,r22,r4
	ctx.r4.u64 = ctx.r22.u64 + ctx.r4.u64;
	// fmadds f9,f7,f0,f4
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fadds f7,f10,f5
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
	// fmsubs f8,f8,f0,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f3.f64));
	// fsubs f10,f10,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f5.f64));
	// fadds f6,f7,f9
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// stfs f6,0(r29)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f9,f10,f8
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// stfs f10,0(r26)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// lwz r10,-26212(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82ca338c
	if (!ctx.cr0.eq) goto loc_82CA338C;
loc_82CA3708:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA3710;
	__restfpr_14(ctx, base);
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA3718"))) PPC_WEAK_FUNC(sub_82CA3718);
PPC_FUNC_IMPL(__imp__sub_82CA3718) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27944
	ctx.r5.s64 = ctx.r11.s64 + -27944;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,13120
	ctx.r4.s64 = ctx.r11.s64 + 13120;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA3730"))) PPC_WEAK_FUNC(sub_82CA3730);
PPC_FUNC_IMPL(__imp__sub_82CA3730) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b4
	ctx.lr = 0x82CA3738;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c540
	ctx.lr = 0x82CA3740;
	__savefpr_14(ctx, base);
	// rlwinm r11,r7,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82ca3af8
	if (!ctx.cr6.lt) goto loc_82CA3AF8;
	// subf r25,r7,r8
	ctx.r25.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32235
	ctx.r8.s64 = -2112552960;
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lis r7,-32235
	ctx.r7.s64 = -2112552960;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lfs f12,29652(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 29652);
	ctx.f12.f64 = double(temp.f32);
	// lis r5,-32235
	ctx.r5.s64 = -2112552960;
	// lfs f10,30716(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 30716);
	ctx.f10.f64 = double(temp.f32);
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// stfs f12,-248(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f12,29648(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 29648);
	ctx.f12.f64 = double(temp.f32);
	// stfs f10,-240(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f10,30712(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 30712);
	ctx.f10.f64 = double(temp.f32);
	// stfs f12,-252(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f13,-29000(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29000);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,29636(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 29636);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,29632(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 29632);
	ctx.f11.f64 = double(temp.f32);
	// stfs f10,-244(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
loc_82CA37AC:
	// mulli r9,r6,24
	ctx.r9.s64 = ctx.r6.s64 * 24;
	// lfs f8,40(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f8.f64 = double(temp.f32);
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f7,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f4,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f27,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f8,f27
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// lfsx f26,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// lfs f31,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f31.f64 = double(temp.f32);
	// lfs f3,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// lfs f30,60(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 60);
	ctx.f30.f64 = double(temp.f32);
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f29,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f10,f29
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfsx f28,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r7,r6,20
	ctx.r7.s64 = ctx.r6.s64 * 20;
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmadds f7,f7,f26,f18
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f18.f64));
	// lfs f1,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// rlwinm r5,r6,5,0,26
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 5) & 0xFFFFFFE0;
	// add r29,r7,r3
	ctx.r29.u64 = ctx.r7.u64 + ctx.r3.u64;
	// fmadds f9,f9,f28,f19
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f19.f64));
	// add r27,r5,r3
	ctx.r27.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r28,r7,r4
	ctx.r28.u64 = ctx.r7.u64 + ctx.r4.u64;
	// add r31,r8,r3
	ctx.r31.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r26,r5,r4
	ctx.r26.u64 = ctx.r5.u64 + ctx.r4.u64;
	// lfs f23,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// add r30,r8,r4
	ctx.r30.u64 = ctx.r8.u64 + ctx.r4.u64;
	// lfs f21,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f27,f4,f23
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f19,f31,f21
	ctx.f19.f64 = double(float(ctx.f31.f64 * ctx.f21.f64));
	// rlwinm r8,r6,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f26,f3,f23
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f22,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// lfs f25,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// lfs f20,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f29,f6,f25
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfs f24,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f28,f5,f25
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// mulli r7,r6,28
	ctx.r7.s64 = ctx.r6.s64 * 28;
	// lfs f25,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f3,f3,f22,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f27.f64));
	// lfs f27,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f30,f30,f20,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 + ctx.f19.f64));
	// lfsx f18,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f4,f4,f22,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f26.f64));
	// lfsx f19,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f31,f31,f20,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f20.f64 - ctx.f21.f64));
	// rlwinm r5,r6,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f5,f5,f24,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f29.f64));
	// lfs f26,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f26.f64 = double(temp.f32);
	// fadds f29,f7,f9
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// lfs f22,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f7,f7,f9
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// lfsx f20,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f9,f8,f10
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f8,f10,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fmsubs f6,f6,f24,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f28.f64));
	// lfsx f17,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f24,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f24.f64 = double(temp.f32);
	// fadds f21,f30,f3
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fsubs f30,f30,f3
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f3.f64));
	// fadds f3,f31,f4
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// fsubs f31,f4,f31
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// fmuls f10,f7,f0
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fnmsubs f7,f29,f13,f2
	ctx.f7.f64 = double(float(-(ctx.f29.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f28,f9,f13,f1
	ctx.f28.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// fmuls f4,f30,f0
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// lfsx f30,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fadds f14,f3,f6
	ctx.f14.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// lfsx f16,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f6,f3,f13,f6
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// stfs f6,-256(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fmuls f3,f25,f19
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// fmuls f6,f27,f30
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fadds f15,f21,f5
	ctx.f15.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// fmuls f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fnmsubs f5,f21,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fmuls f21,f24,f19
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// fmuls f19,f23,f17
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fadds f9,f9,f1
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fadds f1,f7,f8
	ctx.f1.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fmadds f3,f24,f18,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f3.f64));
	// fmuls f24,f22,f17
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmadds f6,f26,f20,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f6.f64));
	// fmsubs f30,f27,f20,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f20.f64 - ctx.f30.f64));
	// lfs f20,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fmsubs f27,f25,f18,f21
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f18.f64 - ctx.f21.f64));
	// fmadds f26,f22,f16,f19
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f19.f64));
	// lfs f19,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f19.f64 = double(temp.f32);
	// fadds f29,f28,f10
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fsubs f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f10.f64));
	// fmsubs f25,f23,f16,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 - ctx.f24.f64));
	// fadds f24,f31,f5
	ctx.f24.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// fsubs f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// fsubs f22,f30,f27
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// fadds f30,f27,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f30.f64));
	// fmuls f17,f24,f11
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// fmuls f16,f24,f12
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f27,f22,f0
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fadds f21,f30,f25
	ctx.f21.f64 = double(float(ctx.f30.f64 + ctx.f25.f64));
	// lfs f23,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f23.f64 = double(temp.f32);
	// fadds f31,f23,f4
	ctx.f31.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// fsubs f4,f23,f4
	ctx.f4.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// fadds f23,f3,f6
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fnmsubs f3,f30,f13,f25
	ctx.f3.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// fadds f25,f21,f14
	ctx.f25.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fsubs f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// fmadds f24,f31,f12,f17
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmsubs f31,f31,f11,f16
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f11.f64 - ctx.f16.f64));
	// fadds f22,f23,f26
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fnmsubs f26,f23,f13,f26
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f7,f21,f0
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fadds f30,f22,f15
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// fadds f23,f27,f26
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fsubs f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// fadds f26,f3,f6
	ctx.f26.f64 = double(float(ctx.f3.f64 + ctx.f6.f64));
	// fsubs f6,f3,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 - ctx.f6.f64));
	// fadds f3,f30,f2
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// stfs f3,0(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f18,f23,f19
	ctx.f18.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// fmuls f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// fnmsubs f3,f30,f13,f2
	ctx.f3.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// fmuls f28,f22,f0
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fadds f22,f9,f25
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f25.f64));
	// fnmsubs f9,f25,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f25.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fmuls f25,f27,f11
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fmadds f2,f26,f20,f18
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f18.f64));
	// fmsubs f30,f26,f19,f23
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 - ctx.f23.f64));
	// fadds f26,f3,f7
	ctx.f26.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfsx f26,r10,r3
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fsubs f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 - ctx.f7.f64));
	// stfsx f7,r9,r3
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// stfs f22,0(r4)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f7,f9,f28
	ctx.f7.f64 = double(float(ctx.f9.f64 - ctx.f28.f64));
	// stfsx f7,r9,r4
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f28.f64));
	// stfsx f9,r10,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f24,f2
	ctx.f9.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// fsubs f3,f30,f31
	ctx.f3.f64 = double(float(ctx.f30.f64 - ctx.f31.f64));
	// fsubs f2,f24,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 - ctx.f2.f64));
	// fadds f7,f31,f30
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f30.f64));
	// fadds f31,f9,f1
	ctx.f31.f64 = double(float(ctx.f9.f64 + ctx.f1.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fnmsubs f9,f9,f13,f1
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// stfsx f31,r5,r3
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f31,f7,f29
	ctx.f31.f64 = double(float(ctx.f7.f64 + ctx.f29.f64));
	// stfsx f31,r5,r4
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r4.u32, temp.u32);
	// fnmsubs f7,f7,f13,f29
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// addi r11,r11,64
	ctx.r11.s64 = ctx.r11.s64 + 64;
	// fsubs f1,f9,f3
	ctx.f1.f64 = double(float(ctx.f9.f64 - ctx.f3.f64));
	// stfsx f1,r7,r3
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f9,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// stfsx f9,r8,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f7,f2
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// stfsx f9,r8,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// lfs f3,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f9,f7,f2
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// lfs f7,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f5,f3
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fmuls f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// stfsx f9,r7,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r4.u32, temp.u32);
	// fmuls f1,f27,f12
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// add r3,r3,r24
	ctx.r3.u64 = ctx.r3.u64 + ctx.r24.u64;
	// fmadds f9,f6,f12,f25
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f25.f64));
	// add r4,r4,r24
	ctx.r4.u64 = ctx.r4.u64 + ctx.r24.u64;
	// fmsubs f7,f4,f7,f2
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 - ctx.f2.f64));
	// fmadds f5,f4,f3,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f5.f64));
	// fmsubs f6,f6,f11,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64 - ctx.f1.f64));
	// fadds f4,f7,f9
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fsubs f7,f7,f9
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fsubs f9,f6,f5
	ctx.f9.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fadds f5,f4,f8
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// stfs f5,0(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fnmsubs f8,f4,f13,f8
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// fadds f5,f9,f10
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfs f5,0(r30)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f10,f9,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fsubs f9,f8,f6
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfs f9,0(r27)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f9,f8,f6
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f9,0(r29)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f9,f10,f7
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fsubs f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// stfs f10,0(r26)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// lwz r10,-26212(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82ca37ac
	if (!ctx.cr0.eq) goto loc_82CA37AC;
loc_82CA3AF8:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA3B00;
	__restfpr_14(ctx, base);
	// b 0x82d5c504
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA3B08"))) PPC_WEAK_FUNC(sub_82CA3B08);
PPC_FUNC_IMPL(__imp__sub_82CA3B08) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27872
	ctx.r5.s64 = ctx.r11.s64 + -27872;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,14128
	ctx.r4.s64 = ctx.r11.s64 + 14128;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA3B20"))) PPC_WEAK_FUNC(sub_82CA3B20);
PPC_FUNC_IMPL(__imp__sub_82CA3B20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b4
	ctx.lr = 0x82CA3B28;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c554
	ctx.lr = 0x82CA3B30;
	__savefpr_19(ctx, base);
	// mulli r11,r7,56
	ctx.r11.s64 = ctx.r7.s64 * 56;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82ca3da4
	if (!ctx.cr6.lt) goto loc_82CA3DA4;
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r29,r7,r8
	ctx.r29.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f0,-29652(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82CA3B54:
	// rlwinm r10,r6,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f13,24(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// mulli r7,r6,28
	ctx.r7.s64 = ctx.r6.s64 * 28;
	// lfs f12,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f1,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f30,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f13,f1
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmuls f21,f11,f30
	ctx.f21.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfsx f31,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f1,f12,f1
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// mulli r5,r6,12
	ctx.r5.s64 = ctx.r6.s64 * 12;
	// fmuls f30,f10,f30
	ctx.f30.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f7,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f5.f64 = double(temp.f32);
	// lfs f8,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f28,r5,r3
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f9,f28
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// lfs f3,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r9,r6,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// fmadds f12,f12,f31,f22
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64 + ctx.f22.f64));
	// add r28,r7,r4
	ctx.r28.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmuls f28,f8,f28
	ctx.f28.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// mulli r8,r6,24
	ctx.r8.s64 = ctx.r6.s64 * 24;
	// fmsubs f13,f13,f31,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f1.f64));
	// lfs f2,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f26,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfs f29,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f7,f26
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// lfsx f24,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f31,f6,f26
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmsubs f11,f11,f29,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f29.f64 - ctx.f30.f64));
	// lfsx f25,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f5,f24
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// add r27,r5,r4
	ctx.r27.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmuls f26,f4,f24
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// lfsx f23,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f10,f10,f29,f21
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f29.f64 + ctx.f21.f64));
	// rlwinm r31,r6,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r30,r6,20
	ctx.r30.s64 = ctx.r6.s64 * 20;
	// lfs f29,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f29.f64 = double(temp.f32);
	// lfs f27,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f8,f8,f27,f20
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64 + ctx.f20.f64));
	// lfsx f24,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f6,f6,f25,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64 + ctx.f1.f64));
	// fmsubs f7,f7,f25,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64 - ctx.f31.f64));
	// lfsx f25,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f1,f4,f23,f30
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f23.f64 + ctx.f30.f64));
	// add r26,r31,r3
	ctx.r26.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fmsubs f5,f5,f23,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64 - ctx.f26.f64));
	// add r25,r30,r3
	ctx.r25.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fmsubs f9,f9,f27,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64 - ctx.f28.f64));
	// lfs f28,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// fadds f31,f12,f3
	ctx.f31.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// fsubs f12,f3,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 - ctx.f12.f64));
	// fsubs f30,f2,f13
	ctx.f30.f64 = double(float(ctx.f2.f64 - ctx.f13.f64));
	// fadds f13,f13,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f2.f64));
	// lfs f2,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// fadds f3,f8,f10
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// lfs f23,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fadds f27,f1,f6
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fadds f26,f5,f7
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// lfs f9,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f6,f6,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// lfs f5,0(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f9,f5
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fadds f1,f27,f31
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fadds f22,f26,f13
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f13.f64));
	// fsubs f31,f31,f27
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fsubs f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f26.f64));
	// fadds f4,f11,f10
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// fsubs f27,f30,f6
	ctx.f27.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// fsubs f26,f12,f7
	ctx.f26.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fmuls f19,f29,f23
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f23.f64));
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// fmuls f20,f2,f5
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// addi r11,r11,56
	ctx.r11.s64 = ctx.r11.s64 + 56;
	// fmuls f23,f28,f23
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmadds f5,f2,f24,f21
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f24.f64 + ctx.f21.f64));
	// fsubs f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// fadds f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f12.f64));
	// fadds f10,f6,f30
	ctx.f10.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// fmadds f2,f28,f25,f19
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f25.f64 + ctx.f19.f64));
	// fmsubs f9,f9,f24,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f24.f64 - ctx.f20.f64));
	// fmsubs f29,f29,f25,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f25.f64 - ctx.f23.f64));
	// fsubs f28,f5,f2
	ctx.f28.f64 = double(float(ctx.f5.f64 - ctx.f2.f64));
	// fadds f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fsubs f2,f9,f29
	ctx.f2.f64 = double(float(ctx.f9.f64 - ctx.f29.f64));
	// fadds f9,f29,f9
	ctx.f9.f64 = double(float(ctx.f29.f64 + ctx.f9.f64));
	// fadds f29,f5,f3
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fsubs f25,f2,f28
	ctx.f25.f64 = double(float(ctx.f2.f64 - ctx.f28.f64));
	// fadds f24,f9,f8
	ctx.f24.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fsubs f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fsubs f5,f1,f29
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f29.f64));
	// stfsx f5,r10,r3
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f3,f29,f1
	ctx.f3.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// stfs f3,0(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f5,f25,f4
	ctx.f5.f64 = double(float(ctx.f25.f64 - ctx.f4.f64));
	// fadds f3,f22,f24
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// stfs f3,0(r4)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fadds f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// fsubs f3,f22,f24
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f3,f31,f9
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f9.f64));
	// stfsx f3,r8,r3
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f31.f64));
	// stfsx f9,r9,r3
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f9,f13,f8
	ctx.f9.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fsubs f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f8.f64));
	// stfsx f13,r8,r4
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fmuls f13,f5,f0
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f9,f4,f0
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fsubs f8,f26,f13
	ctx.f8.f64 = double(float(ctx.f26.f64 - ctx.f13.f64));
	// stfsx f8,r7,r3
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f26.f64));
	// fsubs f8,f27,f9
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// stfsx f8,r30,r4
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r4.u32, temp.u32);
	// stfsx f13,r5,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f2,f28
	ctx.f13.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// fadds f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// stfsx f9,r31,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r4.u32, temp.u32);
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fadds f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fmuls f13,f9,f0
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fsubs f9,f12,f13
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfs f9,0(r25)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + 0, temp.u32);
	// fsubs f9,f10,f11
	ctx.f9.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// stfs f9,0(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// stfs f13,0(r26)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r26.u32 + 0, temp.u32);
	// fadds f13,f11,f10
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// stfs f13,0(r27)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// lwz r10,-26212(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82ca3b54
	if (!ctx.cr0.eq) goto loc_82CA3B54;
loc_82CA3DA4:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c5a0
	ctx.lr = 0x82CA3DAC;
	__restfpr_19(ctx, base);
	// b 0x82d5c504
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA3DB0"))) PPC_WEAK_FUNC(sub_82CA3DB0);
PPC_FUNC_IMPL(__imp__sub_82CA3DB0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27800
	ctx.r5.s64 = ctx.r11.s64 + -27800;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,15136
	ctx.r4.s64 = ctx.r11.s64 + 15136;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA3DC8"))) PPC_WEAK_FUNC(sub_82CA3DC8);
PPC_FUNC_IMPL(__imp__sub_82CA3DC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82CA3DD0;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82d5c540
	ctx.lr = 0x82CA3DD8;
	__savefpr_14(ctx, base);
	// mulli r11,r7,48
	ctx.r11.s64 = ctx.r7.s64 * 48;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82ca40a0
	if (!ctx.cr6.lt) goto loc_82CA40A0;
	// subf r26,r7,r8
	ctx.r26.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r25,r9,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lis r5,-32235
	ctx.r5.s64 = -2112552960;
	// lis r7,-32235
	ctx.r7.s64 = -2112552960;
	// lis r8,-32235
	ctx.r8.s64 = -2112552960;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f9,30852(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 30852);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,30848(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 30848);
	ctx.f10.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f11,30844(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 30844);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,30832(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 30832);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,30840(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 30840);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,30836(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 30836);
	ctx.f0.f64 = double(temp.f32);
loc_82CA3E24:
	// rlwinm r8,r6,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f6,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// mulli r7,r6,24
	ctx.r7.s64 = ctx.r6.s64 * 24;
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f4.f64 = double(temp.f32);
	// lfs f31,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f31.f64 = double(temp.f32);
	// lfs f3,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f30,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// add r31,r8,r3
	ctx.r31.u64 = ctx.r8.u64 + ctx.r3.u64;
	// lfs f27,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f27.f64 = double(temp.f32);
	// add r30,r7,r3
	ctx.r30.u64 = ctx.r7.u64 + ctx.r3.u64;
	// lfs f26,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f26.f64 = double(temp.f32);
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// mulli r9,r6,20
	ctx.r9.s64 = ctx.r6.s64 * 20;
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f29,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfs f25,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f6,f29
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfsx f23,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f29,f5,f29
	ctx.f29.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfsx f21,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f4,f25
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// fmuls f15,f2,f23
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r5,r6,12
	ctx.r5.s64 = ctx.r6.s64 * 12;
	// fmuls f25,f3,f25
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// fmuls f14,f31,f21
	ctx.f14.f64 = double(float(ctx.f31.f64 * ctx.f21.f64));
	// lfsx f20,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f23,f1,f23
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// add r29,r5,r3
	ctx.r29.u64 = ctx.r5.u64 + ctx.r3.u64;
	// fmadds f1,f1,f22,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64 + ctx.f15.f64));
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// add r5,r5,r4
	ctx.r5.u64 = ctx.r5.u64 + ctx.r4.u64;
	// fmsubs f2,f2,f22,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f23.f64));
	// rlwinm r28,r6,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f28,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f19,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f29,f6,f28,f29
	ctx.f29.f64 = double(float(ctx.f6.f64 * ctx.f28.f64 - ctx.f29.f64));
	// lfs f24,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f6,f27,f19
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmsubs f4,f4,f24,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f24.f64 - ctx.f25.f64));
	// lfs f18,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f5,f5,f28,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64 + ctx.f17.f64));
	// add r27,r28,r3
	ctx.r27.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fmadds f3,f3,f24,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f24.f64 + ctx.f16.f64));
	// add r28,r28,r4
	ctx.r28.u64 = ctx.r28.u64 + ctx.r4.u64;
	// fmsubs f25,f31,f20,f21
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f20.f64 - ctx.f21.f64));
	// fmadds f28,f30,f20,f14
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f20.f64 + ctx.f14.f64));
	// fmadds f24,f26,f18,f6
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 + ctx.f6.f64));
	// fmuls f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fsubs f30,f29,f4
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f4.f64));
	// fadds f6,f3,f5
	ctx.f6.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// fsubs f31,f3,f5
	ctx.f31.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// fadds f3,f25,f2
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// fadds f5,f4,f29
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fadds f4,f28,f1
	ctx.f4.f64 = double(float(ctx.f28.f64 + ctx.f1.f64));
	// fsubs f29,f28,f1
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f1.f64));
	// lfs f1,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f28,f2,f25
	ctx.f28.f64 = double(float(ctx.f2.f64 - ctx.f25.f64));
	// lfs f2,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f25,f27,f18,f26
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 - ctx.f26.f64));
	// fmuls f26,f30,f13
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f27,f3,f10
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f23,f4,f10
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmadds f20,f28,f0,f26
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 + ctx.f26.f64));
	// lfs f26,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// fnmadds f21,f5,f11,f27
	ctx.f21.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 + ctx.f27.f64)));
	// lfs f27,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fnmadds f22,f6,f11,f23
	ctx.f22.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 + ctx.f23.f64)));
	// fmuls f23,f2,f27
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// fmuls f27,f1,f27
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fmadds f1,f1,f26,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64 + ctx.f23.f64));
	// fmsubs f23,f2,f26,f27
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f26.f64 - ctx.f27.f64));
	// fadds f2,f1,f24
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f24.f64));
	// fsubs f27,f1,f24
	ctx.f27.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// fsubs f26,f25,f23
	ctx.f26.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f1,f23,f25
	ctx.f1.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// addic. r26,r26,-1
	ctx.xer.ca = ctx.r26.u32 > 0;
	ctx.r26.s64 = ctx.r26.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// fmuls f25,f27,f13
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// addi r11,r11,48
	ctx.r11.s64 = ctx.r11.s64 + 48;
	// fadds f23,f2,f4
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fmuls f24,f26,f13
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmadds f17,f2,f9,f8
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmuls f18,f2,f10
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fadds f19,f1,f3
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fmsubs f16,f31,f0,f25
	ctx.f16.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fadds f25,f23,f6
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// stfs f25,-224(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -224, temp.u32);
	// fmsubs f15,f30,f0,f24
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f24.f64));
	// fmadds f14,f1,f9,f7
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fadds f24,f22,f17
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// fmadds f25,f26,f12,f20
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f20.f64));
	// fnmadds f20,f4,f11,f18
	ctx.f20.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmadds f4,f4,f9,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fadds f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f5.f64));
	// fnmsubs f23,f29,f12,f16
	ctx.f23.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f16.f64)));
	// fnmsubs f22,f28,f12,f15
	ctx.f22.f64 = double(float(-(ctx.f28.f64 * ctx.f12.f64 - ctx.f15.f64)));
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fmadds f30,f30,f12,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f26.f64));
	// fmadds f26,f3,f9,f7
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fadds f19,f19,f7
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f7.f64));
	// lfs f18,-224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -224);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f8.f64));
	// stfs f18,0(r3)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f19,0(r4)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f19,f24,f22
	ctx.f19.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfsx f19,r9,r3
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// stfsx f24,r10,r3
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f24,f21,f23
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfsx f24,r10,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f24,f21,f23
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// stfsx f24,r9,r4
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// fmuls f23,f1,f10
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f24,f31,f13
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// add r3,r25,r3
	ctx.r3.u64 = ctx.r25.u64 + ctx.r3.u64;
	// fmuls f22,f6,f10
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// add r4,r25,r4
	ctx.r4.u64 = ctx.r25.u64 + ctx.r4.u64;
	// fmuls f19,f5,f10
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fmadds f6,f6,f9,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmuls f21,f27,f0
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmadds f5,f5,f9,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fnmadds f23,f3,f11,f23
	ctx.f23.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f23.f64)));
	// fmadds f24,f29,f0,f24
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fnmadds f2,f2,f11,f22
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 + ctx.f22.f64)));
	// fnmadds f1,f1,f11,f19
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 + ctx.f19.f64)));
	// fadds f8,f20,f6
	ctx.f8.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// fmadds f31,f31,f12,f21
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 + ctx.f21.f64));
	// fadds f6,f23,f5
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// fmadds f7,f27,f12,f24
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 + ctx.f24.f64));
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fnmsubs f5,f28,f13,f30
	ctx.f5.f64 = double(float(-(ctx.f28.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fadds f2,f1,f26
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// fsubs f1,f8,f25
	ctx.f1.f64 = double(float(ctx.f8.f64 - ctx.f25.f64));
	// stfs f1,0(r30)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fnmsubs f3,f29,f13,f31
	ctx.f3.f64 = double(float(-(ctx.f29.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// fadds f8,f8,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f25.f64));
	// stfs f8,0(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// stfs f8,0(r8)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// fsubs f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// stfs f8,0(r7)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fsubs f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// stfs f8,0(r27)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + 0, temp.u32);
	// fadds f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f8,0(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fadds f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f8,f2,f3
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// stfs f8,0(r28)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
	// lwz r10,-26212(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82ca3e24
	if (!ctx.cr0.eq) goto loc_82CA3E24;
loc_82CA40A0:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA40A8;
	__restfpr_14(ctx, base);
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA40B0"))) PPC_WEAK_FUNC(sub_82CA40B0);
PPC_FUNC_IMPL(__imp__sub_82CA40B0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27728
	ctx.r5.s64 = ctx.r11.s64 + -27728;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,15816
	ctx.r4.s64 = ctx.r11.s64 + 15816;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA40C8"))) PPC_WEAK_FUNC(sub_82CA40C8);
PPC_FUNC_IMPL(__imp__sub_82CA40C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82CA40D0;
	__savegprlr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82d5c554
	ctx.lr = 0x82CA40D8;
	__savefpr_19(ctx, base);
	// mulli r11,r7,40
	ctx.r11.s64 = ctx.r7.s64 * 40;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82ca42b8
	if (!ctx.cr6.lt) goto loc_82CA42B8;
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// subf r5,r7,r8
	ctx.r5.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f13,-29000(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29000);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f0.f64 = double(temp.f32);
loc_82CA4104:
	// mulli r10,r6,12
	ctx.r10.s64 = ctx.r6.s64 * 12;
	// lfs f12,16(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r7,r6,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f21,f12,f31
	ctx.f21.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// lfs f7,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f31,f11,f31
	ctx.f31.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfsx f30,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r31,r6,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f4,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f4.f64 = double(temp.f32);
	// add r30,r7,r4
	ctx.r30.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// add r29,r31,r3
	ctx.r29.u64 = ctx.r31.u64 + ctx.r3.u64;
	// lfs f3,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f3.f64 = double(temp.f32);
	// mulli r8,r6,20
	ctx.r8.s64 = ctx.r6.s64 * 20;
	// lfs f2,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f29,r7,r3
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f20,f10,f29
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f29.f64));
	// lfsx f27,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// lfsx f26,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f19,f8,f27
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// lfs f28,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f12,f12,f30,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64 - ctx.f31.f64));
	// lfsx f23,r8,r3
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// fmuls f31,f6,f25
	ctx.f31.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfsx f22,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// add r31,r31,r4
	ctx.r31.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fmadds f11,f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f21.f64));
	// fmuls f30,f5,f25
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// lfs f1,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r11,r11,40
	ctx.r11.s64 = ctx.r11.s64 + 40;
	// fmadds f9,f9,f28,f20
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64 + ctx.f20.f64));
	// fmsubs f10,f10,f28,f29
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmuls f29,f4,f23
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// lfs f24,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f7,f7,f26,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f19.f64));
	// fmsubs f8,f8,f26,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64 - ctx.f27.f64));
	// fmadds f5,f5,f24,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64 + ctx.f31.f64));
	// fmsubs f6,f6,f24,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f24.f64 - ctx.f30.f64));
	// fsubs f30,f2,f11
	ctx.f30.f64 = double(float(ctx.f2.f64 - ctx.f11.f64));
	// fadds f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f2.f64));
	// fmadds f31,f3,f22,f29
	ctx.f31.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f29.f64));
	// fmuls f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// fsubs f2,f9,f7
	ctx.f2.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f7,f8,f10
	ctx.f7.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fsubs f29,f1,f12
	ctx.f29.f64 = double(float(ctx.f1.f64 - ctx.f12.f64));
	// fadds f12,f12,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f1.f64));
	// fsubs f8,f5,f31
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// fadds f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// fmsubs f4,f4,f22,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f3.f64));
	// fadds f3,f8,f2
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f2.f64));
	// fadds f1,f5,f9
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f2,f2,f8
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f8.f64));
	// fsubs f5,f9,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f5.f64));
	// fadds f8,f4,f6
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f9,f6,f4
	ctx.f9.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f4,f3,f30
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f30.f64));
	// stfsx f4,r10,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f31,f1,f11
	ctx.f31.f64 = double(float(ctx.f1.f64 + ctx.f11.f64));
	// fmuls f6,f2,f0
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fadds f2,f8,f7
	ctx.f2.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fadds f4,f9,f10
	ctx.f4.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fnmsubs f10,f3,f13,f30
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fnmsubs f11,f1,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f7,f4,f13,f29
	ctx.f7.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f29.f64)));
	// fadds f1,f2,f12
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// fnmsubs f12,f2,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// fadds f3,f4,f29
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f29.f64));
	// fadds f4,f10,f9
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// stfsx f4,r9,r3
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfsx f10,r8,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f11,f8
	ctx.f10.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fadds f9,f7,f6
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f6.f64));
	// stfsx f9,r9,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// stfsx f3,r10,r4
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f9,f7,f6
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// stfsx f9,r8,r4
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r8.u32 + ctx.r4.u32, temp.u32);
	// fadds f9,f12,f5
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f5.f64));
	// stfs f31,0(r3)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fsubs f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f5.f64));
	// stfsx f10,r7,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r3.u32, temp.u32);
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// stfs f11,0(r29)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// stfs f1,0(r4)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// stfs f9,0(r30)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// stfs f12,0(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// lwz r10,-26212(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82ca4104
	if (!ctx.cr0.eq) goto loc_82CA4104;
loc_82CA42B8:
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82d5c5a0
	ctx.lr = 0x82CA42C0;
	__restfpr_19(ctx, base);
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA42C8"))) PPC_WEAK_FUNC(sub_82CA42C8);
PPC_FUNC_IMPL(__imp__sub_82CA42C8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27656
	ctx.r5.s64 = ctx.r11.s64 + -27656;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,16584
	ctx.r4.s64 = ctx.r11.s64 + 16584;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA42E0"))) PPC_WEAK_FUNC(sub_82CA42E0);
PPC_FUNC_IMPL(__imp__sub_82CA42E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82CA42E8;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82d5c558
	ctx.lr = 0x82CA42F0;
	__savefpr_20(ctx, base);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82ca44c0
	if (!ctx.cr6.lt) goto loc_82CA44C0;
	// subf r28,r7,r8
	ctx.r28.s64 = ctx.r8.s64 - ctx.r7.s64;
	// rlwinm r27,r9,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-32255
	ctx.r7.s64 = -2113863680;
	// lis r8,-32235
	ctx.r8.s64 = -2112552960;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lfs f24,-12748(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -12748);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,28200(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 28200);
	ctx.f25.f64 = double(temp.f32);
	// lfs f13,28204(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28204);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28208(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28208);
	ctx.f0.f64 = double(temp.f32);
loc_82CA432C:
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r8,r6,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// mulli r9,r6,12
	ctx.r9.s64 = ctx.r6.s64 * 12;
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f6,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f7,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f5,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// rlwinm r7,r6,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// add r5,r10,r3
	ctx.r5.u64 = ctx.r10.u64 + ctx.r3.u64;
	// add r30,r8,r3
	ctx.r30.u64 = ctx.r8.u64 + ctx.r3.u64;
	// add r31,r9,r3
	ctx.r31.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r29,r7,r3
	ctx.r29.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// lfs f2,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfs f29,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f12,f2
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// lfs f31,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f21,f8,f29
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// lfs f27,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f10,f31
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f20,f6,f27
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// fmuls f2,f11,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// lfs f1,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f29,f7,f29
	ctx.f29.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// lfs f28,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f31,f9,f31
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f30,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lfs f26,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f26.f64 = double(temp.f32);
	// addi r11,r11,32
	ctx.r11.s64 = ctx.r11.s64 + 32;
	// fmadds f11,f11,f1,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 + ctx.f23.f64));
	// fmadds f7,f7,f28,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64 + ctx.f21.f64));
	// fmadds f9,f9,f30,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f22.f64));
	// fmadds f5,f5,f26,f20
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64 + ctx.f20.f64));
	// fmsubs f12,f12,f1,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f1.f64 - ctx.f2.f64));
	// fmsubs f8,f8,f28,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64 - ctx.f29.f64));
	// fmsubs f10,f10,f30,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 - ctx.f31.f64));
	// fmsubs f6,f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64 - ctx.f27.f64));
	// fadds f2,f7,f11
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// fsubs f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fadds f7,f5,f9
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f9,f5,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// fadds f5,f8,f12
	ctx.f5.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// fadds f8,f6,f10
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fsubs f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// fadds f6,f7,f2
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// fsubs f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 - ctx.f7.f64));
	// fmuls f2,f12,f13
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fadds f1,f8,f5
	ctx.f1.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// fmuls f31,f10,f13
	ctx.f31.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fsubs f5,f5,f8
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// fadds f30,f6,f4
	ctx.f30.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// stfs f30,0(r3)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fnmsubs f8,f6,f24,f4
	ctx.f8.f64 = double(float(-(ctx.f6.f64 * ctx.f24.f64 - ctx.f4.f64)));
	// add r3,r27,r3
	ctx.r3.u64 = ctx.r27.u64 + ctx.r3.u64;
	// fmsubs f10,f10,f0,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 - ctx.f2.f64));
	// fadds f30,f1,f3
	ctx.f30.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// stfs f30,0(r4)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmadds f31,f12,f0,f31
	ctx.f31.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f31.f64));
	// add r4,r27,r4
	ctx.r4.u64 = ctx.r27.u64 + ctx.r4.u64;
	// fmuls f12,f7,f25
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// fmuls f7,f5,f25
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// fmuls f5,f11,f13
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmuls f30,f9,f13
	ctx.f30.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fnmsubs f6,f1,f24,f3
	ctx.f6.f64 = double(float(-(ctx.f1.f64 * ctx.f24.f64 - ctx.f3.f64)));
	// fmsubs f9,f9,f0,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fadds f5,f8,f12
	ctx.f5.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// fsubs f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
	// fmadds f11,f11,f0,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f30.f64));
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// fsubs f7,f6,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f7.f64));
	// fsubs f6,f5,f31
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// stfs f6,0(r30)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// fadds f6,f12,f10
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// stfs f6,0(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f6,f5,f31
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f31.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// fsubs f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fsubs f12,f7,f9
	ctx.f12.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fadds f12,f8,f11
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// stfs f12,0(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// fadds f12,f7,f9
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// stfs f12,0(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lwz r10,-26212(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82ca432c
	if (!ctx.cr0.eq) goto loc_82CA432C;
loc_82CA44C0:
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82d5c5a4
	ctx.lr = 0x82CA44C8;
	__restfpr_20(ctx, base);
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA44D0"))) PPC_WEAK_FUNC(sub_82CA44D0);
PPC_FUNC_IMPL(__imp__sub_82CA44D0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27584
	ctx.r5.s64 = ctx.r11.s64 + -27584;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,17120
	ctx.r4.s64 = ctx.r11.s64 + 17120;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA44E8"))) PPC_WEAK_FUNC(sub_82CA44E8);
PPC_FUNC_IMPL(__imp__sub_82CA44E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CA44F0;
	__savegprlr_29(ctx, base);
	// stfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f29.u64);
	// stfd f30,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f31.u64);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82ca4614
	if (!ctx.cr6.lt) goto loc_82CA4614;
	// rlwinm r30,r9,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
loc_82CA4518:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,8(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// mulli r7,r6,12
	ctx.r7.s64 = ctx.r6.s64 * 12;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f3,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfs f8,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// add r31,r7,r3
	ctx.r31.u64 = ctx.r7.u64 + ctx.r3.u64;
	// add r5,r9,r3
	ctx.r5.u64 = ctx.r9.u64 + ctx.r3.u64;
	// add r7,r7,r4
	ctx.r7.u64 = ctx.r7.u64 + ctx.r4.u64;
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f31,f0,f6
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f4,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f29,f10,f2
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmuls f30,f12,f4
	ctx.f30.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f13,f6
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// lfs f1,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmuls f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// fmadds f13,f13,f5,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f31.f64));
	// fmadds f9,f9,f1,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f1.f64 + ctx.f29.f64));
	// fmadds f11,f11,f3,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f3.f64 + ctx.f30.f64));
	// fmsubs f0,f0,f5,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f5.f64 - ctx.f6.f64));
	// fmsubs f12,f12,f3,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 - ctx.f4.f64));
	// fmsubs f10,f10,f1,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f1.f64 - ctx.f2.f64));
	// fadds f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fsubs f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fadds f8,f9,f11
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// fadds f9,f0,f7
	ctx.f9.f64 = double(float(ctx.f0.f64 + ctx.f7.f64));
	// fsubs f0,f7,f0
	ctx.f0.f64 = double(float(ctx.f7.f64 - ctx.f0.f64));
	// fadds f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// fsubs f10,f6,f8
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f8.f64));
	// stfsx f10,r10,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, temp.u32);
	// fadds f10,f8,f6
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfs f10,0(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// fsubs f10,f0,f11
	ctx.f10.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
	// fadds f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fadds f11,f9,f7
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fsubs f11,f9,f7
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// stfsx f11,r10,r4
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r4.u32, temp.u32);
	// fsubs f11,f13,f12
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// stfs f11,0(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f13,0(r5)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfsx f10,r9,r4
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// stfs f0,0(r7)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lwz r10,-26212(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + -26212);
	// xor r6,r10,r6
	ctx.r6.u64 = ctx.r10.u64 ^ ctx.r6.u64;
	// bne 0x82ca4518
	if (!ctx.cr0.eq) goto loc_82CA4518;
loc_82CA4614:
	// lfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f30,-48(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA4628"))) PPC_WEAK_FUNC(sub_82CA4628);
PPC_FUNC_IMPL(__imp__sub_82CA4628) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27512
	ctx.r5.s64 = ctx.r11.s64 + -27512;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,17640
	ctx.r4.s64 = ctx.r11.s64 + 17640;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA4640"))) PPC_WEAK_FUNC(sub_82CA4640);
PPC_FUNC_IMPL(__imp__sub_82CA4640) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bge cr6,0x82ca4740
	if (!ctx.cr6.lt) goto loc_82CA4740;
	// rlwinm r31,r9,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r7,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32235
	ctx.r8.s64 = -2112552960;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lfs f3,28136(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 28136);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,-29000(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29000);
	ctx.f4.f64 = double(temp.f32);
loc_82CA4674:
	// rlwinm r9,r6,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r8,r6,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// add r7,r9,r3
	ctx.r7.u64 = ctx.r9.u64 + ctx.r3.u64;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// add r5,r8,r3
	ctx.r5.u64 = ctx.r8.u64 + ctx.r3.u64;
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// add r9,r9,r4
	ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// add r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 + ctx.r4.u64;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lfs f8,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// lfs f6,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f0,f8
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// fmuls f1,f12,f6
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// lfs f7,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f11,f6
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f5,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f8,f13,f8
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fmadds f13,f13,f7,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f7.f64 + ctx.f2.f64));
	// fmadds f11,f11,f5,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64 + ctx.f1.f64));
	// fmsubs f12,f12,f5,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64 - ctx.f6.f64));
	// fmsubs f0,f0,f7,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 - ctx.f8.f64));
	// fadds f8,f11,f13
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fsubs f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// fadds f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fmuls f0,f11,f3
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fadds f11,f8,f10
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f11,f13,f9
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f9.f64));
	// stfs f11,0(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// fmuls f12,f12,f3
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// add r3,r31,r3
	ctx.r3.u64 = ctx.r31.u64 + ctx.r3.u64;
	// fnmsubs f11,f8,f4,f10
	ctx.f11.f64 = double(float(-(ctx.f8.f64 * ctx.f4.f64 - ctx.f10.f64)));
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// fnmsubs f13,f13,f4,f9
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f4.f64 - ctx.f9.f64)));
	// fsubs f10,f11,f12
	ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// stfs f10,0(r5)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// stfs f12,0(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fadds f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f12,0(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// lwz r9,-26212(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + -26212);
	// xor r6,r9,r6
	ctx.r6.u64 = ctx.r9.u64 ^ ctx.r6.u64;
	// bne 0x82ca4674
	if (!ctx.cr0.eq) goto loc_82CA4674;
loc_82CA4740:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CA4750"))) PPC_WEAK_FUNC(sub_82CA4750);
PPC_FUNC_IMPL(__imp__sub_82CA4750) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27440
	ctx.r5.s64 = ctx.r11.s64 + -27440;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,17984
	ctx.r4.s64 = ctx.r11.s64 + 17984;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA4768"))) PPC_WEAK_FUNC(sub_82CA4768);
PPC_FUNC_IMPL(__imp__sub_82CA4768) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// add r10,r11,r5
	ctx.r10.u64 = ctx.r11.u64 + ctx.r5.u64;
	// bgelr cr6
	if (!ctx.cr6.lt) return;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r7,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r7.s64;
	// lis r8,-32234
	ctx.r8.s64 = -2112487424;
loc_82CA4784:
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f12,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f0,f10
	ctx.f8.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmadds f13,f13,f9,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmsubs f0,f0,f9,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 - ctx.f10.f64));
	// fsubs f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfsx f10,r11,r3
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// fsubs f12,f11,f0
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f0.f64));
	// stfsx f12,r11,r4
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// stfs f13,0(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lwz r11,-26212(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + -26212);
	// add r3,r5,r3
	ctx.r3.u64 = ctx.r5.u64 + ctx.r3.u64;
	// add r4,r5,r4
	ctx.r4.u64 = ctx.r5.u64 + ctx.r4.u64;
	// xor r6,r11,r6
	ctx.r6.u64 = ctx.r11.u64 ^ ctx.r6.u64;
	// bne 0x82ca4784
	if (!ctx.cr0.eq) goto loc_82CA4784;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CA47F0"))) PPC_WEAK_FUNC(sub_82CA47F0);
PPC_FUNC_IMPL(__imp__sub_82CA47F0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27368
	ctx.r5.s64 = ctx.r11.s64 + -27368;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,18280
	ctx.r4.s64 = ctx.r11.s64 + 18280;
	// b 0x82cab898
	sub_82CAB898(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA4808"))) PPC_WEAK_FUNC(sub_82CA4808);
PPC_FUNC_IMPL(__imp__sub_82CA4808) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c49c
	ctx.lr = 0x82CA4810;
	__savegprlr_17(ctx, base);
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82d5c540
	ctx.lr = 0x82CA4818;
	__savefpr_14(ctx, base);
	// stwu r1,-800(r1)
	ea = -800 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82ca742c
	if (!ctx.cr6.gt) goto loc_82CA742C;
	// lwz r11,884(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	// rlwinm r25,r10,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r17,-32235
	ctx.r17.s64 = -2112552960;
	// rlwinm r24,r11,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r18,-32235
	ctx.r18.s64 = -2112552960;
	// lis r19,-32235
	ctx.r19.s64 = -2112552960;
	// lis r20,-32235
	ctx.r20.s64 = -2112552960;
	// lis r21,-32235
	ctx.r21.s64 = -2112552960;
	// lfs f31,30364(r17)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + 30364);
	ctx.f31.f64 = double(temp.f32);
	// lis r22,-32235
	ctx.r22.s64 = -2112552960;
	// lis r26,-32235
	ctx.r26.s64 = -2112552960;
	// lfs f1,30360(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 30360);
	ctx.f1.f64 = double(temp.f32);
	// lis r27,-32235
	ctx.r27.s64 = -2112552960;
	// lfs f2,30368(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 30368);
	ctx.f2.f64 = double(temp.f32);
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// lfs f3,30372(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 30372);
	ctx.f3.f64 = double(temp.f32);
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// lfs f4,30352(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + 30352);
	ctx.f4.f64 = double(temp.f32);
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lfs f5,30356(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 30356);
	ctx.f5.f64 = double(temp.f32);
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lfs f6,30344(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 30344);
	ctx.f6.f64 = double(temp.f32);
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lfs f7,30348(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 30348);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lfs f8,27792(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 27792);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f9,27788(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 27788);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,27784(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 27784);
	ctx.f10.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f11,27780(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 27780);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,27776(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27776);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-29656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29656);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29652(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82CA48B0:
	// rlwinm r27,r7,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f30,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f30.f64 = double(temp.f32);
	// mulli r26,r7,144
	ctx.r26.s64 = ctx.r7.s64 * 144;
	// lfs f29,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f14,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r10,r7,160
	ctx.r10.s64 = ctx.r7.s64 * 160;
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,260(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfsx f14,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfsx f28,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f25,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f14,f28,f27
	ctx.f14.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// mulli r9,r7,224
	ctx.r9.s64 = ctx.r7.s64 * 224;
	// lfsx f26,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fsubs f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfsx f24,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r31,r7,96
	ctx.r31.s64 = ctx.r7.s64 * 96;
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f25,f24,f22
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f25,56(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// rlwinm r30,r7,7,0,24
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 7) & 0xFFFFFF80;
	// lfsx f21,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// rlwinm r29,r7,6,0,25
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// mulli r28,r7,192
	ctx.r28.s64 = ctx.r7.s64 * 192;
	// fsubs f25,f23,f21
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfsx f20,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f19,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f22,f20,f30
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// lfsx f17,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f30,f30,f20
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f20.f64));
	// lfsx f18,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// fadds f21,f19,f29
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f29.f64));
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f17,f18
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfsx f15,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f19,f15,f16
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,268(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f15,f27,f14
	ctx.f15.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// fsubs f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f14.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f25.f64));
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f25,f25,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// fadds f14,f24,f28
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fsubs f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f28.f64));
	// fadds f24,f23,f26
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// fsubs f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f23.f64));
	// fadds f23,f20,f22
	ctx.f23.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fsubs f20,f21,f19
	ctx.f20.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f19,f30,f17
	ctx.f19.f64 = double(float(ctx.f30.f64 - ctx.f17.f64));
	// fadds f30,f17,f30
	ctx.f30.f64 = double(float(ctx.f17.f64 + ctx.f30.f64));
	// fsubs f17,f29,f18
	ctx.f17.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// stfs f29,500(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// lfs f29,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f29.f64 = double(temp.f32);
	// mulli r9,r7,240
	ctx.r9.s64 = ctx.r7.s64 * 240;
	// stfs f17,444(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fsubs f18,f29,f15
	ctx.f18.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// fadds f17,f15,f29
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f29.f64));
	// mulli r31,r7,112
	ctx.r31.s64 = ctx.r7.s64 * 112;
	// fadds f29,f25,f27
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f29,40(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fsubs f15,f27,f25
	ctx.f15.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// fadds f29,f14,f23
	ctx.f29.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// fsubs f27,f23,f14
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// lfsx f14,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,80(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fsubs f25,f20,f28
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f28.f64));
	// fadds f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f20.f64));
	// fmuls f23,f18,f0
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f23,508(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fmuls f23,f17,f0
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f23,432(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f24,f21
	ctx.f23.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r30,r7,48
	ctx.r30.s64 = ctx.r7.s64 * 48;
	// stfs f14,104(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f21,f22,f26
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// fadds f26,f26,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f22.f64));
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f22,468(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// lfsx f15,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// mulli r29,r7,176
	ctx.r29.s64 = ctx.r7.s64 * 176;
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r7,80
	ctx.r11.s64 = ctx.r7.s64 * 80;
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f20,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r7,208
	ctx.r10.s64 = ctx.r7.s64 * 208;
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f18,f0
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f22,452(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f22,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f18,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 - ctx.f18.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,260(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,80(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f22,f15
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f20,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f20,268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f14,140(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,64(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f16,f13
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f18,68(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,148(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f20,f12
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,172(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f18,f22,f13,f18
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f18,476(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// fmadds f22,f22,f12,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f20.f64));
	// stfs f22,464(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fmsubs f22,f16,f12,f17
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f17.f64));
	// stfs f22,480(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f22,260(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// lfs f17,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// lfs f20,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f14,384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f16,f18,f13
	ctx.f16.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmuls f15,f20,f13
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// mulli r31,r7,168
	ctx.r31.s64 = ctx.r7.s64 * 168;
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r30,r7,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f14,436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f18,f18,f12,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f15.f64));
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f14,344(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// mulli r29,r7,136
	ctx.r29.s64 = ctx.r7.s64 * 136;
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// stfs f22,288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fmadds f22,f20,f12,f16
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f22,336(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// mulli r28,r7,72
	ctx.r28.s64 = ctx.r7.s64 * 72;
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f22,f13
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// stfs f18,268(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fmuls f18,f22,f12
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r27,r7,200
	ctx.r27.s64 = ctx.r7.s64 * 200;
	// lfs f22,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f22.f64 = double(temp.f32);
	// stfs f14,96(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fmadds f20,f22,f12,f20
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f20.f64));
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f22,f22,f13,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// mulli r11,r7,232
	ctx.r11.s64 = ctx.r7.s64 * 232;
	// stfs f22,496(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f20,396(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f22,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f20,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r7,104
	ctx.r10.s64 = ctx.r7.s64 * 104;
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// mulli r9,r7,40
	ctx.r9.s64 = ctx.r7.s64 * 40;
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// fsubs f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f16,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,140(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,72(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,148(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f22,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f22,f20
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f17,140(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// fadds f17,f20,f22
	ctx.f17.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f22,24(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f17,f22,f20
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f20,f22
	ctx.f17.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f17,96(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f22,76(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fadds f20,f16,f22
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f20,64(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f18,f15
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f17,f22,f20
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,40(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f22,f17,f0
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,196(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,460(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,228(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// mulli r31,r7,156
	ctx.r31.s64 = ctx.r7.s64 * 156;
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// mulli r30,r7,252
	ctx.r30.s64 = ctx.r7.s64 * 252;
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,352(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f14,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfs f16,296(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,372(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,412(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f16,f22
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f14,492(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// stfs f22,240(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f22,f20
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f16,388(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,256(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// mulli r29,r7,124
	ctx.r29.s64 = ctx.r7.s64 * 124;
	// fsubs f20,f22,f17
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f20,520(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,324(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fsubs f22,f18,f15
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r7,220
	ctx.r11.s64 = ctx.r7.s64 * 220;
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfsx f20,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r28,r7,60
	ctx.r28.s64 = ctx.r7.s64 * 60;
	// fsubs f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f14,328(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r7,188
	ctx.r11.s64 = ctx.r7.s64 * 188;
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// mulli r10,r7,92
	ctx.r10.s64 = ctx.r7.s64 * 92;
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,96(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// mulli r9,r7,28
	ctx.r9.s64 = ctx.r7.s64 * 28;
	// lfsx f14,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f17,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,56(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fsubs f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfsx f16,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// stfs f22,224(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfsx f22,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,104(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f16,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,96(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fadds f14,f22,f20
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f18.f64));
	// stfs f20,76(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,140(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f20,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,20(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f20
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f18,72(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f18,64(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f18,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// stfs f20,48(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f18,16(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fadds f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f20,24(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f20,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,68(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f20,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f18,f20
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fsubs f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// mulli r31,r7,152
	ctx.r31.s64 = ctx.r7.s64 * 152;
	// mulli r30,r7,248
	ctx.r30.s64 = ctx.r7.s64 * 248;
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// mulli r11,r7,216
	ctx.r11.s64 = ctx.r7.s64 * 216;
	// mulli r10,r7,88
	ctx.r10.s64 = ctx.r7.s64 * 88;
	// mulli r9,r7,24
	ctx.r9.s64 = ctx.r7.s64 * 24;
	// mulli r29,r7,120
	ctx.r29.s64 = ctx.r7.s64 * 120;
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,424(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// mulli r28,r7,56
	ctx.r28.s64 = ctx.r7.s64 * 56;
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,440(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,408(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,488(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,276(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f15,448(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,484(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// lfs f22,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,160(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f16,f22,f20
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,308(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f18
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f20,148(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,216(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f17
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,316(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f20,96(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f14,40(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfsx f20,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f16,272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fsubs f18,f17,f22
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f18,140(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f22,420(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// mulli r11,r7,184
	ctx.r11.s64 = ctx.r7.s64 * 184;
	// lfsx f22,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,60(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfsx f14,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f14,f20,f22
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// fsubs f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f20,f17,f18
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,56(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,40(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,76(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,120(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f20,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f20
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f17,f20,f16
	ctx.f17.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// stfs f20,368(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r7,228
	ctx.r11.s64 = ctx.r7.s64 * 228;
	// lfs f20,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r7,100
	ctx.r10.s64 = ctx.r7.s64 * 100;
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,220(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f20,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f20.f64 = double(temp.f32);
	// fadds f16,f15,f20
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f16,64(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f20,264(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// stfs f17,76(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f20,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f16,f17,f20
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f17,f18
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// fadds f17,f18,f17
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f20.f64));
	// stfs f20,40(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// mulli r9,r7,36
	ctx.r9.s64 = ctx.r7.s64 * 36;
	// fmuls f20,f16,f0
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,400(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// mulli r31,r7,164
	ctx.r31.s64 = ctx.r7.s64 * 164;
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r29,r7,132
	ctx.r29.s64 = ctx.r7.s64 * 132;
	// mulli r28,r7,68
	ctx.r28.s64 = ctx.r7.s64 * 68;
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f14,312(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,244(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// mulli r27,r7,196
	ctx.r27.s64 = ctx.r7.s64 * 196;
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f14,132(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f22,292(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// lfs f15,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f15.f64 = double(temp.f32);
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f22,f15
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// stfs f14,304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// lfs f15,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f15.f64 = double(temp.f32);
	// stfs f22,404(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// fsubs f22,f15,f20
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f22,392(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f22,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f14,204(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f16,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f22,168(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f22,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f18,f22,f17
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f18,40(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,220(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fadds f22,f20,f15
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f22,332(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f22,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f16
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f20,368(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,128(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,76(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f22,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfsx f20,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfsx f16,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,72(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,112(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,76(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f14,68(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// stfs f14,120(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,264(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfs f22,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f17,f22
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,36(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f17,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f22,72(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// stfs f14,112(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f22,376(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f18,f15
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f22,44(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// fadds f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fsubs f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f22.f64));
	// stfs f22,380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// lfs f22,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f16,f22,f17
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f17,f17,f22
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// fmuls f18,f14,f0
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f22,f16,f0
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f14,416(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,192(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f15,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f14,208(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f14,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,188(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f20
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,472(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// lfs f20,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f20.f64 = double(temp.f32);
	// lfs f15,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f20
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f14,516(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,180(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f20,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f20,f22
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfs f15,348(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,280(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f18
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f20,252(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,524(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f22,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f17
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f20,76(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 76, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// mulli r31,r7,212
	ctx.r31.s64 = ctx.r7.s64 * 212;
	// stfs f22,456(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// mulli r30,r7,244
	ctx.r30.s64 = ctx.r7.s64 * 244;
	// lfs f22,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f22,f16
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// stfs f20,112(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fadds f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f22,376(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,32(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,20(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,28(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// mulli r29,r7,116
	ctx.r29.s64 = ctx.r7.s64 * 116;
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,24(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,16(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f22,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f20,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r28,r7,52
	ctx.r28.s64 = ctx.r7.s64 * 52;
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,64(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// mulli r11,r7,180
	ctx.r11.s64 = ctx.r7.s64 * 180;
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfsx f14,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,36(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r7,148
	ctx.r10.s64 = ctx.r7.s64 * 148;
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// mulli r9,r7,84
	ctx.r9.s64 = ctx.r7.s64 * 84;
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fsubs f18,f20,f17
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,60(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,104(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,80(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f15,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f15,20(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,116(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// fadds f15,f17,f18
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f15,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fsubs f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f15.f64));
	// stfs f15,28(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f15,84(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,52(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,100(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,64(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,60(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,32(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f17,f12
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,72(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f12
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmadds f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f14.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f12
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f16,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f16,80(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f16,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,184(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f20,f16
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// stfs f15,320(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fadds f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// lfs f16,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f16.f64 = double(temp.f32);
	// stfs f20,104(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmsubs f20,f16,f13,f14
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f15,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f15,f17
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f20,f15
	ctx.f15.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f15,340(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// mulli r9,r7,76
	ctx.r9.s64 = ctx.r7.s64 * 76;
	// fmuls f15,f14,f0
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f15,124(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,176(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f17,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f20,512(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r7,140
	ctx.r10.s64 = ctx.r7.s64 * 140;
	// fsubs f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f20,44(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfs f20,64(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fmuls f17,f16,f12
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f22,f13
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f15,f20,f12
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// mulli r31,r7,204
	ctx.r31.s64 = ctx.r7.s64 * 204;
	// fmuls f14,f20,f13
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f20,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f22,f20,f13,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmsubs f20,f18,f12,f16
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f16.f64));
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// mulli r30,r7,236
	ctx.r30.s64 = ctx.r7.s64 * 236;
	// fmadds f17,f16,f13,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f15.f64));
	// fmsubs f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f14.f64));
	// mulli r29,r7,108
	ctx.r29.s64 = ctx.r7.s64 * 108;
	// mulli r28,r7,44
	ctx.r28.s64 = ctx.r7.s64 * 44;
	// lfs f15,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f18,f18,f13,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f18,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,100(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r7,172
	ctx.r11.s64 = ctx.r7.s64 * 172;
	// stfs f18,84(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f18,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f18,f15
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// fadds f15,f15,f18
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// lfsx f18,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// stfs f18,44(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfsx f18,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f14,284(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfsx f14,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f0
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f14,116(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f14,356(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,108(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfs f22,64(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 64, temp.u32);
	// fadds f22,f17,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfs f15,504(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// stfs f22,264(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfsx f15,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f20,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f14,f16,f17
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f14,72(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 72, temp.u32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// stfs f17,380(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// lfsx f17,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,32(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfsx f16,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,20(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfsx f16,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,28(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfsx f16,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfsx f16,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,16(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfsx f16,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,24(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfsx f16,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f16,68(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfs f14,48(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,52(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f14,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// fsubs f14,f15,f22
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f22.f64));
	// stfs f14,100(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f15.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f20.f64));
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// stfs f20,84(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfs f20,60(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f15,f20
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// stfs f15,56(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f20,f20,f15
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f15.f64));
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,44(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f17,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f17
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f17.f64));
	// stfs f15,32(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f15,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,116(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f17,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f15,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfs f15,16(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// fsubs f15,f16,f22
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f18,f15
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// stfs f15,68(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f15,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,24(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f15,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,48(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f14,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f14,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f16.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r11,r8,7,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 7) & 0xFFFFFF80;
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// lfs f14,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// fsubs f14,f20,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f22.f64 = double(temp.f32);
	// stfs f14,248(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f14,f16,f22
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f22.f64));
	// stfs f14,44(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fsubs f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 + ctx.f18.f64));
	// stfs f18,84(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// stfs f22,364(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// stfs f20,116(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f20,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,212(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f22,60(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f20,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,32(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f20,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f20,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// stfs f15,36(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fadds f18,f20,f22
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfs f22,236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f22,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f22,f12
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f12
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f12
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// stfs f22,28(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fmuls f18,f15,f12
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmuls f15,f17,f12
	ctx.f15.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmsubs f22,f17,f13,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f20.f64));
	// lfs f20,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f20,f20,f13,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f18.f64));
	// fmadds f17,f17,f13,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f15.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// lfs f17,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f13,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 - ctx.f16.f64));
	// lfs f16,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f16.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f17,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f16,f17,f13,f14
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f16,300(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f16,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,36(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// lfs f16,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f17,f17,f12,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f16.f64));
	// stfs f17,232(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f16,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,100(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f17,24(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 24, temp.u32);
	// lfs f16,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,20(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// stfs f15,364(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f17,28(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f12
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f17,f13
	ctx.f16.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f17,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f29
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// stfs f17,248(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// stfs f17,16(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 16, temp.u32);
	// lfs f15,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f17,116(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f15,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// lfs f15,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f16,f15,f12,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f16.f64));
	// fmadds f15,f15,f13,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f14.f64));
	// stfs f15,212(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fsubs f15,f22,f20
	ctx.f15.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f15,120(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,48(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 48, temp.u32);
	// lfs f22,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f20,f18,f22
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// stfs f20,68(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// stfs f22,52(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 52, temp.u32);
	// lfs f22,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f20,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f22,f20
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfs f18,152(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,144(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f20,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f20,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,84(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f22
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// fadds f15,f22,f20
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f22,f20
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfs f22,236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmuls f20,f18,f0
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f20,36(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 36, temp.u32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f20,f14,f0
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f20,32(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 32, temp.u32);
	// lfs f20,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f16,f20
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f18,28(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// stfs f20,60(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 60, temp.u32);
	// lfs f16,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f18,f0
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfs f18,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f15,f18,f16
	ctx.f15.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// stfs f15,44(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 44, temp.u32);
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfs f15,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r10,r8,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// mulli r9,r8,192
	ctx.r9.s64 = ctx.r8.s64 * 192;
	// stfs f18,56(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 56, temp.u32);
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f16,164(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f14,84(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,156(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f16,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f16.f64 = double(temp.f32);
	// mulli r31,r8,160
	ctx.r31.s64 = ctx.r8.s64 * 160;
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f15,f16,f18
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// lfs f16,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,300(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfs f16,232(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f14,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f14.f64 = double(temp.f32);
	// mulli r30,r8,224
	ctx.r30.s64 = ctx.r8.s64 * 224;
	// lfs f16,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// stfsx f15,r11,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,20(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 20);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// lfs f14,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// stfs f29,212(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f29,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f29.f64 = double(temp.f32);
	// lfs f14,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// stfs f29,236(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f29,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfs f29,364(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfs f23,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// stfs f29,248(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f23,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// stfs f29,372(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f23,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f29,384(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f23,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// stfs f29,196(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f23,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// stfs f29,200(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lfs f29,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f29.f64 = double(temp.f32);
	// lfs f23,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f14,f29,f23
	ctx.f14.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// stfsx f14,r11,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 16);
	ctx.f14.f64 = double(temp.f32);
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// fadds f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// stfs f18,0(r5)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfs f29,0(r6)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// rlwinm r11,r8,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f23,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f23.f64 = double(temp.f32);
	// lfs f29,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f29.f64 = double(temp.f32);
	// fadds f18,f29,f23
	ctx.f18.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// lfs f23,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f23.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fsubs f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// lfs f23,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f23.f64 = double(temp.f32);
	// mulli r29,r8,96
	ctx.r29.s64 = ctx.r8.s64 * 96;
	// fsubs f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfs f23,344(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// lfs f23,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f23.f64 = double(temp.f32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfs f27,304(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// lfs f27,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f27.f64 = double(temp.f32);
	// stfs f29,92(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fadds f29,f27,f24
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// lfs f23,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f18,r10,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfs f27,288(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fadds f27,f23,f24
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfsx f14,r10,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// fsubs f23,f16,f15
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// stfsx f18,r9,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f18,f15,f16
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfsx f17,r9,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,164(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f16,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f17.f64 = double(temp.f32);
	// fadds f15,f16,f17
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f15,144(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,156(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f17,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f15,f17,f16
	ctx.f15.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// fadds f16,f16,f17
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f17,f13
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f17,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// stfs f17,92(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmuls f17,f15,f0
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f16,232(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lfs f16,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f16,f16,f12,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f16,196(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f16,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f16,200(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fadds f16,f23,f27
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// fadds f15,f18,f24
	ctx.f15.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// fsubs f23,f23,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f27.f64));
	// fsubs f18,f24,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// fmuls f27,f16,f0
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f16,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f24,f15,f0
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// fmuls f23,f23,f0
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fsubs f15,f16,f27
	ctx.f15.f64 = double(float(ctx.f16.f64 - ctx.f27.f64));
	// stfsx f15,r31,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// stfsx f27,r11,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f27,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f16,f27,f24
	ctx.f16.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// stfsx f16,r31,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// stfsx f27,r11,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f24,f27,f23
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// stfsx f24,r30,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfsx f27,r29,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f24,f27,f18
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f18.f64));
	// stfsx f24,r30,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f18,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 + ctx.f27.f64));
	// lfs f23,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r8,176
	ctx.r11.s64 = ctx.r8.s64 * 176;
	// lfs f24,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f24.f64 = double(temp.f32);
	// mulli r10,r8,48
	ctx.r10.s64 = ctx.r8.s64 * 48;
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// stfs f23,88(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f18,24(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// lfs f23,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// lfs f16,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f14,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f16.f64 = double(temp.f32);
	// stfsx f27,r29,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f27,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f27.f64 = double(temp.f32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f15,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 - ctx.f27.f64));
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f15,184(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// mulli r9,r8,240
	ctx.r9.s64 = ctx.r8.s64 * 240;
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// lfs f14,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// lfs f14,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,144(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f17,f29
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// stfs f15,152(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// fsubs f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f17.f64));
	// stfs f29,164(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f29,f24,f13
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// stfs f14,156(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f24,f24,f12
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// mulli r31,r8,112
	ctx.r31.s64 = ctx.r8.s64 * 112;
	// fmuls f17,f23,f12
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// stfs f23,92(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fsubs f14,f18,f16
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// mulli r30,r8,144
	ctx.r30.s64 = ctx.r8.s64 * 144;
	// fmadds f29,f27,f12,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 + ctx.f29.f64));
	// stfs f29,192(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// rlwinm r29,r8,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r28,r8,208
	ctx.r28.s64 = ctx.r8.s64 * 208;
	// lfs f29,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f29.f64 = double(temp.f32);
	// stfs f24,88(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmr f23,f29
	ctx.f23.f64 = ctx.f29.f64;
	// fmuls f24,f14,f0
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f14,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f29,f23,f13,f17
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f17.f64));
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fadds f14,f24,f14
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f27,f27,f13,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f17.f64));
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f23,f12,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f17.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmadds f17,f17,f12,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f16.f64));
	// lfs f16,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f12,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f15.f64));
	// fsubs f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// lfs f15,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f29,f15
	ctx.f15.f64 = double(float(ctx.f29.f64 + ctx.f15.f64));
	// fadds f14,f23,f27
	ctx.f14.f64 = double(float(ctx.f23.f64 + ctx.f27.f64));
	// stfs f14,184(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,92(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f23.f64));
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfsx f15,r10,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f15,f14
	ctx.f14.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// stfsx f14,r11,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// mulli r11,r8,80
	ctx.r11.s64 = ctx.r8.s64 * 80;
	// lfs f23,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f23.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfsx f15,r10,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// fsubs f15,f24,f29
	ctx.f15.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// stfsx f15,r9,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f29,f29,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f24.f64));
	// stfsx f29,r31,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f29,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f24,f29,f27
	ctx.f24.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfsx f24,r9,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lfs f15,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f15.f64 = double(temp.f32);
	// lfs f29,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f27,f23,f29
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// stfsx f27,r30,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// stfsx f29,r29,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lfs f29,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f16,f29
	ctx.f29.f64 = double(float(ctx.f16.f64 + ctx.f29.f64));
	// lfs f27,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f24,f27,f29
	ctx.f24.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfsx f24,r30,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// stfsx f29,r29,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// lfs f24,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f24.f64 = double(temp.f32);
	// lfs f27,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// lfs f24,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f23,f24,f22
	ctx.f23.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// stfs f23,88(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f23,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f23.f64 = double(temp.f32);
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// stfs f23,192(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f23,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f23.f64 = double(temp.f32);
	// fadds f15,f15,f23
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// lfs f23,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f23,f13
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f23,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f23.f64 = double(temp.f32);
	// stfs f22,276(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// lfs f22,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f22.f64 = double(temp.f32);
	// stfs f23,160(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fadds f23,f22,f20
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f15,f0
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f22,188(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f22,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f22,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f22.f64 = double(temp.f32);
	// lfs f20,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f20.f64 = double(temp.f32);
	// fadds f15,f22,f20
	ctx.f15.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f22,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f20,f22,f12,f14
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f14.f64));
	// stfs f20,180(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f20,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f14,f20,f12,f14
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f14,176(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f14,f22,f13
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f22,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fsubs f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// stfs f18,244(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// stfs f18,228(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f18,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f29,f8
	ctx.f16.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fmsubs f20,f18,f12,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 - ctx.f20.f64));
	// stfs f20,160(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f20,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f12,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f20,152(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f20,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f17
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// stfsx f18,r28,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfsx f20,r11,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f27,f8
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmuls f17,f20,f8
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// lfs f20,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f15,f20,f8
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmsubs f27,f27,f9,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f16.f64));
	// fmadds f29,f29,f9,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f18.f64));
	// stfs f29,88(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmsubs f29,f20,f9,f17
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 - ctx.f17.f64));
	// stfs f29,144(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f29,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f18,f24,f10
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fsubs f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// stfs f29,296(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f29,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f17,f23,f11
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmuls f20,f29,f10
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fmsubs f24,f24,f11,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 - ctx.f20.f64));
	// lfs f29,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f29.f64 = double(temp.f32);
	// lfs f14,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f29,f29,f14
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f14.f64));
	// fmuls f14,f23,f10
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f23,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f23.f64 = double(temp.f32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// stfs f26,188(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f26,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f23.f64 = double(temp.f32);
	// fadds f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f26.f64));
	// lfs f23,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f23,f23,f11,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f18.f64));
	// fsubs f18,f22,f20
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f20.f64));
	// stfsx f18,r28,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// lfs f20,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f20.f64 = double(temp.f32);
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f22,f28,f20
	ctx.f22.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f20,f28
	ctx.f28.f64 = double(float(ctx.f20.f64 + ctx.f28.f64));
	// fmadds f20,f18,f10,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 + ctx.f17.f64));
	// lfs f17,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f9,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f15.f64));
	// lfs f16,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f18,f18,f11,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 - ctx.f14.f64));
	// stfs f17,292(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,180(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f16,f15
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// stfs f14,228(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f29,f14
	ctx.f14.f64 = double(float(ctx.f29.f64 + ctx.f14.f64));
	// stfs f14,244(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fadds f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f14,160(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fsubs f22,f22,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f22,92(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fsubs f22,f15,f16
	ctx.f22.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f22,152(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f17,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,168
	ctx.r11.s64 = ctx.r8.s64 * 168;
	// lfs f22,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f22.f64 = double(temp.f32);
	// mulli r10,r8,40
	ctx.r10.s64 = ctx.r8.s64 * 40;
	// lfs f14,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,176(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fadds f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// lfs f17,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f22.f64 = double(temp.f32);
	// stfs f14,88(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,144(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f22,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// lfs f22,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f16,f22,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f16.f64));
	// lfs f22,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f12
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f14,f22,f13
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f22,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f29,f22,f29
	ctx.f29.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// lfs f22,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f22.f64));
	// stfs f27,156(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f22,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f22.f64 = double(temp.f32);
	// mulli r9,r8,232
	ctx.r9.s64 = ctx.r8.s64 * 232;
	// lfs f27,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// fadds f22,f24,f20
	ctx.f22.f64 = double(float(ctx.f24.f64 + ctx.f20.f64));
	// stfs f22,164(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f22,f26,f28
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfs f22,232(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fsubs f26,f24,f20
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// lfs f20,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f20.f64 = double(temp.f32);
	// lfs f24,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f24.f64 = double(temp.f32);
	// fadds f22,f23,f18
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// fsubs f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// stfs f24,172(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fsubs f24,f18,f23
	ctx.f24.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// mulli r31,r8,104
	ctx.r31.s64 = ctx.r8.s64 * 104;
	// fmuls f23,f17,f0
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f23,300(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmuls f23,f16,f0
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f23,236(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f23,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f23,f23,f13,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f15.f64));
	// stfs f23,360(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f23,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f12,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f14.f64));
	// stfs f23,212(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f23,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f23.f64 = double(temp.f32);
	// mulli r30,r8,136
	ctx.r30.s64 = ctx.r8.s64 * 136;
	// rlwinm r29,r8,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r28,r8,200
	ctx.r28.s64 = ctx.r8.s64 * 200;
	// lfs f20,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f20,f23
	ctx.f18.f64 = double(float(ctx.f20.f64 - ctx.f23.f64));
	// stfsx f18,r11,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f17,f23,f20
	ctx.f17.f64 = double(float(ctx.f23.f64 + ctx.f20.f64));
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// mulli r27,r8,72
	ctx.r27.s64 = ctx.r8.s64 * 72;
	// lfs f20,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f23,f20
	ctx.f18.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f16,f20,f23
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f23,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f15,f23,f20
	ctx.f15.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f23,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f17,r10,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f14,f23,f9
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// stfsx f18,r11,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// mulli r11,r8,184
	ctx.r11.s64 = ctx.r8.s64 * 184;
	// stfs f23,88(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmr f23,f18
	ctx.f23.f64 = ctx.f18.f64;
	// stfsx f16,r10,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// mulli r10,r8,56
	ctx.r10.s64 = ctx.r8.s64 * 56;
	// stfsx f15,r9,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// stfsx f20,r31,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f18,f29,f23
	ctx.f18.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// stfsx f18,r9,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f23,f29
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// lfs f29,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f17,f27,f29
	ctx.f17.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfsx f23,r31,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f16,f29,f27
	ctx.f16.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// lfs f29,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f15,f29,f22
	ctx.f15.f64 = double(float(ctx.f29.f64 - ctx.f22.f64));
	// lfs f27,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f27.f64 = double(temp.f32);
	// fadds f22,f22,f29
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f29.f64));
	// stfsx f17,r30,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f28,f26
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfs f29,244(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfs f28,228(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fsubs f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// stfs f27,160(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f26,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f26.f64 = double(temp.f32);
	// mulli r9,r8,248
	ctx.r9.s64 = ctx.r8.s64 * 248;
	// fadds f24,f24,f26
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f26,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f26.f64 = double(temp.f32);
	// fmr f28,f26
	ctx.f28.f64 = ctx.f26.f64;
	// stfsx f16,r29,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// stfsx f15,r30,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f22,r29,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,36(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 36);
	ctx.f16.f64 = double(temp.f32);
	// lfs f26,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f17,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f17.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f26,172(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// lfs f26,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f29,f21,f28
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// fadds f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f28.f64));
	// lfs f21,32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f21,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// lfs f16,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f15,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// stfs f25,92(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f25,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f25,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f25,f25,f8,f14
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f23,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f23,r28,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f23,r27,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f23,r28,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// stfsx f24,r27,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f20,f17
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// lfs f23,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f23.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 - ctx.f23.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f17,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f13,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 - ctx.f16.f64));
	// stfs f17,208(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f17,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f18,f8
	ctx.f14.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmadds f17,f17,f12,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f15.f64));
	// stfs f17,284(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f22,f11
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f17,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// fmadds f17,f17,f9,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f16.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// mulli r31,r8,120
	ctx.r31.s64 = ctx.r8.s64 * 120;
	// fadds f16,f17,f29
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f29.f64));
	// stfs f16,136(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fsubs f29,f29,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f17.f64));
	// stfs f29,132(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f29,f24,f11
	ctx.f29.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// mulli r30,r8,152
	ctx.r30.s64 = ctx.r8.s64 * 152;
	// fmuls f17,f21,f11
	ctx.f17.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fmuls f16,f23,f11
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmadds f29,f23,f10,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f29.f64));
	// fmsubs f23,f22,f10,f17
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f17.f64));
	// fmadds f22,f21,f10,f15
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f15.f64));
	// lfs f21,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f21.f64 = double(temp.f32);
	// stfs f18,208(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmr f18,f21
	ctx.f18.f64 = ctx.f21.f64;
	// fmsubs f24,f24,f10,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f16.f64));
	// mulli r29,r8,24
	ctx.r29.s64 = ctx.r8.s64 * 24;
	// lfs f17,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f18,f17
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fmadds f17,f20,f9,f14
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 + ctx.f14.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f17,f25
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f20,f20,f8,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 - ctx.f16.f64));
	// fadds f16,f23,f29
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// fadds f23,f22,f24
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f22,f21,f27
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f21,f18,f28
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// fsubs f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// stfsx f16,r10,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f16,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f14,f22,f23
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f14,r11,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfsx f23,r10,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f23,f27,f29
	ctx.f23.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfsx f23,r9,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// stfsx f29,r31,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f29,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f16,f16,f24
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// fadds f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfsx f16,r9,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f21,f15
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f15.f64));
	// stfsx f29,r30,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f15,f21
	ctx.f29.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// stfsx f29,r29,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// mulli r11,r8,216
	ctx.r11.s64 = ctx.r8.s64 * 216;
	// lfs f29,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f29.f64 = double(temp.f32);
	// lfs f27,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// stfs f29,284(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// stfs f27,208(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lfs f15,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// lfs f27,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f27.f64 = double(temp.f32);
	// stfsx f29,r30,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// fadds f29,f15,f16
	ctx.f29.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fsubs f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// stfs f16,132(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f28,f28,f18
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f18.f64));
	// fsubs f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfs f21,108(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f23,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// lfs f14,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r8,88
	ctx.r10.s64 = ctx.r8.s64 * 88;
	// lfs f21,48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 48);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,352(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f23,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f23,f9
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// lfs f21,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// stfs f23,168(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// stfs f14,136(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f15,f21,f8
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// fmuls f14,f21,f9
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,52(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 52);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// lfs f22,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 - ctx.f26.f64));
	// lfs f22,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f22.f64 = double(temp.f32);
	// fadds f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f19.f64));
	// stfs f21,224(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// lfs f20,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f21,216(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f21,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f20,f21,f8,f16
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f8.f64 - ctx.f16.f64));
	// stfs f20,240(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f18,f20,f9,f15
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 + ctx.f15.f64));
	// stfs f18,128(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f17,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f20,f8,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64 - ctx.f14.f64));
	// lfs f18,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,308(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// lfs f17,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f18.f64 = double(temp.f32);
	// stfs f20,124(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f20,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f24,f6
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// stfs f18,280(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// lfs f14,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f4
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f21,f9,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f16.f64));
	// stfs f21,168(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f21,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f18,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f18.f64 = double(temp.f32);
	// stfsx f21,r29,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmuls f20,f29,f6
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f6.f64));
	// fmuls f21,f27,f6
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f18,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// fmsubs f27,f27,f7,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 - ctx.f20.f64));
	// lfs f20,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f29,f29,f7,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f7.f64 + ctx.f21.f64));
	// lfs f21,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f24,f24,f7,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 - ctx.f18.f64));
	// fsubs f18,f26,f25
	ctx.f18.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfsx f18,r11,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmadds f21,f21,f7,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f17.f64));
	// fmadds f20,f20,f5,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 + ctx.f16.f64));
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfsx f26,r10,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f26,f28,f22
	ctx.f26.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// stfsx f26,r11,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f25,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f25.f64 = double(temp.f32);
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// lfs f26,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f26.f64 = double(temp.f32);
	// mulli r11,r8,172
	ctx.r11.s64 = ctx.r8.s64 * 172;
	// stfsx f28,r10,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f26,f25
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f18,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f18.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f22,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f22.f64 = double(temp.f32);
	// mulli r10,r8,44
	ctx.r10.s64 = ctx.r8.s64 * 44;
	// fsubs f25,f22,f18
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// lfs f16,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f16.f64 = double(temp.f32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f18,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f5,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 - ctx.f15.f64));
	// lfs f15,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,136(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f16
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f16.f64));
	// stfs f15,108(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// fmsubs f15,f23,f5,f14
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 - ctx.f14.f64));
	// fmuls f14,f23,f4
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// mulli r9,r8,236
	ctx.r9.s64 = ctx.r8.s64 * 236;
	// fadds f23,f25,f28
	ctx.f23.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// stfs f23,128(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// stfs f28,308(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fadds f25,f24,f29
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// fsubs f29,f24,f29
	ctx.f29.f64 = double(float(ctx.f24.f64 - ctx.f29.f64));
	// lfs f24,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f30
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// fadds f28,f16,f26
	ctx.f28.f64 = double(float(ctx.f16.f64 + ctx.f26.f64));
	// mulli r31,r8,108
	ctx.r31.s64 = ctx.r8.s64 * 108;
	// fadds f23,f15,f20
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f23,240(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fsubs f20,f15,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 - ctx.f20.f64));
	// lfs f15,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f16.f64));
	// mulli r30,r8,140
	ctx.r30.s64 = ctx.r8.s64 * 140;
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f17.f64));
	// stfs f23,132(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 - ctx.f23.f64));
	// lfs f17,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,168(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f15,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,216(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f15,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// lfs f15,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f15.f64));
	// stfs f17,124(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f17,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f5,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// fadds f14,f21,f27
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// stfs f24,108(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f14,224(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// lfs f14,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f14.f64 = double(temp.f32);
	// fadds f15,f15,f22
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// lfs f24,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfs f21,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f21.f64 = double(temp.f32);
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// lfs f21,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f21.f64 = double(temp.f32);
	// mulli r29,r8,12
	ctx.r29.s64 = ctx.r8.s64 * 12;
	// lfs f16,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f16.f64 = double(temp.f32);
	// mulli r28,r8,204
	ctx.r28.s64 = ctx.r8.s64 * 204;
	// fsubs f14,f21,f16
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f14,128(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfs f18,240(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fsubs f17,f28,f25
	ctx.f17.f64 = double(float(ctx.f28.f64 - ctx.f25.f64));
	// lfs f18,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f18.f64 = double(temp.f32);
	// fadds f14,f25,f28
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f28.f64));
	// lfs f28,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f25,f15,f28
	ctx.f25.f64 = double(float(ctx.f15.f64 - ctx.f28.f64));
	// fadds f15,f28,f15
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// fsubs f28,f22,f29
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f29.f64));
	// fadds f22,f29,f22
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f22.f64));
	// fsubs f29,f26,f27
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// stfs f29,224(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfs f26,280(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfs f26,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f26.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// fadds f29,f24,f26
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f26,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f26.f64 = double(temp.f32);
	// stfs f27,216(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmr f27,f26
	ctx.f27.f64 = ctx.f26.f64;
	// lfs f26,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f16,f23,f20
	ctx.f16.f64 = double(float(ctx.f23.f64 - ctx.f20.f64));
	// fadds f20,f20,f23
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f23.f64));
	// lfs f23,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f23.f64 = double(temp.f32);
	// stfs f28,168(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// mulli r27,r8,76
	ctx.r27.s64 = ctx.r8.s64 * 76;
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f21,r10,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f21,f23,f2
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fmsubs f26,f26,f2,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f18.f64));
	// stfs f26,108(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fmadds f28,f27,f3,f21
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f21.f64));
	// fmsubs f27,f27,f2,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 - ctx.f23.f64));
	// lfs f26,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f26.f64 = double(temp.f32);
	// stfs f25,128(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fsubs f24,f24,f26
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// stfsx f24,r11,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// mulli r11,r8,164
	ctx.r11.s64 = ctx.r8.s64 * 164;
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fadds f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// lfs f24,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f24.f64 = double(temp.f32);
	// fmr f25,f24
	ctx.f25.f64 = ctx.f24.f64;
	// stfsx f26,r10,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f26.f64 = double(temp.f32);
	// stfsx f16,r9,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// stfsx f20,r31,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// mulli r10,r8,36
	ctx.r10.s64 = ctx.r8.s64 * 36;
	// fsubs f24,f26,f25
	ctx.f24.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// stfsx f24,r9,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfsx f26,r31,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// stfsx f17,r30,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f14,r29,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lfs f25,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfs f24,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// lfs f23,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f23,r30,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f15,r29,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// stfsx f23,r28,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f22,r27,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// stfsx f23,r28,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f23,r27,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// lfs f23,60(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 60);
	ctx.f23.f64 = double(temp.f32);
	// mulli r9,r8,228
	ctx.r9.s64 = ctx.r8.s64 * 228;
	// lfs f24,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f24.f64 = double(temp.f32);
	// mulli r31,r8,100
	ctx.r31.s64 = ctx.r8.s64 * 100;
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f17,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f17.f64 = double(temp.f32);
	// lfs f22,56(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 56);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f17,f10
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f23,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f22,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f22,f10
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f22,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f10
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f22,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f10
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f20,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f22,f22,f11,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f21.f64));
	// lfs f21,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f20,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f14,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 + ctx.f20.f64));
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f14,f11,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 + ctx.f18.f64));
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f14,f11,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f16.f64));
	// stfs f16,256(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmadds f17,f17,f11,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f15.f64));
	// stfs f17,324(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f26,f31
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// lfs f16,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f24,f31
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// mulli r30,r8,132
	ctx.r30.s64 = ctx.r8.s64 * 132;
	// rlwinm r29,r8,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmadds f17,f16,f3,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f17.f64));
	// stfs f17,220(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f17,f25,f31
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fmuls f16,f23,f31
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// fmsubs f25,f25,f1,f15
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 - ctx.f15.f64));
	// fmadds f23,f23,f1,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f14.f64));
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f26,f26,f1,f17
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f17.f64));
	// fmsubs f24,f24,f1,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 - ctx.f16.f64));
	// fsubs f16,f22,f18
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// fsubs f17,f21,f20
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// lfs f18,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f20,f18,f15
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f15.f64));
	// fadds f18,f15,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 + ctx.f18.f64));
	// fadds f15,f24,f26
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fadds f24,f23,f25
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// fadds f23,f16,f14
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fsubs f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 - ctx.f16.f64));
	// fadds f14,f20,f17
	ctx.f14.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// fsubs f17,f23,f15
	ctx.f17.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfsx f17,r11,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f23,f16,f25
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f25.f64));
	// fadds f17,f25,f16
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// fsubs f25,f14,f24
	ctx.f25.f64 = double(float(ctx.f14.f64 - ctx.f24.f64));
	// stfsx f25,r11,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f25,f24,f14
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfsx f25,r10,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f25,f20,f26
	ctx.f25.f64 = double(float(ctx.f20.f64 - ctx.f26.f64));
	// stfsx f25,r9,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// stfsx f26,r31,r6
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f26,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f26.f64 = double(temp.f32);
	// fadds f25,f18,f29
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// fadds f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfsx f23,r9,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f25,f26
	ctx.f24.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// lfs f16,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f26,f25
	ctx.f23.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// lfs f20,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f29,f29,f18
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfsx f17,r31,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f26,f16,f20
	ctx.f26.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fsubs f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f16.f64));
	// lfs f15,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f17.f64 = double(temp.f32);
	// mulli r11,r8,196
	ctx.r11.s64 = ctx.r8.s64 * 196;
	// stfs f20,316(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fsubs f20,f17,f15
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f15.f64));
	// stfs f20,332(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fadds f25,f15,f17
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// lfs f20,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r8,68
	ctx.r10.s64 = ctx.r8.s64 * 68;
	// stfsx f24,r30,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fmuls f17,f20,f11
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f24,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f20.f64 = double(temp.f32);
	// fadds f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f14.f64));
	// stfsx f23,r29,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fmuls f16,f20,f10
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// lfs f14,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f20,f11
	ctx.f15.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f23,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f20.f64 = double(temp.f32);
	// fadds f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// fmuls f14,f20,f11
	ctx.f14.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f18,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f21,f22
	ctx.f20.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f20,204(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// lfs f21,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f21.f64 = double(temp.f32);
	// fadds f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// lfs f21,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// lfs f19,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f18,f18,f10,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 - ctx.f17.f64));
	// lfs f17,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f11,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f16.f64));
	// stfs f17,252(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f16,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,340(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f16,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,256(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f17,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f17,f17,f10,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f15.f64));
	// stfs f17,324(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f17,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f23,f1
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// fmadds f17,f17,f10,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f14.f64));
	// stfs f17,128(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f23,f31
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// lfs f17,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,120(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,68(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 68, temp.u32);
	// fmuls f17,f25,f31
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fmuls f16,f25,f1
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// lfs f25,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// stfs f25,356(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fmuls f23,f23,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fmadds f25,f26,f1,f17
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f17.f64));
	// stfs f23,348(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmsubs f26,f26,f31,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f31.f64 - ctx.f16.f64));
	// lfs f17,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f23,f24,f31,f15
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f31.f64 - ctx.f15.f64));
	// fsubs f16,f17,f20
	ctx.f16.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfsx f16,r30,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// stfsx f20,r29,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f20,f22,f28
	ctx.f20.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// stfsx f20,r11,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// stfsx f28,r10,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f29,f27
	ctx.f28.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfsx f28,r11,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f29,r10,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f21,f19
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// lfs f22,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f22.f64 = double(temp.f32);
	// fadds f28,f19,f21
	ctx.f28.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// lfs f16,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f18,f22
	ctx.f27.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// fmadds f21,f21,f3,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f16.f64));
	// lfs f20,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f20.f64 = double(temp.f32);
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f24,f24,f1,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f14.f64));
	// fsubs f19,f18,f17
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// lfs f15,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// mulli r11,r8,188
	ctx.r11.s64 = ctx.r8.s64 * 188;
	// mulli r10,r8,60
	ctx.r10.s64 = ctx.r8.s64 * 60;
	// mulli r9,r8,252
	ctx.r9.s64 = ctx.r8.s64 * 252;
	// mulli r31,r8,124
	ctx.r31.s64 = ctx.r8.s64 * 124;
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f20,f20,f3,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 - ctx.f16.f64));
	// lfs f16,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f16,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f15.f64));
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// stfs f16,148(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f16,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f16,f2
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f16,f2
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// fadds f16,f27,f29
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfs f16,272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// lfs f27,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f27.f64 = double(temp.f32);
	// fadds f16,f17,f19
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f17.f64));
	// stfs f19,328(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f17,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f27,f27,f3,f15
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 - ctx.f15.f64));
	// lfs f19,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f19.f64 = double(temp.f32);
	// fadds f15,f23,f25
	ctx.f15.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// stfs f15,204(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// lfs f15,68(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 68);
	ctx.f15.f64 = double(temp.f32);
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// stfs f19,356(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fmadds f15,f15,f3,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 + ctx.f14.f64));
	// lfs f17,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f18,f22
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// lfs f19,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// stfs f14,252(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fadds f14,f24,f26
	ctx.f14.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// lfs f24,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// lfs f24,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// lfs f18,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f23.f64 = double(temp.f32);
	// fadds f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// fsubs f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f23.f64));
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f23,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// stfs f23,256(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f18,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f18.f64 = double(temp.f32);
	// mulli r30,r8,156
	ctx.r30.s64 = ctx.r8.s64 * 156;
	// lfs f23,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f23.f64 = double(temp.f32);
	// mulli r29,r8,28
	ctx.r29.s64 = ctx.r8.s64 * 28;
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f23,340(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fadds f23,f27,f21
	ctx.f23.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fadds f21,f15,f20
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f20.f64));
	// stfs f21,336(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// fsubs f21,f20,f15
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f15.f64));
	// stfs f21,348(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// lfs f21,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f19,f4
	ctx.f18.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fsubs f20,f17,f21
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f21.f64));
	// fadds f17,f21,f17
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// lfs f21,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f15,f21,f14
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// fsubs f14,f22,f25
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// fadds f22,f25,f22
	ctx.f22.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// fsubs f25,f28,f26
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// stfs f25,204(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fadds f28,f26,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// stfs f28,252(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fsubs f28,f30,f24
	ctx.f28.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// lfs f26,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f26.f64 = double(temp.f32);
	// fadds f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 + ctx.f30.f64));
	// lfs f24,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// stfsx f24,r11,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f24,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f24.f64 = double(temp.f32);
	// fmr f25,f26
	ctx.f25.f64 = ctx.f26.f64;
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// stfsx f24,r10,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f24,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f24.f64 = double(temp.f32);
	// mulli r28,r8,220
	ctx.r28.s64 = ctx.r8.s64 * 220;
	// fsubs f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// mulli r27,r8,92
	ctx.r27.s64 = ctx.r8.s64 * 92;
	// fmadds f26,f25,f5,f18
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f18.f64));
	// fmsubs f25,f25,f4,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 - ctx.f19.f64));
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 - ctx.f23.f64));
	// stfsx f23,r11,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f23,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r8,180
	ctx.r11.s64 = ctx.r8.s64 * 180;
	// fadds f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f16.f64));
	// stfsx f23,r10,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfsx f24,r9,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f24,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// stfsx f27,r31,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f24,f29,f27
	ctx.f24.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfsx f24,r9,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// stfsx f20,r30,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// mulli r10,r8,52
	ctx.r10.s64 = ctx.r8.s64 * 52;
	// lfs f27,72(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 72);
	ctx.f27.f64 = double(temp.f32);
	// lfs f29,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f29.f64 = double(temp.f32);
	// stfsx f17,r29,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// stfsx f15,r30,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f24,76(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 76);
	ctx.f24.f64 = double(temp.f32);
	// lfs f27,64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 64);
	ctx.f27.f64 = double(temp.f32);
	// stfsx f21,r29,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfsx f14,r28,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// stfsx f22,r27,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,44(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 44);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f24.f64 = double(temp.f32);
	// stfsx f22,r28,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f22,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f22,r27,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// lfs f22,28(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 28);
	ctx.f22.f64 = double(temp.f32);
	// mulli r9,r8,244
	ctx.r9.s64 = ctx.r8.s64 * 244;
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f22,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f22,f8
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// lfs f22,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f15,f22,f8
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// lfs f17,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f17,f8
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// lfs f19,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f16,f19,f8
	ctx.f16.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// lfs f20,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f20.f64 = double(temp.f32);
	// lfs f14,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f14.f64 = double(temp.f32);
	// mulli r31,r8,116
	ctx.r31.s64 = ctx.r8.s64 * 116;
	// fmadds f19,f19,f9,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 + ctx.f18.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f17,f17,f9,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f15.f64));
	// stfs f17,388(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fmsubs f22,f22,f9,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 - ctx.f21.f64));
	// lfs f21,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f18,f18,f9,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 - ctx.f16.f64));
	// lfs f16,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// lfs f20,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f16,f5
	ctx.f15.f64 = double(float(ctx.f16.f64 * ctx.f5.f64));
	// fsubs f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f14.f64));
	// fmuls f14,f17,f5
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// fmsubs f17,f17,f4,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 - ctx.f15.f64));
	// stfs f17,40(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 40, temp.u32);
	// fmuls f15,f27,f7
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmadds f17,f16,f4,f14
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 + ctx.f14.f64));
	// stfs f17,392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmuls f16,f23,f7
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f7.f64));
	// fmuls f17,f29,f7
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f7.f64));
	// fmuls f14,f24,f7
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fmsubs f29,f29,f6,f15
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 - ctx.f15.f64));
	// fmsubs f24,f24,f6,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 - ctx.f16.f64));
	// fmadds f27,f27,f6,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f17.f64));
	// fmadds f23,f23,f6,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f14.f64));
	// fsubs f16,f22,f19
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// fsubs f17,f21,f20
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f20.f64));
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// fadds f15,f24,f27
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// fsubs f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// fadds f24,f23,f29
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f29.f64));
	// fsubs f29,f29,f23
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f23.f64));
	// fadds f23,f16,f28
	ctx.f23.f64 = double(float(ctx.f16.f64 + ctx.f28.f64));
	// fsubs f28,f28,f16
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f16.f64));
	// lfs f19,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// fsubs f14,f23,f15
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f15.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f23,f28,f29
	ctx.f23.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fadds f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f28.f64));
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// fadds f16,f20,f17
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f17.f64));
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// lfs f18,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f26.f64));
	// fadds f17,f19,f30
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f30.f64));
	// fsubs f28,f16,f24
	ctx.f28.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// stfsx f28,r11,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f28,f24,f16
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f16.f64));
	// stfsx f28,r10,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f20,f27
	ctx.f28.f64 = double(float(ctx.f20.f64 - ctx.f27.f64));
	// stfsx f28,r9,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f28,f27,f20
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// stfsx f28,r31,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f24,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f24.f64 = double(temp.f32);
	// mulli r11,r8,148
	ctx.r11.s64 = ctx.r8.s64 * 148;
	// stfsx f23,r9,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f28,f24,f25
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f27,f21,f22
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// lfs f23,40(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 40);
	ctx.f23.f64 = double(temp.f32);
	// fadds f29,f21,f22
	ctx.f29.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fsubs f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 - ctx.f26.f64));
	// mulli r9,r8,212
	ctx.r9.s64 = ctx.r8.s64 * 212;
	// fsubs f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// mulli r31,r8,84
	ctx.r31.s64 = ctx.r8.s64 * 84;
	// fsubs f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f19.f64));
	// fsubs f24,f17,f18
	ctx.f24.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfsx f24,r11,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f18,f17
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfsx f23,r10,r5
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f24,f29,f28
	ctx.f24.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// stfsx f24,r11,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// stfsx f29,r10,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f28,f27,f26
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// stfsx f28,r9,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f26,f30,f25
	ctx.f26.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// stfsx f27,r31,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f25,f30
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// stfsx f26,r9,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// stfsx f30,r31,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + -26212);
	// add r3,r25,r3
	ctx.r3.u64 = ctx.r25.u64 + ctx.r3.u64;
	// add r4,r25,r4
	ctx.r4.u64 = ctx.r25.u64 + ctx.r4.u64;
	// add r6,r24,r6
	ctx.r6.u64 = ctx.r24.u64 + ctx.r6.u64;
	// add r5,r24,r5
	ctx.r5.u64 = ctx.r24.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82ca48b0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CA48B0;
loc_82CA742C:
	// addi r1,r1,800
	ctx.r1.s64 = ctx.r1.s64 + 800;
	// addi r12,r1,-128
	ctx.r12.s64 = ctx.r1.s64 + -128;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA7438;
	__restfpr_14(ctx, base);
	// b 0x82d5c4ec
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA7440"))) PPC_WEAK_FUNC(sub_82CA7440);
PPC_FUNC_IMPL(__imp__sub_82CA7440) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27304
	ctx.r5.s64 = ctx.r11.s64 + -27304;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,18440
	ctx.r4.s64 = ctx.r11.s64 + 18440;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA7458"))) PPC_WEAK_FUNC(sub_82CA7458);
PPC_FUNC_IMPL(__imp__sub_82CA7458) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82CA7460;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82d5c540
	ctx.lr = 0x82CA7468;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82ca8548
	if (!ctx.cr6.gt) goto loc_82CA8548;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r23,r10,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lfs f8,27788(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 27788);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32236
	ctx.r10.s64 = -2112618496;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f9,27792(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 27792);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,27780(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 27780);
	ctx.f10.f64 = double(temp.f32);
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f11,27784(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 27784);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,27776(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27776);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-29656(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29656);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29652(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82CA74BC:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f7,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r10,r7,80
	ctx.r10.s64 = ctx.r7.s64 * 80;
	// lfs f6,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f15,f5,f4
	ctx.f15.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// mulli r9,r7,112
	ctx.r9.s64 = ctx.r7.s64 * 112;
	// lfsx f3,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f4,f3,f2
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// fadds f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfsx f1,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// mulli r31,r7,48
	ctx.r31.s64 = ctx.r7.s64 * 48;
	// lfsx f30,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f2,f1,f30
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// stfs f2,-460(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// rlwinm r30,r7,6,0,25
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// lfsx f29,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// rlwinm r29,r7,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f2,f31,f29
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f29.f64));
	// mulli r28,r7,96
	ctx.r28.s64 = ctx.r7.s64 * 96;
	// fadds f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f31,f29,f31
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f31.f64));
	// lfsx f28,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f28,f7
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f7.f64));
	// lfsx f26,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f29,f27,f6
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// lfsx f25,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// rlwinm r27,r7,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f24,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r26,r7,72
	ctx.r26.s64 = ctx.r7.s64 * 72;
	// lfsx f23,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f28.f64));
	// fadds f28,f25,f26
	ctx.f28.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f26,f23,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfsx f22,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f25,f24,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfsx f21,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f20,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f24,f21,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// mulli r25,r7,40
	ctx.r25.s64 = ctx.r7.s64 * 40;
	// lfsx f19,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f23,f22,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f22,f19,f20
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f21,f20,f19
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// lfsx f18,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfsx f17,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// mulli r24,r7,104
	ctx.r24.s64 = ctx.r7.s64 * 104;
	// lfsx f16,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f16,f18
	ctx.f20.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// lfsx f14,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f19,f18,f16
	ctx.f19.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// fadds f18,f4,f15
	ctx.f18.f64 = double(float(ctx.f4.f64 + ctx.f15.f64));
	// fsubs f4,f4,f15
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f15.f64));
	// lfs f15,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f16,f15,f2
	ctx.f16.f64 = double(float(ctx.f15.f64 - ctx.f2.f64));
	// fadds f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f15.f64));
	// fadds f15,f1,f5
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// stfs f15,-284(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fadds f15,f31,f3
	ctx.f15.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f5.f64));
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f1,f28,f30
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fsubs f31,f30,f28
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fsubs f30,f29,f26
	ctx.f30.f64 = double(float(ctx.f29.f64 - ctx.f26.f64));
	// fadds f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// fsubs f26,f6,f27
	ctx.f26.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fadds f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 + ctx.f6.f64));
	// fsubs f27,f16,f18
	ctx.f27.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fsubs f28,f7,f25
	ctx.f28.f64 = double(float(ctx.f7.f64 - ctx.f25.f64));
	// fadds f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 + ctx.f7.f64));
	// fadds f25,f18,f16
	ctx.f25.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// fsubs f18,f4,f2
	ctx.f18.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// fadds f16,f2,f4
	ctx.f16.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fmuls f4,f27,f0
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f27,f18,f0
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// mulli r11,r7,120
	ctx.r11.s64 = ctx.r7.s64 * 120;
	// fsubs f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// mulli r10,r7,56
	ctx.r10.s64 = ctx.r7.s64 * 56;
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fmuls f2,f25,f0
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f25,f16,f0
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f16,f19,f21
	ctx.f16.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fsubs f19,f24,f20
	ctx.f19.f64 = double(float(ctx.f24.f64 - ctx.f20.f64));
	// fadds f24,f20,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// lfsx f20,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f14,f23,f18
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f14,-460(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// fadds f18,f18,f23
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f14,-436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// fsubs f14,f22,f17
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,-328(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// mulli r9,r7,24
	ctx.r9.s64 = ctx.r7.s64 * 24;
	// lfsx f22,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-388(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmuls f23,f21,f13
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// stfs f23,-416(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// stfs f18,-376(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfsx f22,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-312(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// mulli r31,r7,88
	ctx.r31.s64 = ctx.r7.s64 * 88;
	// lfsx f22,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-440(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-300(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// mulli r30,r7,124
	ctx.r30.s64 = ctx.r7.s64 * 124;
	// lfsx f22,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// fmsubs f21,f21,f12,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 - ctx.f18.f64));
	// stfs f21,-264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfsx f22,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// mulli r29,r7,60
	ctx.r29.s64 = ctx.r7.s64 * 60;
	// lfsx f22,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-352(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfsx f22,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-448(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f22,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f22.f64 = double(temp.f32);
	// fmr f23,f22
	ctx.f23.f64 = ctx.f22.f64;
	// fsubs f22,f14,f19
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f19.f64));
	// stfs f22,-392(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// fmr f22,f14
	ctx.f22.f64 = ctx.f14.f64;
	// lfs f18,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f12,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f18.f64));
	// stfs f21,-280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fmuls f17,f23,f12
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// stfs f23,-460(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fadds f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f22.f64));
	// stfs f22,-348(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lfs f22,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfs f22,-456(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f19,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f23,f22,f19
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// lfs f22,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// stfs f22,-412(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fmr f20,f19
	ctx.f20.f64 = ctx.f19.f64;
	// lfs f22,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fmsubs f20,f16,f13,f17
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f17.f64));
	// lfs f17,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f16,f12,f17
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f17.f64));
	// lfs f17,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f21,f17,f14
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f18.f64 = double(temp.f32);
	// mulli r10,r7,76
	ctx.r10.s64 = ctx.r7.s64 * 76;
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f18,f16,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f18.f64));
	// fadds f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f16,-460(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f16,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f16.f64 = double(temp.f32);
	// mulli r9,r7,108
	ctx.r9.s64 = ctx.r7.s64 * 108;
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f16
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 - ctx.f14.f64));
	// fadds f14,f21,f23
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f14,-376(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f23,-448(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f23,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f23,-456(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// fsubs f14,f14,f18
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f18.f64));
	// stfs f14,-416(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f21,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f23,f21,f17
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// mulli r11,r7,12
	ctx.r11.s64 = ctx.r7.s64 * 12;
	// fadds f21,f17,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// stfs f21,-364(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// mulli r31,r7,44
	ctx.r31.s64 = ctx.r7.s64 * 44;
	// mulli r30,r7,28
	ctx.r30.s64 = ctx.r7.s64 * 28;
	// rlwinm r28,r7,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r27,r7,68
	ctx.r27.s64 = ctx.r7.s64 * 68;
	// lfs f18,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f14,f22,f18
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f18.f64));
	// stfs f14,-460(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fadds f22,f18,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 + ctx.f22.f64));
	// stfs f22,-340(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f21,f22,f13
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f18,f22,f12
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f22,f13
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f22,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f22.f64 = double(temp.f32);
	// fadds f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f14,-320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f14,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,-460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// fsubs f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f14.f64));
	// lfs f14,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f14.f64 = double(temp.f32);
	// fmr f22,f14
	ctx.f22.f64 = ctx.f14.f64;
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f21,f22,f12,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f21.f64));
	// stfs f21,-312(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fmsubs f22,f22,f13,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f18.f64));
	// stfs f22,-300(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// lfs f22,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f22,-272(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// lfsx f17,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfs f21,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f22,f22,f12,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f21.f64));
	// stfs f22,-288(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f22,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r29,r7,92
	ctx.r29.s64 = ctx.r7.s64 * 92;
	// fadds f18,f22,f14
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// lfsx f21,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// lfsx f14,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-456(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfsx f14,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-448(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfsx f14,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-424(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// mulli r11,r7,36
	ctx.r11.s64 = ctx.r7.s64 * 36;
	// lfsx f14,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-388(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// mulli r10,r7,100
	ctx.r10.s64 = ctx.r7.s64 * 100;
	// lfsx f14,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-432(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-436(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfsx f14,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-408(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfsx f14,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-372(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfsx f14,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-356(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lfsx f14,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfsx f14,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-460(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfsx f14,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfsx f14,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-420(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfsx f14,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfsx f14,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfsx f14,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-368(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f14,-376(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f14,-444(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-464(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfsx f17,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-416(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfsx f17,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f17.f64 = double(temp.f32);
	// stfs f17,-396(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-440(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-456(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,-448(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f17,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,-432(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f14,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-424(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-436(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f14,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f14,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f17,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-428(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-384(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f17,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,-408(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f14,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f17,-400(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f17,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f14,-412(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// lfs f14,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f14.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-296(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfs f17,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f17,f14
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// stfs f14,-444(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-420(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-416(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// lfs f14,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-440(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f14,f21
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f21.f64));
	// stfs f14,-304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f14,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f21,-256(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f21,-248(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f21,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f14.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f14.f64));
	// stfs f14,-316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f14,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f14.f64 = double(temp.f32);
	// fadds f21,f14,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 + ctx.f21.f64));
	// stfs f21,-260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f21,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,-276(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f21,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f16,f21
	ctx.f18.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// stfs f18,-376(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fadds f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f16.f64));
	// stfs f21,-292(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// lfs f21,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f22,f21
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f18,-268(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-460(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -460, temp.u32);
	// lfs f22,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f18,f22,f21
	ctx.f18.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// fadds f16,f21,f22
	ctx.f16.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// fmuls f21,f18,f0
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f21,-416(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -416, temp.u32);
	// fmuls f21,f16,f0
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f21,-296(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// fmuls f21,f14,f0
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f21,-412(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -412, temp.u32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,-252(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f22,f17
	ctx.f21.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f21,-464(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,-356(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// mulli r11,r7,20
	ctx.r11.s64 = ctx.r7.s64 * 20;
	// lfs f21,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f21.f64 = double(temp.f32);
	// mulli r10,r7,84
	ctx.r10.s64 = ctx.r7.s64 * 84;
	// lfs f22,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-432(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -432, temp.u32);
	// lfs f21,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f18,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f21.f64 = double(temp.f32);
	// stfs f22,-424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -424, temp.u32);
	// fsubs f22,f18,f21
	ctx.f22.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,-448(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -448, temp.u32);
	// lfs f21,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f18,f21
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f17,-440(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f17,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f17,-372(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f16,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f16.f64 = double(temp.f32);
	// mulli r9,r7,116
	ctx.r9.s64 = ctx.r7.s64 * 116;
	// lfs f17,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fmuls f16,f22,f13
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f14,f22,f12
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f22,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfs f22,-396(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fsubs f22,f21,f18
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f18,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f18.f64 = double(temp.f32);
	// mulli r31,r7,52
	ctx.r31.s64 = ctx.r7.s64 * 52;
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f21,-452(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f21,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,-388(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f12,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f21,-324(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// fsubs f21,f30,f5
	ctx.f21.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfs f21,-456(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -456, temp.u32);
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f18,f21
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f17,-352(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,-316(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f13,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f14.f64));
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f14,-304(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfs f22,-380(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// fsubs f22,f31,f3
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// stfs f21,-332(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lfs f16,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f17,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfs f21,-408(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f18,-428(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// stfs f17,-368(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfsx f21,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-344(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// lfsx f17,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f16.f64 = double(temp.f32);
	// stfs f22,-360(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfsx f22,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-464(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfsx f22,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f22,-444(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f14,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// lfsx f14,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,-452(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fadds f14,f17,f21
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f21.f64));
	// fsubs f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f17.f64));
	// stfs f22,-336(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfsx f22,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// stfs f14,-400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fadds f14,f16,f18
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f18.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f17.f64));
	// stfs f17,-420(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// stfs f22,-396(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f16,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f16,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 - ctx.f22.f64));
	// fadds f16,f18,f21
	ctx.f16.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fsubs f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfs f21,-440(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// lfs f21,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f21.f64));
	// stfs f18,-464(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fsubs f18,f14,f17
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f18,-452(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// lfs f18,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f18.f64 = double(temp.f32);
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// stfs f21,-436(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -436, temp.u32);
	// lfs f18,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f21,f18,f22
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f22.f64));
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// fadds f18,f17,f14
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f14.f64));
	// lfs f17,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f17.f64 = double(temp.f32);
	// stfs f18,-404(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f14,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-396(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-400(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f14,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-384(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f17,f21,f16
	ctx.f17.f64 = double(float(ctx.f21.f64 - ctx.f16.f64));
	// fadds f16,f16,f21
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f21,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f14,f21,f22
	ctx.f14.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// stfs f21,-420(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -420, temp.u32);
	// lfs f18,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f21,-464(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// lfs f21,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f21,f18
	ctx.f18.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// stfs f18,-444(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f21,-308(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// fmuls f21,f16,f0
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f21,-428(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -428, temp.u32);
	// fmuls f21,f14,f0
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// stfs f21,-440(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -440, temp.u32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f22,-372(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f22,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f17,f22,f12
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// lfs f21,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f22,f13
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfs f5,-396(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f5,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f5.f64 = double(temp.f32);
	// fadds f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f31.f64));
	// lfs f30,-456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -456);
	ctx.f30.f64 = double(temp.f32);
	// mulli r11,r8,88
	ctx.r11.s64 = ctx.r8.s64 * 88;
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fmsubs f5,f5,f12,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 - ctx.f18.f64));
	// fmsubs f22,f21,f13,f17
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f13.f64 - ctx.f17.f64));
	// lfs f17,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f21,f21,f12,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f16.f64));
	// mulli r9,r8,120
	ctx.r9.s64 = ctx.r8.s64 * 120;
	// fsubs f16,f22,f17
	ctx.f16.f64 = double(float(ctx.f22.f64 - ctx.f17.f64));
	// stfs f16,-452(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -452, temp.u32);
	// fadds f22,f17,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f22.f64));
	// stfs f22,-400(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f22,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f22.f64 = double(temp.f32);
	// fadds f17,f22,f21
	ctx.f17.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// stfs f17,-332(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-324(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f22,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f22.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// lfs f17,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f17.f64 = double(temp.f32);
	// stfs f5,-464(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -464, temp.u32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f16,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f16.f64 = double(temp.f32);
	// mulli r31,r8,56
	ctx.r31.s64 = ctx.r8.s64 * 56;
	// lfs f5,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f5.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// fadds f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfs f5,-392(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f30,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f30.f64 = double(temp.f32);
	// lfs f5,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// lfs f21,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f30,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f31,f23,f0
	ctx.f31.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f23,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f12,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f22.f64));
	// lfs f22,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f22.f64 = double(temp.f32);
	// stfs f5,-356(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// mulli r30,r8,72
	ctx.r30.s64 = ctx.r8.s64 * 72;
	// lfs f5,-448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -448);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f5,f12,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f17.f64));
	// stfs f5,-348(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// fmuls f5,f16,f0
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// stfs f5,-320(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f5,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// stfs f5,-408(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -408, temp.u32);
	// lfs f30,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f30.f64 = double(temp.f32);
	// lfs f5,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f22,f22,f12,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f21.f64));
	// fsubs f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfs f5,-444(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -444, temp.u32);
	// lfs f5,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f5.f64 = double(temp.f32);
	// rlwinm r29,r8,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r28,r8,104
	ctx.r28.s64 = ctx.r8.s64 * 104;
	// mulli r27,r8,40
	ctx.r27.s64 = ctx.r8.s64 * 40;
	// lfs f14,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f14.f64 = double(temp.f32);
	// lfs f30,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f18,f5,f30
	ctx.f18.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// lfs f21,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f30,f5
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// lfs f30,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f16,f30,f21
	ctx.f16.f64 = double(float(ctx.f30.f64 - ctx.f21.f64));
	// lfs f5,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f5.f64 = double(temp.f32);
	// fadds f30,f30,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,-452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -452);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 - ctx.f14.f64));
	// fadds f5,f21,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// stfs f30,-360(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fsubs f30,f22,f23
	ctx.f30.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfs f5,-336(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// fadds f5,f31,f3
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// stfsx f18,r11,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f31,f22,f23
	ctx.f31.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f23,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f22,r11,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f22.f64 = double(temp.f32);
	// mulli r11,r8,80
	ctx.r11.s64 = ctx.r8.s64 * 80;
	// fadds f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// lfs f21,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f21.f64 = double(temp.f32);
	// lfs f23,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f17,r10,r5
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// stfsx f22,r10,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f21,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f18.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// lfs f17,-464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -464);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfs f18,-344(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// stfsx f16,r9,r6
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// stfsx f14,r9,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// lfs f17,-408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -408);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f18.f64 = double(temp.f32);
	// stfsx f18,r31,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f18,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f16,f18,f17
	ctx.f16.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// stfsx f14,r31,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f14,f17,f18
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f18,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f1,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 - ctx.f18.f64));
	// lfs f17,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f17,-392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f17,-444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -444);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fmuls f17,f16,f0
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f16,f14,f0
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fsubs f14,f5,f31
	ctx.f14.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// stfsx f14,r30,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// fsubs f31,f22,f23
	ctx.f31.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f31,r30,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f5,r29,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f22,f23
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f5,r29,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f5,f21,f30
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f30.f64));
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f31,f3,f5
	ctx.f31.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfsx f31,r28,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f31,f21,f30
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfsx f31,r27,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// lfs f23,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f23.f64 = double(temp.f32);
	// stfsx f5,r27,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f30,f23,f24
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f3,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f3.f64 = double(temp.f32);
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f22,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f22.f64 = double(temp.f32);
	// lfs f5,-420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -420);
	ctx.f5.f64 = double(temp.f32);
	// fadds f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f1.f64));
	// fadds f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// lfs f31,-424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -424);
	ctx.f31.f64 = double(temp.f32);
	// lfs f22,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f22.f64 = double(temp.f32);
	// lfs f3,-432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -432);
	ctx.f3.f64 = double(temp.f32);
	// lfs f23,-436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -436);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f31,f29,f15
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f15.f64));
	// lfs f21,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f21.f64 = double(temp.f32);
	// fadds f29,f15,f29
	ctx.f29.f64 = double(float(ctx.f15.f64 + ctx.f29.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// mulli r9,r8,112
	ctx.r9.s64 = ctx.r8.s64 * 112;
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// stfs f21,-368(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f14.f64 = double(temp.f32);
	// mulli r31,r8,48
	ctx.r31.s64 = ctx.r8.s64 * 48;
	// lfs f21,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f14
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// lfs f14,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// stfs f15,-364(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lfs f14,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// stfs f15,-328(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lfs f14,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 - ctx.f14.f64));
	// fsubs f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 - ctx.f17.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// fadds f17,f3,f5
	ctx.f17.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// rlwinm r30,r8,6,0,25
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// fsubs f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfs f5,-404(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// fadds f5,f30,f31
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// rlwinm r29,r8,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f3,f31,f30
	ctx.f3.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// mulli r28,r8,96
	ctx.r28.s64 = ctx.r8.s64 * 96;
	// fadds f31,f24,f1
	ctx.f31.f64 = double(float(ctx.f24.f64 + ctx.f1.f64));
	// fsubs f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f24.f64));
	// fadds f30,f22,f23
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fmuls f22,f17,f0
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// lfs f23,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// stfs f23,-336(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lfs f23,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f23,f23,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// lfs f17,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f17,f0
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f21,-360(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f21,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f21,f29
	ctx.f17.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// stfs f17,-364(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fsubs f29,f29,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f21.f64));
	// lfs f21,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfs f21,-404(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// stfs f29,-344(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f29,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f17,f29,f10
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fsubs f29,f28,f27
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// stfs f21,-340(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f29,f29,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f21.f64));
	// stfs f29,-400(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fsubs f21,f6,f4
	ctx.f21.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// stfs f21,-404(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// lfs f29,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// fsubs f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// stfs f21,-324(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lfs f21,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f21.f64 = double(temp.f32);
	// fadds f29,f29,f21
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// fmadds f21,f15,f11,f17
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f17.f64));
	// stfs f21,-332(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// fsubs f21,f5,f16
	ctx.f21.f64 = double(float(ctx.f5.f64 - ctx.f16.f64));
	// fadds f17,f5,f16
	ctx.f17.f64 = double(float(ctx.f5.f64 + ctx.f16.f64));
	// lfs f5,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f16,f31,f30
	ctx.f16.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// fsubs f5,f5,f22
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f22.f64));
	// stfsx f5,r5,r11
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r5.u32 + ctx.r11.u32, temp.u32);
	// fadds f31,f30,f31
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// stfsx f21,r11,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f23,f1
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// lfs f5,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// fadds f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// stfsx f5,r10,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f5,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f5.f64 = double(temp.f32);
	// mulli r11,r8,92
	ctx.r11.s64 = ctx.r8.s64 * 92;
	// stfsx f17,r10,r6
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f3,f5
	ctx.f22.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfsx f22,r9,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f21,f3,f5
	ctx.f21.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfsx f14,r9,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fmuls f17,f15,f10
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f5,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f5.f64 = double(temp.f32);
	// mulli r10,r8,28
	ctx.r10.s64 = ctx.r8.s64 * 28;
	// lfs f3,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f3.f64 = double(temp.f32);
	// stfsx f21,r31,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f3,f5
	ctx.f22.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// stfsx f18,r31,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f3,f5
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfsx f16,r30,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f22,r30,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f5.f64 = double(temp.f32);
	// stfs f31,0(r5)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f21,f5,f24
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// stfs f3,0(r6)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fsubs f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f24.f64));
	// stfsx f21,r29,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// stfsx f30,r29,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// mulli r9,r8,124
	ctx.r9.s64 = ctx.r8.s64 * 124;
	// lfs f3,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f3.f64 = double(temp.f32);
	// lfs f5,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f5.f64 = double(temp.f32);
	// stfsx f1,r28,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f5.f64));
	// lfs f1,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// lfs f31,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f31.f64 = double(temp.f32);
	// lfs f1,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// lfs f30,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f31.f64 = double(temp.f32);
	// mulli r31,r8,60
	ctx.r31.s64 = ctx.r8.s64 * 60;
	// fsubs f31,f30,f31
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f31.f64));
	// lfs f24,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f24.f64 = double(temp.f32);
	// lfs f30,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f24,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f30.f64));
	// lfs f23,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f24.f64));
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// lfs f18,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f7,f2
	ctx.f23.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fsubs f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 - ctx.f16.f64));
	// lfs f16,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f17,f16,f11,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f17.f64));
	// fmuls f15,f1,f8
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// lfs f22,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f1,f1,f9
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// stfs f1,-404(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -404, temp.u32);
	// stfs f17,-360(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// fsubs f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// fmuls f17,f3,f10
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// mulli r30,r8,84
	ctx.r30.s64 = ctx.r8.s64 * 84;
	// fmuls f16,f5,f10
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fsubs f21,f26,f25
	ctx.f21.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fmuls f14,f24,f9
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fmuls f24,f24,f8
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// stfs f24,-364(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// fmadds f24,f31,f9,f15
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f9.f64 + ctx.f15.f64));
	// mulli r29,r8,20
	ctx.r29.s64 = ctx.r8.s64 * 20;
	// fadds f1,f22,f23
	ctx.f1.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fmsubs f5,f5,f11,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 - ctx.f17.f64));
	// fmadds f3,f3,f11,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fadds f17,f18,f21
	ctx.f17.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fmsubs f16,f30,f8,f14
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f8.f64 - ctx.f14.f64));
	// fsubs f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 - ctx.f18.f64));
	// mulli r28,r8,116
	ctx.r28.s64 = ctx.r8.s64 * 116;
	// mulli r27,r8,52
	ctx.r27.s64 = ctx.r8.s64 * 52;
	// lfs f15,-404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -404);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f31,f31,f8,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f8.f64 - ctx.f15.f64));
	// lfs f15,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f30,f30,f9,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f15.f64));
	// lfs f15,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f15.f64 = double(temp.f32);
	// fsubs f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// lfs f14,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f5,f15
	ctx.f22.f64 = double(float(ctx.f5.f64 + ctx.f15.f64));
	// fadds f18,f3,f14
	ctx.f18.f64 = double(float(ctx.f3.f64 + ctx.f14.f64));
	// fsubs f3,f14,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 - ctx.f3.f64));
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f15.f64));
	// fadds f15,f16,f24
	ctx.f15.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// fsubs f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 - ctx.f24.f64));
	// fadds f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// lfs f2,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f2.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f25,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f25.f64 = double(temp.f32);
	// fadds f16,f30,f31
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fsubs f31,f31,f30
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// fsubs f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfsx f14,r11,r5
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// fadds f30,f27,f28
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfsx f22,r10,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f22,f29,f18
	ctx.f22.f64 = double(float(ctx.f29.f64 - ctx.f18.f64));
	// stfsx f22,r11,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f29,f18,f29
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// stfsx f29,r10,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f29,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f29.f64 = double(temp.f32);
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fsubs f22,f29,f5
	ctx.f22.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// stfsx f22,r9,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f5,f29
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// stfsx f5,r31,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f5,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f5.f64 = double(temp.f32);
	// mulli r11,r8,68
	ctx.r11.s64 = ctx.r8.s64 * 68;
	// fsubs f29,f5,f3
	ctx.f29.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// stfsx f29,r9,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// stfsx f5,r31,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f1,f15
	ctx.f5.f64 = double(float(ctx.f1.f64 - ctx.f15.f64));
	// stfsx f5,r30,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f15,f1
	ctx.f5.f64 = double(float(ctx.f15.f64 + ctx.f1.f64));
	// stfsx f5,r29,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fsubs f5,f17,f16
	ctx.f5.f64 = double(float(ctx.f17.f64 - ctx.f16.f64));
	// stfsx f5,r30,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f5,f16,f17
	ctx.f5.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfsx f5,r29,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f5,f21,f24
	ctx.f5.f64 = double(float(ctx.f21.f64 - ctx.f24.f64));
	// stfsx f5,r28,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f5,-428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -428);
	ctx.f5.f64 = double(temp.f32);
	// mulli r9,r8,100
	ctx.r9.s64 = ctx.r8.s64 * 100;
	// fadds f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// lfs f1,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f3.f64 = double(temp.f32);
	// fadds f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// lfs f29,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f29.f64 = double(temp.f32);
	// lfs f1,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f1,f29
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f29.f64));
	// lfs f22,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f22.f64 = double(temp.f32);
	// lfs f29,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f29.f64 = double(temp.f32);
	// fadds f29,f29,f22
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f22.f64));
	// lfs f22,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f22.f64 = double(temp.f32);
	// fadds f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f22.f64));
	// lfs f22,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f22.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// lfs f18,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f22.f64 = double(temp.f32);
	// mulli r31,r8,36
	ctx.r31.s64 = ctx.r8.s64 * 36;
	// fadds f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f18.f64));
	// lfs f17,-440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -440);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f28.f64 = double(temp.f32);
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f4,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f4.f64 = double(temp.f32);
	// fadds f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// lfs f27,-416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -416);
	ctx.f27.f64 = double(temp.f32);
	// fadds f4,f4,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f20.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// stfsx f24,r27,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f5,f11
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f21,-460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -460);
	ctx.f21.f64 = double(temp.f32);
	// fadds f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// lfs f24,-412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -412);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f20,f29,f11
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f11.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// add r3,r23,r3
	ctx.r3.u64 = ctx.r23.u64 + ctx.r3.u64;
	// fmuls f21,f5,f10
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// add r4,r23,r4
	ctx.r4.u64 = ctx.r23.u64 + ctx.r4.u64;
	// fmuls f17,f1,f11
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// fadds f5,f2,f7
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// fsubs f7,f7,f2
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f2.f64));
	// fmsubs f1,f1,f10,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 - ctx.f20.f64));
	// fmuls f20,f18,f8
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fmadds f2,f3,f11,f21
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 + ctx.f21.f64));
	// fmsubs f3,f3,f10,f19
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 - ctx.f19.f64));
	// fmadds f29,f29,f10,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f10.f64 + ctx.f17.f64));
	// fsubs f19,f23,f31
	ctx.f19.f64 = double(float(ctx.f23.f64 - ctx.f31.f64));
	// stfsx f19,r28,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f31,f31,f23
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f23.f64));
	// stfsx f31,r27,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f21,f25,f26
	ctx.f21.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fmuls f25,f22,f8
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fadds f31,f28,f30
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// fadds f23,f1,f2
	ctx.f23.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fsubs f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// fadds f1,f29,f3
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f3.f64));
	// fsubs f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fsubs f28,f6,f4
	ctx.f28.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fmadds f4,f18,f9,f25
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f9.f64 + ctx.f25.f64));
	// fmsubs f25,f22,f9,f20
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 - ctx.f20.f64));
	// fsubs f29,f5,f23
	ctx.f29.f64 = double(float(ctx.f5.f64 - ctx.f23.f64));
	// stfsx f29,r11,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f23,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 + ctx.f5.f64));
	// stfsx f5,r10,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f29,f21,f1
	ctx.f29.f64 = double(float(ctx.f21.f64 - ctx.f1.f64));
	// stfsx f29,r11,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f21.f64));
	// stfsx f1,r10,r6
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f5,f26,f2
	ctx.f5.f64 = double(float(ctx.f26.f64 - ctx.f2.f64));
	// stfsx f5,r9,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f26.f64));
	// stfsx f2,r31,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f5,f7,f3
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// stfsx f5,r9,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// stfsx f7,r31,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fmuls f7,f24,f8
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// mulli r11,r8,76
	ctx.r11.s64 = ctx.r8.s64 * 76;
	// fmuls f5,f27,f8
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fmsubs f7,f27,f9,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f7.f64));
	// fmadds f5,f24,f9,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f5.f64));
	// mulli r9,r8,108
	ctx.r9.s64 = ctx.r8.s64 * 108;
	// fadds f3,f7,f4
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// fsubs f7,f7,f4
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// fadds f4,f5,f25
	ctx.f4.f64 = double(float(ctx.f5.f64 + ctx.f25.f64));
	// fsubs f5,f25,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 - ctx.f5.f64));
	// mulli r31,r8,44
	ctx.r31.s64 = ctx.r8.s64 * 44;
	// fsubs f2,f31,f3
	ctx.f2.f64 = double(float(ctx.f31.f64 - ctx.f3.f64));
	// stfsx f2,r11,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f31.f64));
	// stfsx f3,r10,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f2,f6,f4
	ctx.f2.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// stfsx f2,r11,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfsx f6,r10,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f3,f28,f7
	ctx.f3.f64 = double(float(ctx.f28.f64 - ctx.f7.f64));
	// stfsx f3,r9,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f28.f64));
	// stfsx f7,r31,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f30,f5
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f5.f64));
	// stfsx f7,r9,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f5,f30
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// stfsx f7,r31,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + -26212);
	// add r6,r22,r6
	ctx.r6.u64 = ctx.r22.u64 + ctx.r6.u64;
	// add r5,r22,r5
	ctx.r5.u64 = ctx.r22.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82ca74bc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CA74BC;
loc_82CA8548:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA8550;
	__restfpr_14(ctx, base);
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA8558"))) PPC_WEAK_FUNC(sub_82CA8558);
PPC_FUNC_IMPL(__imp__sub_82CA8558) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27240
	ctx.r5.s64 = ctx.r11.s64 + -27240;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r4,r11,29784
	ctx.r4.s64 = ctx.r11.s64 + 29784;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA8570"))) PPC_WEAK_FUNC(sub_82CA8570);
PPC_FUNC_IMPL(__imp__sub_82CA8570) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82CA8578;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82d5c540
	ctx.lr = 0x82CA8580;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82ca8a74
	if (!ctx.cr6.gt) goto loc_82CA8A74;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r23,r10,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32236
	ctx.r9.s64 = -2112618496;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f12,-29656(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29656);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,27776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27776);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29652(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82CA85B4:
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f11,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// mulli r31,r7,60
	ctx.r31.s64 = ctx.r7.s64 * 60;
	// lfs f10,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f21,f9,f11
	ctx.f21.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// lfsx f3,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// mulli r30,r7,28
	ctx.r30.s64 = ctx.r7.s64 * 28;
	// fadds f9,f8,f10
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// lfsx f2,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// lfsx f1,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f18,f1,f3
	ctx.f18.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// mulli r9,r7,48
	ctx.r9.s64 = ctx.r7.s64 * 48;
	// fsubs f1,f2,f31
	ctx.f1.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f4,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// mulli r29,r7,12
	ctx.r29.s64 = ctx.r7.s64 * 12;
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fsubs f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// lfsx f30,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f29,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r28,r7,44
	ctx.r28.s64 = ctx.r7.s64 * 44;
	// lfsx f28,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f31,f28,f30
	ctx.f31.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// rlwinm r27,r7,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// mulli r26,r7,40
	ctx.r26.s64 = ctx.r7.s64 * 40;
	// fsubs f28,f29,f27
	ctx.f28.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fadds f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// lfsx f26,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f23,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r25,r7,56
	ctx.r25.s64 = ctx.r7.s64 * 56;
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// fadds f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f23,f8,f21
	ctx.f23.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// fsubs f8,f21,f8
	ctx.f8.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// lfsx f22,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f21,f9,f6
	ctx.f21.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// fadds f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 + ctx.f9.f64));
	// lfsx f20,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r7,24
	ctx.r11.s64 = ctx.r7.s64 * 24;
	// fsubs f15,f2,f29
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fsubs f16,f3,f28
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f28.f64));
	// fadds f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 + ctx.f3.f64));
	// lfsx f4,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f19,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f6,f4,f22
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f22.f64));
	// fadds f17,f19,f20
	ctx.f17.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// fsubs f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 - ctx.f4.f64));
	// fsubs f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f19.f64));
	// fsubs f20,f11,f5
	ctx.f20.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// fadds f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// fsubs f5,f10,f7
	ctx.f5.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f19,f30,f1
	ctx.f19.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fadds f7,f31,f18
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f18.f64));
	// fadds f29,f6,f27
	ctx.f29.f64 = double(float(ctx.f6.f64 + ctx.f27.f64));
	// fsubs f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f27.f64));
	// fsubs f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fsubs f28,f25,f17
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f17.f64));
	// fadds f27,f17,f25
	ctx.f27.f64 = double(float(ctx.f17.f64 + ctx.f25.f64));
	// fsubs f31,f18,f31
	ctx.f31.f64 = double(float(ctx.f18.f64 - ctx.f31.f64));
	// fsubs f30,f24,f26
	ctx.f30.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fsubs f25,f4,f22
	ctx.f25.f64 = double(float(ctx.f4.f64 - ctx.f22.f64));
	// mulli r9,r7,20
	ctx.r9.s64 = ctx.r7.s64 * 20;
	// fsubs f18,f31,f15
	ctx.f18.f64 = double(float(ctx.f31.f64 - ctx.f15.f64));
	// mulli r31,r7,52
	ctx.r31.s64 = ctx.r7.s64 * 52;
	// fadds f31,f31,f15
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f15.f64));
	// fadds f14,f27,f9
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f9.f64));
	// fsubs f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f27.f64));
	// fadds f27,f28,f8
	ctx.f27.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// lfsx f15,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f17,f29,f23
	ctx.f17.f64 = double(float(ctx.f29.f64 + ctx.f23.f64));
	// stfs f15,-272(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// lfsx f15,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// stfs f15,-264(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fsubs f29,f23,f29
	ctx.f29.f64 = double(float(ctx.f23.f64 - ctx.f29.f64));
	// fsubs f23,f21,f6
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f6.f64));
	// fadds f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// fadds f6,f6,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f21.f64));
	// lfsx f15,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// stfs f15,-268(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfsx f15,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f15,-260(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// mulli r10,r7,36
	ctx.r10.s64 = ctx.r7.s64 * 36;
	// lfsx f28,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f24,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f15,f24,f28
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// lfsx f21,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// lfsx f22,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// fadds f24,f21,f22
	ctx.f24.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// rlwinm r30,r8,5,0,26
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// rlwinm r29,r8,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r28,r8,48
	ctx.r28.s64 = ctx.r8.s64 * 48;
	// mulli r27,r8,40
	ctx.r27.s64 = ctx.r8.s64 * 40;
	// mulli r26,r8,24
	ctx.r26.s64 = ctx.r8.s64 * 24;
	// rlwinm r25,r8,3,0,28
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r24,r8,56
	ctx.r24.s64 = ctx.r8.s64 * 56;
	// lfs f22,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-256(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f21,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfs f22,-252(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f21,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfs f22,-268(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f21,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfs f21,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 - ctx.f21.f64));
	// stfs f21,-260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f21,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f21,f24,f21
	ctx.f21.f64 = double(float(ctx.f24.f64 - ctx.f21.f64));
	// stfs f21,-264(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f21,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f15.f64));
	// lfs f15,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f15.f64 = double(temp.f32);
	// fadds f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 + ctx.f24.f64));
	// stfs f24,-252(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f15,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f24,f15
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// fsubs f15,f28,f22
	ctx.f15.f64 = double(float(ctx.f28.f64 - ctx.f22.f64));
	// fadds f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f28.f64));
	// stfs f28,-272(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f22,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f22.f64 = double(temp.f32);
	// lfs f28,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f28,f22,f28
	ctx.f28.f64 = double(float(ctx.f22.f64 - ctx.f28.f64));
	// stfs f28,-256(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f28,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f28.f64 = double(temp.f32);
	// lfs f22,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f22.f64 = double(temp.f32);
	// fadds f28,f28,f22
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f22.f64));
	// fadds f22,f21,f7
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f7.f64));
	// stfs f22,-248(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fsubs f7,f7,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f21.f64));
	// lfs f22,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// fsubs f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// stfs f2,-252(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f21,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r8,44
	ctx.r11.s64 = ctx.r8.s64 * 44;
	// lfs f2,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f2.f64 = double(temp.f32);
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fsubs f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// fadds f21,f18,f28
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f28.f64));
	// fsubs f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// lfs f18,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfsx f18,r30,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// lfs f18,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// stfs f18,0(r5)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fsubs f18,f14,f22
	ctx.f18.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfsx f18,r30,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f22,0(r6)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f22,f9,f7
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// stfsx f22,r29,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
	// stfsx f9,r28,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f2,f31
	ctx.f22.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// mulli r9,r8,60
	ctx.r9.s64 = ctx.r8.s64 * 60;
	// mulli r31,r8,28
	ctx.r31.s64 = ctx.r8.s64 * 28;
	// lfs f9,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f7,f29,f9
	ctx.f7.f64 = double(float(ctx.f29.f64 - ctx.f9.f64));
	// stfsx f7,r28,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f9,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// stfsx f9,r29,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fmuls f9,f21,f0
	ctx.f9.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f7,f28,f0
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fsubs f28,f25,f26
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f26.f64));
	// fadds f21,f31,f2
	ctx.f21.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fmuls f31,f22,f0
	ctx.f31.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fsubs f29,f27,f9
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f9.f64));
	// stfsx f29,r27,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f7,f23
	ctx.f29.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// stfsx f29,r26,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fadds f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// stfsx f9,r25,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fsubs f9,f23,f7
	ctx.f9.f64 = double(float(ctx.f23.f64 - ctx.f7.f64));
	// stfsx f9,r24,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fmuls f27,f15,f13
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmuls f29,f19,f13
	ctx.f29.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f7,f15,f12
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fmuls f23,f19,f12
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// lfs f19,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f9,f30,f4
	ctx.f9.f64 = double(float(ctx.f30.f64 - ctx.f4.f64));
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmsubs f2,f24,f12,f27
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 - ctx.f27.f64));
	// fadds f27,f26,f25
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fmadds f7,f24,f13,f7
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f7.f64));
	// lfs f24,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f29,f16,f12,f29
	ctx.f29.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 - ctx.f29.f64));
	// fadds f26,f4,f30
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f30.f64));
	// fmadds f4,f16,f13,f23
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f23.f64));
	// fmuls f25,f19,f12
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f12.f64));
	// fmuls f23,f1,f12
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f18,f24,f12
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// fmuls f30,f21,f0
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fadds f21,f28,f10
	ctx.f21.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fadds f22,f29,f7
	ctx.f22.f64 = double(float(ctx.f29.f64 + ctx.f7.f64));
	// fsubs f7,f29,f7
	ctx.f7.f64 = double(float(ctx.f29.f64 - ctx.f7.f64));
	// fadds f29,f4,f2
	ctx.f29.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// fmadds f25,f24,f13,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f25.f64));
	// fmsubs f24,f3,f13,f23
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 - ctx.f23.f64));
	// fsubs f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// fadds f23,f9,f20
	ctx.f23.f64 = double(float(ctx.f9.f64 + ctx.f20.f64));
	// fsubs f2,f8,f31
	ctx.f2.f64 = double(float(ctx.f8.f64 - ctx.f31.f64));
	// stfsx f2,r24,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fsubs f9,f20,f9
	ctx.f9.f64 = double(float(ctx.f20.f64 - ctx.f9.f64));
	// fsubs f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// fadds f2,f30,f6
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// stfsx f2,r25,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fadds f8,f31,f8
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f8.f64));
	// stfsx f8,r26,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f10,f7
	ctx.f28.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// add r3,r3,r23
	ctx.r3.u64 = ctx.r3.u64 + ctx.r23.u64;
	// fsubs f8,f6,f30
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// stfsx f8,r27,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// add r4,r4,r23
	ctx.r4.u64 = ctx.r4.u64 + ctx.r23.u64;
	// fsubs f30,f23,f22
	ctx.f30.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfsx f30,r11,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f21,f29
	ctx.f7.f64 = double(float(ctx.f21.f64 - ctx.f29.f64));
	// stfsx f7,r11,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f30,f22,f23
	ctx.f30.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f30,r10,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f29,f21
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// stfsx f7,r10,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfsx f28,r9,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f9,f4
	ctx.f7.f64 = double(float(ctx.f9.f64 - ctx.f4.f64));
	// stfsx f7,r9,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f4,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// stfsx f10,r31,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f8,f27,f11
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f11.f64));
	// stfsx f9,r31,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fmuls f9,f3,f12
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fadds f2,f24,f25
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// fmsubs f10,f19,f13,f18
	ctx.f10.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 - ctx.f18.f64));
	// fsubs f6,f5,f26
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f26.f64));
	// fadds f5,f26,f5
	ctx.f5.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// fsubs f31,f24,f25
	ctx.f31.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// fsubs f11,f11,f27
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f27.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r9,r8,52
	ctx.r9.s64 = ctx.r8.s64 * 52;
	// fmadds f9,f1,f13,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f9.f64));
	// fsubs f7,f8,f2
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f2.f64));
	// stfsx f7,r11,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f2,f8
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fsubs f3,f6,f31
	ctx.f3.f64 = double(float(ctx.f6.f64 - ctx.f31.f64));
	// fadds f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// mulli r31,r8,20
	ctx.r31.s64 = ctx.r8.s64 * 20;
	// fadds f8,f9,f10
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fsubs f9,f5,f8
	ctx.f9.f64 = double(float(ctx.f5.f64 - ctx.f8.f64));
	// stfsx f9,r11,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// stfsx f4,r10,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f8,f5
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f5.f64));
	// stfsx f9,r10,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f11,f10
	ctx.f9.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// stfsx f3,r9,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// stfsx f9,r9,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// stfsx f6,r31,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// add r6,r22,r6
	ctx.r6.u64 = ctx.r22.u64 + ctx.r6.u64;
	// stfsx f11,r31,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + -26212);
	// add r5,r22,r5
	ctx.r5.u64 = ctx.r22.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82ca85b4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CA85B4;
loc_82CA8A74:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA8A7C;
	__restfpr_14(ctx, base);
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA8A80"))) PPC_WEAK_FUNC(sub_82CA8A80);
PPC_FUNC_IMPL(__imp__sub_82CA8A80) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27176
	ctx.r5.s64 = ctx.r11.s64 + -27176;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-31376
	ctx.r4.s64 = ctx.r11.s64 + -31376;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA8A98"))) PPC_WEAK_FUNC(sub_82CA8A98);
PPC_FUNC_IMPL(__imp__sub_82CA8A98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b4
	ctx.lr = 0x82CA8AA0;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c540
	ctx.lr = 0x82CA8AA8;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82ca9110
	if (!ctx.cr6.gt) goto loc_82CA9110;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r25,r10,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// rlwinm r24,r11,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lis r31,-32255
	ctx.r31.s64 = -2113863680;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f13,28204(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 28204);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f0,28208(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 28208);
	ctx.f0.f64 = double(temp.f32);
	// lis r23,-32234
	ctx.r23.s64 = -2112487424;
	// lfs f9,-12748(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -12748);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,28200(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28200);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,-29000(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29000);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,28136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28136);
	ctx.f12.f64 = double(temp.f32);
loc_82CA8AF4:
	// mulli r11,r7,44
	ctx.r11.s64 = ctx.r7.s64 * 44;
	// lfs f8,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// mulli r9,r7,56
	ctx.r9.s64 = ctx.r7.s64 * 56;
	// lfsx f4,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f21,f4,f6
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fadds f20,f3,f5
	ctx.f20.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// lfsx f2,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r31,r7,4,0,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f1,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f4,f4,f6
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// mulli r30,r7,20
	ctx.r30.s64 = ctx.r7.s64 * 20;
	// fsubs f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// lfsx f31,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f6,f31,f2
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fadds f5,f30,f1
	ctx.f5.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// lfsx f29,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r29,r7,40
	ctx.r29.s64 = ctx.r7.s64 * 40;
	// fsubs f31,f31,f2
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// fsubs f30,f1,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// lfsx f28,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// lfsx f27,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f26,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f2,f27,f29
	ctx.f2.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// mulli r28,r7,24
	ctx.r28.s64 = ctx.r7.s64 * 24;
	// fadds f1,f26,f28
	ctx.f1.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// fsubs f29,f27,f29
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// fmuls f31,f31,f12
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// fmuls f30,f30,f12
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// lfsx f25,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f21,f25
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f25.f64));
	// mulli r27,r7,36
	ctx.r27.s64 = ctx.r7.s64 * 36;
	// fadds f26,f20,f24
	ctx.f26.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// fnmsubs f24,f20,f11,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f11.f64 - ctx.f24.f64)));
	// fnmsubs f25,f21,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// fmuls f28,f28,f12
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f12.f64));
	// fmuls f29,f29,f12
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f12.f64));
	// lfsx f23,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fadds f21,f6,f23
	ctx.f21.f64 = double(float(ctx.f6.f64 + ctx.f23.f64));
	// fadds f20,f5,f22
	ctx.f20.f64 = double(float(ctx.f5.f64 + ctx.f22.f64));
	// rlwinm r11,r7,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fnmsubs f6,f6,f11,f23
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f23.f64)));
	// mulli r10,r7,52
	ctx.r10.s64 = ctx.r7.s64 * 52;
	// fnmsubs f5,f5,f11,f22
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 - ctx.f22.f64)));
	// fadds f23,f2,f8
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f8.f64));
	// fadds f22,f1,f7
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f7.f64));
	// fnmsubs f8,f2,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// fnmsubs f7,f1,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fsubs f1,f24,f4
	ctx.f1.f64 = double(float(ctx.f24.f64 - ctx.f4.f64));
	// fadds f4,f24,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 + ctx.f4.f64));
	// fsubs f2,f25,f3
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f3.f64));
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f18,f20,f26
	ctx.f18.f64 = double(float(ctx.f20.f64 + ctx.f26.f64));
	// mulli r31,r7,28
	ctx.r31.s64 = ctx.r7.s64 * 28;
	// fsubs f24,f6,f30
	ctx.f24.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// fsubs f17,f5,f31
	ctx.f17.f64 = double(float(ctx.f5.f64 - ctx.f31.f64));
	// fadds f6,f30,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// stfs f6,-236(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// lfsx f6,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// fadds f19,f21,f27
	ctx.f19.f64 = double(float(ctx.f21.f64 + ctx.f27.f64));
	// fsubs f16,f8,f28
	ctx.f16.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// fadds f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f28.f64));
	// fadds f28,f7,f29
	ctx.f28.f64 = double(float(ctx.f7.f64 + ctx.f29.f64));
	// fsubs f7,f7,f29
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f29.f64));
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// fsubs f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f20.f64));
	// fadds f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f31.f64));
	// fadds f29,f24,f2
	ctx.f29.f64 = double(float(ctx.f24.f64 + ctx.f2.f64));
	// fadds f15,f17,f1
	ctx.f15.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// fadds f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f25.f64));
	// mulli r29,r7,48
	ctx.r29.s64 = ctx.r7.s64 * 48;
	// lfsx f20,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f14,f26,f13
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f20,-244(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// lfsx f20,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-240(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfsx f20,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-248(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfsx f20,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-288(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f20,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-280(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfsx f20,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-272(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfsx f20,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-264(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f20,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,-256(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fadds f20,f31,f6
	ctx.f20.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// stfs f20,-284(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fsubs f20,f31,f6
	ctx.f20.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// lfsx f25,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f30,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f6,f25,f30
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f30.f64));
	// stfs f6,-276(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// fsubs f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// lfs f6,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f6.f64 = double(temp.f32);
	// lfs f31,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f31.f64 = double(temp.f32);
	// fadds f25,f31,f6
	ctx.f25.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// stfs f25,-268(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fsubs f25,f31,f6
	ctx.f25.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// lfs f6,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f6.f64 = double(temp.f32);
	// lfs f31,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f31,f6
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// stfs f31,-260(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f31,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f31.f64));
	// stfs f6,-240(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fmuls f31,f30,f12
	ctx.f31.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f6,f20,f12
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmuls f30,f25,f12
	ctx.f30.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f20,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f12
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// stfs f25,-244(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// lfs f25,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f25,-252(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// lfs f20,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f25,-288(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f20,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// stfs f25,-248(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f20,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f20,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// stfs f25,-240(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfs f20,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f20.f64)));
	// stfs f25,-280(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f20,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f20.f64)));
	// stfs f25,-272(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f20,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f20.f64)));
	// stfs f25,-264(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// lfs f20,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f11,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f20.f64)));
	// stfs f25,-268(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f20,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f20.f64 = double(temp.f32);
	// lfs f25,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// lfs f20,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f20.f64 = double(temp.f32);
	// stfs f25,-276(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f25,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fsubs f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// stfs f20,-256(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f20,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// lfs f20,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f20.f64 = double(temp.f32);
	// fsubs f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f31.f64));
	// stfs f20,-284(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfs f20,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f20.f64 = double(temp.f32);
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// fsubs f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f6.f64));
	// stfs f20,-260(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f20,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f20.f64 = double(temp.f32);
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fadds f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f6.f64));
	// lfs f6,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f6.f64 = double(temp.f32);
	// fadds f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// stfs f6,-288(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfs f6,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f6.f64 = double(temp.f32);
	// lfs f31,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f31.f64 = double(temp.f32);
	// fsubs f31,f31,f6
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// stfs f31,-280(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfs f31,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f31.f64 = double(temp.f32);
	// fadds f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// stfs f6,-244(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// lfs f6,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f31,f6,f30
	ctx.f31.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// stfs f31,-264(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fadds f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// stfs f6,-240(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfs f6,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f6.f64 = double(temp.f32);
	// fadds f31,f6,f19
	ctx.f31.f64 = double(float(ctx.f6.f64 + ctx.f19.f64));
	// stfs f31,-272(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f30,f6,f19
	ctx.f30.f64 = double(float(ctx.f6.f64 - ctx.f19.f64));
	// stfs f27,-276(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f21,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f21.f64 = double(temp.f32);
	// mulli r9,r8,48
	ctx.r9.s64 = ctx.r8.s64 * 48;
	// lfs f27,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f21.f64));
	// fsubs f21,f25,f18
	ctx.f21.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// fmuls f30,f30,f10
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f6,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f6,f13
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// lfs f31,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f31.f64 = double(temp.f32);
	// lfs f6,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f26,f26,f0,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fadds f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// stfs f6,-268(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f19,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f0,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f14.f64));
	// lfs f31,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f31.f64 = double(temp.f32);
	// fadds f14,f25,f18
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f18.f64));
	// lfs f18,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f18.f64 = double(temp.f32);
	// lfs f25,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 - ctx.f18.f64));
	// stfs f14,-256(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// lfs f6,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f6.f64 = double(temp.f32);
	// fadds f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// stfs f6,-232(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -232, temp.u32);
	// lfs f31,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f31.f64 = double(temp.f32);
	// lfs f6,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f6.f64 = double(temp.f32);
	// fadds f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// lfs f31,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f31.f64 = double(temp.f32);
	// fadds f31,f31,f20
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// lfs f18,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f18,f29
	ctx.f17.f64 = double(float(ctx.f18.f64 - ctx.f29.f64));
	// fadds f14,f14,f29
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f29.f64));
	// lfs f29,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f18,f29,f9,f23
	ctx.f18.f64 = double(float(-(ctx.f29.f64 * ctx.f9.f64 - ctx.f23.f64)));
	// fadds f29,f18,f30
	ctx.f29.f64 = double(float(ctx.f18.f64 + ctx.f30.f64));
	// fsubs f30,f18,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 - ctx.f30.f64));
	// fadds f18,f6,f15
	ctx.f18.f64 = double(float(ctx.f6.f64 + ctx.f15.f64));
	// stfs f18,-264(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fmuls f18,f17,f10
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// stfs f18,-260(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f18,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// fsubs f6,f6,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f15.f64));
	// lfs f15,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f15,f15,f9,f22
	ctx.f15.f64 = double(float(-(ctx.f15.f64 * ctx.f9.f64 - ctx.f22.f64)));
	// stfs f15,-248(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fnmsubs f15,f14,f9,f16
	ctx.f15.f64 = double(float(-(ctx.f14.f64 * ctx.f9.f64 - ctx.f16.f64)));
	// stfs f15,-252(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmuls f18,f1,f13
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f23,0(r5)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmuls f23,f27,f13
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// fmuls f17,f25,f13
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f15,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f15.f64 = double(temp.f32);
	// fadds f22,f15,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 + ctx.f22.f64));
	// mulli r30,r8,20
	ctx.r30.s64 = ctx.r8.s64 * 20;
	// fsubs f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f24.f64));
	// lfs f24,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// stfs f6,-268(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// lfs f6,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmsubs f1,f1,f0,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 - ctx.f17.f64));
	// mulli r29,r8,56
	ctx.r29.s64 = ctx.r8.s64 * 56;
	// fmadds f6,f27,f0,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fsubs f27,f29,f19
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f19.f64));
	// stfsx f27,r11,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f29,f19
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f19.f64));
	// stfsx f29,r10,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmadds f29,f25,f0,f18
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f18.f64));
	// lfs f27,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f25,f30,f26
	ctx.f25.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// stfsx f25,r9,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f26.f64));
	// stfsx f30,r31,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fmsubs f27,f27,f0,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 - ctx.f23.f64));
	// stfs f22,0(r6)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f23,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f23.f64 = double(temp.f32);
	// mulli r28,r8,44
	ctx.r28.s64 = ctx.r8.s64 * 44;
	// fadds f19,f14,f16
	ctx.f19.f64 = double(float(ctx.f14.f64 + ctx.f16.f64));
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r8,5,0,26
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f26,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f26.f64 = double(temp.f32);
	// fadds f30,f26,f21
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f21.f64));
	// lfs f22,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f21.f64));
	// fadds f25,f22,f23
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fsubs f22,f30,f6
	ctx.f22.f64 = double(float(ctx.f30.f64 - ctx.f6.f64));
	// stfsx f22,r10,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f30,f6
	ctx.f6.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// stfsx f6,r11,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f26.f64 - ctx.f27.f64));
	// stfsx f6,r31,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f26,f27
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfsx f6,r9,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f25,f29
	ctx.f6.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// stfsx f19,r30,r5
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f6,r29,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f25,f29
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// stfsx f6,r28,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f23,f1
	ctx.f6.f64 = double(float(ctx.f23.f64 - ctx.f1.f64));
	// stfsx f6,r27,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f23,f1
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// stfsx f6,r26,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f25,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f25.f64 = double(temp.f32);
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// fadds f1,f25,f3
	ctx.f1.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// lfs f26,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f27.f64 = double(temp.f32);
	// fsubs f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f25.f64));
	// fsubs f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// lfs f23,-232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -232);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fsubs f26,f26,f24
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// mulli r10,r8,28
	ctx.r10.s64 = ctx.r8.s64 * 28;
	// fadds f30,f31,f6
	ctx.f30.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// fsubs f25,f31,f6
	ctx.f25.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// lfs f6,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f6.f64 = double(temp.f32);
	// fadds f29,f23,f1
	ctx.f29.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// fsubs f6,f20,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 - ctx.f6.f64));
	// fsubs f24,f23,f1
	ctx.f24.f64 = double(float(ctx.f23.f64 - ctx.f1.f64));
	// lfs f31,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f31.f64 = double(temp.f32);
	// fnmsubs f4,f31,f9,f7
	ctx.f4.f64 = double(float(-(ctx.f31.f64 * ctx.f9.f64 - ctx.f7.f64)));
	// lfs f23,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f23.f64 = double(temp.f32);
	// fadds f7,f31,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// stfsx f7,r30,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fmuls f22,f27,f13
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// mulli r9,r8,52
	ctx.r9.s64 = ctx.r8.s64 * 52;
	// fnmsubs f31,f30,f9,f28
	ctx.f31.f64 = double(float(-(ctx.f30.f64 * ctx.f9.f64 - ctx.f28.f64)));
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f1,f25,f10
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f21,f26,f13
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f20,f3,f13
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f19,f6,f13
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fnmsubs f25,f29,f9,f8
	ctx.f25.f64 = double(float(-(ctx.f29.f64 * ctx.f9.f64 - ctx.f8.f64)));
	// fmuls f7,f24,f10
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fmuls f24,f2,f13
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fadds f29,f29,f8
	ctx.f29.f64 = double(float(ctx.f29.f64 + ctx.f8.f64));
	// add r3,r25,r3
	ctx.r3.u64 = ctx.r25.u64 + ctx.r3.u64;
	// fmsubs f2,f2,f0,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f22.f64));
	// add r4,r25,r4
	ctx.r4.u64 = ctx.r25.u64 + ctx.r4.u64;
	// fadds f30,f30,f28
	ctx.f30.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// fmsubs f3,f3,f0,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f21.f64));
	// fmadds f26,f26,f0,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f20.f64));
	// fmadds f27,f27,f0,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fadds f24,f4,f23
	ctx.f24.f64 = double(float(ctx.f4.f64 + ctx.f23.f64));
	// fsubs f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f23.f64));
	// fmuls f23,f5,f13
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmsubs f5,f5,f0,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fsubs f28,f24,f27
	ctx.f28.f64 = double(float(ctx.f24.f64 - ctx.f27.f64));
	// stfsx f28,r28,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f28,f24,f27
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// stfsx f28,r29,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fmadds f8,f6,f0,f23
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f23.f64));
	// fsubs f6,f31,f1
	ctx.f6.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f31,f25,f7
	ctx.f31.f64 = double(float(ctx.f25.f64 - ctx.f7.f64));
	// fadds f28,f4,f2
	ctx.f28.f64 = double(float(ctx.f4.f64 + ctx.f2.f64));
	// stfsx f28,r27,r6
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// stfsx f4,r26,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// stfsx f30,r11,r6
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 + ctx.f7.f64));
	// fadds f4,f6,f3
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// stfsx f4,r10,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f3.f64));
	// stfsx f6,r9,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f6,f1,f26
	ctx.f6.f64 = double(float(ctx.f1.f64 - ctx.f26.f64));
	// stfsx f6,r31,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f1,f26
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// stfsx f6,r30,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// stfsx f29,r11,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f31,f5
	ctx.f6.f64 = double(float(ctx.f31.f64 - ctx.f5.f64));
	// stfsx f6,r10,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f31,f5
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f5.f64));
	// stfsx f6,r9,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f6,f7,f8
	ctx.f6.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// stfsx f6,r30,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + -26212);
	// add r5,r24,r5
	ctx.r5.u64 = ctx.r24.u64 + ctx.r5.u64;
	// add r6,r24,r6
	ctx.r6.u64 = ctx.r24.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82ca8af4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CA8AF4;
loc_82CA9110:
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA9118;
	__restfpr_14(ctx, base);
	// b 0x82d5c504
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA9120"))) PPC_WEAK_FUNC(sub_82CA9120);
PPC_FUNC_IMPL(__imp__sub_82CA9120) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27112
	ctx.r5.s64 = ctx.r11.s64 + -27112;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-30056
	ctx.r4.s64 = ctx.r11.s64 + -30056;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA9138"))) PPC_WEAK_FUNC(sub_82CA9138);
PPC_FUNC_IMPL(__imp__sub_82CA9138) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82CA9140;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82d5c540
	ctx.lr = 0x82CA9148;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82ca9678
	if (!ctx.cr6.gt) goto loc_82CA9678;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r24,r10,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f9,30852(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 30852);
	ctx.f9.f64 = double(temp.f32);
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f10,30848(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 30848);
	ctx.f10.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f11,30844(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 30844);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,30832(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 30832);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,30840(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 30840);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,30836(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 30836);
	ctx.f0.f64 = double(temp.f32);
loc_82CA9194:
	// mulli r9,r7,48
	ctx.r9.s64 = ctx.r7.s64 * 48;
	// lfs f7,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// lfs f5,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f2,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f16,f2,f31
	ctx.f16.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f2,f31,f2
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f31,f1,f30
	ctx.f31.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// mulli r29,r7,44
	ctx.r29.s64 = ctx.r7.s64 * 44;
	// fadds f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f4,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f29,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f28,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r10,r7,36
	ctx.r10.s64 = ctx.r7.s64 * 36;
	// lfsx f27,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f26,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f14,f29,f28
	ctx.f14.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// fsubs f29,f27,f26
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f3,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f19,f6,f8
	ctx.f19.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// mulli r28,r7,40
	ctx.r28.s64 = ctx.r7.s64 * 40;
	// fsubs f20,f8,f6
	ctx.f20.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fadds f17,f3,f4
	ctx.f17.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f18,f4,f3
	ctx.f18.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfsx f25,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// mulli r27,r7,12
	ctx.r27.s64 = ctx.r7.s64 * 12;
	// lfsx f23,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f27,f25,f23
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// mulli r26,r7,24
	ctx.r26.s64 = ctx.r7.s64 * 24;
	// fadds f26,f23,f25
	ctx.f26.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fsubs f25,f24,f22
	ctx.f25.f64 = double(float(ctx.f24.f64 - ctx.f22.f64));
	// fadds f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f24.f64));
	// fsubs f23,f2,f19
	ctx.f23.f64 = double(float(ctx.f2.f64 - ctx.f19.f64));
	// lfsx f21,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f21.f64 = double(temp.f32);
	// mulli r11,r7,52
	ctx.r11.s64 = ctx.r7.s64 * 52;
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f22,f21,f8
	ctx.f22.f64 = double(float(ctx.f21.f64 - ctx.f8.f64));
	// rlwinm r10,r7,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f8,f8,f21
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f21.f64));
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f8,-276(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// mulli r25,r7,28
	ctx.r25.s64 = ctx.r7.s64 * 28;
	// fsubs f21,f18,f31
	ctx.f21.f64 = double(float(ctx.f18.f64 - ctx.f31.f64));
	// stfs f21,-260(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfsx f6,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f4,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f8,f6,f4
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f4.f64));
	// stfs f8,-280(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// lfsx f3,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f8,f4,f6
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// stfs f8,-272(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fsubs f8,f7,f3
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f3.f64));
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// lfsx f15,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f15.f64 = double(temp.f32);
	// fadds f3,f2,f19
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// fsubs f2,f17,f1
	ctx.f2.f64 = double(float(ctx.f17.f64 - ctx.f1.f64));
	// stfs f2,-236(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fadds f2,f31,f18
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f18.f64));
	// fadds f4,f16,f20
	ctx.f4.f64 = double(float(ctx.f16.f64 + ctx.f20.f64));
	// fadds f31,f27,f14
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f14.f64));
	// fsubs f19,f30,f26
	ctx.f19.f64 = double(float(ctx.f30.f64 - ctx.f26.f64));
	// stfs f19,-248(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fsubs f6,f5,f15
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f15.f64));
	// fsubs f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 - ctx.f20.f64));
	// stfs f20,-264(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fsubs f27,f27,f14
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f14.f64));
	// stfs f27,-284(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fadds f5,f15,f5
	ctx.f5.f64 = double(float(ctx.f15.f64 + ctx.f5.f64));
	// fadds f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f17.f64));
	// fadds f30,f26,f30
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fsubs f27,f29,f25
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f25.f64));
	// stfs f27,-288(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// fsubs f27,f24,f28
	ctx.f27.f64 = double(float(ctx.f24.f64 - ctx.f28.f64));
	// lfs f26,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f26.f64 = double(temp.f32);
	// fadds f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// lfs f24,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f24.f64 = double(temp.f32);
	// fadds f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// lfsx f18,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// lfs f25,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f19,f26,f24
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f24.f64));
	// stfs f18,-272(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// fmuls f18,f31,f10
	ctx.f18.f64 = double(float(ctx.f31.f64 * ctx.f10.f64));
	// stfs f19,-252(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fsubs f19,f25,f22
	ctx.f19.f64 = double(float(ctx.f25.f64 - ctx.f22.f64));
	// stfs f27,-240(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fadds f27,f25,f22
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// stfs f19,-280(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fadds f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// fmuls f14,f21,f13
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfsx f24,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f25,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// lfsx f22,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fmuls f17,f29,f10
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fnmadds f18,f4,f11,f18
	ctx.f18.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmadds f16,f27,f9,f8
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fadds f15,f26,f30
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f30.f64));
	// fnmadds f17,f2,f11,f17
	ctx.f17.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 + ctx.f17.f64)));
	// mulli r9,r8,36
	ctx.r9.s64 = ctx.r8.s64 * 36;
	// fmsubs f20,f20,f0,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 - ctx.f19.f64));
	// fadds f19,f27,f31
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// fadds f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// stfs f18,-276(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// lfs f18,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f20,f18,f12,f20
	ctx.f20.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f20.f64)));
	// stfs f20,-268(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fadds f20,f19,f4
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f4.f64));
	// fmuls f18,f27,f10
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fadds f19,f15,f3
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f3.f64));
	// fadds f15,f20,f8
	ctx.f15.f64 = double(float(ctx.f20.f64 + ctx.f8.f64));
	// stfsx f15,r11,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fnmadds f20,f31,f11,f18
	ctx.f20.f64 = double(float(-(ctx.f31.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// stfs f20,-256(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fsubs f20,f25,f24
	ctx.f20.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// lfs f16,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f16,f0,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f14.f64));
	// fadds f14,f19,f7
	ctx.f14.f64 = double(float(ctx.f19.f64 + ctx.f7.f64));
	// fadds f19,f24,f25
	ctx.f19.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfs f24,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f24.f64 = double(temp.f32);
	// fsubs f25,f22,f24
	ctx.f25.f64 = double(float(ctx.f22.f64 - ctx.f24.f64));
	// fadds f18,f24,f22
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// fsubs f22,f20,f25
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f25.f64));
	// fadds f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f20.f64));
	// fadds f24,f18,f19
	ctx.f24.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// fsubs f20,f18,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 - ctx.f19.f64));
	// stfs f20,-244(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// fmuls f20,f22,f13
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fadds f19,f25,f29
	ctx.f19.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// fadds f18,f24,f28
	ctx.f18.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// fmadds f16,f22,f12,f16
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f16.f64));
	// stfs f16,-272(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// lfs f16,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f21,f21,f0,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 - ctx.f20.f64));
	// fadds f19,f19,f2
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// fadds f18,f18,f1
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f1.f64));
	// fmadds f20,f25,f9,f6
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f9.f64 + ctx.f6.f64));
	// fnmsubs f21,f16,f12,f21
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f21.f64)));
	// fadds f19,f19,f6
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f6.f64));
	// stfsx f19,r11,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// stfs f14,0(r5)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f19,f18,f5
	ctx.f19.f64 = double(float(ctx.f18.f64 + ctx.f5.f64));
	// stfs f19,0(r6)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f19,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f18,f19,f21
	ctx.f18.f64 = double(float(ctx.f19.f64 - ctx.f21.f64));
	// stfsx f18,r10,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// stfsx f21,r9,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// lfs f21,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f19,f20,f21
	ctx.f19.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfsx f19,r10,r6
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfsx f21,r9,r6
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lfs f21,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f25,f10
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fmuls f20,f21,f13
	ctx.f20.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f17,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f4,f10
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f15,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// mulli r11,r8,52
	ctx.r11.s64 = ctx.r8.s64 * 52;
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f16,f2,f10
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmadds f4,f4,f9,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmadds f2,f2,f9,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f6.f64));
	// fmadds f6,f29,f9,f6
	ctx.f6.f64 = double(float(ctx.f29.f64 * ctx.f9.f64 + ctx.f6.f64));
	// fmadds f14,f3,f9,f7
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fnmadds f19,f29,f11,f19
	ctx.f19.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 + ctx.f19.f64)));
	// fmadds f20,f15,f0,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f20.f64));
	// lfs f15,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f15.f64 = double(temp.f32);
	// fnmadds f27,f27,f11,f18
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// mulli r9,r8,44
	ctx.r9.s64 = ctx.r8.s64 * 44;
	// fmadds f18,f31,f9,f8
	ctx.f18.f64 = double(float(ctx.f31.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmadds f21,f21,f12,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmadds f22,f15,f12,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f22.f64));
	// fnmadds f17,f25,f11,f16
	ctx.f17.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 + ctx.f16.f64)));
	// lfs f16,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f16.f64 = double(temp.f32);
	// fadds f8,f16,f4
	ctx.f8.f64 = double(float(ctx.f16.f64 + ctx.f4.f64));
	// lfs f4,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f4.f64 = double(temp.f32);
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// fadds f31,f19,f2
	ctx.f31.f64 = double(float(ctx.f19.f64 + ctx.f2.f64));
	// lfs f2,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f4,f4,f12,f20
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f20.f64));
	// lfs f20,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f20.f64 = double(temp.f32);
	// fadds f27,f27,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f18.f64));
	// fnmsubs f29,f2,f13,f22
	ctx.f29.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f22.f64)));
	// lfs f2,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f2.f64 = double(temp.f32);
	// fadds f22,f17,f6
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f6.f64));
	// fsubs f18,f8,f20
	ctx.f18.f64 = double(float(ctx.f8.f64 - ctx.f20.f64));
	// stfsx f18,r11,r5
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fnmsubs f25,f2,f13,f21
	ctx.f25.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f21.f64)));
	// lfs f2,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f6,f24,f10
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// fadds f8,f8,f20
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f20.f64));
	// stfsx f8,r10,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f31,f4
	ctx.f8.f64 = double(float(ctx.f31.f64 + ctx.f4.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fmuls f21,f2,f12
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// rlwinm r10,r8,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fsubs f8,f31,f4
	ctx.f8.f64 = double(float(ctx.f31.f64 - ctx.f4.f64));
	// stfsx f8,r11,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f31,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f31.f64 = double(temp.f32);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fsubs f8,f27,f29
	ctx.f8.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// stfsx f8,r9,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f27,f29
	ctx.f8.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fmuls f29,f31,f12
	ctx.f29.f64 = double(float(ctx.f31.f64 * ctx.f12.f64));
	// lfs f4,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f4.f64 = double(temp.f32);
	// fadds f8,f22,f25
	ctx.f8.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// stfsx f8,r31,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fnmadds f19,f28,f11,f6
	ctx.f19.f64 = double(float(-(ctx.f28.f64 * ctx.f11.f64 + ctx.f6.f64)));
	// lfs f6,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f8,f22,f25
	ctx.f8.f64 = double(float(ctx.f22.f64 - ctx.f25.f64));
	// stfsx f8,r9,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fmuls f27,f26,f10
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// lfs f8,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f21,f23,f13,f21
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f21.f64));
	// rlwinm r9,r8,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f25,f6,f13
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// mulli r31,r8,40
	ctx.r31.s64 = ctx.r8.s64 * 40;
	// fmuls f22,f1,f10
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f20,f4,f13
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f18,f3,f10
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmsubs f16,f8,f13,f29
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 - ctx.f29.f64));
	// fmadds f17,f1,f9,f5
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f5.f64));
	// fnmadds f15,f30,f11,f27
	ctx.f15.f64 = double(float(-(ctx.f30.f64 * ctx.f11.f64 + ctx.f27.f64)));
	// fnmsubs f21,f6,f0,f21
	ctx.f21.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f21.f64)));
	// fmadds f29,f23,f12,f25
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f25.f64));
	// stfs f29,-236(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fnmadds f27,f24,f11,f22
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f11.f64 + ctx.f22.f64)));
	// stfs f27,-240(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// fmadds f25,f28,f9,f5
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 + ctx.f5.f64));
	// stfs f25,-244(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -244, temp.u32);
	// fadds f29,f19,f17
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fmadds f22,f8,f12,f20
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f20.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fmadds f20,f30,f9,f7
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f7.f64));
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fnmadds f18,f26,f11,f18
	ctx.f18.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// fnmsubs f27,f4,f0,f16
	ctx.f27.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f16.f64)));
	// fadds f25,f15,f14
	ctx.f25.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fmuls f28,f28,f10
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f10.f64));
	// fmadds f5,f24,f9,f5
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f5.f64));
	// fmuls f30,f30,f10
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f10.f64));
	// fnmadds f1,f1,f11,f28
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 + ctx.f28.f64)));
	// lfs f19,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f19.f64 = double(temp.f32);
	// stfs f22,-236(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -236, temp.u32);
	// fnmsubs f22,f2,f0,f19
	ctx.f22.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f19.f64)));
	// lfs f19,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f19.f64 = double(temp.f32);
	// stfs f20,-240(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -240, temp.u32);
	// lfs f17,-244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -244);
	ctx.f17.f64 = double(temp.f32);
	// fadds f20,f19,f17
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// fmuls f17,f23,f0
	ctx.f17.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmadds f6,f6,f12,f17
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmadds f6,f2,f13,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f6.f64));
	// fsubs f2,f29,f21
	ctx.f2.f64 = double(float(ctx.f29.f64 - ctx.f21.f64));
	// stfsx f2,r11,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f2,f29,f21
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f21.f64));
	// stfsx f2,r10,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f2,f25,f27
	ctx.f2.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// stfsx f2,r11,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f2,f25,f27
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfsx f2,r10,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f2,f20,f22
	ctx.f2.f64 = double(float(ctx.f20.f64 - ctx.f22.f64));
	// stfsx f2,r9,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f2,f20,f22
	ctx.f2.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// stfsx f2,r31,r6
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r10,r8,48
	ctx.r10.s64 = ctx.r8.s64 * 48;
	// lfs f19,-236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -236);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f19,f31,f0,f19
	ctx.f19.f64 = double(float(-(ctx.f31.f64 * ctx.f0.f64 - ctx.f19.f64)));
	// lfs f16,-240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -240);
	ctx.f16.f64 = double(temp.f32);
	// fadds f23,f18,f16
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f16.f64));
	// fsubs f2,f23,f19
	ctx.f2.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// stfsx f2,r9,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f2,f23,f19
	ctx.f2.f64 = double(float(ctx.f23.f64 + ctx.f19.f64));
	// stfsx f2,r31,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fmuls f2,f8,f0
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fadds f8,f1,f5
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// fmadds f5,f4,f12,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f2.f64));
	// fnmadds f4,f3,f11,f30
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f30.f64)));
	// fmadds f3,f26,f9,f7
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fmadds f7,f31,f13,f5
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f13.f64 + ctx.f5.f64));
	// fadds f5,f4,f3
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// fadds f4,f8,f6
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f6.f64));
	// stfsx f4,r11,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f8,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// add r6,r23,r6
	ctx.r6.u64 = ctx.r23.u64 + ctx.r6.u64;
	// fsubs f8,f5,f7
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f7.f64));
	// stfsx f8,r10,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f5,f7
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// stfsx f8,r11,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + -26212);
	// add r5,r23,r5
	ctx.r5.u64 = ctx.r23.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82ca9194
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CA9194;
loc_82CA9678:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA9680;
	__restfpr_14(ctx, base);
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA9688"))) PPC_WEAK_FUNC(sub_82CA9688);
PPC_FUNC_IMPL(__imp__sub_82CA9688) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-27048
	ctx.r5.s64 = ctx.r11.s64 + -27048;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-28360
	ctx.r4.s64 = ctx.r11.s64 + -28360;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA96A0"))) PPC_WEAK_FUNC(sub_82CA96A0);
PPC_FUNC_IMPL(__imp__sub_82CA96A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82CA96A8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c540
	ctx.lr = 0x82CA96B0;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82ca9e14
	if (!ctx.cr6.gt) goto loc_82CA9E14;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r21,r10,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// rlwinm r20,r11,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32230
	ctx.r11.s64 = -2112225280;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lfs f13,-29792(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29792);
	ctx.f13.f64 = double(temp.f32);
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// stfs f13,-364(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -364, temp.u32);
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// stw r11,-360(r1)
	PPC_STORE_U32(ctx.r1.u32 + -360, ctx.r11.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f13,-29788(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -29788);
	ctx.f13.f64 = double(temp.f32);
	// lis r17,-32234
	ctx.r17.s64 = -2112487424;
	// stfs f13,-328(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -328, temp.u32);
	// lis r16,-32234
	ctx.r16.s64 = -2112487424;
	// lfs f13,31524(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 31524);
	ctx.f13.f64 = double(temp.f32);
	// lis r15,-32234
	ctx.r15.s64 = -2112487424;
	// stfs f13,-336(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -336, temp.u32);
	// lis r14,-32234
	ctx.r14.s64 = -2112487424;
	// stw r11,-340(r1)
	PPC_STORE_U32(ctx.r1.u32 + -340, ctx.r11.u32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,-29776(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -29776);
	ctx.f13.f64 = double(temp.f32);
	// lis r18,-32235
	ctx.r18.s64 = -2112552960;
	// stfs f13,-324(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -324, temp.u32);
	// lis r19,-32235
	ctx.r19.s64 = -2112552960;
	// lfs f13,31528(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 31528);
	ctx.f13.f64 = double(temp.f32);
	// lis r23,-32235
	ctx.r23.s64 = -2112552960;
	// stfs f13,-332(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -332, temp.u32);
	// lis r24,-32235
	ctx.r24.s64 = -2112552960;
	// lfs f13,-29800(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -29800);
	ctx.f13.f64 = double(temp.f32);
	// lis r25,-32235
	ctx.r25.s64 = -2112552960;
	// lfs f0,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f0.f64 = double(temp.f32);
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// stfs f13,-348(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -348, temp.u32);
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lfs f13,-29796(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -29796);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// stfs f13,-356(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -356, temp.u32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f13,-29780(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -29780);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,-344(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -344, temp.u32);
	// lfs f13,-29784(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -29784);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,-352(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -352, temp.u32);
	// lfs f12,28136(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28136);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,-29808(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -29808);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,-29804(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -29804);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,31484(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 31484);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,31480(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 31480);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,31472(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 31472);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,31476(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + 31476);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,29472(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 29472);
	ctx.f5.f64 = double(temp.f32);
	// lwz r11,-340(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	// lfs f13,-29912(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29912);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-360(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	// stfs f13,-340(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -340, temp.u32);
	// lfs f13,21356(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21356);
	ctx.f13.f64 = double(temp.f32);
loc_82CA97A4:
	// mulli r9,r7,12
	ctx.r9.s64 = ctx.r7.s64 * 12;
	// lfs f4,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// mulli r31,r7,36
	ctx.r31.s64 = ctx.r7.s64 * 36;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f30,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// lfsx f29,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f17,f29,f30
	ctx.f17.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// mulli r11,r7,40
	ctx.r11.s64 = ctx.r7.s64 * 40;
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// lfsx f2,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r30,r7,44
	ctx.r30.s64 = ctx.r7.s64 * 44;
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f28,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f19,f31,f2
	ctx.f19.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// fsubs f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f31.f64));
	// mulli r29,r7,24
	ctx.r29.s64 = ctx.r7.s64 * 24;
	// lfsx f27,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f29,f27,f28
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// mulli r28,r7,28
	ctx.r28.s64 = ctx.r7.s64 * 28;
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fsubs f15,f30,f2
	ctx.f15.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// fadds f2,f30,f2
	ctx.f2.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// lfsx f26,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// rlwinm r27,r7,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r26,r7,5,0,26
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r25,r7,20
	ctx.r25.s64 = ctx.r7.s64 * 20;
	// fmuls f30,f15,f12
	ctx.f30.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfsx f25,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfsx f24,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// lfsx f23,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 - ctx.f25.f64));
	// lfsx f21,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fadds f25,f23,f24
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// mulli r11,r7,48
	ctx.r11.s64 = ctx.r7.s64 * 48;
	// lfsx f22,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fadds f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fsubs f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// lfsx f20,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f21,f19,f20
	ctx.f21.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfsx f18,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// rlwinm r24,r7,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmsubs f20,f19,f0,f20
	ctx.f20.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f20.f64)));
	// fadds f19,f27,f29
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f29.f64));
	// fsubs f27,f29,f27
	ctx.f27.f64 = double(float(ctx.f29.f64 - ctx.f27.f64));
	// fsubs f29,f28,f26
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f26.f64));
	// lfsx f31,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f16,f17,f31
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f31.f64));
	// fnmsubs f31,f17,f0,f31
	ctx.f31.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f31.f64)));
	// fadds f17,f26,f28
	ctx.f17.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fmuls f28,f27,f12
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fsubs f15,f2,f29
	ctx.f15.f64 = double(float(ctx.f2.f64 - ctx.f29.f64));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fadds f27,f16,f21
	ctx.f27.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// fsubs f26,f16,f21
	ctx.f26.f64 = double(float(ctx.f16.f64 - ctx.f21.f64));
	// fsubs f21,f31,f20
	ctx.f21.f64 = double(float(ctx.f31.f64 - ctx.f20.f64));
	// fadds f31,f31,f20
	ctx.f31.f64 = double(float(ctx.f31.f64 + ctx.f20.f64));
	// fadds f20,f19,f25
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// fnmsubs f29,f17,f0,f24
	ctx.f29.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fadds f16,f17,f24
	ctx.f16.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// fnmsubs f25,f19,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fadds f24,f28,f21
	ctx.f24.f64 = double(float(ctx.f28.f64 + ctx.f21.f64));
	// fsubs f28,f21,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 - ctx.f28.f64));
	// fsubs f21,f27,f20
	ctx.f21.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// fadds f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 + ctx.f27.f64));
	// lfs f20,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64));
	// fsubs f20,f30,f29
	ctx.f20.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// fadds f30,f29,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// fsubs f29,f31,f25
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f25.f64));
	// fadds f31,f25,f31
	ctx.f31.f64 = double(float(ctx.f25.f64 + ctx.f31.f64));
	// lfsx f25,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-368(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfsx f25,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-372(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfsx f25,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-400(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfsx f25,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-388(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// fmuls f17,f20,f6
	ctx.f17.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfsx f25,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fadds f14,f27,f4
	ctx.f14.f64 = double(float(ctx.f27.f64 + ctx.f4.f64));
	// stfs f25,-396(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// fmuls f19,f30,f8
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// lfsx f25,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-320(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfsx f25,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f25,-392(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfsx f25,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// stfs f14,0(r5)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// stfs f25,-376(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// fmuls f25,f16,f10
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmadds f17,f24,f7,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f17.f64));
	// stfs f17,-360(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f17,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f17,f1
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// fsubs f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// lfs f14,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f19,f28,f9,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f9.f64 - ctx.f19.f64));
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-400(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// fmadds f25,f26,f11,f25
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 + ctx.f25.f64));
	// lfs f17,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-388(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f14,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-316(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// lfs f17,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-396(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 - ctx.f14.f64));
	// stfs f17,-392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f17,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f18
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfs f17,-320(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f14,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f1.f64));
	// stfs f17,-312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// lfs f17,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f17,-372(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f17,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f17.f64 = double(temp.f32);
	// fsubs f17,f1,f17
	ctx.f17.f64 = double(float(ctx.f1.f64 - ctx.f17.f64));
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// lfs f1,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f14.f64));
	// stfs f1,-368(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// lfs f1,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f14,f14,f1
	ctx.f14.f64 = double(float(ctx.f14.f64 - ctx.f1.f64));
	// stfs f14,-400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -400, temp.u32);
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// fadds f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 + ctx.f1.f64));
	// stfs f1,-392(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -392, temp.u32);
	// lfs f1,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f1.f64 = double(temp.f32);
	// lfs f14,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f1,f14
	ctx.f14.f64 = double(float(ctx.f1.f64 - ctx.f14.f64));
	// lfs f1,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f1,f0,f18
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f18.f64)));
	// stfs f1,-384(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f18,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f18.f64 = double(temp.f32);
	// lfs f1,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f1,f0,f18
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f18.f64)));
	// fmuls f18,f17,f12
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f17,f14,f12
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f12.f64));
	// stfs f17,-376(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f17,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-316(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// mulli r10,r8,48
	ctx.r10.s64 = ctx.r8.s64 * 48;
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// stfs f17,-308(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + -308, temp.u32);
	// lfs f17,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f17
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// stfs f14,-320(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -320, temp.u32);
	// lfs f14,-400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -400);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 - ctx.f17.f64));
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f23
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f23.f64));
	// stfs f14,-372(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// mulli r9,r8,20
	ctx.r9.s64 = ctx.r8.s64 * 20;
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-396(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -396, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f1,f14
	ctx.f14.f64 = double(float(ctx.f1.f64 + ctx.f14.f64));
	// stfs f14,-380(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -380, temp.u32);
	// lfs f14,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f14.f64));
	// lfs f14,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f23,f14,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfs f14,-392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -392);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f22,f14,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// stfs f22,-312(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// rlwinm r31,r8,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f22,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f22.f64 = double(temp.f32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f14,f22
	ctx.f14.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// stfs f14,-384(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -384, temp.u32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f14,f22,f14
	ctx.f14.f64 = double(float(ctx.f22.f64 - ctx.f14.f64));
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f1.f64));
	// stfs f22,-388(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -388, temp.u32);
	// lfs f22,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f1,f1,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f22.f64));
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f22,f22,f23
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfs f22,-368(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -368, temp.u32);
	// lfs f22,-380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -380);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f23,f22
	ctx.f22.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f23,-364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -364);
	ctx.f23.f64 = double(temp.f32);
	// stfs f22,-316(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -316, temp.u32);
	// fmuls f23,f14,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f23.f64));
	// stfs f23,-372(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -372, temp.u32);
	// lfs f23,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f14,f23,f18
	ctx.f14.f64 = double(float(ctx.f23.f64 - ctx.f18.f64));
	// stfs f14,-312(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -312, temp.u32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// stfs f23,-376(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -376, temp.u32);
	// lfs f18,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f18.f64 = double(temp.f32);
	// lfs f14,-320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f3.f64));
	// stfs f23,0(r6)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f23,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f18,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f23,f14,f18,f23
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f18.f64 + ctx.f23.f64));
	// lfs f18,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f17,f18,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f18.f64 + ctx.f22.f64));
	// fadds f18,f22,f23
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fsubs f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// fmuls f22,f20,f7
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fmuls f20,f30,f9
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// lfs f30,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// lfs f30,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fmsubs f30,f24,f6,f22
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 - ctx.f22.f64));
	// lfs f24,-368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -368);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f8,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f8.f64 + ctx.f20.f64));
	// fmsubs f24,f24,f22,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f14.f64));
	// lfs f14,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f14.f64 = double(temp.f32);
	// lfs f22,-316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -316);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f26,f10
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fmsubs f22,f22,f14,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f14.f64 - ctx.f17.f64));
	// lfs f17,-384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -384);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f14.f64 = double(temp.f32);
	// mulli r29,r8,40
	ctx.r29.s64 = ctx.r8.s64 * 40;
	// fnmsubs f3,f17,f14,f3
	ctx.f3.f64 = double(float(-(ctx.f17.f64 * ctx.f14.f64 - ctx.f3.f64)));
	// lfs f17,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f17.f64 = double(temp.f32);
	// fadds f14,f28,f30
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lfs f26,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f26.f64));
	// mulli r28,r8,12
	ctx.r28.s64 = ctx.r8.s64 * 12;
	// fadds f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 + ctx.f19.f64));
	// fsubs f17,f30,f28
	ctx.f17.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// lfs f30,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f30,f30,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f24.f64));
	// fmsubs f20,f16,f11,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 - ctx.f20.f64));
	// fsubs f16,f3,f22
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f22.f64));
	// fmuls f14,f14,f5
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// stfs f14,-360(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -360, temp.u32);
	// lfs f14,-372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -372);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f3,f22,f13,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f3.f64));
	// fmadds f24,f24,f13,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f14.f64));
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// mulli r27,r8,36
	ctx.r27.s64 = ctx.r8.s64 * 36;
	// fadds f28,f26,f25
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// fmsubs f26,f26,f13,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64 - ctx.f25.f64));
	// fsubs f22,f20,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 - ctx.f17.f64));
	// fmadds f20,f17,f13,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f20.f64));
	// fadds f14,f16,f30
	ctx.f14.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// fsubs f30,f16,f30
	ctx.f30.f64 = double(float(ctx.f16.f64 - ctx.f30.f64));
	// mulli r26,r8,24
	ctx.r26.s64 = ctx.r8.s64 * 24;
	// fadds f17,f3,f24
	ctx.f17.f64 = double(float(ctx.f3.f64 + ctx.f24.f64));
	// fsubs f3,f3,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f24.f64));
	// fadds f25,f19,f23
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f23.f64));
	// fsubs f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f19.f64));
	// fadds f19,f28,f18
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f18.f64));
	// fsubs f24,f14,f22
	ctx.f24.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// mulli r25,r8,44
	ctx.r25.s64 = ctx.r8.s64 * 44;
	// fadds f22,f14,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 + ctx.f22.f64));
	// fadds f14,f17,f20
	ctx.f14.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// stfsx f14,r11,r6
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 - ctx.f20.f64));
	// stfsx f20,r10,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f20,f3,f26
	ctx.f20.f64 = double(float(ctx.f3.f64 + ctx.f26.f64));
	// stfsx f20,r9,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f3,f3,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// stfsx f3,r31,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f20,-312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -312);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f26,f20,f9
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// rlwinm r24,r8,3,0,28
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r23,r8,28
	ctx.r23.s64 = ctx.r8.s64 * 28;
	// fsubs f3,f24,f25
	ctx.f3.f64 = double(float(ctx.f24.f64 - ctx.f25.f64));
	// stfsx f3,r30,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f3,f25,f24
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfsx f3,r29,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f3,f22,f23
	ctx.f3.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f3,r28,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f3,f22,f23
	ctx.f3.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f3,r27,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fmuls f25,f1,f6
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f22,-388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -388);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,-396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -396);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f23,f11
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// lfs f16,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f30,f16
	ctx.f16.f64 = double(float(ctx.f30.f64 + ctx.f16.f64));
	// fsubs f3,f16,f19
	ctx.f3.f64 = double(float(ctx.f16.f64 - ctx.f19.f64));
	// stfsx f3,r26,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// lfs f3,-356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -356);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f24,f15,f3
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// lfs f3,-352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f2,f3
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmadds f3,f22,f8,f26
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f8.f64 + ctx.f26.f64));
	// lfs f26,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f7,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f25.f64));
	// lfs f25,-348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -348);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f25,f29,f25,f24
	ctx.f25.f64 = double(float(ctx.f29.f64 * ctx.f25.f64 - ctx.f24.f64));
	// lfs f24,-344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -344);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f31,f24,f17
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f24.f64 + ctx.f17.f64));
	// lfs f17,-340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -340);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fnmsubs f4,f27,f17,f4
	ctx.f4.f64 = double(float(-(ctx.f27.f64 * ctx.f17.f64 - ctx.f4.f64)));
	// lfs f27,-308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -308);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f1,f7
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// add r3,r21,r3
	ctx.r3.u64 = ctx.r21.u64 + ctx.r3.u64;
	// fmsubs f1,f27,f10,f14
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f14.f64));
	// lfs f14,-336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -336);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f29,f14
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f14.f64));
	// lfs f29,-376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -376);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f28,f18,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 - ctx.f28.f64));
	// add r4,r21,r4
	ctx.r4.u64 = ctx.r21.u64 + ctx.r4.u64;
	// fmsubs f29,f29,f6,f17
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f17,-332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -332);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f31,f17
	ctx.f17.f64 = double(float(ctx.f31.f64 * ctx.f17.f64));
	// fmsubs f31,f22,f9,f20
	ctx.f31.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 - ctx.f20.f64));
	// fmuls f22,f27,f11
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f27,-360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -360);
	ctx.f27.f64 = double(temp.f32);
	// fadds f20,f19,f16
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f16.f64));
	// stfsx f20,r25,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fsubs f30,f30,f27
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f27.f64));
	// lfs f19,-324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -324);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f26,f3
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// lfs f27,-328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -328);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f15,f27,f14
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f27.f64 + ctx.f14.f64));
	// fmsubs f2,f2,f19,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64 - ctx.f17.f64));
	// fmadds f23,f23,f10,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f22.f64));
	// fsubs f22,f3,f26
	ctx.f22.f64 = double(float(ctx.f3.f64 - ctx.f26.f64));
	// fsubs f26,f4,f24
	ctx.f26.f64 = double(float(ctx.f4.f64 - ctx.f24.f64));
	// fmadds f4,f24,f13,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f4.f64));
	// fadds f24,f31,f29
	ctx.f24.f64 = double(float(ctx.f31.f64 + ctx.f29.f64));
	// fsubs f29,f29,f31
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f31.f64));
	// fsubs f3,f21,f25
	ctx.f3.f64 = double(float(ctx.f21.f64 - ctx.f25.f64));
	// fmadds f25,f25,f13,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f21.f64));
	// fadds f31,f30,f28
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f28.f64));
	// stfsx f31,r24,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fsubs f31,f30,f28
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f28.f64));
	// stfsx f31,r23,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// fadds f31,f2,f27
	ctx.f31.f64 = double(float(ctx.f2.f64 + ctx.f27.f64));
	// add r6,r20,r6
	ctx.r6.u64 = ctx.r20.u64 + ctx.r6.u64;
	// fsubs f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 - ctx.f2.f64));
	// fmuls f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// fmuls f30,f29,f5
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// fsubs f29,f1,f22
	ctx.f29.f64 = double(float(ctx.f1.f64 - ctx.f22.f64));
	// fadds f27,f4,f25
	ctx.f27.f64 = double(float(ctx.f4.f64 + ctx.f25.f64));
	// fmadds f1,f22,f13,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fsubs f28,f26,f3
	ctx.f28.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fadds f26,f24,f23
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// fsubs f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f25.f64));
	// fsubs f21,f31,f30
	ctx.f21.f64 = double(float(ctx.f31.f64 - ctx.f30.f64));
	// fadds f31,f30,f31
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f31.f64));
	// fmsubs f30,f24,f13,f23
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 - ctx.f23.f64));
	// fsubs f22,f27,f1
	ctx.f22.f64 = double(float(ctx.f27.f64 - ctx.f1.f64));
	// stfsx f22,r10,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f25,f28,f20
	ctx.f25.f64 = double(float(ctx.f28.f64 - ctx.f20.f64));
	// fsubs f22,f3,f29
	ctx.f22.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fsubs f19,f26,f2
	ctx.f19.f64 = double(float(ctx.f26.f64 - ctx.f2.f64));
	// fadds f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f20.f64));
	// fadds f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 + ctx.f2.f64));
	// fadds f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// stfsx f1,r11,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// fsubs f26,f4,f30
	ctx.f26.f64 = double(float(ctx.f4.f64 - ctx.f30.f64));
	// fadds f4,f30,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f4.f64));
	// fsubs f1,f22,f21
	ctx.f1.f64 = double(float(ctx.f22.f64 - ctx.f21.f64));
	// stfsx f1,r29,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f1,f21,f22
	ctx.f1.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f1,r30,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// stfsx f26,r9,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f1,f25,f19
	ctx.f1.f64 = double(float(ctx.f25.f64 - ctx.f19.f64));
	// stfsx f4,r31,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f29,f19,f25
	ctx.f29.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// stfsx f1,r25,r5
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fsubs f27,f28,f2
	ctx.f27.f64 = double(float(ctx.f28.f64 - ctx.f2.f64));
	// stfsx f29,r26,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// stfsx f27,r23,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f28,f3,f31
	ctx.f28.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// stfsx f2,r24,r5
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f31,f3
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// stfsx f28,r28,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// stfsx f4,r27,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + -26212);
	// add r5,r20,r5
	ctx.r5.u64 = ctx.r20.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82ca97a4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CA97A4;
loc_82CA9E14:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82d5c58c
	ctx.lr = 0x82CA9E1C;
	__restfpr_14(ctx, base);
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA9E20"))) PPC_WEAK_FUNC(sub_82CA9E20);
PPC_FUNC_IMPL(__imp__sub_82CA9E20) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26984
	ctx.r5.s64 = ctx.r11.s64 + -26984;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-26976
	ctx.r4.s64 = ctx.r11.s64 + -26976;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CA9E38"))) PPC_WEAK_FUNC(sub_82CA9E38);
PPC_FUNC_IMPL(__imp__sub_82CA9E38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82CA9E40;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82d5c540
	ctx.lr = 0x82CA9E48;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82caa15c
	if (!ctx.cr6.gt) goto loc_82CAA15C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r23,r10,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// rlwinm r22,r11,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r21,-32234
	ctx.r21.s64 = -2112487424;
	// lfs f13,28136(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f0.f64 = double(temp.f32);
loc_82CA9E74:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r7,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f12,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r9,r7,40
	ctx.r9.s64 = ctx.r7.s64 * 40;
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f22,f9,f10
	ctx.f22.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfsx f7,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f21,f9,f10
	ctx.f21.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// rlwinm r31,r7,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f6,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// mulli r30,r7,28
	ctx.r30.s64 = ctx.r7.s64 * 28;
	// fadds f10,f7,f8
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f5,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f20,f8,f7
	ctx.f20.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfsx f4,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f9,f4,f6
	ctx.f9.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfsx f2,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fadds f8,f3,f5
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f5.f64));
	// mulli r29,r7,44
	ctx.r29.s64 = ctx.r7.s64 * 44;
	// lfsx f1,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f19,f4,f6
	ctx.f19.f64 = double(float(ctx.f4.f64 - ctx.f6.f64));
	// fsubs f18,f5,f3
	ctx.f18.f64 = double(float(ctx.f5.f64 - ctx.f3.f64));
	// fmuls f7,f21,f13
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fadds f21,f10,f11
	ctx.f21.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// fnmsubs f11,f10,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfsx f31,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f6,f20,f13
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfsx f30,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f5,f31,f2
	ctx.f5.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// rlwinm r28,r7,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f4,f30,f1
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// mulli r27,r7,20
	ctx.r27.s64 = ctx.r7.s64 * 20;
	// fsubs f30,f1,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 - ctx.f30.f64));
	// fsubs f31,f31,f2
	ctx.f31.f64 = double(float(ctx.f31.f64 - ctx.f2.f64));
	// fmuls f3,f19,f13
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f2,f18,f13
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfsx f29,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// lfsx f28,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// fadds f20,f11,f7
	ctx.f20.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// fadds f1,f28,f29
	ctx.f1.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// mulli r26,r7,24
	ctx.r26.s64 = ctx.r7.s64 * 24;
	// fsubs f29,f28,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 - ctx.f29.f64));
	// fadds f28,f22,f12
	ctx.f28.f64 = double(float(ctx.f22.f64 + ctx.f12.f64));
	// fnmsubs f12,f22,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fmuls f31,f31,f13
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// fmuls f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfsx f27,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f26,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f10,f9,f27
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f27.f64));
	// mulli r25,r7,12
	ctx.r25.s64 = ctx.r7.s64 * 12;
	// fnmsubs f9,f9,f0,f27
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// fadds f22,f8,f26
	ctx.f22.f64 = double(float(ctx.f8.f64 + ctx.f26.f64));
	// fnmsubs f8,f8,f0,f26
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// fmuls f29,f29,f13
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f13.f64));
	// fadds f15,f6,f12
	ctx.f15.f64 = double(float(ctx.f6.f64 + ctx.f12.f64));
	// lfsx f25,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f5,f25
	ctx.f27.f64 = double(float(ctx.f5.f64 + ctx.f25.f64));
	// mulli r24,r7,36
	ctx.r24.s64 = ctx.r7.s64 * 36;
	// fnmsubs f5,f5,f0,f25
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fadds f26,f4,f24
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f24.f64));
	// fnmsubs f4,f4,f0,f24
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// lfsx f24,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f14,f10,f28
	ctx.f14.f64 = double(float(ctx.f10.f64 + ctx.f28.f64));
	// stfs f14,-256(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fadds f18,f8,f3
	ctx.f18.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// lfsx f23,r24,r3
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// fadds f25,f1,f23
	ctx.f25.f64 = double(float(ctx.f1.f64 + ctx.f23.f64));
	// lfsx f19,r24,r4
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f1,f1,f0,f23
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfsx f23,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fadds f17,f30,f5
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f5.f64));
	// fadds f16,f4,f31
	ctx.f16.f64 = double(float(ctx.f4.f64 + ctx.f31.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fadds f14,f25,f27
	ctx.f14.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// stfs f14,-252(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fsubs f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// mulli r9,r8,36
	ctx.r9.s64 = ctx.r8.s64 * 36;
	// fsubs f25,f21,f22
	ctx.f25.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// fsubs f8,f8,f3
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f3.f64));
	// fadds f14,f22,f21
	ctx.f14.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f22,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f22.f64 = double(temp.f32);
	// fadds f3,f23,f24
	ctx.f3.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fsubs f21,f24,f23
	ctx.f21.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// lfs f23,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f10.f64));
	// fsubs f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f31.f64));
	// mulli r30,r8,28
	ctx.r30.s64 = ctx.r8.s64 * 28;
	// fsubs f31,f20,f18
	ctx.f31.f64 = double(float(ctx.f20.f64 - ctx.f18.f64));
	// fadds f28,f18,f20
	ctx.f28.f64 = double(float(ctx.f18.f64 + ctx.f20.f64));
	// fsubs f20,f23,f22
	ctx.f20.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfsx f20,r11,r5
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f20,f25,f27
	ctx.f20.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// fsubs f18,f25,f27
	ctx.f18.f64 = double(float(ctx.f25.f64 - ctx.f27.f64));
	// fsubs f27,f7,f8
	ctx.f27.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fadds f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,0(r5)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f7,f3,f19
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f19.f64));
	// mulli r29,r8,40
	ctx.r29.s64 = ctx.r8.s64 * 40;
	// fmuls f23,f21,f13
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fnmsubs f3,f3,f0,f19
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f19.f64)));
	// fadds f11,f2,f9
	ctx.f11.f64 = double(float(ctx.f2.f64 + ctx.f9.f64));
	// fsubs f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f6.f64));
	// fsubs f9,f9,f2
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f2.f64));
	// rlwinm r28,r8,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// add r3,r23,r3
	ctx.r3.u64 = ctx.r23.u64 + ctx.r3.u64;
	// add r4,r23,r4
	ctx.r4.u64 = ctx.r23.u64 + ctx.r4.u64;
	// fadds f22,f7,f26
	ctx.f22.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// fadds f25,f23,f1
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f1.f64));
	// fsubs f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 - ctx.f7.f64));
	// fadds f26,f3,f29
	ctx.f26.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// fsubs f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// fsubs f24,f15,f11
	ctx.f24.f64 = double(float(ctx.f15.f64 - ctx.f11.f64));
	// fadds f11,f11,f15
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f15.f64));
	// fsubs f29,f14,f22
	ctx.f29.f64 = double(float(ctx.f14.f64 - ctx.f22.f64));
	// stfsx f29,r11,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f21,f17,f25
	ctx.f21.f64 = double(float(ctx.f17.f64 - ctx.f25.f64));
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fadds f29,f22,f14
	ctx.f29.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// stfs f29,0(r6)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f25,f25,f17
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// stfsx f20,r10,r6
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// stfsx f18,r9,r6
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f10,f7
	ctx.f29.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// stfsx f29,r10,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfsx f10,r9,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f16,f26
	ctx.f10.f64 = double(float(ctx.f16.f64 - ctx.f26.f64));
	// fadds f7,f26,f16
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f16.f64));
	// mulli r10,r8,44
	ctx.r10.s64 = ctx.r8.s64 * 44;
	// fsubs f29,f31,f21
	ctx.f29.f64 = double(float(ctx.f31.f64 - ctx.f21.f64));
	// stfsx f29,r31,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f31,f21,f31
	ctx.f31.f64 = double(float(ctx.f21.f64 + ctx.f31.f64));
	// fsubs f29,f11,f25
	ctx.f29.f64 = double(float(ctx.f11.f64 - ctx.f25.f64));
	// fadds f26,f11,f25
	ctx.f26.f64 = double(float(ctx.f11.f64 + ctx.f25.f64));
	// fsubs f11,f4,f3
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f3,f24,f10
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f10.f64));
	// stfsx f3,r31,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// stfsx f31,r30,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f24,f10
	ctx.f10.f64 = double(float(ctx.f24.f64 - ctx.f10.f64));
	// stfsx f10,r30,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f28,f7
	ctx.f10.f64 = double(float(ctx.f28.f64 - ctx.f7.f64));
	// stfsx f29,r29,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f28.f64));
	// stfsx f10,r29,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f5,f30
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f30.f64));
	// stfsx f26,r28,r5
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r31,r8,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// stfsx f7,r28,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f1,f23
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f23.f64));
	// fsubs f6,f8,f4
	ctx.f6.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// fadds f5,f4,f8
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fsubs f8,f10,f7
	ctx.f8.f64 = double(float(ctx.f10.f64 - ctx.f7.f64));
	// fadds f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// fsubs f7,f12,f9
	ctx.f7.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// fadds f12,f9,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
	// fsubs f9,f27,f8
	ctx.f9.f64 = double(float(ctx.f27.f64 - ctx.f8.f64));
	// stfsx f9,r11,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f9,f8,f27
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f27.f64));
	// fadds f8,f7,f11
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f8,r11,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// stfsx f9,r10,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 - ctx.f11.f64));
	// stfsx f11,r10,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f12,f10
	ctx.f11.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfsx f11,r9,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// stfsx f6,r9,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// stfsx f12,r31,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// add r5,r22,r5
	ctx.r5.u64 = ctx.r22.u64 + ctx.r5.u64;
	// stfsx f5,r31,r6
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,-26212(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + -26212);
	// add r6,r22,r6
	ctx.r6.u64 = ctx.r22.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82ca9e74
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CA9E74;
loc_82CAA15C:
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82d5c58c
	ctx.lr = 0x82CAA164;
	__restfpr_14(ctx, base);
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAA168"))) PPC_WEAK_FUNC(sub_82CAA168);
PPC_FUNC_IMPL(__imp__sub_82CAA168) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26920
	ctx.r5.s64 = ctx.r11.s64 + -26920;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-25032
	ctx.r4.s64 = ctx.r11.s64 + -25032;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAA180"))) PPC_WEAK_FUNC(sub_82CAA180);
PPC_FUNC_IMPL(__imp__sub_82CAA180) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82CAA188;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82d5c540
	ctx.lr = 0x82CAA190;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82caa720
	if (!ctx.cr6.gt) goto loc_82CAA720;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r24,r10,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r25,-32234
	ctx.r25.s64 = -2112487424;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// lis r27,-32234
	ctx.r27.s64 = -2112487424;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lis r29,-32234
	ctx.r29.s64 = -2112487424;
	// lfs f5,-29636(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -29636);
	ctx.f5.f64 = double(temp.f32);
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// lis r31,-32234
	ctx.r31.s64 = -2112487424;
	// lfs f6,-29640(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -29640);
	ctx.f6.f64 = double(temp.f32);
	// lis r9,-32234
	ctx.r9.s64 = -2112487424;
	// lfs f7,-29644(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -29644);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// lfs f8,-29648(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -29648);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lfs f9,-29652(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -29652);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-29656(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -29656);
	ctx.f10.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f11,-29660(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -29660);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-29664(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -29664);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-29668(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29668);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29672(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29672);
	ctx.f0.f64 = double(temp.f32);
loc_82CAA1FC:
	// rlwinm r26,r7,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f4,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// mulli r25,r7,36
	ctx.r25.s64 = ctx.r7.s64 * 36;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f2,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,-284(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// lfsx f2,r25,r4
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// stfs f2,-272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// mulli r10,r7,28
	ctx.r10.s64 = ctx.r7.s64 * 28;
	// lfsx f15,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f15.f64 = double(temp.f32);
	// lfsx f14,r25,r3
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r3.u32);
	ctx.f14.f64 = double(temp.f32);
	// lfsx f1,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f31,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// lfsx f30,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f2,f31,f1
	ctx.f2.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// mulli r9,r7,20
	ctx.r9.s64 = ctx.r7.s64 * 20;
	// lfsx f29,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f22,f31,f1
	ctx.f22.f64 = double(float(ctx.f31.f64 - ctx.f1.f64));
	// stfs f22,-268(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -268, temp.u32);
	// fsubs f31,f30,f29
	ctx.f31.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// stfs f31,-304(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + -304, temp.u32);
	// fadds f1,f29,f30
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// lfsx f27,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f28,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f28.f64 = double(temp.f32);
	// mulli r31,r7,24
	ctx.r31.s64 = ctx.r7.s64 * 24;
	// lfsx f25,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f29,f27,f25
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// stfs f29,-292(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// fadds f30,f25,f27
	ctx.f30.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfsx f26,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// fadds f31,f26,f28
	ctx.f31.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// fsubs f29,f26,f28
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f28.f64));
	// stfs f29,-288(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + -288, temp.u32);
	// lfsx f23,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f24,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// rlwinm r29,r7,5,0,26
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r28,r7,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r27,r7,40
	ctx.r27.s64 = ctx.r7.s64 * 40;
	// lfsx f21,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f21.f64 = double(temp.f32);
	// fsubs f27,f23,f21
	ctx.f27.f64 = double(float(ctx.f23.f64 - ctx.f21.f64));
	// stfs f27,-296(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + -296, temp.u32);
	// lfsx f19,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f19.f64 = double(temp.f32);
	// fadds f28,f21,f23
	ctx.f28.f64 = double(float(ctx.f21.f64 + ctx.f23.f64));
	// lfsx f18,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f23,f14,f15
	ctx.f23.f64 = double(float(ctx.f14.f64 - ctx.f15.f64));
	// fsubs f26,f19,f18
	ctx.f26.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f23,-280(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -280, temp.u32);
	// fadds f27,f18,f19
	ctx.f27.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// lfsx f20,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f20.f64 = double(temp.f32);
	// fadds f29,f20,f24
	ctx.f29.f64 = double(float(ctx.f20.f64 + ctx.f24.f64));
	// lfsx f17,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f17.f64 = double(temp.f32);
	// lfsx f16,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f16.f64 = double(temp.f32);
	// fsubs f20,f20,f24
	ctx.f20.f64 = double(float(ctx.f20.f64 - ctx.f24.f64));
	// fadds f21,f16,f17
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// stfs f26,-260(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -260, temp.u32);
	// lfs f19,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f19.f64 = double(temp.f32);
	// fsubs f25,f16,f17
	ctx.f25.f64 = double(float(ctx.f16.f64 - ctx.f17.f64));
	// fadds f24,f14,f15
	ctx.f24.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// stfs f21,-248(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f18,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f18.f64 = double(temp.f32);
	// fadds f17,f30,f1
	ctx.f17.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fadds f23,f18,f19
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f19.f64));
	// stfs f25,-264(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -264, temp.u32);
	// fsubs f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 - ctx.f18.f64));
	// stfs f20,-276(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -276, temp.u32);
	// fadds f18,f31,f2
	ctx.f18.f64 = double(float(ctx.f31.f64 + ctx.f2.f64));
	// stfs f24,-300(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + -300, temp.u32);
	// stfs f23,-272(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -272, temp.u32);
	// stfs f19,-284(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + -284, temp.u32);
	// fmuls f14,f21,f8
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f8.f64));
	// fadds f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f28.f64));
	// lfs f15,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f18,f29
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f29.f64));
	// fadds f18,f18,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f24.f64));
	// lfs f16,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f11
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// fmsubs f16,f15,f12,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f16.f64));
	// lfs f15,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fadds f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f23.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fmadds f15,f26,f0,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f15.f64));
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fnmadds f24,f24,f9,f14
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f9.f64 + ctx.f14.f64)));
	// fmuls f14,f23,f8
	ctx.f14.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fadds f21,f18,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f21.f64));
	// fmuls f23,f1,f9
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// stfs f23,-256(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r31,r8,36
	ctx.r31.s64 = ctx.r8.s64 * 36;
	// fadds f18,f17,f27
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f27.f64));
	// fadds f17,f15,f16
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// fmuls f16,f22,f10
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f15,f25,f11
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// fadds f21,f21,f4
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f4.f64));
	// stfs f21,0(r5)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmadds f20,f25,f0,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f20.f64));
	// fadds f21,f18,f3
	ctx.f21.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// stfs f21,0(r6)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fnmsubs f21,f19,f10,f17
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f10.f64 - ctx.f17.f64)));
	// lfs f19,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// stfs f21,-252(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmuls f18,f27,f8
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmuls f17,f1,f6
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f21,f2,f6
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmsubs f22,f22,f12,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 - ctx.f19.f64));
	// lfs f19,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f19.f64 = double(temp.f32);
	// fnmadds f19,f19,f9,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f9.f64 + ctx.f18.f64)));
	// fmsubs f18,f30,f7,f17
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 - ctx.f17.f64));
	// lfs f17,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f17.f64 = double(temp.f32);
	// fnmadds f17,f17,f13,f16
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f13.f64 + ctx.f16.f64)));
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// fmr f23,f16
	ctx.f23.f64 = ctx.f16.f64;
	// fmsubs f21,f31,f7,f21
	ctx.f21.f64 = double(float(ctx.f31.f64 * ctx.f7.f64 - ctx.f21.f64));
	// fadds f22,f20,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f22.f64));
	// fadds f20,f19,f18
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// fmadds f19,f28,f5,f3
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fmadds f16,f23,f0,f15
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f15.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// fnmadds f15,f28,f6,f14
	ctx.f15.f64 = double(float(-(ctx.f28.f64 * ctx.f6.f64 + ctx.f14.f64)));
	// fmadds f21,f29,f5,f4
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f5.f64 + ctx.f4.f64));
	// fnmsubs f23,f23,f10,f22
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f10.f64 - ctx.f22.f64)));
	// lfs f14,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f14.f64 = double(temp.f32);
	// fadds f22,f20,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// fmsubs f14,f30,f5,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f5.f64 - ctx.f14.f64));
	// lfs f19,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f19.f64 = double(temp.f32);
	// fadds f18,f17,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fmadds f16,f27,f7,f3
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f3.f64));
	// fadds f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f21.f64));
	// lfs f21,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f21.f64 = double(temp.f32);
	// fadds f17,f15,f14
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f14.f64));
	// fmuls f15,f21,f10
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fnmsubs f21,f19,f12,f18
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f12.f64 - ctx.f18.f64)));
	// lfs f18,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f17,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fnmadds f15,f18,f13,f15
	ctx.f15.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 + ctx.f15.f64)));
	// lfs f18,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f18.f64 = double(temp.f32);
	// fsubs f16,f24,f18
	ctx.f16.f64 = double(float(ctx.f24.f64 - ctx.f18.f64));
	// stfsx f16,r11,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f18.f64));
	// stfsx f24,r10,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfsx f24,r10,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f22,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 - ctx.f23.f64));
	// stfsx f24,r11,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f26,f11
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// mulli r11,r8,40
	ctx.r11.s64 = ctx.r8.s64 * 40;
	// fmuls f23,f2,f9
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fmuls f22,f22,f10
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fadds f24,f20,f21
	ctx.f24.f64 = double(float(ctx.f20.f64 + ctx.f21.f64));
	// stfsx f24,r9,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f24,f20,f21
	ctx.f24.f64 = double(float(ctx.f20.f64 - ctx.f21.f64));
	// stfsx f24,r31,r6
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// lfs f24,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f8
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f24,f29,f6,f24
	ctx.f24.f64 = double(float(-(ctx.f29.f64 * ctx.f6.f64 + ctx.f24.f64)));
	// lfs f16,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f23,f31,f5,f23
	ctx.f23.f64 = double(float(ctx.f31.f64 * ctx.f5.f64 - ctx.f23.f64));
	// fmadds f17,f16,f0,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f17.f64));
	// lfs f16,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f16,f0,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f22.f64));
	// lfs f16,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f16,f11,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f26.f64));
	// lfs f16,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f31,f6
	ctx.f20.f64 = double(float(ctx.f31.f64 * ctx.f6.f64));
	// fmuls f21,f2,f8
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fmuls f19,f19,f10
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f18,f1,f8
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmuls f14,f30,f6
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// fadds f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f23.f64));
	// lfs f23,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f23.f64 = double(temp.f32);
	// stfs f26,-248(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fmr f26,f23
	ctx.f26.f64 = ctx.f23.f64;
	// fadds f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 + ctx.f17.f64));
	// fmsubs f20,f16,f7,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 - ctx.f20.f64));
	// lfs f16,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f16.f64 = double(temp.f32);
	// fnmadds f21,f29,f9,f21
	ctx.f21.f64 = double(float(-(ctx.f29.f64 * ctx.f9.f64 + ctx.f21.f64)));
	// fmadds f19,f16,f0,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f19.f64));
	// lfs f16,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f25,f16,f11,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f25.f64));
	// lfs f16,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f16.f64 = double(temp.f32);
	// fnmadds f18,f28,f9,f18
	ctx.f18.f64 = double(float(-(ctx.f28.f64 * ctx.f9.f64 + ctx.f18.f64)));
	// fmsubs f14,f16,f7,f14
	ctx.f14.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 - ctx.f14.f64));
	// fmadds f15,f26,f7,f4
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fadds f25,f19,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 + ctx.f25.f64));
	// lfs f19,-296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -296);
	ctx.f19.f64 = double(temp.f32);
	// fadds f14,f18,f14
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f14.f64));
	// lfs f23,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// stfs f23,-248(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fadds f22,f21,f20
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// stfs f22,-252(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + -252, temp.u32);
	// fmadds f21,f26,f5,f4
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f4.f64));
	// stfs f21,-256(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + -256, temp.u32);
	// fadds f21,f24,f15
	ctx.f21.f64 = double(float(ctx.f24.f64 + ctx.f15.f64));
	// lfs f24,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f24.f64 = double(temp.f32);
	// stfs f25,-292(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + -292, temp.u32);
	// fmr f25,f24
	ctx.f25.f64 = ctx.f24.f64;
	// fmadds f20,f27,f5,f3
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fmr f23,f19
	ctx.f23.f64 = ctx.f19.f64;
	// fnmsubs f22,f23,f12,f17
	ctx.f22.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f17.f64)));
	// fsubs f15,f21,f22
	ctx.f15.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfsx f15,r31,r5
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f22,r9,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// mulli r9,r8,12
	ctx.r9.s64 = ctx.r8.s64 * 12;
	// fmuls f21,f23,f11
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// lfs f24,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f24.f64 = double(temp.f32);
	// stfs f20,-248(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// fmadds f20,f25,f12,f24
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 + ctx.f24.f64));
	// lfs f24,-252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -252);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,-256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -256);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f24,f19
	ctx.f19.f64 = double(float(ctx.f24.f64 + ctx.f19.f64));
	// lfs f18,-292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -292);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,-288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -288);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f18,f24,f12,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f18.f64));
	// fsubs f22,f19,f20
	ctx.f22.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfsx f22,r11,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f22,f19,f20
	ctx.f22.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfsx f22,r10,r5
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lfs f20,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f31,f8
	ctx.f19.f64 = double(float(ctx.f31.f64 * ctx.f8.f64));
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f17,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 + ctx.f17.f64));
	// fadds f22,f17,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// stfsx f22,r10,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f22,f17,f18
	ctx.f22.f64 = double(float(ctx.f17.f64 - ctx.f18.f64));
	// stfsx f22,r11,r6
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// lfs f22,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f22.f64 = double(temp.f32);
	// rlwinm r10,r8,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// lfs f18,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f22,f10
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64));
	// lfs f17,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fmuls f17,f17,f10
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f14,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f22,f14,f13,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f22.f64));
	// mulli r11,r8,20
	ctx.r11.s64 = ctx.r8.s64 * 20;
	// fmsubs f14,f2,f5,f19
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f5.f64 - ctx.f19.f64));
	// lfs f19,-268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -268);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f21,f25,f0,f21
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 - ctx.f21.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fnmadds f20,f26,f9,f20
	ctx.f20.f64 = double(float(-(ctx.f26.f64 * ctx.f9.f64 + ctx.f20.f64)));
	// fmsubs f18,f24,f0,f18
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 - ctx.f18.f64));
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fmuls f15,f30,f8
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// fmuls f30,f30,f9
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fmuls f31,f31,f9
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f9.f64));
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fmadds f17,f19,f13,f17
	ctx.f17.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// fadds f21,f20,f14
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f14.f64));
	// fmadds f20,f29,f7,f4
	ctx.f20.f64 = double(float(ctx.f29.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fnmadds f16,f27,f9,f16
	ctx.f16.f64 = double(float(-(ctx.f27.f64 * ctx.f9.f64 + ctx.f16.f64)));
	// fmsubs f15,f1,f5,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 - ctx.f15.f64));
	// fmsubs f30,f1,f7,f30
	ctx.f30.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 - ctx.f30.f64));
	// fmuls f29,f29,f8
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f8.f64));
	// fadds f14,f18,f17
	ctx.f14.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f18,-264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -264);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f18,-248(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + -248, temp.u32);
	// lfs f17,-284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -284);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f2,f2,f7,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 - ctx.f31.f64));
	// fnmsubs f22,f17,f12,f22
	ctx.f22.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f22.f64)));
	// lfs f31,-272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -272);
	ctx.f31.f64 = double(temp.f32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,-280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -280);
	ctx.f20.f64 = double(temp.f32);
	// fmr f18,f20
	ctx.f18.f64 = ctx.f20.f64;
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// fmadds f15,f28,f7,f3
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f7.f64 + ctx.f3.f64));
	// fmuls f28,f28,f8
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fnmadds f29,f26,f6,f29
	ctx.f29.f64 = double(float(-(ctx.f26.f64 * ctx.f6.f64 + ctx.f29.f64)));
	// fmadds f3,f31,f5,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fnmsubs f20,f18,f12,f14
	ctx.f20.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f14.f64)));
	// fmuls f14,f19,f11
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fadds f19,f16,f15
	ctx.f19.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f16,-276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -276);
	ctx.f16.f64 = double(temp.f32);
	// fnmadds f28,f27,f6,f28
	ctx.f28.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 + ctx.f28.f64)));
	// fadds f2,f29,f2
	ctx.f2.f64 = double(float(ctx.f29.f64 + ctx.f2.f64));
	// fmsubs f24,f24,f10,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f14.f64));
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// lfs f28,-300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -300);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f28,f5,f4
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f5.f64 + ctx.f4.f64));
	// fadds f4,f30,f3
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// fadds f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// lfs f15,-248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -248);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f16,f16,f0,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f15.f64));
	// fadds f27,f16,f24
	ctx.f27.f64 = double(float(ctx.f16.f64 + ctx.f24.f64));
	// lfs f24,-304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -304);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// fnmsubs f1,f18,f13,f27
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f27.f64)));
	// fsubs f27,f21,f22
	ctx.f27.f64 = double(float(ctx.f21.f64 - ctx.f22.f64));
	// stfsx f27,r10,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f21,f22
	ctx.f27.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// stfsx f27,r9,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f27,f19,f20
	ctx.f27.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// stfsx f27,r9,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fsubs f27,f19,f20
	ctx.f27.f64 = double(float(ctx.f19.f64 - ctx.f20.f64));
	// stfsx f27,r10,r6
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// lfs f27,-260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -260);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f25,f25,f10,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f24.f64));
	// fmuls f27,f27,f12
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fmadds f27,f23,f0,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f27.f64));
	// fadds f31,f27,f25
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// fnmsubs f3,f17,f13,f31
	ctx.f3.f64 = double(float(-(ctx.f17.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// fadds f31,f4,f1
	ctx.f31.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// stfsx f31,r11,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f1.f64));
	// stfsx f4,r10,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// add r6,r23,r6
	ctx.r6.u64 = ctx.r23.u64 + ctx.r6.u64;
	// fsubs f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 - ctx.f3.f64));
	// stfsx f4,r10,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfsx f4,r11,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + -26212);
	// add r5,r23,r5
	ctx.r5.u64 = ctx.r23.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82caa1fc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CAA1FC;
loc_82CAA720:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82d5c58c
	ctx.lr = 0x82CAA728;
	__restfpr_14(ctx, base);
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAA730"))) PPC_WEAK_FUNC(sub_82CAA730);
PPC_FUNC_IMPL(__imp__sub_82CAA730) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26856
	ctx.r5.s64 = ctx.r11.s64 + -26856;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-24192
	ctx.r4.s64 = ctx.r11.s64 + -24192;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAA748"))) PPC_WEAK_FUNC(sub_82CAA748);
PPC_FUNC_IMPL(__imp__sub_82CAA748) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82CAA750;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82d5c544
	ctx.lr = 0x82CAA758;
	__savefpr_15(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82caaa1c
	if (!ctx.cr6.gt) goto loc_82CAAA1C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r24,r10,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32255
	ctx.r31.s64 = -2113863680;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f11,-12748(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -12748);
	ctx.f11.f64 = double(temp.f32);
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f12,28200(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28200);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,28204(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28204);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28208);
	ctx.f0.f64 = double(temp.f32);
loc_82CAA794:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f10,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r10,r7,28
	ctx.r10.s64 = ctx.r7.s64 * 28;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// mulli r9,r7,24
	ctx.r9.s64 = ctx.r7.s64 * 24;
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// fsubs f7,f6,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfsx f4,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r30,r7,5,0,26
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r29,r7,12
	ctx.r29.s64 = ctx.r7.s64 * 12;
	// lfsx f2,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f5,f4,f2
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// lfsx f31,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// lfsx f30,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fsubs f2,f1,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 - ctx.f31.f64));
	// rlwinm r28,r7,4,0,27
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f29,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r27,r7,36
	ctx.r27.s64 = ctx.r7.s64 * 36;
	// lfsx f28,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f20,f3,f30
	ctx.f20.f64 = double(float(ctx.f3.f64 - ctx.f30.f64));
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fsubs f31,f29,f28
	ctx.f31.f64 = double(float(ctx.f29.f64 - ctx.f28.f64));
	// fadds f3,f30,f3
	ctx.f3.f64 = double(float(ctx.f30.f64 + ctx.f3.f64));
	// lfsx f27,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f30,f28,f29
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f29.f64));
	// lfsx f26,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f29,f27,f26
	ctx.f29.f64 = double(float(ctx.f27.f64 - ctx.f26.f64));
	// mulli r26,r7,20
	ctx.r26.s64 = ctx.r7.s64 * 20;
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f28,f26,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// fsubs f27,f25,f24
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// fadds f26,f24,f25
	ctx.f26.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// lfsx f23,r26,r3
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r3.u32);
	ctx.f23.f64 = double(temp.f32);
	// lfsx f22,r26,r4
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + ctx.r4.u32);
	ctx.f22.f64 = double(temp.f32);
	// fsubs f25,f10,f23
	ctx.f25.f64 = double(float(ctx.f10.f64 - ctx.f23.f64));
	// fadds f10,f23,f10
	ctx.f10.f64 = double(float(ctx.f23.f64 + ctx.f10.f64));
	// mulli r25,r8,20
	ctx.r25.s64 = ctx.r8.s64 * 20;
	// fadds f23,f2,f21
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f21.f64));
	// fsubs f24,f9,f22
	ctx.f24.f64 = double(float(ctx.f9.f64 - ctx.f22.f64));
	// fadds f9,f22,f9
	ctx.f9.f64 = double(float(ctx.f22.f64 + ctx.f9.f64));
	// fsubs f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 - ctx.f2.f64));
	// fadds f22,f1,f8
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f8.f64));
	// fadds f21,f31,f7
	ctx.f21.f64 = double(float(ctx.f31.f64 + ctx.f7.f64));
	// fsubs f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f1.f64));
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// mulli r11,r8,36
	ctx.r11.s64 = ctx.r8.s64 * 36;
	// fadds f31,f30,f6
	ctx.f31.f64 = double(float(ctx.f30.f64 + ctx.f6.f64));
	// fadds f1,f29,f5
	ctx.f1.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// fadds f19,f27,f20
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f20.f64));
	// fsubs f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f30.f64));
	// fadds f30,f28,f4
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f4.f64));
	// fadds f18,f26,f3
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// fsubs f5,f29,f5
	ctx.f5.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// fsubs f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// fsubs f4,f28,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 - ctx.f4.f64));
	// fsubs f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// fadds f29,f1,f23
	ctx.f29.f64 = double(float(ctx.f1.f64 + ctx.f23.f64));
	// fadds f26,f19,f21
	ctx.f26.f64 = double(float(ctx.f19.f64 + ctx.f21.f64));
	// fsubs f1,f23,f1
	ctx.f1.f64 = double(float(ctx.f23.f64 - ctx.f1.f64));
	// fadds f28,f30,f22
	ctx.f28.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fadds f20,f18,f31
	ctx.f20.f64 = double(float(ctx.f18.f64 + ctx.f31.f64));
	// fmuls f17,f27,f13
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fadds f16,f29,f25
	ctx.f16.f64 = double(float(ctx.f29.f64 + ctx.f25.f64));
	// stfsx f16,r25,r5
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f15,f26,f24
	ctx.f15.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// stfsx f15,r25,r6
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// fadds f16,f28,f10
	ctx.f16.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// stfs f16,0(r5)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f16,f20,f9
	ctx.f16.f64 = double(float(ctx.f20.f64 + ctx.f9.f64));
	// stfs f16,0(r6)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fsubs f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f30.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fnmsubs f30,f29,f11,f25
	ctx.f30.f64 = double(float(-(ctx.f29.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f25,f7,f13
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fsubs f23,f21,f19
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f19.f64));
	// fnmsubs f26,f26,f11,f24
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f24.f64)));
	// fmuls f24,f5,f13
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fnmsubs f10,f28,f11,f10
	ctx.f10.f64 = double(float(-(ctx.f28.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// fmadds f7,f7,f0,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f17.f64));
	// mulli r31,r8,28
	ctx.r31.s64 = ctx.r8.s64 * 28;
	// fmuls f21,f3,f13
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f28,f22,f12
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f22,f6,f13
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmsubs f27,f27,f0,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fmuls f25,f8,f13
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmuls f29,f23,f12
	ctx.f29.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f23,f2,f13
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmadds f2,f2,f0,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f24.f64));
	// rlwinm r30,r8,3,0,28
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fmuls f24,f4,f13
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// mulli r29,r8,24
	ctx.r29.s64 = ctx.r8.s64 * 24;
	// fnmsubs f9,f20,f11,f9
	ctx.f9.f64 = double(float(-(ctx.f20.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// fmadds f6,f6,f0,f21
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fmsubs f3,f3,f0,f22
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f22.f64));
	// fmsubs f4,f4,f0,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fadds f25,f30,f1
	ctx.f25.f64 = double(float(ctx.f30.f64 + ctx.f1.f64));
	// fsubs f1,f30,f1
	ctx.f1.f64 = double(float(ctx.f30.f64 - ctx.f1.f64));
	// rlwinm r28,r8,5,0,26
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f30,f26,f29
	ctx.f30.f64 = double(float(ctx.f26.f64 + ctx.f29.f64));
	// rlwinm r27,r8,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f29,f26,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 - ctx.f29.f64));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fsubs f26,f10,f28
	ctx.f26.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fmsubs f5,f5,f0,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f23.f64));
	// fadds f10,f28,f10
	ctx.f10.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fsubs f28,f25,f7
	ctx.f28.f64 = double(float(ctx.f25.f64 - ctx.f7.f64));
	// stfsx f28,r11,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f28,f1,f27
	ctx.f28.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// stfsx f28,r10,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f25,f7
	ctx.f7.f64 = double(float(ctx.f25.f64 + ctx.f7.f64));
	// stfsx f7,r9,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f1,f27
	ctx.f7.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// stfsx f7,r31,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f30,f2
	ctx.f7.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// stfsx f7,r9,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f29,f5
	ctx.f7.f64 = double(float(ctx.f29.f64 + ctx.f5.f64));
	// stfsx f7,r31,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f7,f30,f2
	ctx.f7.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// stfsx f7,r11,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f29,f5
	ctx.f7.f64 = double(float(ctx.f29.f64 - ctx.f5.f64));
	// stfsx f7,r10,r6
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f7,f26,f3
	ctx.f7.f64 = double(float(ctx.f26.f64 - ctx.f3.f64));
	// stfsx f7,r30,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f10,f6
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// stfsx f7,r29,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f26,f3
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// stfsx f7,r28,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f7,f31,f18
	ctx.f7.f64 = double(float(ctx.f31.f64 - ctx.f18.f64));
	// fsubs f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f6.f64));
	// stfsx f10,r27,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fmadds f10,f8,f0,f24
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f24.f64));
	// add r5,r23,r5
	ctx.r5.u64 = ctx.r23.u64 + ctx.r5.u64;
	// fmuls f8,f7,f12
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fsubs f7,f9,f8
	ctx.f7.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// fadds f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
	// fadds f8,f7,f4
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f4.f64));
	// stfsx f8,r30,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f9,f10
	ctx.f8.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// stfsx f8,r29,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f7,f4
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f4.f64));
	// stfsx f8,r28,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// stfsx f10,r27,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,-26212(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + -26212);
	// add r6,r23,r6
	ctx.r6.u64 = ctx.r23.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82caa794
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CAA794;
loc_82CAAA1C:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82d5c590
	ctx.lr = 0x82CAAA24;
	__restfpr_15(ctx, base);
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAAA28"))) PPC_WEAK_FUNC(sub_82CAAA28);
PPC_FUNC_IMPL(__imp__sub_82CAAA28) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26792
	ctx.r5.s64 = ctx.r11.s64 + -26792;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-22712
	ctx.r4.s64 = ctx.r11.s64 + -22712;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAAA40"))) PPC_WEAK_FUNC(sub_82CAAA40);
PPC_FUNC_IMPL(__imp__sub_82CAAA40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82CAAA48;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82d5c540
	ctx.lr = 0x82CAAA50;
	__savefpr_14(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82caad2c
	if (!ctx.cr6.gt) goto loc_82CAAD2C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r26,r10,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r27,-32235
	ctx.r27.s64 = -2112552960;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r28,-32235
	ctx.r28.s64 = -2112552960;
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lfs f17,30712(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 30712);
	ctx.f17.f64 = double(temp.f32);
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f18,30716(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 30716);
	ctx.f18.f64 = double(temp.f32);
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f11,29632(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 29632);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,29636(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 29636);
	ctx.f12.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f19,29648(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 29648);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,29652(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 29652);
	ctx.f20.f64 = double(temp.f32);
	// lfs f13,-29000(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29000);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28136);
	ctx.f0.f64 = double(temp.f32);
loc_82CAAAAC:
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f10,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// mulli r10,r7,28
	ctx.r10.s64 = ctx.r7.s64 * 28;
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fadds f23,f7,f8
	ctx.f23.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// mulli r9,r7,20
	ctx.r9.s64 = ctx.r7.s64 * 20;
	// lfsx f6,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f7,f7,f8
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fadds f8,f5,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfsx f4,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// rlwinm r31,r7,5,0,26
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// mulli r28,r7,12
	ctx.r28.s64 = ctx.r7.s64 * 12;
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// lfsx f2,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f5,f2,f4
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fadds f22,f1,f3
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// lfsx f29,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// mulli r27,r7,24
	ctx.r27.s64 = ctx.r7.s64 * 24;
	// fsubs f1,f3,f1
	ctx.f1.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// lfsx f28,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// fsubs f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f4.f64));
	// lfsx f25,r27,r3
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r3.u32);
	ctx.f25.f64 = double(temp.f32);
	// lfsx f24,r27,r4
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + ctx.r4.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f4,f25,f29
	ctx.f4.f64 = double(float(ctx.f25.f64 + ctx.f29.f64));
	// rlwinm r30,r7,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f3,f24,f28
	ctx.f3.f64 = double(float(ctx.f24.f64 + ctx.f28.f64));
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f24.f64));
	// fsubs f29,f25,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 - ctx.f29.f64));
	// mulli r11,r8,12
	ctx.r11.s64 = ctx.r8.s64 * 12;
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfsx f27,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// lfsx f31,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f24,f8,f27
	ctx.f24.f64 = double(float(ctx.f8.f64 + ctx.f27.f64));
	// lfsx f30,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f25,f23,f31
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f31.f64));
	// fnmsubs f31,f23,f13,f31
	ctx.f31.f64 = double(float(-(ctx.f23.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// lfsx f26,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f8,f8,f13,f27
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f27.f64)));
	// mulli r10,r8,24
	ctx.r10.s64 = ctx.r8.s64 * 24;
	// fadds f27,f5,f30
	ctx.f27.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// fnmsubs f5,f5,f13,f30
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fadds f23,f22,f26
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// fnmsubs f30,f22,f13,f26
	ctx.f30.f64 = double(float(-(ctx.f22.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fadds f26,f4,f10
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f10.f64));
	// fnmsubs f10,f4,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fadds f22,f3,f9
	ctx.f22.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// fnmsubs f9,f3,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// rlwinm r9,r8,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f4,f31,f6
	ctx.f4.f64 = double(float(ctx.f31.f64 + ctx.f6.f64));
	// mulli r31,r8,28
	ctx.r31.s64 = ctx.r8.s64 * 28;
	// fadds f3,f8,f7
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// fsubs f6,f31,f6
	ctx.f6.f64 = double(float(ctx.f31.f64 - ctx.f6.f64));
	// fadds f21,f5,f1
	ctx.f21.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fsubs f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 - ctx.f1.f64));
	// fadds f1,f30,f2
	ctx.f1.f64 = double(float(ctx.f30.f64 + ctx.f2.f64));
	// fsubs f2,f30,f2
	ctx.f2.f64 = double(float(ctx.f30.f64 - ctx.f2.f64));
	// fsubs f31,f24,f23
	ctx.f31.f64 = double(float(ctx.f24.f64 - ctx.f23.f64));
	// fmuls f29,f29,f0
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64));
	// fmuls f28,f28,f0
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// fmuls f30,f4,f19
	ctx.f30.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f15,f4,f20
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// fmuls f16,f21,f11
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fmuls f14,f21,f12
	ctx.f14.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fadds f7,f27,f25
	ctx.f7.f64 = double(float(ctx.f27.f64 + ctx.f25.f64));
	// fmuls f31,f31,f0
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fadds f21,f9,f29
	ctx.f21.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// fmadds f4,f3,f20,f30
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f20.f64 + ctx.f30.f64));
	// fadds f30,f23,f24
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// fadds f24,f28,f10
	ctx.f24.f64 = double(float(ctx.f28.f64 + ctx.f10.f64));
	// fmadds f23,f1,f12,f16
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f16.f64));
	// fmsubs f3,f3,f19,f15
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f19.f64 - ctx.f15.f64));
	// fmuls f16,f6,f11
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmsubs f1,f1,f11,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 - ctx.f14.f64));
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fsubs f14,f27,f25
	ctx.f14.f64 = double(float(ctx.f27.f64 - ctx.f25.f64));
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// fmuls f15,f5,f17
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// fsubs f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f28.f64));
	// fadds f28,f23,f4
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f4.f64));
	// fsubs f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 - ctx.f4.f64));
	// fnmsubs f27,f7,f13,f26
	ctx.f27.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// fsubs f9,f9,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f29.f64));
	// fadds f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f26.f64));
	// stfs f7,0(r5)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fmadds f25,f8,f12,f16
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f16.f64));
	// fadds f4,f1,f3
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fsubs f16,f3,f1
	ctx.f16.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// fnmsubs f3,f30,f13,f22
	ctx.f3.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f22.f64)));
	// fmuls f29,f14,f0
	ctx.f29.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmsubs f7,f2,f18,f15
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f18.f64 - ctx.f15.f64));
	// fadds f26,f30,f22
	ctx.f26.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fadds f30,f27,f31
	ctx.f30.f64 = double(float(ctx.f27.f64 + ctx.f31.f64));
	// stfsx f30,r11,r5
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fmuls f1,f23,f0
	ctx.f1.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fmuls f5,f5,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// fsubs f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 - ctx.f31.f64));
	// stfsx f31,r10,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fmuls f31,f16,f0
	ctx.f31.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fadds f27,f28,f24
	ctx.f27.f64 = double(float(ctx.f28.f64 + ctx.f24.f64));
	// fadds f23,f3,f29
	ctx.f23.f64 = double(float(ctx.f3.f64 + ctx.f29.f64));
	// stfsx f23,r11,r6
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f29,f3,f29
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f29.f64));
	// stfs f26,0(r6)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fsubs f30,f7,f25
	ctx.f30.f64 = double(float(ctx.f7.f64 - ctx.f25.f64));
	// stfsx f29,r10,r6
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f3,f28,f13,f24
	ctx.f3.f64 = double(float(-(ctx.f28.f64 * ctx.f13.f64 - ctx.f24.f64)));
	// stfsx f27,r9,r5
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f25.f64));
	// rlwinm r11,r8,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f25,f4,f21
	ctx.f25.f64 = double(float(ctx.f4.f64 + ctx.f21.f64));
	// stfsx f25,r9,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// fnmsubs f4,f4,f13,f21
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f21.f64)));
	// mulli r10,r8,20
	ctx.r10.s64 = ctx.r8.s64 * 20;
	// fmsubs f8,f8,f11,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 - ctx.f6.f64));
	// fmadds f6,f2,f17,f5
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f17.f64 + ctx.f5.f64));
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fsubs f29,f3,f31
	ctx.f29.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// stfsx f29,r31,r5
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f31.f64));
	// stfsx f3,r30,r5
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// rlwinm r9,r8,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// stfsx f3,r30,r6
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fsubs f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f1.f64));
	// stfsx f4,r31,r6
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fadds f4,f7,f10
	ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfsx f4,r11,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fnmsubs f10,f7,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fsubs f7,f8,f6
	ctx.f7.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fadds f6,f7,f9
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// stfsx f6,r11,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fnmsubs f9,f7,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f7.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fsubs f7,f10,f8
	ctx.f7.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// fadds f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// fadds f8,f9,f30
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f30.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f30.f64));
	// stfsx f9,r9,r6
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// stfsx f7,r9,r5
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// stfsx f10,r10,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + -26212);
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82caaaac
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CAAAAC;
loc_82CAAD2C:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82d5c58c
	ctx.lr = 0x82CAAD34;
	__restfpr_14(ctx, base);
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAAD38"))) PPC_WEAK_FUNC(sub_82CAAD38);
PPC_FUNC_IMPL(__imp__sub_82CAAD38) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26728
	ctx.r5.s64 = ctx.r11.s64 + -26728;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-21952
	ctx.r4.s64 = ctx.r11.s64 + -21952;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAAD50"))) PPC_WEAK_FUNC(sub_82CAAD50);
PPC_FUNC_IMPL(__imp__sub_82CAAD50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a8
	ctx.lr = 0x82CAAD58;
	__savegprlr_20(ctx, base);
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82d5c568
	ctx.lr = 0x82CAAD60;
	__savefpr_24(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82caaf3c
	if (!ctx.cr6.gt) goto loc_82CAAF3C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r22,r10,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r20,-32234
	ctx.r20.s64 = -2112487424;
	// rlwinm r21,r11,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32236
	ctx.r11.s64 = -2112618496;
	// lfs f0,-29652(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29652);
	ctx.f0.f64 = double(temp.f32);
loc_82CAAD84:
	// mulli r11,r7,28
	ctx.r11.s64 = ctx.r7.s64 * 28;
	// lfs f13,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 * 12;
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f28,f11,f9
	ctx.f28.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f27,f10,f8
	ctx.f27.f64 = double(float(ctx.f10.f64 - ctx.f8.f64));
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fadds f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 + ctx.f10.f64));
	// lfsx f7,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f6,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fadds f8,f6,f7
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// rlwinm r30,r7,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f4,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f9,f7,f6
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f6.f64));
	// rlwinm r29,r7,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f7,f5,f4
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// mulli r28,r7,24
	ctx.r28.s64 = ctx.r7.s64 * 24;
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// lfsx f3,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f3.f64 = double(temp.f32);
	// lfsx f31,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f31.f64 = double(temp.f32);
	// fadds f5,f3,f13
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f13.f64));
	// fsubs f13,f13,f3
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f3.f64));
	// lfsx f1,r28,r3
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f29,r28,r4
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r4.u32);
	ctx.f29.f64 = double(temp.f32);
	// fadds f3,f31,f12
	ctx.f3.f64 = double(float(ctx.f31.f64 + ctx.f12.f64));
	// lfsx f2,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f31.f64));
	// lfsx f30,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f30.f64 = double(temp.f32);
	// fadds f4,f1,f2
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fadds f31,f29,f30
	ctx.f31.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// rlwinm r27,r8,4,0,27
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f30,f30,f29
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f29.f64));
	// rlwinm r26,r8,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// mulli r25,r8,24
	ctx.r25.s64 = ctx.r8.s64 * 24;
	// fsubs f1,f28,f27
	ctx.f1.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f29,f27,f28
	ctx.f29.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// fadds f27,f7,f9
	ctx.f27.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f28,f8,f11
	ctx.f28.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fadds f26,f6,f10
	ctx.f26.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// fadds f8,f4,f5
	ctx.f8.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// mulli r24,r8,20
	ctx.r24.s64 = ctx.r8.s64 * 20;
	// fsubs f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fsubs f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// fsubs f7,f5,f4
	ctx.f7.f64 = double(float(ctx.f5.f64 - ctx.f4.f64));
	// fsubs f5,f3,f31
	ctx.f5.f64 = double(float(ctx.f3.f64 - ctx.f31.f64));
	// fadds f6,f31,f3
	ctx.f6.f64 = double(float(ctx.f31.f64 + ctx.f3.f64));
	// fadds f31,f27,f1
	ctx.f31.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// fadds f4,f30,f13
	ctx.f4.f64 = double(float(ctx.f30.f64 + ctx.f13.f64));
	// rlwinm r23,r8,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f3,f12,f2
	ctx.f3.f64 = double(float(ctx.f12.f64 - ctx.f2.f64));
	// fsubs f24,f8,f28
	ctx.f24.f64 = double(float(ctx.f8.f64 - ctx.f28.f64));
	// stfsx f24,r27,r5
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f28,f8
	ctx.f8.f64 = double(float(ctx.f28.f64 + ctx.f8.f64));
	// stfs f8,0(r5)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f25,f9,f29
	ctx.f25.f64 = double(float(ctx.f9.f64 + ctx.f29.f64));
	// fsubs f28,f7,f10
	ctx.f28.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fmuls f8,f31,f0
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fsubs f31,f6,f26
	ctx.f31.f64 = double(float(ctx.f6.f64 - ctx.f26.f64));
	// stfsx f31,r27,r6
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// stfs f6,0(r6)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fadds f6,f5,f11
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f11.f64));
	// stfsx f6,r26,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fsubs f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 - ctx.f11.f64));
	// stfsx f11,r25,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// stfsx f28,r25,r5
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f10,f7
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f7.f64));
	// stfsx f11,r26,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fsubs f11,f4,f8
	ctx.f11.f64 = double(float(ctx.f4.f64 - ctx.f8.f64));
	// stfsx f11,r24,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r5.u32, temp.u32);
	// fadds f11,f8,f4
	ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// stfsx f11,r23,r5
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r5.u32, temp.u32);
	// fsubs f10,f1,f27
	ctx.f10.f64 = double(float(ctx.f1.f64 - ctx.f27.f64));
	// mulli r11,r8,28
	ctx.r11.s64 = ctx.r8.s64 * 28;
	// fsubs f9,f9,f29
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f29.f64));
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// fmuls f11,f25,f0
	ctx.f11.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fadds f12,f2,f12
	ctx.f12.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// fsubs f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f30.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fsubs f8,f3,f11
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f11.f64));
	// stfsx f8,r24,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + ctx.r6.u32, temp.u32);
	// fadds f11,f11,f3
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f3.f64));
	// stfsx f11,r23,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r23.u32 + ctx.r6.u32, temp.u32);
	// add r3,r22,r3
	ctx.r3.u64 = ctx.r22.u64 + ctx.r3.u64;
	// add r4,r22,r4
	ctx.r4.u64 = ctx.r22.u64 + ctx.r4.u64;
	// fsubs f11,f12,f10
	ctx.f11.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// stfsx f11,r11,r6
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfsx f12,r10,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f12,f13,f9
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// stfsx f12,r11,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfsx f13,r10,r5
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + -26212);
	// add r5,r21,r5
	ctx.r5.u64 = ctx.r21.u64 + ctx.r5.u64;
	// add r6,r21,r6
	ctx.r6.u64 = ctx.r21.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82caad84
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CAAD84;
loc_82CAAF3C:
	// addi r12,r1,-104
	ctx.r12.s64 = ctx.r1.s64 + -104;
	// bl 0x82d5c5b4
	ctx.lr = 0x82CAAF44;
	__restfpr_24(ctx, base);
	// b 0x82d5c4f8
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAAF48"))) PPC_WEAK_FUNC(sub_82CAAF48);
PPC_FUNC_IMPL(__imp__sub_82CAAF48) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26664
	ctx.r5.s64 = ctx.r11.s64 + -26664;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-21168
	ctx.r4.s64 = ctx.r11.s64 + -21168;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAAF60"))) PPC_WEAK_FUNC(sub_82CAAF60);
PPC_FUNC_IMPL(__imp__sub_82CAAF60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82CAAF68;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82d5c550
	ctx.lr = 0x82CAAF70;
	__savefpr_18(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82cab19c
	if (!ctx.cr6.gt) goto loc_82CAB19C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r26,r10,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r29,-32235
	ctx.r29.s64 = -2112552960;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32235
	ctx.r30.s64 = -2112552960;
	// lis r31,-32235
	ctx.r31.s64 = -2112552960;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lfs f9,30852(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 30852);
	ctx.f9.f64 = double(temp.f32);
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f10,30848(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 30848);
	ctx.f10.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f11,30844(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 30844);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,30832(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 30832);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,30840(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 30840);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,30836(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 30836);
	ctx.f0.f64 = double(temp.f32);
loc_82CAAFBC:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f8,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// mulli r10,r7,24
	ctx.r10.s64 = ctx.r7.s64 * 24;
	// lfs f7,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfsx f5,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f4,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f4.f64 = double(temp.f32);
	// lfsx f3,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f6,f4,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f2,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f2.f64 = double(temp.f32);
	// mulli r31,r7,20
	ctx.r31.s64 = ctx.r7.s64 * 20;
	// fsubs f31,f4,f5
	ctx.f31.f64 = double(float(ctx.f4.f64 - ctx.f5.f64));
	// fadds f5,f2,f3
	ctx.f5.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// fsubs f30,f3,f2
	ctx.f30.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfsx f28,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f28.f64 = double(temp.f32);
	// lfsx f27,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f27.f64 = double(temp.f32);
	// fadds f3,f27,f28
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// lfsx f1,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// lfsx f29,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f29.f64 = double(temp.f32);
	// fsubs f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 - ctx.f27.f64));
	// fadds f4,f29,f1
	ctx.f4.f64 = double(float(ctx.f29.f64 + ctx.f1.f64));
	// fsubs f29,f29,f1
	ctx.f29.f64 = double(float(ctx.f29.f64 - ctx.f1.f64));
	// lfsx f26,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f26.f64 = double(temp.f32);
	// lfsx f25,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f25.f64 = double(temp.f32);
	// rlwinm r29,r7,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// mulli r28,r8,20
	ctx.r28.s64 = ctx.r8.s64 * 20;
	// lfsx f24,r29,r3
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r3.u32);
	ctx.f24.f64 = double(temp.f32);
	// fadds f2,f24,f26
	ctx.f2.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfsx f23,r29,r4
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r4.u32);
	ctx.f23.f64 = double(temp.f32);
	// fsubs f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 - ctx.f26.f64));
	// fmuls f24,f3,f10
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f27,f25,f23
	ctx.f27.f64 = double(float(ctx.f25.f64 - ctx.f23.f64));
	// mulli r11,r8,24
	ctx.r11.s64 = ctx.r8.s64 * 24;
	// fadds f1,f23,f25
	ctx.f1.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// fmuls f25,f4,f10
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fadds f21,f2,f4
	ctx.f21.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
	// fmuls f22,f26,f13
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fnmadds f23,f5,f11,f24
	ctx.f23.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 + ctx.f24.f64)));
	// rlwinm r9,r8,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f24,f27,f13
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// mulli r31,r8,12
	ctx.r31.s64 = ctx.r8.s64 * 12;
	// fadds f20,f1,f3
	ctx.f20.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fnmadds f25,f6,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 + ctx.f25.f64)));
	// fmadds f19,f2,f9,f8
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fmadds f18,f1,f9,f7
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fadds f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// fmsubs f22,f31,f0,f22
	ctx.f22.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 - ctx.f22.f64));
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// fmsubs f24,f30,f0,f24
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f24.f64));
	// fadds f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f5.f64));
	// fadds f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// fmuls f19,f26,f0
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f18,f5,f10
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// fadds f21,f21,f8
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f8.f64));
	// stfs f21,0(r5)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fnmsubs f22,f29,f12,f22
	ctx.f22.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f22.f64)));
	// fnmsubs f24,f28,f12,f24
	ctx.f24.f64 = double(float(-(ctx.f28.f64 * ctx.f12.f64 - ctx.f24.f64)));
	// fadds f21,f20,f7
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f7.f64));
	// stfs f21,0(r6)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmuls f20,f6,f10
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmadds f6,f6,f9,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fsubs f21,f25,f24
	ctx.f21.f64 = double(float(ctx.f25.f64 - ctx.f24.f64));
	// stfsx f21,r28,r5
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfsx f25,r27,r5
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f25,f23,f22
	ctx.f25.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// stfsx f25,r27,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f25,f23,f22
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f22.f64));
	// stfsx f25,r28,r6
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fmuls f25,f30,f13
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// fmuls f24,f2,f10
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f23,f31,f13
	ctx.f23.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// fmuls f22,f1,f10
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f21,f27,f0
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmadds f25,f28,f0,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 + ctx.f25.f64));
	// fnmadds f24,f4,f11,f24
	ctx.f24.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 + ctx.f24.f64)));
	// fnmadds f22,f3,f11,f22
	ctx.f22.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 + ctx.f22.f64)));
	// fmadds f5,f5,f9,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fmadds f23,f29,f0,f23
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f23.f64));
	// fmadds f30,f30,f12,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f21.f64));
	// fmadds f21,f4,f9,f8
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 + ctx.f8.f64));
	// fnmadds f2,f2,f11,f20
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 + ctx.f20.f64)));
	// fmadds f20,f3,f9,f7
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f7.f64));
	// fmadds f31,f31,f12,f19
	ctx.f31.f64 = double(float(ctx.f31.f64 * ctx.f12.f64 + ctx.f19.f64));
	// fadds f7,f24,f6
	ctx.f7.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// fmadds f8,f27,f12,f25
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f12.f64 + ctx.f25.f64));
	// fnmadds f1,f1,f11,f18
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 + ctx.f18.f64)));
	// fadds f5,f22,f5
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f5.f64));
	// fmadds f6,f26,f12,f23
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f23.f64));
	// fnmsubs f4,f28,f13,f30
	ctx.f4.f64 = double(float(-(ctx.f28.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// fadds f3,f2,f21
	ctx.f3.f64 = double(float(ctx.f2.f64 + ctx.f21.f64));
	// fnmsubs f2,f29,f13,f31
	ctx.f2.f64 = double(float(-(ctx.f29.f64 * ctx.f13.f64 - ctx.f31.f64)));
	// fsubs f31,f7,f8
	ctx.f31.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// stfsx f31,r11,r5
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r5.u32, temp.u32);
	// fadds f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f20.f64));
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// stfsx f8,r10,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f5,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfsx f8,r10,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f5,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f6.f64));
	// stfsx f8,r11,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f3,f4
	ctx.f8.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// stfsx f8,r9,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f8,f3,f4
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// fadds f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// stfsx f8,r31,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f8,f1,f2
	ctx.f8.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// stfsx f8,r9,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,-26212(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + -26212);
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82caafbc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CAAFBC;
loc_82CAB19C:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82d5c59c
	ctx.lr = 0x82CAB1A4;
	__restfpr_18(ctx, base);
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB1A8"))) PPC_WEAK_FUNC(sub_82CAB1A8);
PPC_FUNC_IMPL(__imp__sub_82CAB1A8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26600
	ctx.r5.s64 = ctx.r11.s64 + -26600;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-20640
	ctx.r4.s64 = ctx.r11.s64 + -20640;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB1C0"))) PPC_WEAK_FUNC(sub_82CAB1C0);
PPC_FUNC_IMPL(__imp__sub_82CAB1C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82CAB1C8;
	__savegprlr_22(ctx, base);
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82d5c578
	ctx.lr = 0x82CAB1D0;
	__savefpr_28(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82cab344
	if (!ctx.cr6.gt) goto loc_82CAB344;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r24,r10,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lis r22,-32234
	ctx.r22.s64 = -2112487424;
	// lfs f13,28136(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-29000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -29000);
	ctx.f0.f64 = double(temp.f32);
loc_82CAB1FC:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f12,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mulli r10,r7,20
	ctx.r10.s64 = ctx.r7.s64 * 20;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f31,f10,f9
	ctx.f31.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// rlwinm r9,r7,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f7,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// rlwinm r31,r7,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// fadds f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fsubs f9,f8,f7
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// mulli r30,r7,12
	ctx.r30.s64 = ctx.r7.s64 * 12;
	// fadds f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f6,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f5.f64 = double(temp.f32);
	// lfsx f3,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f7,f6,f5
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfsx f4,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// fsubs f5,f4,f3
	ctx.f5.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// lfsx f2,r30,r3
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r3.u32);
	ctx.f2.f64 = double(temp.f32);
	// lfsx f1,r30,r4
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r4.u32);
	ctx.f1.f64 = double(temp.f32);
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// fsubs f3,f12,f2
	ctx.f3.f64 = double(float(ctx.f12.f64 - ctx.f2.f64));
	// mulli r29,r8,12
	ctx.r29.s64 = ctx.r8.s64 * 12;
	// fadds f12,f2,f12
	ctx.f12.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// fsubs f30,f11,f1
	ctx.f30.f64 = double(float(ctx.f11.f64 - ctx.f1.f64));
	// fadds f11,f1,f11
	ctx.f11.f64 = double(float(ctx.f1.f64 + ctx.f11.f64));
	// fadds f2,f7,f31
	ctx.f2.f64 = double(float(ctx.f7.f64 + ctx.f31.f64));
	// fadds f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f10.f64));
	// mulli r28,r8,20
	ctx.r28.s64 = ctx.r8.s64 * 20;
	// fadds f29,f5,f9
	ctx.f29.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fsubs f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f5.f64));
	// fsubs f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f31.f64));
	// fsubs f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// fadds f28,f4,f8
	ctx.f28.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fsubs f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f4.f64));
	// rlwinm r27,r8,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r26,r8,3,0,28
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r25,r8,4,0,27
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fnmsubs f5,f29,f0,f30
	ctx.f5.f64 = double(float(-(ctx.f29.f64 * ctx.f0.f64 - ctx.f30.f64)));
	// add r3,r24,r3
	ctx.r3.u64 = ctx.r24.u64 + ctx.r3.u64;
	// fmuls f10,f9,f13
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// add r4,r24,r4
	ctx.r4.u64 = ctx.r24.u64 + ctx.r4.u64;
	// fmuls f9,f7,f13
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f7,f6,f13
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fadds f6,f2,f3
	ctx.f6.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// stfsx f6,r29,r5
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f6,f29,f30
	ctx.f6.f64 = double(float(ctx.f29.f64 + ctx.f30.f64));
	// stfsx f6,r29,r6
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f6,f1,f12
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f12.f64));
	// stfs f6,0(r5)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f6,f28,f11
	ctx.f6.f64 = double(float(ctx.f28.f64 + ctx.f11.f64));
	// stfs f6,0(r6)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fnmsubs f6,f2,f0,f3
	ctx.f6.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// fnmsubs f12,f1,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fnmsubs f11,f28,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f28.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// fsubs f4,f6,f10
	ctx.f4.f64 = double(float(ctx.f6.f64 - ctx.f10.f64));
	// stfsx f4,r28,r5
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f6.f64));
	// stfsx f10,r27,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fadds f10,f5,f9
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// stfsx f10,r27,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f5,f9
	ctx.f10.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// stfsx f10,r28,r6
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f10,f12,f8
	ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// stfsx f10,r26,r5
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// stfsx f12,r25,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f11,f7
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// stfsx f12,r26,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f7,f11
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f11.f64));
	// stfsx f12,r25,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r25.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,-26212(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + -26212);
	// add r5,r23,r5
	ctx.r5.u64 = ctx.r23.u64 + ctx.r5.u64;
	// add r6,r23,r6
	ctx.r6.u64 = ctx.r23.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82cab1fc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CAB1FC;
loc_82CAB344:
	// addi r12,r1,-88
	ctx.r12.s64 = ctx.r1.s64 + -88;
	// bl 0x82d5c5c4
	ctx.lr = 0x82CAB34C;
	__restfpr_28(ctx, base);
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB350"))) PPC_WEAK_FUNC(sub_82CAB350);
PPC_FUNC_IMPL(__imp__sub_82CAB350) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26536
	ctx.r5.s64 = ctx.r11.s64 + -26536;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-20032
	ctx.r4.s64 = ctx.r11.s64 + -20032;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB368"))) PPC_WEAK_FUNC(sub_82CAB368);
PPC_FUNC_IMPL(__imp__sub_82CAB368) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82CAB370;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82d5c574
	ctx.lr = 0x82CAB378;
	__savefpr_27(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82cab4dc
	if (!ctx.cr6.gt) goto loc_82CAB4DC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r26,r10,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r31,-32255
	ctx.r31.s64 = -2113863680;
	// rlwinm r25,r11,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r9,-32235
	ctx.r9.s64 = -2112552960;
	// lis r10,-32235
	ctx.r10.s64 = -2112552960;
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lfs f31,-12748(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -12748);
	ctx.f31.f64 = double(temp.f32);
	// lis r24,-32234
	ctx.r24.s64 = -2112487424;
	// lfs f13,28204(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28204);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,28208(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28208);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,28200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28200);
	ctx.f1.f64 = double(temp.f32);
loc_82CAB3B4:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f12,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r10,r7,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 * 12;
	// lfsx f10,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// lfsx f9,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f9.f64 = double(temp.f32);
	// lfsx f8,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f2,f9,f10
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfsx f7,r31,r3
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r3.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f9,f7,f8
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// lfsx f6,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f6.f64 = double(temp.f32);
	// lfsx f5,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// lfsx f3,r31,r4
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r4.u32);
	ctx.f3.f64 = double(temp.f32);
	// fadds f7,f5,f6
	ctx.f7.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfsx f4,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// fadds f5,f3,f4
	ctx.f5.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// rlwinm r30,r8,4,0,27
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// mulli r29,r8,12
	ctx.r29.s64 = ctx.r8.s64 * 12;
	// fmuls f27,f10,f13
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fadds f3,f9,f2
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f2.f64));
	// fsubs f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 - ctx.f9.f64));
	// fmuls f30,f8,f13
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// rlwinm r28,r8,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fmuls f28,f6,f13
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// rlwinm r27,r8,3,0,28
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fadds f9,f5,f7
	ctx.f9.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// add r3,r26,r3
	ctx.r3.u64 = ctx.r26.u64 + ctx.r3.u64;
	// fsubs f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// add r4,r26,r4
	ctx.r4.u64 = ctx.r26.u64 + ctx.r4.u64;
	// fmuls f29,f4,f13
	ctx.f29.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmsubs f8,f8,f0,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f27.f64));
	// fmuls f7,f2,f1
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// fadds f2,f3,f12
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f12.f64));
	// stfs f2,0(r5)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fnmsubs f12,f3,f31,f12
	ctx.f12.f64 = double(float(-(ctx.f3.f64 * ctx.f31.f64 - ctx.f12.f64)));
	// fadds f2,f9,f11
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// stfs f2,0(r6)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmuls f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fnmsubs f11,f9,f31,f11
	ctx.f11.f64 = double(float(-(ctx.f9.f64 * ctx.f31.f64 - ctx.f11.f64)));
	// fmadds f6,f6,f0,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f29.f64));
	// fmsubs f4,f4,f0,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 - ctx.f28.f64));
	// fmadds f10,f10,f0,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f30.f64));
	// fadds f9,f12,f7
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f7.f64));
	// fsubs f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f7.f64));
	// fadds f7,f11,f5
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// fsubs f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f5.f64));
	// fsubs f5,f9,f6
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f6.f64));
	// stfsx f5,r30,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f5,f12,f4
	ctx.f5.f64 = double(float(ctx.f12.f64 + ctx.f4.f64));
	// stfsx f5,r29,r5
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// fadds f9,f9,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f6.f64));
	// stfsx f9,r28,r5
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f12,f4
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f4.f64));
	// stfsx f12,r27,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r5.u32, temp.u32);
	// fsubs f12,f7,f10
	ctx.f12.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// stfsx f12,r28,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + ctx.r6.u32, temp.u32);
	// fsubs f12,f11,f8
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// stfsx f12,r29,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f7,f10
	ctx.f12.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// stfsx f12,r30,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f11,f8
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f8.f64));
	// stfsx f12,r27,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,-26212(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + -26212);
	// add r5,r25,r5
	ctx.r5.u64 = ctx.r25.u64 + ctx.r5.u64;
	// add r6,r25,r6
	ctx.r6.u64 = ctx.r25.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82cab3b4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CAB3B4;
loc_82CAB4DC:
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82d5c5c0
	ctx.lr = 0x82CAB4E4;
	__restfpr_27(ctx, base);
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB4E8"))) PPC_WEAK_FUNC(sub_82CAB4E8);
PPC_FUNC_IMPL(__imp__sub_82CAB4E8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26472
	ctx.r5.s64 = ctx.r11.s64 + -26472;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-19608
	ctx.r4.s64 = ctx.r11.s64 + -19608;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB500"))) PPC_WEAK_FUNC(sub_82CAB500);
PPC_FUNC_IMPL(__imp__sub_82CAB500) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82CAB508;
	__savegprlr_26(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82cab5dc
	if (!ctx.cr6.gt) goto loc_82CAB5DC;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r28,r10,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r26,-32234
	ctx.r26.s64 = -2112487424;
	// rlwinm r27,r11,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82CAB524:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mulli r9,r7,12
	ctx.r9.s64 = ctx.r7.s64 * 12;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f9,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fadds f6,f12,f0
	ctx.f6.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// lfsx f10,r9,r3
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// lfsx f11,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// fadds f5,f9,f13
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// lfsx f8,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// fadds f12,f10,f11
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// lfsx f7,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// fadds f9,f7,f8
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f8.f64));
	// rlwinm r31,r8,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// rlwinm r30,r8,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f10,f8,f7
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f7.f64));
	// mulli r29,r8,12
	ctx.r29.s64 = ctx.r8.s64 * 12;
	// fsubs f8,f6,f12
	ctx.f8.f64 = double(float(ctx.f6.f64 - ctx.f12.f64));
	// stfsx f8,r31,r5
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f12,f12,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// add r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 + ctx.r3.u64;
	// fsubs f8,f5,f9
	ctx.f8.f64 = double(float(ctx.f5.f64 - ctx.f9.f64));
	// stfsx f8,r31,r6
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// stfs f12,0(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fadds f12,f9,f5
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fsubs f12,f13,f11
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfsx f12,r30,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r6.u32, temp.u32);
	// fadds f12,f10,f0
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f0.f64));
	// stfsx f12,r30,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + ctx.r5.u32, temp.u32);
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfsx f13,r29,r6
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r6.u32, temp.u32);
	// fsubs f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f10.f64));
	// stfsx f0,r29,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + ctx.r5.u32, temp.u32);
	// lwz r11,-26212(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + -26212);
	// add r4,r28,r4
	ctx.r4.u64 = ctx.r28.u64 + ctx.r4.u64;
	// add r6,r27,r6
	ctx.r6.u64 = ctx.r27.u64 + ctx.r6.u64;
	// add r5,r27,r5
	ctx.r5.u64 = ctx.r27.u64 + ctx.r5.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82cab524
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CAB524;
loc_82CAB5DC:
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB5E0"))) PPC_WEAK_FUNC(sub_82CAB5E0);
PPC_FUNC_IMPL(__imp__sub_82CAB5E0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26408
	ctx.r5.s64 = ctx.r11.s64 + -26408;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-19200
	ctx.r4.s64 = ctx.r11.s64 + -19200;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB5F8"))) PPC_WEAK_FUNC(sub_82CAB5F8);
PPC_FUNC_IMPL(__imp__sub_82CAB5F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CAB600;
	__savegprlr_28(ctx, base);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82cab6c4
	if (!ctx.cr6.gt) goto loc_82CAB6C4;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r30,r10,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32235
	ctx.r11.s64 = -2112552960;
	// lis r28,-32234
	ctx.r28.s64 = -2112487424;
	// lfs f6,-29000(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -29000);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,28136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28136);
	ctx.f7.f64 = double(temp.f32);
loc_82CAB62C:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r9,r8,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r31,r8,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f12,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfsx f11,r10,r3
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	ctx.f11.f64 = double(temp.f32);
	// add r3,r30,r3
	ctx.r3.u64 = ctx.r30.u64 + ctx.r3.u64;
	// lfsx f10,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// fadds f8,f11,f12
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfsx f9,r10,r4
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fadds f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// add r4,r30,r4
	ctx.r4.u64 = ctx.r30.u64 + ctx.r4.u64;
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// fadds f9,f8,f0
	ctx.f9.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// stfs f9,0(r5)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// fnmsubs f0,f8,f6,f0
	ctx.f0.f64 = double(float(-(ctx.f8.f64 * ctx.f6.f64 - ctx.f0.f64)));
	// fadds f9,f12,f13
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f9,0(r6)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// fmuls f10,f10,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// fnmsubs f13,f12,f6,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f6.f64 - ctx.f13.f64)));
	// fmuls f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fsubs f12,f0,f10
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f10.f64));
	// stfsx f12,r9,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f0,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f10.f64));
	// stfsx f0,r31,r5
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f13,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// stfsx f0,r31,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r6.u32, temp.u32);
	// fsubs f0,f13,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfsx f0,r9,r6
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r6.u32, temp.u32);
	// lwz r11,-26212(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + -26212);
	// add r5,r29,r5
	ctx.r5.u64 = ctx.r29.u64 + ctx.r5.u64;
	// add r6,r29,r6
	ctx.r6.u64 = ctx.r29.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82cab62c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CAB62C;
loc_82CAB6C4:
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB6C8"))) PPC_WEAK_FUNC(sub_82CAB6C8);
PPC_FUNC_IMPL(__imp__sub_82CAB6C8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26344
	ctx.r5.s64 = ctx.r11.s64 + -26344;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-18952
	ctx.r4.s64 = ctx.r11.s64 + -18952;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB6E0"))) PPC_WEAK_FUNC(sub_82CAB6E0);
PPC_FUNC_IMPL(__imp__sub_82CAB6E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82cab75c
	if (!ctx.cr6.gt) goto loc_82CAB75C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r30,-32234
	ctx.r30.s64 = -2112487424;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82CAB704:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f12,r10,r5
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r5.u32, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r5)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// lfsx f13,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f13.f64 = double(temp.f32);
	// add r5,r31,r5
	ctx.r5.u64 = ctx.r31.u64 + ctx.r5.u64;
	// lfs f0,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// add r4,r9,r4
	ctx.r4.u64 = ctx.r9.u64 + ctx.r4.u64;
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// stfsx f12,r10,r6
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lwz r11,-26212(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -26212);
	// add r6,r31,r6
	ctx.r6.u64 = ctx.r31.u64 + ctx.r6.u64;
	// xor r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 ^ ctx.r7.u64;
	// xor r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 ^ ctx.r8.u64;
	// bdnz 0x82cab704
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82CAB704;
loc_82CAB75C:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAB768"))) PPC_WEAK_FUNC(sub_82CAB768);
PPC_FUNC_IMPL(__imp__sub_82CAB768) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r5,r11,-26280
	ctx.r5.s64 = ctx.r11.s64 + -26280;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r4,r11,-18720
	ctx.r4.s64 = ctx.r11.s64 + -18720;
	// b 0x82cab908
	sub_82CAB908(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB780"))) PPC_WEAK_FUNC(sub_82CAB780);
PPC_FUNC_IMPL(__imp__sub_82CAB780) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// bl 0x82cabb80
	ctx.lr = 0x82CAB7A0;
	sub_82CABB80(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c42018
	ctx.lr = 0x82CAB7AC;
	sub_82C42018(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAB7C0"))) PPC_WEAK_FUNC(sub_82CAB7C0);
PPC_FUNC_IMPL(__imp__sub_82CAB7C0) {
	PPC_FUNC_PROLOGUE();
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAB7C8"))) PPC_WEAK_FUNC(sub_82CAB7C8);
PPC_FUNC_IMPL(__imp__sub_82CAB7C8) {
	PPC_FUNC_PROLOGUE();
	// b 0x82cac948
	sub_82CAC948(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB7D0"))) PPC_WEAK_FUNC(sub_82CAB7D0);
PPC_FUNC_IMPL(__imp__sub_82CAB7D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CAB7D8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82cad660
	ctx.lr = 0x82CAB7F4;
	sub_82CAD660(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c42018
	ctx.lr = 0x82CAB800;
	sub_82C42018(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82cad6b8
	ctx.lr = 0x82CAB80C;
	sub_82CAD6B8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c42018
	ctx.lr = 0x82CAB818;
	sub_82C42018(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82cacd40
	ctx.lr = 0x82CAB824;
	sub_82CACD40(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c42018
	ctx.lr = 0x82CAB830;
	sub_82C42018(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB838"))) PPC_WEAK_FUNC(sub_82CAB838);
PPC_FUNC_IMPL(__imp__sub_82CAB838) {
	PPC_FUNC_PROLOGUE();
	// b 0x82cadfc0
	sub_82CADFC0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB840"))) PPC_WEAK_FUNC(sub_82CAB840);
PPC_FUNC_IMPL(__imp__sub_82CAB840) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,48(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cab854
	if (ctx.cr0.eq) goto loc_82CAB854;
	// cmpw cr6,r11,r6
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r6.s32, ctx.xer);
	// bne cr6,0x82cab880
	if (!ctx.cr6.eq) goto loc_82CAB880;
loc_82CAB854:
	// lwz r11,52(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cab868
	if (ctx.cr0.eq) goto loc_82CAB868;
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// bne cr6,0x82cab880
	if (!ctx.cr6.eq) goto loc_82CAB880;
loc_82CAB868:
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cab888
	if (ctx.cr0.eq) goto loc_82CAB888;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// beq cr6,0x82cab888
	if (ctx.cr6.eq) goto loc_82CAB888;
loc_82CAB880:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82CAB888:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAB890"))) PPC_WEAK_FUNC(sub_82CAB890);
PPC_FUNC_IMPL(__imp__sub_82CAB890) {
	PPC_FUNC_PROLOGUE();
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82cae338
	sub_82CAE338(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB898"))) PPC_WEAK_FUNC(sub_82CAB898);
PPC_FUNC_IMPL(__imp__sub_82CAB898) {
	PPC_FUNC_PROLOGUE();
	// li r6,1
	ctx.r6.s64 = 1;
	// b 0x82caed40
	sub_82CAED40(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB8A0"))) PPC_WEAK_FUNC(sub_82CAB8A0);
PPC_FUNC_IMPL(__imp__sub_82CAB8A0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,44(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cab8b4
	if (ctx.cr0.eq) goto loc_82CAB8B4;
	// cmpw cr6,r11,r8
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x82cab8f8
	if (!ctx.cr6.eq) goto loc_82CAB8F8;
loc_82CAB8B4:
	// lwz r11,48(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cab8c8
	if (ctx.cr0.eq) goto loc_82CAB8C8;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82cab8f8
	if (!ctx.cr6.eq) goto loc_82CAB8F8;
loc_82CAB8C8:
	// lwz r11,52(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cab8e0
	if (ctx.cr0.eq) goto loc_82CAB8E0;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82cab8f8
	if (!ctx.cr6.eq) goto loc_82CAB8F8;
loc_82CAB8E0:
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cab900
	if (ctx.cr0.eq) goto loc_82CAB900;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// beq cr6,0x82cab900
	if (ctx.cr6.eq) goto loc_82CAB900;
loc_82CAB8F8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82CAB900:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAB908"))) PPC_WEAK_FUNC(sub_82CAB908);
PPC_FUNC_IMPL(__imp__sub_82CAB908) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CAB910;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82caf608
	ctx.lr = 0x82CAB92C;
	sub_82CAF608(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c42018
	ctx.lr = 0x82CAB938;
	sub_82C42018(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82caf660
	ctx.lr = 0x82CAB944;
	sub_82CAF660(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c42018
	ctx.lr = 0x82CAB950;
	sub_82C42018(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB958"))) PPC_WEAK_FUNC(sub_82CAB958);
PPC_FUNC_IMPL(__imp__sub_82CAB958) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// lwz r8,68(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r7,64(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// lwz r6,80(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	// lwz r5,76(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// lwz r11,84(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_82CAB988"))) PPC_WEAK_FUNC(sub_82CAB988);
PPC_FUNC_IMPL(__imp__sub_82CAB988) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAB990"))) PPC_WEAK_FUNC(sub_82CAB990);
PPC_FUNC_IMPL(__imp__sub_82CAB990) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CAB998;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,88(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 88);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r30,64(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 64);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r29,4(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r28,0(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r3,44(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	// bl 0x82c53578
	ctx.lr = 0x82CAB9BC;
	sub_82C53578(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r11,20348
	ctx.r4.s64 = ctx.r11.s64 + 20348;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAB9E4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAB9F0"))) PPC_WEAK_FUNC(sub_82CAB9F0);
PPC_FUNC_IMPL(__imp__sub_82CAB9F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82caba9c
	if (!ctx.cr6.eq) goto loc_82CABA9C;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bgt cr6,0x82caba9c
	if (ctx.cr6.gt) goto loc_82CABA9C;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82caba9c
	if (!ctx.cr6.eq) goto loc_82CABA9C;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r11,44(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82caba9c
	if (!ctx.cr6.eq) goto loc_82CABA9C;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82c529f8
	ctx.lr = 0x82CABA5C;
	sub_82C529F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caba9c
	if (ctx.cr0.eq) goto loc_82CABA9C;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82caba94
	if (!ctx.cr6.eq) goto loc_82CABA94;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82caba94
	if (ctx.cr6.eq) goto loc_82CABA94;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82c55450
	ctx.lr = 0x82CABA8C;
	sub_82C55450(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caba9c
	if (ctx.cr0.eq) goto loc_82CABA9C;
loc_82CABA94:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82cabaa0
	goto loc_82CABAA0;
loc_82CABA9C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CABAA0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CABAB8"))) PPC_WEAK_FUNC(sub_82CABAB8);
PPC_FUNC_IMPL(__imp__sub_82CABAB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CABAC0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// bl 0x82cab9f0
	ctx.lr = 0x82CABAD0;
	sub_82CAB9F0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cabb78
	if (ctx.cr0.eq) goto loc_82CABB78;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r5,r11,-18088
	ctx.r5.s64 = ctx.r11.s64 + -18088;
	// addi r4,r10,-26120
	ctx.r4.s64 = ctx.r10.s64 + -26120;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82c53a60
	ctx.lr = 0x82CABAF0;
	sub_82C53A60(ctx, base);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// addi r29,r31,64
	ctx.r29.s64 = ctx.r31.s64 + 64;
	// addi r6,r31,72
	ctx.r6.s64 = ctx.r31.s64 + 72;
	// addi r5,r31,68
	ctx.r5.s64 = ctx.r31.s64 + 68;
	// stw r10,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r10.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r10,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r10.u32);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// lwz r3,8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// bl 0x82c529f8
	ctx.lr = 0x82CABB28;
	sub_82C529F8(ctx, base);
	// addi r28,r31,8
	ctx.r28.s64 = ctx.r31.s64 + 8;
	// stw r30,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r30.u32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82c3ffa8
	ctx.lr = 0x82CABB38;
	sub_82C3FFA8(ctx, base);
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r4,r11,8
	ctx.r4.s64 = ctx.r11.s64 + 8;
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// lwz r8,40(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lwz r11,0(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// andc r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// divw r3,r9,r11
	ctx.r3.s32 = ctx.r9.s32 / ctx.r11.s32;
	// twllei r11,0
	// twlgei r10,-1
	// bl 0x82c40108
	ctx.lr = 0x82CABB6C;
	sub_82C40108(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r11.u32);
loc_82CABB78:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CABB80"))) PPC_WEAK_FUNC(sub_82CABB80);
PPC_FUNC_IMPL(__imp__sub_82CABB80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,-26104
	ctx.r4.s64 = ctx.r11.s64 + -26104;
	// li r3,16
	ctx.r3.s64 = 16;
	// bl 0x82c41f78
	ctx.lr = 0x82CABBAC;
	sub_82C41F78(ctx, base);
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CABBD0"))) PPC_WEAK_FUNC(sub_82CABBD0);
PPC_FUNC_IMPL(__imp__sub_82CABBD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a4
	ctx.lr = 0x82CABBD8;
	__savegprlr_19(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r27,84(r29)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r29.u32 + 84);
	// lwz r22,68(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 68);
	// lwz r21,72(r29)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r29.u32 + 72);
	// cmpwi r27,0
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// lwz r11,80(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 80);
	// lwz r28,92(r29)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r29.u32 + 92);
	// lwz r10,96(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 96);
	// ble 0x82cabcbc
	if (!ctx.cr0.gt) goto loc_82CABCBC;
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// srawi r9,r9,1
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 1;
	// mullw r8,r8,r28
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r28.s32);
	// addze r20,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r20.s64 = temp.s64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// rlwinm r26,r8,2,0,29
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// rlwinm r25,r28,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// rlwinm r24,r11,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r10,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82CABC38:
	// lwz r11,56(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 56);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CABC58;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,108(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 108);
	// lwz r8,100(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 100);
	// mr r10,r20
	ctx.r10.u64 = ctx.r20.u64;
	// lwz r19,64(r29)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r29.u32 + 64);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// add r6,r26,r30
	ctx.r6.u64 = ctx.r26.u64 + ctx.r30.u64;
	// add r5,r26,r31
	ctx.r5.u64 = ctx.r26.u64 + ctx.r31.u64;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r4,r25,r30
	ctx.r4.u64 = ctx.r25.u64 + ctx.r30.u64;
	// add r3,r25,r31
	ctx.r3.u64 = ctx.r25.u64 + ctx.r31.u64;
	// mtctr r19
	ctx.ctr.u64 = ctx.r19.u64;
	// bctrl 
	ctx.lr = 0x82CABC8C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// add r7,r24,r30
	ctx.r7.u64 = ctx.r24.u64 + ctx.r30.u64;
	// add r6,r24,r31
	ctx.r6.u64 = ctx.r24.u64 + ctx.r31.u64;
	// lwz r11,56(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 56);
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CABCAC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addic. r27,r27,-1
	ctx.xer.ca = ctx.r27.u32 > 0;
	ctx.r27.s64 = ctx.r27.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// add r31,r23,r31
	ctx.r31.u64 = ctx.r23.u64 + ctx.r31.u64;
	// add r30,r23,r30
	ctx.r30.u64 = ctx.r23.u64 + ctx.r30.u64;
	// bne 0x82cabc38
	if (!ctx.cr0.eq) goto loc_82CABC38;
loc_82CABCBC:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82d5c4f4
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CABCC8"))) PPC_WEAK_FUNC(sub_82CABCC8);
PPC_FUNC_IMPL(__imp__sub_82CABCC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c498
	ctx.lr = 0x82CABCD0;
	__savegprlr_16(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r26,84(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// lwz r18,68(r31)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r17,72(r31)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// cmpwi r26,0
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// srawi r8,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r8.s64 = ctx.r10.s32 >> 1;
	// lwz r28,92(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r9,96(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// addze r27,r8
	temp.s64 = ctx.r8.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r8.u32;
	ctx.r27.s64 = temp.s64;
	// ble 0x82cabe00
	if (!ctx.cr0.gt) goto loc_82CABE00;
	// srawi r8,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r8.s64 = ctx.r11.s32 >> 1;
	// subf r11,r27,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r27.s64;
	// addze r8,r8
	temp.s64 = ctx.r8.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r8.u32;
	ctx.r8.s64 = temp.s64;
	// mullw r10,r10,r28
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// mullw r7,r27,r28
	ctx.r7.s64 = int64_t(ctx.r27.s32) * int64_t(ctx.r28.s32);
	// mullw r8,r8,r28
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r28.s32);
	// rlwinm r25,r10,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r24,r28,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r19,r27,2
	ctx.r19.s64 = ctx.r27.s64 + 2;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r22,r7,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r21,r8,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r20,r9,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
loc_82CABD44:
	// lwz r11,56(r18)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r18.u32 + 56);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CABD64;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// lwz r8,100(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// lwz r16,64(r31)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// add r6,r25,r29
	ctx.r6.u64 = ctx.r25.u64 + ctx.r29.u64;
	// add r5,r25,r30
	ctx.r5.u64 = ctx.r25.u64 + ctx.r30.u64;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r4,r24,r29
	ctx.r4.u64 = ctx.r24.u64 + ctx.r29.u64;
	// add r3,r24,r30
	ctx.r3.u64 = ctx.r24.u64 + ctx.r30.u64;
	// mtctr r16
	ctx.ctr.u64 = ctx.r16.u64;
	// bctrl 
	ctx.lr = 0x82CABD98;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// mr r10,r19
	ctx.r10.u64 = ctx.r19.u64;
	// lwz r8,100(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// lwz r16,64(r31)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// add r6,r23,r29
	ctx.r6.u64 = ctx.r23.u64 + ctx.r29.u64;
	// add r5,r23,r30
	ctx.r5.u64 = ctx.r23.u64 + ctx.r30.u64;
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// add r3,r22,r30
	ctx.r3.u64 = ctx.r22.u64 + ctx.r30.u64;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r4,r22,r29
	ctx.r4.u64 = ctx.r22.u64 + ctx.r29.u64;
	// mtctr r16
	ctx.ctr.u64 = ctx.r16.u64;
	// bctrl 
	ctx.lr = 0x82CABDD0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// add r7,r21,r29
	ctx.r7.u64 = ctx.r21.u64 + ctx.r29.u64;
	// lwz r11,56(r17)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r17.u32 + 56);
	// add r6,r21,r30
	ctx.r6.u64 = ctx.r21.u64 + ctx.r30.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CABDF0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addic. r26,r26,-1
	ctx.xer.ca = ctx.r26.u32 > 0;
	ctx.r26.s64 = ctx.r26.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// add r30,r20,r30
	ctx.r30.u64 = ctx.r20.u64 + ctx.r30.u64;
	// add r29,r20,r29
	ctx.r29.u64 = ctx.r20.u64 + ctx.r29.u64;
	// bne 0x82cabd44
	if (!ctx.cr0.eq) goto loc_82CABD44;
loc_82CABE00:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82d5c4e8
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CABE08"))) PPC_WEAK_FUNC(sub_82CABE08);
PPC_FUNC_IMPL(__imp__sub_82CABE08) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CABE18"))) PPC_WEAK_FUNC(sub_82CABE18);
PPC_FUNC_IMPL(__imp__sub_82CABE18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82CABE20;
	__savegprlr_14(ctx, base);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r26,340(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r23,r8
	ctx.r23.u64 = ctx.r8.u64;
	// mr r14,r10
	ctx.r14.u64 = ctx.r10.u64;
	// mr r20,r9
	ctx.r20.u64 = ctx.r9.u64;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// lwz r29,92(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// li r15,2
	ctx.r15.s64 = 2;
	// lwz r30,104(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// subf r27,r23,r20
	ctx.r27.s64 = ctx.r20.s64 - ctx.r23.s64;
	// mullw r10,r29,r23
	ctx.r10.s64 = int64_t(ctx.r29.s32) * int64_t(ctx.r23.s32);
	// lwz r9,76(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r28,100(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// stw r15,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r15.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// addi r3,r30,-2
	ctx.r3.s64 = ctx.r30.s64 + -2;
	// rlwinm r25,r10,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// srawi r9,r9,1
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 1;
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// add r18,r25,r4
	ctx.r18.u64 = ctx.r25.u64 + ctx.r4.u64;
	// add r19,r25,r11
	ctx.r19.u64 = ctx.r25.u64 + ctx.r11.u64;
	// addi r22,r26,4
	ctx.r22.s64 = ctx.r26.s64 + 4;
	// mr r17,r7
	ctx.r17.u64 = ctx.r7.u64;
	// mr r16,r6
	ctx.r16.u64 = ctx.r6.u64;
	// addze r7,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r7.s64 = temp.s64;
	// add r24,r3,r26
	ctx.r24.u64 = ctx.r3.u64 + ctx.r26.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r6,r22
	ctx.r6.u64 = ctx.r22.u64;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// bl 0x82c92ce0
	ctx.lr = 0x82CABEAC;
	sub_82C92CE0(ctx, base);
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// subf r17,r25,r17
	ctx.r17.s64 = ctx.r17.s64 - ctx.r25.s64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// subf r25,r25,r16
	ctx.r25.s64 = ctx.r16.s64 - ctx.r25.s64;
	// addze r7,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r7.s64 = temp.s64;
	// li r11,-2
	ctx.r11.s64 = -2;
	// neg r16,r29
	ctx.r16.s64 = -ctx.r29.s64;
	// addi r21,r24,4
	ctx.r21.s64 = ctx.r24.s64 + 4;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r16,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r16.u32);
	// mr r6,r21
	ctx.r6.u64 = ctx.r21.u64;
	// mr r4,r17
	ctx.r4.u64 = ctx.r17.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82c92ce0
	ctx.lr = 0x82CABEF4;
	sub_82C92CE0(ctx, base);
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// mr r9,r23
	ctx.r9.u64 = ctx.r23.u64;
	// lwz r8,104(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// mr r6,r21
	ctx.r6.u64 = ctx.r21.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r15,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r15.u32);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r10,r20,r14
	ctx.r10.u64 = ctx.r20.u64 + ctx.r14.u64;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CABF30;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// stw r15,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r15.u32);
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// addze r7,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r7.s64 = temp.s64;
	// mr r6,r19
	ctx.r6.u64 = ctx.r19.u64;
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c92d70
	ctx.lr = 0x82CABF64;
	sub_82C92D70(ctx, base);
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// li r7,-2
	ctx.r7.s64 = -2;
	// stw r16,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r16.u32);
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// mr r6,r17
	ctx.r6.u64 = ctx.r17.u64;
	// addze r7,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r7.s64 = temp.s64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c92d70
	ctx.lr = 0x82CABF9C;
	sub_82C92D70(ctx, base);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CABFA8"))) PPC_WEAK_FUNC(sub_82CABFA8);
PPC_FUNC_IMPL(__imp__sub_82CABFA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c498
	ctx.lr = 0x82CABFB0;
	__savegprlr_16(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r9,80(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// lwz r17,68(r31)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r19,72(r31)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r18,92(r31)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r28,84(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// addi r22,r10,2
	ctx.r22.s64 = ctx.r10.s64 + 2;
	// srawi r10,r9,1
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 1;
	// mullw r11,r11,r22
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r22.s32);
	// rlwinm r3,r11,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// addze r27,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r27.s64 = temp.s64;
	// bl 0x82c3fd60
	ctx.lr = 0x82CABFFC;
	sub_82C3FD60(ctx, base);
	// mr r21,r3
	ctx.r21.u64 = ctx.r3.u64;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// ble cr6,0x82cac0f4
	if (!ctx.cr6.gt) goto loc_82CAC0F4;
	// mullw r11,r27,r18
	ctx.r11.s64 = int64_t(ctx.r27.s32) * int64_t(ctx.r18.s32);
	// rlwinm r20,r11,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r16,r22,1
	ctx.r16.s64 = ctx.r22.s64 + 1;
	// mr r23,r28
	ctx.r23.u64 = ctx.r28.u64;
loc_82CAC018:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lwz r10,56(r17)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r17.u32 + 56);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mullw r11,r18,r11
	ctx.r11.s64 = int64_t(ctx.r18.s32) * int64_t(ctx.r11.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// add r25,r11,r30
	ctx.r25.u64 = ctx.r11.u64 + ctx.r30.u64;
	// add r24,r11,r29
	ctx.r24.u64 = ctx.r11.u64 + ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82CAC04C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r28,1
	ctx.r28.s64 = 1;
	// cmpw cr6,r16,r27
	ctx.cr6.compare<int32_t>(ctx.r16.s32, ctx.r27.s32, ctx.xer);
	// bge cr6,0x82cac094
	if (!ctx.cr6.lt) goto loc_82CAC094;
	// mr r26,r16
	ctx.r26.u64 = ctx.r16.u64;
loc_82CAC05C:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r21.u32);
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cabe18
	ctx.lr = 0x82CAC084;
	sub_82CABE18(ctx, base);
	// add r26,r26,r22
	ctx.r26.u64 = ctx.r26.u64 + ctx.r22.u64;
	// add r28,r28,r22
	ctx.r28.u64 = ctx.r28.u64 + ctx.r22.u64;
	// cmpw cr6,r26,r27
	ctx.cr6.compare<int32_t>(ctx.r26.s32, ctx.r27.s32, ctx.xer);
	// blt cr6,0x82cac05c
	if (ctx.cr6.lt) goto loc_82CAC05C;
loc_82CAC094:
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// lwz r10,88(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r21.u32);
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cabe18
	ctx.lr = 0x82CAC0BC;
	sub_82CABE18(ctx, base);
	// add r7,r20,r29
	ctx.r7.u64 = ctx.r20.u64 + ctx.r29.u64;
	// add r6,r20,r30
	ctx.r6.u64 = ctx.r20.u64 + ctx.r30.u64;
	// lwz r11,56(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 56);
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAC0DC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,96(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// bne 0x82cac018
	if (!ctx.cr0.eq) goto loc_82CAC018;
loc_82CAC0F4:
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x82c3fdb8
	ctx.lr = 0x82CAC0FC;
	sub_82C3FDB8(ctx, base);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82d5c4e8
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAC108"))) PPC_WEAK_FUNC(sub_82CAC108);
PPC_FUNC_IMPL(__imp__sub_82CAC108) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82c3fc78
	ctx.lr = 0x82CAC12C;
	sub_82C3FC78(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// bl 0x82c3fc78
	ctx.lr = 0x82CAC138;
	sub_82C3FC78(ctx, base);
	// lwz r9,112(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// addi r4,r31,108
	ctx.r4.s64 = ctx.r31.s64 + 108;
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r10,88(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mullw r6,r7,r11
	ctx.r6.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r11.s32);
	// lwz r9,20(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// lwz r5,8(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// addi r9,r11,-1
	ctx.r9.s64 = ctx.r11.s64 + -1;
	// srawi r9,r9,1
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 1;
	// addze r11,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r11.s64 = temp.s64;
	// add r8,r11,r10
	ctx.r8.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82c540c0
	ctx.lr = 0x82CAC170;
	sub_82C540C0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAC188"))) PPC_WEAK_FUNC(sub_82CAC188);
PPC_FUNC_IMPL(__imp__sub_82CAC188) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82c3fc28
	ctx.lr = 0x82CAC1A4;
	sub_82C3FC28(ctx, base);
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// bl 0x82c3fc28
	ctx.lr = 0x82CAC1AC;
	sub_82C3FC28(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAC1C0"))) PPC_WEAK_FUNC(sub_82CAC1C0);
PPC_FUNC_IMPL(__imp__sub_82CAC1C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b8
	ctx.lr = 0x82CAC1C8;
	__savegprlr_24(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r3,76(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// beq cr6,0x82cac24c
	if (ctx.cr6.eq) goto loc_82CAC24C;
	// lwz r26,4(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// lwz r28,72(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r27,68(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// rlwinm r29,r11,0,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r25,84(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r24,88(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// bl 0x82c53cb0
	ctx.lr = 0x82CAC210;
	sub_82C53CB0(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r27.u32);
	// addi r4,r11,20380
	ctx.r4.s64 = ctx.r11.s64 + 20380;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r5,r29,2
	ctx.r5.s64 = ctx.r29.s64 + 2;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r28.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// mr r10,r26
	ctx.r10.u64 = ctx.r26.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAC248;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82cac29c
	goto loc_82CAC29C;
loc_82CAC24C:
	// lwz r29,72(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r28,68(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r27,4(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r26,84(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r25,88(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// bl 0x82c53cb0
	ctx.lr = 0x82CAC264;
	sub_82C53CB0(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// lwz r5,76(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// addi r11,r11,20380
	ctx.r11.s64 = ctx.r11.s64 + 20380;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r4,r11,48
	ctx.r4.s64 = ctx.r11.s64 + 48;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAC29C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82CAC29C:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c508
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAC2A8"))) PPC_WEAK_FUNC(sub_82CAC2A8);
PPC_FUNC_IMPL(__imp__sub_82CAC2A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c498
	ctx.lr = 0x82CAC2B0;
	__savegprlr_16(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,20(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r31,r8
	ctx.r31.u64 = ctx.r8.u64;
	// mr r16,r10
	ctx.r16.u64 = ctx.r10.u64;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpw cr6,r5,r11
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82cac438
	if (!ctx.cr6.eq) goto loc_82CAC438;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82cac438
	if (!ctx.cr6.eq) goto loc_82CAC438;
	// addi r11,r7,1
	ctx.r11.s64 = ctx.r7.s64 + 1;
	// lwz r20,332(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// addi r21,r7,-1
	ctx.r21.s64 = ctx.r7.s64 + -1;
	// lwz r18,316(r1)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// lwz r17,308(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// mullw r9,r21,r31
	ctx.r9.s64 = int64_t(ctx.r21.s32) * int64_t(ctx.r31.s32);
	// lwz r22,324(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// addze r19,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r19.s64 = temp.s64;
	// li r11,0
	ctx.r11.s64 = 0;
	// rlwinm r28,r9,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r29,r31,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// add r24,r28,r18
	ctx.r24.u64 = ctx.r28.u64 + ctx.r18.u64;
	// add r26,r29,r18
	ctx.r26.u64 = ctx.r29.u64 + ctx.r18.u64;
	// add r25,r29,r17
	ctx.r25.u64 = ctx.r29.u64 + ctx.r17.u64;
	// stw r11,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r11.u32);
	// add r23,r28,r17
	ctx.r23.u64 = ctx.r28.u64 + ctx.r17.u64;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r9,r19
	ctx.r9.u64 = ctx.r19.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAC358;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82cac3e8
	if (!ctx.cr0.eq) goto loc_82CAC3E8;
	// srawi r11,r21,1
	ctx.xer.ca = (ctx.r21.s32 < 0) & ((ctx.r21.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r21.s32 >> 1;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// addze r21,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r21.s64 = temp.s64;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// stw r11,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r11.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAC3A4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cac438
	if (ctx.cr0.eq) goto loc_82CAC438;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// addi r9,r21,2
	ctx.r9.s64 = ctx.r21.s64 + 2;
	// mr r8,r21
	ctx.r8.u64 = ctx.r21.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAC3E0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cac438
	if (ctx.cr0.eq) goto loc_82CAC438;
loc_82CAC3E8:
	// lwz r6,12(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// rlwinm r11,r16,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r16.u32 | (ctx.r16.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r20)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// add r3,r11,r17
	ctx.r3.u64 = ctx.r11.u64 + ctx.r17.u64;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// add r11,r11,r18
	ctx.r11.u64 = ctx.r11.u64 + ctx.r18.u64;
	// add r5,r28,r3
	ctx.r5.u64 = ctx.r28.u64 + ctx.r3.u64;
	// lwz r31,0(r6)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// li r8,1
	ctx.r8.s64 = 1;
	// subf r9,r9,r19
	ctx.r9.s64 = ctx.r19.s64 - ctx.r9.s64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// add r6,r28,r11
	ctx.r6.u64 = ctx.r28.u64 + ctx.r11.u64;
	// add r4,r29,r11
	ctx.r4.u64 = ctx.r29.u64 + ctx.r11.u64;
	// add r3,r29,r3
	ctx.r3.u64 = ctx.r29.u64 + ctx.r3.u64;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82CAC42C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne 0x82cac43c
	if (!ctx.cr0.eq) goto loc_82CAC43C;
loc_82CAC438:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CAC43C:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82d5c4e8
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAC448"))) PPC_WEAK_FUNC(sub_82CAC448);
PPC_FUNC_IMPL(__imp__sub_82CAC448) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b4
	ctx.lr = 0x82CAC450;
	__savegprlr_23(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r25,20(r3)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmpw cr6,r5,r11
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82cac58c
	if (!ctx.cr6.eq) goto loc_82CAC58C;
	// lwz r11,12(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpw cr6,r4,r10
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82cac58c
	if (!ctx.cr6.eq) goto loc_82CAC58C;
	// addi r9,r5,3
	ctx.r9.s64 = ctx.r5.s64 + 3;
	// lwz r24,0(r11)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r26,276(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// li r10,2
	ctx.r10.s64 = 2;
	// rlwinm r11,r9,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r31,r11,2
	ctx.r31.s64 = ctx.r11.s64 + 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// rlwinm r30,r31,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r11,r30,-2
	ctx.r11.s64 = ctx.r30.s64 + -2;
	// addi r9,r31,1
	ctx.r9.s64 = ctx.r31.s64 + 1;
	// rlwinm r29,r11,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// addi r28,r29,4
	ctx.r28.s64 = ctx.r29.s64 + 4;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mtctr r24
	ctx.ctr.u64 = ctx.r24.u64;
	// bctrl 
	ctx.lr = 0x82CAC4C8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cac58c
	if (ctx.cr0.eq) goto loc_82CAC58C;
	// addi r11,r27,-1
	ctx.r11.s64 = ctx.r27.s64 + -1;
	// lwz r24,284(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// li r10,2
	ctx.r10.s64 = 2;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// li r8,1
	ctx.r8.s64 = 1;
	// addze r9,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r9.s64 = temp.s64;
	// li r11,0
	ctx.r11.s64 = 0;
	// divw r7,r9,r31
	ctx.r7.s32 = ctx.r9.s32 / ctx.r31.s32;
	// twllei r31,0
	// mullw r7,r7,r31
	ctx.r7.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r31.s32);
	// stw r11,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r11.u32);
	// lwz r6,12(r25)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// lwz r23,0(r6)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rotlwi r11,r9,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// subf r27,r7,r9
	ctx.r27.s64 = ctx.r9.s64 - ctx.r7.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// andc r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 & ~ctx.r11.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// twlgei r11,-1
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r9,r27,1
	ctx.r9.s64 = ctx.r27.s64 + 1;
	// mtctr r23
	ctx.ctr.u64 = ctx.r23.u64;
	// bctrl 
	ctx.lr = 0x82CAC53C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82cac584
	if (!ctx.cr0.eq) goto loc_82CAC584;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r9,r27,2
	ctx.r9.s64 = ctx.r27.s64 + 2;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// stw r11,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r11.u32);
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// lwz r11,12(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAC57C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cac58c
	if (ctx.cr0.eq) goto loc_82CAC58C;
loc_82CAC584:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82cac590
	goto loc_82CAC590;
loc_82CAC58C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CAC590:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c504
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAC598"))) PPC_WEAK_FUNC(sub_82CAC598);
PPC_FUNC_IMPL(__imp__sub_82CAC598) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CAC5A0;
	__savegprlr_28(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r28,260(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lwz r11,268(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// beq cr6,0x82cac5ec
	if (ctx.cr6.eq) goto loc_82CAC5EC;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,252(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r28.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r11,244(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82cac448
	ctx.lr = 0x82CAC5E0;
	sub_82CAC448(ctx, base);
loc_82CAC5E0:
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82cac60c
	if (!ctx.cr0.eq) goto loc_82CAC60C;
	// b 0x82cac648
	goto loc_82CAC648;
loc_82CAC5EC:
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,252(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r28.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r11,244(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82cac2a8
	ctx.lr = 0x82CAC608;
	sub_82CAC2A8(ctx, base);
	// b 0x82cac5e0
	goto loc_82CAC5E0;
loc_82CAC60C:
	// lwz r11,152(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 152);
	// rlwinm. r11,r11,0,3,3
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cac644
	if (ctx.cr0.eq) goto loc_82CAC644;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mullw r4,r30,r29
	ctx.r4.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r29.s32);
	// subfic r11,r11,0
	ctx.xer.ca = ctx.r11.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,23,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1F0;
	// addi r3,r11,16
	ctx.r3.s64 = ctx.r11.s64 + 16;
	// bl 0x82caf6b8
	ctx.lr = 0x82CAC638;
	sub_82CAF6B8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// bne 0x82cac648
	if (!ctx.cr0.eq) goto loc_82CAC648;
loc_82CAC644:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82CAC648:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAC650"))) PPC_WEAK_FUNC(sub_82CAC650);
PPC_FUNC_IMPL(__imp__sub_82CAC650) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c49c
	ctx.lr = 0x82CAC658;
	__savegprlr_17(ctx, base);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r6
	ctx.r24.u64 = ctx.r6.u64;
	// lwz r22,356(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// mr r25,r7
	ctx.r25.u64 = ctx.r7.u64;
	// lwz r30,348(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// lwz r23,340(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// srawi r11,r25,1
	ctx.xer.ca = (ctx.r25.s32 < 0) & ((ctx.r25.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r25.s32 >> 1;
	// mr r21,r8
	ctx.r21.u64 = ctx.r8.u64;
	// stw r22,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r22.u32);
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// stw r6,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r6.u32);
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// lwz r18,20(r28)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r23.u32);
	// mr r29,r9
	ctx.r29.u64 = ctx.r9.u64;
	// mr r17,r10
	ctx.r17.u64 = ctx.r10.u64;
	// li r27,0
	ctx.r27.s64 = 0;
	// mullw r19,r11,r21
	ctx.r19.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r21.s32);
	// bl 0x82cac598
	ctx.lr = 0x82CAC6B8;
	sub_82CAC598(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82cac6c8
	if (!ctx.cr0.eq) goto loc_82CAC6C8;
loc_82CAC6C0:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82cac8e8
	goto loc_82CAC8E8;
loc_82CAC6C8:
	// bl 0x82c42a70
	ctx.lr = 0x82CAC6CC;
	sub_82C42A70(ctx, base);
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c42a78
	ctx.lr = 0x82CAC6E0;
	sub_82C42A78(ctx, base);
	// mr r4,r20
	ctx.r4.u64 = ctx.r20.u64;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r7,r23
	ctx.r7.u64 = ctx.r23.u64;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// bl 0x82c54fd8
	ctx.lr = 0x82CAC6FC;
	sub_82C54FD8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82c41a30
	ctx.lr = 0x82CAC708;
	sub_82C41A30(ctx, base);
	// mr. r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// beq 0x82cac794
	if (ctx.cr0.eq) goto loc_82CAC794;
	// srawi r11,r25,1
	ctx.xer.ca = (ctx.r25.s32 < 0) & ((ctx.r25.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r25.s32 >> 1;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// subf. r11,r11,r25
	ctx.r11.s64 = ctx.r25.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cac72c
	if (ctx.cr0.eq) goto loc_82CAC72C;
	// bl 0x82c42a70
	ctx.lr = 0x82CAC728;
	sub_82C42A70(ctx, base);
	// b 0x82cac73c
	goto loc_82CAC73C;
loc_82CAC72C:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c42a78
	ctx.lr = 0x82CAC73C;
	sub_82C42A78(ctx, base);
loc_82CAC73C:
	// subfic r10,r31,0
	ctx.xer.ca = ctx.r31.u32 <= 0;
	ctx.r10.s64 = 0 - ctx.r31.s64;
	// rlwinm r11,r19,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 2) & 0xFFFFFFFC;
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// add r31,r11,r30
	ctx.r31.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// add r30,r11,r23
	ctx.r30.u64 = ctx.r11.u64 + ctx.r23.u64;
	// andi. r10,r10,5
	ctx.r10.u64 = ctx.r10.u64 & 5;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r19,r10,1
	ctx.r19.s64 = ctx.r10.s64 + 1;
	// bl 0x82c42a70
	ctx.lr = 0x82CAC760;
	sub_82C42A70(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r8,r31
	ctx.r8.u64 = ctx.r31.u64;
	// mr r9,r19
	ctx.r9.u64 = ctx.r19.u64;
	// bl 0x82c54fd8
	ctx.lr = 0x82CAC780;
	sub_82C54FD8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82c41a30
	ctx.lr = 0x82CAC78C;
	sub_82C41A30(ctx, base);
	// mr. r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// bne 0x82cac7a8
	if (!ctx.cr0.eq) goto loc_82CAC7A8;
loc_82CAC794:
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82c3fc28
	ctx.lr = 0x82CAC79C;
	sub_82C3FC28(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c3fc28
	ctx.lr = 0x82CAC7A4;
	sub_82C3FC28(ctx, base);
	// b 0x82cac6c0
	goto loc_82CAC6C0;
loc_82CAC7A8:
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r23,112(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82cac7cc
	if (ctx.cr6.eq) goto loc_82CAC7CC;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r5,r11,-16472
	ctx.r5.s64 = ctx.r11.s64 + -16472;
	// addi r4,r10,-26092
	ctx.r4.s64 = ctx.r10.s64 + -26092;
	// b 0x82cac7f0
	goto loc_82CAC7F0;
loc_82CAC7CC:
	// cmpwi cr6,r23,0
	ctx.cr6.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq cr6,0x82cac7e0
	if (ctx.cr6.eq) goto loc_82CAC7E0;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-17208
	ctx.r5.s64 = ctx.r11.s64 + -17208;
	// b 0x82cac7e8
	goto loc_82CAC7E8;
loc_82CAC7E0:
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-17456
	ctx.r5.s64 = ctx.r11.s64 + -17456;
loc_82CAC7E8:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r4,r11,-26092
	ctx.r4.s64 = ctx.r11.s64 + -26092;
loc_82CAC7F0:
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82cafe60
	ctx.lr = 0x82CAC7F8;
	sub_82CAFE60(ctx, base);
	// addi r11,r26,3
	ctx.r11.s64 = ctx.r26.s64 + 3;
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r30,r31,8
	ctx.r30.s64 = ctx.r31.s64 + 8;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r10,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r26,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r26.u32);
	// stw r24,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r24.u32);
	// stw r25,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r25.u32);
	// stw r21,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r21.u32);
	// stw r29,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r29.u32);
	// stw r10,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r10.u32);
	// stw r17,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r17.u32);
	// stw r28,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r28.u32);
	// stw r11,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r11.u32);
	// stw r20,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r20.u32);
	// stw r27,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r27.u32);
	// stw r23,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r23.u32);
	// bl 0x82c3ffa8
	ctx.lr = 0x82CAC854;
	sub_82C3FFA8(ctx, base);
	// addi r11,r25,-1
	ctx.r11.s64 = ctx.r25.s64 + -1;
	// lwz r10,12(r18)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r18.u32 + 12);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// addi r4,r18,16
	ctx.r4.s64 = ctx.r18.s64 + 16;
	// addze r9,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r9.s64 = temp.s64;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rotlwi r11,r9,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r9,r9,r10
	ctx.r9.s32 = ctx.r9.s32 / ctx.r10.s32;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mullw r3,r9,r29
	ctx.r3.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r29.s32);
	// andc r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// twllei r10,0
	// twlgei r11,-1
	// bl 0x82c40108
	ctx.lr = 0x82CAC890;
	sub_82C40108(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r20,8
	ctx.r4.s64 = ctx.r20.s64 + 8;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c40108
	ctx.lr = 0x82CAC8A0;
	sub_82C40108(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r27,8
	ctx.r4.s64 = ctx.r27.s64 + 8;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c40108
	ctx.lr = 0x82CAC8B0;
	sub_82C40108(ctx, base);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82cac8e4
	if (ctx.cr6.eq) goto loc_82CAC8E4;
	// mullw r11,r26,r25
	ctx.r11.s64 = int64_t(ctx.r26.s32) * int64_t(ctx.r25.s32);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// mullw r11,r11,r29
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r29.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r11.u64);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82CAC8E4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82CAC8E8:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82d5c4ec
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAC8F0"))) PPC_WEAK_FUNC(sub_82CAC8F0);
PPC_FUNC_IMPL(__imp__sub_82CAC8F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CAC8F8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// addi r6,r11,-14768
	ctx.r6.s64 = ctx.r11.s64 + -14768;
	// li r3,32
	ctx.r3.s64 = 32;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// bl 0x82cafe28
	ctx.lr = 0x82CAC924;
	sub_82CAFE28(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, ctx.r29.u32);
	// stw r31,20(r4)
	PPC_STORE_U32(ctx.r4.u32 + 20, ctx.r31.u32);
	// stw r28,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r28.u32);
	// bl 0x82c42018
	ctx.lr = 0x82CAC93C;
	sub_82C42018(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAC948"))) PPC_WEAK_FUNC(sub_82CAC948);
PPC_FUNC_IMPL(__imp__sub_82CAC948) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CAC950;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// bl 0x82cac8f0
	ctx.lr = 0x82CAC96C;
	sub_82CAC8F0(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cac8f0
	ctx.lr = 0x82CAC984;
	sub_82CAC8F0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAC990"))) PPC_WEAK_FUNC(sub_82CAC990);
PPC_FUNC_IMPL(__imp__sub_82CAC990) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// lwz r8,80(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	// lwz r31,76(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// lwz r9,68(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// lwz r7,64(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// stw r8,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r8.u32);
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// lwz r11,84(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAC9E0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAC9F8"))) PPC_WEAK_FUNC(sub_82CAC9F8);
PPC_FUNC_IMPL(__imp__sub_82CAC9F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82CACA00;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// lwz r28,80(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r9,68(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r30,72(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r7,64(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// lwz r27,84(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r28.u32);
	// mtctr r27
	ctx.ctr.u64 = ctx.r27.u64;
	// bctrl 
	ctx.lr = 0x82CACA4C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82caca7c
	if (!ctx.cr6.gt) goto loc_82CACA7C;
	// lis r10,-32230
	ctx.r10.s64 = -2112225280;
	// rlwinm r11,r28,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,21348(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 21348);
	ctx.f0.f64 = double(temp.f32);
loc_82CACA60:
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stfsx f0,r10,r29
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + ctx.r29.u32, temp.u32);
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// bne 0x82caca60
	if (!ctx.cr0.eq) goto loc_82CACA60;
loc_82CACA7C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CACA88"))) PPC_WEAK_FUNC(sub_82CACA88);
PPC_FUNC_IMPL(__imp__sub_82CACA88) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CACA90"))) PPC_WEAK_FUNC(sub_82CACA90);
PPC_FUNC_IMPL(__imp__sub_82CACA90) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CACA98;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,88(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 88);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r30,72(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 72);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// lwz r29,4(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r28,0(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// bl 0x82c53578
	ctx.lr = 0x82CACAC0;
	sub_82C53578(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r11,20472
	ctx.r4.s64 = ctx.r11.s64 + 20472;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CACAE8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CACAF0"))) PPC_WEAK_FUNC(sub_82CACAF0);
PPC_FUNC_IMPL(__imp__sub_82CACAF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82cacba4
	if (!ctx.cr6.eq) goto loc_82CACBA4;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bgt cr6,0x82cacba4
	if (ctx.cr6.gt) goto loc_82CACBA4;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82cacba4
	if (!ctx.cr6.eq) goto loc_82CACBA4;
	// lwz r11,40(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82cacba4
	if (!ctx.cr6.eq) goto loc_82CACBA4;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// bl 0x82c529f8
	ctx.lr = 0x82CACB5C;
	sub_82C529F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cacba4
	if (ctx.cr0.eq) goto loc_82CACBA4;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82cacb9c
	if (!ctx.cr6.eq) goto loc_82CACB9C;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82cacb9c
	if (ctx.cr6.eq) goto loc_82CACB9C;
	// lis r4,32767
	ctx.r4.s64 = 2147418112;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// ori r4,r4,65535
	ctx.r4.u64 = ctx.r4.u64 | 65535;
	// bl 0x82c54798
	ctx.lr = 0x82CACB94;
	sub_82C54798(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cacba4
	if (ctx.cr0.eq) goto loc_82CACBA4;
loc_82CACB9C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82cacba8
	goto loc_82CACBA8;
loc_82CACBA4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CACBA8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CACBC0"))) PPC_WEAK_FUNC(sub_82CACBC0);
PPC_FUNC_IMPL(__imp__sub_82CACBC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82CACBC8;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// bl 0x82cacaf0
	ctx.lr = 0x82CACBD8;
	sub_82CACAF0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cacd34
	if (ctx.cr0.eq) goto loc_82CACD34;
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt 0x82cacbf8
	if (ctx.cr0.lt) goto loc_82CACBF8;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// li r29,1
	ctx.r29.s64 = 1;
	// ble cr6,0x82cacbfc
	if (!ctx.cr6.gt) goto loc_82CACBFC;
loc_82CACBF8:
	// li r29,0
	ctx.r29.s64 = 0;
loc_82CACBFC:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82cacc10
	if (!ctx.cr6.eq) goto loc_82CACC10;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-13832
	ctx.r5.s64 = ctx.r11.s64 + -13832;
	// b 0x82cacc18
	goto loc_82CACC18;
loc_82CACC10:
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-13936
	ctx.r5.s64 = ctx.r11.s64 + -13936;
loc_82CACC18:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r3,96
	ctx.r3.s64 = 96;
	// addi r4,r11,-26076
	ctx.r4.s64 = ctx.r11.s64 + -26076;
	// bl 0x82c54a68
	ctx.lr = 0x82CACC28;
	sub_82C54A68(ctx, base);
	// lwz r11,12(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r30,4(r28)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// beq cr6,0x82cacc48
	if (ctx.cr6.eq) goto loc_82CACC48;
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82cacc4c
	goto loc_82CACC4C;
loc_82CACC48:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
loc_82CACC4C:
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// beq cr6,0x82cacc60
	if (ctx.cr6.eq) goto loc_82CACC60;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// b 0x82cacc64
	goto loc_82CACC64;
loc_82CACC60:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
loc_82CACC64:
	// addi r29,r31,72
	ctx.r29.s64 = ctx.r31.s64 + 72;
	// stw r11,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r11.u32);
	// addi r6,r31,80
	ctx.r6.s64 = ctx.r31.s64 + 80;
	// lwz r3,8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// addi r5,r31,76
	ctx.r5.s64 = ctx.r31.s64 + 76;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82c529f8
	ctx.lr = 0x82CACC80;
	sub_82C529F8(ctx, base);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// srawi r10,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 1;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// subf. r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82cacca0
	if (ctx.cr0.eq) goto loc_82CACCA0;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82caccb0
	goto loc_82CACCB0;
loc_82CACCA0:
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
loc_82CACCB0:
	// addi r30,r31,8
	ctx.r30.s64 = ctx.r31.s64 + 8;
	// stw r11,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r11.u32);
	// stw r27,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r27.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c3ffa8
	ctx.lr = 0x82CACCC4;
	sub_82C3FFA8(ctx, base);
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r11,8
	ctx.r4.s64 = ctx.r11.s64 + 8;
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// lwz r8,40(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lwz r11,4(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// andc r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// divw r3,r9,r11
	ctx.r3.s32 = ctx.r9.s32 / ctx.r11.s32;
	// twllei r11,0
	// twlgei r10,-1
	// bl 0x82c40108
	ctx.lr = 0x82CACCF8;
	sub_82C40108(ctx, base);
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82cacd28
	if (!ctx.cr6.eq) goto loc_82CACD28;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82CACD28:
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r11.u32);
loc_82CACD34:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CACD40"))) PPC_WEAK_FUNC(sub_82CACD40);
PPC_FUNC_IMPL(__imp__sub_82CACD40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,-26060
	ctx.r4.s64 = ctx.r11.s64 + -26060;
	// li r3,16
	ctx.r3.s64 = 16;
	// bl 0x82c41f78
	ctx.lr = 0x82CACD6C;
	sub_82C41F78(ctx, base);
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CACD90"))) PPC_WEAK_FUNC(sub_82CACD90);
PPC_FUNC_IMPL(__imp__sub_82CACD90) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CACD98;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	// lwz r9,96(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// lwz r30,104(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r29,100(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	// rlwinm r31,r9,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r7,r5
	ctx.r6.u64 = ctx.r7.u64 + ctx.r5.u64;
	// lwz r10,92(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// add r4,r31,r4
	ctx.r4.u64 = ctx.r31.u64 + ctx.r4.u64;
	// lwz r8,68(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r7,64(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// lwz r11,116(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CACDE8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CACDF0"))) PPC_WEAK_FUNC(sub_82CACDF0);
PPC_FUNC_IMPL(__imp__sub_82CACDF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CACDF8;
	__savegprlr_29(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 108);
	// lwz r9,96(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// lwz r30,104(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r29,100(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	// rlwinm r31,r9,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r7,r4
	ctx.r6.u64 = ctx.r7.u64 + ctx.r4.u64;
	// lwz r10,92(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// add r4,r31,r3
	ctx.r4.u64 = ctx.r31.u64 + ctx.r3.u64;
	// lwz r8,68(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r7,64(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// lwz r11,116(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 116);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CACE4C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CACE58"))) PPC_WEAK_FUNC(sub_82CACE58);
PPC_FUNC_IMPL(__imp__sub_82CACE58) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CACE68"))) PPC_WEAK_FUNC(sub_82CACE68);
PPC_FUNC_IMPL(__imp__sub_82CACE68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82CACE70;
	__savegprlr_26(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r29,1
	ctx.r29.s64 = 1;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r9,100(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// lwz r6,96(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r7,80(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// bl 0x82c55fd8
	ctx.lr = 0x82CACEB0;
	sub_82C55FD8(ctx, base);
	// lwz r8,68(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// neg r10,r8
	ctx.r10.s64 = -ctx.r8.s64;
	// blt 0x82cacec4
	if (ctx.cr0.lt) goto loc_82CACEC4;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_82CACEC4:
	// lwz r5,104(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// cmpwi r5,0
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// neg r11,r5
	ctx.r11.s64 = -ctx.r5.s64;
	// blt 0x82caced8
	if (ctx.cr0.lt) goto loc_82CACED8;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
loc_82CACED8:
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bge cr6,0x82cacf24
	if (!ctx.cr6.lt) goto loc_82CACF24;
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// lwz r10,80(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// rlwinm r6,r11,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,72(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// rlwinm r11,r10,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r5,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r5.u32);
	// lwz r31,116(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// add r6,r6,r27
	ctx.r6.u64 = ctx.r6.u64 + ctx.r27.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// add r4,r11,r30
	ctx.r4.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82CACF20;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82cacf84
	goto loc_82CACF84;
loc_82CACF24:
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// lwz r8,80(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,84(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r26,116(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// add r6,r11,r30
	ctx.r6.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// add r4,r11,r30
	ctx.r4.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mtctr r26
	ctx.ctr.u64 = ctx.r26.u64;
	// bctrl 
	ctx.lr = 0x82CACF5C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// lwz r10,104(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r7,68(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r6,80(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// bl 0x82c56078
	ctx.lr = 0x82CACF84;
	sub_82C56078(ctx, base);
loc_82CACF84:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CACF90"))) PPC_WEAK_FUNC(sub_82CACF90);
PPC_FUNC_IMPL(__imp__sub_82CACF90) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82CACF98;
	__savegprlr_26(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// lwz r6,68(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// cmpwi r6,0
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// neg r9,r6
	ctx.r9.s64 = -ctx.r6.s64;
	// blt 0x82cacfc4
	if (ctx.cr0.lt) goto loc_82CACFC4;
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
loc_82CACFC4:
	// lwz r11,100(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// neg r10,r11
	ctx.r10.s64 = -ctx.r11.s64;
	// blt 0x82cacfd8
	if (ctx.cr0.lt) goto loc_82CACFD8;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82CACFD8:
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// li r29,1
	ctx.r29.s64 = 1;
	// bge cr6,0x82cad02c
	if (!ctx.cr6.lt) goto loc_82CAD02C;
	// lwz r8,108(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// rlwinm r5,r8,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// lwz r9,72(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// add r6,r5,r3
	ctx.r6.u64 = ctx.r5.u64 + ctx.r3.u64;
	// lwz r26,116(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// add r4,r11,r30
	ctx.r4.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mtctr r26
	ctx.ctr.u64 = ctx.r26.u64;
	// bctrl 
	ctx.lr = 0x82CAD028;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82cad08c
	goto loc_82CAD08C;
loc_82CAD02C:
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r7,80(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c55fd8
	ctx.lr = 0x82CAD04C;
	sub_82C55FD8(ctx, base);
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r8,80(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,84(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// add r6,r11,r30
	ctx.r6.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r26,116(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// add r4,r11,r30
	ctx.r4.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mtctr r26
	ctx.ctr.u64 = ctx.r26.u64;
	// bctrl 
	ctx.lr = 0x82CAD08C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82CAD08C:
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r10,104(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// lwz r7,96(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r6,80(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// bl 0x82c56078
	ctx.lr = 0x82CAD0B4;
	sub_82C56078(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAD0C0"))) PPC_WEAK_FUNC(sub_82CAD0C0);
PPC_FUNC_IMPL(__imp__sub_82CAD0C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b4
	ctx.lr = 0x82CAD0C8;
	__savegprlr_23(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r24,r6
	ctx.r24.u64 = ctx.r6.u64;
	// lwz r11,88(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// lwz r23,92(r30)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r31,r10,2
	ctx.r31.s64 = ctx.r10.s64 + 2;
	// mullw r11,r31,r11
	ctx.r11.s64 = int64_t(ctx.r31.s32) * int64_t(ctx.r11.s32);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82c3fd60
	ctx.lr = 0x82CAD0FC;
	sub_82C3FD60(ctx, base);
	// subf. r25,r31,r23
	ctx.r25.s64 = ctx.r23.s64 - ctx.r31.s64;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r29,0
	ctx.r29.s64 = 0;
	// ble 0x82cad154
	if (!ctx.cr0.gt) goto loc_82CAD154;
loc_82CAD10C:
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r24
	ctx.ctr.u64 = ctx.r24.u64;
	// bctrl 
	ctx.lr = 0x82CAD128;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,100(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	// lwz r10,104(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 104);
	// add r29,r29,r31
	ctx.r29.u64 = ctx.r29.u64 + ctx.r31.u64;
	// mullw r11,r11,r31
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r31.s32);
	// mullw r9,r10,r31
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r31.s32);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpw cr6,r29,r25
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r25.s32, ctx.xer);
	// add r28,r10,r28
	ctx.r28.u64 = ctx.r10.u64 + ctx.r28.u64;
	// add r27,r11,r27
	ctx.r27.u64 = ctx.r11.u64 + ctx.r27.u64;
	// blt cr6,0x82cad10c
	if (ctx.cr6.lt) goto loc_82CAD10C;
loc_82CAD154:
	// subf r7,r29,r23
	ctx.r7.s64 = ctx.r23.s64 - ctx.r29.s64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r24
	ctx.ctr.u64 = ctx.r24.u64;
	// bctrl 
	ctx.lr = 0x82CAD170;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c3fdb8
	ctx.lr = 0x82CAD178;
	sub_82C3FDB8(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c504
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAD180"))) PPC_WEAK_FUNC(sub_82CAD180);
PPC_FUNC_IMPL(__imp__sub_82CAD180) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r6,r11,-12696
	ctx.r6.s64 = ctx.r11.s64 + -12696;
	// b 0x82cad0c0
	sub_82CAD0C0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAD190"))) PPC_WEAK_FUNC(sub_82CAD190);
PPC_FUNC_IMPL(__imp__sub_82CAD190) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r6,r11,-12400
	ctx.r6.s64 = ctx.r11.s64 + -12400;
	// b 0x82cad0c0
	sub_82CAD0C0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAD1A0"))) PPC_WEAK_FUNC(sub_82CAD1A0);
PPC_FUNC_IMPL(__imp__sub_82CAD1A0) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAD1A8"))) PPC_WEAK_FUNC(sub_82CAD1A8);
PPC_FUNC_IMPL(__imp__sub_82CAD1A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82CAD1B0;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,120(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 120);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r30,92(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 92);
	// lwz r29,88(r3)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 88);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// beq cr6,0x82cad218
	if (ctx.cr6.eq) goto loc_82CAD218;
	// lwz r28,80(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 80);
	// lwz r27,4(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// bl 0x82c53578
	ctx.lr = 0x82CAD1E8;
	sub_82C53578(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r11,20500
	ctx.r4.s64 = ctx.r11.s64 + 20500;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAD214;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82cad250
	goto loc_82CAD250;
loc_82CAD218:
	// lwz r28,4(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// bl 0x82c53578
	ctx.lr = 0x82CAD224;
	sub_82C53578(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r11,r11,20500
	ctx.r11.s64 = ctx.r11.s64 + 20500;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,40
	ctx.r4.s64 = ctx.r11.s64 + 40;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAD250;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82CAD250:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAD258"))) PPC_WEAK_FUNC(sub_82CAD258);
PPC_FUNC_IMPL(__imp__sub_82CAD258) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82cad270
	if (ctx.cr6.eq) goto loc_82CAD270;
	// cmpwi cr6,r3,4
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 4, ctx.xer);
	// beq cr6,0x82cad270
	if (ctx.cr6.eq) goto loc_82CAD270;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
loc_82CAD270:
	// mullw r3,r11,r5
	ctx.r3.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r5.s32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAD278"))) PPC_WEAK_FUNC(sub_82CAD278);
PPC_FUNC_IMPL(__imp__sub_82CAD278) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82cad324
	if (!ctx.cr6.eq) goto loc_82CAD324;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bgt cr6,0x82cad324
	if (ctx.cr6.gt) goto loc_82CAD324;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82cad324
	if (!ctx.cr6.eq) goto loc_82CAD324;
	// lwz r11,40(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82cad324
	if (!ctx.cr6.eq) goto loc_82CAD324;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82c529f8
	ctx.lr = 0x82CAD2E4;
	sub_82C529F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cad324
	if (ctx.cr0.eq) goto loc_82CAD324;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82cad31c
	if (!ctx.cr6.eq) goto loc_82CAD31C;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82cad31c
	if (ctx.cr6.eq) goto loc_82CAD31C;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82c55450
	ctx.lr = 0x82CAD314;
	sub_82C55450(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cad324
	if (ctx.cr0.eq) goto loc_82CAD324;
loc_82CAD31C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82cad328
	goto loc_82CAD328;
loc_82CAD324:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CAD328:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAD340"))) PPC_WEAK_FUNC(sub_82CAD340);
PPC_FUNC_IMPL(__imp__sub_82CAD340) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r30,8(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82cad400
	if (!ctx.cr6.eq) goto loc_82CAD400;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bgt cr6,0x82cad400
	if (ctx.cr6.gt) goto loc_82CAD400;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82cad400
	if (!ctx.cr6.eq) goto loc_82CAD400;
	// lwz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82cad400
	if (!ctx.cr6.eq) goto loc_82CAD400;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82c529f8
	ctx.lr = 0x82CAD3B0;
	sub_82C529F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cad400
	if (ctx.cr0.eq) goto loc_82CAD400;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// rlwinm r30,r11,0,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82cad3f8
	if (!ctx.cr6.eq) goto loc_82CAD3F8;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82c55450
	ctx.lr = 0x82CAD3E0;
	sub_82C55450(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82cad3f8
	if (!ctx.cr0.eq) goto loc_82CAD3F8;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r30,2
	ctx.r11.s64 = ctx.r30.s64 + 2;
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bgt cr6,0x82cad400
	if (ctx.cr6.gt) goto loc_82CAD400;
loc_82CAD3F8:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82cad404
	goto loc_82CAD404;
loc_82CAD400:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CAD404:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAD420"))) PPC_WEAK_FUNC(sub_82CAD420);
PPC_FUNC_IMPL(__imp__sub_82CAD420) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82CAD428;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82cad450
	if (ctx.cr6.eq) goto loc_82CAD450;
	// bl 0x82cad340
	ctx.lr = 0x82CAD444;
	sub_82CAD340(ctx, base);
loc_82CAD444:
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82cad458
	if (!ctx.cr0.eq) goto loc_82CAD458;
	// b 0x82cad614
	goto loc_82CAD614;
loc_82CAD450:
	// bl 0x82cad278
	ctx.lr = 0x82CAD454;
	sub_82CAD278(ctx, base);
	// b 0x82cad444
	goto loc_82CAD444;
loc_82CAD458:
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt 0x82cad49c
	if (ctx.cr0.lt) goto loc_82CAD49C;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bgt cr6,0x82cad49c
	if (ctx.cr6.gt) goto loc_82CAD49C;
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r26,8(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r30,12(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// beq cr6,0x82cad490
	if (ctx.cr6.eq) goto loc_82CAD490;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-11904
	ctx.r5.s64 = ctx.r11.s64 + -11904;
	// b 0x82cad4c8
	goto loc_82CAD4C8;
loc_82CAD490:
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-12912
	ctx.r5.s64 = ctx.r11.s64 + -12912;
	// b 0x82cad4c8
	goto loc_82CAD4C8;
loc_82CAD49C:
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r26,12(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r30,8(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// beq cr6,0x82cad4c0
	if (ctx.cr6.eq) goto loc_82CAD4C0;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-11888
	ctx.r5.s64 = ctx.r11.s64 + -11888;
	// b 0x82cad4c8
	goto loc_82CAD4C8;
loc_82CAD4C0:
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-12816
	ctx.r5.s64 = ctx.r11.s64 + -12816;
loc_82CAD4C8:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r3,128
	ctx.r3.s64 = 128;
	// addi r4,r11,-26048
	ctx.r4.s64 = ctx.r11.s64 + -26048;
	// bl 0x82c53a60
	ctx.lr = 0x82CAD4D8;
	sub_82C53A60(ctx, base);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r10,12(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// rlwinm r9,r26,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 1) & 0xFFFFFFFE;
	// neg r8,r30
	ctx.r8.s64 = -ctx.r30.s64;
	// lwz r28,4(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r10.u32);
	// stw r26,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r26.u32);
	// stw r9,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r9.u32);
	// stw r30,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r30.u32);
	// stw r8,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r8.u32);
	// stw r28,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r28.u32);
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cad520
	if (ctx.cr0.eq) goto loc_82CAD520;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// addi r11,r28,-1
	ctx.r11.s64 = ctx.r28.s64 + -1;
	// bne cr6,0x82cad524
	if (!ctx.cr6.eq) goto loc_82CAD524;
loc_82CAD520:
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
loc_82CAD524:
	// mullw r11,r11,r30
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// addi r10,r28,3
	ctx.r10.s64 = ctx.r28.s64 + 3;
	// stw r11,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r11.u32);
	// rlwinm r11,r10,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// neg r9,r11
	ctx.r9.s64 = -ctx.r11.s64;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// stw r10,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r10.u32);
	// stw r9,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r9.u32);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82cad564
	if (ctx.cr0.eq) goto loc_82CAD564;
	// cmpwi cr6,r10,4
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 4, ctx.xer);
	// addi r10,r28,-1
	ctx.r10.s64 = ctx.r28.s64 + -1;
	// bne cr6,0x82cad568
	if (!ctx.cr6.eq) goto loc_82CAD568;
loc_82CAD564:
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
loc_82CAD568:
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// addi r30,r31,92
	ctx.r30.s64 = ctx.r31.s64 + 92;
	// stw r11,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r11.u32);
	// lwz r3,8(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// addi r6,r31,104
	ctx.r6.s64 = ctx.r31.s64 + 104;
	// addi r5,r31,100
	ctx.r5.s64 = ctx.r31.s64 + 100;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c529f8
	ctx.lr = 0x82CAD588;
	sub_82C529F8(ctx, base);
	// addi r29,r31,8
	ctx.r29.s64 = ctx.r31.s64 + 8;
	// stw r27,120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 120, ctx.r27.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c3ffa8
	ctx.lr = 0x82CAD598;
	sub_82C3FFA8(ctx, base);
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r4,r11,8
	ctx.r4.s64 = ctx.r11.s64 + 8;
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// lwz r8,40(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lwz r11,4(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// andc r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// divw r3,r9,r11
	ctx.r3.s32 = ctx.r9.s32 / ctx.r11.s32;
	// twllei r11,0
	// twlgei r10,-1
	// bl 0x82c40108
	ctx.lr = 0x82CAD5CC;
	sub_82C40108(ctx, base);
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82cad600
	if (ctx.cr6.eq) goto loc_82CAD600;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82CAD600:
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// stw r11,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r11.u32);
loc_82CAD614:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAD620"))) PPC_WEAK_FUNC(sub_82CAD620);
PPC_FUNC_IMPL(__imp__sub_82CAD620) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CAD628;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,-26032
	ctx.r4.s64 = ctx.r11.s64 + -26032;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82c41f78
	ctx.lr = 0x82CAD648;
	sub_82C41F78(ctx, base);
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// stw r29,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r29.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAD660"))) PPC_WEAK_FUNC(sub_82CAD660);
PPC_FUNC_IMPL(__imp__sub_82CAD660) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,-26032
	ctx.r4.s64 = ctx.r11.s64 + -26032;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82c41f78
	ctx.lr = 0x82CAD68C;
	sub_82C41F78(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAD6B8"))) PPC_WEAK_FUNC(sub_82CAD6B8);
PPC_FUNC_IMPL(__imp__sub_82CAD6B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,-26032
	ctx.r4.s64 = ctx.r11.s64 + -26032;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82c41f78
	ctx.lr = 0x82CAD6E4;
	sub_82C41F78(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAD710"))) PPC_WEAK_FUNC(sub_82CAD710);
PPC_FUNC_IMPL(__imp__sub_82CAD710) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a8
	ctx.lr = 0x82CAD718;
	__savegprlr_20(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r28,84(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r26,68(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r25,72(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// cmpwi r28,0
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r27,96(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r20,100(r31)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// lwz r29,88(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// ble 0x82cad7dc
	if (!ctx.cr0.gt) goto loc_82CAD7DC;
	// srawi r9,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r11.s32 >> 1;
	// subf r11,r27,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r27.s64;
	// addze r9,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r9.s64 = temp.s64;
	// mullw r11,r11,r29
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r29.s32);
	// mullw r8,r29,r27
	ctx.r8.s64 = int64_t(ctx.r29.s32) * int64_t(ctx.r27.s32);
	// mullw r9,r9,r29
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r29.s32);
	// rlwinm r24,r11,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r8,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r22,r9,2,0,29
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r21,r10,2,0,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82CAD774:
	// lwz r11,56(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 56);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAD78C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r6,104(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r8,r20
	ctx.r8.u64 = ctx.r20.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// add r4,r24,r30
	ctx.r4.u64 = ctx.r24.u64 + ctx.r30.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r3,r23,r30
	ctx.r3.u64 = ctx.r23.u64 + ctx.r30.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82CAD7B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// add r5,r22,r30
	ctx.r5.u64 = ctx.r22.u64 + ctx.r30.u64;
	// lwz r11,56(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 56);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAD7D0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// add r30,r21,r30
	ctx.r30.u64 = ctx.r21.u64 + ctx.r30.u64;
	// bne 0x82cad774
	if (!ctx.cr0.eq) goto loc_82CAD774;
loc_82CAD7DC:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82d5c4f8
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAD7E8"))) PPC_WEAK_FUNC(sub_82CAD7E8);
PPC_FUNC_IMPL(__imp__sub_82CAD7E8) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAD7F8"))) PPC_WEAK_FUNC(sub_82CAD7F8);
PPC_FUNC_IMPL(__imp__sub_82CAD7F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c49c
	ctx.lr = 0x82CAD800;
	__savegprlr_17(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r24,r6
	ctx.r24.u64 = ctx.r6.u64;
	// mr r29,r8
	ctx.r29.u64 = ctx.r8.u64;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r21,r7
	ctx.r21.u64 = ctx.r7.u64;
	// lwz r28,88(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// li r22,1
	ctx.r22.s64 = 1;
	// lwz r30,108(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// subf r26,r24,r21
	ctx.r26.s64 = ctx.r21.s64 - ctx.r24.s64;
	// mullw r9,r28,r24
	ctx.r9.s64 = int64_t(ctx.r28.s32) * int64_t(ctx.r24.s32);
	// lwz r27,104(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// lwz r25,76(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// rlwinm r3,r30,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r20,r9,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r3,r29
	ctx.r3.u64 = ctx.r3.u64 + ctx.r29.u64;
	// add r19,r20,r11
	ctx.r19.u64 = ctx.r20.u64 + ctx.r11.u64;
	// mr r17,r5
	ctx.r17.u64 = ctx.r5.u64;
	// addi r23,r3,-4
	ctx.r23.s64 = ctx.r3.s64 + -4;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x82c55fd8
	ctx.lr = 0x82CAD874;
	sub_82C55FD8(ctx, base);
	// neg r18,r28
	ctx.r18.s64 = -ctx.r28.s64;
	// subf r20,r20,r17
	ctx.r20.s64 = ctx.r17.s64 - ctx.r20.s64;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r9,r18
	ctx.r9.u64 = ctx.r18.u64;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82c55fd8
	ctx.lr = 0x82CAD8A4;
	sub_82C55FD8(ctx, base);
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r6,108(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r8,r21
	ctx.r8.u64 = ctx.r21.u64;
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82CAD8D0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c56078
	ctx.lr = 0x82CAD8F8;
	sub_82C56078(ctx, base);
	// mr r10,r18
	ctx.r10.u64 = ctx.r18.u64;
	// li r9,-1
	ctx.r9.s64 = -1;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r20
	ctx.r4.u64 = ctx.r20.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82c56078
	ctx.lr = 0x82CAD920;
	sub_82C56078(ctx, base);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82d5c4ec
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAD928"))) PPC_WEAK_FUNC(sub_82CAD928);
PPC_FUNC_IMPL(__imp__sub_82CAD928) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c49c
	ctx.lr = 0x82CAD930;
	__savegprlr_17(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r18,68(r31)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// lwz r21,72(r31)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r28,80(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r29,84(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r22,96(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// addi r26,r10,2
	ctx.r26.s64 = ctx.r10.s64 + 2;
	// lwz r25,100(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// lwz r27,88(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mullw r11,r26,r11
	ctx.r11.s64 = int64_t(ctx.r26.s32) * int64_t(ctx.r11.s32);
	// rlwinm r3,r11,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x82c3fd60
	ctx.lr = 0x82CAD974;
	sub_82C3FD60(ctx, base);
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// ble cr6,0x82cada40
	if (!ctx.cr6.gt) goto loc_82CADA40;
	// srawi r11,r28,1
	ctx.xer.ca = (ctx.r28.s32 < 0) & ((ctx.r28.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r28.s32 >> 1;
	// mullw r10,r27,r28
	ctx.r10.s64 = int64_t(ctx.r27.s32) * int64_t(ctx.r28.s32);
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// rlwinm r17,r10,2,0,29
	ctx.r17.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// mullw r11,r11,r27
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r27.s32);
	// add r19,r26,r22
	ctx.r19.u64 = ctx.r26.u64 + ctx.r22.u64;
	// rlwinm r20,r11,2,0,29
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r24,r29
	ctx.r24.u64 = ctx.r29.u64;
loc_82CAD9A0:
	// lwz r11,56(r18)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r18.u32 + 56);
	// add r27,r17,r30
	ctx.r27.u64 = ctx.r17.u64 + ctx.r30.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAD9BC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r29,r22
	ctx.r29.u64 = ctx.r22.u64;
	// cmpw cr6,r19,r25
	ctx.cr6.compare<int32_t>(ctx.r19.s32, ctx.r25.s32, ctx.xer);
	// bge cr6,0x82cad9f8
	if (!ctx.cr6.lt) goto loc_82CAD9F8;
	// mr r28,r19
	ctx.r28.u64 = ctx.r19.u64;
loc_82CAD9CC:
	// mr r8,r23
	ctx.r8.u64 = ctx.r23.u64;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cad7f8
	ctx.lr = 0x82CAD9E8;
	sub_82CAD7F8(ctx, base);
	// add r28,r28,r26
	ctx.r28.u64 = ctx.r28.u64 + ctx.r26.u64;
	// add r29,r29,r26
	ctx.r29.u64 = ctx.r29.u64 + ctx.r26.u64;
	// cmpw cr6,r28,r25
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r25.s32, ctx.xer);
	// blt cr6,0x82cad9cc
	if (ctx.cr6.lt) goto loc_82CAD9CC;
loc_82CAD9F8:
	// mr r8,r23
	ctx.r8.u64 = ctx.r23.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cad7f8
	ctx.lr = 0x82CADA14;
	sub_82CAD7F8(ctx, base);
	// add r5,r20,r30
	ctx.r5.u64 = ctx.r20.u64 + ctx.r30.u64;
	// lwz r11,56(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 56);
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CADA2C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addic. r24,r24,-1
	ctx.xer.ca = ctx.r24.u32 > 0;
	ctx.r24.s64 = ctx.r24.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// bne 0x82cad9a0
	if (!ctx.cr0.eq) goto loc_82CAD9A0;
loc_82CADA40:
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82c3fdb8
	ctx.lr = 0x82CADA48;
	sub_82C3FDB8(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82d5c4ec
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CADA50"))) PPC_WEAK_FUNC(sub_82CADA50);
PPC_FUNC_IMPL(__imp__sub_82CADA50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82c3fc78
	ctx.lr = 0x82CADA74;
	sub_82C3FC78(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// bl 0x82c3fc78
	ctx.lr = 0x82CADA80;
	sub_82C3FC78(ctx, base);
	// lwz r10,116(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// addi r4,r31,112
	ctx.r4.s64 = ctx.r31.s64 + 112;
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mullw r6,r7,r11
	ctx.r6.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r11.s32);
	// lwz r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// lwz r5,8(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// addze r8,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r8.s64 = temp.s64;
	// bl 0x82c540c0
	ctx.lr = 0x82CADAB0;
	sub_82C540C0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CADAC8"))) PPC_WEAK_FUNC(sub_82CADAC8);
PPC_FUNC_IMPL(__imp__sub_82CADAC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82c3fc28
	ctx.lr = 0x82CADAE4;
	sub_82C3FC28(ctx, base);
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// bl 0x82c3fc28
	ctx.lr = 0x82CADAEC;
	sub_82C3FC28(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CADB00"))) PPC_WEAK_FUNC(sub_82CADB00);
PPC_FUNC_IMPL(__imp__sub_82CADB00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82CADB08;
	__savegprlr_25(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// lwz r3,76(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r10,r3,3
	ctx.r10.s64 = ctx.r3.s64 + 3;
	// rlwinm r29,r10,0,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// beq cr6,0x82cadb84
	if (ctx.cr6.eq) goto loc_82CADB84;
	// lwz r28,72(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r27,68(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r26,4(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r25,84(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// bl 0x82c53cb0
	ctx.lr = 0x82CADB4C;
	sub_82C53CB0(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// addi r4,r11,20572
	ctx.r4.s64 = ctx.r11.s64 + 20572;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r5,r29,2
	ctx.r5.s64 = ctx.r29.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CADB80;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82cadbcc
	goto loc_82CADBCC;
loc_82CADB84:
	// lwz r29,72(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r28,68(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r27,4(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r26,84(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// bl 0x82c53cb0
	ctx.lr = 0x82CADB98;
	sub_82C53CB0(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// lwz r5,76(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r11,r11,20572
	ctx.r11.s64 = ctx.r11.s64 + 20572;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r4,r11,48
	ctx.r4.s64 = ctx.r11.s64 + 48;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CADBCC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82CADBCC:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CADBD8"))) PPC_WEAK_FUNC(sub_82CADBD8);
PPC_FUNC_IMPL(__imp__sub_82CADBD8) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r5,r10
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82cadbfc
	if (!ctx.cr6.eq) goto loc_82CADBFC;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82CADBFC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CADC08"))) PPC_WEAK_FUNC(sub_82CADC08);
PPC_FUNC_IMPL(__imp__sub_82CADC08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r5,r10
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82cadc34
	if (!ctx.cr6.eq) goto loc_82CADC34;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x82cadc3c
	if (ctx.cr6.eq) goto loc_82CADC3C;
loc_82CADC34:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82cadc74
	goto loc_82CADC74;
loc_82CADC3C:
	// lwz r11,152(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 152);
	// rlwinm. r11,r11,0,3,3
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cadc70
	if (ctx.cr0.eq) goto loc_82CADC70;
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mullw r4,r5,r6
	ctx.r4.s64 = int64_t(ctx.r5.s32) * int64_t(ctx.r6.s32);
	// subfic r11,r11,0
	ctx.xer.ca = ctx.r11.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,23,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1F0;
	// addi r3,r11,16
	ctx.r3.s64 = ctx.r11.s64 + 16;
	// bl 0x82caf6b8
	ctx.lr = 0x82CADC64;
	sub_82CAF6B8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// bne 0x82cadc74
	if (!ctx.cr0.eq) goto loc_82CADC74;
loc_82CADC70:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82CADC74:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CADC88"))) PPC_WEAK_FUNC(sub_82CADC88);
PPC_FUNC_IMPL(__imp__sub_82CADC88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c490
	ctx.lr = 0x82CADC90;
	__savegprlr_14(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r6
	ctx.r25.u64 = ctx.r6.u64;
	// lwz r18,340(r1)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// srawi r11,r25,1
	ctx.xer.ca = (ctx.r25.s32 < 0) & ((ctx.r25.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r25.s32 >> 1;
	// mr r23,r7
	ctx.r23.u64 = ctx.r7.u64;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// mr r7,r18
	ctx.r7.u64 = ctx.r18.u64;
	// lwz r22,16(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// mr r15,r9
	ctx.r15.u64 = ctx.r9.u64;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// li r27,0
	ctx.r27.s64 = 0;
	// mullw r14,r11,r23
	ctx.r14.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r23.s32);
	// mullw r21,r25,r23
	ctx.r21.s64 = int64_t(ctx.r25.s32) * int64_t(ctx.r23.s32);
	// bl 0x82cadc08
	ctx.lr = 0x82CADCD8;
	sub_82CADC08(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82cadce8
	if (!ctx.cr0.eq) goto loc_82CADCE8;
loc_82CADCE0:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82cadf20
	goto loc_82CADF20;
loc_82CADCE8:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82cadd04
	if (!ctx.cr6.eq) goto loc_82CADD04;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c42a78
	ctx.lr = 0x82CADD00;
	sub_82C42A78(ctx, base);
	// b 0x82cadd08
	goto loc_82CADD08;
loc_82CADD04:
	// bl 0x82c42a70
	ctx.lr = 0x82CADD08;
	sub_82C42A70(ctx, base);
loc_82CADD08:
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// bl 0x82c42a70
	ctx.lr = 0x82CADD10;
	sub_82C42A70(ctx, base);
	// lwz r16,332(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// mr r5,r16
	ctx.r5.u64 = ctx.r16.u64;
	// mr r6,r16
	ctx.r6.u64 = ctx.r16.u64;
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// bl 0x82c539d0
	ctx.lr = 0x82CADD2C;
	sub_82C539D0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// bl 0x82c41a30
	ctx.lr = 0x82CADD38;
	sub_82C41A30(ctx, base);
	// mr. r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// beq 0x82caddbc
	if (ctx.cr0.eq) goto loc_82CADDBC;
	// lwz r17,324(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// addi r20,r25,2
	ctx.r20.s64 = ctx.r25.s64 + 2;
	// add r11,r30,r17
	ctx.r11.u64 = ctx.r30.u64 + ctx.r17.u64;
	// rlwinm r19,r11,1,0,30
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpw cr6,r19,r20
	ctx.cr6.compare<int32_t>(ctx.r19.s32, ctx.r20.s32, ctx.xer);
	// bne cr6,0x82cadd6c
	if (!ctx.cr6.eq) goto loc_82CADD6C;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c42a78
	ctx.lr = 0x82CADD68;
	sub_82C42A78(ctx, base);
	// b 0x82cadd70
	goto loc_82CADD70;
loc_82CADD6C:
	// bl 0x82c42a70
	ctx.lr = 0x82CADD70;
	sub_82C42A70(ctx, base);
loc_82CADD70:
	// subfic r10,r31,0
	ctx.xer.ca = ctx.r31.u32 <= 0;
	ctx.r10.s64 = 0 - ctx.r31.s64;
	// rlwinm r11,r14,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r14.u32 | (ctx.r14.u64 << 32), 2) & 0xFFFFFFFC;
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// add r31,r11,r16
	ctx.r31.u64 = ctx.r11.u64 + ctx.r16.u64;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// andi. r11,r10,5
	ctx.r11.u64 = ctx.r10.u64 & 5;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// addi r16,r11,1
	ctx.r16.s64 = ctx.r11.s64 + 1;
	// bl 0x82c42a70
	ctx.lr = 0x82CADD90;
	sub_82C42A70(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r7,r16
	ctx.r7.u64 = ctx.r16.u64;
	// bl 0x82c539d0
	ctx.lr = 0x82CADDA8;
	sub_82C539D0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// bl 0x82c41a30
	ctx.lr = 0x82CADDB4;
	sub_82C41A30(ctx, base);
	// mr. r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// bne 0x82caddd0
	if (!ctx.cr0.eq) goto loc_82CADDD0;
loc_82CADDBC:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c3fc28
	ctx.lr = 0x82CADDC4;
	sub_82C3FC28(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82c3fc28
	ctx.lr = 0x82CADDCC;
	sub_82C3FC28(ctx, base);
	// b 0x82cadce0
	goto loc_82CADCE0;
loc_82CADDD0:
	// lwz r11,24(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82cadde8
	if (ctx.cr6.eq) goto loc_82CADDE8;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-9944
	ctx.r5.s64 = ctx.r11.s64 + -9944;
	// b 0x82caddf0
	goto loc_82CADDF0;
loc_82CADDE8:
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-10480
	ctx.r5.s64 = ctx.r11.s64 + -10480;
loc_82CADDF0:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// li r3,120
	ctx.r3.s64 = 120;
	// addi r4,r11,-26020
	ctx.r4.s64 = ctx.r11.s64 + -26020;
	// bl 0x82c54630
	ctx.lr = 0x82CADE00;
	sub_82C54630(ctx, base);
	// subf r11,r19,r20
	ctx.r11.s64 = ctx.r20.s64 - ctx.r19.s64;
	// addi r10,r26,3
	ctx.r10.s64 = ctx.r26.s64 + 3;
	// lwz r9,20(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// cntlzw r8,r11
	ctx.r8.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// rlwinm r11,r10,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// cntlzw r10,r30
	ctx.r10.u64 = ctx.r30.u32 == 0 ? 32 : __builtin_clz(ctx.r30.u32);
	// addi r7,r11,2
	ctx.r7.s64 = ctx.r11.s64 + 2;
	// subf r11,r8,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r8.s64;
	// stw r9,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r9.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// stw r26,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r26.u32);
	// rlwinm r8,r7,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r21,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r21.u32);
	// add r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 + ctx.r30.u64;
	// stw r25,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r25.u32);
	// add r11,r11,r17
	ctx.r11.u64 = ctx.r11.u64 + ctx.r17.u64;
	// stw r23,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r23.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r28,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r28.u32);
	// addi r30,r31,8
	ctx.r30.s64 = ctx.r31.s64 + 8;
	// stw r15,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r15.u32);
	// stw r29,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r29.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r8,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r8.u32);
	// stw r24,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r24.u32);
	// stw r9,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r9.u32);
	// stw r27,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r27.u32);
	// stw r10,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r10.u32);
	// stw r11,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r11.u32);
	// bl 0x82c3ffa8
	ctx.lr = 0x82CADE80;
	sub_82C3FFA8(ctx, base);
	// lwz r11,100(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r10,96(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// addi r4,r22,16
	ctx.r4.s64 = ctx.r22.s64 + 16;
	// lwz r9,12(r22)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r22.u32 + 12);
	// subf r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rotlwi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 1);
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// divw r10,r10,r9
	ctx.r10.s32 = ctx.r10.s32 / ctx.r9.s32;
	// andc r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 & ~ctx.r11.u64;
	// mullw r3,r10,r28
	ctx.r3.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r28.s32);
	// twllei r9,0
	// twlgei r11,-1
	// bl 0x82c40108
	ctx.lr = 0x82CADEBC;
	sub_82C40108(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r24,8
	ctx.r4.s64 = ctx.r24.s64 + 8;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82c40108
	ctx.lr = 0x82CADECC;
	sub_82C40108(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r27,8
	ctx.r4.s64 = ctx.r27.s64 + 8;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82c40108
	ctx.lr = 0x82CADEDC;
	sub_82C40108(ctx, base);
	// lwz r11,24(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82cadf1c
	if (ctx.cr6.eq) goto loc_82CADF1C;
	// lwz r11,100(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// lwz r10,96(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// mullw r11,r11,r26
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r26.s32);
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82CADF1C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82CADF20:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82d5c4e0
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CADF28"))) PPC_WEAK_FUNC(sub_82CADF28);
PPC_FUNC_IMPL(__imp__sub_82CADF28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CADF30;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r3,28
	ctx.r3.s64 = 28;
	// addi r5,r11,-9080
	ctx.r5.s64 = ctx.r11.s64 + -9080;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// bl 0x82c545e8
	ctx.lr = 0x82CADF58;
	sub_82C545E8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,20(r4)
	PPC_STORE_U32(ctx.r4.u32 + 20, ctx.r29.u32);
	// stw r31,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r31.u32);
	// stw r28,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r28.u32);
	// bl 0x82c42018
	ctx.lr = 0x82CADF70;
	sub_82C42018(ctx, base);
	// lis r11,-31979
	ctx.r11.s64 = -2095775744;
	// lwz r10,-27220(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27220);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82cadfb4
	if (ctx.cr6.eq) goto loc_82CADFB4;
	// lis r10,-32053
	ctx.r10.s64 = -2100625408;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,-27220(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27220);
	// li r3,28
	ctx.r3.s64 = 28;
	// addi r5,r10,-9080
	ctx.r5.s64 = ctx.r10.s64 + -9080;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CADF9C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,20(r4)
	PPC_STORE_U32(ctx.r4.u32 + 20, ctx.r29.u32);
	// stw r31,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r31.u32);
	// stw r28,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r28.u32);
	// bl 0x82c42018
	ctx.lr = 0x82CADFB4;
	sub_82C42018(ctx, base);
loc_82CADFB4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CADFC0"))) PPC_WEAK_FUNC(sub_82CADFC0);
PPC_FUNC_IMPL(__imp__sub_82CADFC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CADFC8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82cadf28
	ctx.lr = 0x82CADFE0;
	sub_82CADF28(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cadf28
	ctx.lr = 0x82CADFF4;
	sub_82CADF28(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE000"))) PPC_WEAK_FUNC(sub_82CAE000);
PPC_FUNC_IMPL(__imp__sub_82CAE000) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,100(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 100);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r8,92(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 92);
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// lwz r10,84(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 84);
	// lwz r9,96(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 96);
	// lwz r7,76(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 76);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mullw r11,r10,r8
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
	// lwz r6,72(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 72);
	// lwz r30,64(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 64);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// add r3,r11,r31
	ctx.r3.u64 = ctx.r11.u64 + ctx.r31.u64;
	// mtctr r30
	ctx.ctr.u64 = ctx.r30.u64;
	// bctrl 
	ctx.lr = 0x82CAE054;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAE070"))) PPC_WEAK_FUNC(sub_82CAE070);
PPC_FUNC_IMPL(__imp__sub_82CAE070) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r4,r11,100
	ctx.r4.s64 = ctx.r11.s64 + 100;
	// lwz r8,80(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	// lwz r7,68(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r11,104(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// mullw r6,r7,r8
	ctx.r6.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r8.s32);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// b 0x82c540c0
	sub_82C540C0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE098"))) PPC_WEAK_FUNC(sub_82CAE098);
PPC_FUNC_IMPL(__imp__sub_82CAE098) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAE0A0"))) PPC_WEAK_FUNC(sub_82CAE0A0);
PPC_FUNC_IMPL(__imp__sub_82CAE0A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CAE0A8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,104(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// lwz r29,88(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r28,4(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82c53cb0
	ctx.lr = 0x82CAE0D0;
	sub_82C53CB0(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// lwz r5,68(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r4,r11,20660
	ctx.r4.s64 = ctx.r11.s64 + 20660;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAE0F8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE100"))) PPC_WEAK_FUNC(sub_82CAE100);
PPC_FUNC_IMPL(__imp__sub_82CAE100) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,24(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpw cr6,r4,r10
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82cae180
	if (!ctx.cr6.eq) goto loc_82CAE180;
	// cmpw cr6,r4,r9
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82cae180
	if (!ctx.cr6.eq) goto loc_82CAE180;
	// lwz r10,196(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// cmpw cr6,r5,r10
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82cae180
	if (!ctx.cr6.eq) goto loc_82CAE180;
	// cmpw cr6,r11,r6
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r6.s32, ctx.xer);
	// bne cr6,0x82cae180
	if (!ctx.cr6.eq) goto loc_82CAE180;
	// lwz r6,12(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r10,236(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// lwz r9,204(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// lwz r4,220(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// lwz r10,212(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// lwz r5,228(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAE174;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne 0x82cae184
	if (!ctx.cr0.eq) goto loc_82CAE184;
loc_82CAE180:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CAE184:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAE198"))) PPC_WEAK_FUNC(sub_82CAE198);
PPC_FUNC_IMPL(__imp__sub_82CAE198) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a4
	ctx.lr = 0x82CAE1A0;
	__savegprlr_19(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,364(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r20,332(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// lwz r28,340(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// mr r24,r7
	ctx.r24.u64 = ctx.r7.u64;
	// add r19,r20,r28
	ctx.r19.u64 = ctx.r20.u64 + ctx.r28.u64;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r11.u32);
	// mr r23,r8
	ctx.r23.u64 = ctx.r8.u64;
	// lwz r11,356(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// mr r22,r9
	ctx.r22.u64 = ctx.r9.u64;
	// lwz r27,24(r30)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// mr r21,r10
	ctx.r21.u64 = ctx.r10.u64;
	// stw r20,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r20.u32);
	// stw r19,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r19.u32);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// lwz r11,348(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,324(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82cae100
	ctx.lr = 0x82CAE1FC;
	sub_82CAE100(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cae290
	if (ctx.cr0.eq) goto loc_82CAE290;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r5,r11,-8192
	ctx.r5.s64 = ctx.r11.s64 + -8192;
	// addi r4,r10,-26004
	ctx.r4.s64 = ctx.r10.s64 + -26004;
	// li r3,112
	ctx.r3.s64 = 112;
	// bl 0x82c933f0
	ctx.lr = 0x82CAE21C;
	sub_82C933F0(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r29,r31,8
	ctx.r29.s64 = ctx.r31.s64 + 8;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r25,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r25.u32);
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
	// stw r21,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r21.u32);
	// stw r10,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r10.u32);
	// stw r26,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r26.u32);
	// stw r24,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r24.u32);
	// stw r23,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r23.u32);
	// stw r22,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r22.u32);
	// stw r20,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r20.u32);
	// stw r19,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r19.u32);
	// stw r30,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r30.u32);
	// bl 0x82c3ffa8
	ctx.lr = 0x82CAE260;
	sub_82C3FFA8(ctx, base);
	// lwz r10,12(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// rotlwi r11,r28,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r28.u32, 1);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r4,r27,16
	ctx.r4.s64 = ctx.r27.s64 + 16;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// andc r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// divw r3,r28,r10
	ctx.r3.s32 = ctx.r28.s32 / ctx.r10.s32;
	// twllei r10,0
	// twlgei r11,-1
	// bl 0x82c40108
	ctx.lr = 0x82CAE28C;
	sub_82C40108(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82CAE290:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82d5c4f4
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE298"))) PPC_WEAK_FUNC(sub_82CAE298);
PPC_FUNC_IMPL(__imp__sub_82CAE298) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CAE2A0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-7784
	ctx.r6.s64 = ctx.r11.s64 + -7784;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r3,32
	ctx.r3.s64 = 32;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c933b0
	ctx.lr = 0x82CAE2D0;
	sub_82C933B0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, ctx.r29.u32);
	// stw r31,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r31.u32);
	// bl 0x82c42018
	ctx.lr = 0x82CAE2E4;
	sub_82C42018(ctx, base);
	// lis r11,-31979
	ctx.r11.s64 = -2095775744;
	// lwz r10,-27216(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27216);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82cae32c
	if (ctx.cr6.eq) goto loc_82CAE32C;
	// lis r10,-32053
	ctx.r10.s64 = -2100625408;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,-27216(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27216);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r10,-7784
	ctx.r6.s64 = ctx.r10.s64 + -7784;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r3,32
	ctx.r3.s64 = 32;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAE318;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, ctx.r29.u32);
	// stw r31,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r31.u32);
	// bl 0x82c42018
	ctx.lr = 0x82CAE32C;
	sub_82C42018(ctx, base);
loc_82CAE32C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE338"))) PPC_WEAK_FUNC(sub_82CAE338);
PPC_FUNC_IMPL(__imp__sub_82CAE338) {
	PPC_FUNC_PROLOGUE();
	// addi r6,r6,2
	ctx.r6.s64 = ctx.r6.s64 + 2;
	// b 0x82cae298
	sub_82CAE298(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE340"))) PPC_WEAK_FUNC(sub_82CAE340);
PPC_FUNC_IMPL(__imp__sub_82CAE340) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CAE348;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82cae3bc
	if (!ctx.cr6.gt) goto loc_82CAE3BC;
loc_82CAE368:
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// lwz r7,92(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r9,80(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r8,96(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r6,72(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mullw r11,r9,r7
	ctx.r11.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r7.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// add r4,r11,r28
	ctx.r4.u64 = ctx.r11.u64 + ctx.r28.u64;
	// add r3,r11,r29
	ctx.r3.u64 = ctx.r11.u64 + ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82CAE39C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// lwz r10,84(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpw cr6,r30,r10
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r10.s32, ctx.xer);
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// add r28,r11,r28
	ctx.r28.u64 = ctx.r11.u64 + ctx.r28.u64;
	// blt cr6,0x82cae368
	if (ctx.cr6.lt) goto loc_82CAE368;
loc_82CAE3BC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE3C8"))) PPC_WEAK_FUNC(sub_82CAE3C8);
PPC_FUNC_IMPL(__imp__sub_82CAE3C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82CAE3D0;
	__savegprlr_21(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r29,84(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r10,96(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmpwi r29,0
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// lwz r22,92(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addi r30,r10,-1
	ctx.r30.s64 = ctx.r10.s64 + -1;
	// lwz r26,80(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// ble 0x82cae480
	if (!ctx.cr0.gt) goto loc_82CAE480;
	// mullw r10,r26,r22
	ctx.r10.s64 = int64_t(ctx.r26.s32) * int64_t(ctx.r22.s32);
	// mullw r9,r26,r30
	ctx.r9.s64 = int64_t(ctx.r26.s32) * int64_t(ctx.r30.s32);
	// rlwinm r25,r10,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r21,r30,2
	ctx.r21.s64 = ctx.r30.s64 + 2;
	// rlwinm r24,r9,2,0,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r23,r11,2,0,29
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_82CAE418:
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
	// lwz r6,72(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// add r4,r25,r27
	ctx.r4.u64 = ctx.r25.u64 + ctx.r27.u64;
	// add r3,r25,r28
	ctx.r3.u64 = ctx.r25.u64 + ctx.r28.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82CAE444;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// lwz r6,72(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r8,r21
	ctx.r8.u64 = ctx.r21.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// add r4,r24,r27
	ctx.r4.u64 = ctx.r24.u64 + ctx.r27.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r3,r24,r28
	ctx.r3.u64 = ctx.r24.u64 + ctx.r28.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82CAE470;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// add r28,r23,r28
	ctx.r28.u64 = ctx.r23.u64 + ctx.r28.u64;
	// add r27,r23,r27
	ctx.r27.u64 = ctx.r23.u64 + ctx.r27.u64;
	// bne 0x82cae418
	if (!ctx.cr0.eq) goto loc_82CAE418;
loc_82CAE480:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE488"))) PPC_WEAK_FUNC(sub_82CAE488);
PPC_FUNC_IMPL(__imp__sub_82CAE488) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a8
	ctx.lr = 0x82CAE490;
	__savegprlr_20(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r8
	ctx.r30.u64 = ctx.r8.u64;
	// mr r26,r7
	ctx.r26.u64 = ctx.r7.u64;
	// lwz r28,80(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// li r20,2
	ctx.r20.s64 = 2;
	// lwz r25,72(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// subf r24,r29,r26
	ctx.r24.s64 = ctx.r26.s64 - ctx.r29.s64;
	// mullw r11,r28,r29
	ctx.r11.s64 = int64_t(ctx.r28.s32) * int64_t(ctx.r29.s32);
	// lwz r23,104(r31)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// lwz r7,68(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// stw r20,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r20.u32);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r27,r30,4
	ctx.r27.s64 = ctx.r30.s64 + 4;
	// add r22,r11,r3
	ctx.r22.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r21,r11,r4
	ctx.r21.u64 = ctx.r11.u64 + ctx.r4.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r9,r23
	ctx.r9.u64 = ctx.r23.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x82c92ce0
	ctx.lr = 0x82CAE4FC;
	sub_82C92CE0(ctx, base);
	// lwz r11,108(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// lwz r6,104(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// li r9,2
	ctx.r9.s64 = 2;
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82CAE528;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// lwz r7,68(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r28.u32);
	// mr r8,r23
	ctx.r8.u64 = ctx.r23.u64;
	// stw r20,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r20.u32);
	// mr r6,r22
	ctx.r6.u64 = ctx.r22.u64;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c92d70
	ctx.lr = 0x82CAE554;
	sub_82C92D70(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82d5c4f8
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE560"))) PPC_WEAK_FUNC(sub_82CAE560);
PPC_FUNC_IMPL(__imp__sub_82CAE560) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAE570"))) PPC_WEAK_FUNC(sub_82CAE570);
PPC_FUNC_IMPL(__imp__sub_82CAE570) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82CAE578;
	__savegprlr_21(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r30,84(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// lwz r22,92(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r25,96(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r26,r10,2
	ctx.r26.s64 = ctx.r10.s64 + 2;
	// mullw r11,r26,r11
	ctx.r11.s64 = int64_t(ctx.r26.s32) * int64_t(ctx.r11.s32);
	// rlwinm r3,r11,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x82c3fd60
	ctx.lr = 0x82CAE5B0;
	sub_82C3FD60(ctx, base);
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82cae634
	if (!ctx.cr6.gt) goto loc_82CAE634;
	// add r21,r22,r26
	ctx.r21.u64 = ctx.r22.u64 + ctx.r26.u64;
	// mr r23,r30
	ctx.r23.u64 = ctx.r30.u64;
loc_82CAE5C4:
	// mr r29,r22
	ctx.r29.u64 = ctx.r22.u64;
	// cmpw cr6,r21,r25
	ctx.cr6.compare<int32_t>(ctx.r21.s32, ctx.r25.s32, ctx.xer);
	// bge cr6,0x82cae600
	if (!ctx.cr6.lt) goto loc_82CAE600;
	// mr r30,r21
	ctx.r30.u64 = ctx.r21.u64;
loc_82CAE5D4:
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cae488
	ctx.lr = 0x82CAE5F0;
	sub_82CAE488(ctx, base);
	// add r30,r30,r26
	ctx.r30.u64 = ctx.r30.u64 + ctx.r26.u64;
	// add r29,r29,r26
	ctx.r29.u64 = ctx.r29.u64 + ctx.r26.u64;
	// cmpw cr6,r30,r25
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r25.s32, ctx.xer);
	// blt cr6,0x82cae5d4
	if (ctx.cr6.lt) goto loc_82CAE5D4;
loc_82CAE600:
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82cae488
	ctx.lr = 0x82CAE61C;
	sub_82CAE488(ctx, base);
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r11,r28
	ctx.r28.u64 = ctx.r11.u64 + ctx.r28.u64;
	// add r27,r11,r27
	ctx.r27.u64 = ctx.r11.u64 + ctx.r27.u64;
	// bne 0x82cae5c4
	if (!ctx.cr0.eq) goto loc_82CAE5C4;
loc_82CAE634:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c3fdb8
	ctx.lr = 0x82CAE63C;
	sub_82C3FDB8(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE648"))) PPC_WEAK_FUNC(sub_82CAE648);
PPC_FUNC_IMPL(__imp__sub_82CAE648) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r4,r11,108
	ctx.r4.s64 = ctx.r11.s64 + 108;
	// lwz r9,112(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 112);
	// lwz r10,76(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// lwz r7,68(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r11,100(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	// mullw r6,r7,r10
	ctx.r6.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r10.s32);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// lwz r5,8(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// add r8,r11,r10
	ctx.r8.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82c540c0
	sub_82C540C0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE678"))) PPC_WEAK_FUNC(sub_82CAE678);
PPC_FUNC_IMPL(__imp__sub_82CAE678) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAE680"))) PPC_WEAK_FUNC(sub_82CAE680);
PPC_FUNC_IMPL(__imp__sub_82CAE680) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82CAE688;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// beq cr6,0x82cae6f4
	if (ctx.cr6.eq) goto loc_82CAE6F4;
	// lwz r28,4(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// lwz r27,84(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// rlwinm r29,r11,0,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x82c53cb0
	ctx.lr = 0x82CAE6C4;
	sub_82C53CB0(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// lwz r6,68(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// addi r4,r11,20692
	ctx.r4.s64 = ctx.r11.s64 + 20692;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r5,r29,2
	ctx.r5.s64 = ctx.r29.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAE6F0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82cae72c
	goto loc_82CAE72C;
loc_82CAE6F4:
	// lwz r29,4(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r28,84(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// bl 0x82c53cb0
	ctx.lr = 0x82CAE700;
	sub_82C53CB0(ctx, base);
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// lwz r5,68(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r11,r11,20692
	ctx.r11.s64 = ctx.r11.s64 + 20692;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r4,r11,36
	ctx.r4.s64 = ctx.r11.s64 + 36;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAE72C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82CAE72C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE738"))) PPC_WEAK_FUNC(sub_82CAE738);
PPC_FUNC_IMPL(__imp__sub_82CAE738) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82CAE740;
	__savegprlr_21(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,24(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82cae8bc
	if (!ctx.cr6.eq) goto loc_82CAE8BC;
	// cmpw cr6,r5,r6
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r6.s32, ctx.xer);
	// bne cr6,0x82cae8bc
	if (!ctx.cr6.eq) goto loc_82CAE8BC;
	// lwz r11,276(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82cae8bc
	if (!ctx.cr6.eq) goto loc_82CAE8BC;
	// lwz r21,324(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r26,316(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// lwz r27,292(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r22,284(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lwz r25,308(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// stw r11,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r11.u32);
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// lwz r24,300(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAE7CC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82cae870
	if (!ctx.cr0.eq) goto loc_82CAE870;
	// li r11,1
	ctx.r11.s64 = 1;
	// cmpwi cr6,r22,0
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// stw r11,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r11.u32);
	// bne cr6,0x82cae8bc
	if (!ctx.cr6.eq) goto loc_82CAE8BC;
	// cmpw cr6,r27,r29
	ctx.cr6.compare<int32_t>(ctx.r27.s32, ctx.r29.s32, ctx.xer);
	// bne cr6,0x82cae8bc
	if (!ctx.cr6.eq) goto loc_82CAE8BC;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r23,r27,-1
	ctx.r23.s64 = ctx.r27.s64 + -1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAE828;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cae8bc
	if (ctx.cr0.eq) goto loc_82CAE8BC;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r10,r27,1
	ctx.r10.s64 = ctx.r27.s64 + 1;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// mr r9,r23
	ctx.r9.u64 = ctx.r23.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAE868;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cae8bc
	if (ctx.cr0.eq) goto loc_82CAE8BC;
loc_82CAE870:
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// rlwinm r11,r30,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// subf r10,r10,r27
	ctx.r10.s64 = ctx.r27.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r29,0(r6)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// add r5,r11,r25
	ctx.r5.u64 = ctx.r11.u64 + ctx.r25.u64;
	// add r4,r11,r24
	ctx.r4.u64 = ctx.r11.u64 + ctx.r24.u64;
	// mtctr r29
	ctx.ctr.u64 = ctx.r29.u64;
	// bctrl 
	ctx.lr = 0x82CAE8B0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne 0x82cae8c0
	if (!ctx.cr0.eq) goto loc_82CAE8C0;
loc_82CAE8BC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CAE8C0:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE8C8"))) PPC_WEAK_FUNC(sub_82CAE8C8);
PPC_FUNC_IMPL(__imp__sub_82CAE8C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82CAE8D0;
	__savegprlr_26(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,24(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpw cr6,r4,r11
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82cae99c
	if (!ctx.cr6.eq) goto loc_82CAE99C;
	// cmpw cr6,r5,r6
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r6.s32, ctx.xer);
	// bne cr6,0x82cae99c
	if (!ctx.cr6.eq) goto loc_82CAE99C;
	// lwz r11,244(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82cae99c
	if (!ctx.cr6.eq) goto loc_82CAE99C;
	// addi r11,r4,3
	ctx.r11.s64 = ctx.r4.s64 + 3;
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r27,284(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// li r26,2
	ctx.r26.s64 = 2;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r30,252(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// rlwinm r29,r11,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// add r10,r11,r30
	ctx.r10.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAE950;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cae99c
	if (ctx.cr0.eq) goto loc_82CAE99C;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// lwz r10,260(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAE990;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bne 0x82cae9a0
	if (!ctx.cr0.eq) goto loc_82CAE9A0;
loc_82CAE99C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CAE9A0:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAE9A8"))) PPC_WEAK_FUNC(sub_82CAE9A8);
PPC_FUNC_IMPL(__imp__sub_82CAE9A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CAE9B0;
	__savegprlr_28(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r28,300(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82caea24
	if (ctx.cr6.eq) goto loc_82CAEA24;
	// lwz r4,276(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r7,292(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r28.u32);
	// stw r4,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r4.u32);
	// lwz r4,308(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// stw r7,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r7.u32);
	// lwz r7,284(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,268(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// stw r7,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r7.u32);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r11,260(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82cae8c8
	ctx.lr = 0x82CAEA14;
	sub_82CAE8C8(ctx, base);
loc_82CAEA14:
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82caea68
	if (!ctx.cr0.eq) goto loc_82CAEA68;
loc_82CAEA1C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82caeac0
	goto loc_82CAEAC0;
loc_82CAEA24:
	// lwz r11,308(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r28.u32);
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// lwz r11,292(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// lwz r11,284(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,276(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// lwz r11,268(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r11,260(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82cae738
	ctx.lr = 0x82CAEA64;
	sub_82CAE738(ctx, base);
	// b 0x82caea14
	goto loc_82CAEA14;
loc_82CAEA68:
	// lwz r11,152(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 152);
	// rlwinm. r11,r11,0,3,3
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82caea9c
	if (ctx.cr0.eq) goto loc_82CAEA9C;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mullw r4,r30,r29
	ctx.r4.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r29.s32);
	// subfic r11,r11,0
	ctx.xer.ca = ctx.r11.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,23,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1F0;
	// addi r3,r11,16
	ctx.r3.s64 = ctx.r11.s64 + 16;
	// bl 0x82caf6b8
	ctx.lr = 0x82CAEA94;
	sub_82CAF6B8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82caea1c
	if (!ctx.cr0.eq) goto loc_82CAEA1C;
loc_82CAEA9C:
	// mullw r11,r30,r29
	ctx.r11.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r29.s32);
	// lis r10,4
	ctx.r10.s64 = 262144;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82caeabc
	if (!ctx.cr6.gt) goto loc_82CAEABC;
	// lwz r11,152(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 152);
	// li r3,0
	ctx.r3.s64 = 0;
	// rlwinm. r11,r11,0,8,8
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x800000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82caeac0
	if (!ctx.cr0.eq) goto loc_82CAEAC0;
loc_82CAEABC:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82CAEAC0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAEAC8"))) PPC_WEAK_FUNC(sub_82CAEAC8);
PPC_FUNC_IMPL(__imp__sub_82CAEAC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4a0
	ctx.lr = 0x82CAEAD0;
	__savegprlr_18(ctx, base);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r5
	ctx.r24.u64 = ctx.r5.u64;
	// lwz r21,364(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// mr r23,r8
	ctx.r23.u64 = ctx.r8.u64;
	// lwz r5,356(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// mr r27,r9
	ctx.r27.u64 = ctx.r9.u64;
	// lwz r8,380(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// mr r22,r10
	ctx.r22.u64 = ctx.r10.u64;
	// lwz r9,388(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// lwz r10,396(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r26,372(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// add r20,r21,r26
	ctx.r20.u64 = ctx.r21.u64 + ctx.r26.u64;
	// stw r8,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r8.u32);
	// stw r9,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r9.u32);
	// mr r8,r23
	ctx.r8.u64 = ctx.r23.u64;
	// stw r10,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r10.u32);
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
	// lwz r25,24(r30)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// stw r21,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r21.u32);
	// mr r19,r7
	ctx.r19.u64 = ctx.r7.u64;
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// stw r20,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r20.u32);
	// bl 0x82cae9a8
	ctx.lr = 0x82CAEB44;
	sub_82CAE9A8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caec8c
	if (ctx.cr0.eq) goto loc_82CAEC8C;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// lwz r18,144(r1)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82caeb70
	if (ctx.cr6.eq) goto loc_82CAEB70;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r5,r11,-6800
	ctx.r5.s64 = ctx.r11.s64 + -6800;
	// addi r4,r10,-25988
	ctx.r4.s64 = ctx.r10.s64 + -25988;
	// b 0x82caeb94
	goto loc_82CAEB94;
loc_82CAEB70:
	// cmpwi cr6,r18,0
	ctx.cr6.compare<int32_t>(ctx.r18.s32, 0, ctx.xer);
	// beq cr6,0x82caeb84
	if (ctx.cr6.eq) goto loc_82CAEB84;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-7224
	ctx.r5.s64 = ctx.r11.s64 + -7224;
	// b 0x82caeb8c
	goto loc_82CAEB8C;
loc_82CAEB84:
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-7360
	ctx.r5.s64 = ctx.r11.s64 + -7360;
loc_82CAEB8C:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r4,r11,-25988
	ctx.r4.s64 = ctx.r11.s64 + -25988;
loc_82CAEB94:
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82c933f0
	ctx.lr = 0x82CAEB9C;
	sub_82C933F0(ctx, base);
	// addi r11,r28,3
	ctx.r11.s64 = ctx.r28.s64 + 3;
	// lwz r10,32(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r29,r31,8
	ctx.r29.s64 = ctx.r31.s64 + 8;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r10,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r10.u32);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r24,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r24.u32);
	// stw r28,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r28.u32);
	// stw r19,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r19.u32);
	// stw r23,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r23.u32);
	// stw r27,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r27.u32);
	// stw r10,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r10.u32);
	// stw r22,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r22.u32);
	// stw r21,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r21.u32);
	// stw r20,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r20.u32);
	// stw r30,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r30.u32);
	// stw r11,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r11.u32);
	// stw r18,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r18.u32);
	// bl 0x82c3ffa8
	ctx.lr = 0x82CAEBF8;
	sub_82C3FFA8(ctx, base);
	// lwz r10,12(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// rotlwi r11,r26,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r26.u32, 1);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r4,r25,16
	ctx.r4.s64 = ctx.r25.s64 + 16;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// divw r9,r26,r10
	ctx.r9.s32 = ctx.r26.s32 / ctx.r10.s32;
	// andc r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// mullw r3,r9,r27
	ctx.r3.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r27.s32);
	// twllei r10,0
	// twlgei r11,-1
	// bl 0x82c40108
	ctx.lr = 0x82CAEC28;
	sub_82C40108(ctx, base);
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82caec5c
	if (ctx.cr6.eq) goto loc_82CAEC5C;
	// mullw r11,r28,r27
	ctx.r11.s64 = int64_t(ctx.r28.s32) * int64_t(ctx.r27.s32);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// mullw r11,r11,r26
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r26.s32);
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r11.u64);
	// lfd f13,144(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82CAEC5C:
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82caec80
	if (!ctx.cr6.eq) goto loc_82CAEC80;
	// addi r11,r28,-5
	ctx.r11.s64 = ctx.r28.s64 + -5;
	// cmplwi cr6,r11,58
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 58, ctx.xer);
	// bgt cr6,0x82caec80
	if (ctx.cr6.gt) goto loc_82CAEC80;
	// cmpw cr6,r19,r28
	ctx.cr6.compare<int32_t>(ctx.r19.s32, ctx.r28.s32, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bge cr6,0x82caec84
	if (!ctx.cr6.lt) goto loc_82CAEC84;
loc_82CAEC80:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82CAEC84:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r11.u32);
loc_82CAEC8C:
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x82d5c4f0
	__restgprlr_18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAEC98"))) PPC_WEAK_FUNC(sub_82CAEC98);
PPC_FUNC_IMPL(__imp__sub_82CAEC98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82CAECA0;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-5432
	ctx.r6.s64 = ctx.r11.s64 + -5432;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r3,36
	ctx.r3.s64 = 36;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82c933b0
	ctx.lr = 0x82CAECD4;
	sub_82C933B0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,32(r4)
	PPC_STORE_U32(ctx.r4.u32 + 32, ctx.r29.u32);
	// stw r31,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r31.u32);
	// stw r27,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, ctx.r27.u32);
	// bl 0x82c42018
	ctx.lr = 0x82CAECEC;
	sub_82C42018(ctx, base);
	// lis r11,-31979
	ctx.r11.s64 = -2095775744;
	// lwz r10,-27216(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27216);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82caed38
	if (ctx.cr6.eq) goto loc_82CAED38;
	// lis r10,-32053
	ctx.r10.s64 = -2100625408;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,-27216(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27216);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r10,-5432
	ctx.r6.s64 = ctx.r10.s64 + -5432;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r3,36
	ctx.r3.s64 = 36;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAED20;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,32(r4)
	PPC_STORE_U32(ctx.r4.u32 + 32, ctx.r29.u32);
	// stw r31,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r31.u32);
	// stw r27,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, ctx.r27.u32);
	// bl 0x82c42018
	ctx.lr = 0x82CAED38;
	sub_82C42018(ctx, base);
loc_82CAED38:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAED40"))) PPC_WEAK_FUNC(sub_82CAED40);
PPC_FUNC_IMPL(__imp__sub_82CAED40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c8
	ctx.lr = 0x82CAED48;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// bl 0x82caec98
	ctx.lr = 0x82CAED64;
	sub_82CAEC98(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82caec98
	ctx.lr = 0x82CAED7C;
	sub_82CAEC98(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c518
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAED88"))) PPC_WEAK_FUNC(sub_82CAED88);
PPC_FUNC_IMPL(__imp__sub_82CAED88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82CAED90;
	__savegprlr_25(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r8
	ctx.r30.u64 = ctx.r8.u64;
	// li r25,2
	ctx.r25.s64 = 2;
	// mr r28,r9
	ctx.r28.u64 = ctx.r9.u64;
	// addi r29,r30,4
	ctx.r29.s64 = ctx.r30.s64 + 4;
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// lwz r8,64(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// lwz r9,72(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// stw r25,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r25.u32);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mr r26,r7
	ctx.r26.u64 = ctx.r7.u64;
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// bl 0x82c92ce0
	ctx.lr = 0x82CAEDE0;
	sub_82C92CE0(ctx, base);
	// lwz r8,68(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// neg r9,r8
	ctx.r9.s64 = -ctx.r8.s64;
	// blt 0x82caedf4
	if (ctx.cr0.lt) goto loc_82CAEDF4;
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
loc_82CAEDF4:
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// neg r10,r11
	ctx.r10.s64 = -ctx.r11.s64;
	// blt 0x82caee08
	if (ctx.cr0.lt) goto loc_82CAEE08;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82CAEE08:
	// cmpw cr6,r9,r10
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, ctx.xer);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bge cr6,0x82caee40
	if (!ctx.cr6.lt) goto loc_82CAEE40;
	// lwz r7,72(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// lwz r31,92(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82CAEE3C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82caee90
	goto loc_82CAEE90;
loc_82CAEE40:
	// lwz r8,72(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r25.u32);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAEE60;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// lwz r9,68(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r8,72(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r7,76(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r25.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// bl 0x82c92d70
	ctx.lr = 0x82CAEE90;
	sub_82C92D70(ctx, base);
loc_82CAEE90:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAEE98"))) PPC_WEAK_FUNC(sub_82CAEE98);
PPC_FUNC_IMPL(__imp__sub_82CAEE98) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,3
	ctx.r11.s64 = ctx.r3.s64 + 3;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAEEA8"))) PPC_WEAK_FUNC(sub_82CAEEA8);
PPC_FUNC_IMPL(__imp__sub_82CAEEA8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4b0
	ctx.lr = 0x82CAEEB0;
	__savegprlr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// mr r25,r7
	ctx.r25.u64 = ctx.r7.u64;
	// lwz r11,76(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 76);
	// lwz r22,80(r30)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r30.u32 + 80);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r31,r10,2
	ctx.r31.s64 = ctx.r10.s64 + 2;
	// mullw r11,r31,r11
	ctx.r11.s64 = int64_t(ctx.r31.s32) * int64_t(ctx.r11.s32);
	// rlwinm r3,r11,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x82c3fd60
	ctx.lr = 0x82CAEEE8;
	sub_82C3FD60(ctx, base);
	// subf. r23,r31,r22
	ctx.r23.s64 = ctx.r22.s64 - ctx.r31.s64;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// li r29,0
	ctx.r29.s64 = 0;
	// ble 0x82caef4c
	if (!ctx.cr0.gt) goto loc_82CAEF4C;
loc_82CAEEF8:
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82caed88
	ctx.lr = 0x82CAEF18;
	sub_82CAED88(ctx, base);
	// lwz r11,84(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 84);
	// lwz r10,88(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// add r29,r29,r31
	ctx.r29.u64 = ctx.r29.u64 + ctx.r31.u64;
	// mullw r11,r11,r31
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r31.s32);
	// mullw r10,r10,r31
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r31.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpw cr6,r29,r23
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r23.s32, ctx.xer);
	// add r28,r11,r28
	ctx.r28.u64 = ctx.r11.u64 + ctx.r28.u64;
	// add r27,r11,r27
	ctx.r27.u64 = ctx.r11.u64 + ctx.r27.u64;
	// add r26,r10,r26
	ctx.r26.u64 = ctx.r10.u64 + ctx.r26.u64;
	// add r25,r10,r25
	ctx.r25.u64 = ctx.r10.u64 + ctx.r25.u64;
	// blt cr6,0x82caeef8
	if (ctx.cr6.lt) goto loc_82CAEEF8;
loc_82CAEF4C:
	// subf r9,r29,r22
	ctx.r9.s64 = ctx.r22.s64 - ctx.r29.s64;
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82caed88
	ctx.lr = 0x82CAEF6C;
	sub_82CAED88(ctx, base);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c3fdb8
	ctx.lr = 0x82CAEF74;
	sub_82C3FDB8(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82d5c500
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAEF80"))) PPC_WEAK_FUNC(sub_82CAEF80);
PPC_FUNC_IMPL(__imp__sub_82CAEF80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// lwz r31,88(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// lwz r10,84(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	// lwz r9,80(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	// lwz r8,68(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r7,64(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// lwz r11,92(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAEFC8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAEFE0"))) PPC_WEAK_FUNC(sub_82CAEFE0);
PPC_FUNC_IMPL(__imp__sub_82CAEFE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4bc
	ctx.lr = 0x82CAEFE8;
	__savegprlr_25(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r26,r7
	ctx.r26.u64 = ctx.r7.u64;
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r25,92(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// addi r30,r11,-1
	ctx.r30.s64 = ctx.r11.s64 + -1;
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// lwz r10,84(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r8,68(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r7,64(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mtctr r25
	ctx.ctr.u64 = ctx.r25.u64;
	// bctrl 
	ctx.lr = 0x82CAF03C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r10,84(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// li r9,0
	ctx.r9.s64 = 0;
	// mullw r10,r10,r30
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r30.s32);
	// lwz r8,68(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r7,64(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// lwz r31,92(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// mullw r11,r30,r11
	ctx.r11.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r11.s32);
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r3,r28
	ctx.r4.u64 = ctx.r3.u64 + ctx.r28.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,1
	ctx.r9.s64 = 1;
	// add r6,r11,r26
	ctx.r6.u64 = ctx.r11.u64 + ctx.r26.u64;
	// add r5,r11,r27
	ctx.r5.u64 = ctx.r11.u64 + ctx.r27.u64;
	// add r3,r3,r29
	ctx.r3.u64 = ctx.r3.u64 + ctx.r29.u64;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82CAF088;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82d5c50c
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAF090"))) PPC_WEAK_FUNC(sub_82CAF090);
PPC_FUNC_IMPL(__imp__sub_82CAF090) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAF098"))) PPC_WEAK_FUNC(sub_82CAF098);
PPC_FUNC_IMPL(__imp__sub_82CAF098) {
	PPC_FUNC_PROLOGUE();
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r11,96(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 96);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lis r9,-31988
	ctx.r9.s64 = -2096365568;
	// beq cr6,0x82caf0e0
	if (ctx.cr6.eq) goto loc_82CAF0E0;
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r4,r9,20756
	ctx.r4.s64 = ctx.r9.s64 + 20756;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r11,r6,3
	ctx.r11.s64 = ctx.r6.s64 + 3;
	// lwz r7,80(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r5,r11,2
	ctx.r5.s64 = ctx.r11.s64 + 2;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
loc_82CAF0E0:
	// addi r9,r9,20756
	ctx.r9.s64 = ctx.r9.s64 + 20756;
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r6,80(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	// addi r4,r9,32
	ctx.r4.s64 = ctx.r9.s64 + 32;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_82CAF100"))) PPC_WEAK_FUNC(sub_82CAF100);
PPC_FUNC_IMPL(__imp__sub_82CAF100) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82CAF108;
	__savegprlr_26(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r29,8(r3)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82caf294
	if (!ctx.cr6.eq) goto loc_82CAF294;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82caf294
	if (!ctx.cr6.eq) goto loc_82CAF294;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82caf294
	if (!ctx.cr6.eq) goto loc_82CAF294;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// addi r4,r1,116
	ctx.r4.s64 = ctx.r1.s64 + 116;
	// bl 0x82c529f8
	ctx.lr = 0x82CAF158;
	sub_82C529F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caf294
	if (ctx.cr0.eq) goto loc_82CAF294;
	// lwz r11,152(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 152);
	// rlwinm. r11,r11,0,3,3
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82caf18c
	if (ctx.cr0.eq) goto loc_82CAF18C;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82c54758
	ctx.lr = 0x82CAF178;
	sub_82C54758(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r3,120(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// bl 0x82c54758
	ctx.lr = 0x82CAF184;
	sub_82C54758(ctx, base);
	// cmpw cr6,r30,r3
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r3.s32, ctx.xer);
	// ble cr6,0x82caf294
	if (!ctx.cr6.gt) goto loc_82CAF294;
loc_82CAF18C:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r26,2
	ctx.r26.s64 = 2;
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// stw r27,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r27.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r30,r11,2
	ctx.r30.s64 = ctx.r11.s64 + 2;
	// lwz r11,40(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	// stw r9,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r9.u32);
	// rlwinm r28,r30,1,0,30
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAF1E8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caf294
	if (ctx.cr0.eq) goto loc_82CAF294;
	// lwz r9,40(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	// twllei r30,0
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r27,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r27.u32);
	// rotlwi r10,r11,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r27,0(r9)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// divw r6,r11,r30
	ctx.r6.s32 = ctx.r11.s32 / ctx.r30.s32;
	// lwz r9,12(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lwz r8,112(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mullw r5,r6,r30
	ctx.r5.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r30.s32);
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// stw r8,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r8.u32);
	// andc r4,r30,r10
	ctx.r4.u64 = ctx.r30.u64 & ~ctx.r10.u64;
	// subf r10,r5,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r5.s64;
	// twlgei r4,-1
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,0
	ctx.r4.s64 = 0;
	// mtctr r27
	ctx.ctr.u64 = ctx.r27.u64;
	// bctrl 
	ctx.lr = 0x82CAF254;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caf294
	if (ctx.cr0.eq) goto loc_82CAF294;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82caf28c
	if (!ctx.cr6.eq) goto loc_82CAF28C;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82c55450
	ctx.lr = 0x82CAF278;
	sub_82C55450(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82caf28c
	if (!ctx.cr0.eq) goto loc_82CAF28C;
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmpw cr6,r11,r30
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r30.s32, ctx.xer);
	// bgt cr6,0x82caf294
	if (ctx.cr6.gt) goto loc_82CAF294;
loc_82CAF28C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82caf298
	goto loc_82CAF298;
loc_82CAF294:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CAF298:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAF2A0"))) PPC_WEAK_FUNC(sub_82CAF2A0);
PPC_FUNC_IMPL(__imp__sub_82CAF2A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c0
	ctx.lr = 0x82CAF2A8;
	__savegprlr_26(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r30,8(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82caf438
	if (!ctx.cr6.eq) goto loc_82CAF438;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bgt cr6,0x82caf438
	if (ctx.cr6.gt) goto loc_82CAF438;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82caf438
	if (!ctx.cr6.eq) goto loc_82CAF438;
	// addi r6,r1,116
	ctx.r6.s64 = ctx.r1.s64 + 116;
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82c529f8
	ctx.lr = 0x82CAF300;
	sub_82C529F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caf438
	if (ctx.cr0.eq) goto loc_82CAF438;
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r27,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r27.u32);
	// lwz r26,40(r30)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r29.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAF354;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82caf400
	if (!ctx.cr0.eq) goto loc_82CAF400;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r29.u32);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// lwz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// lwz r9,40(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r28,0(r9)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r28
	ctx.ctr.u64 = ctx.r28.u64;
	// bctrl 
	ctx.lr = 0x82CAF3B0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caf438
	if (ctx.cr0.eq) goto loc_82CAF438;
	// lwz r9,40(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r10,2
	ctx.r10.s64 = 2;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r30,0(r9)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r29.u32);
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r27.u32);
	// mtctr r30
	ctx.ctr.u64 = ctx.r30.u64;
	// bctrl 
	ctx.lr = 0x82CAF3F8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caf438
	if (ctx.cr0.eq) goto loc_82CAF438;
loc_82CAF400:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82caf430
	if (!ctx.cr6.eq) goto loc_82CAF430;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82caf430
	if (ctx.cr6.eq) goto loc_82CAF430;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82c55450
	ctx.lr = 0x82CAF428;
	sub_82C55450(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caf438
	if (ctx.cr0.eq) goto loc_82CAF438;
loc_82CAF430:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82caf43c
	goto loc_82CAF43C;
loc_82CAF438:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
loc_82CAF43C:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82d5c510
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAF448"))) PPC_WEAK_FUNC(sub_82CAF448);
PPC_FUNC_IMPL(__imp__sub_82CAF448) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82CAF450;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// lwz r27,8(r30)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82caf494
	if (ctx.cr6.eq) goto loc_82CAF494;
	// bl 0x82caf100
	ctx.lr = 0x82CAF470;
	sub_82CAF100(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82caf480
	if (!ctx.cr0.eq) goto loc_82CAF480;
loc_82CAF478:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82caf5c0
	goto loc_82CAF5C0;
loc_82CAF480:
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r5,r11,-4440
	ctx.r5.s64 = ctx.r11.s64 + -4440;
	// addi r4,r10,-25972
	ctx.r4.s64 = ctx.r10.s64 + -25972;
	// b 0x82caf4d4
	goto loc_82CAF4D4;
loc_82CAF494:
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x82caf2a0
	ctx.lr = 0x82CAF4A4;
	sub_82CAF2A0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82caf478
	if (ctx.cr0.eq) goto loc_82CAF478;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82caf4c4
	if (ctx.cr6.eq) goto loc_82CAF4C4;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-4128
	ctx.r5.s64 = ctx.r11.s64 + -4128;
	// b 0x82caf4cc
	goto loc_82CAF4CC;
loc_82CAF4C4:
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-4224
	ctx.r5.s64 = ctx.r11.s64 + -4224;
loc_82CAF4CC:
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r4,r11,-25972
	ctx.r4.s64 = ctx.r11.s64 + -25972;
loc_82CAF4D4:
	// li r3,104
	ctx.r3.s64 = 104;
	// bl 0x82c55cf0
	ctx.lr = 0x82CAF4DC;
	sub_82C55CF0(ctx, base);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// addi r29,r31,80
	ctx.r29.s64 = ctx.r31.s64 + 80;
	// addi r6,r31,88
	ctx.r6.s64 = ctx.r31.s64 + 88;
	// addi r5,r31,84
	ctx.r5.s64 = ctx.r31.s64 + 84;
	// stw r10,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r10.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r10.u32);
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// rlwinm r10,r10,0,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// stw r9,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r9.u32);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r11,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r11.u32);
	// stw r10,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r10.u32);
	// lwz r3,8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// bl 0x82c529f8
	ctx.lr = 0x82CAF534;
	sub_82C529F8(ctx, base);
	// addi r28,r31,8
	ctx.r28.s64 = ctx.r31.s64 + 8;
	// stw r30,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r30.u32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82c3ffa8
	ctx.lr = 0x82CAF544;
	sub_82C3FFA8(ctx, base);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r9,40(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 40);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rotlwi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 1);
	// addi r4,r27,8
	ctx.r4.s64 = ctx.r27.s64 + 8;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// andc r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 & ~ctx.r11.u64;
	// divw r3,r10,r9
	ctx.r3.s32 = ctx.r10.s32 / ctx.r9.s32;
	// twllei r9,0
	// twlgei r11,-1
	// bl 0x82c40108
	ctx.lr = 0x82CAF574;
	sub_82C40108(ctx, base);
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82caf5ac
	if (ctx.cr6.eq) goto loc_82CAF5AC;
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lfd f0,32(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fadd f0,f13,f0
	ctx.f0.f64 = ctx.f13.f64 + ctx.f0.f64;
	// stfd f0,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.f0.u64);
loc_82CAF5AC:
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// stw r11,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r11.u32);
loc_82CAF5C0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAF5C8"))) PPC_WEAK_FUNC(sub_82CAF5C8);
PPC_FUNC_IMPL(__imp__sub_82CAF5C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CAF5D0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,-25956
	ctx.r4.s64 = ctx.r11.s64 + -25956;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82c41f78
	ctx.lr = 0x82CAF5F0;
	sub_82C41F78(ctx, base);
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// stw r29,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r29.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAF608"))) PPC_WEAK_FUNC(sub_82CAF608);
PPC_FUNC_IMPL(__imp__sub_82CAF608) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,-25956
	ctx.r4.s64 = ctx.r11.s64 + -25956;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82c41f78
	ctx.lr = 0x82CAF634;
	sub_82C41F78(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAF660"))) PPC_WEAK_FUNC(sub_82CAF660);
PPC_FUNC_IMPL(__imp__sub_82CAF660) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r4,r11,-25956
	ctx.r4.s64 = ctx.r11.s64 + -25956;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82c41f78
	ctx.lr = 0x82CAF68C;
	sub_82C41F78(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAF6B8"))) PPC_WEAK_FUNC(sub_82CAF6B8);
PPC_FUNC_IMPL(__imp__sub_82CAF6B8) {
	PPC_FUNC_PROLOGUE();
	// cmpw cr6,r4,r3
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r3.s32, ctx.xer);
	// ble cr6,0x82caf6fc
	if (!ctx.cr6.gt) goto loc_82CAF6FC;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// ble cr6,0x82caf6f4
	if (!ctx.cr6.gt) goto loc_82CAF6F4;
	// addi r11,r4,-1
	ctx.r11.s64 = ctx.r4.s64 + -1;
	// and. r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 & ctx.r4.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82caf6f4
	if (!ctx.cr0.eq) goto loc_82CAF6F4;
	// rotlwi r11,r4,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 1);
	// divw r10,r4,r5
	ctx.r10.s32 = ctx.r4.s32 / ctx.r5.s32;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// twllei r5,0
	// andc r11,r5,r11
	ctx.r11.u64 = ctx.r5.u64 & ~ctx.r11.u64;
	// cmpwi cr6,r10,4
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 4, ctx.xer);
	// twlgei r11,-1
	// ble cr6,0x82caf6fc
	if (!ctx.cr6.gt) goto loc_82CAF6FC;
loc_82CAF6F4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82CAF6FC:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAF708"))) PPC_WEAK_FUNC(sub_82CAF708);
PPC_FUNC_IMPL(__imp__sub_82CAF708) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CAF710;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAF734;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAF74C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAF758"))) PPC_WEAK_FUNC(sub_82CAF758);
PPC_FUNC_IMPL(__imp__sub_82CAF758) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CAF760;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAF788;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAF7A0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAF7A8"))) PPC_WEAK_FUNC(sub_82CAF7A8);
PPC_FUNC_IMPL(__imp__sub_82CAF7A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CAF7B0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAF7D0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAF7E8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAF7F0"))) PPC_WEAK_FUNC(sub_82CAF7F0);
PPC_FUNC_IMPL(__imp__sub_82CAF7F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4c4
	ctx.lr = 0x82CAF7F8;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAF828;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAF848;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82d5c514
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAF850"))) PPC_WEAK_FUNC(sub_82CAF850);
PPC_FUNC_IMPL(__imp__sub_82CAF850) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// bl 0x82c3fc78
	ctx.lr = 0x82CAF874;
	sub_82C3FC78(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82c3fc78
	ctx.lr = 0x82CAF880;
	sub_82C3FC78(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAF898"))) PPC_WEAK_FUNC(sub_82CAF898);
PPC_FUNC_IMPL(__imp__sub_82CAF898) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,68(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// bl 0x82c3fc28
	ctx.lr = 0x82CAF8B4;
	sub_82C3FC28(ctx, base);
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// bl 0x82c3fc28
	ctx.lr = 0x82CAF8BC;
	sub_82C3FC28(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAF8D0"))) PPC_WEAK_FUNC(sub_82CAF8D0);
PPC_FUNC_IMPL(__imp__sub_82CAF8D0) {
	PPC_FUNC_PROLOGUE();
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lis r9,-32053
	ctx.r9.s64 = -2100625408;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r9,r9,-2296
	ctx.r9.s64 = ctx.r9.s64 + -2296;
	// lwz r11,56(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82caf90c
	if (ctx.cr6.eq) goto loc_82CAF90C;
	// lis r9,-32053
	ctx.r9.s64 = -2100625408;
	// addi r9,r9,-2136
	ctx.r9.s64 = ctx.r9.s64 + -2136;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82caf90c
	if (ctx.cr6.eq) goto loc_82CAF90C;
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// addi r11,r11,20812
	ctx.r11.s64 = ctx.r11.s64 + 20812;
	// addi r5,r11,4
	ctx.r5.s64 = ctx.r11.s64 + 4;
	// b 0x82caf918
	goto loc_82CAF918;
loc_82CAF90C:
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// addi r11,r11,20812
	ctx.r11.s64 = ctx.r11.s64 + 20812;
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
loc_82CAF918:
	// addi r4,r11,8
	ctx.r4.s64 = ctx.r11.s64 + 8;
	// lwz r8,64(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	// lwz r7,68(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 68);
	// lwz r6,72(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctr 
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	return;
}

__attribute__((alias("__imp__sub_82CAF938"))) PPC_WEAK_FUNC(sub_82CAF938);
PPC_FUNC_IMPL(__imp__sub_82CAF938) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82caf9c4
	if (!ctx.cr6.eq) goto loc_82CAF9C4;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bgt cr6,0x82caf9c4
	if (ctx.cr6.gt) goto loc_82CAF9C4;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82caf99c
	if (ctx.cr0.eq) goto loc_82CAF99C;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82caf9c4
	if (!ctx.cr6.eq) goto loc_82CAF9C4;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82caf99c
	if (ctx.cr6.eq) goto loc_82CAF99C;
	// lwz r11,152(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 152);
	// rlwinm. r11,r11,0,7,7
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82caf9c4
	if (!ctx.cr0.eq) goto loc_82CAF9C4;
loc_82CAF99C:
	// lwz r4,4(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// bl 0x82c424e0
	ctx.lr = 0x82CAF9A8;
	sub_82C424E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// ble 0x82caf9c4
	if (!ctx.cr0.gt) goto loc_82CAF9C4;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpw cr6,r11,r3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r3.s32, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bgt cr6,0x82caf9c8
	if (ctx.cr6.gt) goto loc_82CAF9C8;
loc_82CAF9C4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82CAF9C8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAF9E0"))) PPC_WEAK_FUNC(sub_82CAF9E0);
PPC_FUNC_IMPL(__imp__sub_82CAF9E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// bl 0x82caf938
	ctx.lr = 0x82CAFA00;
	sub_82CAF938(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82cafa2c
	if (ctx.cr0.eq) goto loc_82CAFA2C;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82cafa28
	if (ctx.cr6.eq) goto loc_82CAFA28;
	// lwz r11,152(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 152);
	// li r3,0
	ctx.r3.s64 = 0;
	// rlwinm. r11,r11,0,15,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82cafa2c
	if (!ctx.cr0.eq) goto loc_82CAFA2C;
loc_82CAFA28:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82CAFA2C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAFA48"))) PPC_WEAK_FUNC(sub_82CAFA48);
PPC_FUNC_IMPL(__imp__sub_82CAFA48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4ac
	ctx.lr = 0x82CAFA50;
	__savegprlr_21(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// li r24,0
	ctx.r24.s64 = 0;
	// li r25,0
	ctx.r25.s64 = 0;
	// li r23,0
	ctx.r23.s64 = 0;
	// bl 0x82caf9e0
	ctx.lr = 0x82CAFA70;
	sub_82CAF9E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82cafa80
	if (!ctx.cr0.eq) goto loc_82CAFA80;
loc_82CAFA78:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82cafe20
	goto loc_82CAFE20;
loc_82CAFA80:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// addi r30,r11,4
	ctx.r30.s64 = ctx.r11.s64 + 4;
	// lwz r29,0(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82c424e0
	ctx.lr = 0x82CAFA98;
	sub_82C424E0(ctx, base);
	// rotlwi r11,r29,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r29.u32, 1);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// andc r11,r27,r11
	ctx.r11.u64 = ctx.r27.u64 & ~ctx.r11.u64;
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// divw r29,r29,r27
	ctx.r29.s32 = ctx.r29.s32 / ctx.r27.s32;
	// twllei r27,0
	// twlgei r11,-1
	// bl 0x82c529f8
	ctx.lr = 0x82CAFAC8;
	sub_82C529F8(ctx, base);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82cafc58
	if (ctx.cr0.eq) goto loc_82CAFC58;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82cafdf8
	if (!ctx.cr6.eq) goto loc_82CAFDF8;
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lwz r23,20(r31)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r8,4(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r11,12(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// mullw r6,r8,r29
	ctx.r6.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r29.s32);
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r26.u32);
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r23.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAFB1C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq 0x82cafdc8
	if (ctx.cr0.eq) goto loc_82CAFDC8;
	// lwz r11,16(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82cafbbc
	if (ctx.cr6.lt) goto loc_82CAFBBC;
	// bne cr6,0x82cafdf8
	if (!ctx.cr6.eq) goto loc_82CAFDF8;
	// srawi r11,r27,1
	ctx.xer.ca = (ctx.r27.s32 < 0) & ((ctx.r27.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r27.s32 >> 1;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r25,12(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addze r28,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r28.s64 = temp.s64;
	// lwz r24,16(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mullw r4,r10,r29
	ctx.r4.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r29.s32);
	// lwz r22,20(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r8,120(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r7,116(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r6,112(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r31,24(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r5,8(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82c54660
	ctx.lr = 0x82CAFB6C;
	sub_82C54660(ctx, base);
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// mr r21,r3
	ctx.r21.u64 = ctx.r3.u64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mullw r5,r11,r28
	ctx.r5.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c42a78
	ctx.lr = 0x82CAFB84;
	sub_82C42A78(ctx, base);
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r6,r22
	ctx.r6.u64 = ctx.r22.u64;
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// bl 0x82c428e0
	ctx.lr = 0x82CAFB9C;
	sub_82C428E0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c41a30
	ctx.lr = 0x82CAFBA8;
	sub_82C41A30(ctx, base);
	// mr. r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// beq 0x82cafdc8
	if (ctx.cr0.eq) goto loc_82CAFDC8;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-2064
	ctx.r5.s64 = ctx.r11.s64 + -2064;
	// b 0x82cafde4
	goto loc_82CAFDE4;
loc_82CAFBBC:
	// srawi r11,r27,1
	ctx.xer.ca = (ctx.r27.s32 < 0) & ((ctx.r27.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r27.s32 >> 1;
	// lwz r6,120(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r28,12(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// li r3,2
	ctx.r3.s64 = 2;
	// addze r24,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r24.s64 = temp.s64;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r25,20(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// subf r11,r28,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r28.s64;
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// subf r4,r25,r8
	ctx.r4.s64 = ctx.r8.s64 - ctx.r25.s64;
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// srawi r5,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r5.s64 = ctx.r11.s32 >> 2;
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// mullw r7,r7,r29
	ctx.r7.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r29.s32);
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// srawi r4,r4,2
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x3) != 0);
	ctx.r4.s64 = ctx.r4.s32 >> 2;
	// bl 0x82c546b0
	ctx.lr = 0x82CAFC0C;
	sub_82C546B0(ctx, base);
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mullw r5,r11,r24
	ctx.r5.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r24.s32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c42a78
	ctx.lr = 0x82CAFC24;
	sub_82C42A78(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// li r7,4
	ctx.r7.s64 = 4;
	// bl 0x82c539d0
	ctx.lr = 0x82CAFC38;
	sub_82C539D0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c41a30
	ctx.lr = 0x82CAFC44;
	sub_82C41A30(ctx, base);
	// mr. r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// beq 0x82cafdc8
	if (ctx.cr0.eq) goto loc_82CAFDC8;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-2216
	ctx.r5.s64 = ctx.r11.s64 + -2216;
	// b 0x82cafde4
	goto loc_82CAFDE4;
loc_82CAFC58:
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lwz r23,20(r31)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,12(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// mullw r6,r8,r29
	ctx.r6.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r29.s32);
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r26.u32);
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r23.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAFC98;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq 0x82cafdc8
	if (ctx.cr0.eq) goto loc_82CAFDC8;
	// lwz r11,16(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82cafd38
	if (ctx.cr6.lt) goto loc_82CAFD38;
	// bne cr6,0x82cafdf8
	if (!ctx.cr6.eq) goto loc_82CAFDF8;
	// srawi r11,r27,1
	ctx.xer.ca = (ctx.r27.s32 < 0) & ((ctx.r27.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r27.s32 >> 1;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r25,24(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addze r28,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r28.s64 = temp.s64;
	// lwz r24,20(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mullw r5,r10,r29
	ctx.r5.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r29.s32);
	// lwz r22,16(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r8,120(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r7,116(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r6,112(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82c54660
	ctx.lr = 0x82CAFCE8;
	sub_82C54660(ctx, base);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mr r21,r3
	ctx.r21.u64 = ctx.r3.u64;
	// lwz r5,8(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// mullw r4,r11,r28
	ctx.r4.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c42a78
	ctx.lr = 0x82CAFD00;
	sub_82C42A78(ctx, base);
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r6,r22
	ctx.r6.u64 = ctx.r22.u64;
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// bl 0x82c428e0
	ctx.lr = 0x82CAFD18;
	sub_82C428E0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c41a30
	ctx.lr = 0x82CAFD24;
	sub_82C41A30(ctx, base);
	// mr. r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// beq 0x82cafdc8
	if (ctx.cr0.eq) goto loc_82CAFDC8;
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-2136
	ctx.r5.s64 = ctx.r11.s64 + -2136;
	// b 0x82cafde4
	goto loc_82CAFDE4;
loc_82CAFD38:
	// srawi r11,r27,1
	ctx.xer.ca = (ctx.r27.s32 < 0) & ((ctx.r27.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r27.s32 >> 1;
	// lwz r6,120(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r28,20(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// li r3,2
	ctx.r3.s64 = 2;
	// addze r24,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r24.s64 = temp.s64;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r7,16(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r25,12(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// subf r11,r28,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r28.s64;
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// subf r4,r25,r7
	ctx.r4.s64 = ctx.r7.s64 - ctx.r25.s64;
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// srawi r5,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r5.s64 = ctx.r11.s32 >> 2;
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// mullw r8,r8,r29
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r29.s32);
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// srawi r4,r4,2
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x3) != 0);
	ctx.r4.s64 = ctx.r4.s32 >> 2;
	// bl 0x82c546b0
	ctx.lr = 0x82CAFD88;
	sub_82C546B0(ctx, base);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r5,8(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// mullw r4,r11,r24
	ctx.r4.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r24.s32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c42a78
	ctx.lr = 0x82CAFDA0;
	sub_82C42A78(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// bl 0x82c539d0
	ctx.lr = 0x82CAFDB4;
	sub_82C539D0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c41a30
	ctx.lr = 0x82CAFDC0;
	sub_82C41A30(ctx, base);
	// mr. r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// bne 0x82cafddc
	if (!ctx.cr0.eq) goto loc_82CAFDDC;
loc_82CAFDC8:
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82c3fc28
	ctx.lr = 0x82CAFDD0;
	sub_82C3FC28(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82c3fc28
	ctx.lr = 0x82CAFDD8;
	sub_82C3FC28(ctx, base);
	// b 0x82cafa78
	goto loc_82CAFA78;
loc_82CAFDDC:
	// lis r11,-32053
	ctx.r11.s64 = -2100625408;
	// addi r5,r11,-2296
	ctx.r5.s64 = ctx.r11.s64 + -2296;
loc_82CAFDE4:
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// li r3,80
	ctx.r3.s64 = 80;
	// addi r4,r10,-25944
	ctx.r4.s64 = ctx.r10.s64 + -25944;
	// bl 0x82c54a68
	ctx.lr = 0x82CAFDF4;
	sub_82C54A68(ctx, base);
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
loc_82CAFDF8:
	// addi r5,r24,8
	ctx.r5.s64 = ctx.r24.s64 + 8;
	// stw r25,64(r24)
	PPC_STORE_U32(ctx.r24.u32 + 64, ctx.r25.u32);
	// addi r4,r23,8
	ctx.r4.s64 = ctx.r23.s64 + 8;
	// stw r23,68(r24)
	PPC_STORE_U32(ctx.r24.u32 + 68, ctx.r23.u32);
	// addi r3,r25,8
	ctx.r3.s64 = ctx.r25.s64 + 8;
	// stw r27,72(r24)
	PPC_STORE_U32(ctx.r24.u32 + 72, ctx.r27.u32);
	// bl 0x82c40078
	ctx.lr = 0x82CAFE14;
	sub_82C40078(ctx, base);
	// lwz r11,52(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 52);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// stw r11,52(r24)
	PPC_STORE_U32(ctx.r24.u32 + 52, ctx.r11.u32);
loc_82CAFE20:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82d5c4fc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAFE28"))) PPC_WEAK_FUNC(sub_82CAFE28);
PPC_FUNC_IMPL(__imp__sub_82CAFE28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82d5c4cc
	ctx.lr = 0x82CAFE30;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// addi r4,r11,-25928
	ctx.r4.s64 = ctx.r11.s64 + -25928;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// bl 0x82c41f78
	ctx.lr = 0x82CAFE4C;
	sub_82C41F78(ctx, base);
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// stw r30,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r30.u32);
	// stw r29,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r29.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82d5c51c
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAFE60"))) PPC_WEAK_FUNC(sub_82CAFE60);
PPC_FUNC_IMPL(__imp__sub_82CAFE60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82c3fbc8
	ctx.lr = 0x82CAFE78;
	sub_82C3FBC8(ctx, base);
	// stw r31,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r31.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAFE90"))) PPC_WEAK_FUNC(sub_82CAFE90);
PPC_FUNC_IMPL(__imp__sub_82CAFE90) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r11,r11,-25912
	ctx.r11.s64 = ctx.r11.s64 + -25912;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAFEA0"))) PPC_WEAK_FUNC(sub_82CAFEA0);
PPC_FUNC_IMPL(__imp__sub_82CAFEA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31979
	ctx.r11.s64 = -2095775744;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r10,-23900(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -23900);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82cafed0
	if (ctx.cr6.eq) goto loc_82CAFED0;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAFED0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82CAFED0:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CAFEE4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d59ce8
	ctx.lr = 0x82CAFEEC;
	sub_82D59CE8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAFF00"))) PPC_WEAK_FUNC(sub_82CAFF00);
PPC_FUNC_IMPL(__imp__sub_82CAFF00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,-25912
	ctx.r11.s64 = ctx.r11.s64 + -25912;
	// clrlwi r10,r4,31
	ctx.r10.u64 = ctx.r4.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// beq cr6,0x82caff34
	if (ctx.cr6.eq) goto loc_82CAFF34;
	// bl 0x8247d948
	ctx.lr = 0x82CAFF30;
	sub_8247D948(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82CAFF34:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAFF48"))) PPC_WEAK_FUNC(sub_82CAFF48);
PPC_FUNC_IMPL(__imp__sub_82CAFF48) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,-25888
	ctx.r11.s64 = ctx.r11.s64 + -25888;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// bl 0x82d375b0
	ctx.lr = 0x82CAFF70;
	sub_82D375B0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82d371b8
	ctx.lr = 0x82CAFF78;
	sub_82D371B8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAFF90"))) PPC_WEAK_FUNC(sub_82CAFF90);
PPC_FUNC_IMPL(__imp__sub_82CAFF90) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// addi r3,r11,-25860
	ctx.r3.s64 = ctx.r11.s64 + -25860;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAFFA0"))) PPC_WEAK_FUNC(sub_82CAFFA0);
PPC_FUNC_IMPL(__imp__sub_82CAFFA0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-31988
	ctx.r11.s64 = -2096365568;
	// addi r3,r11,22656
	ctx.r3.s64 = ctx.r11.s64 + 22656;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAFFB0"))) PPC_WEAK_FUNC(sub_82CAFFB0);
PPC_FUNC_IMPL(__imp__sub_82CAFFB0) {
	PPC_FUNC_PROLOGUE();
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CAFFB8"))) PPC_WEAK_FUNC(sub_82CAFFB8);
PPC_FUNC_IMPL(__imp__sub_82CAFFB8) {
	PPC_FUNC_PROLOGUE();
	// b 0x82d371c8
	sub_82D371C8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CAFFC0"))) PPC_WEAK_FUNC(sub_82CAFFC0);
PPC_FUNC_IMPL(__imp__sub_82CAFFC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82cc0110
	ctx.lr = 0x82CAFFD8;
	sub_82CC0110(ctx, base);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r11,r11,-25832
	ctx.r11.s64 = ctx.r11.s64 + -25832;
	// addi r10,r10,-25848
	ctx.r10.s64 = ctx.r10.s64 + -25848;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CB0008"))) PPC_WEAK_FUNC(sub_82CB0008);
PPC_FUNC_IMPL(__imp__sub_82CB0008) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82cc0110
	ctx.lr = 0x82CB0028;
	sub_82CC0110(ctx, base);
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r11,r11,-25832
	ctx.r11.s64 = ctx.r11.s64 + -25832;
	// addi r10,r10,-25848
	ctx.r10.s64 = ctx.r10.s64 + -25848;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
	// bl 0x82ceb7a8
	ctx.lr = 0x82CB004C;
	sub_82CEB7A8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82CB0068"))) PPC_WEAK_FUNC(sub_82CB0068);
PPC_FUNC_IMPL(__imp__sub_82CB0068) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32234
	ctx.r11.s64 = -2112487424;
	// lis r10,-32234
	ctx.r10.s64 = -2112487424;
	// addi r11,r11,-25832
	ctx.r11.s64 = ctx.r11.s64 + -25832;
	// addi r10,r10,-25848
	ctx.r10.s64 = ctx.r10.s64 + -25848;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// b 0x82cc0220
	sub_82CC0220(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82CB0088"))) PPC_WEAK_FUNC(sub_82CB0088);
PPC_FUNC_IMPL(__imp__sub_82CB0088) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82CB00AC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

