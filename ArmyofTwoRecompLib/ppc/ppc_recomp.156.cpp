#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82B26270"))) PPC_WEAK_FUNC(sub_82B26270);
PPC_FUNC_IMPL(__imp__sub_82B26270) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B26278;
	__savegprlr_29(ctx, base);
	// lbz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 8);
	// clrlwi r11,r11,29
	ctx.r11.u64 = ctx.r11.u32 & 0x7;
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// beq cr6,0x82b26368
	if (ctx.cr6.eq) goto loc_82B26368;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm. r11,r10,0,13,13
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b26368
	if (!ctx.cr0.eq) goto loc_82B26368;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82b262a8
	if (ctx.cr6.eq) goto loc_82B262A8;
	// lwz r11,20(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// rlwinm. r11,r11,0,14,14
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b26368
	if (!ctx.cr0.eq) goto loc_82B26368;
loc_82B262A8:
	// lwz r8,20(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// rlwinm r6,r10,27,27,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1F;
	// lwz r9,24(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// li r31,0
	ctx.r31.s64 = 0;
	// addi r7,r4,32
	ctx.r7.s64 = ctx.r4.s64 + 32;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r11,r11,9
	ctx.r11.s64 = ctx.r11.s64 + 9;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// rlwinm. r9,r8,27,27,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1F;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// beq 0x82b2632c
	if (ctx.cr0.eq) goto loc_82B2632C;
	// mr r31,r9
	ctx.r31.u64 = ctx.r9.u64;
loc_82B262E4:
	// lwz r5,0(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// clrlwi r30,r5,24
	ctx.r30.u64 = ctx.r5.u32 & 0xFF;
	// b 0x82b26304
	goto loc_82B26304;
loc_82B262F0:
	// lbz r29,3(r11)
	ctx.r29.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplw cr6,r29,r30
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r30.u32, ctx.xer);
	// bge cr6,0x82b2630c
	if (!ctx.cr6.lt) goto loc_82B2630C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
loc_82B26304:
	// cmplw cr6,r10,r6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82b262f0
	if (ctx.cr6.lt) goto loc_82B262F0;
loc_82B2630C:
	// clrlwi r5,r5,16
	ctx.r5.u64 = ctx.r5.u32 & 0xFFFF;
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r5,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r5.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82b262e4
	if (!ctx.cr0.eq) goto loc_82B262E4;
loc_82B2632C:
	// cmplw cr6,r31,r6
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r6.u32, ctx.xer);
	// bge cr6,0x82b26350
	if (!ctx.cr6.lt) goto loc_82B26350;
	// subf. r11,r31,r6
	ctx.r11.s64 = ctx.r6.s64 - ctx.r31.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// beq 0x82b26350
	if (ctx.cr0.eq) goto loc_82B26350;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_82B26344:
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bdnz 0x82b26344
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B26344;
loc_82B26350:
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,20(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// stw r10,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r10.u32);
	// lwz r10,20(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// rlwimi r11,r10,0,13,31
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 0) & 0x7FFFF) | (ctx.r11.u64 & 0xFFFFFFFFFFF80000);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r11.u32);
loc_82B26368:
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B26370"))) PPC_WEAK_FUNC(sub_82B26370);
PPC_FUNC_IMPL(__imp__sub_82B26370) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82B26378;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
	// mr r30,r8
	ctx.r30.u64 = ctx.r8.u64;
loc_82B26390:
	// lwz r11,52(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 52);
	// twllei r30,0
	// subf r11,r4,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r4.s64;
	// srawi r11,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// divw. r11,r10,r30
	ctx.r11.s32 = ctx.r10.s32 / ctx.r30.s32;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// rotlwi r10,r10,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 1);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// andc r10,r30,r10
	ctx.r10.u64 = ctx.r30.u64 & ~ctx.r10.u64;
	// twlgei r10,-1
	// ble 0x82b26400
	if (!ctx.cr0.gt) goto loc_82B26400;
	// mullw r11,r11,r30
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82b263cc
	if (ctx.cr6.lt) goto loc_82B263CC;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82B263CC:
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// subf r31,r11,r31
	ctx.r31.s64 = ctx.r31.s64 - ctx.r11.s64;
	// rlwinm r10,r10,16,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// or r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 | ctx.r28.u64;
	// stwu r10,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r4.u32 = ea;
	// beq cr6,0x82b263fc
	if (ctx.cr6.eq) goto loc_82B263FC;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B263EC:
	// lwzu r9,4(r27)
	ea = 4 + ctx.r27.u32;
	ctx.r9.u64 = PPC_LOAD_U32(ea);
	ctx.r27.u32 = ea;
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stwu r9,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r4.u32 = ea;
	// bne 0x82b263ec
	if (!ctx.cr0.eq) goto loc_82B263EC;
loc_82B263FC:
	// add r28,r11,r28
	ctx.r28.u64 = ctx.r11.u64 + ctx.r28.u64;
loc_82B26400:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b2641c
	if (ctx.cr6.eq) goto loc_82B2641C;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r4,48(r29)
	PPC_STORE_U32(ctx.r29.u32 + 48, ctx.r4.u32);
	// bl 0x82b1dae8
	ctx.lr = 0x82B26414;
	sub_82B1DAE8(ctx, base);
	// lwz r4,48(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	// b 0x82b26390
	goto loc_82B26390;
loc_82B2641C:
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B26428"))) PPC_WEAK_FUNC(sub_82B26428);
PPC_FUNC_IMPL(__imp__sub_82B26428) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r11,12692(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12692);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b26464
	if (ctx.cr0.eq) goto loc_82B26464;
	// lwz r10,64(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r11,48(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	// rlwinm r8,r11,5,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0x1;
loc_82B26464:
	// lwz r9,11852(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11852);
	// lwz r10,10548(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwinm r9,r9,12,20,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 12) & 0xFFF;
	// lbz r11,10942(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10942);
	// rlwinm r7,r10,31,1,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// lwz r6,10560(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10560);
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// and r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 & ctx.r7.u64;
	// rlwimi r11,r6,0,0,30
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r6.u32, 0) & 0xFFFFFFFE) | (ctx.r11.u64 & 0xFFFFFFFF00000001);
	// stw r11,10560(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10560, ctx.r11.u32);
	// rlwinm. r5,r9,0,30,30
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// bne 0x82b2649c
	if (!ctx.cr0.eq) goto loc_82B2649C;
	// clrlwi r11,r9,31
	ctx.r11.u64 = ctx.r9.u32 & 0x1;
	// b 0x82b26540
	goto loc_82B26540;
loc_82B2649C:
	// rlwinm. r6,r11,0,27,27
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// rlwinm r9,r10,28,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0x7;
	// bne 0x82b264b8
	if (!ctx.cr0.eq) goto loc_82B264B8;
	// cmplwi cr6,r9,1
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1, ctx.xer);
	// beq cr6,0x82b264d4
	if (ctx.cr6.eq) goto loc_82B264D4;
	// cmplwi cr6,r9,3
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 3, ctx.xer);
	// b 0x82b264c4
	goto loc_82B264C4;
loc_82B264B8:
	// cmplwi cr6,r9,4
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 4, ctx.xer);
	// beq cr6,0x82b264d4
	if (ctx.cr6.eq) goto loc_82B264D4;
	// cmplwi cr6,r9,6
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 6, ctx.xer);
loc_82B264C4:
	// beq cr6,0x82b264d4
	if (ctx.cr6.eq) goto loc_82B264D4;
	// cmplwi cr6,r9,2
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 2, ctx.xer);
	// li r9,0
	ctx.r9.s64 = 0;
	// bne cr6,0x82b264d8
	if (!ctx.cr6.eq) goto loc_82B264D8;
loc_82B264D4:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82B264D8:
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// clrlwi. r6,r10,31
	ctx.r6.u64 = ctx.r10.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// and r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 & ctx.r11.u64;
	// and r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 & ctx.r7.u64;
	// and r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 & ctx.r9.u64;
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// beq 0x82b26540
	if (ctx.cr0.eq) goto loc_82B26540;
	// rlwinm r9,r10,0,18,20
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x3800;
	// rlwinm r8,r10,0,12,14
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE0000;
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r9,r9,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// rlwinm. r6,r10,0,24,24
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// and r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 & ctx.r8.u64;
	// and r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 & ctx.r11.u64;
	// beq 0x82b26540
	if (ctx.cr0.eq) goto loc_82B26540;
	// rlwinm r9,r10,0,0,2
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xE0000000;
	// rlwinm r8,r10,0,6,8
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x3800000;
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r9,r9,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// and r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 & ctx.r8.u64;
	// and r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 & ctx.r11.u64;
loc_82B26540:
	// lwz r9,10560(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10560);
	// rlwimi r9,r11,1,30,30
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 1) & 0x2) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFFD);
	// stw r9,10560(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10560, ctx.r9.u32);
	// rlwinm. r11,r9,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b265b4
	if (ctx.cr0.eq) goto loc_82B265B4;
	// lbz r11,10941(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b2660c
	if (ctx.cr0.eq) goto loc_82B2660C;
	// lwz r10,13504(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13504);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b26578
	if (ctx.cr6.eq) goto loc_82B26578;
	// lwz r10,13512(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13512);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// bne cr6,0x82b2660c
	if (!ctx.cr6.eq) goto loc_82B2660C;
loc_82B26578:
	// andi. r11,r11,251
	ctx.r11.u64 = ctx.r11.u64 & 251;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r3,r10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, ctx.xer);
	// stb r11,10941(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10941, ctx.r11.u8);
	// ble cr6,0x82b26598
	if (!ctx.cr6.gt) goto loc_82B26598;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B26598;
	sub_82B1DAE8(ctx, base);
loc_82B26598:
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// li r10,15
	ctx.r10.s64 = 15;
	// ori r11,r11,17920
	ctx.r11.u64 = ctx.r11.u64 | 17920;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// b 0x82b2660c
	goto loc_82B2660C;
loc_82B265B4:
	// clrlwi. r11,r7,31
	ctx.r11.u64 = ctx.r7.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2660c
	if (ctx.cr0.eq) goto loc_82B2660C;
	// rlwinm. r11,r10,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2660c
	if (ctx.cr0.eq) goto loc_82B2660C;
	// rlwinm r11,r10,28,29,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0x7;
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// beq cr6,0x82b26600
	if (ctx.cr6.eq) goto loc_82B26600;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// beq cr6,0x82b26600
	if (ctx.cr6.eq) goto loc_82B26600;
	// rlwinm. r10,r9,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82b265f0
	if (!ctx.cr0.eq) goto loc_82B265F0;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// beq cr6,0x82b26600
	if (ctx.cr6.eq) goto loc_82B26600;
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// b 0x82b265fc
	goto loc_82B265FC;
loc_82B265F0:
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82b26600
	if (ctx.cr6.eq) goto loc_82B26600;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
loc_82B265FC:
	// bne cr6,0x82b2660c
	if (!ctx.cr6.eq) goto loc_82B2660C;
loc_82B26600:
	// lbz r11,10941(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stb r11,10941(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10941, ctx.r11.u8);
loc_82B2660C:
	// ori r3,r30,256
	ctx.r3.u64 = ctx.r30.u64 | 256;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B26628"))) PPC_WEAK_FUNC(sub_82B26628);
PPC_FUNC_IMPL(__imp__sub_82B26628) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82B26630;
	__savegprlr_20(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r21,r4
	ctx.r21.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b26658
	if (!ctx.cr6.gt) goto loc_82B26658;
	// bl 0x82b1dae8
	ctx.lr = 0x82B26654;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B26658:
	// li r10,-1
	ctx.r10.s64 = -1;
	// rlwinm r9,r21,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r21.u32 | (ctx.r21.u64 << 32), 0) & 0x100;
	// mr r23,r10
	ctx.r23.u64 = ctx.r10.u64;
	// mr r22,r10
	ctx.r22.u64 = ctx.r10.u64;
	// mr r20,r10
	ctx.r20.u64 = ctx.r10.u64;
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// cmpldi cr6,r9,0
	ctx.cr6.compare<uint64_t>(ctx.r9.u64, 0, ctx.xer);
	// ori r25,r10,24832
	ctx.r25.u64 = ctx.r10.u64 | 24832;
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// ori r28,r10,24576
	ctx.r28.u64 = ctx.r10.u64 | 24576;
	// lis r10,-16383
	ctx.r10.s64 = -1073676288;
	// ori r26,r10,11521
	ctx.r26.u64 = ctx.r10.u64 | 11521;
	// lis r10,4
	ctx.r10.s64 = 262144;
	// ori r24,r10,515
	ctx.r24.u64 = ctx.r10.u64 | 515;
	// beq cr6,0x82b2689c
	if (ctx.cr6.eq) goto loc_82B2689C;
	// lbz r10,10943(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10943);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b2685c
	if (ctx.cr0.eq) goto loc_82B2685C;
	// lbz r10,10940(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10940);
	// rlwinm. r9,r10,0,27,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82b266b4
	if (ctx.cr0.eq) goto loc_82B266B4;
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82b26744
	goto loc_82B26744;
loc_82B266B4:
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b2673c
	if (ctx.cr0.eq) goto loc_82B2673C;
	// lwz r10,12440(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12440);
	// lwz r9,12728(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12728);
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b266d4
	if (ctx.cr6.eq) goto loc_82B266D4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82b2673c
	if (!ctx.cr6.eq) goto loc_82B2673C;
loc_82B266D4:
	// lwz r10,12444(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12444);
	// lwz r9,12732(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12732);
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b266ec
	if (ctx.cr6.eq) goto loc_82B266EC;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82b2673c
	if (!ctx.cr6.eq) goto loc_82B2673C;
loc_82B266EC:
	// lwz r10,12448(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12448);
	// lwz r9,12736(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12736);
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b26704
	if (ctx.cr6.eq) goto loc_82B26704;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82b2673c
	if (!ctx.cr6.eq) goto loc_82B2673C;
loc_82B26704:
	// lwz r10,12452(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12452);
	// lwz r9,12740(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12740);
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b2671c
	if (ctx.cr6.eq) goto loc_82B2671C;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82b2673c
	if (!ctx.cr6.eq) goto loc_82B2673C;
loc_82B2671C:
	// lwz r10,12456(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12456);
	// lwz r9,12744(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12744);
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b26734
	if (ctx.cr6.eq) goto loc_82B26734;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82b2673c
	if (!ctx.cr6.eq) goto loc_82B2673C;
loc_82B26734:
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82b26740
	goto loc_82B26740;
loc_82B2673C:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82B26740:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
loc_82B26744:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b2685c
	if (ctx.cr0.eq) goto loc_82B2685C;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12748(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12748);
	// addic. r30,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r30.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b267fc
	if (ctx.cr0.lt) goto loc_82B267FC;
loc_82B26768:
	// lwz r10,11852(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11852);
	// addi r9,r30,3278
	ctx.r9.s64 = ctx.r30.s64 + 3278;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r31.u32);
	// rlwimi r27,r9,17,0,14
	ctx.r27.u64 = (__builtin_rotateleft32(ctx.r9.u32, 17) & 0xFFFE0000) | (ctx.r27.u64 & 0xFFFFFFFF0001FFFF);
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// rlwinm. r10,r10,15,29,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0x7;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b267a4
	if (ctx.cr0.eq) goto loc_82B267A4;
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// bne cr6,0x82b267a8
	if (!ctx.cr6.eq) goto loc_82B267A8;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82b267a4
	if (!ctx.cr6.eq) goto loc_82B267A4;
	// lbz r10,10943(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10943);
	// rlwinm. r10,r10,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82b267a8
	if (!ctx.cr0.eq) goto loc_82B267A8;
loc_82B267A4:
	// rlwinm r29,r27,0,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0xFFFFFFFE;
loc_82B267A8:
	// rlwinm r9,r30,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 1) & 0xFFFFFFFE;
	// li r8,3
	ctx.r8.s64 = 3;
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// mr r10,r26
	ctx.r10.u64 = ctx.r26.u64;
	// slw r9,r8,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r9.u8 & 0x3F));
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r29,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r29.u32);
	ctx.r11.u32 = ea;
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// ble cr6,0x82b267f0
	if (!ctx.cr6.gt) goto loc_82B267F0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B267EC;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B267F0:
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bge 0x82b26768
	if (!ctx.cr0.lt) goto loc_82B26768;
	// b 0x82b26800
	goto loc_82B26800;
loc_82B267FC:
	// lwz r29,80(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82B26800:
	// cmplw cr6,r29,r27
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82b26838
	if (ctx.cr6.eq) goto loc_82B26838;
	// lbz r10,10940(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10940);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b26838
	if (ctx.cr0.eq) goto loc_82B26838;
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r27,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r27.u32);
	ctx.r11.u32 = ea;
loc_82B26838:
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12708(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12708);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12712(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12712);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// b 0x82b26894
	goto loc_82B26894;
loc_82B2685C:
	// lwz r9,11852(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11852);
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// rlwinm. r9,r9,0,12,14
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE0000;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne 0x82b26870
	if (!ctx.cr0.eq) goto loc_82B26870;
	// rlwinm r10,r27,0,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0xFFFFFFFE;
loc_82B26870:
	// li r9,8707
	ctx.r9.s64 = 8707;
	// cmplw cr6,r10,r27
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r27.u32, ctx.xer);
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// beq cr6,0x82b26894
	if (ctx.cr6.eq) goto loc_82B26894;
	// lbz r10,10940(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10940);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b26894
	if (ctx.cr0.eq) goto loc_82B26894;
	// mr r23,r27
	ctx.r23.u64 = ctx.r27.u64;
loc_82B26894:
	// li r12,-257
	ctx.r12.s64 = -257;
	// and r21,r21,r12
	ctx.r21.u64 = ctx.r21.u64 & ctx.r12.u64;
loc_82B2689C:
	// ld r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 40);
	// li r12,1
	ctx.r12.s64 = 1;
	// and r9,r10,r21
	ctx.r9.u64 = ctx.r10.u64 & ctx.r21.u64;
	// rldicr r12,r12,57,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 57) & 0xFFFFFFFFFFFFFFFF;
	// and r10,r9,r12
	ctx.r10.u64 = ctx.r9.u64 & ctx.r12.u64;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b268dc
	if (ctx.cr6.eq) goto loc_82B268DC;
	// li r8,8192
	ctx.r8.s64 = 8192;
	// lwz r10,10368(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10368);
	// li r12,-2
	ctx.r12.s64 = -2;
	// rldicr r12,r12,57,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 57) & 0xFFFFFFFFFFFFFFFF;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// and r21,r21,r12
	ctx.r21.u64 = ctx.r21.u64 & ctx.r12.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r22,13176(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13176);
	// rlwimi r22,r10,0,0,17
	ctx.r22.u64 = (__builtin_rotateleft32(ctx.r10.u32, 0) & 0xFFFFC000) | (ctx.r22.u64 & 0xFFFFFFFF00003FFF);
loc_82B268DC:
	// li r12,1
	ctx.r12.s64 = 1;
	// rldicr r12,r12,37,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 37) & 0xFFFFFFFFFFFFFFFF;
	// and r10,r9,r12
	ctx.r10.u64 = ctx.r9.u64 & ctx.r12.u64;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b26910
	if (ctx.cr6.eq) goto loc_82B26910;
	// li r10,8452
	ctx.r10.s64 = 8452;
	// li r12,-2
	ctx.r12.s64 = -2;
	// li r20,0
	ctx.r20.s64 = 0;
	// rldicr r12,r12,37,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 37) & 0xFFFFFFFFFFFFFFFF;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// and r21,r21,r12
	ctx.r21.u64 = ctx.r21.u64 & ctx.r12.u64;
	// lwz r10,10460(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10460);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
loc_82B26910:
	// and r10,r20,r22
	ctx.r10.u64 = ctx.r20.u64 & ctx.r22.u64;
	// and r10,r10,r23
	ctx.r10.u64 = ctx.r10.u64 & ctx.r23.u64;
	// cmpwi cr6,r10,-1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, -1, ctx.xer);
	// beq cr6,0x82b269ac
	if (ctx.cr6.eq) goto loc_82B269AC;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// lis r8,5461
	ctx.r8.s64 = 357892096;
	// cmpwi cr6,r23,-1
	ctx.cr6.compare<int32_t>(ctx.r23.s32, -1, ctx.xer);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// ori r8,r8,21845
	ctx.r8.u64 = ctx.r8.u64 | 21845;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// beq cr6,0x82b2695c
	if (ctx.cr6.eq) goto loc_82B2695C;
	// mr r10,r26
	ctx.r10.u64 = ctx.r26.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r24,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r24.u32);
	ctx.r11.u32 = ea;
	// stwu r23,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r23.u32);
	ctx.r11.u32 = ea;
loc_82B2695C:
	// cmpwi cr6,r22,-1
	ctx.cr6.compare<int32_t>(ctx.r22.s32, -1, ctx.xer);
	// beq cr6,0x82b26978
	if (ctx.cr6.eq) goto loc_82B26978;
	// mr r10,r26
	ctx.r10.u64 = ctx.r26.u64;
	// lis r9,4
	ctx.r9.s64 = 262144;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r22,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r22.u32);
	ctx.r11.u32 = ea;
loc_82B26978:
	// cmpwi cr6,r20,-1
	ctx.cr6.compare<int32_t>(ctx.r20.s32, -1, ctx.xer);
	// beq cr6,0x82b26994
	if (ctx.cr6.eq) goto loc_82B26994;
	// lis r10,4
	ctx.r10.s64 = 262144;
	// stwu r26,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r26.u32);
	ctx.r11.u32 = ea;
	// ori r10,r10,260
	ctx.r10.u64 = ctx.r10.u64 | 260;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r20,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r20.u32);
	ctx.r11.u32 = ea;
loc_82B26994:
	// stwu r28,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12708(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12708);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r25,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r25.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12712(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12712);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
loc_82B269AC:
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B269C0"))) PPC_WEAK_FUNC(sub_82B269C0);
PPC_FUNC_IMPL(__imp__sub_82B269C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B269C8;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// addi r29,r6,-4
	ctx.r29.s64 = ctx.r6.s64 + -4;
	// lwz r4,48(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 48);
loc_82B269DC:
	// cntlzd r11,r31
	ctx.r11.u64 = ctx.r31.u64 == 0 ? 64 : __builtin_clzll(ctx.r31.u64);
	// lwz r9,52(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 52);
	// clrldi r8,r11,32
	ctx.r8.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r11,r5
	ctx.r28.u64 = ctx.r11.u64 + ctx.r5.u64;
	// add r29,r10,r29
	ctx.r29.u64 = ctx.r10.u64 + ctx.r29.u64;
	// sld r31,r31,r8
	ctx.r31.u64 = ctx.r8.u8 & 0x40 ? 0 : (ctx.r31.u64 << (ctx.r8.u8 & 0x7F));
	// not r11,r31
	ctx.r11.u64 = ~ctx.r31.u64;
	// cntlzd r30,r11
	ctx.r30.u64 = ctx.r11.u64 == 0 ? 64 : __builtin_clzll(ctx.r11.u64);
	// rlwinm r27,r30,2,0,29
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// add r10,r27,r4
	ctx.r10.u64 = ctx.r27.u64 + ctx.r4.u64;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82b26a44
	if (ctx.cr6.lt) goto loc_82B26A44;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82b26370
	ctx.lr = 0x82B26A2C;
	sub_82B26370(ctx, base);
	// clrldi r11,r30,32
	ctx.r11.u64 = ctx.r30.u64 & 0xFFFFFFFF;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// add r29,r27,r29
	ctx.r29.u64 = ctx.r27.u64 + ctx.r29.u64;
	// add r5,r30,r28
	ctx.r5.u64 = ctx.r30.u64 + ctx.r28.u64;
	// sld r31,r31,r11
	ctx.r31.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r31.u64 << (ctx.r11.u8 & 0x7F));
	// b 0x82b26a6c
	goto loc_82B26A6C;
loc_82B26A44:
	// addi r10,r30,-1
	ctx.r10.s64 = ctx.r30.s64 + -1;
	// add r5,r30,r28
	ctx.r5.u64 = ctx.r30.u64 + ctx.r28.u64;
	// rlwinm r10,r10,16,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// or r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 | ctx.r28.u64;
	// stwu r10,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r4.u32 = ea;
loc_82B26A58:
	// lwzu r10,4(r29)
	ea = 4 + ctx.r29.u32;
	ctx.r10.u64 = PPC_LOAD_U32(ea);
	ctx.r29.u32 = ea;
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// rldicr r31,r31,1,62
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u64, 1) & 0xFFFFFFFFFFFFFFFE;
	// stwu r10,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r4.u32 = ea;
	// bne 0x82b26a58
	if (!ctx.cr0.eq) goto loc_82B26A58;
loc_82B26A6C:
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// bne cr6,0x82b269dc
	if (!ctx.cr6.eq) goto loc_82B269DC;
	// stw r4,48(r26)
	PPC_STORE_U32(ctx.r26.u32 + 48, ctx.r4.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B26A80"))) PPC_WEAK_FUNC(sub_82B26A80);
PPC_FUNC_IMPL(__imp__sub_82B26A80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82B26A88;
	__savegprlr_23(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// li r29,9096
	ctx.r29.s64 = 9096;
	// addi r31,r30,10272
	ctx.r31.s64 = ctx.r30.s64 + 10272;
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// lwz r10,56(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b26ab4
	if (!ctx.cr6.gt) goto loc_82B26AB4;
	// bl 0x82b1dae8
	ctx.lr = 0x82B26AB0;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B26AB4:
	// li r10,8199
	ctx.r10.s64 = 8199;
	// li r9,2609
	ctx.r9.s64 = 2609;
	// lis r8,1
	ctx.r8.s64 = 65536;
	// lis r7,1
	ctx.r7.s64 = 65536;
	// li r6,0
	ctx.r6.s64 = 0;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// ori r7,r7,2607
	ctx.r7.u64 = ctx.r7.u64 | 2607;
	// lwz r10,10396(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10396);
	// li r5,4096
	ctx.r5.s64 = 4096;
	// lis r4,-16380
	ctx.r4.s64 = -1073479680;
	// li r3,3
	ctx.r3.s64 = 3;
	// ori r4,r4,15360
	ctx.r4.u64 = ctx.r4.u64 | 15360;
	// li r27,2609
	ctx.r27.s64 = 2609;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// li r26,0
	ctx.r26.s64 = 0;
	// lis r24,-32768
	ctx.r24.s64 = -2147483648;
	// li r25,8
	ctx.r25.s64 = 8;
	// mr r23,r24
	ctx.r23.u64 = ctx.r24.u64;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r6,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r11.u32 = ea;
	// stwu r5,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r11.u32 = ea;
	// stwu r4,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	ctx.r11.u32 = ea;
	// stwu r3,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r11.u32 = ea;
	// stwu r27,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r27.u32);
	ctx.r11.u32 = ea;
	// stwu r26,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r26.u32);
	ctx.r11.u32 = ea;
	// stwu r23,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r23.u32);
	ctx.r11.u32 = ea;
	// stwu r25,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r25.u32);
	ctx.r11.u32 = ea;
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// stw r4,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r4.u32);
loc_82B26B34:
	// cntlzd r11,r28
	ctx.r11.u64 = ctx.r28.u64 == 0 ? 64 : __builtin_clzll(ctx.r28.u64);
	// lwz r9,52(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// clrldi r8,r11,32
	ctx.r8.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// rlwinm r10,r11,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r10,r31
	ctx.r31.u64 = ctx.r10.u64 + ctx.r31.u64;
	// add r27,r11,r29
	ctx.r27.u64 = ctx.r11.u64 + ctx.r29.u64;
	// sld r28,r28,r8
	ctx.r28.u64 = ctx.r8.u8 & 0x40 ? 0 : (ctx.r28.u64 << (ctx.r8.u8 & 0x7F));
	// not r11,r28
	ctx.r11.u64 = ~ctx.r28.u64;
	// cntlzd r26,r11
	ctx.r26.u64 = ctx.r11.u64 == 0 ? 64 : __builtin_clzll(ctx.r11.u64);
	// rlwinm r29,r26,2,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r25,r29,2,0,29
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r25,r4
	ctx.r11.u64 = ctx.r25.u64 + ctx.r4.u64;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82b26ba4
	if (ctx.cr6.lt) goto loc_82B26BA4;
	// li r8,4
	ctx.r8.s64 = 4;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b26370
	ctx.lr = 0x82B26B8C;
	sub_82B26370(ctx, base);
	// clrldi r11,r26,32
	ctx.r11.u64 = ctx.r26.u64 & 0xFFFFFFFF;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// add r31,r25,r31
	ctx.r31.u64 = ctx.r25.u64 + ctx.r31.u64;
	// add r29,r29,r27
	ctx.r29.u64 = ctx.r29.u64 + ctx.r27.u64;
	// sld r28,r28,r11
	ctx.r28.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r28.u64 << (ctx.r11.u8 & 0x7F));
	// b 0x82b26be8
	goto loc_82B26BE8;
loc_82B26BA4:
	// addi r10,r29,-1
	ctx.r10.s64 = ctx.r29.s64 + -1;
	// stw r24,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r24.u32);
	// clrlwi r11,r4,29
	ctx.r11.u64 = ctx.r4.u32 & 0x7;
	// rlwinm r10,r10,16,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// or r11,r10,r27
	ctx.r11.u64 = ctx.r10.u64 | ctx.r27.u64;
	// add r29,r29,r27
	ctx.r29.u64 = ctx.r29.u64 + ctx.r27.u64;
	// stwu r11,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r4.u32 = ea;
loc_82B26BC4:
	// ld r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 4);
	// addic. r26,r26,-1
	ctx.xer.ca = ctx.r26.u32 > 0;
	ctx.r26.s64 = ctx.r26.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// ld r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 12);
	// rldicr r28,r28,1,62
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r28.u64, 1) & 0xFFFFFFFFFFFFFFFE;
	// addi r31,r31,16
	ctx.r31.s64 = ctx.r31.s64 + 16;
	// std r11,4(r4)
	PPC_STORE_U64(ctx.r4.u32 + 4, ctx.r11.u64);
	// std r10,12(r4)
	PPC_STORE_U64(ctx.r4.u32 + 12, ctx.r10.u64);
	// addi r4,r4,16
	ctx.r4.s64 = ctx.r4.s64 + 16;
	// bne 0x82b26bc4
	if (!ctx.cr0.eq) goto loc_82B26BC4;
loc_82B26BE8:
	// cmpldi cr6,r28,0
	ctx.cr6.compare<uint64_t>(ctx.r28.u64, 0, ctx.xer);
	// bne cr6,0x82b26b34
	if (!ctx.cr6.eq) goto loc_82B26B34;
	// stw r4,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r4.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B26C00"))) PPC_WEAK_FUNC(sub_82B26C00);
PPC_FUNC_IMPL(__imp__sub_82B26C00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B26C08;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// addi r11,r28,1152
	ctx.r11.s64 = ctx.r28.s64 + 1152;
	// li r10,18432
	ctx.r10.s64 = 18432;
	// addi r30,r11,-4
	ctx.r30.s64 = ctx.r11.s64 + -4;
	// lwz r4,48(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 48);
loc_82B26C24:
	// cntlzd r11,r31
	ctx.r11.u64 = ctx.r31.u64 == 0 ? 64 : __builtin_clzll(ctx.r31.u64);
	// lwz r8,52(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 52);
	// clrldi r7,r11,32
	ctx.r7.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// mulli r9,r11,24
	ctx.r9.s64 = ctx.r11.s64 * 24;
	// mulli r11,r11,6
	ctx.r11.s64 = ctx.r11.s64 * 6;
	// sld r31,r31,r7
	ctx.r31.u64 = ctx.r7.u8 & 0x40 ? 0 : (ctx.r31.u64 << (ctx.r7.u8 & 0x7F));
	// add r27,r11,r10
	ctx.r27.u64 = ctx.r11.u64 + ctx.r10.u64;
	// not r11,r31
	ctx.r11.u64 = ~ctx.r31.u64;
	// add r30,r9,r30
	ctx.r30.u64 = ctx.r9.u64 + ctx.r30.u64;
	// cntlzd r26,r11
	ctx.r26.u64 = ctx.r11.u64 == 0 ? 64 : __builtin_clzll(ctx.r11.u64);
	// mulli r29,r26,6
	ctx.r29.s64 = ctx.r26.s64 * 6;
	// addi r11,r29,5
	ctx.r11.s64 = ctx.r29.s64 + 5;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// blt cr6,0x82b26ce8
	if (ctx.cr6.lt) goto loc_82B26CE8;
	// li r8,6
	ctx.r8.s64 = 6;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b26370
	ctx.lr = 0x82B26C7C;
	sub_82B26370(ctx, base);
	// clrldi r9,r26,32
	ctx.r9.u64 = ctx.r26.u64 & 0xFFFFFFFF;
	// rlwinm r11,r29,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// add r10,r29,r27
	ctx.r10.u64 = ctx.r29.u64 + ctx.r27.u64;
	// sld r31,r31,r9
	ctx.r31.u64 = ctx.r9.u8 & 0x40 ? 0 : (ctx.r31.u64 << (ctx.r9.u8 & 0x7F));
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// bne cr6,0x82b26c24
	if (!ctx.cr6.eq) goto loc_82B26C24;
	// lwz r10,56(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 56);
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// stw r4,48(r28)
	PPC_STORE_U32(ctx.r28.u32 + 48, ctx.r4.u32);
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b26cbc
	if (!ctx.cr6.gt) goto loc_82B26CBC;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B26CB8;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B26CBC:
	// lis r10,2
	ctx.r10.s64 = 131072;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r10,r10,20480
	ctx.r10.u64 = ctx.r10.u64 | 20480;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r28)
	PPC_STORE_U32(ctx.r28.u32 + 48, ctx.r11.u32);
	// b 0x82b26d58
	goto loc_82B26D58;
loc_82B26CE8:
	// lis r10,-32768
	ctx.r10.s64 = -2147483648;
	// addi r9,r29,-1
	ctx.r9.s64 = ctx.r29.s64 + -1;
	// clrlwi r11,r4,29
	ctx.r11.u64 = ctx.r4.u32 & 0x7;
	// rlwinm r9,r9,16,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0xFFFF0000;
	// stw r10,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r10.u32);
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
	// or r11,r9,r27
	ctx.r11.u64 = ctx.r9.u64 | ctx.r27.u64;
	// add r10,r29,r27
	ctx.r10.u64 = ctx.r29.u64 + ctx.r27.u64;
	// stwu r11,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r4.u32 = ea;
loc_82B26D0C:
	// ld r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r30.u32 + 4);
	// addic. r26,r26,-1
	ctx.xer.ca = ctx.r26.u32 > 0;
	ctx.r26.s64 = ctx.r26.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// ld r9,12(r30)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r30.u32 + 12);
	// rldicr r31,r31,1,62
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u64, 1) & 0xFFFFFFFFFFFFFFFE;
	// ld r8,20(r30)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r30.u32 + 20);
	// addi r30,r30,24
	ctx.r30.s64 = ctx.r30.s64 + 24;
	// std r11,4(r4)
	PPC_STORE_U64(ctx.r4.u32 + 4, ctx.r11.u64);
	// std r9,12(r4)
	PPC_STORE_U64(ctx.r4.u32 + 12, ctx.r9.u64);
	// std r8,20(r4)
	PPC_STORE_U64(ctx.r4.u32 + 20, ctx.r8.u64);
	// addi r4,r4,24
	ctx.r4.s64 = ctx.r4.s64 + 24;
	// bne 0x82b26d0c
	if (!ctx.cr0.eq) goto loc_82B26D0C;
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// bne cr6,0x82b26c24
	if (!ctx.cr6.eq) goto loc_82B26C24;
	// li r11,37
	ctx.r11.s64 = 37;
	// addi r10,r4,16
	ctx.r10.s64 = ctx.r4.s64 + 16;
	// rldicr r11,r11,44,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 44) & 0xFFFFF00000000000;
	// stw r10,48(r28)
	PPC_STORE_U32(ctx.r28.u32 + 48, ctx.r10.u32);
	// std r11,4(r4)
	PPC_STORE_U64(ctx.r4.u32 + 4, ctx.r11.u64);
	// std r11,12(r4)
	PPC_STORE_U64(ctx.r4.u32 + 12, ctx.r11.u64);
loc_82B26D58:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B26D60"))) PPC_WEAK_FUNC(sub_82B26D60);
PPC_FUNC_IMPL(__imp__sub_82B26D60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82B26D68;
	__savegprlr_21(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r31,r6,-4
	ctx.r31.s64 = ctx.r6.s64 + -4;
	// lis r25,-32768
	ctx.r25.s64 = -2147483648;
	// li r21,4
	ctx.r21.s64 = 4;
	// lwz r4,48(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 48);
	// li r22,20
	ctx.r22.s64 = 20;
	// li r23,36
	ctx.r23.s64 = 36;
	// li r24,52
	ctx.r24.s64 = 52;
loc_82B26D90:
	// cntlzd r11,r30
	ctx.r11.u64 = ctx.r30.u64 == 0 ? 64 : __builtin_clzll(ctx.r30.u64);
	// lwz r9,52(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 52);
	// clrldi r8,r11,32
	ctx.r8.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// rlwinm r10,r11,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r31,r10,r31
	ctx.r31.u64 = ctx.r10.u64 + ctx.r31.u64;
	// add r27,r11,r5
	ctx.r27.u64 = ctx.r11.u64 + ctx.r5.u64;
	// sld r30,r30,r8
	ctx.r30.u64 = ctx.r8.u8 & 0x40 ? 0 : (ctx.r30.u64 << (ctx.r8.u8 & 0x7F));
	// not r11,r30
	ctx.r11.u64 = ~ctx.r30.u64;
	// cntlzd r28,r11
	ctx.r28.u64 = ctx.r11.u64 == 0 ? 64 : __builtin_clzll(ctx.r11.u64);
	// rlwinm r29,r28,4,0,27
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r11,r29,3
	ctx.r11.s64 = ctx.r29.s64 + 3;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82b26e04
	if (ctx.cr6.lt) goto loc_82B26E04;
	// li r8,16
	ctx.r8.s64 = 16;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82b26370
	ctx.lr = 0x82B26DE8;
	sub_82B26370(ctx, base);
	// clrldi r10,r28,32
	ctx.r10.u64 = ctx.r28.u64 & 0xFFFFFFFF;
	// rlwinm r11,r29,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// add r31,r11,r31
	ctx.r31.u64 = ctx.r11.u64 + ctx.r31.u64;
	// add r5,r29,r27
	ctx.r5.u64 = ctx.r29.u64 + ctx.r27.u64;
	// sld r30,r30,r10
	ctx.r30.u64 = ctx.r10.u8 & 0x40 ? 0 : (ctx.r30.u64 << (ctx.r10.u8 & 0x7F));
	// b 0x82b26ea8
	goto loc_82B26EA8;
loc_82B26E04:
	// clrlwi r11,r4,28
	ctx.r11.u64 = ctx.r4.u32 & 0xF;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bne cr6,0x82b26e1c
	if (!ctx.cr6.eq) goto loc_82B26E1C;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stwu r11,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r4.u32 = ea;
	// b 0x82b26e60
	goto loc_82B26E60;
loc_82B26E1C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b26e38
	if (!ctx.cr6.eq) goto loc_82B26E38;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// stwu r11,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r4.u32 = ea;
	// stwu r10,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r4.u32 = ea;
	// b 0x82b26e60
	goto loc_82B26E60;
loc_82B26E38:
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bne cr6,0x82b26e60
	if (!ctx.cr6.eq) goto loc_82B26E60;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// stwu r11,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r4.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
loc_82B26E60:
	// addi r11,r29,-1
	ctx.r11.s64 = ctx.r29.s64 + -1;
	// add r5,r29,r27
	ctx.r5.u64 = ctx.r29.u64 + ctx.r27.u64;
	// rlwinm r11,r11,16,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 16) & 0xFFFF0000;
	// or r11,r11,r27
	ctx.r11.u64 = ctx.r11.u64 | ctx.r27.u64;
	// stwu r11,4(r4)
	ea = 4 + ctx.r4.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r4.u32 = ea;
loc_82B26E74:
	// lvx128 v0,r31,r21
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r31.u32 + ctx.r21.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lvx128 v13,r31,r22
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r31.u32 + ctx.r22.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// rldicr r30,r30,1,62
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r30.u64, 1) & 0xFFFFFFFFFFFFFFFE;
	// lvx128 v12,r31,r23
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r31.u32 + ctx.r23.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v11,r31,r24
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r31.u32 + ctx.r24.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r31,r31,64
	ctx.r31.s64 = ctx.r31.s64 + 64;
	// stvx128 v0,r4,r21
	_mm_store_si128((__m128i*)(base + ((ctx.r4.u32 + ctx.r21.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v13,r4,r22
	_mm_store_si128((__m128i*)(base + ((ctx.r4.u32 + ctx.r22.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v12,r4,r23
	_mm_store_si128((__m128i*)(base + ((ctx.r4.u32 + ctx.r23.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v11,r4,r24
	_mm_store_si128((__m128i*)(base + ((ctx.r4.u32 + ctx.r24.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r4,r4,64
	ctx.r4.s64 = ctx.r4.s64 + 64;
	// bne 0x82b26e74
	if (!ctx.cr0.eq) goto loc_82B26E74;
loc_82B26EA8:
	// cmpldi cr6,r30,0
	ctx.cr6.compare<uint64_t>(ctx.r30.u64, 0, ctx.xer);
	// bne cr6,0x82b26d90
	if (!ctx.cr6.eq) goto loc_82B26D90;
	// stw r4,48(r26)
	PPC_STORE_U32(ctx.r26.u32 + 48, ctx.r4.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B26EC0"))) PPC_WEAK_FUNC(sub_82B26EC0);
PPC_FUNC_IMPL(__imp__sub_82B26EC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82B26EC8;
	__savegprlr_20(ctx, base);
	// stwu r1,-592(r1)
	ea = -592 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r7,112
	ctx.r11.s64 = ctx.r7.s64 + 112;
	// mr r22,r4
	ctx.r22.u64 = ctx.r4.u64;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r11,r11,r3
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// addi r11,r11,872
	ctx.r11.s64 = ctx.r11.s64 + 872;
	// lwz r26,28(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// cmplwi r26,0
	ctx.cr0.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq 0x82b274c8
	if (ctx.cr0.eq) goto loc_82B274C8;
	// lwz r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// mulli r10,r7,416
	ctx.r10.s64 = ctx.r7.s64 * 416;
	// addi r9,r9,9
	ctx.r9.s64 = ctx.r9.s64 + 9;
	// lwz r25,24(r5)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// add r30,r9,r11
	ctx.r30.u64 = ctx.r9.u64 + ctx.r11.u64;
	// addi r10,r10,68
	ctx.r10.s64 = ctx.r10.s64 + 68;
	// mr r27,r30
	ctx.r27.u64 = ctx.r30.u64;
	// beq cr6,0x82b271fc
	if (ctx.cr6.eq) goto loc_82B271FC;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// lhz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r1.u32 + 80);
	// addi r24,r5,52
	ctx.r24.s64 = ctx.r5.s64 + 52;
	// subf r23,r11,r10
	ctx.r23.s64 = ctx.r10.s64 - ctx.r11.s64;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// addi r4,r11,-23144
	ctx.r4.s64 = ctx.r11.s64 + -23144;
loc_82B26F3C:
	// add r9,r23,r7
	ctx.r9.u64 = ctx.r23.u64 + ctx.r7.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r29,4(r9)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwz r28,8(r9)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// beq cr6,0x82b26f98
	if (ctx.cr6.eq) goto loc_82B26F98;
	// lwz r9,0(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// rlwinm r31,r9,20,28,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 20) & 0xF;
loc_82B26F64:
	// lbz r21,9(r5)
	ctx.r21.u64 = PPC_LOAD_U8(ctx.r5.u32 + 9);
	// cmplw cr6,r21,r31
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82b26f80
	if (!ctx.cr6.eq) goto loc_82B26F80;
	// lbz r21,10(r5)
	ctx.r21.u64 = PPC_LOAD_U8(ctx.r5.u32 + 10);
	// rlwinm r20,r9,16,28,31
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0xF;
	// cmplw cr6,r21,r20
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, ctx.r20.u32, ctx.xer);
	// beq cr6,0x82b26f90
	if (ctx.cr6.eq) goto loc_82B26F90;
loc_82B26F80:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r5,r5,12
	ctx.r5.s64 = ctx.r5.s64 + 12;
	// cmplw cr6,r10,r25
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r25.u32, ctx.xer);
	// blt cr6,0x82b26f64
	if (ctx.cr6.lt) goto loc_82B26F64;
loc_82B26F90:
	// cmplw cr6,r10,r25
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r25.u32, ctx.xer);
	// blt cr6,0x82b26fc8
	if (ctx.cr6.lt) goto loc_82B26FC8;
loc_82B26F98:
	// lis r12,-16442
	ctx.r12.s64 = -1077542912;
	// lbz r5,0(r6)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// li r10,95
	ctx.r10.s64 = 95;
	// ori r12,r12,53247
	ctx.r12.u64 = ctx.r12.u64 | 53247;
	// clrlwi r9,r8,28
	ctx.r9.u64 = ctx.r8.u32 & 0xF;
	// rlwimi r11,r10,20,2,11
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 20) & 0x3FF00000) | (ctx.r11.u64 & 0xFFFFFFFFC00FFFFF);
	// and r10,r29,r12
	ctx.r10.u64 = ctx.r29.u64 & ctx.r12.u64;
	// rlwinm r8,r28,0,0,0
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 0) & 0x80000000;
	// ori r9,r9,37456
	ctx.r9.u64 = ctx.r9.u64 | 37456;
	// oris r10,r10,6
	ctx.r10.u64 = ctx.r10.u64 | 393216;
	// or r5,r8,r5
	ctx.r5.u64 = ctx.r8.u64 | ctx.r5.u64;
	// b 0x82b270e8
	goto loc_82B270E8;
loc_82B26FC8:
	// lwz r10,4(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// clrlwi r9,r8,28
	ctx.r9.u64 = ctx.r8.u32 & 0xF;
	// rlwinm r31,r10,16,29,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0x7;
	// rlwinm r8,r10,22,26,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 22) & 0x38;
	// rlwinm r21,r10,13,29,31
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0x7;
	// or r8,r8,r31
	ctx.r8.u64 = ctx.r8.u64 | ctx.r31.u64;
	// rlwinm r31,r10,0,16,21
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFC00;
	// rlwinm r8,r8,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r20,r10,0,24,25
	ctx.r20.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xC0;
	// or r8,r8,r21
	ctx.r8.u64 = ctx.r8.u64 | ctx.r21.u64;
	// cmplwi cr6,r20,64
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 64, ctx.xer);
	// rlwinm r8,r8,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// or r8,r8,r31
	ctx.r8.u64 = ctx.r8.u64 | ctx.r31.u64;
	// rlwinm r8,r8,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// or r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 | ctx.r9.u64;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// bne cr6,0x82b2708c
	if (!ctx.cr6.eq) goto loc_82B2708C;
	// clrlwi r8,r9,16
	ctx.r8.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwinm r31,r8,0,0,18
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFE000;
	// cmplwi cr6,r31,24576
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 24576, ctx.xer);
	// bgt cr6,0x82b2702c
	if (ctx.cr6.gt) goto loc_82B2702C;
	// rlwinm r9,r8,0,16,18
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xE000;
	// clrlwi r8,r8,19
	ctx.r8.u64 = ctx.r8.u32 & 0x1FFF;
	// xori r9,r9,8192
	ctx.r9.u64 = ctx.r9.u64 ^ 8192;
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
loc_82B2702C:
	// clrlwi r8,r9,16
	ctx.r8.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwinm r31,r8,0,19,21
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x1C00;
	// cmplwi cr6,r31,3072
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 3072, ctx.xer);
	// bgt cr6,0x82b2704c
	if (ctx.cr6.gt) goto loc_82B2704C;
	// rlwinm r9,r8,0,19,21
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x1C00;
	// andi. r8,r8,58367
	ctx.r8.u64 = ctx.r8.u64 & 58367;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// xori r9,r9,1024
	ctx.r9.u64 = ctx.r9.u64 ^ 1024;
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
loc_82B2704C:
	// clrlwi r8,r9,16
	ctx.r8.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwinm r31,r8,0,22,24
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x380;
	// cmplwi cr6,r31,384
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 384, ctx.xer);
	// bgt cr6,0x82b2706c
	if (ctx.cr6.gt) goto loc_82B2706C;
	// rlwinm r9,r8,0,22,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x380;
	// andi. r8,r8,64639
	ctx.r8.u64 = ctx.r8.u64 & 64639;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// xori r9,r9,128
	ctx.r9.u64 = ctx.r9.u64 ^ 128;
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
loc_82B2706C:
	// clrlwi r8,r9,16
	ctx.r8.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwinm r31,r8,0,25,27
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x70;
	// cmplwi cr6,r31,48
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 48, ctx.xer);
	// bgt cr6,0x82b2708c
	if (ctx.cr6.gt) goto loc_82B2708C;
	// rlwinm r9,r8,0,25,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x70;
	// andi. r8,r8,65423
	ctx.r8.u64 = ctx.r8.u64 & 65423;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// xori r9,r9,16
	ctx.r9.u64 = ctx.r9.u64 ^ 16;
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
loc_82B2708C:
	// rlwinm r21,r10,12,14,19
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0x3F000;
	// lhz r8,0(r5)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r5.u32 + 0);
	// rlwinm r10,r10,0,22,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x300;
	// lhz r5,2(r5)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r5.u32 + 2);
	// lis r12,-16448
	ctx.r12.s64 = -1077936128;
	// or r10,r21,r10
	ctx.r10.u64 = ctx.r21.u64 | ctx.r10.u64;
	// ori r12,r12,53247
	ctx.r12.u64 = ctx.r12.u64 | 53247;
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// lbzx r21,r8,r6
	ctx.r21.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r6.u32);
	// and r29,r29,r12
	ctx.r29.u64 = ctx.r29.u64 & ctx.r12.u64;
	// lis r31,342
	ctx.r31.s64 = 22413312;
	// or r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 | ctx.r29.u64;
	// ori r31,r31,86
	ctx.r31.u64 = ctx.r31.u64 | 86;
	// subfic r29,r8,95
	ctx.xer.ca = ctx.r8.u32 <= 95;
	ctx.r29.s64 = 95 - ctx.r8.s64;
	// rlwinm r5,r5,6,1,23
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 6) & 0x7FFFFF00;
	// mullw r8,r29,r31
	ctx.r8.s64 = int64_t(ctx.r29.s32) * int64_t(ctx.r31.s32);
	// mr r31,r8
	ctx.r31.u64 = ctx.r8.u64;
	// rlwinm r28,r28,0,0,0
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 0) & 0x80000000;
	// or r5,r5,r21
	ctx.r5.u64 = ctx.r5.u64 | ctx.r21.u64;
	// rlwimi r31,r8,11,8,12
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r8.u32, 11) & 0xF80000) | (ctx.r31.u64 & 0xFFFFFFFFFF07FFFF);
	// or r5,r5,r28
	ctx.r5.u64 = ctx.r5.u64 | ctx.r28.u64;
	// rlwimi r11,r31,1,5,11
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r31.u32, 1) & 0x7F00000) | (ctx.r11.u64 & 0xFFFFFFFFF80FFFFF);
	// rlwinm r11,r11,0,5,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFC7FFFFFF;
loc_82B270E8:
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r11.u32);
	// stw r5,8(r7)
	PPC_STORE_U32(ctx.r7.u32 + 8, ctx.r5.u32);
	// addic. r3,r3,-1
	ctx.xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// ori r8,r9,14
	ctx.r8.u64 = ctx.r9.u64 | 14;
	// rlwinm r9,r10,1,28,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xE;
	// clrlwi r11,r8,16
	ctx.r11.u64 = ctx.r8.u32 & 0xFFFF;
	// clrlwi r31,r8,16
	ctx.r31.u64 = ctx.r8.u32 & 0xFFFF;
	// clrlwi r29,r8,16
	ctx.r29.u64 = ctx.r8.u32 & 0xFFFF;
	// clrlwi r28,r8,16
	ctx.r28.u64 = ctx.r8.u32 & 0xFFFF;
	// lhzx r9,r9,r4
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r9.u32 + ctx.r4.u32);
	// addi r27,r27,4
	ctx.r27.s64 = ctx.r27.s64 + 4;
	// and r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 & ctx.r11.u64;
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// rlwinm r9,r11,29,3,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// or r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 | ctx.r11.u64;
	// rlwinm r9,r9,29,3,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFF;
	// or r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 | ctx.r11.u64;
	// rlwinm r9,r9,29,3,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFF;
	// or r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 | ctx.r11.u64;
	// rlwinm r9,r9,29,3,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFF;
	// or r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 | ctx.r11.u64;
	// rlwimi r10,r11,31,29,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 31) & 0x7) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFF8);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// rlwinm r11,r9,30,28,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0xE;
	// lhzx r11,r11,r4
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + ctx.r4.u32);
	// and r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 & ctx.r31.u64;
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// rlwinm r10,r11,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | ctx.r11.u64;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | ctx.r11.u64;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// or r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 | ctx.r11.u64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// or r10,r11,r31
	ctx.r10.u64 = ctx.r11.u64 | ctx.r31.u64;
	// rlwimi r10,r9,0,29,25
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFFFFFFFFFFFFFFC7) | (ctx.r10.u64 & 0x38);
	// rlwinm r11,r10,27,28,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0xE;
	// lhzx r11,r11,r4
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + ctx.r4.u32);
	// and r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 & ctx.r29.u64;
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// rlwinm r9,r11,29,3,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// rlwinm r31,r11,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// or r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 | ctx.r11.u64;
	// or r31,r31,r11
	ctx.r31.u64 = ctx.r31.u64 | ctx.r11.u64;
	// rlwinm r9,r9,29,3,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFF;
	// rlwinm r31,r31,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 | ctx.r11.u64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// or r9,r11,r31
	ctx.r9.u64 = ctx.r11.u64 | ctx.r31.u64;
	// rlwimi r9,r10,0,26,22
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r10.u32, 0) & 0xFFFFFFFFFFFFFE3F) | (ctx.r9.u64 & 0x1C0);
	// rlwinm r11,r9,24,28,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xE;
	// lhzx r11,r11,r4
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + ctx.r4.u32);
	// and r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 & ctx.r28.u64;
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r31,r11,29,3,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | ctx.r11.u64;
	// or r31,r31,r11
	ctx.r31.u64 = ctx.r31.u64 | ctx.r11.u64;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r31,r31,31,1,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 31) & 0x7FFFFFFF;
	// or r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 | ctx.r11.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 | ctx.r31.u64;
	// rlwimi r11,r9,0,23,19
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFFFFFFFFFFFFF1FF) | (ctx.r11.u64 & 0xE00);
	// stw r11,4(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4, ctx.r11.u32);
	// addi r7,r7,12
	ctx.r7.s64 = ctx.r7.s64 + 12;
	// bne 0x82b26f3c
	if (!ctx.cr0.eq) goto loc_82B26F3C;
loc_82B271FC:
	// rlwinm r11,r26,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r27,r30
	ctx.r27.u64 = ctx.r30.u64;
	// add r26,r11,r30
	ctx.r26.u64 = ctx.r11.u64 + ctx.r30.u64;
	// cmplw cr6,r30,r26
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r26.u32, ctx.xer);
	// bge cr6,0x82b2748c
	if (!ctx.cr6.lt) goto loc_82B2748C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r25,r11,-23128
	ctx.r25.s64 = ctx.r11.s64 + -23128;
loc_82B27218:
	// cmplw cr6,r27,r26
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r26.u32, ctx.xer);
	// bge cr6,0x82b2748c
	if (!ctx.cr6.lt) goto loc_82B2748C;
loc_82B27220:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// rlwinm. r11,r11,0,10,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x300000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b27238
	if (!ctx.cr0.eq) goto loc_82B27238;
	// addi r27,r27,4
	ctx.r27.s64 = ctx.r27.s64 + 4;
	// cmplw cr6,r27,r26
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r26.u32, ctx.xer);
	// blt cr6,0x82b27220
	if (ctx.cr6.lt) goto loc_82B27220;
loc_82B27238:
	// cmplw cr6,r27,r26
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r26.u32, ctx.xer);
	// bge cr6,0x82b2748c
	if (!ctx.cr6.lt) goto loc_82B2748C;
	// addi r11,r27,4
	ctx.r11.s64 = ctx.r27.s64 + 4;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// bge cr6,0x82b2748c
	if (!ctx.cr6.lt) goto loc_82B2748C;
loc_82B27250:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// rlwinm. r9,r9,0,10,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x300000;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne 0x82b27268
	if (!ctx.cr0.eq) goto loc_82B27268;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// blt cr6,0x82b27250
	if (ctx.cr6.lt) goto loc_82B27250;
loc_82B27268:
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// bge cr6,0x82b2748c
	if (!ctx.cr6.lt) goto loc_82B2748C;
	// subf r8,r30,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r30.s64;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// subf r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// srawi r10,r10,2
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 2;
	// srawi r8,r8,2
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x3) != 0);
	ctx.r8.s64 = ctx.r8.s32 >> 2;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// mulli r10,r8,12
	ctx.r10.s64 = ctx.r8.s64 * 12;
	// add r3,r10,r9
	ctx.r3.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r8,r5,0,10,11
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x300000;
	// lis r7,48
	ctx.r7.s64 = 3145728;
	// addi r9,r6,-1
	ctx.r9.s64 = ctx.r6.s64 + -1;
	// addi r27,r11,4
	ctx.r27.s64 = ctx.r11.s64 + 4;
	// li r31,-1
	ctx.r31.s64 = -1;
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// bne cr6,0x82b272e0
	if (!ctx.cr6.eq) goto loc_82B272E0;
	// subf r11,r30,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r30.s64;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// srawi r11,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 2;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// mulli r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 * 12;
	// lwzx r11,r11,r8
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// rlwinm r9,r11,14,25,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 14) & 0x7C;
	// rlwinm r11,r11,7,30,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 7) & 0x3;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// or r31,r9,r11
	ctx.r31.u64 = ctx.r9.u64 | ctx.r11.u64;
loc_82B272E0:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b273d4
	if (ctx.cr6.eq) goto loc_82B273D4;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r28,r10
	ctx.r28.u64 = ctx.r10.u64;
loc_82B272F4:
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// bge cr6,0x82b273c4
	if (!ctx.cr6.lt) goto loc_82B273C4;
	// addi r10,r11,12
	ctx.r10.s64 = ctx.r11.s64 + 12;
	// subf r29,r4,r5
	ctx.r29.s64 = ctx.r5.s64 - ctx.r4.s64;
loc_82B27304:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r7,r9,14,25,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 14) & 0x7C;
	// rlwinm r9,r9,7,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0x3;
	// rlwinm r24,r8,14,25,29
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 14) & 0x7C;
	// rlwinm r23,r8,7,30,31
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 7) & 0x3;
	// or r8,r7,r9
	ctx.r8.u64 = ctx.r7.u64 | ctx.r9.u64;
	// or r7,r24,r23
	ctx.r7.u64 = ctx.r24.u64 | ctx.r23.u64;
	// subf. r9,r8,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r8.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82b27344
	if (ctx.cr0.eq) goto loc_82B27344;
	// cmpw cr6,r31,r8
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r8.s32, ctx.xer);
	// beq cr6,0x82b27388
	if (ctx.cr6.eq) goto loc_82B27388;
	// cmpw cr6,r31,r7
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r7.s32, ctx.xer);
	// bne cr6,0x82b27380
	if (!ctx.cr6.eq) goto loc_82B27380;
	// li r9,-1
	ctx.r9.s64 = -1;
	// b 0x82b27380
	goto loc_82B27380;
loc_82B27344:
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r9,r9,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r8,r8,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// srawi r9,r9,9
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1FF) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 9;
	// srawi r8,r8,9
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x1FF) != 0);
	ctx.r8.s64 = ctx.r8.s32 >> 9;
	// subf. r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne 0x82b27380
	if (!ctx.cr0.eq) goto loc_82B27380;
	// lhz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// lhz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r10.u32 + 4);
	// clrlwi r9,r9,26
	ctx.r9.u64 = ctx.r9.u32 & 0x3F;
	// clrlwi r8,r8,26
	ctx.r8.u64 = ctx.r8.u32 & 0x3F;
	// lbzx r9,r9,r25
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r25.u32);
	// lbzx r8,r8,r25
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r25.u32);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
loc_82B27380:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// ble cr6,0x82b273b8
	if (!ctx.cr6.gt) goto loc_82B273B8;
loc_82B27388:
	// lwz r24,0(r10)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r24,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r24.u32);
	// lwz r24,4(r10)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r24,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r24.u32);
	// lwz r24,8(r10)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stw r24,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r24.u32);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
loc_82B273B8:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// bne 0x82b27304
	if (!ctx.cr0.eq) goto loc_82B27304;
loc_82B273C4:
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// bne 0x82b272f4
	if (!ctx.cr0.eq) goto loc_82B272F4;
loc_82B273D4:
	// mulli r11,r6,12
	ctx.r11.s64 = ctx.r6.s64 * 12;
	// add r6,r11,r3
	ctx.r6.u64 = ctx.r11.u64 + ctx.r3.u64;
	// addi r11,r3,12
	ctx.r11.s64 = ctx.r3.s64 + 12;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// b 0x82b27480
	goto loc_82B27480;
loc_82B273E8:
	// lwz r8,0(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
	// rlwimi r9,r8,25,12,13
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r8.u32, 25) & 0xC0000) | (ctx.r9.u64 & 0xFFFFFFFFFFF3FFFF);
	// rlwimi r5,r10,25,12,13
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r10.u32, 25) & 0xC0000) | (ctx.r5.u64 & 0xFFFFFFFFFFF3FFFF);
	// rlwinm r10,r9,0,7,13
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1FC0000;
	// rlwinm r9,r5,0,7,13
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x1FC0000;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82b27478
	if (!ctx.cr6.eq) goto loc_82B27478;
	// lwz r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r9,r9,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// srawi r10,r10,9
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1FF) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 9;
	// srawi r9,r9,9
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1FF) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 9;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bgt cr6,0x82b27478
	if (ctx.cr6.gt) goto loc_82B27478;
	// lhz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// clrlwi r5,r5,26
	ctx.r5.u64 = ctx.r5.u32 & 0x3F;
	// lbzx r5,r5,r25
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r5.u32 + ctx.r25.u32);
	// subf r10,r10,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r10.s64;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplwi cr6,r10,8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 8, ctx.xer);
	// bgt cr6,0x82b27478
	if (ctx.cr6.gt) goto loc_82B27478;
	// rlwinm r9,r8,5,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0x7;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b27460
	if (!ctx.cr6.gt) goto loc_82B27460;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_82B27460:
	// rlwimi r8,r10,27,2,4
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 27) & 0x38000000) | (ctx.r8.u64 & 0xFFFFFFFFC7FFFFFF);
	// stw r8,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r8.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// oris r10,r10,16384
	ctx.r10.u64 = ctx.r10.u64 | 1073741824;
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// b 0x82b2747c
	goto loc_82B2747C;
loc_82B27478:
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82B2747C:
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
loc_82B27480:
	// cmplw cr6,r11,r6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82b273e8
	if (ctx.cr6.lt) goto loc_82B273E8;
	// b 0x82b27218
	goto loc_82B27218;
loc_82B2748C:
	// addi r31,r1,96
	ctx.r31.s64 = ctx.r1.s64 + 96;
	// b 0x82b274c0
	goto loc_82B274C0;
loc_82B27494:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// clrlwi r11,r11,20
	ctx.r11.u64 = ctx.r11.u32 & 0xFFF;
	// mulli r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 * 12;
	// add r3,r11,r22
	ctx.r3.u64 = ctx.r11.u64 + ctx.r22.u64;
	// cmplw cr6,r3,r31
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82b274b8
	if (ctx.cr6.eq) goto loc_82B274B8;
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B274B8;
	sub_82E28FD0(ctx, base);
loc_82B274B8:
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// addi r31,r31,12
	ctx.r31.s64 = ctx.r31.s64 + 12;
loc_82B274C0:
	// cmplw cr6,r30,r26
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r26.u32, ctx.xer);
	// blt cr6,0x82b27494
	if (ctx.cr6.lt) goto loc_82B27494;
loc_82B274C8:
	// addi r1,r1,592
	ctx.r1.s64 = ctx.r1.s64 + 592;
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B274D0"))) PPC_WEAK_FUNC(sub_82B274D0);
PPC_FUNC_IMPL(__imp__sub_82B274D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r8,28(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r7,r10,27,27,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1F;
	// lhz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r5.u32 + 0);
	// lwz r9,24(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// clrlwi r10,r10,20
	ctx.r10.u64 = ctx.r10.u32 & 0xFFF;
	// li r4,1
	ctx.r4.s64 = 1;
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
	// std r6,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r6.u64);
	// stw r6,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r6.u32);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwimi r11,r4,25,3,7
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r4.u32, 25) & 0x1F000000) | (ctx.r11.u64 & 0xFFFFFFFFE0FFFFFF);
	// addi r10,r10,9
	ctx.r10.s64 = ctx.r10.s64 + 9;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r10,r3
	ctx.r31.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// clrlwi r10,r10,6
	ctx.r10.u64 = ctx.r10.u32 & 0x3FFFFFF;
	// oris r10,r10,51200
	ctx.r10.u64 = ctx.r10.u64 | 3355443200;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
loc_82B27548:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// clrlwi r11,r11,20
	ctx.r11.u64 = ctx.r11.u32 & 0xFFF;
	// mulli r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 * 12;
	// add r3,r11,r30
	ctx.r3.u64 = ctx.r11.u64 + ctx.r30.u64;
	// cmplw cr6,r3,r10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b27570
	if (ctx.cr6.eq) goto loc_82B27570;
	// li r5,12
	ctx.r5.s64 = 12;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82e28fd0
	ctx.lr = 0x82B27570;
	sub_82E28FD0(ctx, base);
loc_82B27570:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// rlwinm. r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b27584
	if (!ctx.cr0.eq) goto loc_82B27584;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// b 0x82b27548
	goto loc_82B27548;
loc_82B27584:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B275A0"))) PPC_WEAK_FUNC(sub_82B275A0);
PPC_FUNC_IMPL(__imp__sub_82B275A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B275A8;
	__savegprlr_28(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,20(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r9,28(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// rlwinm r8,r11,27,27,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1F;
	// lhz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r5.u32 + 0);
	// lwz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// clrlwi r11,r11,20
	ctx.r11.u64 = ctx.r11.u32 & 0xFFF;
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,9
	ctx.r11.s64 = ctx.r11.s64 + 9;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r30,r11,r3
	ctx.r30.u64 = ctx.r11.u64 + ctx.r3.u64;
loc_82B275E4:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// clrlwi r11,r11,20
	ctx.r11.u64 = ctx.r11.u32 & 0xFFF;
	// mulli r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 * 12;
	// add r31,r11,r29
	ctx.r31.u64 = ctx.r11.u64 + ctx.r29.u64;
	// cmplw cr6,r10,r31
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82b27610
	if (ctx.cr6.eq) goto loc_82B27610;
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82e28fd0
	ctx.lr = 0x82B27610;
	sub_82E28FD0(ctx, base);
loc_82B27610:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmplw cr6,r31,r9
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r9.u32, ctx.xer);
	// rlwimi r10,r11,24,28,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 24) & 0xF) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFF0);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// beq cr6,0x82b2763c
	if (ctx.cr6.eq) goto loc_82B2763C;
	// li r5,12
	ctx.r5.s64 = 12;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B2763C;
	sub_82E28FD0(ctx, base);
loc_82B2763C:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm. r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b27650
	if (!ctx.cr0.eq) goto loc_82B27650;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// b 0x82b275e4
	goto loc_82B275E4;
loc_82B27650:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B27658"))) PPC_WEAK_FUNC(sub_82B27658);
PPC_FUNC_IMPL(__imp__sub_82B27658) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82B27660;
	__savegprlr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r23,r5
	ctx.r23.u64 = ctx.r5.u64;
	// mr r22,r6
	ctx.r22.u64 = ctx.r6.u64;
	// lbz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 8);
	// clrlwi r11,r11,29
	ctx.r11.u64 = ctx.r11.u32 & 0x7;
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// beq cr6,0x82b277a0
	if (ctx.cr6.eq) goto loc_82B277A0;
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// rlwinm. r11,r10,0,13,13
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b277a0
	if (!ctx.cr0.eq) goto loc_82B277A0;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82b276a0
	if (ctx.cr6.eq) goto loc_82B276A0;
	// lwz r11,20(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// rlwinm. r11,r11,0,14,14
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b277a0
	if (!ctx.cr0.eq) goto loc_82B277A0;
loc_82B276A0:
	// rlwinm r26,r10,27,27,31
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1F;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,9
	ctx.r11.s64 = ctx.r11.s64 + 9;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r11,r30
	ctx.r31.u64 = ctx.r11.u64 + ctx.r30.u64;
	// beq cr6,0x82b276e4
	if (ctx.cr6.eq) goto loc_82B276E4;
	// lwz r11,20(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// addi r28,r7,32
	ctx.r28.s64 = ctx.r7.s64 + 32;
	// clrlwi. r24,r11,27
	ctx.r24.u64 = ctx.r11.u32 & 0x1F;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// rlwinm r11,r11,27,27,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1F;
	// beq 0x82b276f0
	if (ctx.cr0.eq) goto loc_82B276F0;
	// addi r24,r24,-1
	ctx.r24.s64 = ctx.r24.s64 + -1;
	// b 0x82b276f0
	goto loc_82B276F0;
loc_82B276E4:
	// li r28,0
	ctx.r28.s64 = 0;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r24,0
	ctx.r24.s64 = 0;
loc_82B276F0:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b2776c
	if (ctx.cr6.eq) goto loc_82B2776C;
	// mr r25,r11
	ctx.r25.u64 = ctx.r11.u64;
loc_82B276FC:
	// lbz r27,3(r28)
	ctx.r27.u64 = PPC_LOAD_U8(ctx.r28.u32 + 3);
	// b 0x82b27728
	goto loc_82B27728;
loc_82B27704:
	// lbz r11,3(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 3);
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// bge cr6,0x82b27730
	if (!ctx.cr6.lt) goto loc_82B27730;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b274d0
	ctx.lr = 0x82B27720;
	sub_82B274D0(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
loc_82B27728:
	// cmplw cr6,r29,r26
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r26.u32, ctx.xer);
	// blt cr6,0x82b27704
	if (ctx.cr6.lt) goto loc_82B27704;
loc_82B27730:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// xor r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 ^ ctx.r10.u64;
	// rlwinm. r11,r11,0,20,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xF00;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27758
	if (ctx.cr0.eq) goto loc_82B27758;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b275a0
	ctx.lr = 0x82B27758;
	sub_82B275A0(ctx, base);
loc_82B27758:
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r28,r28,4
	ctx.r28.s64 = ctx.r28.s64 + 4;
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// bne 0x82b276fc
	if (!ctx.cr0.eq) goto loc_82B276FC;
loc_82B2776C:
	// cmplw cr6,r29,r26
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r26.u32, ctx.xer);
	// bge cr6,0x82b27794
	if (!ctx.cr6.lt) goto loc_82B27794;
	// subf r29,r29,r26
	ctx.r29.s64 = ctx.r26.s64 - ctx.r29.s64;
loc_82B27778:
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b274d0
	ctx.lr = 0x82B27788;
	sub_82B274D0(ctx, base);
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x82b27778
	if (!ctx.cr0.eq) goto loc_82B27778;
loc_82B27794:
	// lwz r11,0(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// rlwimi r11,r24,20,8,11
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r24.u32, 20) & 0xF00000) | (ctx.r11.u64 & 0xFFFFFFFFFF0FFFFF);
	// stw r11,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r11.u32);
loc_82B277A0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B277A8"))) PPC_WEAK_FUNC(sub_82B277A8);
PPC_FUNC_IMPL(__imp__sub_82B277A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82B277B0;
	__savegprlr_19(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r10
	ctx.r23.u64 = ctx.r10.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// addi r11,r23,112
	ctx.r11.s64 = ctx.r23.s64 + 112;
	// mr r24,r4
	ctx.r24.u64 = ctx.r4.u64;
	// rlwinm r29,r11,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r21,r6
	ctx.r21.u64 = ctx.r6.u64;
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// mr r20,r8
	ctx.r20.u64 = ctx.r8.u64;
	// lwzx r11,r29,r31
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r31.u32);
	// mr r19,r9
	ctx.r19.u64 = ctx.r9.u64;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r27,876(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 876);
	// rlwinm r28,r27,30,2,31
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r4,r28,5
	ctx.r4.s64 = ctx.r28.s64 + 5;
	// bl 0x82b1dd08
	ctx.lr = 0x82B277F4;
	sub_82B1DD08(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b27900
	if (ctx.cr0.eq) goto loc_82B27900;
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// li r10,256
	ctx.r10.s64 = 256;
	// ori r11,r11,15104
	ctx.r11.u64 = ctx.r11.u64 | 15104;
	// lis r8,-16384
	ctx.r8.s64 = -1073741824;
	// addi r9,r28,1
	ctx.r9.s64 = ctx.r28.s64 + 1;
	// ori r8,r8,11008
	ctx.r8.u64 = ctx.r8.u64 | 11008;
	// li r7,0
	ctx.r7.s64 = 0;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// rlwimi r8,r9,16,2,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 16) & 0x3FFF0000) | (ctx.r8.u64 & 0xFFFFFFFFC000FFFF);
	// clrlwi r11,r28,18
	ctx.r11.u64 = ctx.r28.u32 & 0x3FFF;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// stwu r7,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r3.u32 = ea;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwzx r11,r29,r31
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r31.u32);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// addi r26,r25,4
	ctx.r26.s64 = ctx.r25.s64 + 4;
	// lwz r11,872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 872);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r9,r11,12,20,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0xFFF;
	// clrlwi r10,r11,3
	ctx.r10.u64 = ctx.r11.u32 & 0x1FFFFFFF;
	// addi r11,r9,512
	ctx.r11.s64 = ctx.r9.s64 + 512;
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addis r29,r11,-16384
	ctx.r29.s64 = ctx.r11.s64 + -1073741824;
	// sync 
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B2787C;
	sub_82E28FD0(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// add r4,r29,r27
	ctx.r4.u64 = ctx.r29.u64 + ctx.r27.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b28870
	ctx.lr = 0x82B2788C;
	sub_82B28870(ctx, base);
	// cmpwi cr6,r24,0
	ctx.cr6.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// beq cr6,0x82b278ac
	if (ctx.cr6.eq) goto loc_82B278AC;
	// mr r7,r19
	ctx.r7.u64 = ctx.r19.u64;
	// mr r6,r21
	ctx.r6.u64 = ctx.r21.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r20
	ctx.r4.u64 = ctx.r20.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82b27658
	ctx.lr = 0x82B278AC;
	sub_82B27658(ctx, base);
loc_82B278AC:
	// cntlzw r10,r24
	ctx.r10.u64 = ctx.r24.u32 == 0 ? 32 : __builtin_clz(ctx.r24.u32);
	// lbz r11,10942(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10942);
	// addi r6,r30,12528
	ctx.r6.s64 = ctx.r30.s64 + 12528;
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// clrlwi r11,r11,25
	ctx.r11.u64 = ctx.r11.u32 & 0x7F;
	// rlwinm r10,r10,7,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x80;
	// mr r7,r23
	ctx.r7.u64 = ctx.r23.u64;
	// xori r10,r10,128
	ctx.r10.u64 = ctx.r10.u64 ^ 128;
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// or r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 | ctx.r11.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stb r11,10942(r30)
	PPC_STORE_U8(ctx.r30.u32 + 10942, ctx.r11.u8);
	// bl 0x82b26ec0
	ctx.lr = 0x82B278E4;
	sub_82B26EC0(ctx, base);
	// rlwinm r11,r28,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// ld r10,12528(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 12528);
	// ld r9,12536(r30)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r30.u32 + 12536);
	// add r11,r11,r25
	ctx.r11.u64 = ctx.r11.u64 + ctx.r25.u64;
	// std r10,11832(r30)
	PPC_STORE_U64(ctx.r30.u32 + 11832, ctx.r10.u64);
	// std r9,11840(r30)
	PPC_STORE_U64(ctx.r30.u32 + 11840, ctx.r9.u64);
	// stw r11,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r11.u32);
loc_82B27900:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B27908"))) PPC_WEAK_FUNC(sub_82B27908);
PPC_FUNC_IMPL(__imp__sub_82B27908) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82B27910;
	__savegprlr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,20(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b279b0
	if (ctx.cr0.eq) goto loc_82B279B0;
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// addi r31,r11,20
	ctx.r31.s64 = ctx.r11.s64 + 20;
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// add r27,r11,r31
	ctx.r27.u64 = ctx.r11.u64 + ctx.r31.u64;
	// b 0x82b279a8
	goto loc_82B279A8;
loc_82B2793C:
	// lhz r28,2(r31)
	ctx.r28.u64 = PPC_LOAD_U16(ctx.r31.u32 + 2);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// lhz r26,0(r31)
	ctx.r26.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi r28,0
	ctx.cr0.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq 0x82b279b0
	if (ctx.cr0.eq) goto loc_82B279B0;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r31,r11,4
	ctx.r31.s64 = ctx.r11.s64 + 4;
	// lwz r3,48(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	// lwz r11,56(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	// add r30,r10,r25
	ctx.r30.u64 = ctx.r10.u64 + ctx.r25.u64;
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b27974
	if (!ctx.cr6.gt) goto loc_82B27974;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B27974;
	sub_82B1DAE8(ctx, base);
loc_82B27974:
	// lis r11,-16382
	ctx.r11.s64 = -1073610752;
	// clrlwi r10,r30,3
	ctx.r10.u64 = ctx.r30.u32 & 0x1FFFFFFF;
	// ori r9,r11,12032
	ctx.r9.u64 = ctx.r11.u64 | 12032;
	// rlwinm r11,r30,12,20,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 12) & 0xFFF;
	// rlwinm r8,r26,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,512
	ctx.r11.s64 = ctx.r11.s64 + 512;
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// stwu r28,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r3.u32 = ea;
	// stw r3,48(r29)
	PPC_STORE_U32(ctx.r29.u32 + 48, ctx.r3.u32);
loc_82B279A8:
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82b2793c
	if (ctx.cr6.lt) goto loc_82B2793C;
loc_82B279B0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B279B8"))) PPC_WEAK_FUNC(sub_82B279B8);
PPC_FUNC_IMPL(__imp__sub_82B279B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B279C0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mulli r11,r7,416
	ctx.r11.s64 = ctx.r7.s64 * 416;
	// lwz r10,48(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// add r28,r11,r4
	ctx.r28.u64 = ctx.r11.u64 + ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,40(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 40);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82b27a20
	if (!ctx.cr6.eq) goto loc_82B27A20;
	// ld r10,12528(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 12528);
	// addi r29,r31,12528
	ctx.r29.s64 = ctx.r31.s64 + 12528;
	// ld r11,48(r28)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r28.u32 + 48);
	// ld r9,56(r28)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r28.u32 + 56);
	// ld r8,12536(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 12536);
	// xor r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 ^ ctx.r10.u64;
	// ld r10,32(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 32);
	// ld r6,40(r30)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r30.u32 + 40);
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// and r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ctx.r10.u64;
	// and r10,r9,r6
	ctx.r10.u64 = ctx.r9.u64 & ctx.r6.u64;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82b27adc
	if (ctx.cr6.eq) goto loc_82B27ADC;
loc_82B27A20:
	// lwz r9,64(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 64);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq 0x82b27a50
	if (ctx.cr0.eq) goto loc_82B27A50;
	// lwz r10,10896(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10896);
	// lwz r11,10908(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10908);
	// subf r9,r9,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r9.s64;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82b27a50
	if (!ctx.cr6.lt) goto loc_82B27A50;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b27af0
	goto loc_82B27AF0;
loc_82B27A50:
	// addi r11,r7,112
	ctx.r11.s64 = ctx.r7.s64 + 112;
	// lwz r10,32(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// addi r29,r31,12528
	ctx.r29.s64 = ctx.r31.s64 + 12528;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// lwzx r11,r11,r4
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// lwz r11,872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 872);
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82b26ec0
	ctx.lr = 0x82B27A80;
	sub_82B26EC0(ctx, base);
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b27ac4
	if (!ctx.cr6.eq) goto loc_82B27AC4;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r10,r11,7376
	ctx.r10.s64 = ctx.r11.s64 + 7376;
loc_82B27A94:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82B27A98:
	// mfmsr r9
	ctx.r9.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r8
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stwcx. r11,0,r8
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b27a98
	if (!ctx.cr0.eq) goto loc_82B27A98;
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,2
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 2, ctx.xer);
	// blt cr6,0x82b27a94
	if (ctx.cr6.lt) goto loc_82B27A94;
	// stw r11,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r11.u32);
loc_82B27AC4:
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// stw r11,40(r28)
	PPC_STORE_U32(ctx.r28.u32 + 40, ctx.r11.u32);
	// ld r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r29.u32 + 0);
	// std r11,48(r28)
	PPC_STORE_U64(ctx.r28.u32 + 48, ctx.r11.u64);
	// ld r11,12536(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 12536);
	// std r11,56(r28)
	PPC_STORE_U64(ctx.r28.u32 + 56, ctx.r11.u64);
loc_82B27ADC:
	// ld r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r29.u32 + 0);
	// li r3,1
	ctx.r3.s64 = 1;
	// ld r10,12536(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 12536);
	// std r11,11832(r31)
	PPC_STORE_U64(ctx.r31.u32 + 11832, ctx.r11.u64);
	// std r10,11840(r31)
	PPC_STORE_U64(ctx.r31.u32 + 11840, ctx.r10.u64);
loc_82B27AF0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B27AF8"))) PPC_WEAK_FUNC(sub_82B27AF8);
PPC_FUNC_IMPL(__imp__sub_82B27AF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82B27B00;
	__savegprlr_14(ctx, base);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,-1
	ctx.r11.s64 = -1;
	// mr r20,r4
	ctx.r20.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// rlwinm r10,r20,0,14,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 0) & 0x20000;
	// mr r14,r11
	ctx.r14.u64 = ctx.r11.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// mr r15,r11
	ctx.r15.u64 = ctx.r11.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// mr r19,r11
	ctx.r19.u64 = ctx.r11.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b27b3c
	if (ctx.cr6.eq) goto loc_82B27B3C;
	// bl 0x82b26428
	ctx.lr = 0x82B27B38;
	sub_82B26428(ctx, base);
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
loc_82B27B3C:
	// lwz r31,12696(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12696);
	// lwz r21,11820(r30)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r30.u32 + 11820);
	// lwz r29,12692(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12692);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82b28300
	if (ctx.cr0.eq) goto loc_82B28300;
	// lwz r11,896(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 896);
	// li r24,0
	ctx.r24.s64 = 0;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// li r23,5
	ctx.r23.s64 = 5;
	// addi r25,r11,872
	ctx.r25.s64 = ctx.r11.s64 + 872;
	// lis r11,-16383
	ctx.r11.s64 = -1073676288;
	// ori r17,r11,9984
	ctx.r17.u64 = ctx.r11.u64 | 9984;
	// bne cr6,0x82b27c14
	if (!ctx.cr6.eq) goto loc_82B27C14;
	// lwz r11,872(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 872);
	// li r28,0
	ctx.r28.s64 = 0;
	// li r18,0
	ctx.r18.s64 = 0;
	// li r16,0
	ctx.r16.s64 = 0;
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27b9c
	if (ctx.cr0.eq) goto loc_82B27B9C;
	// lwz r11,904(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 904);
	// li r24,1
	ctx.r24.s64 = 1;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// addi r25,r11,872
	ctx.r25.s64 = ctx.r11.s64 + 872;
loc_82B27B9C:
	// lwz r11,10580(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10580);
	// clrlwi r10,r11,29
	ctx.r10.u64 = ctx.r11.u32 & 0x7;
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// beq cr6,0x82b27be0
	if (ctx.cr6.eq) goto loc_82B27BE0;
	// lbz r10,10943(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10943);
	// rlwimi r11,r23,0,29,31
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r23.u32, 0) & 0x7) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFF8);
	// oris r20,r20,8
	ctx.r20.u64 = ctx.r20.u64 | 524288;
	// ori r20,r20,8
	ctx.r20.u64 = ctx.r20.u64 | 8;
	// stw r11,10580(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10580, ctx.r11.u32);
	// rlwinm. r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b27be0
	if (ctx.cr0.eq) goto loc_82B27BE0;
	// lwz r11,10372(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10372);
	// li r12,1
	ctx.r12.s64 = 1;
	// rlwinm r11,r11,0,16,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFF0FFFF;
	// rldicr r12,r12,56,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// or r20,r20,r12
	ctx.r20.u64 = ctx.r20.u64 | ctx.r12.u64;
	// stw r11,10372(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10372, ctx.r11.u32);
loc_82B27BE0:
	// lwz r11,20(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 20);
	// clrlwi r11,r11,27
	ctx.r11.u64 = ctx.r11.u32 & 0x1F;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r27,r11,1
	ctx.r27.u64 = ctx.r11.u64 ^ 1;
loc_82B27BF4:
	// lwz r11,13504(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 13504);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b27d68
	if (!ctx.cr6.eq) goto loc_82B27D68;
	// lwz r11,872(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 872);
	// rlwinm. r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27d68
	if (ctx.cr0.eq) goto loc_82B27D68;
	// li r3,245
	ctx.r3.s64 = 245;
	// bl 0x83158244
	ctx.lr = 0x82B27C14;
	__imp__KeBugCheck(ctx, base);
loc_82B27C14:
	// lwz r10,64(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 64);
	// rlwinm r8,r20,0,11,11
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 0) & 0x100000;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// lbz r11,10942(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10942);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + ctx.r29.u64;
	// cmpldi cr6,r8,0
	ctx.cr6.compare<uint64_t>(ctx.r8.u64, 0, ctx.xer);
	// addi r28,r10,40
	ctx.r28.s64 = ctx.r10.s64 + 40;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// lwz r18,8(r28)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// lwz r16,12(r28)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// rlwinm r8,r18,0,1,3
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r18.u32 | (ctx.r18.u64 << 32), 0) & 0x70000000;
	// subfc r9,r8,r9
	ctx.xer.ca = ctx.r9.u32 >= ctx.r8.u32;
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// subfe r9,r9,r9
	temp.u8 = (~ctx.r9.u32 + ctx.r9.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r9.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r9.u64 = ~ctx.r9.u64 + ctx.r9.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r9,r9,3,28,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0x8;
	// or r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 | ctx.r11.u64;
	// rlwimi r10,r11,0,28,28
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 0) & 0x8) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFF7);
	// stb r10,10942(r30)
	PPC_STORE_U8(ctx.r30.u32 + 10942, ctx.r10.u8);
	// beq cr6,0x82b27d2c
	if (ctx.cr6.eq) goto loc_82B27D2C;
	// addi r4,r29,40
	ctx.r4.s64 = ctx.r29.s64 + 40;
	// lwz r5,24(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b27908
	ctx.lr = 0x82B27C6C;
	sub_82B27908(ctx, base);
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// lwz r10,56(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b27c88
	if (!ctx.cr6.gt) goto loc_82B27C88;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B27C84;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B27C88:
	// mr r10,r17
	ctx.r10.u64 = ctx.r17.u64;
	// ori r20,r20,16384
	ctx.r20.u64 = ctx.r20.u64 | 16384;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,64(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 64);
	// lwz r9,24(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + ctx.r29.u64;
	// lwz r10,40(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r8,r10,12,20,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFF;
	// rlwinm r9,r10,0,3,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1FFFFFFE;
	// addi r10,r8,512
	ctx.r10.s64 = ctx.r8.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,64(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 64);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + ctx.r29.u64;
	// lwz r10,44(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 44);
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,10580(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10580);
	// stw r11,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r11.u32);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// stw r11,10536(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10536, ctx.r11.u32);
	// clrlwi r11,r10,29
	ctx.r11.u64 = ctx.r10.u32 & 0x7;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// beq cr6,0x82b27d2c
	if (ctx.cr6.eq) goto loc_82B27D2C;
	// lbz r11,10943(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10943);
	// li r9,1
	ctx.r9.s64 = 1;
	// oris r20,r20,8
	ctx.r20.u64 = ctx.r20.u64 | 524288;
	// rlwimi r10,r9,2,29,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 2) & 0x7) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFF8);
	// ori r20,r20,8
	ctx.r20.u64 = ctx.r20.u64 | 8;
	// stw r10,10580(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10580, ctx.r10.u32);
	// rlwinm. r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27d2c
	if (ctx.cr0.eq) goto loc_82B27D2C;
	// lwz r11,12440(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12440);
	// li r12,1
	ctx.r12.s64 = 1;
	// rldicr r12,r12,56,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// or r20,r20,r12
	ctx.r20.u64 = ctx.r20.u64 | ctx.r12.u64;
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,10372(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10372, ctx.r11.u32);
loc_82B27D2C:
	// lwz r11,20(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	// lwz r10,20(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 20);
	// lwz r9,13504(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 13504);
	// xor r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 ^ ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// clrlwi r11,r11,13
	ctx.r11.u64 = ctx.r11.u32 & 0x7FFFF;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r27,r11,1
	ctx.r27.u64 = ctx.r11.u64 ^ 1;
	// bne cr6,0x82b27bf4
	if (!ctx.cr6.eq) goto loc_82B27BF4;
	// lwz r11,40(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	// rlwinm. r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27bf4
	if (ctx.cr0.eq) goto loc_82B27BF4;
	// li r3,245
	ctx.r3.s64 = 245;
	// bl 0x83158244
	ctx.lr = 0x82B27D68;
	__imp__KeBugCheck(ctx, base);
loc_82B27D68:
	// lbz r11,10940(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10940);
	// lwz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	// lwz r26,10580(r30)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10580);
	// lwz r22,12(r25)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// mr r29,r26
	ctx.r29.u64 = ctx.r26.u64;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// rlwinm. r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27e00
	if (ctx.cr0.eq) goto loc_82B27E00;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82b27db0
	if (ctx.cr6.eq) goto loc_82B27DB0;
	// lwz r11,10556(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10556);
	// rlwinm. r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b27db4
	if (!ctx.cr0.eq) goto loc_82B27DB4;
	// lwz r11,28(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82b27db4
	if (!ctx.cr0.eq) goto loc_82B27DB4;
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b27db4
	if (!ctx.cr0.eq) goto loc_82B27DB4;
loc_82B27DB0:
	// rlwimi r29,r23,0,29,31
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r23.u32, 0) & 0x7) | (ctx.r29.u64 & 0xFFFFFFFFFFFFFFF8);
loc_82B27DB4:
	// lwz r11,12700(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12700);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b27dcc
	if (!ctx.cr6.eq) goto loc_82B27DCC;
	// rlwinm r11,r20,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 0) & 0x8;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82b27e00
	if (ctx.cr6.eq) goto loc_82B27E00;
loc_82B27DCC:
	// lbz r11,10943(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10943);
	// ori r20,r20,8
	ctx.r20.u64 = ctx.r20.u64 | 8;
	// mr r14,r29
	ctx.r14.u64 = ctx.r29.u64;
	// stw r29,12700(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12700, ctx.r29.u32);
	// rlwinm. r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27e00
	if (ctx.cr0.eq) goto loc_82B27E00;
	// clrlwi r10,r29,29
	ctx.r10.u64 = ctx.r29.u32 & 0x7;
	// lwz r11,10372(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10372);
	// cmplwi cr6,r10,5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 5, ctx.xer);
	// bne cr6,0x82b27df8
	if (!ctx.cr6.eq) goto loc_82B27DF8;
	// rlwinm r11,r11,0,16,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFF0FFFF;
loc_82B27DF8:
	// mr r23,r11
	ctx.r23.u64 = ctx.r11.u64;
	// b 0x82b27e04
	goto loc_82B27E04;
loc_82B27E00:
	// lwz r23,84(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82B27E04:
	// lbz r11,10942(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10942);
	// rlwinm. r10,r11,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82b27f1c
	if (!ctx.cr0.eq) goto loc_82B27F1C;
	// cmpwi cr6,r27,0
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// bne cr6,0x82b27f1c
	if (!ctx.cr6.eq) goto loc_82B27F1C;
	// rlwinm r11,r20,0,12,12
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 0) & 0x80000;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82b27f64
	if (ctx.cr6.eq) goto loc_82B27F64;
	// addi r27,r31,872
	ctx.r27.s64 = ctx.r31.s64 + 872;
	// lwz r5,32(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82b27908
	ctx.lr = 0x82B27E38;
	sub_82B27908(ctx, base);
	// lbz r11,10942(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10942);
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// andi. r11,r11,191
	ctx.r11.u64 = ctx.r11.u64 & 191;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stb r11,10942(r30)
	PPC_STORE_U8(ctx.r30.u32 + 10942, ctx.r11.u8);
	// beq cr6,0x82b27efc
	if (ctx.cr6.eq) goto loc_82B27EFC;
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82b27efc
	if (!ctx.cr0.eq) goto loc_82B27EFC;
	// lbz r11,10940(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10940);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// rlwinm. r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27e70
	if (ctx.cr0.eq) goto loc_82B27E70;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x82b27f48
	goto loc_82B27F48;
loc_82B27E70:
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82b279b8
	ctx.lr = 0x82B27E80;
	sub_82B279B8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b27e90
	if (ctx.cr0.eq) goto loc_82B27E90;
	// mr r19,r24
	ctx.r19.u64 = ctx.r24.u64;
	// b 0x82b27eb4
	goto loc_82B27EB4;
loc_82B27E90:
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// mr r7,r21
	ctx.r7.u64 = ctx.r21.u64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b277a8
	ctx.lr = 0x82B27EB4;
	sub_82B277A8(ctx, base);
loc_82B27EB4:
	// xor r11,r29,r26
	ctx.r11.u64 = ctx.r29.u64 ^ ctx.r26.u64;
	// clrlwi. r11,r11,29
	ctx.r11.u64 = ctx.r11.u32 & 0x7;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27f64
	if (ctx.cr0.eq) goto loc_82B27F64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27f64
	if (ctx.cr0.eq) goto loc_82B27F64;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b279b8
	ctx.lr = 0x82B27EE0;
	sub_82B279B8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b27f64
	if (ctx.cr0.eq) goto loc_82B27F64;
	// lbz r11,10942(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10942);
loc_82B27EEC:
	// ori r11,r11,64
	ctx.r11.u64 = ctx.r11.u64 | 64;
	// li r15,1
	ctx.r15.s64 = 1;
	// stb r11,10942(r30)
	PPC_STORE_U8(ctx.r30.u32 + 10942, ctx.r11.u8);
	// b 0x82b27f64
	goto loc_82B27F64;
loc_82B27EFC:
	// xor r10,r29,r26
	ctx.r10.u64 = ctx.r29.u64 ^ ctx.r26.u64;
	// mr r19,r24
	ctx.r19.u64 = ctx.r24.u64;
	// clrlwi. r10,r10,29
	ctx.r10.u64 = ctx.r10.u32 & 0x7;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b27f64
	if (ctx.cr0.eq) goto loc_82B27F64;
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b27f64
	if (ctx.cr0.eq) goto loc_82B27F64;
	// b 0x82b27eec
	goto loc_82B27EEC;
loc_82B27F1C:
	// rlwinm r10,r20,0,11,12
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 0) & 0x180000;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b27f64
	if (ctx.cr6.eq) goto loc_82B27F64;
	// andi. r11,r11,191
	ctx.r11.u64 = ctx.r11.u64 & 191;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// addi r4,r31,872
	ctx.r4.s64 = ctx.r31.s64 + 872;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stb r11,10942(r30)
	PPC_STORE_U8(ctx.r30.u32 + 10942, ctx.r11.u8);
	// lwz r5,32(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// bl 0x82b27908
	ctx.lr = 0x82B27F40;
	sub_82B27908(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82B27F48:
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// mr r7,r21
	ctx.r7.u64 = ctx.r21.u64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// bl 0x82b277a8
	ctx.lr = 0x82B27F64;
	sub_82B277A8(ctx, base);
loc_82B27F64:
	// rlwinm r11,r20,0,11,12
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 0) & 0x180000;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82b27fb4
	if (ctx.cr6.eq) goto loc_82B27FB4;
	// lbz r11,10942(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10942);
	// or r9,r22,r16
	ctx.r9.u64 = ctx.r22.u64 | ctx.r16.u64;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// oris r20,r20,1
	ctx.r20.u64 = ctx.r20.u64 | 65536;
	// or r10,r10,r18
	ctx.r10.u64 = ctx.r10.u64 | ctx.r18.u64;
	// ori r20,r20,32768
	ctx.r20.u64 = ctx.r20.u64 | 32768;
	// stw r9,10532(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10532, ctx.r9.u32);
	// stw r10,10528(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10528, ctx.r10.u32);
	// rlwinm. r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b27fb4
	if (ctx.cr0.eq) goto loc_82B27FB4;
	// lwz r11,904(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 904);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r10,880(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 880);
	// lwz r11,884(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 884);
	// or r29,r10,r18
	ctx.r29.u64 = ctx.r10.u64 | ctx.r18.u64;
	// or r28,r11,r16
	ctx.r28.u64 = ctx.r11.u64 | ctx.r16.u64;
	// b 0x82b27fbc
	goto loc_82B27FBC;
loc_82B27FB4:
	// lwz r28,88(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r29,92(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
loc_82B27FBC:
	// lbz r11,10940(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10940);
	// rlwinm. r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2827c
	if (ctx.cr0.eq) goto loc_82B2827C;
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// lwz r10,56(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b27fe4
	if (!ctx.cr6.gt) goto loc_82B27FE4;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B27FE0;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B27FE4:
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// lis r9,5461
	ctx.r9.s64 = 357892096;
	// ori r5,r10,24576
	ctx.r5.u64 = ctx.r10.u64 | 24576;
	// lis r8,-16384
	ctx.r8.s64 = -1073741824;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// ori r9,r9,21845
	ctx.r9.u64 = ctx.r9.u64 | 21845;
	// ori r4,r8,24832
	ctx.r4.u64 = ctx.r8.u64 | 24832;
	// rlwinm r7,r20,0,28,28
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 0) & 0x8;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpldi cr6,r7,0
	ctx.cr6.compare<uint64_t>(ctx.r7.u64, 0, ctx.xer);
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// beq cr6,0x82b2803c
	if (ctx.cr6.eq) goto loc_82B2803C;
	// li r10,8712
	ctx.r10.s64 = 8712;
	// li r12,-9
	ctx.r12.s64 = -9;
	// and r20,r20,r12
	ctx.r20.u64 = ctx.r20.u64 & ctx.r12.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,10580(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10580);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
loc_82B2803C:
	// lis r10,-16383
	ctx.r10.s64 = -1073676288;
	// cmpwi cr6,r14,-1
	ctx.cr6.compare<int32_t>(ctx.r14.s32, -1, ctx.xer);
	// ori r10,r10,11521
	ctx.r10.u64 = ctx.r10.u64 | 11521;
	// beq cr6,0x82b28064
	if (ctx.cr6.eq) goto loc_82B28064;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// lis r8,4
	ctx.r8.s64 = 262144;
	// ori r8,r8,520
	ctx.r8.u64 = ctx.r8.u64 | 520;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// stwu r14,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r14.u32);
	ctx.r11.u32 = ea;
loc_82B28064:
	// li r12,1
	ctx.r12.s64 = 1;
	// rldicr r12,r12,56,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// and r9,r20,r12
	ctx.r9.u64 = ctx.r20.u64 & ctx.r12.u64;
	// cmpldi cr6,r9,0
	ctx.cr6.compare<uint64_t>(ctx.r9.u64, 0, ctx.xer);
	// beq cr6,0x82b28094
	if (ctx.cr6.eq) goto loc_82B28094;
	// li r9,8193
	ctx.r9.s64 = 8193;
	// li r12,-2
	ctx.r12.s64 = -2;
	// rldicr r12,r12,56,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// and r20,r20,r12
	ctx.r20.u64 = ctx.r20.u64 & ctx.r12.u64;
	// lwz r9,10372(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10372);
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
loc_82B28094:
	// cmpwi cr6,r23,-1
	ctx.cr6.compare<int32_t>(ctx.r23.s32, -1, ctx.xer);
	// beq cr6,0x82b280b0
	if (ctx.cr6.eq) goto loc_82B280B0;
	// lis r9,4
	ctx.r9.s64 = 262144;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r23,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r23.u32);
	ctx.r11.u32 = ea;
loc_82B280B0:
	// rlwinm r10,r20,0,15,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r20.u32 | (ctx.r20.u64 << 32), 0) & 0x10000;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b280e4
	if (ctx.cr6.eq) goto loc_82B280E4;
	// lis r10,1
	ctx.r10.s64 = 65536;
	// lis r12,-2
	ctx.r12.s64 = -131072;
	// ori r10,r10,8576
	ctx.r10.u64 = ctx.r10.u64 | 8576;
	// ori r12,r12,32767
	ctx.r12.u64 = ctx.r12.u64 | 32767;
	// and r20,r20,r12
	ctx.r20.u64 = ctx.r20.u64 & ctx.r12.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,10528(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10528);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,10532(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10532);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
loc_82B280E4:
	// cmpwi cr6,r29,-1
	ctx.cr6.compare<int32_t>(ctx.r29.s32, -1, ctx.xer);
	// beq cr6,0x82b2810c
	if (ctx.cr6.eq) goto loc_82B2810C;
	// lis r10,-16382
	ctx.r10.s64 = -1073610752;
	// lis r9,4
	ctx.r9.s64 = 262144;
	// ori r10,r10,11521
	ctx.r10.u64 = ctx.r10.u64 | 11521;
	// ori r9,r9,384
	ctx.r9.u64 = ctx.r9.u64 | 384;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r29,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r29.u32);
	ctx.r11.u32 = ea;
	// stwu r28,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r11.u32 = ea;
loc_82B2810C:
	// cmpwi cr6,r15,-1
	ctx.cr6.compare<int32_t>(ctx.r15.s32, -1, ctx.xer);
	// beq cr6,0x82b281fc
	if (ctx.cr6.eq) goto loc_82B281FC;
	// lis r10,-16383
	ctx.r10.s64 = -1073676288;
	// addi r9,r15,112
	ctx.r9.s64 = ctx.r15.s64 + 112;
	// ori r10,r10,9985
	ctx.r10.u64 = ctx.r10.u64 | 9985;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// mulli r9,r15,416
	ctx.r9.s64 = ctx.r15.s64 * 416;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// lwz r7,32(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// add r3,r9,r31
	ctx.r3.u64 = ctx.r9.u64 + ctx.r31.u64;
	// lwzx r9,r8,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r31.u32);
	// cmpwi cr6,r19,-1
	ctx.cr6.compare<int32_t>(ctx.r19.s32, -1, ctx.xer);
	// add r9,r9,r31
	ctx.r9.u64 = ctx.r9.u64 + ctx.r31.u64;
	// lwz r9,872(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 872);
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// rlwinm r6,r9,12,20,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 12) & 0xFFF;
	// clrlwi r7,r9,3
	ctx.r7.u64 = ctx.r9.u32 & 0x1FFFFFFF;
	// addi r9,r6,512
	ctx.r9.s64 = ctx.r6.s64 + 512;
	// rlwinm r9,r9,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1000;
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// lwzx r9,r8,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r31.u32);
	// add r9,r9,r31
	ctx.r9.u64 = ctx.r9.u64 + ctx.r31.u64;
	// lwz r9,876(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 876);
	// rlwinm r9,r9,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// lwz r9,10908(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10908);
	// stw r9,64(r3)
	PPC_STORE_U32(ctx.r3.u32 + 64, ctx.r9.u32);
	// beq cr6,0x82b28260
	if (ctx.cr6.eq) goto loc_82B28260;
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
	// lis r9,10922
	ctx.r9.s64 = 715784192;
	// addi r7,r19,112
	ctx.r7.s64 = ctx.r19.s64 + 112;
	// ori r6,r9,43690
	ctx.r6.u64 = ctx.r9.u64 | 43690;
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// mulli r10,r19,416
	ctx.r10.s64 = ctx.r19.s64 * 416;
	// stwu r6,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r11.u32 = ea;
	// add r3,r10,r31
	ctx.r3.u64 = ctx.r10.u64 + ctx.r31.u64;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// lwzx r10,r9,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r31.u32);
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// lwz r10,872(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 872);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r7,r10,12,20,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFF;
	// clrlwi r8,r10,3
	ctx.r8.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// addi r10,r7,512
	ctx.r10.s64 = ctx.r7.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwzx r10,r9,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r31.u32);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// lwz r10,876(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 876);
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,10908(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10908);
	// stw r10,64(r3)
	PPC_STORE_U32(ctx.r3.u32 + 64, ctx.r10.u32);
	// b 0x82b28260
	goto loc_82B28260;
loc_82B281FC:
	// cmpwi cr6,r19,-1
	ctx.cr6.compare<int32_t>(ctx.r19.s32, -1, ctx.xer);
	// beq cr6,0x82b28260
	if (ctx.cr6.eq) goto loc_82B28260;
	// addi r10,r19,112
	ctx.r10.s64 = ctx.r19.s64 + 112;
	// stwu r17,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r17.u32);
	ctx.r11.u32 = ea;
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// rlwinm r9,r10,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r10,r19,416
	ctx.r10.s64 = ctx.r19.s64 * 416;
	// add r6,r10,r31
	ctx.r6.u64 = ctx.r10.u64 + ctx.r31.u64;
	// lwzx r10,r9,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r31.u32);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// lwz r10,872(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 872);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r7,r10,12,20,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFF;
	// clrlwi r8,r10,3
	ctx.r8.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// addi r10,r7,512
	ctx.r10.s64 = ctx.r7.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwzx r10,r9,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r31.u32);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// lwz r10,876(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 876);
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,10908(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10908);
	// stw r10,64(r6)
	PPC_STORE_U32(ctx.r6.u32 + 64, ctx.r10.u32);
loc_82B28260:
	// stwu r5,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12708(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12708);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r4,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12712(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12712);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// b 0x82b282fc
	goto loc_82B282FC;
loc_82B2827C:
	// cmpwi cr6,r19,-1
	ctx.cr6.compare<int32_t>(ctx.r19.s32, -1, ctx.xer);
	// beq cr6,0x82b28300
	if (ctx.cr6.eq) goto loc_82B28300;
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// lwz r10,56(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b282a0
	if (!ctx.cr6.gt) goto loc_82B282A0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B2829C;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B282A0:
	// addi r10,r19,112
	ctx.r10.s64 = ctx.r19.s64 + 112;
	// stwu r17,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r17.u32);
	ctx.r11.u32 = ea;
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// rlwinm r9,r10,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// mulli r10,r19,416
	ctx.r10.s64 = ctx.r19.s64 * 416;
	// add r6,r10,r31
	ctx.r6.u64 = ctx.r10.u64 + ctx.r31.u64;
	// lwzx r10,r9,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r31.u32);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// lwz r10,872(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 872);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r7,r10,12,20,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFF;
	// clrlwi r8,r10,3
	ctx.r8.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// addi r10,r7,512
	ctx.r10.s64 = ctx.r7.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwzx r10,r9,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r31.u32);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// lwz r10,876(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 876);
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,10908(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10908);
	// stw r10,64(r6)
	PPC_STORE_U32(ctx.r6.u32 + 64, ctx.r10.u32);
loc_82B282FC:
	// stw r11,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r11.u32);
loc_82B28300:
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B28310"))) PPC_WEAK_FUNC(sub_82B28310);
PPC_FUNC_IMPL(__imp__sub_82B28310) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82B28318;
	__savegprlr_25(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r9,28(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 28);
loc_82B28330:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r8,r8,30,2,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 30) & 0x3FFFFFFF;
	// stbx r8,r11,r6
	PPC_STORE_U8(ctx.r11.u32 + ctx.r6.u32, ctx.r8.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82b28330
	if (!ctx.cr6.gt) goto loc_82B28330;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82b283b8
	if (ctx.cr6.eq) goto loc_82B283B8;
	// lwz r10,64(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 64);
	// lwz r11,896(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 896);
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// addi r29,r10,40
	ctx.r29.s64 = ctx.r10.s64 + 40;
	// addi r30,r11,872
	ctx.r30.s64 = ctx.r11.s64 + 872;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b26148
	ctx.lr = 0x82B2837C;
	sub_82B26148(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b283b8
	if (ctx.cr0.eq) goto loc_82B283B8;
	// cmplwi cr6,r3,1
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 1, ctx.xer);
	// bne cr6,0x82b283b8
	if (!ctx.cr6.eq) goto loc_82B283B8;
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r6,r30,8
	ctx.r6.s64 = ctx.r30.s64 + 8;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82b27658
	ctx.lr = 0x82B283AC;
	sub_82B27658(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b26270
	ctx.lr = 0x82B283B8;
	sub_82B26270(ctx, base);
loc_82B283B8:
	// lwz r11,872(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 872);
	// li r29,0
	ctx.r29.s64 = 0;
	// rlwinm r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 ^ 1;
	// addic. r26,r11,1
	ctx.xer.ca = ctx.r11.u32 > 4294967294;
	ctx.r26.s64 = ctx.r11.s64 + 1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// beq 0x82b28478
	if (ctx.cr0.eq) goto loc_82B28478;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r30,r31,40
	ctx.r30.s64 = ctx.r31.s64 + 40;
	// addi r28,r31,896
	ctx.r28.s64 = ctx.r31.s64 + 896;
	// addi r25,r11,7376
	ctx.r25.s64 = ctx.r11.s64 + 7376;
loc_82B283E8:
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,872(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 872);
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x82b26ec0
	ctx.lr = 0x82B28410;
	sub_82B26EC0(ctx, base);
	// addi r3,r30,8
	ctx.r3.s64 = ctx.r30.s64 + 8;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r5,16
	ctx.r5.s64 = 16;
	// bl 0x82e28fd0
	ctx.lr = 0x82B28420;
	sub_82E28FD0(ctx, base);
	// lwz r11,48(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 48);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2845c
	if (!ctx.cr6.eq) goto loc_82B2845C;
loc_82B2842C:
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
loc_82B28430:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r9
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r9.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stwcx. r11,0,r9
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r9.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b28430
	if (!ctx.cr0.eq) goto loc_82B28430;
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// blt cr6,0x82b2842c
	if (ctx.cr6.lt) goto loc_82B2842C;
	// stw r11,48(r27)
	PPC_STORE_U32(ctx.r27.u32 + 48, ctx.r11.u32);
loc_82B2845C:
	// lwz r11,48(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 48);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r28,r28,8
	ctx.r28.s64 = ctx.r28.s64 + 8;
	// cmplw cr6,r29,r26
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r26.u32, ctx.xer);
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// addi r30,r30,416
	ctx.r30.s64 = ctx.r30.s64 + 416;
	// blt cr6,0x82b283e8
	if (ctx.cr6.lt) goto loc_82B283E8;
loc_82B28478:
	// lwz r11,872(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 872);
	// ori r11,r11,64
	ctx.r11.u64 = ctx.r11.u64 | 64;
	// stw r11,872(r31)
	PPC_STORE_U32(ctx.r31.u32 + 872, ctx.r11.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B28490"))) PPC_WEAK_FUNC(sub_82B28490);
PPC_FUNC_IMPL(__imp__sub_82B28490) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r7,r3,32
	ctx.r7.s64 = ctx.r3.s64 + 32;
	// addi r6,r3,800
	ctx.r6.s64 = ctx.r3.s64 + 800;
	// rlwinm r11,r10,29,3,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmplw cr6,r11,r6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82b284b4
	if (!ctx.cr6.eq) goto loc_82B284B4;
loc_82B284AC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82B284B4:
	// clrlwi r8,r10,27
	ctx.r8.u64 = ctx.r10.u32 & 0x1F;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// srw r8,r10,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r8.u8 & 0x3F));
	// andc r8,r8,r9
	ctx.r8.u64 = ctx.r8.u64 & ~ctx.r9.u64;
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// cmplwi cr6,r8,32
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 32, ctx.xer);
	// bne cr6,0x82b284f8
	if (!ctx.cr6.eq) goto loc_82B284F8;
loc_82B284D4:
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r9,-1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, -1, ctx.xer);
	// beq cr6,0x82b284d4
	if (ctx.cr6.eq) goto loc_82B284D4;
	// cmplw cr6,r11,r6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82b284ac
	if (ctx.cr6.eq) goto loc_82B284AC;
	// rotlwi r9,r9,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// not r8,r9
	ctx.r8.u64 = ~ctx.r9.u64;
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
loc_82B284F8:
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// srw r5,r5,r8
	ctx.r5.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r5.u32 >> (ctx.r8.u8 & 0x3F));
	// and r9,r5,r9
	ctx.r9.u64 = ctx.r5.u64 & ctx.r9.u64;
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// cmplwi cr6,r9,32
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 32, ctx.xer);
	// bne cr6,0x82b28544
	if (!ctx.cr6.eq) goto loc_82B28544;
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// b 0x82b28520
	goto loc_82B28520;
loc_82B2851C:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_82B28520:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82b2851c
	if (ctx.cr6.eq) goto loc_82B2851C;
	// cmplw cr6,r10,r6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82b2853c
	if (!ctx.cr6.eq) goto loc_82B2853C;
	// li r9,0
	ctx.r9.s64 = 0;
	// b 0x82b28544
	goto loc_82B28544;
loc_82B2853C:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
loc_82B28544:
	// subf r11,r7,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r7.s64;
	// subf r10,r7,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r7.s64;
	// srawi r11,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 2;
	// srawi r10,r10,2
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 2;
	// rlwinm r11,r11,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// add r3,r10,r9
	ctx.r3.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B28570"))) PPC_WEAK_FUNC(sub_82B28570);
PPC_FUNC_IMPL(__imp__sub_82B28570) {
	PPC_FUNC_PROLOGUE();
	// rlwinm r8,r5,27,5,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r4,27,5,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r8,8
	ctx.r9.s64 = ctx.r8.s64 + 8;
	// addi r11,r10,8
	ctx.r11.s64 = ctx.r10.s64 + 8;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// clrlwi r5,r5,27
	ctx.r5.u64 = ctx.r5.u32 & 0x1F;
	// cmpwi cr6,r6,0
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r9,r9,r3
	ctx.r9.u64 = ctx.r9.u64 + ctx.r3.u64;
	// beq cr6,0x82b28620
	if (ctx.cr6.eq) goto loc_82B28620;
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// li r10,-1
	ctx.r10.s64 = -1;
	// bne cr6,0x82b285c4
	if (!ctx.cr6.eq) goto loc_82B285C4;
	// srw r8,r10,r5
	ctx.r8.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r5.u8 & 0x3F));
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// srw r10,r10,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r7.u8 & 0x3F));
	// andc r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r8.u64;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// b 0x82b286a0
	goto loc_82B286A0;
loc_82B285C4:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// srw r7,r10,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r7.u8 & 0x3F));
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82b28610
	if (!ctx.cr6.lt) goto loc_82B28610;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r11.s64;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// rlwinm r9,r9,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
	// addic. r9,r9,1
	ctx.xer.ca = ctx.r9.u32 > 4294967294;
	ctx.r9.s64 = ctx.r9.s64 + 1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82b28608
	if (ctx.cr0.eq) goto loc_82B28608;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82B285FC:
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bdnz 0x82b285fc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B285FC;
loc_82B28608:
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
loc_82B28610:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// srw r10,r10,r5
	ctx.r10.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r5.u8 & 0x3F));
	// orc r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ~ctx.r10.u64;
	// b 0x82b286a0
	goto loc_82B286A0;
loc_82B28620:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// li r10,-1
	ctx.r10.s64 = -1;
	// bne cr6,0x82b28644
	if (!ctx.cr6.eq) goto loc_82B28644;
	// srw r8,r10,r5
	ctx.r8.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r5.u8 & 0x3F));
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// srw r10,r10,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r7.u8 & 0x3F));
	// andc r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r8.u64;
	// andc r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ~ctx.r10.u64;
	// b 0x82b286a0
	goto loc_82B286A0;
loc_82B28644:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// srw r7,r10,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r7.u8 & 0x3F));
	// andc r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 & ~ctx.r7.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82b28694
	if (!ctx.cr6.lt) goto loc_82B28694;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r11.s64;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwinm r9,r9,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
	// addic. r9,r9,1
	ctx.xer.ca = ctx.r9.u32 > 4294967294;
	ctx.r9.s64 = ctx.r9.s64 + 1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82b2868c
	if (ctx.cr0.eq) goto loc_82B2868C;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82B28680:
	// stw r7,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r7.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bdnz 0x82b28680
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B28680;
loc_82B2868C:
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
loc_82B28694:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// srw r10,r10,r5
	ctx.r10.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r5.u8 & 0x3F));
	// and r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 & ctx.r9.u64;
loc_82B286A0:
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B286A8"))) PPC_WEAK_FUNC(sub_82B286A8);
PPC_FUNC_IMPL(__imp__sub_82B286A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B286B0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r31,7384(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 7384);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x83157d14
	ctx.lr = 0x82B286CC;
	__imp__RtlEnterCriticalSection(ctx, base);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// li r6,0
	ctx.r6.s64 = 0;
	// add r11,r29,r11
	ctx.r11.u64 = ctx.r29.u64 + ctx.r11.u64;
	// add r5,r30,r29
	ctx.r5.u64 = ctx.r30.u64 + ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// bl 0x82b28570
	ctx.lr = 0x82B286EC;
	sub_82B28570(ctx, base);
	// bl 0x83157d24
	ctx.lr = 0x82B286F0;
	__imp__RtlLeaveCriticalSection(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B286F8"))) PPC_WEAK_FUNC(sub_82B286F8);
PPC_FUNC_IMPL(__imp__sub_82B286F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82B28700;
	__savegprlr_25(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// li r27,-1
	ctx.r27.s64 = -1;
	// addi r30,r11,7384
	ctx.r30.s64 = ctx.r11.s64 + 7384;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r25,r4
	ctx.r25.u64 = ctx.r4.u64;
	// mr r26,r27
	ctx.r26.u64 = ctx.r27.u64;
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82b287b0
	if (!ctx.cr0.eq) goto loc_82B287B0;
	// lis r4,25728
	ctx.r4.s64 = 1686110208;
	// li r3,804
	ctx.r3.s64 = 804;
	// bl 0x82547910
	ctx.lr = 0x82B28738;
	sub_82547910(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne 0x82b28748
	if (!ctx.cr0.eq) goto loc_82B28748;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b28864
	goto loc_82B28864;
loc_82B28748:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x83157d34
	ctx.lr = 0x82B28750;
	__imp__RtlInitializeCriticalSection(ctx, base);
	// lis r10,21845
	ctx.r10.s64 = 1431633920;
	// li r11,6144
	ctx.r11.s64 = 6144;
	// ori r10,r10,21845
	ctx.r10.u64 = ctx.r10.u64 | 21845;
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// stw r10,800(r31)
	PPC_STORE_U32(ctx.r31.u32 + 800, ctx.r10.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
loc_82B28768:
	// mfmsr r8
	ctx.r8.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r9,0,r10
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r10.u32);
	ctx.r9.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r9,r29
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r29.s32, ctx.xer);
	// bne cr6,0x82b2878c
	if (!ctx.cr6.eq) goto loc_82B2878C;
	// stwcx. r31,0,r10
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r10.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r31.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r8,1
	ctx.msr = (ctx.r8.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b28768
	if (!ctx.cr0.eq) goto loc_82B28768;
	// b 0x82b28794
	goto loc_82B28794;
loc_82B2878C:
	// stwcx. r9,0,r10
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r10.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r9.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r8,1
	ctx.msr = (ctx.r8.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_82B28794:
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b287b0
	if (ctx.cr6.eq) goto loc_82B287B0;
	// lis r4,25728
	ctx.r4.s64 = 1686110208;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82547938
	ctx.lr = 0x82B287AC;
	sub_82547938(ctx, base);
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
loc_82B287B0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x83157d14
	ctx.lr = 0x82B287B8;
	__imp__RtlEnterCriticalSection(ctx, base);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// bgt cr6,0x82b28848
	if (ctx.cr6.gt) goto loc_82B28848;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r29.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r30,r29
	ctx.r30.u64 = ctx.r29.u64;
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// bl 0x82b28490
	ctx.lr = 0x82B287DC;
	sub_82B28490(ctx, base);
	// mr. r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b28848
	if (ctx.cr0.eq) goto loc_82B28848;
loc_82B287E4:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// blt cr6,0x82b28800
	if (ctx.cr6.lt) goto loc_82B28800;
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// bge cr6,0x82b28800
	if (!ctx.cr6.lt) goto loc_82B28800;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
loc_82B28800:
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x82b28490
	ctx.lr = 0x82B28814;
	sub_82B28490(ctx, base);
	// mr. r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b287e4
	if (!ctx.cr0.eq) goto loc_82B287E4;
	// cmpwi cr6,r29,-1
	ctx.cr6.compare<int32_t>(ctx.r29.s32, -1, ctx.xer);
	// beq cr6,0x82b28848
	if (ctx.cr6.eq) goto loc_82B28848;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// li r6,1
	ctx.r6.s64 = 1;
	// add r5,r30,r28
	ctx.r5.u64 = ctx.r30.u64 + ctx.r28.u64;
	// subf r11,r28,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r28.s64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// bl 0x82b28570
	ctx.lr = 0x82B28844;
	sub_82B28570(ctx, base);
	// mr r26,r30
	ctx.r26.u64 = ctx.r30.u64;
loc_82B28848:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x83157d24
	ctx.lr = 0x82B28850;
	__imp__RtlLeaveCriticalSection(ctx, base);
	// subf r11,r26,r27
	ctx.r11.s64 = ctx.r27.s64 - ctx.r26.s64;
	// stw r26,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r26.u32);
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = ctx.r11.u64 ^ 1;
loc_82B28864:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B28870"))) PPC_WEAK_FUNC(sub_82B28870);
PPC_FUNC_IMPL(__imp__sub_82B28870) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,2031
	ctx.r11.s64 = 133103616;
	// addis r10,r3,-32528
	ctx.r10.s64 = ctx.r3.s64 + -2131755008;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// addi r10,r4,127
	ctx.r10.s64 = ctx.r4.s64 + 127;
	// rlwinm r11,r3,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFF80;
	// rlwinm r10,r10,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFF80;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// srawi r10,r10,7
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7F) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 7;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// rlwinm. r9,r10,29,3,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// clrlwi r10,r10,29
	ctx.r10.u64 = ctx.r10.u32 & 0x7;
	// beq 0x82b288f0
	if (ctx.cr0.eq) goto loc_82B288F0;
loc_82B288A8:
	// dcbf r0,r11
	// li r8,128
	ctx.r8.s64 = 128;
	// dcbf r8,r11
	// li r8,256
	ctx.r8.s64 = 256;
	// dcbf r8,r11
	// li r8,384
	ctx.r8.s64 = 384;
	// dcbf r8,r11
	// li r8,512
	ctx.r8.s64 = 512;
	// dcbf r8,r11
	// li r8,640
	ctx.r8.s64 = 640;
	// dcbf r8,r11
	// li r8,768
	ctx.r8.s64 = 768;
	// dcbf r8,r11
	// li r8,896
	ctx.r8.s64 = 896;
	// dcbf r8,r11
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// addi r11,r11,1024
	ctx.r11.s64 = ctx.r11.s64 + 1024;
	// bne 0x82b288a8
	if (!ctx.cr0.eq) goto loc_82B288A8;
loc_82B288F0:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b28908
	if (ctx.cr6.eq) goto loc_82B28908;
loc_82B288F8:
	// dcbf r0,r11
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,128
	ctx.r11.s64 = ctx.r11.s64 + 128;
	// bne 0x82b288f8
	if (!ctx.cr0.eq) goto loc_82B288F8;
loc_82B28908:
	// sync 
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B28910"))) PPC_WEAK_FUNC(sub_82B28910);
PPC_FUNC_IMPL(__imp__sub_82B28910) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r4,24(r1)
	PPC_STORE_U64(ctx.r1.u32 + 24, ctx.r4.u64);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,392
	ctx.r10.s64 = ctx.r1.s64 + 392;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,260
	ctx.r4.s64 = 260;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x83158254
	ctx.lr = 0x82B28958;
	__imp___vsnprintf(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x83158034
	ctx.lr = 0x82B28960;
	__imp__DbgPrint(ctx, base);
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B28970"))) PPC_WEAK_FUNC(sub_82B28970);
PPC_FUNC_IMPL(__imp__sub_82B28970) {
	PPC_FUNC_PROLOGUE();
	// addis r11,r3,8178
	ctx.r11.s64 = ctx.r3.s64 + 535953408;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B28980"))) PPC_WEAK_FUNC(sub_82B28980);
PPC_FUNC_IMPL(__imp__sub_82B28980) {
	PPC_FUNC_PROLOGUE();
	// addis r11,r3,8178
	ctx.r11.s64 = ctx.r3.s64 + 535953408;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r4,0(r11)
	PPC_MM_STORE_U32(ctx.r11.u32 + 0, ctx.r4.u32);
	// eieio 
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B28998"))) PPC_WEAK_FUNC(sub_82B28998);
PPC_FUNC_IMPL(__imp__sub_82B28998) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,432
	ctx.r10.s64 = ctx.r1.s64 + 432;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,260
	ctx.r4.s64 = 260;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r6,96(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bl 0x83158254
	ctx.lr = 0x82B289E4;
	__imp___vsnprintf(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b28a00
	if (ctx.cr0.eq) goto loc_82B28A00;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B289FC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82b28a04
	goto loc_82B28A04;
loc_82B28A00:
	// bl 0x82b28910
	ctx.lr = 0x82B28A04;
	sub_82B28910(ctx, base);
loc_82B28A04:
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B28A18"))) PPC_WEAK_FUNC(sub_82B28A18);
PPC_FUNC_IMPL(__imp__sub_82B28A18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82B28A20;
	__savegprlr_23(ctx, base);
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r3,1488
	ctx.r3.s64 = 1488;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B28A38;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r5,r11,-22376
	ctx.r5.s64 = ctx.r11.s64 + -22376;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-22396
	ctx.r4.s64 = ctx.r11.s64 + -22396;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// bl 0x82b28998
	ctx.lr = 0x82B28A5C;
	sub_82B28998(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// li r26,11
	ctx.r26.s64 = 11;
	// addi r27,r11,-29152
	ctx.r27.s64 = ctx.r11.s64 + -29152;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r30,r27,4
	ctx.r30.s64 = ctx.r27.s64 + 4;
	// addi r25,r11,-3992
	ctx.r25.s64 = ctx.r11.s64 + -3992;
loc_82B28A74:
	// lwz r11,-4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -4);
	// and. r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 & ctx.r29.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b28aa4
	if (ctx.cr0.eq) goto loc_82B28AA4;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// beq cr6,0x82b28a94
	if (ctx.cr6.eq) goto loc_82B28A94;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// bl 0x82b28998
	ctx.lr = 0x82B28A94;
	sub_82B28998(ctx, base);
loc_82B28A94:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82b28998
	ctx.lr = 0x82B28AA0;
	sub_82B28998(ctx, base);
	// li r28,1
	ctx.r28.s64 = 1;
loc_82B28AA4:
	// addic. r26,r26,-1
	ctx.xer.ca = ctx.r26.u32 > 0;
	ctx.r26.s64 = ctx.r26.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// addi r30,r30,8
	ctx.r30.s64 = ctx.r30.s64 + 8;
	// bne 0x82b28a74
	if (!ctx.cr0.eq) goto loc_82B28A74;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82b28ac8
	if (!ctx.cr6.eq) goto loc_82B28AC8;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-22416
	ctx.r4.s64 = ctx.r11.s64 + -22416;
	// bl 0x82b28998
	ctx.lr = 0x82B28AC8;
	sub_82B28998(ctx, base);
loc_82B28AC8:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,-22420
	ctx.r4.s64 = ctx.r11.s64 + -22420;
	// bl 0x82b28998
	ctx.lr = 0x82B28AD8;
	sub_82B28998(ctx, base);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,3857
	ctx.r3.s64 = 3857;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B28AEC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82b07ad0
	ctx.lr = 0x82B28AF4;
	sub_82B07AD0(ctx, base);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r3,3858
	ctx.r3.s64 = 3858;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B28B04;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r11,-22440
	ctx.r5.s64 = ctx.r11.s64 + -22440;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r29,r11,-22460
	ctx.r29.s64 = ctx.r11.s64 + -22460;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82b28998
	ctx.lr = 0x82B28B24;
	sub_82B28998(ctx, base);
	// addi r30,r27,88
	ctx.r30.s64 = ctx.r27.s64 + 88;
	// li r28,30
	ctx.r28.s64 = 30;
loc_82B28B2C:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B28B3C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,4(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82b28998
	ctx.lr = 0x82B28B50;
	sub_82B28998(ctx, base);
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// addi r30,r30,8
	ctx.r30.s64 = ctx.r30.s64 + 8;
	// bne 0x82b28b2c
	if (!ctx.cr0.eq) goto loc_82B28B2C;
	// addi r11,r27,328
	ctx.r11.s64 = ctx.r27.s64 + 328;
	// li r23,5
	ctx.r23.s64 = 5;
	// addi r29,r11,16
	ctx.r29.s64 = ctx.r11.s64 + 16;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// addi r26,r11,-1980
	ctx.r26.s64 = ctx.r11.s64 + -1980;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r27,r11,-22468
	ctx.r27.s64 = ctx.r11.s64 + -22468;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r25,r11,-22480
	ctx.r25.s64 = ctx.r11.s64 + -22480;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// addi r24,r11,16820
	ctx.r24.s64 = ctx.r11.s64 + 16820;
loc_82B28B88:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// bl 0x82b28998
	ctx.lr = 0x82B28B94;
	sub_82B28998(ctx, base);
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r30,0
	ctx.r30.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82b28c6c
	if (!ctx.cr6.gt) goto loc_82B28C6C;
loc_82B28BA4:
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lwz r5,4(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x83158234
	ctx.lr = 0x82B28BB8;
	__imp__sprintf(ctx, base);
	// mr r28,r30
	ctx.r28.u64 = ctx.r30.u64;
	// addi r30,r30,8
	ctx.r30.s64 = ctx.r30.s64 + 8;
loc_82B28BC0:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82b28bd0
	if (!ctx.cr6.lt) goto loc_82B28BD0;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
loc_82B28BD0:
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82b28c50
	if (!ctx.cr6.lt) goto loc_82B28C50;
	// lwz r11,-4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + -4);
	// lwz r10,-8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + -8);
	// lwz r3,-16(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + -16);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// slw r11,r28,r11
	ctx.r11.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r28.u32 << (ctx.r11.u8 & 0x3F));
	// or r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 | ctx.r10.u64;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82B28BF8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82b07ad0
	ctx.lr = 0x82B28C00;
	sub_82B07AD0(ctx, base);
	// lwz r3,-12(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + -12);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B28C10;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B28C1C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b28c1c
	if (!ctx.cr6.eq) goto loc_82B28C1C;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x83158234
	ctx.lr = 0x82B28C48;
	__imp__sprintf(ctx, base);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// b 0x82b28bc0
	goto loc_82B28BC0;
loc_82B28C50:
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b28998
	ctx.lr = 0x82B28C60;
	sub_82B28998(ctx, base);
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b28ba4
	if (ctx.cr6.lt) goto loc_82B28BA4;
loc_82B28C6C:
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// addi r29,r29,24
	ctx.r29.s64 = ctx.r29.s64 + 24;
	// bne 0x82b28b88
	if (!ctx.cr0.eq) goto loc_82B28B88;
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B28C80"))) PPC_WEAK_FUNC(sub_82B28C80);
PPC_FUNC_IMPL(__imp__sub_82B28C80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82B28C88;
	__savegprlr_27(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// addi r4,r11,-22064
	ctx.r4.s64 = ctx.r11.s64 + -22064;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// bl 0x82b28998
	ctx.lr = 0x82B28CA8;
	sub_82B28998(ctx, base);
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82b28d44
	if (!ctx.cr6.eq) goto loc_82B28D44;
	// lwz r11,152(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 152);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b28cd4
	if (!ctx.cr6.eq) goto loc_82B28CD4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r6,164(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 164);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r5,172(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 172);
	// addi r4,r11,-22192
	ctx.r4.s64 = ctx.r11.s64 + -22192;
	// bl 0x82b28998
	ctx.lr = 0x82B28CD4;
	sub_82B28998(ctx, base);
loc_82B28CD4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r4,r11,-22328
	ctx.r4.s64 = ctx.r11.s64 + -22328;
	// bl 0x82b28998
	ctx.lr = 0x82B28CE4;
	sub_82B28998(ctx, base);
	// lwz r30,116(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq 0x82b28d44
	if (ctx.cr0.eq) goto loc_82B28D44;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r27,r11,-22348
	ctx.r27.s64 = ctx.r11.s64 + -22348;
loc_82B28CF8:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82b28d38
	if (!ctx.cr6.gt) goto loc_82B28D38;
	// addi r31,r30,12
	ctx.r31.s64 = ctx.r30.s64 + 12;
loc_82B28D0C:
	// lwz r11,-4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// clrlwi r6,r11,8
	ctx.r6.u64 = ctx.r11.u32 & 0xFFFFFF;
	// bl 0x82b28998
	ctx.lr = 0x82B28D24;
	sub_82B28998(ctx, base);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r31,r31,8
	ctx.r31.s64 = ctx.r31.s64 + 8;
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b28d0c
	if (ctx.cr6.lt) goto loc_82B28D0C;
loc_82B28D38:
	// lwz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne 0x82b28cf8
	if (!ctx.cr0.eq) goto loc_82B28CF8;
loc_82B28D44:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B28D50"))) PPC_WEAK_FUNC(sub_82B28D50);
PPC_FUNC_IMPL(__imp__sub_82B28D50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82B28D58;
	__savegprlr_20(ctx, base);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// li r20,1
	ctx.r20.s64 = 1;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b28d80
	if (ctx.cr6.eq) goto loc_82B28D80;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82b28d94
	if (!ctx.cr6.eq) goto loc_82B28D94;
loc_82B28D80:
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// lis r11,-32077
	ctx.r11.s64 = -2102198272;
	// addi r31,r10,-30352
	ctx.r31.s64 = ctx.r10.s64 + -30352;
	// addi r29,r11,-30336
	ctx.r29.s64 = ctx.r11.s64 + -30336;
	// li r20,0
	ctx.r20.s64 = 0;
loc_82B28D94:
	// li r3,1488
	ctx.r3.s64 = 1488;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28DA0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// li r3,3878
	ctx.r3.s64 = 3878;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28DB0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r3,448
	ctx.r3.s64 = 448;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28DBC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// li r3,1403
	ctx.r3.s64 = 1403;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28DCC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r21,r3
	ctx.r21.u64 = ctx.r3.u64;
	// li r3,1404
	ctx.r3.s64 = 1404;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28DDC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r3,1405
	ctx.r3.s64 = 1405;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28DEC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// li r4,12
	ctx.r4.s64 = 12;
	// li r3,3200
	ctx.r3.s64 = 3200;
	// mtctr r29
	ctx.ctr.u64 = ctx.r29.u64;
	// bctrl 
	ctx.lr = 0x82B28E00;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r3,3201
	ctx.r3.s64 = 3201;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28E0C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// li r3,3201
	ctx.r3.s64 = 3201;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28E1C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r3.u32);
	// li r3,3201
	ctx.r3.s64 = 3201;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28E2C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r3.u32);
	// li r3,3201
	ctx.r3.s64 = 3201;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28E3C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r3.u32);
	// li r3,3201
	ctx.r3.s64 = 3201;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
	// bctrl 
	ctx.lr = 0x82B28E4C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r3.u32);
	// li r28,0
	ctx.r28.s64 = 0;
	// stw r27,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r27.u32);
	// stw r31,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r31.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// stw r29,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r29.u32);
	// beq cr6,0x82b28ee0
	if (ctx.cr6.eq) goto loc_82B28EE0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-19768
	ctx.r4.s64 = ctx.r11.s64 + -19768;
	// bl 0x82b28998
	ctx.lr = 0x82B28E78;
	sub_82B28998(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r9,16560(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16560);
	// addi r7,r11,-19776
	ctx.r7.s64 = ctx.r11.s64 + -19776;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,6534
	ctx.r5.s64 = 6534;
	// addi r4,r11,-19820
	ctx.r4.s64 = ctx.r11.s64 + -19820;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// lwz r11,2324(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2324);
	// lhz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// bl 0x82b28998
	ctx.lr = 0x82B28EA8;
	sub_82B28998(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r7,10900(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10900);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,10896(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10896);
	// addi r4,r11,-19868
	ctx.r4.s64 = ctx.r11.s64 + -19868;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b28998
	ctx.lr = 0x82B28EC4;
	sub_82B28998(ctx, base);
	// lwz r10,10896(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10896);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r5,10908(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 10908);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-19904
	ctx.r4.s64 = ctx.r11.s64 + -19904;
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// bl 0x82b28998
	ctx.lr = 0x82B28EE0;
	sub_82B28998(ctx, base);
loc_82B28EE0:
	// lis r11,-32763
	ctx.r11.s64 = -2147155968;
	// ori r11,r11,272
	ctx.r11.u64 = ctx.r11.u64 | 272;
	// cmplw cr6,r25,r11
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b28f24
	if (!ctx.cr6.eq) goto loc_82B28F24;
	// lis r11,2989
	ctx.r11.s64 = 195887104;
	// ori r11,r11,61453
	ctx.r11.u64 = ctx.r11.u64 | 61453;
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82b28f24
	if (ctx.cr6.eq) goto loc_82B28F24;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82b28f24
	if (ctx.cr6.eq) goto loc_82B28F24;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// addi r4,r11,-20064
	ctx.r4.s64 = ctx.r11.s64 + -20064;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b28998
	ctx.lr = 0x82B28F20;
	sub_82B28998(ctx, base);
	// b 0x82b2907c
	goto loc_82B2907C;
loc_82B28F24:
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b28a18
	ctx.lr = 0x82B28F2C;
	sub_82B28A18(ctx, base);
	// lis r12,32763
	ctx.r12.s64 = 2147155968;
	// lis r11,1025
	ctx.r11.s64 = 67174400;
	// ori r12,r12,61664
	ctx.r12.u64 = ctx.r12.u64 | 61664;
	// and r31,r25,r12
	ctx.r31.u64 = ctx.r25.u64 & ctx.r12.u64;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b28f68
	if (!ctx.cr6.eq) goto loc_82B28F68;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-20200
	ctx.r4.s64 = ctx.r11.s64 + -20200;
	// bl 0x82b28998
	ctx.lr = 0x82B28F54;
	sub_82B28998(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-20352
	ctx.r4.s64 = ctx.r11.s64 + -20352;
	// bl 0x82b28998
	ctx.lr = 0x82B28F64;
	sub_82B28998(ctx, base);
	// li r28,1
	ctx.r28.s64 = 1;
loc_82B28F68:
	// rlwinm. r11,r22,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b28fb8
	if (ctx.cr0.eq) goto loc_82B28FB8;
	// rlwinm. r11,r22,0,21,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 0) & 0x7C0;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b28fb8
	if (!ctx.cr0.eq) goto loc_82B28FB8;
	// rlwinm r11,r22,21,28,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 21) & 0xC;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// lis r9,32
	ctx.r9.s64 = 2097152;
	// lwzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// rlwinm r11,r11,0,5,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x7F00000;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82b28fb8
	if (!ctx.cr6.eq) goto loc_82B28FB8;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-20488
	ctx.r4.s64 = ctx.r11.s64 + -20488;
	// bl 0x82b28998
	ctx.lr = 0x82B28FA4;
	sub_82B28998(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-20664
	ctx.r4.s64 = ctx.r11.s64 + -20664;
	// bl 0x82b28998
	ctx.lr = 0x82B28FB4;
	sub_82B28998(ctx, base);
	// li r28,1
	ctx.r28.s64 = 1;
loc_82B28FB8:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82b28ff4
	if (!ctx.cr6.eq) goto loc_82B28FF4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-20808
	ctx.r4.s64 = ctx.r11.s64 + -20808;
	// bl 0x82b28998
	ctx.lr = 0x82B28FD0;
	sub_82B28998(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-20960
	ctx.r4.s64 = ctx.r11.s64 + -20960;
	// bl 0x82b28998
	ctx.lr = 0x82B28FE0;
	sub_82B28998(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-21128
	ctx.r4.s64 = ctx.r11.s64 + -21128;
	// bl 0x82b28998
	ctx.lr = 0x82B28FF0;
	sub_82B28998(ctx, base);
	// li r28,1
	ctx.r28.s64 = 1;
loc_82B28FF4:
	// rlwinm r11,r31,0,9,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x7FFFE0;
	// lis r10,64
	ctx.r10.s64 = 4194304;
	// rlwinm r11,r11,0,26,9
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFC0003F;
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82b29040
	if (!ctx.cr6.eq) goto loc_82B29040;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-21288
	ctx.r4.s64 = ctx.r11.s64 + -21288;
	// bl 0x82b28998
	ctx.lr = 0x82B2901C;
	sub_82B28998(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-21448
	ctx.r4.s64 = ctx.r11.s64 + -21448;
	// bl 0x82b28998
	ctx.lr = 0x82B2902C;
	sub_82B28998(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r11,-21632
	ctx.r4.s64 = ctx.r11.s64 + -21632;
	// bl 0x82b28998
	ctx.lr = 0x82B2903C;
	sub_82B28998(ctx, base);
	// li r28,1
	ctx.r28.s64 = 1;
loc_82B29040:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82b29058
	if (ctx.cr6.eq) goto loc_82B29058;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b28c80
	ctx.lr = 0x82B29058;
	sub_82B28C80(ctx, base);
loc_82B29058:
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// beq cr6,0x82b29070
	if (ctx.cr6.eq) goto loc_82B29070;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r4,r11,-21776
	ctx.r4.s64 = ctx.r11.s64 + -21776;
	// b 0x82b29078
	goto loc_82B29078;
loc_82B29070:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r4,r11,-21920
	ctx.r4.s64 = ctx.r11.s64 + -21920;
loc_82B29078:
	// bl 0x82b28998
	ctx.lr = 0x82B2907C;
	sub_82B28998(ctx, base);
loc_82B2907C:
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B29088"))) PPC_WEAK_FUNC(sub_82B29088);
PPC_FUNC_IMPL(__imp__sub_82B29088) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r3,r11,-19416
	ctx.r3.s64 = ctx.r11.s64 + -19416;
	// bl 0x82b28910
	ctx.lr = 0x82B290A8;
	sub_82B28910(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,13432(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13432);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b28d50
	ctx.lr = 0x82B290BC;
	sub_82B28D50(ctx, base);
	// lwz r11,13432(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13432);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b29114
	if (ctx.cr6.eq) goto loc_82B29114;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// lwz r11,7388(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 7388);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b290e0
	if (ctx.cr6.eq) goto loc_82B290E0;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b29134
	goto loc_82B29134;
loc_82B290E0:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lbz r9,10941(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// lwz r11,10908(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10908);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-22364
	ctx.r3.s64 = ctx.r10.s64 + -22364;
	// ori r10,r9,3
	ctx.r10.u64 = ctx.r9.u64 | 3;
	// lwz r9,10896(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10896);
	// addi r11,r11,-2
	ctx.r11.s64 = ctx.r11.s64 + -2;
	// stb r10,10941(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10941, ctx.r10.u8);
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r11.u32);
	// stw r8,11008(r31)
	PPC_STORE_U32(ctx.r31.u32 + 11008, ctx.r8.u32);
	// bl 0x82b2d430
	ctx.lr = 0x82B29110;
	sub_82B2D430(ctx, base);
	// b 0x82b29130
	goto loc_82B29130;
loc_82B29114:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-19640
	ctx.r3.s64 = ctx.r11.s64 + -19640;
	// bl 0x82b28910
	ctx.lr = 0x82B29120;
	sub_82B28910(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-19736
	ctx.r3.s64 = ctx.r11.s64 + -19736;
	// bl 0x82b28910
	ctx.lr = 0x82B2912C;
	sub_82B28910(ctx, base);
	// twi 31,r0,22
loc_82B29130:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82B29134:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29148"))) PPC_WEAK_FUNC(sub_82B29148);
PPC_FUNC_IMPL(__imp__sub_82B29148) {
	PPC_FUNC_PROLOGUE();
	// lis r11,32712
	ctx.r11.s64 = 2143813632;
	// li r10,7
	ctx.r10.s64 = 7;
	// stw r10,12820(r11)
	PPC_MM_STORE_U32(ctx.r11.u32 + 12820, ctx.r10.u32);
	// eieio 
	// li r10,2048
	ctx.r10.s64 = 2048;
	// stw r10,13320(r11)
	PPC_MM_STORE_U32(ctx.r11.u32 + 13320, ctx.r10.u32);
	// eieio 
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29168"))) PPC_WEAK_FUNC(sub_82B29168);
PPC_FUNC_IMPL(__imp__sub_82B29168) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x83158274
	ctx.lr = 0x82B2917C;
	__imp__ExRegisterTitleTerminateNotification(ctx, base);
	// bl 0x83158264
	ctx.lr = 0x82B29180;
	__imp__VdShutdownEngines(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29190"))) PPC_WEAK_FUNC(sub_82B29190);
PPC_FUNC_IMPL(__imp__sub_82B29190) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82B29198;
	__savegprlr_23(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// li r23,0
	ctx.r23.s64 = 0;
	// addi r29,r11,-30624
	ctx.r29.s64 = ctx.r11.s64 + -30624;
	// mr r30,r23
	ctx.r30.u64 = ctx.r23.u64;
	// lwz r25,13596(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13596);
	// lwz r24,22300(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 22300);
loc_82B291B8:
	// rlwinm r11,r30,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 30) & 0x3FFFFFFF;
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// add r9,r30,r31
	ctx.r9.u64 = ctx.r30.u64 + ctx.r31.u64;
	// addi r8,r11,16
	ctx.r8.s64 = ctx.r11.s64 + 16;
	// addi r11,r11,137
	ctx.r11.s64 = ctx.r11.s64 + 137;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stwx r10,r8,r31
	PPC_STORE_U32(ctx.r8.u32 + ctx.r31.u32, ctx.r10.u32);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// stwx r10,r11,r31
	PPC_STORE_U32(ctx.r11.u32 + ctx.r31.u32, ctx.r10.u32);
	// lwz r4,8(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// lwz r11,64(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 64);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B291F4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// addi r29,r29,12
	ctx.r29.s64 = ctx.r29.s64 + 12;
	// cmplwi cr6,r30,404
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 404, ctx.xer);
	// blt cr6,0x82b291b8
	if (ctx.cr6.lt) goto loc_82B291B8;
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// mr r28,r23
	ctx.r28.u64 = ctx.r23.u64;
	// addi r27,r31,1152
	ctx.r27.s64 = ctx.r31.s64 + 1152;
	// addi r26,r11,-29408
	ctx.r26.s64 = ctx.r11.s64 + -29408;
loc_82B29214:
	// mr r30,r23
	ctx.r30.u64 = ctx.r23.u64;
	// addi r29,r26,8
	ctx.r29.s64 = ctx.r26.s64 + 8;
loc_82B2921C:
	// rlwinm r11,r30,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 30) & 0x3FFFFFFF;
	// lwz r10,-4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + -4);
	// add r9,r30,r31
	ctx.r9.u64 = ctx.r30.u64 + ctx.r31.u64;
	// addi r8,r11,117
	ctx.r8.s64 = ctx.r11.s64 + 117;
	// addi r11,r11,238
	ctx.r11.s64 = ctx.r11.s64 + 238;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stwx r10,r8,r31
	PPC_STORE_U32(ctx.r8.u32 + ctx.r31.u32, ctx.r10.u32);
	// lwz r10,-8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + -8);
	// stwx r10,r11,r31
	PPC_STORE_U32(ctx.r11.u32 + ctx.r31.u32, ctx.r10.u32);
	// lwz r5,0(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r11,468(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 468);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2925C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// addi r29,r29,12
	ctx.r29.s64 = ctx.r29.s64 + 12;
	// cmplwi cr6,r30,80
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 80, ctx.xer);
	// blt cr6,0x82b2921c
	if (ctx.cr6.lt) goto loc_82B2921C;
	// addi r11,r28,32
	ctx.r11.s64 = ctx.r28.s64 + 32;
	// li r10,1
	ctx.r10.s64 = 1;
	// clrldi r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// rldicr r10,r10,63,63
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// srd r6,r10,r11
	ctx.r6.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82b14468
	ctx.lr = 0x82B29290;
	sub_82B14468(ctx, base);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r27,r27,24
	ctx.r27.s64 = ctx.r27.s64 + 24;
	// cmplwi cr6,r28,26
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 26, ctx.xer);
	// blt cr6,0x82b29214
	if (ctx.cr6.lt) goto loc_82B29214;
	// li r11,5
	ctx.r11.s64 = 5;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,12192(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12192, ctx.r11.u32);
	// stw r10,12196(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12196, ctx.r10.u32);
	// bl 0x82b104f0
	ctx.lr = 0x82B292BC;
	sub_82B104F0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b180f8
	ctx.lr = 0x82B292C8;
	sub_82B180F8(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1fe80
	ctx.lr = 0x82B292D4;
	sub_82B1FE80(ctx, base);
	// clrlwi r4,r24,31
	ctx.r4.u64 = ctx.r24.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1ec88
	ctx.lr = 0x82B292E0;
	sub_82B1EC88(ctx, base);
	// lbz r10,10940(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10940);
	// stw r23,12716(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12716, ctx.r23.u32);
	// rlwinm. r11,r10,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b293b0
	if (!ctx.cr0.eq) goto loc_82B293B0;
	// rlwinm. r11,r10,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b293b0
	if (!ctx.cr0.eq) goto loc_82B293B0;
	// lbz r11,12187(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 12187);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b293b0
	if (!ctx.cr0.eq) goto loc_82B293B0;
	// rlwinm. r11,r10,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b29314
	if (ctx.cr0.eq) goto loc_82B29314;
	// li r11,1
	ctx.r11.s64 = 1;
	// b 0x82b293a4
	goto loc_82B293A4;
loc_82B29314:
	// rlwinm. r11,r10,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2939c
	if (ctx.cr0.eq) goto loc_82B2939C;
	// lwz r11,12440(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12440);
	// lwz r9,12728(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12728);
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82b29334
	if (ctx.cr6.eq) goto loc_82B29334;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2939c
	if (!ctx.cr6.eq) goto loc_82B2939C;
loc_82B29334:
	// lwz r11,12444(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12444);
	// lwz r9,12732(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12732);
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82b2934c
	if (ctx.cr6.eq) goto loc_82B2934C;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2939c
	if (!ctx.cr6.eq) goto loc_82B2939C;
loc_82B2934C:
	// lwz r11,12448(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12448);
	// lwz r9,12736(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12736);
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82b29364
	if (ctx.cr6.eq) goto loc_82B29364;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2939c
	if (!ctx.cr6.eq) goto loc_82B2939C;
loc_82B29364:
	// lwz r11,12452(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12452);
	// lwz r9,12740(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12740);
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82b2937c
	if (ctx.cr6.eq) goto loc_82B2937C;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2939c
	if (!ctx.cr6.eq) goto loc_82B2939C;
loc_82B2937C:
	// lwz r11,12456(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12456);
	// lwz r9,12744(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12744);
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82b29394
	if (ctx.cr6.eq) goto loc_82B29394;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2939c
	if (!ctx.cr6.eq) goto loc_82B2939C;
loc_82B29394:
	// li r11,1
	ctx.r11.s64 = 1;
	// b 0x82b293a0
	goto loc_82B293A0;
loc_82B2939C:
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
loc_82B293A0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
loc_82B293A4:
	// clrlwi. r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne 0x82b293b4
	if (!ctx.cr0.eq) goto loc_82B293B4;
loc_82B293B0:
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
loc_82B293B4:
	// rlwimi r11,r10,0,24,30
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 0) & 0xFE) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFF01);
	// stw r23,12712(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12712, ctx.r23.u32);
	// li r9,-1
	ctx.r9.s64 = -1;
	// stw r23,10932(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10932, ctx.r23.u32);
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// stw r23,10936(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10936, ctx.r23.u32);
	// stw r9,12708(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12708, ctx.r9.u32);
	// stb r11,10940(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10940, ctx.r11.u8);
	// rlwinm. r10,r11,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82b293f0
	if (!ctx.cr0.eq) goto loc_82B293F0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b16a58
	ctx.lr = 0x82B293F0;
	sub_82B16A58(ctx, base);
loc_82B293F0:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B293F8"))) PPC_WEAK_FUNC(sub_82B293F8);
PPC_FUNC_IMPL(__imp__sub_82B293F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82B29400;
	__savegprlr_22(ctx, base);
	// stwu r1,-1760(r1)
	ea = -1760 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lwz r30,64(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// lwz r28,0(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r27,4(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmpwi r30,0
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// lwz r24,16(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r22,40(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// lwz r25,8(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bne 0x82b29434
	if (!ctx.cr0.eq) goto loc_82B29434;
	// clrlwi r11,r25,26
	ctx.r11.u64 = ctx.r25.u32 & 0x3F;
	// b 0x82b29444
	goto loc_82B29444;
loc_82B29434:
	// lis r11,10280
	ctx.r11.s64 = 673710080;
	// ori r11,r11,390
	ctx.r11.u64 = ctx.r11.u64 | 390;
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82b2944c
	if (!ctx.cr6.eq) goto loc_82B2944C;
loc_82B29444:
	// lis r30,10280
	ctx.r30.s64 = 673710080;
	// b 0x82b29460
	goto loc_82B29460;
loc_82B2944C:
	// lis r11,6184
	ctx.r11.s64 = 405274624;
	// ori r11,r11,390
	ctx.r11.u64 = ctx.r11.u64 | 390;
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82b29468
	if (!ctx.cr6.eq) goto loc_82B29468;
	// lis r30,6184
	ctx.r30.s64 = 405274624;
loc_82B29460:
	// ori r30,r30,262
	ctx.r30.u64 = ctx.r30.u64 | 262;
	// b 0x82b29498
	goto loc_82B29498;
loc_82B29468:
	// lis r11,10280
	ctx.r11.s64 = 673710080;
	// ori r11,r11,438
	ctx.r11.u64 = ctx.r11.u64 | 438;
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82b29480
	if (!ctx.cr6.eq) goto loc_82B29480;
	// lis r30,10280
	ctx.r30.s64 = 673710080;
	// b 0x82b29494
	goto loc_82B29494;
loc_82B29480:
	// lis r11,6184
	ctx.r11.s64 = 405274624;
	// ori r11,r11,438
	ctx.r11.u64 = ctx.r11.u64 | 438;
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82b29498
	if (!ctx.cr6.eq) goto loc_82B29498;
	// lis r30,6184
	ctx.r30.s64 = 405274624;
loc_82B29494:
	// ori r30,r30,310
	ctx.r30.u64 = ctx.r30.u64 | 310;
loc_82B29498:
	// clrlwi r23,r30,26
	ctx.r23.u64 = ctx.r30.u32 & 0x3F;
	// mr r26,r23
	ctx.r26.u64 = ctx.r23.u64;
	// cmplwi cr6,r26,50
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 50, ctx.xer);
	// bne cr6,0x82b294b0
	if (!ctx.cr6.eq) goto loc_82B294B0;
	// li r26,6
	ctx.r26.s64 = 6;
	// b 0x82b294bc
	goto loc_82B294BC;
loc_82B294B0:
	// cmplwi cr6,r26,7
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 7, ctx.xer);
	// bne cr6,0x82b294bc
	if (!ctx.cr6.eq) goto loc_82B294BC;
	// li r26,54
	ctx.r26.s64 = 54;
loc_82B294BC:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83158284
	ctx.lr = 0x82B294C4;
	__imp__VdQueryVideoMode(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r9,r29,21552
	ctx.r9.s64 = ctx.r29.s64 + 21552;
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stw r10,21544(r29)
	PPC_STORE_U32(ctx.r29.u32 + 21544, ctx.r10.u32);
	// stw r11,21540(r29)
	PPC_STORE_U32(ctx.r29.u32 + 21540, ctx.r11.u32);
	// stw r11,21548(r29)
	PPC_STORE_U32(ctx.r29.u32 + 21548, ctx.r11.u32);
	// fctidz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b29538
	if (!ctx.cr6.eq) goto loc_82B29538;
	// li r10,3
	ctx.r10.s64 = 3;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b14100
	ctx.lr = 0x82B29524;
	sub_82B14100(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne 0x82b29534
	if (!ctx.cr0.eq) goto loc_82B29534;
loc_82B2952C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b2962c
	goto loc_82B2962C;
loc_82B29534:
	// stw r3,14828(r29)
	PPC_STORE_U32(ctx.r29.u32 + 14828, ctx.r3.u32);
loc_82B29538:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b29574
	if (!ctx.cr6.eq) goto loc_82B29574;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b14220
	ctx.lr = 0x82B2955C;
	sub_82B14220(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// beq 0x82b2952c
	if (ctx.cr0.eq) goto loc_82B2952C;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r5,14832(r29)
	PPC_STORE_U32(ctx.r29.u32 + 14832, ctx.r5.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b21260
	ctx.lr = 0x82B29574;
	sub_82B21260(ctx, base);
loc_82B29574:
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b295ac
	if (ctx.cr6.eq) goto loc_82B295AC;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b14220
	ctx.lr = 0x82B29598;
	sub_82B14220(ctx, base);
	// mr. r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq 0x82b2952c
	if (ctx.cr0.eq) goto loc_82B2952C;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r4,14824(r29)
	PPC_STORE_U32(ctx.r29.u32 + 14824, ctx.r4.u32);
	// bl 0x82b215c8
	ctx.lr = 0x82B295AC;
	sub_82B215C8(ctx, base);
loc_82B295AC:
	// addi r3,r29,13544
	ctx.r3.s64 = ctx.r29.s64 + 13544;
	// li r5,124
	ctx.r5.s64 = 124;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B295BC;
	sub_82E28FD0(ctx, base);
	// oris r11,r23,10280
	ctx.r11.u64 = ctx.r23.u64 | 673710080;
	// addi r4,r31,96
	ctx.r4.s64 = ctx.r31.s64 + 96;
	// ori r11,r11,256
	ctx.r11.u64 = ctx.r11.u64 | 256;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r11,13608(r29)
	PPC_STORE_U32(ctx.r29.u32 + 13608, ctx.r11.u32);
	// bl 0x82b2f230
	ctx.lr = 0x82B295D4;
	sub_82B2F230(ctx, base);
	// cmplwi cr6,r26,7
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 7, ctx.xer);
	// beq cr6,0x82b29604
	if (ctx.cr6.eq) goto loc_82B29604;
	// cmplwi cr6,r26,54
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 54, ctx.xer);
	// beq cr6,0x82b29604
	if (ctx.cr6.eq) goto loc_82B29604;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82b2bdc0
	ctx.lr = 0x82B295F0;
	sub_82B2BDC0(ctx, base);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b20c28
	ctx.lr = 0x82B29600;
	sub_82B20C28(ctx, base);
	// b 0x82b29620
	goto loc_82B29620;
loc_82B29604:
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82b2be18
	ctx.lr = 0x82B29610;
	sub_82B2BE18(ctx, base);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b20cf0
	ctx.lr = 0x82B29620;
	sub_82B20CF0(ctx, base);
loc_82B29620:
	// li r11,-1
	ctx.r11.s64 = -1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,16708(r29)
	PPC_STORE_U32(ctx.r29.u32 + 16708, ctx.r11.u32);
loc_82B2962C:
	// addi r1,r1,1760
	ctx.r1.s64 = ctx.r1.s64 + 1760;
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B29638"))) PPC_WEAK_FUNC(sub_82B29638);
PPC_FUNC_IMPL(__imp__sub_82B29638) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B29640;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82b30660
	ctx.lr = 0x82B2964C;
	sub_82B30660(ctx, base);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b29690
	if (ctx.cr6.eq) goto loc_82B29690;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b215c8
	ctx.lr = 0x82B29668;
	sub_82B215C8(ctx, base);
	// mr r30,r29
	ctx.r30.u64 = ctx.r29.u64;
loc_82B2966C:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b21260
	ctx.lr = 0x82B2967C;
	sub_82B21260(ctx, base);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// cmplwi cr6,r30,4
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 4, ctx.xer);
	// blt cr6,0x82b2966c
	if (ctx.cr6.lt) goto loc_82B2966C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dd70
	ctx.lr = 0x82B29690;
	sub_82B1DD70(ctx, base);
loc_82B29690:
	// lwz r3,14828(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14828);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b296a4
	if (ctx.cr0.eq) goto loc_82B296A4;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B296A0;
	sub_82B0F2F0(ctx, base);
	// stw r29,14828(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14828, ctx.r29.u32);
loc_82B296A4:
	// lwz r3,14832(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14832);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b296b8
	if (ctx.cr0.eq) goto loc_82B296B8;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B296B4;
	sub_82B0F2F0(ctx, base);
	// stw r29,14832(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14832, ctx.r29.u32);
loc_82B296B8:
	// lwz r3,14824(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14824);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b296cc
	if (ctx.cr0.eq) goto loc_82B296CC;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B296C8;
	sub_82B0F2F0(ctx, base);
	// stw r29,14824(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14824, ctx.r29.u32);
loc_82B296CC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B296D8"))) PPC_WEAK_FUNC(sub_82B296D8);
PPC_FUNC_IMPL(__imp__sub_82B296D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b2971c
	if (ctx.cr6.eq) goto loc_82B2971C;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// bl 0x82b296d8
	ctx.lr = 0x82B296FC;
	sub_82B296D8(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lis r4,-20096
	ctx.r4.s64 = -1317011456;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// bl 0x82547938
	ctx.lr = 0x82B29710;
	sub_82547938(ctx, base);
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82547938
	ctx.lr = 0x82B2971C;
	sub_82547938(ctx, base);
loc_82B2971C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29730"))) PPC_WEAK_FUNC(sub_82B29730);
PPC_FUNC_IMPL(__imp__sub_82B29730) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// beq cr6,0x82b297a4
	if (ctx.cr6.eq) goto loc_82B297A4;
	// lwz r11,64(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 64);
	// li r10,0
	ctx.r10.s64 = 0;
	// clrlwi r11,r11,26
	ctx.r11.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// beq cr6,0x82b29768
	if (ctx.cr6.eq) goto loc_82B29768;
	// cmplwi cr6,r11,54
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 54, ctx.xer);
	// bne cr6,0x82b2976c
	if (!ctx.cr6.eq) goto loc_82B2976C;
loc_82B29768:
	// lis r10,2048
	ctx.r10.s64 = 134217728;
loc_82B2976C:
	// lwz r11,68(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 68);
	// lis r9,16384
	ctx.r9.s64 = 1073741824;
	// lwz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// rlwimi r9,r11,28,2,3
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 28) & 0x30000000) | (ctx.r9.u64 & 0xFFFFFFFFCFFFFFFF);
	// cmplwi cr6,r8,720
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 720, ctx.xer);
	// or r3,r9,r10
	ctx.r3.u64 = ctx.r9.u64 | ctx.r10.u64;
	// bne cr6,0x82b297a0
	if (!ctx.cr6.eq) goto loc_82B297A0;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplwi cr6,r11,480
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 480, ctx.xer);
	// beq cr6,0x82b2979c
	if (ctx.cr6.eq) goto loc_82B2979C;
	// cmplwi cr6,r11,576
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 576, ctx.xer);
	// bne cr6,0x82b297a0
	if (!ctx.cr6.eq) goto loc_82B297A0;
loc_82B2979C:
	// ori r3,r3,2
	ctx.r3.u64 = ctx.r3.u64 | 2;
loc_82B297A0:
	// bl 0x831582a4
	ctx.lr = 0x82B297A4;
	__imp__VdSetDisplayMode(ctx, base);
loc_82B297A4:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x83158294
	ctx.lr = 0x82B297AC;
	__imp__VdGetCurrentDisplayInformation(ctx, base);
	// lhz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 152);
	// lhz r10,154(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 154);
	// lhz r9,166(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 166);
	// stw r11,21540(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21540, ctx.r11.u32);
	// stw r10,21544(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21544, ctx.r10.u32);
	// stw r9,21548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21548, ctx.r9.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B297D8"))) PPC_WEAK_FUNC(sub_82B297D8);
PPC_FUNC_IMPL(__imp__sub_82B297D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r7,r11,-9736
	ctx.r7.s64 = ctx.r11.s64 + -9736;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lis r3,6534
	ctx.r3.s64 = 428212224;
	// addi r6,r11,-10888
	ctx.r6.s64 = ctx.r11.s64 + -10888;
	// lis r11,-32077
	ctx.r11.s64 = -2102198272;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r11,-28344
	ctx.r4.s64 = ctx.r11.s64 + -28344;
	// ori r3,r3,1
	ctx.r3.u64 = ctx.r3.u64 | 1;
	// bl 0x831582c4
	ctx.lr = 0x82B29814;
	__imp__VdInitializeEngines(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r3,r11,-28704
	ctx.r3.s64 = ctx.r11.s64 + -28704;
	// bl 0x83158274
	ctx.lr = 0x82B29824;
	__imp__ExRegisterTitleTerminateNotification(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// lis r11,-32078
	ctx.r11.s64 = -2102263808;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r11,-13728
	ctx.r3.s64 = ctx.r11.s64 + -13728;
	// stw r10,16712(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16712, ctx.r10.u32);
	// bl 0x831582b4
	ctx.lr = 0x82B2983C;
	__imp__VdSetGraphicsInterruptCallback(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29858"))) PPC_WEAK_FUNC(sub_82B29858);
PPC_FUNC_IMPL(__imp__sub_82B29858) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// ld r11,-29160(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + -29160);
	// std r11,10880(r31)
	PPC_STORE_U64(ctx.r31.u32 + 10880, ctx.r11.u64);
	// bl 0x82b076f0
	ctx.lr = 0x82B29884;
	sub_82B076F0(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// lis r4,-19072
	ctx.r4.s64 = -1249902592;
	// li r3,4800
	ctx.r3.s64 = 4800;
	// stw r11,10888(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10888, ctx.r11.u32);
	// stw r10,10892(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10892, ctx.r10.u32);
	// bl 0x82547910
	ctx.lr = 0x82B298A0;
	sub_82547910(ctx, base);
	// cntlzw r11,r3
	ctx.r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// stw r3,16728(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16728, ctx.r3.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = ctx.r11.u64 ^ 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B298C8"))) PPC_WEAK_FUNC(sub_82B298C8);
PPC_FUNC_IMPL(__imp__sub_82B298C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r3,r31,14944
	ctx.r3.s64 = ctx.r31.s64 + 14944;
	// bl 0x83157d34
	ctx.lr = 0x82B298EC;
	__imp__RtlInitializeCriticalSection(ctx, base);
	// addi r3,r31,14972
	ctx.r3.s64 = ctx.r31.s64 + 14972;
	// bl 0x83157d34
	ctx.lr = 0x82B298F4;
	__imp__RtlInitializeCriticalSection(ctx, base);
	// lbz r11,10942(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10942);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stb r11,10942(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10942, ctx.r11.u8);
	// bl 0x82b297d8
	ctx.lr = 0x82B29908;
	sub_82B297D8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b29918
	if (!ctx.cr0.eq) goto loc_82B29918;
loc_82B29910:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b29ab4
	goto loc_82B29AB4;
loc_82B29918:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r31,16716
	ctx.r5.s64 = ctx.r31.s64 + 16716;
	// li r4,10
	ctx.r4.s64 = 10;
	// lwz r11,2016(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2016);
	// li r3,3
	ctx.r3.s64 = 3;
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// sth r11,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, ctx.r11.u16);
	// bl 0x83157da4
	ctx.lr = 0x82B29944;
	__imp__ExGetXConfigSetting(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b29910
	if (ctx.cr0.lt) goto loc_82B29910;
	// addi r4,r30,72
	ctx.r4.s64 = ctx.r30.s64 + 72;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1de40
	ctx.lr = 0x82B29958;
	sub_82B1DE40(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b29910
	if (!ctx.cr0.eq) goto loc_82B29910;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b2b1f8
	ctx.lr = 0x82B29968;
	sub_82B2B1F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b29910
	if (ctx.cr0.eq) goto loc_82B29910;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b15f40
	ctx.lr = 0x82B29978;
	sub_82B15F40(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b29910
	if (ctx.cr0.eq) goto loc_82B29910;
	// li r11,-1
	ctx.r11.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,21556(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21556, ctx.r11.u32);
	// stw r11,21560(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21560, ctx.r11.u32);
	// bl 0x82b2b5c0
	ctx.lr = 0x82B29994;
	sub_82B2B5C0(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b293f8
	ctx.lr = 0x82B299A0;
	sub_82B293F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b29910
	if (ctx.cr0.eq) goto loc_82B29910;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b29190
	ctx.lr = 0x82B299B0;
	sub_82B29190(ctx, base);
	// lis r4,-20096
	ctx.r4.s64 = -1317011456;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82547938
	ctx.lr = 0x82B299BC;
	sub_82547938(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b299d8
	if (ctx.cr0.eq) goto loc_82B299D8;
	// lwz r11,32(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// b 0x82b299dc
	goto loc_82B299DC;
loc_82B299D8:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82B299DC:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b29a10
	if (ctx.cr6.eq) goto loc_82B29A10;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 8, ctx.xer);
	// ble cr6,0x82b29a00
	if (!ctx.cr6.gt) goto loc_82B29A00;
	// addi r10,r31,16720
	ctx.r10.s64 = ctx.r31.s64 + 16720;
	// addi r9,r31,16724
	ctx.r9.s64 = ctx.r31.s64 + 16724;
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
loc_82B29A00:
	// addi r10,r31,16560
	ctx.r10.s64 = ctx.r31.s64 + 16560;
	// addi r9,r31,21572
	ctx.r9.s64 = ctx.r31.s64 + 21572;
	// stw r10,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r10.u32);
	// stw r9,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r9.u32);
loc_82B29A10:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B29A18;
	sub_82B1DAE8(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82b08168
	ctx.lr = 0x82B29A20;
	sub_82B08168(ctx, base);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lfs f13,-13896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f13.f64 = double(temp.f32);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,21584(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 21584, temp.u32);
	// fdivs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 / ctx.f0.f64));
	// stfs f0,21588(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 21588, temp.u32);
	// bl 0x82b2cdf8
	ctx.lr = 0x82B29A48;
	sub_82B2CDF8(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b2f260
	ctx.lr = 0x82B29A58;
	sub_82B2F260(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b20db8
	ctx.lr = 0x82B29A64;
	sub_82B20DB8(ctx, base);
	// lis r30,-31967
	ctx.r30.s64 = -2094989312;
	// lwz r11,7368(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 7368);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b29a88
	if (!ctx.cr6.eq) goto loc_82B29A88;
	// bl 0x831582d4
	ctx.lr = 0x82B29A78;
	__imp__VdIsHSIOTrainingSucceeded(ctx, base);
	// cntlzw r11,r3
	ctx.r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm. r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,7368(r30)
	PPC_STORE_U32(ctx.r30.u32 + 7368, ctx.r11.u32);
	// beq 0x82b29a94
	if (ctx.cr0.eq) goto loc_82B29A94;
loc_82B29A88:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-19264
	ctx.r3.s64 = ctx.r11.s64 + -19264;
	// bl 0x82b28910
	ctx.lr = 0x82B29A94;
	sub_82B28910(ctx, base);
loc_82B29A94:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b2f480
	ctx.lr = 0x82B29A9C;
	sub_82B2F480(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b29ab0
	if (!ctx.cr0.eq) goto loc_82B29AB0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-19336
	ctx.r3.s64 = ctx.r11.s64 + -19336;
	// bl 0x82b28910
	ctx.lr = 0x82B29AB0;
	sub_82B28910(ctx, base);
loc_82B29AB0:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82B29AB4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29AD0"))) PPC_WEAK_FUNC(sub_82B29AD0);
PPC_FUNC_IMPL(__imp__sub_82B29AD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82b1cc08
	ctx.lr = 0x82B29AE8;
	sub_82B1CC08(ctx, base);
	// li r11,-1
	ctx.r11.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,21556(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21556, ctx.r11.u32);
	// stw r11,21560(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21560, ctx.r11.u32);
	// stw r11,14936(r31)
	PPC_STORE_U32(ctx.r31.u32 + 14936, ctx.r11.u32);
	// bl 0x82b2b5c0
	ctx.lr = 0x82B29B00;
	sub_82B2B5C0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b29190
	ctx.lr = 0x82B29B08;
	sub_82B29190(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29B20"))) PPC_WEAK_FUNC(sub_82B29B20);
PPC_FUNC_IMPL(__imp__sub_82B29B20) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B29B28;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b29b40
	if (ctx.cr6.eq) goto loc_82B29B40;
	// bl 0x82b1dd70
	ctx.lr = 0x82B29B40;
	sub_82B1DD70(ctx, base);
loc_82B29B40:
	// addi r31,r30,21632
	ctx.r31.s64 = ctx.r30.s64 + 21632;
	// li r28,4
	ctx.r28.s64 = 4;
	// li r29,0
	ctx.r29.s64 = 0;
loc_82B29B4C:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b29b64
	if (ctx.cr0.eq) goto loc_82B29B64;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x82547938
	ctx.lr = 0x82B29B60;
	sub_82547938(ctx, base);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
loc_82B29B64:
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x82b29b4c
	if (!ctx.cr0.eq) goto loc_82B29B4C;
	// lwz r3,21628(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21628);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b29b8c
	if (ctx.cr0.eq) goto loc_82B29B8C;
	// lis r4,-20096
	ctx.r4.s64 = -1317011456;
	// bl 0x82547938
	ctx.lr = 0x82B29B84;
	sub_82547938(ctx, base);
	// stw r29,21628(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21628, ctx.r29.u32);
	// stw r29,21648(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21648, ctx.r29.u32);
loc_82B29B8C:
	// stw r29,21652(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21652, ctx.r29.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B29B98"))) PPC_WEAK_FUNC(sub_82B29B98);
PPC_FUNC_IMPL(__imp__sub_82B29B98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b29bc0
	if (ctx.cr6.eq) goto loc_82B29BC0;
	// bl 0x82b0f910
	ctx.lr = 0x82B29BC0;
	sub_82B0F910(ctx, base);
loc_82B29BC0:
	// lbz r11,10940(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10940);
	// rlwinm. r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b29c98
	if (!ctx.cr0.eq) goto loc_82B29C98;
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b29be0
	if (ctx.cr6.eq) goto loc_82B29BE0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dd70
	ctx.lr = 0x82B29BE0;
	sub_82B1DD70(ctx, base);
loc_82B29BE0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b29b20
	ctx.lr = 0x82B29BE8;
	sub_82B29B20(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b31378
	ctx.lr = 0x82B29BF0;
	sub_82B31378(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b2cef8
	ctx.lr = 0x82B29BF8;
	sub_82B2CEF8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831581f4
	ctx.lr = 0x82B29C00;
	__imp__VdSetSystemCommandBufferGpuIdentifierAddress(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b29638
	ctx.lr = 0x82B29C08;
	sub_82B29638(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b2b378
	ctx.lr = 0x82B29C10;
	sub_82B2B378(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b16078
	ctx.lr = 0x82B29C18;
	sub_82B16078(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// li r30,0
	ctx.r30.s64 = 0;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b29c38
	if (ctx.cr0.eq) goto loc_82B29C38;
	// lwz r11,32(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// b 0x82b29c3c
	goto loc_82B29C3C;
loc_82B29C38:
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
loc_82B29C3C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b29c60
	if (ctx.cr6.eq) goto loc_82B29C60;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 8, ctx.xer);
	// ble cr6,0x82b29c58
	if (!ctx.cr6.gt) goto loc_82B29C58;
	// stw r30,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r30.u32);
	// stw r30,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r30.u32);
loc_82B29C58:
	// stw r30,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r30.u32);
	// stw r30,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r30.u32);
loc_82B29C60:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831582b4
	ctx.lr = 0x82B29C6C;
	__imp__VdSetGraphicsInterruptCallback(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1de40
	ctx.lr = 0x82B29C78;
	sub_82B1DE40(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r11,-28704
	ctx.r3.s64 = ctx.r11.s64 + -28704;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2016(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2016);
	// stw r30,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r30.u32);
	// bl 0x83158274
	ctx.lr = 0x82B29C94;
	__imp__ExRegisterTitleTerminateNotification(ctx, base);
	// bl 0x83158264
	ctx.lr = 0x82B29C98;
	__imp__VdShutdownEngines(ctx, base);
loc_82B29C98:
	// lwz r3,16728(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16728);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b29cac
	if (ctx.cr0.eq) goto loc_82B29CAC;
	// lis r4,-20096
	ctx.r4.s64 = -1317011456;
	// bl 0x82547938
	ctx.lr = 0x82B29CAC;
	sub_82547938(ctx, base);
loc_82B29CAC:
	// lwz r3,21568(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21568);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b29cbc
	if (ctx.cr0.eq) goto loc_82B29CBC;
	// bl 0x82b296d8
	ctx.lr = 0x82B29CBC;
	sub_82B296D8(ctx, base);
loc_82B29CBC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29CD8"))) PPC_WEAK_FUNC(sub_82B29CD8);
PPC_FUNC_IMPL(__imp__sub_82B29CD8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r10,r11,23776
	ctx.r10.s64 = ctx.r11.s64 + 23776;
loc_82B29CE0:
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addi r6,r11,2
	ctx.r6.s64 = ctx.r11.s64 + 2;
	// clrlwi r6,r6,20
	ctx.r6.u64 = ctx.r6.u32 & 0xFFF;
loc_82B29CF0:
	// mfmsr r8
	ctx.r8.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r9,0,r7
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r9.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82b29d14
	if (!ctx.cr6.eq) goto loc_82B29D14;
	// stwcx. r6,0,r7
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r6.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r8,1
	ctx.msr = (ctx.r8.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b29cf0
	if (!ctx.cr0.eq) goto loc_82B29CF0;
	// b 0x82b29d1c
	goto loc_82B29D1C;
loc_82B29D14:
	// stwcx. r9,0,r7
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r9.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r8,1
	ctx.msr = (ctx.r8.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_82B29D1C:
	// mr r9,r9
	ctx.r9.u64 = ctx.r9.u64;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b29ce0
	if (!ctx.cr6.eq) goto loc_82B29CE0;
	// lis r10,-31967
	ctx.r10.s64 = -2094989312;
	// lbz r8,268(r13)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r13.u32 + 268);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,7392
	ctx.r10.s64 = ctx.r10.s64 + 7392;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// stwx r8,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r8.u32);
	// stwx r3,r11,r9
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, ctx.r3.u32);
	// lwsync 
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29D50"))) PPC_WEAK_FUNC(sub_82B29D50);
PPC_FUNC_IMPL(__imp__sub_82B29D50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r10,1
	ctx.r10.s64 = 1;
	// clrlwi. r11,r4,31
	ctx.r11.u64 = ctx.r4.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lis r31,4
	ctx.r31.s64 = 262144;
	// stw r10,104(r3)
	PPC_STORE_U32(ctx.r3.u32 + 104, ctx.r10.u32);
	// bne 0x82b29d7c
	if (!ctx.cr0.eq) goto loc_82B29D7C;
	// lis r31,2
	ctx.r31.s64 = 131072;
loc_82B29D7C:
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r30,32528
	ctx.r30.s64 = 2131755008;
	// ori r7,r11,1
	ctx.r7.u64 = ctx.r11.u64 | 1;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// lis r4,32528
	ctx.r4.s64 = 2131755008;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r30.u32);
	// bl 0x831582e4
	ctx.lr = 0x82B29DA0;
	__imp__KeLockL2(ctx, base);
	// add r11,r31,r30
	ctx.r11.u64 = ctx.r31.u64 + ctx.r30.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
loc_82B29DA8:
	// dcbzl r0,r30
	memset(base + ((ctx.r30.u32) & ~127), 0, 128);
	// li r10,128
	ctx.r10.s64 = 128;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// dcbzl r10,r11
	memset(base + ((ctx.r10.u32 + ctx.r11.u32) & ~127), 0, 128);
	// li r10,256
	ctx.r10.s64 = 256;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// dcbzl r10,r11
	memset(base + ((ctx.r10.u32 + ctx.r11.u32) & ~127), 0, 128);
	// li r10,384
	ctx.r10.s64 = 384;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// dcbzl r10,r11
	memset(base + ((ctx.r10.u32 + ctx.r11.u32) & ~127), 0, 128);
	// li r10,512
	ctx.r10.s64 = 512;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// dcbzl r10,r11
	memset(base + ((ctx.r10.u32 + ctx.r11.u32) & ~127), 0, 128);
	// li r10,640
	ctx.r10.s64 = 640;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// dcbzl r10,r11
	memset(base + ((ctx.r10.u32 + ctx.r11.u32) & ~127), 0, 128);
	// li r10,768
	ctx.r10.s64 = 768;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// dcbzl r10,r11
	memset(base + ((ctx.r10.u32 + ctx.r11.u32) & ~127), 0, 128);
	// li r10,896
	ctx.r10.s64 = 896;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// dcbzl r10,r11
	memset(base + ((ctx.r10.u32 + ctx.r11.u32) & ~127), 0, 128);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r30,r11,1024
	ctx.r30.s64 = ctx.r11.s64 + 1024;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r30.u32);
	// blt cr6,0x82b29da8
	if (ctx.cr6.lt) goto loc_82B29DA8;
	// sync 
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29E38"))) PPC_WEAK_FUNC(sub_82B29E38);
PPC_FUNC_IMPL(__imp__sub_82B29E38) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,48(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// srawi. r9,r10,31
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFFFFFF) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 31;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82b29e50
	if (ctx.cr0.eq) goto loc_82B29E50;
	// lis r11,10922
	ctx.r11.s64 = 715784192;
	// ori r11,r11,43690
	ctx.r11.u64 = ctx.r11.u64 | 43690;
	// b 0x82b29e68
	goto loc_82B29E68;
loc_82B29E50:
	// rlwinm. r11,r10,0,1,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b29e64
	if (ctx.cr0.eq) goto loc_82B29E64;
	// lis r11,5461
	ctx.r11.s64 = 357892096;
	// ori r11,r11,21845
	ctx.r11.u64 = ctx.r11.u64 | 21845;
	// b 0x82b29e68
	goto loc_82B29E68;
loc_82B29E64:
	// li r11,-1
	ctx.r11.s64 = -1;
loc_82B29E68:
	// rlwinm. r10,r10,0,2,2
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000000;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b29e98
	if (ctx.cr0.eq) goto loc_82B29E98;
	// lwz r10,52(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	// li r8,3
	ctx.r8.s64 = 3;
	// rlwinm r7,r10,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// slw r10,r8,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r7.u8 & 0x3F));
	// and r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	// bne 0x82b29e98
	if (!ctx.cr0.eq) goto loc_82B29E98;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82b29e98
	if (!ctx.cr6.eq) goto loc_82B29E98;
	// oris r11,r11,32768
	ctx.r11.u64 = ctx.r11.u64 | 2147483648;
loc_82B29E98:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B29EA0"))) PPC_WEAK_FUNC(sub_82B29EA0);
PPC_FUNC_IMPL(__imp__sub_82B29EA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82B29EA8;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// addi r27,r11,8
	ctx.r27.s64 = ctx.r11.s64 + 8;
	// lwz r26,4(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
loc_82B29EC0:
	// lwz r4,0(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r10,r3,4
	ctx.r10.s64 = ctx.r3.s64 + 4;
	// cmplw cr6,r10,r4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, ctx.xer);
	// bge cr6,0x82b29f78
	if (!ctx.cr6.lt) goto loc_82B29F78;
	// addi r28,r26,-1
	ctx.r28.s64 = ctx.r26.s64 + -1;
	// addi r11,r10,8
	ctx.r11.s64 = ctx.r10.s64 + 8;
loc_82B29ED8:
	// lhz r9,2(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 2);
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// lhz r8,-2(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + -2);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lhz r31,-4(r11)
	ctx.r31.u64 = PPC_LOAD_U16(ctx.r11.u32 + -4);
	// lhz r30,0(r11)
	ctx.r30.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// rlwinm r29,r9,3,0,28
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r5,0(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r7,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// rotlwi r31,r31,3
	ctx.r31.u64 = __builtin_rotateleft32(ctx.r31.u32, 3);
	// add r9,r9,r27
	ctx.r9.u64 = ctx.r9.u64 + ctx.r27.u64;
	// rlwinm r8,r8,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rotlwi r30,r30,3
	ctx.r30.u64 = __builtin_rotateleft32(ctx.r30.u32, 3);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
loc_82B29F18:
	// lwz r24,-4(r9)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r9.u32 + -4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r24,r8
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r8.u32, ctx.xer);
	// bge cr6,0x82b29f50
	if (!ctx.cr6.lt) goto loc_82B29F50;
	// lwz r24,4(r9)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r24,r31
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r31.u32, ctx.xer);
	// ble cr6,0x82b29f50
	if (!ctx.cr6.gt) goto loc_82B29F50;
	// lwz r24,0(r9)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r24,r29
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r29.u32, ctx.xer);
	// bge cr6,0x82b29f50
	if (!ctx.cr6.lt) goto loc_82B29F50;
	// lwz r24,8(r9)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmplw cr6,r24,r30
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r30.u32, ctx.xer);
	// ble cr6,0x82b29f50
	if (!ctx.cr6.gt) goto loc_82B29F50;
	// ori r6,r6,3
	ctx.r6.u64 = ctx.r6.u64 | 3;
loc_82B29F50:
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// addi r9,r9,-16
	ctx.r9.s64 = ctx.r9.s64 + -16;
	// bne cr6,0x82b29f18
	if (!ctx.cr6.eq) goto loc_82B29F18;
	// oris r9,r6,32768
	ctx.r9.u64 = ctx.r6.u64 | 2147483648;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// cmplw cr6,r10,r4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, ctx.xer);
	// stw r9,8(r5)
	PPC_STORE_U32(ctx.r5.u32 + 8, ctx.r9.u32);
	// blt cr6,0x82b29ed8
	if (ctx.cr6.lt) goto loc_82B29ED8;
loc_82B29F78:
	// lwz r31,0(r10)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r25,0
	ctx.cr6.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// beq cr6,0x82b29f8c
	if (ctx.cr6.eq) goto loc_82B29F8C;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x82b28870
	ctx.lr = 0x82B29F8C;
	sub_82B28870(ctx, base);
loc_82B29F8C:
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b29ec0
	if (!ctx.cr6.eq) goto loc_82B29EC0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B29FA8"))) PPC_WEAK_FUNC(sub_82B29FA8);
PPC_FUNC_IMPL(__imp__sub_82B29FA8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B29FB0;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// bl 0x82b29ea0
	ctx.lr = 0x82B29FC4;
	sub_82B29EA0(ctx, base);
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82B29FC8:
	// lwz r30,0(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r31,r11,4
	ctx.r31.s64 = ctx.r11.s64 + 4;
	// b 0x82b29fe8
	goto loc_82B29FE8;
loc_82B29FD4:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b29ea0
	ctx.lr = 0x82B29FE4;
	sub_82B29EA0(ctx, base);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
loc_82B29FE8:
	// cmplw cr6,r31,r30
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r30.u32, ctx.xer);
	// blt cr6,0x82b29fd4
	if (ctx.cr6.lt) goto loc_82B29FD4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82b29fc8
	if (!ctx.cr6.eq) goto loc_82B29FC8;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2A008"))) PPC_WEAK_FUNC(sub_82B2A008);
PPC_FUNC_IMPL(__imp__sub_82B2A008) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B2A010;
	__savegprlr_26(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b29d50
	ctx.lr = 0x82B2A02C;
	sub_82B29D50(ctx, base);
	// li r29,0
	ctx.r29.s64 = 0;
	// lis r26,256
	ctx.r26.s64 = 16777216;
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82B2A03C:
	// slw r9,r26,r11
	ctx.r9.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r26.u32 << (ctx.r11.u8 & 0x3F));
	// and. r9,r9,r27
	ctx.r9.u64 = ctx.r9.u64 & ctx.r27.u64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82b2a04c
	if (ctx.cr0.eq) goto loc_82B2A04C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
loc_82B2A04C:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// blt cr6,0x82b2a03c
	if (ctx.cr6.lt) goto loc_82B2A03C;
	// rlwinm r11,r27,0,2,7
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0x3F000000;
	// clrlwi. r9,r27,31
	ctx.r9.u64 = ctx.r27.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// stw r11,56(r30)
	PPC_STORE_U32(ctx.r30.u32 + 56, ctx.r11.u32);
	// lis r11,4
	ctx.r11.s64 = 262144;
	// bne 0x82b2a070
	if (!ctx.cr0.eq) goto loc_82B2A070;
	// lis r11,2
	ctx.r11.s64 = 131072;
loc_82B2A070:
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// twllei r10,0
	// lwz r10,11804(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11804);
	// rlwinm r6,r11,0,0,24
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lis r9,32528
	ctx.r9.s64 = 2131755008;
	// addi r11,r31,11340
	ctx.r11.s64 = ctx.r31.s64 + 11340;
loc_82B2A08C:
	// slw r8,r26,r7
	ctx.r8.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r26.u32 << (ctx.r7.u8 & 0x3F));
	// and. r8,r8,r27
	ctx.r8.u64 = ctx.r8.u64 & ctx.r27.u64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b2a0e4
	if (ctx.cr0.eq) goto loc_82B2A0E4;
	// lis r5,-16382
	ctx.r5.s64 = -1073610752;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// add r8,r9,r6
	ctx.r8.u64 = ctx.r9.u64 + ctx.r6.u64;
	// stw r29,-4(r11)
	PPC_STORE_U32(ctx.r11.u32 + -4, ctx.r29.u32);
	// rotlwi r9,r9,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// ori r5,r5,22528
	ctx.r5.u64 = ctx.r5.u64 | 22528;
	// li r4,3
	ctx.r4.s64 = 3;
	// stw r8,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r8.u32);
	// stw r9,-8(r11)
	PPC_STORE_U32(ctx.r11.u32 + -8, ctx.r9.u32);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// stw r5,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r5.u32);
	// stw r4,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r4.u32);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r8,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r8.u32);
	// lwz r8,-8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// lwz r5,-4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// rlwimi r8,r5,0,30,31
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r5.u32, 0) & 0x3) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r8,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r8.u32);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
loc_82B2A0E4:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,80
	ctx.r11.s64 = ctx.r11.s64 + 80;
	// cmplwi cr6,r7,6
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 6, ctx.xer);
	// blt cr6,0x82b2a08c
	if (ctx.cr6.lt) goto loc_82B2A08C;
	// lwz r11,11804(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11804);
	// addi r9,r1,84
	ctx.r9.s64 = ctx.r1.s64 + 84;
	// li r5,1
	ctx.r5.s64 = 1;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// srawi r10,r10,2
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 2;
	// stw r29,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r29.u32);
	// rlwinm r9,r11,12,20,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0xFFF;
	// clrlwi r10,r10,8
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFFF;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// oris r10,r10,33024
	ctx.r10.u64 = ctx.r10.u64 | 2164260864;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// clrlwi r10,r11,3
	ctx.r10.u64 = ctx.r11.u32 & 0x1FFFFFFF;
	// addi r11,r9,512
	ctx.r11.s64 = ctx.r9.s64 + 512;
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82b1cf20
	ctx.lr = 0x82B2A13C;
	sub_82B1CF20(ctx, base);
	// addi r30,r31,11332
	ctx.r30.s64 = ctx.r31.s64 + 11332;
loc_82B2A140:
	// slw r11,r26,r29
	ctx.r11.u64 = ctx.r29.u8 & 0x20 ? 0 : (ctx.r26.u32 << (ctx.r29.u8 & 0x3F));
	// and. r11,r11,r27
	ctx.r11.u64 = ctx.r11.u64 & ctx.r27.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2a190
	if (ctx.cr0.eq) goto loc_82B2A190;
	// lwz r28,4(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// rlwimi r28,r11,0,0,29
	ctx.r28.u64 = (__builtin_rotateleft32(ctx.r11.u32, 0) & 0xFFFFFFFC) | (ctx.r28.u64 & 0xFFFFFFFF00000003);
	// bl 0x82b0f478
	ctx.lr = 0x82B2A168;
	sub_82B0F478(ctx, base);
loc_82B2A168:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82b0f628
	ctx.lr = 0x82B2A170;
	sub_82B0F628(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2a188
	if (ctx.cr0.eq) goto loc_82B2A188;
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82b2a168
	if (!ctx.cr6.eq) goto loc_82B2A168;
loc_82B2A188:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82b0f4a8
	ctx.lr = 0x82B2A190;
	sub_82B0F4A8(ctx, base);
loc_82B2A190:
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,80
	ctx.r30.s64 = ctx.r30.s64 + 80;
	// cmplwi cr6,r29,6
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 6, ctx.xer);
	// blt cr6,0x82b2a140
	if (ctx.cr6.lt) goto loc_82B2A140;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2A1A8"))) PPC_WEAK_FUNC(sub_82B2A1A8);
PPC_FUNC_IMPL(__imp__sub_82B2A1A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// bl 0x82b29e38
	ctx.lr = 0x82B2A1BC;
	sub_82B29E38(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r9,356(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 356);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// lwz r10,2016(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2016);
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// beq cr6,0x82b2a1f8
	if (ctx.cr6.eq) goto loc_82B2A1F8;
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// stw r11,356(r6)
	PPC_STORE_U32(ctx.r6.u32 + 356, ctx.r11.u32);
	// li r5,2
	ctx.r5.s64 = 2;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// ori r10,r10,25088
	ctx.r10.u64 = ctx.r10.u64 | 25088;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x82b1c8a8
	ctx.lr = 0x82B2A1F8;
	sub_82B1C8A8(ctx, base);
loc_82B2A1F8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2A208"))) PPC_WEAK_FUNC(sub_82B2A208);
PPC_FUNC_IMPL(__imp__sub_82B2A208) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B2A210;
	__savegprlr_28(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// li r28,6
	ctx.r28.s64 = 6;
	// lwz r11,2016(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2016);
	// lwz r29,0(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r31,r29,11336
	ctx.r31.s64 = ctx.r29.s64 + 11336;
loc_82B2A228:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b2a278
	if (ctx.cr6.eq) goto loc_82B2A278;
	// lwz r30,-4(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rlwimi r30,r11,0,30,31
	ctx.r30.u64 = (__builtin_rotateleft32(ctx.r11.u32, 0) & 0x3) | (ctx.r30.u64 & 0xFFFFFFFFFFFFFFFC);
	// bl 0x82b0f478
	ctx.lr = 0x82B2A250;
	sub_82B0F478(ctx, base);
loc_82B2A250:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82b0f628
	ctx.lr = 0x82B2A258;
	sub_82B0F628(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2a270
	if (ctx.cr0.eq) goto loc_82B2A270;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82b2a250
	if (!ctx.cr6.eq) goto loc_82B2A250;
loc_82B2A270:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82b0f4a8
	ctx.lr = 0x82B2A278;
	sub_82B0F4A8(ctx, base);
loc_82B2A278:
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// addi r31,r31,80
	ctx.r31.s64 = ctx.r31.s64 + 80;
	// bne 0x82b2a228
	if (!ctx.cr0.eq) goto loc_82B2A228;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2A290"))) PPC_WEAK_FUNC(sub_82B2A290);
PPC_FUNC_IMPL(__imp__sub_82B2A290) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r4,16384
	ctx.r4.s64 = 1073741824;
loc_82B2A294:
	// lwz r5,0(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r10,r3,4
	ctx.r10.s64 = ctx.r3.s64 + 4;
	// b 0x82b2a33c
	goto loc_82B2A33C;
loc_82B2A2A0:
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r8,r11,29,3,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi. r7,r11,31
	ctx.r7.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// subf r11,r4,r8
	ctx.r11.s64 = ctx.r8.s64 - ctx.r4.s64;
	// beq 0x82b2a2d8
	if (ctx.cr0.eq) goto loc_82B2A2D8;
	// lhz r8,2(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 2);
	// lhz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// subfc r8,r7,r8
	ctx.xer.ca = ctx.r8.u32 >= ctx.r7.u32;
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	// subfe r8,r8,r8
	temp.u8 = (~ctx.r8.u32 + ctx.r8.u32 < ~ctx.r8.u32) | (~ctx.r8.u32 + ctx.r8.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r8.u64 = ~ctx.r8.u64 + ctx.r8.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// addi r6,r8,-1
	ctx.r6.s64 = ctx.r8.s64 + -1;
	// b 0x82b2a30c
	goto loc_82B2A30C;
loc_82B2A2D8:
	// addi r8,r11,48
	ctx.r8.s64 = ctx.r11.s64 + 48;
	// addi r7,r11,16
	ctx.r7.s64 = ctx.r11.s64 + 16;
	// addi r6,r11,52
	ctx.r6.s64 = ctx.r11.s64 + 52;
	// addi r3,r11,20
	ctx.r3.s64 = ctx.r11.s64 + 20;
	// lwbrx r8,0,r8
	ctx.r8.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r8.u32));
	// lwbrx r7,0,r7
	ctx.r7.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r7.u32));
	// lwbrx r6,0,r6
	ctx.r6.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r6.u32));
	// subf r8,r8,r7
	ctx.r8.s64 = ctx.r7.s64 - ctx.r8.s64;
	// lwbrx r7,0,r3
	ctx.r7.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r3.u32));
	// subf r8,r6,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r6.s64;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// subfic r8,r8,0
	ctx.xer.ca = ctx.r8.u32 <= 0;
	ctx.r8.s64 = 0 - ctx.r8.s64;
	// subfe r6,r8,r8
	temp.u8 = (~ctx.r8.u32 + ctx.r8.u32 < ~ctx.r8.u32) | (~ctx.r8.u32 + ctx.r8.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r6.u64 = ~ctx.r8.u64 + ctx.r8.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
loc_82B2A30C:
	// rlwinm r8,r9,12,20,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 12) & 0xFFF;
	// stw r6,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r6.u32);
	// clrlwi r7,r9,3
	ctx.r7.u64 = ctx.r9.u32 & 0x1FFFFFFF;
	// addi r8,r8,512
	ctx.r8.s64 = ctx.r8.s64 + 512;
	// rlwinm r8,r8,0,19,19
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x1000;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// subf r9,r4,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r4.s64;
	// dcbf r0,r9
	// dcbf r0,r11
	// li r9,24
	ctx.r9.s64 = 24;
	// dcbf r9,r11
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
loc_82B2A33C:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// blt cr6,0x82b2a2a0
	if (ctx.cr6.lt) goto loc_82B2A2A0;
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b2a294
	if (!ctx.cr6.eq) goto loc_82B2A294;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2A358"))) PPC_WEAK_FUNC(sub_82B2A358);
PPC_FUNC_IMPL(__imp__sub_82B2A358) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82B2A360;
	__savegprlr_27(ctx, base);
	// lwz r31,4(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r30,r3,8
	ctx.r30.s64 = ctx.r3.s64 + 8;
	// lis r28,16384
	ctx.r28.s64 = 1073741824;
loc_82B2A36C:
	// lwz r29,0(r4)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r6,r4,4
	ctx.r6.s64 = ctx.r4.s64 + 4;
	// b 0x82b2a474
	goto loc_82B2A474;
loc_82B2A378:
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r3,4(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm r11,r10,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// subf r11,r28,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r28.s64;
	// dcbf r0,r11
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82b2a41c
	if (!ctx.cr0.eq) goto loc_82B2A41C;
	// lhz r9,2(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 2);
	// addi r7,r31,-1
	ctx.r7.s64 = ctx.r31.s64 + -1;
	// lhz r10,6(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 6);
	// li r8,0
	ctx.r8.s64 = 0;
	// lhz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// addi r4,r9,1
	ctx.r4.s64 = ctx.r9.s64 + 1;
	// lhz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// addi r27,r10,1
	ctx.r27.s64 = ctx.r10.s64 + 1;
	// rotlwi r9,r5,3
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r5.u32, 3);
	// rotlwi r5,r11,3
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// rlwinm r11,r7,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r10,r4,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// rlwinm r4,r27,3,0,28
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
loc_82B2A3D0:
	// lwz r27,-4(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r27,r10
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82b2a408
	if (!ctx.cr6.lt) goto loc_82B2A408;
	// lwz r27,4(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplw cr6,r27,r9
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82b2a408
	if (!ctx.cr6.gt) goto loc_82B2A408;
	// lwz r27,0(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r27,r4
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r4.u32, ctx.xer);
	// bge cr6,0x82b2a408
	if (!ctx.cr6.lt) goto loc_82B2A408;
	// lwz r27,8(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplw cr6,r27,r5
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r5.u32, ctx.xer);
	// ble cr6,0x82b2a408
	if (!ctx.cr6.gt) goto loc_82B2A408;
	// ori r8,r8,3
	ctx.r8.u64 = ctx.r8.u64 | 3;
loc_82B2A408:
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// addi r11,r11,-16
	ctx.r11.s64 = ctx.r11.s64 + -16;
	// bne cr6,0x82b2a3d0
	if (!ctx.cr6.eq) goto loc_82B2A3D0;
	// b 0x82b2a450
	goto loc_82B2A450;
loc_82B2A41C:
	// addi r10,r11,48
	ctx.r10.s64 = ctx.r11.s64 + 48;
	// addi r9,r11,16
	ctx.r9.s64 = ctx.r11.s64 + 16;
	// addi r8,r11,52
	ctx.r8.s64 = ctx.r11.s64 + 52;
	// addi r11,r11,20
	ctx.r11.s64 = ctx.r11.s64 + 20;
	// lwbrx r10,0,r10
	ctx.r10.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r10.u32));
	// lwbrx r9,0,r9
	ctx.r9.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r9.u32));
	// lwbrx r8,0,r8
	ctx.r8.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r8.u32));
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// lwbrx r10,0,r11
	ctx.r10.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r11.u32));
	// subf r11,r8,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r8.s64;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// subfic r11,r11,0
	ctx.xer.ca = ctx.r11.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r11.s64;
	// subfe r8,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r8.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
loc_82B2A450:
	// rlwinm r11,r3,12,20,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 12) & 0xFFF;
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// clrlwi r10,r3,3
	ctx.r10.u64 = ctx.r3.u32 & 0x1FFFFFFF;
	// addi r11,r11,512
	ctx.r11.s64 = ctx.r11.s64 + 512;
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// subf r11,r28,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r28.s64;
	// dcbf r0,r11
	// addi r6,r6,8
	ctx.r6.s64 = ctx.r6.s64 + 8;
loc_82B2A474:
	// cmplw cr6,r6,r29
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r29.u32, ctx.xer);
	// blt cr6,0x82b2a378
	if (ctx.cr6.lt) goto loc_82B2A378;
	// lwz r4,0(r6)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// cmplw cr6,r4,r11
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b2a36c
	if (!ctx.cr6.eq) goto loc_82B2A36C;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2A490"))) PPC_WEAK_FUNC(sub_82B2A490);
PPC_FUNC_IMPL(__imp__sub_82B2A490) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B2A498;
	__savegprlr_26(ctx, base);
	// lwz r27,4(r3)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r29,r3,8
	ctx.r29.s64 = ctx.r3.s64 + 8;
loc_82B2A4A0:
	// lwz r28,0(r4)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r10,r4,4
	ctx.r10.s64 = ctx.r4.s64 + 4;
	// cmplw cr6,r10,r28
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r28.u32, ctx.xer);
	// bge cr6,0x82b2a570
	if (!ctx.cr6.lt) goto loc_82B2A570;
	// addi r30,r27,-1
	ctx.r30.s64 = ctx.r27.s64 + -1;
	// addi r11,r10,8
	ctx.r11.s64 = ctx.r10.s64 + 8;
loc_82B2A4B8:
	// lhz r8,-2(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + -2);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// lhz r5,-4(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + -4);
	// li r6,0
	ctx.r6.s64 = 0;
	// lhz r9,2(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 2);
	// addi r3,r8,1
	ctx.r3.s64 = ctx.r8.s64 + 1;
	// lhz r31,0(r11)
	ctx.r31.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// rotlwi r4,r5,3
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r5.u32, 3);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r5,r3,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 3) & 0xFFFFFFF8;
	// rotlwi r3,r31,3
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r31.u32, 3);
	// rlwinm r31,r9,3,0,28
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r9,r7,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0xFFFFFFF0;
	// add r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 + ctx.r29.u64;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
loc_82B2A4F8:
	// lwz r26,-4(r9)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + -4);
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r26,r5
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r5.u32, ctx.xer);
	// bge cr6,0x82b2a530
	if (!ctx.cr6.lt) goto loc_82B2A530;
	// lwz r26,4(r9)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r26,r4
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r4.u32, ctx.xer);
	// ble cr6,0x82b2a530
	if (!ctx.cr6.gt) goto loc_82B2A530;
	// lwz r26,0(r9)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r26,r31
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r31.u32, ctx.xer);
	// bge cr6,0x82b2a530
	if (!ctx.cr6.lt) goto loc_82B2A530;
	// lwz r26,8(r9)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmplw cr6,r26,r3
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r3.u32, ctx.xer);
	// ble cr6,0x82b2a530
	if (!ctx.cr6.gt) goto loc_82B2A530;
	// ori r6,r6,3
	ctx.r6.u64 = ctx.r6.u64 | 3;
loc_82B2A530:
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// addi r9,r9,-16
	ctx.r9.s64 = ctx.r9.s64 + -16;
	// bne cr6,0x82b2a4f8
	if (!ctx.cr6.eq) goto loc_82B2A4F8;
	// rlwinm r9,r8,12,20,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 12) & 0xFFF;
	// stw r6,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r6.u32);
	// clrlwi r7,r8,3
	ctx.r7.u64 = ctx.r8.u32 & 0x1FFFFFFF;
	// addi r9,r9,512
	ctx.r9.s64 = ctx.r9.s64 + 512;
	// rlwinm r9,r9,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1000;
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// addis r9,r9,-16384
	ctx.r9.s64 = ctx.r9.s64 + -1073741824;
	// dcbf r0,r9
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// cmplw cr6,r10,r28
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r28.u32, ctx.xer);
	// blt cr6,0x82b2a4b8
	if (ctx.cr6.lt) goto loc_82B2A4B8;
loc_82B2A570:
	// lwz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// cmplw cr6,r4,r11
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b2a4a0
	if (!ctx.cr6.eq) goto loc_82B2A4A0;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2A588"))) PPC_WEAK_FUNC(sub_82B2A588);
PPC_FUNC_IMPL(__imp__sub_82B2A588) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82B2A590;
	__savegprlr_25(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,2016(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2016);
	// lwz r26,0(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// rlwinm. r11,r10,0,0,0
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2a8a0
	if (ctx.cr0.eq) goto loc_82B2A8A0;
	// lis r25,-30976
	ctx.r25.s64 = -2030043136;
loc_82B2A5B8:
	// rlwinm r11,r10,0,0,7
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFF000000;
	// cmplw cr6,r11,r25
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r25.u32, ctx.xer);
	// bgt cr6,0x82b2a748
	if (ctx.cr6.gt) goto loc_82B2A748;
	// beq cr6,0x82b2a718
	if (ctx.cr6.eq) goto loc_82B2A718;
	// lis r9,-32768
	ctx.r9.s64 = -2147483648;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a6e4
	if (ctx.cr6.eq) goto loc_82B2A6E4;
	// lis r9,-32512
	ctx.r9.s64 = -2130706432;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a6bc
	if (ctx.cr6.eq) goto loc_82B2A6BC;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a894
	if (ctx.cr6.eq) goto loc_82B2A894;
	// lis r9,-32000
	ctx.r9.s64 = -2097152000;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a67c
	if (ctx.cr6.eq) goto loc_82B2A67C;
	// lis r9,-31744
	ctx.r9.s64 = -2080374784;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a65c
	if (ctx.cr6.eq) goto loc_82B2A65C;
	// lis r9,-31488
	ctx.r9.s64 = -2063597568;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a630
	if (ctx.cr6.eq) goto loc_82B2A630;
	// lis r9,-31232
	ctx.r9.s64 = -2046820352;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82b2a79c
	if (!ctx.cr6.eq) goto loc_82B2A79C;
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// stw r31,372(r30)
	PPC_STORE_U32(ctx.r30.u32 + 372, ctx.r31.u32);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// oris r11,r11,8192
	ctx.r11.u64 = ctx.r11.u64 | 536870912;
	// b 0x82b2a6ac
	goto loc_82B2A6AC;
loc_82B2A630:
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// stw r31,368(r30)
	PPC_STORE_U32(ctx.r30.u32 + 368, ctx.r31.u32);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// rlwinm r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80000000;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwimi r11,r10,26,0,0
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 26) & 0x80000000) | (ctx.r11.u64 & 0xFFFFFFFF7FFFFFFF);
	// stw r11,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r11.u32);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b2a6b0
	if (ctx.cr0.eq) goto loc_82B2A6B0;
	// lwz r31,364(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 364);
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A65C:
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// rlwinm r11,r11,0,2,0
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r11,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r11.u32);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b2a6b0
	if (ctx.cr0.eq) goto loc_82B2A6B0;
	// lwz r31,368(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 368);
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A67C:
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// lwz r10,52(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// oris r11,r11,16384
	ctx.r11.u64 = ctx.r11.u64 | 1073741824;
	// stw r31,364(r30)
	PPC_STORE_U32(ctx.r30.u32 + 364, ctx.r31.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// stw r11,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r11.u32);
	// ble cr6,0x82b2a6b0
	if (!ctx.cr6.gt) goto loc_82B2A6B0;
	// lwz r10,108(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 108);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b2a6b0
	if (ctx.cr0.eq) goto loc_82B2A6B0;
	// oris r11,r11,32768
	ctx.r11.u64 = ctx.r11.u64 | 2147483648;
loc_82B2A6AC:
	// stw r11,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r11.u32);
loc_82B2A6B0:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b2a1a8
	ctx.lr = 0x82B2A6B8;
	sub_82B2A1A8(ctx, base);
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A6BC:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// clrlwi r11,r10,8
	ctx.r11.u64 = ctx.r10.u32 & 0xFFFFFF;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x82b1cf20
	ctx.lr = 0x82B2A6DC;
	sub_82B1CF20(ctx, base);
	// addi r31,r31,8
	ctx.r31.s64 = ctx.r31.s64 + 8;
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A6E4:
	// addi r4,r31,4
	ctx.r4.s64 = ctx.r31.s64 + 4;
	// addi r3,r30,108
	ctx.r3.s64 = ctx.r30.s64 + 108;
	// li r5,248
	ctx.r5.s64 = 248;
	// bl 0x82e28fd0
	ctx.lr = 0x82B2A6F4;
	sub_82E28FD0(ctx, base);
	// lis r10,32767
	ctx.r10.s64 = 2147418112;
	// li r11,0
	ctx.r11.s64 = 0;
	// ori r10,r10,65535
	ctx.r10.u64 = ctx.r10.u64 | 65535;
	// li r9,-1
	ctx.r9.s64 = -1;
	// addi r31,r31,252
	ctx.r31.s64 = ctx.r31.s64 + 252;
	// stw r11,52(r30)
	PPC_STORE_U32(ctx.r30.u32 + 52, ctx.r11.u32);
	// stw r10,356(r30)
	PPC_STORE_U32(ctx.r30.u32 + 356, ctx.r10.u32);
	// stw r9,360(r30)
	PPC_STORE_U32(ctx.r30.u32 + 360, ctx.r9.u32);
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A718:
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// lwz r10,48(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r9,112(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 112);
	// rlwinm r10,r10,0,3,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFDFFFFFFF;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// stw r11,52(r30)
	PPC_STORE_U32(ctx.r30.u32 + 52, ctx.r11.u32);
	// stw r10,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r10.u32);
	// bge cr6,0x82b2a6b0
	if (!ctx.cr6.lt) goto loc_82B2A6B0;
	// lwz r31,372(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 372);
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A748:
	// lis r9,-30720
	ctx.r9.s64 = -2013265920;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a878
	if (ctx.cr6.eq) goto loc_82B2A878;
	// lis r9,-30464
	ctx.r9.s64 = -1996488704;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a854
	if (ctx.cr6.eq) goto loc_82B2A854;
	// lis r9,-30208
	ctx.r9.s64 = -1979711488;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a7f4
	if (ctx.cr6.eq) goto loc_82B2A7F4;
	// lis r9,-29952
	ctx.r9.s64 = -1962934272;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a7ec
	if (ctx.cr6.eq) goto loc_82B2A7EC;
	// lis r9,-29696
	ctx.r9.s64 = -1946157056;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a8a0
	if (ctx.cr6.eq) goto loc_82B2A8A0;
	// lis r9,-29440
	ctx.r9.s64 = -1929379840;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a8a0
	if (ctx.cr6.eq) goto loc_82B2A8A0;
	// lis r9,-29184
	ctx.r9.s64 = -1912602624;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b2a7b0
	if (ctx.cr6.eq) goto loc_82B2A7B0;
loc_82B2A79C:
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82b2a8a0
	if (ctx.cr6.eq) goto loc_82B2A8A0;
	// addi r31,r10,4
	ctx.r31.s64 = ctx.r10.s64 + 4;
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A7B0:
	// lwz r11,356(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 356);
	// rlwinm. r11,r11,0,0,0
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2a7dc
	if (ctx.cr0.eq) goto loc_82B2A7DC;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// bl 0x82b1cf20
	ctx.lr = 0x82B2A7DC;
	sub_82B1CF20(ctx, base);
loc_82B2A7DC:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addi r31,r31,16
	ctx.r31.s64 = ctx.r31.s64 + 16;
	// stw r11,360(r30)
	PPC_STORE_U32(ctx.r30.u32 + 360, ctx.r11.u32);
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A7EC:
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A7F4:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r29,4(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r28,8(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r27,12(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// bl 0x82b2a008
	ctx.lr = 0x82B2A810;
	sub_82B2A008(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b2a290
	ctx.lr = 0x82B2A818;
	sub_82B2A290(ctx, base);
	// lwz r11,356(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 356);
	// rlwinm. r11,r11,0,0,0
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2a834
	if (ctx.cr0.eq) goto loc_82B2A834;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// addi r3,r30,108
	ctx.r3.s64 = ctx.r30.s64 + 108;
	// bl 0x82b2a358
	ctx.lr = 0x82B2A830;
	sub_82B2A358(ctx, base);
	// b 0x82b2a84c
	goto loc_82B2A84C;
loc_82B2A834:
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bne cr6,0x82b2a84c
	if (!ctx.cr6.eq) goto loc_82B2A84C;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// addi r3,r30,108
	ctx.r3.s64 = ctx.r30.s64 + 108;
	// bl 0x82b2a490
	ctx.lr = 0x82B2A84C;
	sub_82B2A490(ctx, base);
loc_82B2A84C:
	// addi r31,r31,20
	ctx.r31.s64 = ctx.r31.s64 + 20;
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A854:
	// lwz r11,356(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 356);
	// rlwinm. r11,r11,0,0,0
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2a870
	if (ctx.cr0.eq) goto loc_82B2A870;
	// addi r3,r30,108
	ctx.r3.s64 = ctx.r30.s64 + 108;
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82b29fa8
	ctx.lr = 0x82B2A870;
	sub_82B29FA8(ctx, base);
loc_82B2A870:
	// addi r31,r31,12
	ctx.r31.s64 = ctx.r31.s64 + 12;
	// b 0x82b2a894
	goto loc_82B2A894;
loc_82B2A878:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addi r31,r31,8
	ctx.r31.s64 = ctx.r31.s64 + 8;
	// lwz r10,356(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 356);
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2a894
	if (ctx.cr0.eq) goto loc_82B2A894;
	// stw r31,72(r30)
	PPC_STORE_U32(ctx.r30.u32 + 72, ctx.r31.u32);
	// addi r31,r30,84
	ctx.r31.s64 = ctx.r30.s64 + 84;
loc_82B2A894:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// rlwinm. r11,r10,0,0,0
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b2a5b8
	if (!ctx.cr0.eq) goto loc_82B2A5B8;
loc_82B2A8A0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2A8B0"))) PPC_WEAK_FUNC(sub_82B2A8B0);
PPC_FUNC_IMPL(__imp__sub_82B2A8B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82B2A8B8;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// addi r27,r31,68
	ctx.r27.s64 = ctx.r31.s64 + 68;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x831581a4
	ctx.lr = 0x82B2A8D4;
	__imp__KfAcquireSpinLock(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// lwz r29,0(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82b29cd8
	ctx.lr = 0x82B2A8E4;
	sub_82B29CD8(ctx, base);
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b2a9c0
	if (!ctx.cr6.eq) goto loc_82B2A9C0;
	// stw r30,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r30.u32);
	// lis r7,256
	ctx.r7.s64 = 16777216;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// slw r10,r7,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r10.u8 & 0x3F));
	// andc r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// stw r11,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r11.u32);
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// bne 0x82b2a980
	if (!ctx.cr0.eq) goto loc_82B2A980;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,2016(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2016);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,11384
	ctx.r11.s64 = ctx.r11.s64 + 11384;
loc_82B2A930:
	// lwz r8,56(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// slw r9,r7,r10
	ctx.r9.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r10.u8 & 0x3F));
	// and. r8,r8,r9
	ctx.r8.u64 = ctx.r8.u64 & ctx.r9.u64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b2a958
	if (ctx.cr0.eq) goto loc_82B2A958;
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// lwz r8,56(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// andc r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 & ~ctx.r9.u64;
	// stw r9,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r9.u32);
loc_82B2A958:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,80
	ctx.r11.s64 = ctx.r11.s64 + 80;
	// cmplwi cr6,r10,6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 6, ctx.xer);
	// blt cr6,0x82b2a930
	if (ctx.cr6.lt) goto loc_82B2A930;
	// lwz r11,72(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2a980
	if (!ctx.cr6.eq) goto loc_82B2A980;
	// lwz r11,64(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r11.u32);
loc_82B2A980:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x83158194
	ctx.lr = 0x82B2A988;
	__imp__KfReleaseSpinLock(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b2a208
	ctx.lr = 0x82B2A990;
	sub_82B2A208(ctx, base);
	// lwz r11,104(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b2a9a4
	if (ctx.cr6.eq) goto loc_82B2A9A4;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x831582f4
	ctx.lr = 0x82B2A9A4;
	__imp__KeUnlockL2(ctx, base);
loc_82B2A9A4:
	// lwsync 
	// li r11,0
	ctx.r11.s64 = 0;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// bl 0x82b29cd8
	ctx.lr = 0x82B2A9B8;
	sub_82B29CD8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b2a9cc
	goto loc_82B2A9CC;
loc_82B2A9C0:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x83158194
	ctx.lr = 0x82B2A9C8;
	__imp__KfReleaseSpinLock(ctx, base);
	// addi r3,r29,4
	ctx.r3.s64 = ctx.r29.s64 + 4;
loc_82B2A9CC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2A9D8"))) PPC_WEAK_FUNC(sub_82B2A9D8);
PPC_FUNC_IMPL(__imp__sub_82B2A9D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82B2A9E0;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lis r3,-17477
	ctx.r3.s64 = -1145372672;
	// ori r3,r3,48059
	ctx.r3.u64 = ctx.r3.u64 | 48059;
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82b29cd8
	ctx.lr = 0x82B2A9F8;
	sub_82B29CD8(ctx, base);
	// lis r29,256
	ctx.r29.s64 = 16777216;
	// b 0x82b2aa18
	goto loc_82B2AA18;
loc_82B2AA00:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// slw r11,r29,r11
	ctx.r11.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r11.u8 & 0x3F));
	// and. r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ctx.r10.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b2aa24
	if (!ctx.cr0.eq) goto loc_82B2AA24;
	// db16cyc 
loc_82B2AA18:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b2aa00
	if (!ctx.cr6.eq) goto loc_82B2AA00;
loc_82B2AA24:
	// li r28,0
	ctx.r28.s64 = 0;
	// li r27,1
	ctx.r27.s64 = 1;
loc_82B2AA2C:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r11,r28
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r28.s32, ctx.xer);
	// bne cr6,0x82b2aa50
	if (!ctx.cr6.eq) goto loc_82B2AA50;
	// stwcx. r27,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r27.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b2aa2c
	if (!ctx.cr0.eq) goto loc_82B2AA2C;
	// b 0x82b2aa58
	goto loc_82B2AA58;
loc_82B2AA50:
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_82B2AA58:
	// mr r11,r11
	ctx.r11.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b2aa2c
	if (!ctx.cr6.eq) goto loc_82B2AA2C;
	// lwsync 
	// lwz r11,60(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// lwz r10,56(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// lis r3,-17477
	ctx.r3.s64 = -1145372672;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82b2aa94
	if (!ctx.cr6.eq) goto loc_82B2AA94;
	// ori r3,r3,48060
	ctx.r3.u64 = ctx.r3.u64 | 48060;
	// bl 0x82b29cd8
	ctx.lr = 0x82B2AA84;
	sub_82B29CD8(ctx, base);
	// lwsync 
	// stw r28,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r28.u32);
loc_82B2AA8C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
loc_82B2AA94:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// ori r3,r3,48061
	ctx.r3.u64 = ctx.r3.u64 | 48061;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r11.u32);
	// lwz r11,60(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// clrlwi r10,r11,30
	ctx.r10.u64 = ctx.r11.u32 & 0x3;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// stw r11,60(r30)
	PPC_STORE_U32(ctx.r30.u32 + 60, ctx.r11.u32);
	// bl 0x82b29cd8
	ctx.lr = 0x82B2AAC4;
	sub_82B29CD8(ctx, base);
	// lwz r3,60(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// bl 0x82b29cd8
	ctx.lr = 0x82B2AACC;
	sub_82B29CD8(ctx, base);
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x82b29cd8
	ctx.lr = 0x82B2AAD4;
	sub_82B29CD8(ctx, base);
	// lwz r11,56(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// lwz r10,60(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// clrlwi r3,r11,30
	ctx.r3.u64 = ctx.r11.u32 & 0x3;
	// bl 0x82b29cd8
	ctx.lr = 0x82B2AAE8;
	sub_82B29CD8(ctx, base);
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// ble cr6,0x82b2aafc
	if (!ctx.cr6.gt) goto loc_82B2AAFC;
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// b 0x82b2ab28
	goto loc_82B2AB28;
loc_82B2AAFC:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r5,72(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// stw r28,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r28.u32);
	// cmplwi r5,0
	ctx.cr0.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// slw r11,r29,r11
	ctx.r11.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r11.u8 & 0x3F));
	// stw r11,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r11.u32);
	// beq 0x82b2ab20
	if (ctx.cr0.eq) goto loc_82B2AB20;
	// stw r28,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r28.u32);
	// b 0x82b2ab28
	goto loc_82B2AB28;
loc_82B2AB20:
	// addi r5,r4,4
	ctx.r5.s64 = ctx.r4.s64 + 4;
	// stw r4,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r4.u32);
loc_82B2AB28:
	// lis r29,-16384
	ctx.r29.s64 = -1073741824;
loc_82B2AB2C:
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmplw cr6,r6,r11
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82b2ab54
	if (!ctx.cr6.lt) goto loc_82B2AB54;
	// addi r11,r6,1
	ctx.r11.s64 = ctx.r6.s64 + 1;
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r5,32(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// stw r11,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r11.u32);
	// lwsync 
	// b 0x82b2aba4
	goto loc_82B2ABA4;
loc_82B2AB54:
	// lwz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82b2abc0
	if (!ctx.cr0.eq) goto loc_82B2ABC0;
	// lwz r9,360(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 360);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// lwz r8,356(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 356);
	// rlwinm r10,r11,16,17,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 16) & 0x7FFF;
	// and. r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 & ctx.r8.u64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne 0x82b2ab80
	if (!ctx.cr0.eq) goto loc_82B2AB80;
	// add r5,r10,r5
	ctx.r5.u64 = ctx.r10.u64 + ctx.r5.u64;
	// b 0x82b2ab2c
	goto loc_82B2AB2C;
loc_82B2AB80:
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// lwz r4,20(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// add r10,r10,r5
	ctx.r10.u64 = ctx.r10.u64 + ctx.r5.u64;
	// stw r27,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r27.u32);
	// stw r5,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r5.u32);
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// stw r10,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r10.u32);
	// lwsync 
	// li r6,0
	ctx.r6.s64 = 0;
loc_82B2ABA4:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r28,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r28.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2ABB8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// b 0x82b2ab2c
	goto loc_82B2AB2C;
loc_82B2ABC0:
	// lis r10,-29440
	ctx.r10.s64 = -1929379840;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82b2abdc
	if (!ctx.cr6.eq) goto loc_82B2ABDC;
	// lwz r11,4(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// addi r5,r5,8
	ctx.r5.s64 = ctx.r5.s64 + 8;
	// stw r11,360(r31)
	PPC_STORE_U32(ctx.r31.u32 + 360, ctx.r11.u32);
	// b 0x82b2ab2c
	goto loc_82B2AB2C;
loc_82B2ABDC:
	// lis r10,-29696
	ctx.r10.s64 = -1946157056;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82b2ac00
	if (!ctx.cr6.eq) goto loc_82B2AC00;
	// lwz r11,4(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// lwz r11,8(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// addi r5,r5,12
	ctx.r5.s64 = ctx.r5.s64 + 12;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// b 0x82b2ab2c
	goto loc_82B2AB2C;
loc_82B2AC00:
	// rlwinm r10,r11,0,0,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0000000;
	// cmplw cr6,r10,r29
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r29.u32, ctx.xer);
	// bne cr6,0x82b2ac34
	if (!ctx.cr6.eq) goto loc_82B2AC34;
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// bne cr6,0x82b2ac2c
	if (!ctx.cr6.eq) goto loc_82B2AC2C;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b2a8b0
	ctx.lr = 0x82B2AC20;
	sub_82B2A8B0(ctx, base);
	// mr. r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// bne 0x82b2ab2c
	if (!ctx.cr0.eq) goto loc_82B2AB2C;
	// b 0x82b2aa8c
	goto loc_82B2AA8C;
loc_82B2AC2C:
	// addi r5,r11,4
	ctx.r5.s64 = ctx.r11.s64 + 4;
	// b 0x82b2ab2c
	goto loc_82B2AB2C;
loc_82B2AC34:
	// lis r3,-12288
	ctx.r3.s64 = -805306368;
	// bl 0x82b29cd8
	ctx.lr = 0x82B2AC3C;
	sub_82B29CD8(ctx, base);
	// lwz r11,100(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// stw r27,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r27.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r11.u32);
	// beq cr6,0x82b2acbc
	if (ctx.cr6.eq) goto loc_82B2ACBC;
	// stw r5,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r5.u32);
	// lwsync 
	// stw r28,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r28.u32);
	// b 0x82b2ac6c
	goto loc_82B2AC6C;
loc_82B2AC68:
	// db16cyc 
loc_82B2AC6C:
	// lwz r11,96(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b2ac68
	if (!ctx.cr6.eq) goto loc_82B2AC68;
loc_82B2AC78:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r11,r28
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r28.s32, ctx.xer);
	// bne cr6,0x82b2ac9c
	if (!ctx.cr6.eq) goto loc_82B2AC9C;
	// stwcx. r27,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r27.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b2ac78
	if (!ctx.cr0.eq) goto loc_82B2AC78;
	// b 0x82b2aca4
	goto loc_82B2ACA4;
loc_82B2AC9C:
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_82B2ACA4:
	// mr r11,r11
	ctx.r11.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b2ac78
	if (!ctx.cr6.eq) goto loc_82B2AC78;
	// lwsync 
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// b 0x82b2acd0
	goto loc_82B2ACD0;
loc_82B2ACBC:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// bl 0x82b2a588
	ctx.lr = 0x82B2ACC8;
	sub_82B2A588(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// stw r28,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r28.u32);
loc_82B2ACD0:
	// lwz r11,100(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	// lis r3,-12288
	ctx.r3.s64 = -805306368;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// ori r3,r3,1
	ctx.r3.u64 = ctx.r3.u64 | 1;
	// stw r11,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r11.u32);
	// bl 0x82b29cd8
	ctx.lr = 0x82B2ACE8;
	sub_82B29CD8(ctx, base);
	// b 0x82b2ab2c
	goto loc_82B2AB2C;
}

__attribute__((alias("__imp__sub_82B2ACF0"))) PPC_WEAK_FUNC(sub_82B2ACF0);
PPC_FUNC_IMPL(__imp__sub_82B2ACF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82B2ACF8;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// lwz r4,4(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// bl 0x82b07950
	ctx.lr = 0x82B2AD0C;
	sub_82B07950(ctx, base);
	// lis r24,-32256
	ctx.r24.s64 = -2113929216;
loc_82B2AD10:
	// lis r11,-5
	ctx.r11.s64 = -327680;
	// lwz r25,0(r26)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// ori r11,r11,27680
	ctx.r11.u64 = ctx.r11.u64 | 27680;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// lwz r10,376(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 376);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b2ad38
	if (ctx.cr6.eq) goto loc_82B2AD38;
	// li r27,0
	ctx.r27.s64 = 0;
loc_82B2AD38:
	// lwz r11,60(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 60);
	// lwz r10,56(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82b2ae3c
	if (!ctx.cr6.eq) goto loc_82B2AE3C;
	// addi r31,r25,44
	ctx.r31.s64 = ctx.r25.s64 + 44;
loc_82B2AD4C:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b2ad4c
	if (!ctx.cr0.eq) goto loc_82B2AD4C;
	// addi r28,r26,32
	ctx.r28.s64 = ctx.r26.s64 + 32;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x83158314
	ctx.lr = 0x82B2AD84;
	__imp__KeWaitForSingleObject(ctx, base);
loc_82B2AD84:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b2ad84
	if (!ctx.cr0.eq) goto loc_82B2AD84;
	// b 0x82b2ae34
	goto loc_82B2AE34;
loc_82B2ADA4:
	// lwz r11,2016(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2016);
	// lwz r30,0(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r29,r30,14944
	ctx.r29.s64 = ctx.r30.s64 + 14944;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x83157d14
	ctx.lr = 0x82B2ADB8;
	__imp__RtlEnterCriticalSection(ctx, base);
	// lbz r11,10942(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 10942);
	// rlwinm. r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2addc
	if (ctx.cr0.eq) goto loc_82B2ADDC;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b23570
	ctx.lr = 0x82B2ADCC;
	sub_82B23570(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r30,14844
	ctx.r4.s64 = ctx.r30.s64 + 14844;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b23578
	ctx.lr = 0x82B2ADDC;
	sub_82B23578(ctx, base);
loc_82B2ADDC:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x83157d24
	ctx.lr = 0x82B2ADE4;
	__imp__RtlLeaveCriticalSection(ctx, base);
loc_82B2ADE4:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b2ade4
	if (!ctx.cr0.eq) goto loc_82B2ADE4;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x83158314
	ctx.lr = 0x82B2AE18;
	__imp__KeWaitForSingleObject(ctx, base);
loc_82B2AE18:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b2ae18
	if (!ctx.cr0.eq) goto loc_82B2AE18;
loc_82B2AE34:
	// cmplwi cr6,r3,258
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 258, ctx.xer);
	// beq cr6,0x82b2ada4
	if (ctx.cr6.eq) goto loc_82B2ADA4;
loc_82B2AE3C:
	// addi r3,r26,32
	ctx.r3.s64 = ctx.r26.s64 + 32;
	// bl 0x83158304
	ctx.lr = 0x82B2AE44;
	__imp__KeResetEvent(ctx, base);
	// lwz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b2ae5c
	if (ctx.cr6.eq) goto loc_82B2AE5C;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82b2a9d8
	ctx.lr = 0x82B2AE58;
	sub_82B2A9D8(ctx, base);
	// b 0x82b2ad10
	goto loc_82B2AD10;
loc_82B2AE5C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2AE68"))) PPC_WEAK_FUNC(sub_82B2AE68);
PPC_FUNC_IMPL(__imp__sub_82B2AE68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lbz r10,268(r13)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r13.u32 + 268);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mulli r10,r10,80
	ctx.r10.s64 = ctx.r10.s64 * 80;
	// lwz r11,2016(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2016);
	// lis r3,-21846
	ctx.r3.s64 = -1431699456;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// ori r3,r3,43690
	ctx.r3.u64 = ctx.r3.u64 | 43690;
	// addi r31,r11,11324
	ctx.r31.s64 = ctx.r11.s64 + 11324;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// clrlwi r11,r11,30
	ctx.r11.u64 = ctx.r11.u32 & 0x3;
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r5,r11,r31
	PPC_STORE_U32(ctx.r11.u32 + ctx.r31.u32, ctx.r5.u32);
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r11.u32);
	// bl 0x82b29cd8
	ctx.lr = 0x82B2AEC4;
	sub_82B29CD8(ctx, base);
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// bl 0x82b29cd8
	ctx.lr = 0x82B2AECC;
	sub_82B29CD8(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r3,r31,32
	ctx.r3.s64 = ctx.r31.s64 + 32;
	// bl 0x83158324
	ctx.lr = 0x82B2AEDC;
	__imp__KeSetEvent(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2AEF0"))) PPC_WEAK_FUNC(sub_82B2AEF0);
PPC_FUNC_IMPL(__imp__sub_82B2AEF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B2AF0C;
	sub_82B1DAE8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1c6e8
	ctx.lr = 0x82B2AF14;
	sub_82B1C6E8(ctx, base);
	// lwz r11,13244(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13244);
	// lwz r8,13240(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13240);
	// addi r30,r31,13368
	ctx.r30.s64 = ctx.r31.s64 + 13368;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r31,13388
	ctx.r10.s64 = ctx.r31.s64 + 13388;
	// li r9,5
	ctx.r9.s64 = 5;
	// stw r8,13232(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13232, ctx.r8.u32);
	// stw r11,13236(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13236, ctx.r11.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82B2AF3C:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82b2af3c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B2AF3C;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b1d940
	ctx.lr = 0x82B2AF5C;
	sub_82B1D940(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13248
	ctx.r3.s64 = ctx.r31.s64 + 13248;
	// bl 0x82b1d940
	ctx.lr = 0x82B2AF68;
	sub_82B1D940(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13348
	ctx.r3.s64 = ctx.r31.s64 + 13348;
	// bl 0x82b1d940
	ctx.lr = 0x82B2AF74;
	sub_82B1D940(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13268
	ctx.r3.s64 = ctx.r31.s64 + 13268;
	// bl 0x82b1d940
	ctx.lr = 0x82B2AF80;
	sub_82B1D940(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13288
	ctx.r3.s64 = ctx.r31.s64 + 13288;
	// bl 0x82b1d940
	ctx.lr = 0x82B2AF8C;
	sub_82B1D940(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13308
	ctx.r3.s64 = ctx.r31.s64 + 13308;
	// bl 0x82b1d940
	ctx.lr = 0x82B2AF98;
	sub_82B1D940(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r31,13328
	ctx.r3.s64 = ctx.r31.s64 + 13328;
	// bl 0x82b1d940
	ctx.lr = 0x82B2AFA4;
	sub_82B1D940(ctx, base);
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addi r10,r3,252
	ctx.r10.s64 = ctx.r3.s64 + 252;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b2afc0
	if (!ctx.cr6.gt) goto loc_82B2AFC0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b1d6e8
	ctx.lr = 0x82B2AFC0;
	sub_82B1D6E8(ctx, base);
loc_82B2AFC0:
	// lis r11,-32768
	ctx.r11.s64 = -2147483648;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// lwz r11,13188(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13188);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// lwz r11,12748(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12748);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// lwz r11,12748(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12748);
	// lwz r8,12992(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12992);
	// lwz r7,12996(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12996);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82b2b040
	if (!ctx.cr6.gt) goto loc_82B2B040;
	// addi r10,r3,16
	ctx.r10.s64 = ctx.r3.s64 + 16;
	// addi r11,r31,12756
	ctx.r11.s64 = ctx.r31.s64 + 12756;
loc_82B2AFF8:
	// lwz r6,-4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// subf r6,r8,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r8.s64;
	// stw r6,-4(r10)
	PPC_STORE_U32(ctx.r10.u32 + -4, ctx.r6.u32);
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// stw r6,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r6.u32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// subf r6,r8,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r8.s64;
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// lwz r6,8(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// subf r6,r7,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r7.s64;
	// stw r6,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r6.u32);
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lwz r6,12748(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12748);
	// cmplw cr6,r9,r6
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82b2aff8
	if (ctx.cr6.lt) goto loc_82B2AFF8;
loc_82B2B040:
	// addi r11,r3,252
	ctx.r11.s64 = ctx.r3.s64 + 252;
	// stw r11,13376(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13376, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2B060"))) PPC_WEAK_FUNC(sub_82B2B060);
PPC_FUNC_IMPL(__imp__sub_82B2B060) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B2B068;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lbz r11,10941(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b2b08c
	if (!ctx.cr0.eq) goto loc_82B2B08C;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// bl 0x82b1d108
	ctx.lr = 0x82B2B08C;
	sub_82B1D108(ctx, base);
loc_82B2B08C:
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,100
	ctx.r4.s64 = 100;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1ce38
	ctx.lr = 0x82B2B09C;
	sub_82B1CE38(ctx, base);
	// li r26,0
	ctx.r26.s64 = 0;
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq 0x82b2b0f4
	if (ctx.cr0.eq) goto loc_82B2B0F4;
	// lwz r11,13368(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13368);
	// addi r4,r29,-4
	ctx.r4.s64 = ctx.r29.s64 + -4;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b2b0c0
	if (!ctx.cr0.eq) goto loc_82B2B0C0;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// b 0x82b2b0d8
	goto loc_82B2B0D8;
loc_82B2B0C0:
	// rlwinm r9,r11,12,20,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0xFFF;
	// clrlwi r10,r11,3
	ctx.r10.u64 = ctx.r11.u32 & 0x1FFFFFFF;
	// addi r11,r9,512
	ctx.r11.s64 = ctx.r9.s64 + 512;
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addis r7,r11,-16384
	ctx.r7.s64 = ctx.r11.s64 + -1073741824;
loc_82B2B0D8:
	// lis r11,-32077
	ctx.r11.s64 = -2102198272;
	// ori r5,r30,1
	ctx.r5.u64 = ctx.r30.u64 | 1;
	// addi r6,r11,-20888
	ctx.r6.s64 = ctx.r11.s64 + -20888;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1d550
	ctx.lr = 0x82B2B0EC;
	sub_82B1D550(ctx, base);
	// addi r28,r3,4
	ctx.r28.s64 = ctx.r3.s64 + 4;
	// b 0x82b2b0f8
	goto loc_82B2B0F8;
loc_82B2B0F4:
	// lwz r28,84(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82B2B0F8:
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,32
	ctx.r4.s64 = 32;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1ce38
	ctx.lr = 0x82B2B108;
	sub_82B1CE38(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bne 0x82b2b118
	if (!ctx.cr0.eq) goto loc_82B2B118;
	// lwz r30,84(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82B2B118:
	// lbz r11,10941(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// stw r26,13232(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13232, ctx.r26.u32);
	// stw r26,13236(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13236, ctx.r26.u32);
	// rlwinm. r27,r11,27,31,31
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// beq 0x82b2b144
	if (ctx.cr0.eq) goto loc_82B2B144;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1c720
	ctx.lr = 0x82B2B134;
	sub_82B1C720(ctx, base);
	// lbz r11,10941(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// andi. r11,r11,223
	ctx.r11.u64 = ctx.r11.u64 & 223;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stb r11,10941(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10941, ctx.r11.u8);
	// b 0x82b2b1ec
	goto loc_82B2B1EC;
loc_82B2B144:
	// addi r3,r31,13368
	ctx.r3.s64 = ctx.r31.s64 + 13368;
	// bl 0x82b1cb18
	ctx.lr = 0x82B2B14C;
	sub_82B1CB18(ctx, base);
	// addi r3,r31,13248
	ctx.r3.s64 = ctx.r31.s64 + 13248;
	// bl 0x82b1cb18
	ctx.lr = 0x82B2B154;
	sub_82B1CB18(ctx, base);
	// addi r3,r31,13348
	ctx.r3.s64 = ctx.r31.s64 + 13348;
	// bl 0x82b1cb18
	ctx.lr = 0x82B2B15C;
	sub_82B1CB18(ctx, base);
	// addi r3,r31,13268
	ctx.r3.s64 = ctx.r31.s64 + 13268;
	// bl 0x82b1cb18
	ctx.lr = 0x82B2B164;
	sub_82B1CB18(ctx, base);
	// addi r3,r31,13288
	ctx.r3.s64 = ctx.r31.s64 + 13288;
	// bl 0x82b1cb18
	ctx.lr = 0x82B2B16C;
	sub_82B1CB18(ctx, base);
	// addi r3,r31,13308
	ctx.r3.s64 = ctx.r31.s64 + 13308;
	// bl 0x82b1cb18
	ctx.lr = 0x82B2B174;
	sub_82B1CB18(ctx, base);
	// addi r3,r31,13328
	ctx.r3.s64 = ctx.r31.s64 + 13328;
	// bl 0x82b1cb18
	ctx.lr = 0x82B2B17C;
	sub_82B1CB18(ctx, base);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82b2b1a4
	if (ctx.cr6.eq) goto loc_82B2B1A4;
	// addi r8,r31,13388
	ctx.r8.s64 = ctx.r31.s64 + 13388;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1d3b0
	ctx.lr = 0x82B2B1A0;
	sub_82B1D3B0(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82B2B1A4:
	// lwz r11,21532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21532);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2b1bc
	if (!ctx.cr6.eq) goto loc_82B2B1BC;
	// lbz r11,10941(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10941);
	// rlwinm. r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b2b1ec
	if (!ctx.cr0.eq) goto loc_82B2B1EC;
loc_82B2B1BC:
	// rlwinm r11,r29,12,20,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 12) & 0xFFF;
	// subf r9,r29,r28
	ctx.r9.s64 = ctx.r28.s64 - ctx.r29.s64;
	// addi r11,r11,512
	ctx.r11.s64 = ctx.r11.s64 + 512;
	// clrlwi r10,r29,3
	ctx.r10.u64 = ctx.r29.u32 & 0x1FFFFFFF;
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// addi r8,r31,13388
	ctx.r8.s64 = ctx.r31.s64 + 13388;
	// li r7,1
	ctx.r7.s64 = 1;
	// srawi r6,r9,2
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r6.s64 = ctx.r9.s32 >> 2;
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1d3b0
	ctx.lr = 0x82B2B1EC;
	sub_82B1D3B0(ctx, base);
loc_82B2B1EC:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2B1F8"))) PPC_WEAK_FUNC(sub_82B2B1F8);
PPC_FUNC_IMPL(__imp__sub_82B2B1F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82B2B200;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,22300(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 22300);
	// rlwinm. r11,r11,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x100;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b2b368
	if (!ctx.cr0.eq) goto loc_82B2B368;
	// lis r4,-19072
	ctx.r4.s64 = -1249902592;
	// li r3,200
	ctx.r3.s64 = 200;
	// bl 0x82547910
	ctx.lr = 0x82B2B220;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,11804(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11804, ctx.r3.u32);
	// bne 0x82b2b234
	if (!ctx.cr0.eq) goto loc_82B2B234;
loc_82B2B22C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b2b36c
	goto loc_82B2B36C;
loc_82B2B234:
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r11,22300(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 22300);
	// lis r24,256
	ctx.r24.s64 = 16777216;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// stw r27,11012(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11012, ctx.r27.u32);
loc_82B2B24C:
	// slw r8,r24,r10
	ctx.r8.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r24.u32 << (ctx.r10.u8 & 0x3F));
	// and. r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b2b25c
	if (ctx.cr0.eq) goto loc_82B2B25C;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
loc_82B2B25C:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r10,6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 6, ctx.xer);
	// blt cr6,0x82b2b24c
	if (ctx.cr6.lt) goto loc_82B2B24C;
	// lwz r10,14896(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14896);
	// lis r7,-16384
	ctx.r7.s64 = -1073741824;
	// lwz r8,14900(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 14900);
	// rlwinm. r11,r11,0,5,5
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// li r26,-1
	ctx.r26.s64 = -1;
	// stw r9,10984(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10984, ctx.r9.u32);
	// stw r27,10988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10988, ctx.r27.u32);
	// stw r10,10948(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10948, ctx.r10.u32);
	// stw r7,11028(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11028, ctx.r7.u32);
	// stw r8,10956(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10956, ctx.r8.u32);
	// beq 0x82b2b29c
	if (ctx.cr0.eq) goto loc_82B2B29C;
	// li r26,2
	ctx.r26.s64 = 2;
	// stw r26,11320(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11320, ctx.r26.u32);
loc_82B2B29C:
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// lis r28,32512
	ctx.r28.s64 = 2130706432;
	// addi r31,r30,11364
	ctx.r31.s64 = ctx.r30.s64 + 11364;
	// lis r25,-32256
	ctx.r25.s64 = -2113929216;
loc_82B2B2AC:
	// lwz r11,22300(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 22300);
	// slw r10,r24,r29
	ctx.r10.u64 = ctx.r29.u8 & 0x20 ? 0 : (ctx.r24.u32 << (ctx.r29.u8 & 0x3F));
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2b34c
	if (ctx.cr0.eq) goto loc_82B2B34C;
	// cmpwi cr6,r26,0
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// bge cr6,0x82b2b2cc
	if (!ctx.cr6.lt) goto loc_82B2B2CC;
	// mr r26,r29
	ctx.r26.u64 = ctx.r29.u64;
	// stw r29,11320(r30)
	PPC_STORE_U32(ctx.r30.u32 + 11320, ctx.r29.u32);
loc_82B2B2CC:
	// addi r11,r30,10944
	ctx.r11.s64 = ctx.r30.s64 + 10944;
	// stw r29,-36(r31)
	PPC_STORE_U32(ctx.r31.u32 + -36, ctx.r29.u32);
	// addis r10,r28,16640
	ctx.r10.s64 = ctx.r28.s64 + 1090519040;
	// stw r28,-12(r31)
	PPC_STORE_U32(ctx.r31.u32 + -12, ctx.r28.u32);
	// addi r6,r31,-40
	ctx.r6.s64 = ctx.r31.s64 + -40;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// addi r8,r31,12
	ctx.r8.s64 = ctx.r31.s64 + 12;
	// stw r11,-40(r31)
	PPC_STORE_U32(ctx.r31.u32 + -40, ctx.r11.u32);
	// lis r11,-32077
	ctx.r11.s64 = -2102198272;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r11,-21264
	ctx.r5.s64 = ctx.r11.s64 + -21264;
	// stw r10,-16(r31)
	PPC_STORE_U32(ctx.r31.u32 + -16, ctx.r10.u32);
	// lis r4,1
	ctx.r4.s64 = 65536;
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r27,-8(r31)
	PPC_STORE_U8(ctx.r31.u32 + -8, ctx.r27.u8);
	// stw r27,-4(r31)
	PPC_STORE_U32(ctx.r31.u32 + -4, ctx.r27.u32);
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// bl 0x82b07ad8
	ctx.lr = 0x82B2B318;
	sub_82B07AD8(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// beq 0x82b2b22c
	if (ctx.cr0.eq) goto loc_82B2B22C;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,2344(r25)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r25.u32 + 2344);
	// bl 0x83157ea4
	ctx.lr = 0x82B2B330;
	__imp__ObReferenceObjectByHandle(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b2b34c
	if (ctx.cr0.lt) goto loc_82B2B34C;
	// li r4,17
	ctx.r4.s64 = 17;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x83157e94
	ctx.lr = 0x82B2B344;
	__imp__KeSetBasePriorityThread(ctx, base);
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x83157e84
	ctx.lr = 0x82B2B34C;
	__imp__ObDereferenceObject(ctx, base);
loc_82B2B34C:
	// lis r11,32512
	ctx.r11.s64 = 2130706432;
	// addi r28,r28,128
	ctx.r28.s64 = ctx.r28.s64 + 128;
	// ori r11,r11,768
	ctx.r11.u64 = ctx.r11.u64 | 768;
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r31,r31,80
	ctx.r31.s64 = ctx.r31.s64 + 80;
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b2b2ac
	if (ctx.cr6.lt) goto loc_82B2B2AC;
loc_82B2B368:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82B2B36C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2B378"))) PPC_WEAK_FUNC(sub_82B2B378);
PPC_FUNC_IMPL(__imp__sub_82B2B378) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B2B380;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// lis r4,-20096
	ctx.r4.s64 = -1317011456;
	// lwz r3,11804(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11804);
	// stw r28,10948(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10948, ctx.r28.u32);
	// bl 0x82547938
	ctx.lr = 0x82B2B39C;
	sub_82547938(ctx, base);
	// addi r30,r31,11356
	ctx.r30.s64 = ctx.r31.s64 + 11356;
	// li r29,6
	ctx.r29.s64 = 6;
loc_82B2B3A4:
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b2b3c0
	if (ctx.cr6.eq) goto loc_82B2B3C0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x83158324
	ctx.lr = 0x82B2B3C0;
	__imp__KeSetEvent(ctx, base);
loc_82B2B3C0:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r30,r30,80
	ctx.r30.s64 = ctx.r30.s64 + 80;
	// bne 0x82b2b3a4
	if (!ctx.cr0.eq) goto loc_82B2B3A4;
	// addi r30,r31,11372
	ctx.r30.s64 = ctx.r31.s64 + 11372;
	// li r29,6
	ctx.r29.s64 = 6;
loc_82B2B3D4:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b2b3f0
	if (ctx.cr0.eq) goto loc_82B2B3F0;
	// li r4,-1
	ctx.r4.s64 = -1;
	// bl 0x82b07700
	ctx.lr = 0x82B2B3E8;
	sub_82B07700(ctx, base);
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82b07040
	ctx.lr = 0x82B2B3F0;
	sub_82B07040(ctx, base);
loc_82B2B3F0:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r30,r30,80
	ctx.r30.s64 = ctx.r30.s64 + 80;
	// bne 0x82b2b3d4
	if (!ctx.cr0.eq) goto loc_82B2B3D4;
	// stw r28,10984(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10984, ctx.r28.u32);
	// stw r28,10988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10988, ctx.r28.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2B410"))) PPC_WEAK_FUNC(sub_82B2B410);
PPC_FUNC_IMPL(__imp__sub_82B2B410) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82B2B418;
	__savegprlr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b2b440
	if (!ctx.cr6.gt) goto loc_82B2B440;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B2B440;
	sub_82B1DAE8(ctx, base);
loc_82B2B440:
	// li r11,8712
	ctx.r11.s64 = 8712;
	// li r10,6
	ctx.r10.s64 = 6;
	// lis r9,1
	ctx.r9.s64 = 65536;
	// lis r8,2
	ctx.r8.s64 = 131072;
	// ori r9,r9,8192
	ctx.r9.u64 = ctx.r9.u64 | 8192;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// li r7,0
	ctx.r7.s64 = 0;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// lwz r10,148(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 148);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// bgt cr6,0x82b2b4a8
	if (ctx.cr6.gt) goto loc_82B2B4A8;
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// rlwinm r9,r28,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 5) & 0xFFFFFFE0;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// li r9,8997
	ctx.r9.s64 = 8997;
	// rlwinm r8,r10,12,20,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFF;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// clrlwi r9,r10,3
	ctx.r9.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// addi r10,r8,512
	ctx.r10.s64 = ctx.r8.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// b 0x82b2b56c
	goto loc_82B2B56C;
loc_82B2B4A8:
	// lis r9,-16384
	ctx.r9.s64 = -1073741824;
	// li r8,0
	ctx.r8.s64 = 0;
	// ori r25,r9,24832
	ctx.r25.u64 = ctx.r9.u64 | 24832;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// lis r9,-16384
	ctx.r9.s64 = -1073741824;
	// ori r30,r9,24576
	ctx.r30.u64 = ctx.r9.u64 | 24576;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// beq cr6,0x82b2b558
	if (ctx.cr6.eq) goto loc_82B2B558;
	// rlwinm r27,r28,5,0,26
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 5) & 0xFFFFFFE0;
	// li r28,0
	ctx.r28.s64 = 0;
	// addi r29,r29,28
	ctx.r29.s64 = ctx.r29.s64 + 28;
	// mr r26,r10
	ctx.r26.u64 = ctx.r10.u64;
loc_82B2B4E0:
	// li r8,3
	ctx.r8.s64 = 3;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// lis r7,-16383
	ctx.r7.s64 = -1073676288;
	// add r10,r27,r10
	ctx.r10.u64 = ctx.r27.u64 + ctx.r10.u64;
	// ori r7,r7,11521
	ctx.r7.u64 = ctx.r7.u64 | 11521;
	// lis r6,4
	ctx.r6.s64 = 262144;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// clrlwi r9,r10,3
	ctx.r9.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// ori r6,r6,805
	ctx.r6.u64 = ctx.r6.u64 | 805;
	// slw r5,r8,r28
	ctx.r5.u64 = ctx.r28.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r28.u8 & 0x3F));
	// rlwinm r8,r10,12,20,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFF;
	// addi r10,r8,512
	ctx.r10.s64 = ctx.r8.s64 + 512;
	// stwu r5,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r11.u32 = ea;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r6,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// ble cr6,0x82b2b548
	if (!ctx.cr6.gt) goto loc_82B2B548;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B2B544;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B2B548:
	// addic. r26,r26,-1
	ctx.xer.ca = ctx.r26.u32 > 0;
	ctx.r26.s64 = ctx.r26.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// addi r28,r28,2
	ctx.r28.s64 = ctx.r28.s64 + 2;
	// bne 0x82b2b4e0
	if (!ctx.cr0.eq) goto loc_82B2B4E0;
loc_82B2B558:
	// stwu r30,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r30.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12708(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12708);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r25,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r25.u32);
	ctx.r11.u32 = ea;
	// lwz r10,12712(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12712);
loc_82B2B56C:
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// li r9,21
	ctx.r9.s64 = 21;
	// ori r10,r10,23296
	ctx.r10.u64 = ctx.r10.u64 | 23296;
	// li r12,1
	ctx.r12.s64 = 1;
	// rldicr r12,r12,57,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 57) & 0xFFFFFFFFFFFFFFFF;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r11,r11,8
	ctx.r11.u64 = ctx.r11.u64 | 8;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// or r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 | ctx.r12.u64;
	// li r12,1
	ctx.r12.s64 = 1;
	// rldicr r12,r12,56,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// or r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2B5C0"))) PPC_WEAK_FUNC(sub_82B2B5C0);
PPC_FUNC_IMPL(__imp__sub_82B2B5C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B2B5C8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,-1
	ctx.r11.s64 = -1;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// clrldi r30,r11,32
	ctx.r30.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// addi r11,r31,1152
	ctx.r11.s64 = ctx.r31.s64 + 1152;
	// li r10,26
	ctx.r10.s64 = 26;
	// std r30,11824(r31)
	PPC_STORE_U64(ctx.r31.u32 + 11824, ctx.r30.u64);
loc_82B2B5E4:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// rlwinm r9,r9,0,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// bne 0x82b2b5e4
	if (!ctx.cr0.eq) goto loc_82B2B5E4;
	// addi r11,r31,1776
	ctx.r11.s64 = ctx.r31.s64 + 1776;
	// li r10,18
	ctx.r10.s64 = 18;
loc_82B2B604:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r8,1
	ctx.r8.s64 = 1;
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// rlwimi r9,r8,0,30,31
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r8.u32, 0) & 0x3) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bne 0x82b2b604
	if (!ctx.cr0.eq) goto loc_82B2B604;
	// lis r7,8192
	ctx.r7.s64 = 536870912;
	// lwz r11,10564(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10564);
	// lis r6,15
	ctx.r6.s64 = 983040;
	// lwz r8,10568(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10568);
	// ori r7,r7,8192
	ctx.r7.u64 = ctx.r7.u64 | 8192;
	// lis r5,15
	ctx.r5.s64 = 983040;
	// li r9,8
	ctx.r9.s64 = 8;
	// ori r6,r6,61440
	ctx.r6.u64 = ctx.r6.u64 | 61440;
	// ori r5,r5,61696
	ctx.r5.u64 = ctx.r5.u64 | 61696;
	// stw r7,10428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10428, ctx.r7.u32);
	// oris r7,r11,8
	ctx.r7.u64 = ctx.r11.u64 | 524288;
	// lis r11,255
	ctx.r11.s64 = 16711680;
	// stw r9,10604(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10604, ctx.r9.u32);
	// li r10,14
	ctx.r10.s64 = 14;
	// stw r6,10708(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10708, ctx.r6.u32);
	// li r9,4
	ctx.r9.s64 = 4;
	// stw r5,10712(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10712, ctx.r5.u32);
	// ori r6,r11,65535
	ctx.r6.u64 = ctx.r11.u64 | 65535;
	// li r4,16
	ctx.r4.s64 = 16;
	// stw r7,10564(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10564, ctx.r7.u32);
	// oris r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 65536;
	// li r5,2
	ctx.r5.s64 = 2;
	// stw r10,10628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10628, ctx.r10.u32);
	// li r11,-1
	ctx.r11.s64 = -1;
	// stw r9,10580(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10580, ctx.r9.u32);
	// stw r9,10688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10688, ctx.r9.u32);
	// stw r10,10768(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10768, ctx.r10.u32);
	// stw r4,10772(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10772, ctx.r4.u32);
	// stw r8,10568(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10568, ctx.r8.u32);
	// stw r6,10444(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10444, ctx.r6.u32);
	// stw r5,10824(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10824, ctx.r5.u32);
	// std r11,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r11.u64);
	// std r11,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r11.u64);
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// std r11,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r11.u64);
	// std r11,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r11.u64);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// stw r10,10916(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10916, ctx.r10.u32);
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82b2b6d0
	if (!ctx.cr6.gt) goto loc_82B2B6D0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B2B6CC;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B2B6D0:
	// li r9,3329
	ctx.r9.s64 = 3329;
	// lis r8,1024
	ctx.r8.s64 = 67108864;
	// lis r10,-16382
	ctx.r10.s64 = -1073610752;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// ori r10,r10,8448
	ctx.r10.u64 = ctx.r10.u64 | 8448;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// li r9,129
	ctx.r9.s64 = 129;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
	// lis r10,-31967
	ctx.r10.s64 = -2094989312;
	// li r5,130
	ctx.r5.s64 = 130;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// li r3,3650
	ctx.r3.s64 = 3650;
	// li r29,8032
	ctx.r29.s64 = 8032;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// li r9,15
	ctx.r9.s64 = 15;
	// stwu r6,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r11.u32 = ea;
	// lwz r10,23788(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 23788);
	// oris r10,r10,32769
	ctx.r10.u64 = ctx.r10.u64 | 2147549184;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// lis r10,-31967
	ctx.r10.s64 = -2094989312;
	// stwu r4,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	ctx.r11.u32 = ea;
	// stwu r5,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r11.u32 = ea;
	// stwu r30,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r30.u32);
	ctx.r11.u32 = ea;
	// lwz r10,23792(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 23792);
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r3,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r11.u32 = ea;
	// stwu r29,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r29.u32);
	ctx.r11.u32 = ea;
	// lwz r10,22300(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 22300);
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// li r10,3205
	ctx.r10.s64 = 3205;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// bne 0x82b2b75c
	if (!ctx.cr0.eq) goto loc_82B2B75C;
	// li r9,3
	ctx.r9.s64 = 3;
loc_82B2B75C:
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// li r10,1404
	ctx.r10.s64 = 1404;
	// lis r9,2989
	ctx.r9.s64 = 195887104;
	// li r8,1403
	ctx.r8.s64 = 1403;
	// ori r9,r9,61453
	ctx.r9.u64 = ctx.r9.u64 | 61453;
	// li r7,0
	ctx.r7.s64 = 0;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2B790"))) PPC_WEAK_FUNC(sub_82B2B790);
PPC_FUNC_IMPL(__imp__sub_82B2B790) {
	PPC_FUNC_PROLOGUE();
	// lhz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r4.u32 + 0);
	// lhz r9,2(r4)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r4.u32 + 2);
	// rlwinm r10,r11,26,6,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r11,r9,26,6,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x3FFFFFF;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// clrlwi r9,r11,16
	ctx.r9.u64 = ctx.r11.u32 & 0xFFFF;
	// cmplwi cr6,r9,1023
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 1023, ctx.xer);
	// ble cr6,0x82b2b7b4
	if (!ctx.cr6.gt) goto loc_82B2B7B4;
	// li r11,1023
	ctx.r11.s64 = 1023;
loc_82B2B7B4:
	// rlwinm r10,r10,1,15,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1FFFE;
	// rlwinm r11,r11,1,15,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0x1FFFE;
	// lhzx r9,r10,r5
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r5.u32);
	// rotlwi r9,r9,6
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 6);
	// sth r9,0(r3)
	PPC_STORE_U16(ctx.r3.u32 + 0, ctx.r9.u16);
	// lhzx r11,r11,r5
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + ctx.r5.u32);
	// lhzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r5.u32);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// sth r11,2(r3)
	PPC_STORE_U16(ctx.r3.u32 + 2, ctx.r11.u16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2B7E0"))) PPC_WEAK_FUNC(sub_82B2B7E0);
PPC_FUNC_IMPL(__imp__sub_82B2B7E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82b2b83c
	if (ctx.cr6.eq) goto loc_82B2B83C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f0,-19128(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -19128);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bgt cr6,0x82b2b810
	if (ctx.cr6.gt) goto loc_82B2B810;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f0,-19132(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19132);
	ctx.f0.f64 = double(temp.f32);
	// b 0x82b2b854
	goto loc_82B2B854;
loc_82B2B810:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f0,-19136(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19136);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fadds f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f0.f64));
	// lfd f2,-19144(r11)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + -19144);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f0,-19152(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19152);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82e28570
	ctx.lr = 0x82B2B834;
	sub_82E28570(ctx, base);
	// frsp f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// b 0x82b2b880
	goto loc_82B2B880;
loc_82B2B83C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f0,-19160(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -19160);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bgt cr6,0x82b2b85c
	if (ctx.cr6.gt) goto loc_82B2B85C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f0,-19168(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19168);
	ctx.f0.f64 = double(temp.f32);
loc_82B2B854:
	// fmuls f1,f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// b 0x82b2b880
	goto loc_82B2B880;
loc_82B2B85C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f2,-19176(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + -19176);
	// bl 0x82e28570
	ctx.lr = 0x82B2B868;
	sub_82E28570(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// frsp f12,f1
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f1.f64));
	// lfs f0,-19184(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19184);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f13,-19136(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19136);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64));
loc_82B2B880:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2B890"))) PPC_WEAK_FUNC(sub_82B2B890);
PPC_FUNC_IMPL(__imp__sub_82B2B890) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82b2b8ec
	if (ctx.cr6.eq) goto loc_82B2B8EC;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f0,-19064(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -19064);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bge cr6,0x82b2b8c0
	if (!ctx.cr6.lt) goto loc_82B2B8C0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f0,-19068(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19068);
	ctx.f0.f64 = double(temp.f32);
	// b 0x82b2b904
	goto loc_82B2B904;
loc_82B2B8C0:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f0,-19072(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19072);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fadds f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f0.f64));
	// lfd f2,-19080(r11)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + -19080);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f0,-19088(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19088);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82e28570
	ctx.lr = 0x82B2B8E4;
	sub_82E28570(ctx, base);
	// frsp f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// b 0x82b2b930
	goto loc_82B2B930;
loc_82B2B8EC:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f0,-19096(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -19096);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bge cr6,0x82b2b90c
	if (!ctx.cr6.lt) goto loc_82B2B90C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f0,-19104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19104);
	ctx.f0.f64 = double(temp.f32);
loc_82B2B904:
	// fmuls f1,f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// b 0x82b2b930
	goto loc_82B2B930;
loc_82B2B90C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f2,-19112(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + -19112);
	// bl 0x82e28570
	ctx.lr = 0x82B2B918;
	sub_82E28570(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// frsp f12,f1
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f1.f64));
	// lfs f0,-19120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19120);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f13,-19072(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19072);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64));
loc_82B2B930:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2B940"))) PPC_WEAK_FUNC(sub_82B2B940);
PPC_FUNC_IMPL(__imp__sub_82B2B940) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B2B948;
	__savegprlr_28(ctx, base);
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82e28f18
	ctx.lr = 0x82B2B950;
	__savefpr_28(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// cntlzw r11,r30
	ctx.r11.u64 = ctx.r30.u32 == 0 ? 32 : __builtin_clz(ctx.r30.u32);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r31,r11,1
	ctx.r31.u64 = ctx.r11.u64 ^ 1;
	// bl 0x83158334
	ctx.lr = 0x82B2B970;
	__imp__VdGetCurrentDisplayGamma(ctx, base);
	// lis r10,-31975
	ctx.r10.s64 = -2095513600;
	// lfs f2,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// lis r9,-31967
	ctx.r9.s64 = -2094989312;
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,-28688
	ctx.r10.s64 = ctx.r10.s64 + -28688;
	// addi r9,r9,23808
	ctx.r9.s64 = ctx.r9.s64 + 23808;
	// rlwinm r8,r31,11,0,20
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 11) & 0xFFFFF800;
	// add r28,r8,r9
	ctx.r28.u64 = ctx.r8.u64 + ctx.r9.u64;
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// lis r9,-31967
	ctx.r9.s64 = -2094989312;
	// addi r9,r9,23800
	ctx.r9.s64 = ctx.r9.s64 + 23800;
	// bne cr6,0x82b2b9b4
	if (!ctx.cr6.eq) goto loc_82B2B9B4;
	// lfsx f0,r11,r9
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f2
	ctx.cr6.compare(ctx.f0.f64, ctx.f2.f64);
	// beq cr6,0x82b2bab8
	if (ctx.cr6.eq) goto loc_82B2BAB8;
loc_82B2B9B4:
	// stfsx f2,r11,r9
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, temp.u32);
	// stwx r8,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r8.u32);
	// lis r7,-32253
	ctx.r7.s64 = -2113732608;
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// lis r11,-32243
	ctx.r11.s64 = -2113077248;
	// li r31,0
	ctx.r31.s64 = 0;
	// lfd f29,-3064(r7)
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r7.u32 + -3064);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// lfd f30,-19056(r9)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r9.u32 + -19056);
	// lfs f31,-13896(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13896);
	ctx.f31.f64 = double(temp.f32);
	// lfs f28,-13972(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13972);
	ctx.f28.f64 = double(temp.f32);
	// b 0x82b2b9f0
	goto loc_82B2B9F0;
loc_82B2B9E8:
	// lfs f2,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82B2B9F0:
	// extsw r11,r31
	ctx.r11.s64 = ctx.r31.s32;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r11.u64);
	// lfd f0,96(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmuls f1,f0,f28
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// bne cr6,0x82b2ba20
	if (!ctx.cr6.eq) goto loc_82B2BA20;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b2b7e0
	ctx.lr = 0x82B2BA18;
	sub_82B2B7E0(ctx, base);
	// lfs f2,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82B2BA20:
	// cmplwi cr6,r8,1
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 1, ctx.xer);
	// beq cr6,0x82b2ba5c
	if (ctx.cr6.eq) goto loc_82B2BA5C;
	// cmplwi cr6,r8,2
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 2, ctx.xer);
	// beq cr6,0x82b2ba50
	if (ctx.cr6.eq) goto loc_82B2BA50;
	// cmplwi cr6,r8,3
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 3, ctx.xer);
	// bne cr6,0x82b2ba50
	if (!ctx.cr6.eq) goto loc_82B2BA50;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82b2ba44
	if (!ctx.cr6.eq) goto loc_82B2BA44;
	// fdivs f2,f31,f2
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = double(float(ctx.f31.f64 / ctx.f2.f64));
loc_82B2BA44:
	// bl 0x82e28570
	ctx.lr = 0x82B2BA48;
	sub_82E28570(ctx, base);
	// frsp f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// b 0x82b2ba64
	goto loc_82B2BA64;
loc_82B2BA50:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82b2b890
	ctx.lr = 0x82B2BA58;
	sub_82B2B890(ctx, base);
	// b 0x82b2ba64
	goto loc_82B2BA64;
loc_82B2BA5C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82b2b7e0
	ctx.lr = 0x82B2BA64;
	sub_82B2B7E0(ctx, base);
loc_82B2BA64:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82b2ba74
	if (ctx.cr6.eq) goto loc_82B2BA74;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82b2b7e0
	ctx.lr = 0x82B2BA74;
	sub_82B2B7E0(ctx, base);
loc_82B2BA74:
	// fmadd f0,f1,f30,f29
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f1.f64 * ctx.f30.f64 + ctx.f29.f64;
	// addi r11,r1,88
	ctx.r11.s64 = ctx.r1.s64 + 88;
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82b2ba98
	if (!ctx.cr6.lt) goto loc_82B2BA98;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82b2baa4
	goto loc_82B2BAA4;
loc_82B2BA98:
	// cmpwi cr6,r11,1023
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1023, ctx.xer);
	// ble cr6,0x82b2baa4
	if (!ctx.cr6.gt) goto loc_82B2BAA4;
	// li r11,1023
	ctx.r11.s64 = 1023;
loc_82B2BAA4:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// sth r11,0(r29)
	PPC_STORE_U16(ctx.r29.u32 + 0, ctx.r11.u16);
	// addi r29,r29,2
	ctx.r29.s64 = ctx.r29.s64 + 2;
	// cmpwi cr6,r31,1024
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 1024, ctx.xer);
	// blt cr6,0x82b2b9e8
	if (ctx.cr6.lt) goto loc_82B2B9E8;
loc_82B2BAB8:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82e28f64
	ctx.lr = 0x82B2BAC8;
	__restfpr_28(ctx, base);
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2BAD0"))) PPC_WEAK_FUNC(sub_82B2BAD0);
PPC_FUNC_IMPL(__imp__sub_82B2BAD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82b2b940
	ctx.lr = 0x82B2BAF4;
	sub_82B2B940(ctx, base);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// addi r11,r31,512
	ctx.r11.s64 = ctx.r31.s64 + 512;
	// subf r8,r31,r30
	ctx.r8.s64 = ctx.r30.s64 - ctx.r31.s64;
	// li r9,256
	ctx.r9.s64 = 256;
loc_82B2BB04:
	// lhz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// rlwinm r7,r7,27,5,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFE;
	// lhzx r7,r7,r3
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r7.u32 + ctx.r3.u32);
	// rotlwi r7,r7,6
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r7.u32, 6);
	// sth r7,-512(r11)
	PPC_STORE_U16(ctx.r11.u32 + -512, ctx.r7.u16);
	// lhzx r7,r8,r11
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r8.u32 + ctx.r11.u32);
	// rlwinm r7,r7,27,5,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFE;
	// lhzx r7,r7,r3
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r7.u32 + ctx.r3.u32);
	// rotlwi r7,r7,6
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r7.u32, 6);
	// sth r7,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r7.u16);
	// lhz r7,1024(r10)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r10.u32 + 1024);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// rlwinm r7,r7,27,5,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFE;
	// lhzx r7,r7,r3
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r7.u32 + ctx.r3.u32);
	// rotlwi r7,r7,6
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r7.u32, 6);
	// sth r7,512(r11)
	PPC_STORE_U16(ctx.r11.u32 + 512, ctx.r7.u16);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// bne 0x82b2bb04
	if (!ctx.cr0.eq) goto loc_82B2BB04;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2BB68"))) PPC_WEAK_FUNC(sub_82B2BB68);
PPC_FUNC_IMPL(__imp__sub_82B2BB68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82b2b940
	ctx.lr = 0x82B2BB8C;
	sub_82B2B940(ctx, base);
	// addi r8,r31,512
	ctx.r8.s64 = ctx.r31.s64 + 512;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// subf r31,r31,r30
	ctx.r31.s64 = ctx.r30.s64 - ctx.r31.s64;
	// li r6,128
	ctx.r6.s64 = 128;
loc_82B2BBA0:
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// addi r3,r8,-512
	ctx.r3.s64 = ctx.r8.s64 + -512;
	// bl 0x82b2b790
	ctx.lr = 0x82B2BBAC;
	sub_82B2B790(ctx, base);
	// add r4,r31,r8
	ctx.r4.u64 = ctx.r31.u64 + ctx.r8.u64;
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82b2b790
	ctx.lr = 0x82B2BBB8;
	sub_82B2B790(ctx, base);
	// addi r4,r7,1024
	ctx.r4.s64 = ctx.r7.s64 + 1024;
	// addi r3,r8,512
	ctx.r3.s64 = ctx.r8.s64 + 512;
	// bl 0x82b2b790
	ctx.lr = 0x82B2BBC4;
	sub_82B2B790(ctx, base);
	// addic. r6,r6,-1
	ctx.xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82b2bba0
	if (!ctx.cr0.eq) goto loc_82B2BBA0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2BBF0"))) PPC_WEAK_FUNC(sub_82B2BBF0);
PPC_FUNC_IMPL(__imp__sub_82B2BBF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// li r4,2309
	ctx.r4.s64 = 2309;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bl 0x82b1dd08
	ctx.lr = 0x82B2BC14;
	sub_82B1DD08(ctx, base);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// li r10,0
	ctx.r10.s64 = 0;
	// ori r8,r11,6433
	ctx.r8.u64 = ctx.r11.u64 | 6433;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6439
	ctx.r6.s64 = 6439;
	// li r5,7
	ctx.r5.s64 = 7;
	// li r9,0
	ctx.r9.s64 = 0;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// addi r11,r31,1024
	ctx.r11.s64 = ctx.r31.s64 + 1024;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r7,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r3.u32 = ea;
	// stwu r6,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r3.u32 = ea;
	// stwu r5,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r3.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
loc_82B2BC4C:
	// lhz r8,-1024(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + -1024);
	// li r6,6437
	ctx.r6.s64 = 6437;
	// lhz r7,-512(r11)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r11.u32 + -512);
	// lis r4,-16379
	ctx.r4.s64 = -1073414144;
	// lhz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// li r3,6434
	ctx.r3.s64 = 6434;
	// rlwimi r7,r8,10,6,15
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r8.u32, 10) & 0x3FF0000) | (ctx.r7.u64 & 0xFFFFFFFFFC00FFFF);
	// rlwinm r8,r5,26,6,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r7,r7,4,2,21
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0x3FFFFC00;
	// stwu r6,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r10.u32 = ea;
	// ori r4,r4,17664
	ctx.r4.u64 = ctx.r4.u64 | 17664;
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// li r7,7
	ctx.r7.s64 = 7;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// cmplwi cr6,r9,256
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 256, ctx.xer);
	// stwu r4,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	ctx.r10.u32 = ea;
	// stwu r7,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r10.u32 = ea;
	// stwu r6,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r10.u32 = ea;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// stwu r5,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r10.u32 = ea;
	// stwu r3,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r10.u32 = ea;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// blt cr6,0x82b2bc4c
	if (ctx.cr6.lt) goto loc_82B2BC4C;
	// stw r10,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2BCD0"))) PPC_WEAK_FUNC(sub_82B2BCD0);
PPC_FUNC_IMPL(__imp__sub_82B2BCD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B2BCD8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// li r4,1413
	ctx.r4.s64 = 1413;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bl 0x82b1dd08
	ctx.lr = 0x82B2BCEC;
	sub_82B1DD08(ctx, base);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// li r10,1
	ctx.r10.s64 = 1;
	// ori r8,r11,6433
	ctx.r8.u64 = ctx.r11.u64 | 6433;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,6439
	ctx.r6.s64 = 6439;
	// li r5,7
	ctx.r5.s64 = 7;
	// li r9,0
	ctx.r9.s64 = 0;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// addi r11,r31,514
	ctx.r11.s64 = ctx.r31.s64 + 514;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r7,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r3.u32 = ea;
	// stwu r6,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r3.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// stwu r5,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r10.u32 = ea;
loc_82B2BD24:
	// lis r8,2
	ctx.r8.s64 = 131072;
	// lis r7,-16379
	ctx.r7.s64 = -1073414144;
	// ori r8,r8,39204
	ctx.r8.u64 = ctx.r8.u64 | 39204;
	// ori r7,r7,17664
	ctx.r7.u64 = ctx.r7.u64 | 17664;
	// li r6,7
	ctx.r6.s64 = 7;
	// li r5,6436
	ctx.r5.s64 = 6436;
	// li r4,0
	ctx.r4.s64 = 0;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// li r3,-1
	ctx.r3.s64 = -1;
	// lhz r8,-512(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + -512);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lhz r31,-514(r11)
	ctx.r31.u64 = PPC_LOAD_U16(ctx.r11.u32 + -514);
	// rotlwi r8,r8,16
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 16);
	// cmplwi cr6,r9,128
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 128, ctx.xer);
	// or r8,r8,r31
	ctx.r8.u64 = ctx.r8.u64 | ctx.r31.u64;
	// li r31,6434
	ctx.r31.s64 = 6434;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// lhz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// lhz r29,-2(r11)
	ctx.r29.u64 = PPC_LOAD_U16(ctx.r11.u32 + -2);
	// rotlwi r8,r8,16
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 16);
	// or r8,r8,r29
	ctx.r8.u64 = ctx.r8.u64 | ctx.r29.u64;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// lhz r8,512(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 512);
	// lhz r29,510(r11)
	ctx.r29.u64 = PPC_LOAD_U16(ctx.r11.u32 + 510);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// rotlwi r8,r8,16
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 16);
	// or r8,r8,r29
	ctx.r8.u64 = ctx.r8.u64 | ctx.r29.u64;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// stwu r7,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r10.u32 = ea;
	// stwu r6,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r10.u32 = ea;
	// stwu r5,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r10.u32 = ea;
	// stwu r4,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	ctx.r10.u32 = ea;
	// stwu r3,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r10.u32 = ea;
	// stwu r31,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r31.u32);
	ctx.r10.u32 = ea;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// blt cr6,0x82b2bd24
	if (ctx.cr6.lt) goto loc_82B2BD24;
	// stw r10,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2BDC0"))) PPC_WEAK_FUNC(sub_82B2BDC0);
PPC_FUNC_IMPL(__imp__sub_82B2BDC0) {
	PPC_FUNC_PROLOGUE();
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r3,1024
	ctx.r11.s64 = ctx.r3.s64 + 1024;
loc_82B2BDC8:
	// li r9,255
	ctx.r9.s64 = 255;
	// lis r8,3
	ctx.r8.s64 = 196608;
	// divwu r9,r10,r9
	ctx.r9.u32 = ctx.r10.u32 / ctx.r9.u32;
	// ori r8,r8,65280
	ctx.r8.u64 = ctx.r8.u64 | 65280;
	// rlwinm r9,r9,6,10,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0x3FFFC0;
	// addi r10,r10,1023
	ctx.r10.s64 = ctx.r10.s64 + 1023;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// sth r9,-1024(r11)
	PPC_STORE_U16(ctx.r11.u32 + -1024, ctx.r9.u16);
	// sth r9,-512(r11)
	PPC_STORE_U16(ctx.r11.u32 + -512, ctx.r9.u16);
	// sth r9,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r9.u16);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// blt cr6,0x82b2bdc8
	if (ctx.cr6.lt) goto loc_82B2BDC8;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x82b2bad0
	sub_82B2BAD0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2BE10"))) PPC_WEAK_FUNC(sub_82B2BE10);
PPC_FUNC_IMPL(__imp__sub_82B2BE10) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2BE18"))) PPC_WEAK_FUNC(sub_82B2BE18);
PPC_FUNC_IMPL(__imp__sub_82B2BE18) {
	PPC_FUNC_PROLOGUE();
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r11,r3,512
	ctx.r11.s64 = ctx.r3.s64 + 512;
	// li r7,127
	ctx.r7.s64 = 127;
loc_82B2BE24:
	// divwu r10,r9,r7
	ctx.r10.u32 = ctx.r9.u32 / ctx.r7.u32;
	// addis r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 65536;
	// lis r8,127
	ctx.r8.s64 = 8323072;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// ori r6,r8,65408
	ctx.r6.u64 = ctx.r8.u64 | 65408;
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// divwu r8,r9,r7
	ctx.r8.u32 = ctx.r9.u32 / ctx.r7.u32;
	// cmplw cr6,r9,r6
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, ctx.xer);
	// subf r8,r10,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r10.s64;
	// clrlwi r8,r8,16
	ctx.r8.u64 = ctx.r8.u32 & 0xFFFF;
	// sth r10,-512(r11)
	PPC_STORE_U16(ctx.r11.u32 + -512, ctx.r10.u16);
	// sth r10,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
	// sth r10,512(r11)
	PPC_STORE_U16(ctx.r11.u32 + 512, ctx.r10.u16);
	// sth r8,-510(r11)
	PPC_STORE_U16(ctx.r11.u32 + -510, ctx.r8.u16);
	// sth r8,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r8.u16);
	// sth r8,514(r11)
	PPC_STORE_U16(ctx.r11.u32 + 514, ctx.r8.u16);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// blt cr6,0x82b2be24
	if (ctx.cr6.lt) goto loc_82B2BE24;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x82b2bb68
	sub_82B2BB68(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2BE80"))) PPC_WEAK_FUNC(sub_82B2BE80);
PPC_FUNC_IMPL(__imp__sub_82B2BE80) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2BE88"))) PPC_WEAK_FUNC(sub_82B2BE88);
PPC_FUNC_IMPL(__imp__sub_82B2BE88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82B2BE90;
	__savegprlr_21(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r7,16(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r8,r11,-27720
	ctx.r8.s64 = ctx.r11.s64 + -27720;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// clrlwi r31,r10,26
	ctx.r31.u64 = ctx.r10.u32 & 0x3F;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r23,r8,1
	ctx.r23.s64 = ctx.r8.s64 + 1;
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r8,r7,26,28,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 26) & 0xF;
	// rlwinm r7,r31,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r27,r8,1
	ctx.r27.s64 = ctx.r8.s64 + 1;
	// rlwinm r8,r11,10,23,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 10) & 0x1FF;
	// rlwinm r25,r11,1,31,31
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0x1;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lbzx r11,r7,r23
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r23.u32);
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// rlwinm r22,r10,13,0,18
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0xFFFFE000;
	// mullw r11,r11,r8
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r8.s32);
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// addi r5,r1,132
	ctx.r5.s64 = ctx.r1.s64 + 132;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// rlwinm r26,r9,23,30,31
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 23) & 0x3;
	// rlwinm r24,r9,21,31,31
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 21) & 0x1;
	// rlwinm r23,r10,1,31,31
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// srawi r22,r22,26
	ctx.xer.ca = (ctx.r22.s32 < 0) & ((ctx.r22.u32 & 0x3FFFFFF) != 0);
	ctx.r22.s64 = ctx.r22.s32 >> 26;
	// rlwinm r21,r11,2,3,29
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x1FFFFFFC;
	// bl 0x82b12530
	ctx.lr = 0x82B2BF08;
	sub_82B12530(ctx, base);
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// lwz r5,128(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// lwz r4,132(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// lwz r3,136(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r28.u32);
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r29.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// stw r21,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r21.u32);
	// stw r22,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r22.u32);
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r23.u32);
	// bl 0x82b12720
	ctx.lr = 0x82B2BF44;
	sub_82B12720(ctx, base);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2BF50"))) PPC_WEAK_FUNC(sub_82B2BF50);
PPC_FUNC_IMPL(__imp__sub_82B2BF50) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,10943(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 10943);
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stb r11,10943(r3)
	PPC_STORE_U8(ctx.r3.u32 + 10943, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2BF60"))) PPC_WEAK_FUNC(sub_82B2BF60);
PPC_FUNC_IMPL(__imp__sub_82B2BF60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,32767
	ctx.r11.s64 = 2147418112;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bne cr6,0x82b2bf94
	if (!ctx.cr6.eq) goto loc_82B2BF94;
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// b 0x82b2bfb4
	goto loc_82B2BFB4;
loc_82B2BF94:
	// bl 0x82e2f000
	ctx.lr = 0x82B2BF98;
	sub_82E2F000(ctx, base);
	// lis r11,-32246
	ctx.r11.s64 = -2113273856;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lfd f0,-19784(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -19784);
	// fmul f31,f1,f0
	ctx.f31.f64 = ctx.f1.f64 * ctx.f0.f64;
	// bl 0x82e2f000
	ctx.lr = 0x82B2BFAC;
	sub_82E2F000(ctx, base);
	// fdiv f0,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64 / ctx.f1.f64;
	// frsp f1,f0
	ctx.f1.f64 = double(float(ctx.f0.f64));
loc_82B2BFB4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2BFD0"))) PPC_WEAK_FUNC(sub_82B2BFD0);
PPC_FUNC_IMPL(__imp__sub_82B2BFD0) {
	PPC_FUNC_PROLOGUE();
	// cmpdi cr6,r3,0
	ctx.cr6.compare<int64_t>(ctx.r3.s64, 0, ctx.xer);
	// bge cr6,0x82b2bfe0
	if (!ctx.cr6.lt) goto loc_82B2BFE0;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82B2BFE0:
	// cmpdi cr6,r4,0
	ctx.cr6.compare<int64_t>(ctx.r4.s64, 0, ctx.xer);
	// bne cr6,0x82b2bff4
	if (!ctx.cr6.eq) goto loc_82B2BFF4;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,65535
	ctx.r3.u64 = ctx.r3.u64 | 65535;
	// blr 
	return;
loc_82B2BFF4:
	// cmpd cr6,r3,r4
	ctx.cr6.compare<int64_t>(ctx.r3.s64, ctx.r4.s64, ctx.xer);
	// blt cr6,0x82b2c008
	if (ctx.cr6.lt) goto loc_82B2C008;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,65534
	ctx.r3.u64 = ctx.r3.u64 | 65534;
	// blr 
	return;
loc_82B2C008:
	// lis r11,0
	ctx.r11.s64 = 0;
	// tdllei r4,0
	// ori r11,r11,65534
	ctx.r11.u64 = ctx.r11.u64 | 65534;
	// mulld r10,r3,r11
	ctx.r10.s64 = ctx.r3.s64 * ctx.r11.s64;
	// rotldi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u64, 1);
	// divd r10,r10,r4
	ctx.r10.s64 = ctx.r10.s64 / ctx.r4.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r3,r10,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// andc r11,r4,r11
	ctx.r11.u64 = ctx.r4.u64 & ~ctx.r11.u64;
	// tdlgei r11,-1
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2C038"))) PPC_WEAK_FUNC(sub_82B2C038);
PPC_FUNC_IMPL(__imp__sub_82B2C038) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82b2c060
	if (!ctx.cr6.eq) goto loc_82B2C060;
	// lis r3,-32038
	ctx.r3.s64 = -2099642368;
	// ori r3,r3,23
	ctx.r3.u64 = ctx.r3.u64 | 23;
	// b 0x82b2c0cc
	goto loc_82B2C0CC;
loc_82B2C060:
	// lbz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 4);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,107
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 107, ctx.xer);
	// bgt cr6,0x82b2c0a8
	if (ctx.cr6.gt) goto loc_82B2C0A8;
	// beq cr6,0x82b2c098
	if (ctx.cr6.eq) goto loc_82B2C098;
	// cmpwi cr6,r11,97
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 97, ctx.xer);
	// beq cr6,0x82b2c098
	if (ctx.cr6.eq) goto loc_82B2C098;
	// cmpwi cr6,r11,98
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 98, ctx.xer);
	// ble cr6,0x82b2c0c8
	if (!ctx.cr6.gt) goto loc_82B2C0C8;
	// cmpwi cr6,r11,100
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 100, ctx.xer);
	// ble cr6,0x82b2c098
	if (!ctx.cr6.gt) goto loc_82B2C098;
	// addi r11,r11,-102
	ctx.r11.s64 = ctx.r11.s64 + -102;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bgt cr6,0x82b2c0c8
	if (ctx.cr6.gt) goto loc_82B2C0C8;
loc_82B2C098:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r4,r11,-19048
	ctx.r4.s64 = ctx.r11.s64 + -19048;
	// bl 0x83158234
	ctx.lr = 0x82B2C0A4;
	__imp__sprintf(ctx, base);
	// b 0x82b2c0c8
	goto loc_82B2C0C8;
loc_82B2C0A8:
	// cmpwi cr6,r11,109
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 109, ctx.xer);
	// beq cr6,0x82b2c0bc
	if (ctx.cr6.eq) goto loc_82B2C0BC;
	// cmpwi cr6,r11,116
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 116, ctx.xer);
	// bne cr6,0x82b2c0c8
	if (!ctx.cr6.eq) goto loc_82B2C0C8;
	// b 0x82b2c098
	goto loc_82B2C098;
loc_82B2C0BC:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x82b2f4a8
	ctx.lr = 0x82B2C0C8;
	sub_82B2F4A8(ctx, base);
loc_82B2C0C8:
	// lis r3,730
	ctx.r3.s64 = 47841280;
loc_82B2C0CC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2C0E0"))) PPC_WEAK_FUNC(sub_82B2C0E0);
PPC_FUNC_IMPL(__imp__sub_82B2C0E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,16560(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16560);
	// lwz r10,21664(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21664);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82b2c110
	if (!ctx.cr6.eq) goto loc_82B2C110;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82b2c130
	goto loc_82B2C130;
loc_82B2C110:
	// lwz r11,21652(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21652);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82b2c148
	if (ctx.cr6.eq) goto loc_82B2C148;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2c12c
	if (!ctx.cr6.eq) goto loc_82B2C12C;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,21652(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21652, ctx.r11.u32);
loc_82B2C12C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B2C130:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82B2C148:
	// lwz r11,21656(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21656);
	// lwz r10,21660(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21660);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b2c12c
	if (ctx.cr6.eq) goto loc_82B2C12C;
	// addi r11,r11,5408
	ctx.r11.s64 = ctx.r11.s64 + 5408;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// bl 0x82b10ce8
	ctx.lr = 0x82B2C168;
	sub_82B10CE8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b2c12c
	if (!ctx.cr0.eq) goto loc_82B2C12C;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// li r5,480
	ctx.r5.s64 = 480;
	// addi r31,r11,27988
	ctx.r31.s64 = ctx.r11.s64 + 27988;
	// addi r3,r31,4
	ctx.r3.s64 = ctx.r31.s64 + 4;
	// addi r4,r31,484
	ctx.r4.s64 = ctx.r31.s64 + 484;
	// bl 0x82e28fd0
	ctx.lr = 0x82B2C188;
	sub_82E28FD0(ctx, base);
	// lwz r11,21656(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21656);
	// addi r4,r31,484
	ctx.r4.s64 = ctx.r31.s64 + 484;
	// addi r11,r11,5408
	ctx.r11.s64 = ctx.r11.s64 + 5408;
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwzx r3,r10,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// stw r11,-4(r31)
	PPC_STORE_U32(ctx.r31.u32 + -4, ctx.r11.u32);
	// bl 0x82b12428
	ctx.lr = 0x82B2C1B0;
	sub_82B12428(ctx, base);
	// lwz r11,21656(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21656);
	// lwz r10,21648(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 21648);
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// bne cr6,0x82b2c1e0
	if (!ctx.cr6.eq) goto loc_82B2C1E0;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82b2c1e4
	goto loc_82B2C1E4;
loc_82B2C1E0:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82B2C1E4:
	// lwz r10,16560(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16560);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,21656(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21656, ctx.r11.u32);
	// stw r10,21664(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21664, ctx.r10.u32);
	// b 0x82b2c130
	goto loc_82B2C130;
}

__attribute__((alias("__imp__sub_82B2C1F8"))) PPC_WEAK_FUNC(sub_82B2C1F8);
PPC_FUNC_IMPL(__imp__sub_82B2C1F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mftb r8
	ctx.r8.u64 = __rdtsc();
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r10,8
	ctx.r10.s64 = 8;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82B2C220:
	// std r7,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r7.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82b2c220
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B2C220;
	// lwz r6,21572(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21572);
	// sradi r7,r8,32
	ctx.xer.ca = (ctx.r8.s64 < 0) & ((ctx.r8.u64 & 0xFFFFFFFF) != 0);
	ctx.r7.s64 = ctx.r8.s64 >> 32;
	// stw r8,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r8.u32);
	// lfs f0,21588(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21588);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,21668(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21668);
	// stfs f0,112(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lwz r11,21616(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21616);
	// lfs f0,21584(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 21584);
	ctx.f0.f64 = double(temp.f32);
	// lwz r10,10896(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10896);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stw r6,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r6.u32);
	// addi r5,r11,-1
	ctx.r5.s64 = ctx.r11.s64 + -1;
	// lwz r6,16560(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16560);
	// stw r8,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r8.u32);
	// lwz r8,136(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stw r7,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
	// lwz r7,21612(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21612);
	// stw r6,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r6.u32);
	// lwz r6,21608(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21608);
	// stw r7,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r7.u32);
	// clrlwi r7,r11,29
	ctx.r7.u64 = ctx.r11.u32 & 0x7;
	// stw r6,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r6.u32);
	// ori r6,r8,65535
	ctx.r6.u64 = ctx.r8.u64 | 65535;
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// addi r7,r7,16
	ctx.r7.s64 = ctx.r7.s64 + 16;
	// clrlwi r8,r8,29
	ctx.r8.u64 = ctx.r8.u32 & 0x7;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r8,16
	ctx.r4.s64 = ctx.r8.s64 + 16;
	// stw r6,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r6.u32);
	// clrlwi r8,r5,29
	ctx.r8.u64 = ctx.r5.u32 & 0x7;
	// rlwinm r5,r4,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r8,16
	ctx.r8.s64 = ctx.r8.s64 + 16;
	// lwbrx r7,r7,r10
	ctx.r7.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32));
	// rlwinm r4,r8,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwbrx r8,r5,r10
	ctx.r8.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r5.u32 + ctx.r10.u32));
	// cmpldi cr6,r8,0
	ctx.cr6.compare<uint64_t>(ctx.r8.u64, 0, ctx.xer);
	// lwbrx r5,r4,r10
	ctx.r5.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r4.u32 + ctx.r10.u32));
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// beq cr6,0x82b2c318
	if (ctx.cr6.eq) goto loc_82B2C318;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// stw r11,21616(r9)
	PPC_STORE_U32(ctx.r9.u32 + 21616, ctx.r11.u32);
	// beq cr6,0x82b2c318
	if (ctx.cr6.eq) goto loc_82B2C318;
	// cmpldi cr6,r7,0
	ctx.cr6.compare<uint64_t>(ctx.r7.u64, 0, ctx.xer);
	// beq cr6,0x82b2c318
	if (ctx.cr6.eq) goto loc_82B2C318;
	// li r11,1
	ctx.r11.s64 = 1;
	// cmpld cr6,r10,r7
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, ctx.r7.u64, ctx.xer);
	// rldicr r11,r11,32,63
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// bgt cr6,0x82b2c2f8
	if (ctx.cr6.gt) goto loc_82B2C2F8;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
loc_82B2C2F8:
	// cmpld cr6,r8,r10
	ctx.cr6.compare<uint64_t>(ctx.r8.u64, ctx.r10.u64, ctx.xer);
	// bgt cr6,0x82b2c304
	if (ctx.cr6.gt) goto loc_82B2C304;
	// add r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 + ctx.r11.u64;
loc_82B2C304:
	// subf r4,r7,r8
	ctx.r4.s64 = ctx.r8.s64 - ctx.r7.s64;
	// subf r3,r10,r8
	ctx.r3.s64 = ctx.r8.s64 - ctx.r10.s64;
	// bl 0x82b2bfd0
	ctx.lr = 0x82B2C310;
	sub_82B2BFD0(ctx, base);
	// rlwimi r3,r6,0,0,15
	ctx.r3.u64 = (__builtin_rotateleft32(ctx.r6.u32, 0) & 0xFFFF0000) | (ctx.r3.u64 & 0xFFFFFFFF0000FFFF);
	// stw r3,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r3.u32);
loc_82B2C318:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2C320;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2c5f8
	if (ctx.cr0.eq) goto loc_82B2C5F8;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r9,r11,27988
	ctx.r9.s64 = ctx.r11.s64 + 27988;
	// ld r11,4(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 4);
	// ld r10,484(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 484);
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - ctx.r11.s64;
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// ld r10,492(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 492);
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// ld r11,12(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 12);
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r11.s64;
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// subf r3,r11,r8
	ctx.r3.s64 = ctx.r8.s64 - ctx.r11.s64;
	// bl 0x82b2bfd0
	ctx.lr = 0x82B2C368;
	sub_82B2BFD0(ctx, base);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// rlwimi r10,r11,16,0,15
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r10.u64 & 0xFFFFFFFF0000FFFF);
	// stw r10,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r10.u32);
	// bl 0x82b2bfd0
	ctx.lr = 0x82B2C380;
	sub_82B2BFD0(ctx, base);
	// ld r11,124(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 124);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// ld r10,604(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 604);
	// ld r6,132(r9)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r9.u32 + 132);
	// ld r5,612(r9)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r9.u32 + 612);
	// subf r4,r11,r10
	ctx.r4.s64 = ctx.r10.s64 - ctx.r11.s64;
	// subf r3,r6,r5
	ctx.r3.s64 = ctx.r5.s64 - ctx.r6.s64;
	// bl 0x82b2bfd0
	ctx.lr = 0x82B2C3A0;
	sub_82B2BFD0(ctx, base);
	// ld r31,620(r9)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r9.u32 + 620);
	// rlwimi r8,r3,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r3.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// subf r11,r31,r4
	ctx.r11.s64 = ctx.r4.s64 - ctx.r31.s64;
	// subf r11,r5,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r5.s64;
	// ld r5,140(r9)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r9.u32 + 140);
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// stw r8,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r8.u32);
	// add r3,r11,r6
	ctx.r3.u64 = ctx.r11.u64 + ctx.r6.u64;
	// bl 0x82b2bfd0
	ctx.lr = 0x82B2C3C4;
	sub_82B2BFD0(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// subf r3,r5,r31
	ctx.r3.s64 = ctx.r31.s64 - ctx.r5.s64;
	// bl 0x82b2bfd0
	ctx.lr = 0x82B2C3D0;
	sub_82B2BFD0(ctx, base);
	// ld r11,444(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 444);
	// ld r10,924(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 924);
	// rlwimi r8,r3,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r3.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// ld r11,436(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 436);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// ld r11,916(r9)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 916);
	// stw r8,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r8.u32);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lis r10,0
	ctx.r10.s64 = 0;
	// cmpdi cr6,r11,0
	ctx.cr6.compare<int64_t>(ctx.r11.s64, 0, ctx.xer);
	// ori r4,r10,65535
	ctx.r4.u64 = ctx.r10.u64 | 65535;
	// lis r10,0
	ctx.r10.s64 = 0;
	// ori r5,r10,43689
	ctx.r5.u64 = ctx.r10.u64 | 43689;
	// bge cr6,0x82b2c414
	if (!ctx.cr6.lt) goto loc_82B2C414;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82b2c444
	goto loc_82B2C444;
loc_82B2C414:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82b2c424
	if (!ctx.cr6.eq) goto loc_82B2C424;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// b 0x82b2c444
	goto loc_82B2C444;
loc_82B2C424:
	// mulld r10,r11,r5
	ctx.r10.s64 = ctx.r11.s64 * ctx.r5.s64;
	// rotldi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u64, 1);
	// divd r10,r10,r7
	ctx.r10.s64 = ctx.r10.s64 / ctx.r7.s64;
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// andc r10,r7,r8
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r8.u64;
	// tdllei r7,0
	// tdlgei r10,-1
loc_82B2C444:
	// ld r8,932(r9)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r9.u32 + 932);
	// ld r10,452(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 452);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// lwz r8,148(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// rlwimi r11,r8,0,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 0) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// bge cr6,0x82b2c468
	if (!ctx.cr6.lt) goto loc_82B2C468;
	// li r8,0
	ctx.r8.s64 = 0;
	// b 0x82b2c498
	goto loc_82B2C498;
loc_82B2C468:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82b2c478
	if (!ctx.cr6.eq) goto loc_82B2C478;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// b 0x82b2c498
	goto loc_82B2C498;
loc_82B2C478:
	// mulld r8,r10,r5
	ctx.r8.s64 = ctx.r10.s64 * ctx.r5.s64;
	// rotldi r10,r8,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u64, 1);
	// divd r8,r8,r7
	ctx.r8.s64 = ctx.r8.s64 / ctx.r7.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// tdllei r7,0
	// andc r10,r7,r10
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r10.u64;
	// rotlwi r8,r8,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// tdlgei r10,-1
loc_82B2C498:
	// ld r10,236(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 236);
	// rlwimi r11,r8,16,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 16) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// ld r6,716(r9)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r9.u32 + 716);
	// subf r10,r10,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r10.s64;
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r11.u32);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// bge cr6,0x82b2c4bc
	if (!ctx.cr6.lt) goto loc_82B2C4BC;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82b2c4ec
	goto loc_82B2C4EC;
loc_82B2C4BC:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82b2c4cc
	if (!ctx.cr6.eq) goto loc_82B2C4CC;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// b 0x82b2c4ec
	goto loc_82B2C4EC;
loc_82B2C4CC:
	// mulld r10,r10,r5
	ctx.r10.s64 = ctx.r10.s64 * ctx.r5.s64;
	// rotldi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u64, 1);
	// divd r10,r10,r7
	ctx.r10.s64 = ctx.r10.s64 / ctx.r7.s64;
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// andc r10,r7,r8
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r8.u64;
	// tdllei r7,0
	// tdlgei r10,-1
loc_82B2C4EC:
	// ld r8,572(r9)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r9.u32 + 572);
	// ld r10,92(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 92);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// lwz r8,152(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// rlwimi r11,r8,0,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 0) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// bge cr6,0x82b2c510
	if (!ctx.cr6.lt) goto loc_82B2C510;
	// li r8,0
	ctx.r8.s64 = 0;
	// b 0x82b2c540
	goto loc_82B2C540;
loc_82B2C510:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82b2c520
	if (!ctx.cr6.eq) goto loc_82B2C520;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// b 0x82b2c540
	goto loc_82B2C540;
loc_82B2C520:
	// mulld r8,r10,r5
	ctx.r8.s64 = ctx.r10.s64 * ctx.r5.s64;
	// rotldi r10,r8,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u64, 1);
	// divd r8,r8,r7
	ctx.r8.s64 = ctx.r8.s64 / ctx.r7.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// tdllei r7,0
	// andc r10,r7,r10
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r10.u64;
	// rotlwi r8,r8,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// tdlgei r10,-1
loc_82B2C540:
	// ld r10,460(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 460);
	// rlwimi r11,r8,16,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 16) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// ld r6,940(r9)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r9.u32 + 940);
	// subf r10,r10,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r10.s64;
	// rldicr r10,r10,1,62
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u64, 1) & 0xFFFFFFFFFFFFFFFE;
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r11.u32);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// bge cr6,0x82b2c568
	if (!ctx.cr6.lt) goto loc_82B2C568;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82b2c598
	goto loc_82B2C598;
loc_82B2C568:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82b2c578
	if (!ctx.cr6.eq) goto loc_82B2C578;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// b 0x82b2c598
	goto loc_82B2C598;
loc_82B2C578:
	// mulld r10,r10,r5
	ctx.r10.s64 = ctx.r10.s64 * ctx.r5.s64;
	// rotldi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u64, 1);
	// divd r10,r10,r7
	ctx.r10.s64 = ctx.r10.s64 / ctx.r7.s64;
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// andc r10,r7,r8
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r8.u64;
	// tdllei r7,0
	// tdlgei r10,-1
loc_82B2C598:
	// ld r10,468(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 468);
	// ld r9,948(r9)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r9.u32 + 948);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// lwz r9,156(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// rldicr r10,r10,1,62
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u64, 1) & 0xFFFFFFFFFFFFFFFE;
	// rlwimi r11,r9,0,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// bge cr6,0x82b2c5c0
	if (!ctx.cr6.lt) goto loc_82B2C5C0;
	// li r10,0
	ctx.r10.s64 = 0;
	// b 0x82b2c5f0
	goto loc_82B2C5F0;
loc_82B2C5C0:
	// cmpdi cr6,r7,0
	ctx.cr6.compare<int64_t>(ctx.r7.s64, 0, ctx.xer);
	// bne cr6,0x82b2c5d0
	if (!ctx.cr6.eq) goto loc_82B2C5D0;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// b 0x82b2c5f0
	goto loc_82B2C5F0;
loc_82B2C5D0:
	// mulld r9,r10,r5
	ctx.r9.s64 = ctx.r10.s64 * ctx.r5.s64;
	// rotldi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u64, 1);
	// divd r9,r9,r7
	ctx.r9.s64 = ctx.r9.s64 / ctx.r7.s64;
	// addi r8,r10,-1
	ctx.r8.s64 = ctx.r10.s64 + -1;
	// rotlwi r10,r9,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// andc r9,r7,r8
	ctx.r9.u64 = ctx.r7.u64 & ~ctx.r8.u64;
	// tdllei r7,0
	// tdlgei r9,-1
loc_82B2C5F0:
	// rlwimi r11,r10,16,0,15
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r11.u64 & 0xFFFFFFFF0000FFFF);
	// b 0x82b2c618
	goto loc_82B2C618;
loc_82B2C5F8:
	// lwz r11,136(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// oris r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 4294901760;
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r11.u32);
	// li r11,-1
	ctx.r11.s64 = -1;
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r11.u32);
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r11.u32);
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r11.u32);
loc_82B2C618:
	// lis r3,17459
	ctx.r3.s64 = 1144193024;
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r11.u32);
	// li r5,64
	ctx.r5.s64 = 64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// ori r3,r3,25703
	ctx.r3.u64 = ctx.r3.u64 | 25703;
	// bl 0x82f66158
	ctx.lr = 0x82B2C630;
	sub_82F66158(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2C648"))) PPC_WEAK_FUNC(sub_82B2C648);
PPC_FUNC_IMPL(__imp__sub_82B2C648) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f30,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f30.u64);
	// stfd f31,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,32767
	ctx.r11.s64 = 2147418112;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// cmplwi cr6,r31,18
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 18, ctx.xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bgt cr6,0x82b2caec
	if (ctx.cr6.gt) goto loc_82B2CAEC;
	// lis r12,-32239
	ctx.r12.s64 = -2112815104;
	// addi r12,r12,-19040
	ctx.r12.s64 = ctx.r12.s64 + -19040;
	// rlwinm r0,r31,1,0,30
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U16(ctx.r12.u32 + ctx.r0.u32);
	// lis r12,-32077
	ctx.r12.s64 = -2102198272;
	// addi r12,r12,-14684
	ctx.r12.s64 = ctx.r12.s64 + -14684;
	// add r12,r12,r0
	ctx.r12.u64 = ctx.r12.u64 + ctx.r0.u64;
	// mtctr r12
	ctx.ctr.u64 = ctx.r12.u64;
	// nop 
	// bctr 
	switch (ctx.r31.u64) {
	case 0:
		goto loc_82B2C6A4;
	case 1:
		goto loc_82B2C6C4;
	case 2:
		goto loc_82B2C6F0;
	case 3:
		goto loc_82B2C708;
	case 4:
		goto loc_82B2C76C;
	case 5:
		goto loc_82B2C788;
	case 6:
		goto loc_82B2C7C8;
	case 7:
		goto loc_82B2C86C;
	case 8:
		goto loc_82B2C8E8;
	case 9:
		goto loc_82B2C938;
	case 10:
		goto loc_82B2C998;
	case 11:
		goto loc_82B2C9CC;
	case 12:
		goto loc_82B2CA10;
	case 13:
		goto loc_82B2CA40;
	case 14:
		goto loc_82B2CA6C;
	case 15:
		goto loc_82B2CA98;
	case 16:
		goto loc_82B2CACC;
	case 17:
		goto loc_82B2C85C;
	case 18:
		goto loc_82B2C86C;
	default:
		__builtin_unreachable();
	}
loc_82B2C6A4:
	// lwz r11,21572(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21572);
	// lfs f0,21588(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 21588);
	ctx.f0.f64 = double(temp.f32);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x82b2caf0
	goto loc_82B2CAF0;
loc_82B2C6C4:
	// lwz r11,21572(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21572);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// clrldi r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// lfs f0,21584(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 21584);
	ctx.f0.f64 = double(temp.f32);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f1,f0,f13
	ctx.f1.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// b 0x82b2caf0
	goto loc_82B2CAF0;
loc_82B2C6F0:
	// lwz r11,16560(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16560);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
loc_82B2C6FC:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(ctx.f0.f64));
	// b 0x82b2caf0
	goto loc_82B2CAF0;
loc_82B2C708:
	// lwz r11,21608(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21608);
	// lwz r10,21572(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21572);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
loc_82B2C720:
	// fcfid f13,f13
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fdivs f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
loc_82B2C734:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,-27592(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -27592);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f12,-13892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f12
	ctx.cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// bge cr6,0x82b2c758
	if (!ctx.cr6.lt) goto loc_82B2C758;
	// fmr f0,f12
	ctx.f0.f64 = ctx.f12.f64;
	// b 0x82b2c764
	goto loc_82B2C764;
loc_82B2C758:
	// fcmpu cr6,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bgt cr6,0x82b2c764
	if (ctx.cr6.gt) goto loc_82B2C764;
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
loc_82B2C764:
	// fmr f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f0.f64;
	// b 0x82b2caf0
	goto loc_82B2CAF0;
loc_82B2C76C:
	// lwz r11,21612(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21612);
	// lwz r10,21572(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21572);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// b 0x82b2c720
	goto loc_82B2C720;
loc_82B2C788:
	// lwz r11,21572(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21572);
	// lwz r10,21612(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21612);
	// lwz r9,21608(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21608);
	// subf r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f0.f64));
	// b 0x82b2c734
	goto loc_82B2C734;
loc_82B2C7C8:
	// lwz r11,21616(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21616);
	// lwz r10,10896(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10896);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// addi r7,r11,-1
	ctx.r7.s64 = ctx.r11.s64 + -1;
	// clrlwi r9,r9,29
	ctx.r9.u64 = ctx.r9.u32 & 0x7;
	// clrlwi r8,r11,29
	ctx.r8.u64 = ctx.r11.u32 & 0x7;
	// addi r6,r9,16
	ctx.r6.s64 = ctx.r9.s64 + 16;
	// clrlwi r9,r7,29
	ctx.r9.u64 = ctx.r7.u32 & 0x7;
	// addi r8,r8,16
	ctx.r8.s64 = ctx.r8.s64 + 16;
	// addi r9,r9,16
	ctx.r9.s64 = ctx.r9.s64 + 16;
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwbrx r31,r7,r10
	ctx.r31.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32));
	// lwbrx r8,r8,r10
	ctx.r8.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32));
	// lwbrx r30,r9,r10
	ctx.r30.u64 = __builtin_bswap32(PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32));
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// beq cr6,0x82b2caec
	if (ctx.cr6.eq) goto loc_82B2CAEC;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// stw r11,21616(r3)
	PPC_STORE_U32(ctx.r3.u32 + 21616, ctx.r11.u32);
	// beq cr6,0x82b2caec
	if (ctx.cr6.eq) goto loc_82B2CAEC;
	// cmpldi cr6,r30,0
	ctx.cr6.compare<uint64_t>(ctx.r30.u64, 0, ctx.xer);
	// beq cr6,0x82b2caec
	if (ctx.cr6.eq) goto loc_82B2CAEC;
	// li r11,1
	ctx.r11.s64 = 1;
	// cmpld cr6,r10,r30
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, ctx.r30.u64, ctx.xer);
	// rldicr r11,r11,32,63
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// bgt cr6,0x82b2c840
	if (ctx.cr6.gt) goto loc_82B2C840;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
loc_82B2C840:
	// cmpld cr6,r31,r10
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, ctx.r10.u64, ctx.xer);
	// bgt cr6,0x82b2c84c
	if (ctx.cr6.gt) goto loc_82B2C84C;
	// add r31,r31,r11
	ctx.r31.u64 = ctx.r31.u64 + ctx.r11.u64;
loc_82B2C84C:
	// subf r3,r10,r31
	ctx.r3.s64 = ctx.r31.s64 - ctx.r10.s64;
	// bl 0x82e2f000
	ctx.lr = 0x82B2C854;
	sub_82E2F000(ctx, base);
	// subf r3,r30,r31
	ctx.r3.s64 = ctx.r31.s64 - ctx.r30.s64;
	// b 0x82b2c924
	goto loc_82B2C924;
loc_82B2C85C:
	// lwz r11,21668(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 21668);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// b 0x82b2c6fc
	goto loc_82B2C6FC;
loc_82B2C86C:
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2C870;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// cmpwi cr6,r31,7
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 7, ctx.xer);
	// addi r11,r11,27988
	ctx.r11.s64 = ctx.r11.s64 + 27988;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// subf r30,r10,r9
	ctx.r30.s64 = ctx.r9.s64 - ctx.r10.s64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// ld r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 12);
	// ld r11,492(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 492);
	// subf r3,r10,r11
	ctx.r3.s64 = ctx.r11.s64 - ctx.r10.s64;
	// bne cr6,0x82b2c8b8
	if (!ctx.cr6.eq) goto loc_82B2C8B8;
	// ld r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// subf r3,r11,r3
	ctx.r3.s64 = ctx.r3.s64 - ctx.r11.s64;
loc_82B2C8B8:
	// cmpldi cr6,r3,0
	ctx.cr6.compare<uint64_t>(ctx.r3.u64, 0, ctx.xer);
	// beq cr6,0x82b2caec
	if (ctx.cr6.eq) goto loc_82B2CAEC;
	// bl 0x82e2f000
	ctx.lr = 0x82B2C8C4;
	sub_82E2F000(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// bl 0x82e2f000
	ctx.lr = 0x82B2C8D0;
	sub_82E2F000(ctx, base);
	// fdiv f0,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64 / ctx.f1.f64;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,-13896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// b 0x82b2c734
	goto loc_82B2C734;
loc_82B2C8E8:
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2C8EC;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r11,r11,27988
	ctx.r11.s64 = ctx.r11.s64 + 27988;
	// ld r10,124(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 124);
	// ld r9,604(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 604);
	// subf r31,r10,r9
	ctx.r31.s64 = ctx.r9.s64 - ctx.r10.s64;
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// beq cr6,0x82b2caec
	if (ctx.cr6.eq) goto loc_82B2CAEC;
	// ld r10,132(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 132);
	// ld r11,612(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 612);
loc_82B2C918:
	// subf r3,r10,r11
	ctx.r3.s64 = ctx.r11.s64 - ctx.r10.s64;
	// bl 0x82e2f000
	ctx.lr = 0x82B2C920;
	sub_82E2F000(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82B2C924:
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// bl 0x82e2f000
	ctx.lr = 0x82B2C92C;
	sub_82E2F000(ctx, base);
	// fdiv f0,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64 / ctx.f1.f64;
loc_82B2C930:
	// frsp f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// b 0x82b2c734
	goto loc_82B2C734;
loc_82B2C938:
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2C93C;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r31,r11,27988
	ctx.r31.s64 = ctx.r11.s64 + 27988;
	// ld r11,124(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 124);
	// ld r10,604(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 604);
	// subf r3,r11,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r11.s64;
	// cmpldi cr6,r3,0
	ctx.cr6.compare<uint64_t>(ctx.r3.u64, 0, ctx.xer);
	// beq cr6,0x82b2caec
	if (ctx.cr6.eq) goto loc_82B2CAEC;
	// bl 0x82e2f000
	ctx.lr = 0x82B2C964;
	sub_82E2F000(ctx, base);
	// ld r11,132(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 132);
	// ld r10,612(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 612);
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// subf r3,r11,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r11.s64;
	// bl 0x82e2f000
	ctx.lr = 0x82B2C978;
	sub_82E2F000(ctx, base);
	// ld r11,140(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 140);
	// ld r10,620(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 620);
	// fsub f30,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f31.f64 - ctx.f1.f64;
	// subf r3,r11,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r11.s64;
	// bl 0x82e2f000
	ctx.lr = 0x82B2C98C;
	sub_82E2F000(ctx, base);
	// fsub f0,f30,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f30.f64 - ctx.f1.f64;
	// fdiv f0,f0,f31
	ctx.f0.f64 = ctx.f0.f64 / ctx.f31.f64;
	// b 0x82b2c930
	goto loc_82B2C930;
loc_82B2C998:
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2C99C;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r11,r11,27988
	ctx.r11.s64 = ctx.r11.s64 + 27988;
	// ld r10,124(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 124);
	// ld r9,604(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 604);
	// subf r31,r10,r9
	ctx.r31.s64 = ctx.r9.s64 - ctx.r10.s64;
	// cmpldi cr6,r31,0
	ctx.cr6.compare<uint64_t>(ctx.r31.u64, 0, ctx.xer);
	// beq cr6,0x82b2caec
	if (ctx.cr6.eq) goto loc_82B2CAEC;
	// ld r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 140);
	// ld r11,620(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 620);
	// b 0x82b2c918
	goto loc_82B2C918;
loc_82B2C9CC:
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2C9D0;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r11,r11,27988
	ctx.r11.s64 = ctx.r11.s64 + 27988;
	// ld r10,444(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 444);
	// ld r9,924(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 924);
	// subf r8,r10,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// subf r4,r10,r9
	ctx.r4.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,436(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 436);
	// ld r11,916(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 916);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + ctx.r11.u64;
loc_82B2CA08:
	// bl 0x82b2bf60
	ctx.lr = 0x82B2CA0C;
	sub_82B2BF60(ctx, base);
	// b 0x82b2caf0
	goto loc_82B2CAF0;
loc_82B2CA10:
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2CA14;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r11,r11,27988
	ctx.r11.s64 = ctx.r11.s64 + 27988;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// subf r4,r10,r9
	ctx.r4.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,452(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 452);
	// ld r11,932(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 932);
loc_82B2CA38:
	// subf r3,r10,r11
	ctx.r3.s64 = ctx.r11.s64 - ctx.r10.s64;
	// b 0x82b2ca08
	goto loc_82B2CA08;
loc_82B2CA40:
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2CA44;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r11,r11,27988
	ctx.r11.s64 = ctx.r11.s64 + 27988;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// subf r4,r10,r9
	ctx.r4.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,236(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 236);
	// ld r11,716(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 716);
	// b 0x82b2ca38
	goto loc_82B2CA38;
loc_82B2CA6C:
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2CA70;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r11,r11,27988
	ctx.r11.s64 = ctx.r11.s64 + 27988;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r9,484(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// subf r4,r10,r9
	ctx.r4.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,92(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 92);
	// ld r11,572(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 572);
	// b 0x82b2ca38
	goto loc_82B2CA38;
loc_82B2CA98:
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2CA9C;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r11,r11,27988
	ctx.r11.s64 = ctx.r11.s64 + 27988;
	// ld r10,460(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 460);
	// ld r9,940(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 940);
loc_82B2CAB4:
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// ld r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 4);
	// ld r11,484(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 484);
	// rldicr r3,r9,1,62
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r9.u64, 1) & 0xFFFFFFFFFFFFFFFE;
	// subf r4,r10,r11
	ctx.r4.s64 = ctx.r11.s64 - ctx.r10.s64;
	// b 0x82b2ca08
	goto loc_82B2CA08;
loc_82B2CACC:
	// bl 0x82b2c0e0
	ctx.lr = 0x82B2CAD0;
	sub_82B2C0E0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2caec
	if (ctx.cr0.eq) goto loc_82B2CAEC;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r11,r11,27988
	ctx.r11.s64 = ctx.r11.s64 + 27988;
	// ld r10,468(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 468);
	// ld r9,948(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 948);
	// b 0x82b2cab4
	goto loc_82B2CAB4;
loc_82B2CAEC:
	// lfs f1,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
loc_82B2CAF0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f30,-40(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// lfd f31,-32(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2CB10"))) PPC_WEAK_FUNC(sub_82B2CB10);
PPC_FUNC_IMPL(__imp__sub_82B2CB10) {
	PPC_FUNC_PROLOGUE();
	// b 0x82b1dd70
	sub_82B1DD70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2CB18"))) PPC_WEAK_FUNC(sub_82B2CB18);
PPC_FUNC_IMPL(__imp__sub_82B2CB18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82f661e8
	ctx.lr = 0x82B2CB34;
	sub_82F661E8(ctx, base);
	// rlwinm. r11,r3,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2cb44
	if (ctx.cr0.eq) goto loc_82B2CB44;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b2c1f8
	ctx.lr = 0x82B2CB44;
	sub_82B2C1F8(ctx, base);
loc_82B2CB44:
	// li r5,40
	ctx.r5.s64 = 40;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x82e29500
	ctx.lr = 0x82B2CB54;
	sub_82E29500(ctx, base);
	// lis r11,-32077
	ctx.r11.s64 = -2102198272;
	// lbz r10,10943(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10943);
	// lis r30,-32256
	ctx.r30.s64 = -2113929216;
	// lwz r9,16560(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16560);
	// addi r11,r11,-13552
	ctx.r11.s64 = ctx.r11.s64 + -13552;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// li r9,6534
	ctx.r9.s64 = 6534;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r10,10943(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10943, ctx.r10.u8);
	// lwz r10,2332(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2332);
	// stw r3,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r3.u32);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2cbbc
	if (ctx.cr0.eq) goto loc_82B2CBBC;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,82
	ctx.r3.s64 = 82;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2CBB8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r10,2332(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2332);
loc_82B2CBBC:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82b2cc14
	if (!ctx.cr6.eq) goto loc_82B2CC14;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2020(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2020);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82b2cbf4
	if (ctx.cr6.eq) goto loc_82B2CBF4;
	// rotlwi r11,r9,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2cc14
	if (ctx.cr0.eq) goto loc_82B2CC14;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2cc14
	if (ctx.cr0.eq) goto loc_82B2CC14;
	// b 0x82b2cc04
	goto loc_82B2CC04;
loc_82B2CBF4:
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2cc14
	if (ctx.cr0.eq) goto loc_82B2CC14;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82B2CC04:
	// lwz r4,16560(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16560);
	// li r3,46
	ctx.r3.s64 = 46;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2CC14;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B2CC14:
	// lbz r11,10943(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10943);
	// andi. r11,r11,253
	ctx.r11.u64 = ctx.r11.u64 & 253;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stb r11,10943(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10943, ctx.r11.u8);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2CC38"))) PPC_WEAK_FUNC(sub_82B2CC38);
PPC_FUNC_IMPL(__imp__sub_82B2CC38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B2CC40;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2016(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2016);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b2cdf0
	if (ctx.cr6.eq) goto loc_82B2CDF0;
	// rotlwi r31,r10,0
	ctx.r31.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b2cdf0
	if (ctx.cr6.eq) goto loc_82B2CDF0;
	// ld r11,10880(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 10880);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82b2cdf0
	if (ctx.cr6.eq) goto loc_82B2CDF0;
	// cmplwi cr6,r3,34
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 34, ctx.xer);
	// bgt cr6,0x82b2cd14
	if (ctx.cr6.gt) goto loc_82B2CD14;
	// beq cr6,0x82b2cd0c
	if (ctx.cr6.eq) goto loc_82B2CD0C;
	// cmplwi cr6,r3,1
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 1, ctx.xer);
	// blt cr6,0x82b2ccfc
	if (ctx.cr6.lt) goto loc_82B2CCFC;
	// beq cr6,0x82b2ccfc
	if (ctx.cr6.eq) goto loc_82B2CCFC;
	// cmplwi cr6,r3,16
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 16, ctx.xer);
	// beq cr6,0x82b2ccd0
	if (ctx.cr6.eq) goto loc_82B2CCD0;
	// cmplwi cr6,r3,17
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 17, ctx.xer);
	// bne cr6,0x82b2cdf0
	if (!ctx.cr6.eq) goto loc_82B2CDF0;
	// li r9,1
	ctx.r9.s64 = 1;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// cmplwi cr6,r4,6
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 6, ctx.xer);
	// lwz r10,28992(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28992);
	// slw r8,r9,r4
	ctx.r8.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r4.u8 & 0x3F));
	// or r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 | ctx.r10.u64;
	// stw r10,28992(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28992, ctx.r10.u32);
	// bne cr6,0x82b2cdf0
	if (!ctx.cr6.eq) goto loc_82B2CDF0;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r9,21624(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21624, ctx.r9.u32);
	// stw r11,21616(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21616, ctx.r11.u32);
	// stw r11,21620(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21620, ctx.r11.u32);
	// b 0x82b2cdf0
	goto loc_82B2CDF0;
loc_82B2CCD0:
	// li r11,1
	ctx.r11.s64 = 1;
	// cmplwi cr6,r4,6
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 6, ctx.xer);
	// slw r9,r11,r4
	ctx.r9.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r11.u32 << (ctx.r4.u8 & 0x3F));
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// lwz r10,28992(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28992);
	// andc r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r9.u64;
	// stw r10,28992(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28992, ctx.r10.u32);
	// bne cr6,0x82b2cdf0
	if (!ctx.cr6.eq) goto loc_82B2CDF0;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82B2CCF4:
	// stw r11,21624(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21624, ctx.r11.u32);
	// b 0x82b2cdf0
	goto loc_82B2CDF0;
loc_82B2CCFC:
	// li r11,0
	ctx.r11.s64 = 0;
	// lis r10,-31967
	ctx.r10.s64 = -2094989312;
	// stw r11,28992(r10)
	PPC_STORE_U32(ctx.r10.u32 + 28992, ctx.r11.u32);
	// b 0x82b2ccf4
	goto loc_82B2CCF4;
loc_82B2CD0C:
	// stw r4,21676(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21676, ctx.r4.u32);
	// b 0x82b2cdf0
	goto loc_82B2CDF0;
loc_82B2CD14:
	// cmplwi cr6,r3,224
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 224, ctx.xer);
	// beq cr6,0x82b2cdb8
	if (ctx.cr6.eq) goto loc_82B2CDB8;
	// cmplwi cr6,r3,225
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 225, ctx.xer);
	// beq cr6,0x82b2cdb8
	if (ctx.cr6.eq) goto loc_82B2CDB8;
	// cmplwi cr6,r3,226
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 226, ctx.xer);
	// beq cr6,0x82b2cdb8
	if (ctx.cr6.eq) goto loc_82B2CDB8;
	// cmplwi cr6,r3,255
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 255, ctx.xer);
	// bne cr6,0x82b2cdf0
	if (!ctx.cr6.eq) goto loc_82B2CDF0;
	// lis r28,-31967
	ctx.r28.s64 = -2094989312;
	// lwz r11,28992(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28992);
	// clrlwi. r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2cd74
	if (ctx.cr0.eq) goto loc_82B2CD74;
	// lwz r11,21572(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21572);
	// lfs f0,21588(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 21588);
	ctx.f0.f64 = double(temp.f32);
	// lis r3,2
	ctx.r3.s64 = 131072;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f0,-18448(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18448);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x82f660f0
	ctx.lr = 0x82B2CD74;
	sub_82F660F0(ctx, base);
loc_82B2CD74:
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// li r29,17
	ctx.r29.s64 = 17;
	// addi r11,r11,-28672
	ctx.r11.s64 = ctx.r11.s64 + -28672;
	// addi r30,r11,8
	ctx.r30.s64 = ctx.r11.s64 + 8;
loc_82B2CD84:
	// lwz r11,-8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -8);
	// lwz r10,28992(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28992);
	// and. r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ctx.r10.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2cda8
	if (ctx.cr0.eq) goto loc_82B2CDA8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82b2c648
	ctx.lr = 0x82B2CDA0;
	sub_82B2C648(ctx, base);
	// lwz r3,-4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -4);
	// bl 0x82f660f0
	ctx.lr = 0x82B2CDA8;
	sub_82F660F0(ctx, base);
loc_82B2CDA8:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r30,r30,12
	ctx.r30.s64 = ctx.r30.s64 + 12;
	// bne 0x82b2cd84
	if (!ctx.cr0.eq) goto loc_82B2CD84;
	// b 0x82b2cdf0
	goto loc_82B2CDF0;
loc_82B2CDB8:
	// lwz r11,21532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21532);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b2cdf0
	if (ctx.cr6.eq) goto loc_82B2CDF0;
	// bl 0x82b076f0
	ctx.lr = 0x82B2CDC8;
	sub_82B076F0(ctx, base);
	// lwz r11,10888(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10888);
	// cmplw cr6,r11,r3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r3.u32, ctx.xer);
	// bne cr6,0x82b2cdf0
	if (!ctx.cr6.eq) goto loc_82B2CDF0;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b2cdec
	if (!ctx.cr6.gt) goto loc_82B2CDEC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B2CDEC;
	sub_82B1DAE8(ctx, base);
loc_82B2CDEC:
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
loc_82B2CDF0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2CDF8"))) PPC_WEAK_FUNC(sub_82B2CDF8);
PPC_FUNC_IMPL(__imp__sub_82B2CDF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lis r31,-32256
	ctx.r31.s64 = -2113929216;
	// lwz r11,2020(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2020);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b2ce44
	if (ctx.cr6.eq) goto loc_82B2CE44;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2ce6c
	if (ctx.cr0.eq) goto loc_82B2CE6C;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2ce6c
	if (ctx.cr0.eq) goto loc_82B2CE6C;
	// b 0x82b2ce58
	goto loc_82B2CE58;
loc_82B2CE44:
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2ce6c
	if (ctx.cr0.eq) goto loc_82B2CE6C;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82B2CE58:
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// li r3,28
	ctx.r3.s64 = 28;
	// addi r4,r10,-16328
	ctx.r4.s64 = ctx.r10.s64 + -16328;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2CE6C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B2CE6C:
	// lis r11,-32077
	ctx.r11.s64 = -2102198272;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r30.u32);
	// addi r11,r11,-16560
	ctx.r11.s64 = ctx.r11.s64 + -16560;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2cea0
	if (ctx.cr0.eq) goto loc_82B2CEA0;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,66
	ctx.r3.s64 = 66;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2CEA0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B2CEA0:
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2cec8
	if (ctx.cr0.eq) goto loc_82B2CEC8;
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// li r3,89
	ctx.r3.s64 = 89;
	// addi r4,r10,-13256
	ctx.r4.s64 = ctx.r10.s64 + -13256;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2CEC8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B2CEC8:
	// li r11,0
	ctx.r11.s64 = 0;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,21616(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21616, ctx.r11.u32);
	// stw r11,21620(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21620, ctx.r11.u32);
	// stw r10,21624(r30)
	PPC_STORE_U32(ctx.r30.u32 + 21624, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2CEF8"))) PPC_WEAK_FUNC(sub_82B2CEF8);
PPC_FUNC_IMPL(__imp__sub_82B2CEF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32256
	ctx.r31.s64 = -2113929216;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82b2cf3c
	if (ctx.cr0.eq) goto loc_82B2CF3C;
	// lwz r11,24(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,28
	ctx.r3.s64 = 28;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2CF38;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
loc_82B2CF3C:
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r30.u32);
	// addi r10,r10,-16560
	ctx.r10.s64 = ctx.r10.s64 + -16560;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82b2cf70
	if (ctx.cr0.eq) goto loc_82B2CF70;
	// lwz r11,24(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,65
	ctx.r3.s64 = 65;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2CF6C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,2332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2332);
loc_82B2CF70:
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2cf94
	if (ctx.cr0.eq) goto loc_82B2CF94;
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// li r3,90
	ctx.r3.s64 = 90;
	// addi r4,r10,-13256
	ctx.r4.s64 = ctx.r10.s64 + -13256;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2CF94;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B2CF94:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2CFB0"))) PPC_WEAK_FUNC(sub_82B2CFB0);
PPC_FUNC_IMPL(__imp__sub_82B2CFB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b2cfe4
	if (!ctx.cr6.gt) goto loc_82B2CFE4;
	// bl 0x82b1dae8
	ctx.lr = 0x82B2CFE0;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B2CFE4:
	// lis r10,-16382
	ctx.r10.s64 = -1073610752;
	// ori r9,r10,22528
	ctx.r9.u64 = ctx.r10.u64 | 22528;
	// lis r10,-32768
	ctx.r10.s64 = -2147483648;
	// ori r8,r10,3
	ctx.r8.u64 = ctx.r10.u64 | 3;
	// rlwinm r10,r30,12,20,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 12) & 0xFFF;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// clrlwi r9,r30,3
	ctx.r9.u64 = ctx.r30.u32 & 0x1FFFFFFF;
	// addi r10,r10,512
	ctx.r10.s64 = ctx.r10.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// lis r9,-8531
	ctx.r9.s64 = -559087616;
	// ori r9,r9,48879
	ctx.r9.u64 = ctx.r9.u64 | 48879;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2D040"))) PPC_WEAK_FUNC(sub_82B2D040);
PPC_FUNC_IMPL(__imp__sub_82B2D040) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,70
	ctx.r4.s64 = 70;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82b1dd08
	ctx.lr = 0x82B2D05C;
	sub_82B1DD08(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b2d068
	if (ctx.cr0.eq) goto loc_82B2D068;
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
loc_82B2D068:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2D080"))) PPC_WEAK_FUNC(sub_82B2D080);
PPC_FUNC_IMPL(__imp__sub_82B2D080) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,21652(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21652);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bne cr6,0x82b2d144
	if (!ctx.cr6.eq) goto loc_82B2D144;
	// lwz r11,21660(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21660);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bne cr6,0x82b2d0b8
	if (!ctx.cr6.eq) goto loc_82B2D0B8;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82b2d0bc
	goto loc_82B2D0BC;
loc_82B2D0B8:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82B2D0BC:
	// lwz r10,21656(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21656);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b2d144
	if (ctx.cr6.eq) goto loc_82B2D144;
	// rlwinm r30,r11,1,0,30
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// bne cr6,0x82b2d0d8
	if (!ctx.cr6.eq) goto loc_82B2D0D8;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82B2D0D8:
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b2d0f4
	if (!ctx.cr6.gt) goto loc_82B2D0F4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B2D0F0;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B2D0F4:
	// lis r10,-16382
	ctx.r10.s64 = -1073610752;
	// lis r9,-32768
	ctx.r9.s64 = -2147483648;
	// ori r10,r10,22528
	ctx.r10.u64 = ctx.r10.u64 | 22528;
	// ori r8,r9,3
	ctx.r8.u64 = ctx.r9.u64 | 3;
	// rlwinm r9,r30,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r7,-8531
	ctx.r7.s64 = -559087616;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// ori r7,r7,48879
	ctx.r7.u64 = ctx.r7.u64 | 48879;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// lwz r10,21648(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21648);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r8,r10,12,20,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFF;
	// clrlwi r9,r10,3
	ctx.r9.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// addi r10,r8,512
	ctx.r10.s64 = ctx.r8.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
loc_82B2D144:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2D160"))) PPC_WEAK_FUNC(sub_82B2D160);
PPC_FUNC_IMPL(__imp__sub_82B2D160) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B2D168;
	__savegprlr_28(ctx, base);
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// lwz r9,16720(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16720);
	// rlwinm. r11,r9,0,21,21
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x400;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2d330
	if (ctx.cr0.eq) goto loc_82B2D330;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2d19c
	if (ctx.cr0.eq) goto loc_82B2D19C;
	// lwz r11,32(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// b 0x82b2d1a0
	goto loc_82B2D1A0;
loc_82B2D19C:
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
loc_82B2D1A0:
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2D1AC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,16724(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16724, ctx.r3.u32);
loc_82B2D1B0:
	// stw r28,16720(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16720, ctx.r28.u32);
loc_82B2D1B4:
	// lwz r11,21580(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21580);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// lwz r11,21576(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21576);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// mftb r11
	ctx.r11.u64 = __rdtsc();
	// ld r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// cmpdi cr6,r10,0
	ctx.cr6.compare<int64_t>(ctx.r10.s64, 0, ctx.xer);
	// beq cr6,0x82b2d1e8
	if (ctx.cr6.eq) goto loc_82B2D1E8;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// stw r11,21572(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21572, ctx.r11.u32);
loc_82B2D1E8:
	// ld r9,21592(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 21592);
	// ld r7,21600(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 21600);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,21652(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21652);
	// std r28,21592(r31)
	PPC_STORE_U64(ctx.r31.u32 + 21592, ctx.r28.u64);
	// stw r9,21608(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21608, ctx.r9.u32);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// stw r10,21580(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21580, ctx.r10.u32);
	// stw r8,21576(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21576, ctx.r8.u32);
	// stw r7,21612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21612, ctx.r7.u32);
	// std r28,21600(r31)
	PPC_STORE_U64(ctx.r31.u32 + 21600, ctx.r28.u64);
	// bne cr6,0x82b2d394
	if (!ctx.cr6.eq) goto loc_82B2D394;
	// li r5,240
	ctx.r5.s64 = 240;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82e29500
	ctx.lr = 0x82B2D22C;
	sub_82E29500(ctx, base);
	// lbz r11,10942(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10942);
	// stw r28,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r28.u32);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// li r11,8
	ctx.r11.s64 = 8;
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r11.u32);
	// li r11,13
	ctx.r11.s64 = 13;
	// stw r11,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r11.u32);
	// li r11,37
	ctx.r11.s64 = 37;
	// stw r11,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r11.u32);
	// li r11,19
	ctx.r11.s64 = 19;
	// stw r11,312(r1)
	PPC_STORE_U32(ctx.r1.u32 + 312, ctx.r11.u32);
	// stw r11,316(r1)
	PPC_STORE_U32(ctx.r1.u32 + 316, ctx.r11.u32);
	// li r11,6
	ctx.r11.s64 = 6;
	// stw r11,320(r1)
	PPC_STORE_U32(ctx.r1.u32 + 320, ctx.r11.u32);
	// li r11,25
	ctx.r11.s64 = 25;
	// stw r11,324(r1)
	PPC_STORE_U32(ctx.r1.u32 + 324, ctx.r11.u32);
	// li r11,26
	ctx.r11.s64 = 26;
	// stw r11,328(r1)
	PPC_STORE_U32(ctx.r1.u32 + 328, ctx.r11.u32);
	// li r11,200
	ctx.r11.s64 = 200;
	// stw r11,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r11.u32);
	// li r11,30
	ctx.r11.s64 = 30;
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r11.u32);
	// bne 0x82b2d29c
	if (!ctx.cr0.eq) goto loc_82B2D29C;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b10560
	ctx.lr = 0x82B2D29C;
	sub_82B10560(ctx, base);
loc_82B2D29C:
	// lwz r11,21628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21628);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2d2b8
	if (!ctx.cr6.eq) goto loc_82B2D2B8;
	// lis r4,-23680
	ctx.r4.s64 = -1551892480;
	// li r3,1952
	ctx.r3.s64 = 1952;
	// bl 0x82547910
	ctx.lr = 0x82B2D2B4;
	sub_82547910(ctx, base);
	// stw r3,21628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21628, ctx.r3.u32);
loc_82B2D2B8:
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// addi r29,r31,21632
	ctx.r29.s64 = ctx.r31.s64 + 21632;
loc_82B2D2C0:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b2d2e4
	if (!ctx.cr6.eq) goto loc_82B2D2E4;
	// lwz r11,21628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21628);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r5,r11,r30
	ctx.r5.u64 = ctx.r11.u64 + ctx.r30.u64;
	// bl 0x82b10648
	ctx.lr = 0x82B2D2E0;
	sub_82B10648(ctx, base);
	// stw r3,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r3.u32);
loc_82B2D2E4:
	// addi r30,r30,480
	ctx.r30.s64 = ctx.r30.s64 + 480;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// cmpwi cr6,r30,1920
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 1920, ctx.xer);
	// blt cr6,0x82b2d2c0
	if (ctx.cr6.lt) goto loc_82B2D2C0;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b106e0
	ctx.lr = 0x82B2D304;
	sub_82B106E0(ctx, base);
	// lwz r11,21648(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21648);
	// stw r28,21656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21656, ctx.r28.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r28,21660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21660, ctx.r28.u32);
	// bne cr6,0x82b2d324
	if (!ctx.cr6.eq) goto loc_82B2D324;
	// lwz r11,21628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21628);
	// addi r11,r11,1920
	ctx.r11.s64 = ctx.r11.s64 + 1920;
	// stw r11,21648(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21648, ctx.r11.u32);
loc_82B2D324:
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r11,21652(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21652, ctx.r11.u32);
	// b 0x82b2d3f0
	goto loc_82B2D3F0;
loc_82B2D330:
	// rlwinm. r11,r9,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b2d1b4
	if (ctx.cr0.eq) goto loc_82B2D1B4;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2d354
	if (ctx.cr0.eq) goto loc_82B2D354;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// b 0x82b2d358
	goto loc_82B2D358;
loc_82B2D354:
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
loc_82B2D358:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// rlwinm r4,r9,20,4,11
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 20) & 0xFF00000;
	// addi r3,r11,-19000
	ctx.r3.s64 = ctx.r11.s64 + -19000;
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2D370;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// stw r3,16724(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16724, ctx.r3.u32);
	// blt 0x82b2d1b0
	if (ctx.cr0.lt) goto loc_82B2D1B0;
	// lwz r11,16720(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16720);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwimi r11,r10,10,23,23
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 10) & 0x100) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFEFF);
	// rlwimi r11,r10,10,21,21
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 10) & 0x400) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFBFF);
	// stw r11,16720(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16720, ctx.r11.u32);
	// b 0x82b2d1b4
	goto loc_82B2D1B4;
loc_82B2D394:
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bne cr6,0x82b2d3f0
	if (!ctx.cr6.eq) goto loc_82B2D3F0;
	// lbz r11,10942(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10942);
	// clrlwi. r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b2d3b4
	if (!ctx.cr0.eq) goto loc_82B2D3B4;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b10560
	ctx.lr = 0x82B2D3B4;
	sub_82B10560(ctx, base);
loc_82B2D3B4:
	// lwz r11,21660(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21660);
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82b2d3c8
	if (ctx.cr6.eq) goto loc_82B2D3C8;
	// addi r30,r11,1
	ctx.r30.s64 = ctx.r11.s64 + 1;
loc_82B2D3C8:
	// lwz r11,21656(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21656);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82b2d3f0
	if (ctx.cr6.eq) goto loc_82B2D3F0;
	// addi r11,r30,5408
	ctx.r11.s64 = ctx.r30.s64 + 5408;
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwzx r4,r11,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// bl 0x82b10df0
	ctx.lr = 0x82B2D3EC;
	sub_82B10DF0(ctx, base);
	// stw r30,21660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 21660, ctx.r30.u32);
loc_82B2D3F0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b2cb18
	ctx.lr = 0x82B2D3F8;
	sub_82B2CB18(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2020(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2020);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2d424
	if (ctx.cr0.eq) goto loc_82B2D424;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2d424
	if (ctx.cr0.eq) goto loc_82B2D424;
	// li r3,0
	ctx.r3.s64 = 0;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2D424;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B2D424:
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2D430"))) PPC_WEAK_FUNC(sub_82B2D430);
PPC_FUNC_IMPL(__imp__sub_82B2D430) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r5,255
	ctx.r5.s64 = 255;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,81
	ctx.r3.s64 = ctx.r1.s64 + 81;
	// stb r11,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r11.u8);
	// bl 0x82e29500
	ctx.lr = 0x82B2D45C;
	sub_82E29500(ctx, base);
	// li r5,256
	ctx.r5.s64 = 256;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82e2ab28
	ctx.lr = 0x82B2D46C;
	sub_82E2AB28(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2d498
	if (ctx.cr0.eq) goto loc_82B2D498;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,84
	ctx.r3.s64 = 84;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2D494;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82b2d49c
	goto loc_82B2D49C;
loc_82B2D498:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B2D49C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b2d4ac
	if (ctx.cr6.eq) goto loc_82B2D4AC;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b2d4b4
	goto loc_82B2D4B4;
loc_82B2D4AC:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_82B2D4B4:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2D4C8"))) PPC_WEAK_FUNC(sub_82B2D4C8);
PPC_FUNC_IMPL(__imp__sub_82B2D4C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B2D4D0;
	__savegprlr_26(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r7,12(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
	// stw r7,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r7.u32);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82b2d53c
	if (!ctx.cr6.eq) goto loc_82B2D53C;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b2d53c
	if (!ctx.cr6.eq) goto loc_82B2D53C;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82b2d53c
	if (!ctx.cr6.eq) goto loc_82B2D53C;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b2d53c
	if (!ctx.cr6.eq) goto loc_82B2D53C;
	// stw r4,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r4.u32);
	// stw r5,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r5.u32);
loc_82B2D53C:
	// lwz r8,88(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// subf r29,r9,r8
	ctx.r29.s64 = ctx.r8.s64 - ctx.r9.s64;
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// bne 0x82b2d560
	if (!ctx.cr0.eq) goto loc_82B2D560;
	// lwz r27,21540(r26)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r26.u32 + 21540);
loc_82B2D560:
	// lwz r30,20(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne 0x82b2d5a8
	if (!ctx.cr0.eq) goto loc_82B2D5A8;
	// lwz r11,13588(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 13588);
	// mullw r9,r27,r29
	ctx.r9.s64 = int64_t(ctx.r27.s32) * int64_t(ctx.r29.s32);
	// divwu r30,r9,r10
	ctx.r30.u32 = ctx.r9.u32 / ctx.r10.u32;
	// twllei r10,0
	// clrlwi. r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b2d5a4
	if (!ctx.cr0.eq) goto loc_82B2D5A4;
	// bl 0x83158344
	ctx.lr = 0x82B2D588;
	__imp__VdQueryVideoFlags(ctx, base);
	// clrlwi. r11,r3,31
	ctx.r11.u64 = ctx.r3.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b2d5a4
	if (!ctx.cr0.eq) goto loc_82B2D5A4;
	// cmplw cr6,r30,r29
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r29.u32, ctx.xer);
	// bgt cr6,0x82b2d5a4
	if (ctx.cr6.gt) goto loc_82B2D5A4;
	// lwz r11,21544(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 21544);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b2d5a8
	if (!ctx.cr6.gt) goto loc_82B2D5A8;
loc_82B2D5A4:
	// lwz r30,21544(r26)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r26.u32 + 21544);
loc_82B2D5A8:
	// li r5,56
	ctx.r5.s64 = 56;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B2D5B8;
	sub_82E28FD0(ctx, base);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// stw r27,16(r28)
	PPC_STORE_U32(ctx.r28.u32 + 16, ctx.r27.u32);
	// stw r30,20(r28)
	PPC_STORE_U32(ctx.r28.u32 + 20, ctx.r30.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r10,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r10.u32);
	// stw r9,4(r28)
	PPC_STORE_U32(ctx.r28.u32 + 4, ctx.r9.u32);
	// stw r8,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r8.u32);
	// stw r11,12(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2D5F0"))) PPC_WEAK_FUNC(sub_82B2D5F0);
PPC_FUNC_IMPL(__imp__sub_82B2D5F0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r11,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r11.u32);
	// lwz r11,8(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// stw r11,8(r5)
	PPC_STORE_U32(ctx.r5.u32 + 8, ctx.r11.u32);
	// lwz r11,12(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// stw r11,12(r5)
	PPC_STORE_U32(ctx.r5.u32 + 12, ctx.r11.u32);
	// lwz r11,16(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// stw r11,16(r5)
	PPC_STORE_U32(ctx.r5.u32 + 16, ctx.r11.u32);
	// lwz r11,20(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// stw r11,20(r5)
	PPC_STORE_U32(ctx.r5.u32 + 20, ctx.r11.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r10,24(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82b2d63c
	if (!ctx.cr6.eq) goto loc_82B2D63C;
	// stw r11,24(r5)
	PPC_STORE_U32(ctx.r5.u32 + 24, ctx.r11.u32);
	// stw r11,40(r5)
	PPC_STORE_U32(ctx.r5.u32 + 40, ctx.r11.u32);
	// b 0x82b2d648
	goto loc_82B2D648;
loc_82B2D63C:
	// li r10,3
	ctx.r10.s64 = 3;
	// stw r10,24(r5)
	PPC_STORE_U32(ctx.r5.u32 + 24, ctx.r10.u32);
	// stw r10,40(r5)
	PPC_STORE_U32(ctx.r5.u32 + 40, ctx.r10.u32);
loc_82B2D648:
	// stw r11,28(r5)
	PPC_STORE_U32(ctx.r5.u32 + 28, ctx.r11.u32);
	// stw r11,32(r5)
	PPC_STORE_U32(ctx.r5.u32 + 32, ctx.r11.u32);
	// stw r11,36(r5)
	PPC_STORE_U32(ctx.r5.u32 + 36, ctx.r11.u32);
	// stw r11,44(r5)
	PPC_STORE_U32(ctx.r5.u32 + 44, ctx.r11.u32);
	// stw r11,48(r5)
	PPC_STORE_U32(ctx.r5.u32 + 48, ctx.r11.u32);
	// stw r11,52(r5)
	PPC_STORE_U32(ctx.r5.u32 + 52, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2D668"))) PPC_WEAK_FUNC(sub_82B2D668);
PPC_FUNC_IMPL(__imp__sub_82B2D668) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B2D670;
	__savegprlr_29(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82b2d4c8
	ctx.lr = 0x82B2D688;
	sub_82B2D4C8(ctx, base);
	// lwz r11,21540(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21540);
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// lwz r10,21544(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21544);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r5,56
	ctx.r5.s64 = 56;
	// sth r30,144(r1)
	PPC_STORE_U16(ctx.r1.u32 + 144, ctx.r30.u16);
	// sth r29,146(r1)
	PPC_STORE_U16(ctx.r1.u32 + 146, ctx.r29.u16);
	// sth r11,148(r1)
	PPC_STORE_U16(ctx.r1.u32 + 148, ctx.r11.u16);
	// sth r10,150(r1)
	PPC_STORE_U16(ctx.r1.u32 + 150, ctx.r10.u16);
	// bl 0x82e28fd0
	ctx.lr = 0x82B2D6B0;
	sub_82E28FD0(ctx, base);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x83158354
	ctx.lr = 0x82B2D6BC;
	__imp__VdCallGraphicsNotificationRoutines(ctx, base);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2D6C8"))) PPC_WEAK_FUNC(sub_82B2D6C8);
PPC_FUNC_IMPL(__imp__sub_82B2D6C8) {
	PPC_FUNC_PROLOGUE();
	// vrfim v11,v1
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v11.f32, _mm_round_ps(_mm_load_ps(ctx.v1.f32), _MM_FROUND_TO_NEG_INF | _MM_FROUND_NO_EXC));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r11,r11,-18960
	ctx.r11.s64 = ctx.r11.s64 + -18960;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// vspltw v12,v0,0
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vspltw v10,v0,1
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// addi r11,r11,-18976
	ctx.r11.s64 = ctx.r11.s64 + -18976;
	// vspltw v7,v0,2
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// vspltw v5,v0,3
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x0));
	// vsubfp v0,v1,v11
	_mm_store_ps(ctx.v0.f32, _mm_sub_ps(_mm_load_ps(ctx.v1.f32), _mm_load_ps(ctx.v11.f32)));
	// vexptefp v11,v11
	ctx.v11.f32[0] = exp2f(ctx.v11.f32[0]);
	ctx.v11.f32[1] = exp2f(ctx.v11.f32[1]);
	ctx.v11.f32[2] = exp2f(ctx.v11.f32[2]);
	ctx.v11.f32[3] = exp2f(ctx.v11.f32[3]);
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v8,v13,1
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xAA));
	// vspltw v9,v13,0
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vspltw v6,v13,2
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x55));
	// vspltw v4,v13,3
	_mm_store_si128((__m128i*)ctx.v4.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x0));
	// vmaddfp v10,v0,v10,v12
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v12.f32)));
	// vmulfp128 v13,v0,v0
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v9,v0,v8,v9
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v9.f32)));
	// vmulfp128 v0,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v10,v13,v7,v10
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v7.f32)), _mm_load_ps(ctx.v10.f32)));
	// vmaddfp v9,v13,v6,v9
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v6.f32)), _mm_load_ps(ctx.v9.f32)));
	// vmulfp128 v13,v13,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v10,v0,v5,v10
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v5.f32)), _mm_load_ps(ctx.v10.f32)));
	// vmaddfp v0,v0,v4,v9
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v4.f32)), _mm_load_ps(ctx.v9.f32)));
	// vmaddfp v0,v13,v0,v10
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v10.f32)));
	// vor v13,v0,v0
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vor v10,v0,v0
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vrefp v0,v0
	_mm_store_ps(ctx.v0.f32, _mm_div_ps(_mm_set1_ps(1), _mm_load_ps(ctx.v0.f32)));
	// vnmsubfp v13,v13,v0,v12
	_mm_store_ps(ctx.v13.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v12.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vor v8,v0,v0
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vmaddfp v0,v0,v13,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)), _mm_load_ps(ctx.v0.f32)));
	// vnmsubfp v13,v10,v0,v12
	_mm_store_ps(ctx.v13.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v12.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vcmpeqfp v12,v0,v0
	_mm_store_ps(ctx.v12.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v0,v0,v13,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)), _mm_load_ps(ctx.v0.f32)));
	// vsel v0,v8,v0,v12
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v8.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8))));
	// vmulfp128 v1,v11,v0
	_mm_store_ps(ctx.v1.f32, _mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2D768"))) PPC_WEAK_FUNC(sub_82B2D768);
PPC_FUNC_IMPL(__imp__sub_82B2D768) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,292
	ctx.r11.s64 = 19136512;
	// stfs f1,-48(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -48, temp.u32);
	// addi r9,r1,-48
	ctx.r9.s64 = ctx.r1.s64 + -48;
	// ori r10,r11,16237
	ctx.r10.u64 = ctx.r11.u64 | 16237;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,-18472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18472);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f13,-13896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// stfs f13,-32(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -32, temp.u32);
	// addi r11,r11,-30032
	ctx.r11.s64 = ctx.r11.s64 + -30032;
	// lvx128 v12,r0,r11
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// addi r11,r11,-30016
	ctx.r11.s64 = ctx.r11.s64 + -30016;
	// lvx128 v11,r0,r11
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// addi r11,r11,-30048
	ctx.r11.s64 = ctx.r11.s64 + -30048;
	// lvx128 v10,r0,r11
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lwz r11,-48(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -48);
	// rlwimi r11,r10,30,1,31
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 30) & 0x7FFFFFFF) | (ctx.r11.u64 & 0xFFFFFFFF80000000);
	// stw r11,-48(r1)
	PPC_STORE_U32(ctx.r1.u32 + -48, ctx.r11.u32);
	// lfs f13,-48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -48);
	ctx.f13.f64 = double(temp.f32);
	// fadds f12,f13,f1
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f1.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f13,-18912(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18912);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// stfiwx f13,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f13.u32);
	// lwa r11,-48(r1)
	ctx.r11.s64 = int32_t(PPC_LOAD_U32(ctx.r1.u32 + -48));
	// std r11,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.r11.u64);
	// lfd f13,-48(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fnmsubs f0,f13,f0,f1
	ctx.f0.f64 = double(float(-(ctx.f13.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// stfs f0,-28(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -28, temp.u32);
	// fmuls f13,f0,f0
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// stfs f13,-24(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -24, temp.u32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,-20(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -20, temp.u32);
	// addi r11,r1,-32
	ctx.r11.s64 = ctx.r1.s64 + -32;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,-16
	ctx.r11.s64 = ctx.r1.s64 + -16;
	// vspltw v13,v0,1
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// vmulfp128 v0,v0,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v0,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vspltw v9,v0,3
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x0));
	// vmsum4fp128 v10,v0,v10
	_mm_store_ps(ctx.v10.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v10.f32), 0xFF));
	// vmulfp128 v13,v9,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v9.f32), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v10,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v10.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,-32
	ctx.r11.s64 = ctx.r1.s64 + -32;
	// vmulfp128 v0,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v13,v0,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmsum4fp128 v0,v0,v12
	_mm_store_ps(ctx.v0.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v12.f32), 0xFF));
	// vmsum4fp128 v13,v13,v11
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v11.f32), 0xFF));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,-48
	ctx.r11.s64 = ctx.r1.s64 + -48;
	// lfs f0,-32(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -32);
	ctx.f0.f64 = double(temp.f32);
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f13,-48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -48);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f13,-16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	ctx.f13.f64 = double(temp.f32);
	// fadds f1,f0,f13
	ctx.f1.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2D868"))) PPC_WEAK_FUNC(sub_82B2D868);
PPC_FUNC_IMPL(__imp__sub_82B2D868) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	PPCVRegister vTemp{};
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// stfs f1,20(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// addi r10,r1,-32
	ctx.r10.s64 = ctx.r1.s64 + -32;
	// stfs f2,28(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 28, temp.u32);
	// addi r9,r1,-28
	ctx.r9.s64 = ctx.r1.s64 + -28;
	// vspltisw v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_set1_epi32(int(0x0)));
	// addi r8,r1,20
	ctx.r8.s64 = ctx.r1.s64 + 20;
	// vspltisw v11,-1
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_set1_epi32(int(0xFFFFFFFF)));
	// addi r7,r1,-20
	ctx.r7.s64 = ctx.r1.s64 + -20;
	// vspltisw v4,-9
	_mm_store_si128((__m128i*)ctx.v4.u32, _mm_set1_epi32(int(0xFFFFFFF7)));
	// lfs f0,-13892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r1,-24
	ctx.r11.s64 = ctx.r1.s64 + -24;
	// stfs f0,-32(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -32, temp.u32);
	// stfs f0,-28(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -28, temp.u32);
	// vslw v3,v11,v11
	ctx.v3.u32[0] = ctx.v11.u32[0] << (ctx.v11.u8[0] & 0x1F);
	ctx.v3.u32[1] = ctx.v11.u32[1] << (ctx.v11.u8[4] & 0x1F);
	ctx.v3.u32[2] = ctx.v11.u32[2] << (ctx.v11.u8[8] & 0x1F);
	ctx.v3.u32[3] = ctx.v11.u32[3] << (ctx.v11.u8[12] & 0x1F);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r10,r1,-20
	ctx.r10.s64 = ctx.r1.s64 + -20;
	// lvlx v12,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r9,r1,28
	ctx.r9.s64 = ctx.r1.s64 + 28;
	// stfs f0,-24(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -24, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v10,0,r11
	temp.u32 = ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r11,r1,-24
	ctx.r11.s64 = ctx.r1.s64 + -24;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v0,v10,4,3
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v10.f32), 57), 4));
	// stfs f0,-20(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -20, temp.u32);
	// lvlx v10,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,-20(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -20, temp.u32);
	// stfs f0,-24(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -24, temp.u32);
	// lvlx v9,0,r11
	temp.u32 = ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// lvlx v8,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lvlx v7,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v7.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v8,v10,4,3
	_mm_store_ps(ctx.v8.f32, _mm_blend_ps(_mm_load_ps(ctx.v8.f32), _mm_permute_ps(_mm_load_ps(ctx.v10.f32), 57), 4));
	// vrlimi128 v7,v9,4,3
	_mm_store_ps(ctx.v7.f32, _mm_blend_ps(_mm_load_ps(ctx.v7.f32), _mm_permute_ps(_mm_load_ps(ctx.v9.f32), 57), 4));
	// addi r11,r11,-18928
	ctx.r11.s64 = ctx.r11.s64 + -18928;
	// vor v12,v8,v8
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_load_si128((__m128i*)ctx.v8.u8));
	// vor v10,v7,v7
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_load_si128((__m128i*)ctx.v7.u8));
	// vor v8,v0,v0
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// lvx128 v9,r0,r11
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v7,v9,0
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0xFF));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// vspltw v5,v9,1
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0xAA));
	// vrlimi128 v10,v12,3,2
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// vupkd3d128 v12,v13,4
	temp.f32 = 3.0f;
	temp.s32 += ctx.v13.s16[1];
	vTemp.f32[3] = temp.f32;
	temp.f32 = 3.0f;
	temp.s32 += ctx.v13.s16[0];
	vTemp.f32[2] = temp.f32;
	vTemp.f32[1] = 0.0f;
	vTemp.f32[0] = 1.0f;
	ctx.v12 = vTemp;
	// addi r11,r11,-18944
	ctx.r11.s64 = ctx.r11.s64 + -18944;
	// vspltw v29,v9,2
	_mm_store_si128((__m128i*)ctx.v29.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0x55));
	// vspltw v6,v12,3
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0x0));
	// vandc v12,v8,v3
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v3.u8), _mm_load_si128((__m128i*)ctx.v8.u8)));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vslw v10,v11,v4
	ctx.v10.u32[0] = ctx.v11.u32[0] << (ctx.v4.u8[0] & 0x1F);
	ctx.v10.u32[1] = ctx.v11.u32[1] << (ctx.v4.u8[4] & 0x1F);
	ctx.v10.u32[2] = ctx.v11.u32[2] << (ctx.v4.u8[8] & 0x1F);
	ctx.v10.u32[3] = ctx.v11.u32[3] << (ctx.v4.u8[12] & 0x1F);
	// vlogefp v2,v12
	ctx.fpscr.enableFlushModeUnconditional();
	ctx.v2.f32[0] = log2f(ctx.v12.f32[0]);
	ctx.v2.f32[1] = log2f(ctx.v12.f32[1]);
	ctx.v2.f32[2] = log2f(ctx.v12.f32[2]);
	ctx.v2.f32[3] = log2f(ctx.v12.f32[3]);
	// vsel v10,v12,v6,v10
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v10.u8), _mm_load_si128((__m128i*)ctx.v12.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v10.u8), _mm_load_si128((__m128i*)ctx.v6.u8))));
	// vsubfp v12,v10,v6
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v6.f32)));
	// vrfim v10,v2
	_mm_store_ps(ctx.v10.f32, _mm_round_ps(_mm_load_ps(ctx.v2.f32), _MM_FROUND_TO_NEG_INF | _MM_FROUND_NO_EXC));
	// vmaddfp v5,v12,v5,v7
	_mm_store_ps(ctx.v5.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v5.f32)), _mm_load_ps(ctx.v7.f32)));
	// lvx128 v7,r0,r11
	_mm_store_si128((__m128i*)ctx.v7.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// vspltw v30,v7,1
	_mm_store_si128((__m128i*)ctx.v30.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0xAA));
	// vspltw v31,v7,0
	_mm_store_si128((__m128i*)ctx.v31.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0xFF));
	// addi r11,r11,-18960
	ctx.r11.s64 = ctx.r11.s64 + -18960;
	// vspltw v28,v7,2
	_mm_store_si128((__m128i*)ctx.v28.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0x55));
	// vspltw v27,v7,3
	_mm_store_si128((__m128i*)ctx.v27.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0x0));
	// vmulfp128 v1,v10,v0
	_mm_store_ps(ctx.v1.f32, _mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v10,v12,v12
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v31,v12,v30,v31
	_mm_store_ps(ctx.v31.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v30.f32)), _mm_load_ps(ctx.v31.f32)));
	// vmaddfp v30,v10,v29,v5
	_mm_store_ps(ctx.v30.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v29.f32)), _mm_load_ps(ctx.v5.f32)));
	// vspltw v29,v9,3
	_mm_store_si128((__m128i*)ctx.v29.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0x0));
	// lvx128 v9,r0,r11
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// vmulfp128 v2,v12,v10
	_mm_store_ps(ctx.v2.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v10.f32)));
	// vspltw v5,v9,0
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0xFF));
	// addi r11,r11,-18976
	ctx.r11.s64 = ctx.r11.s64 + -18976;
	// vmulfp128 v26,v10,v10
	_mm_store_ps(ctx.v26.f32, _mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v10.f32)));
	// vmaddfp v10,v10,v28,v31
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v28.f32)), _mm_load_ps(ctx.v31.f32)));
	// vspltw v25,v9,1
	_mm_store_si128((__m128i*)ctx.v25.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0xAA));
	// vmulfp128 v12,v12,v0
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)));
	// lvx128 v7,r0,r11
	_mm_store_si128((__m128i*)ctx.v7.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v31,v7,0
	_mm_store_si128((__m128i*)ctx.v31.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0xFF));
	// vspltw v28,v7,1
	_mm_store_si128((__m128i*)ctx.v28.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0xAA));
	// vmaddfp v10,v2,v27,v10
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v2.f32), _mm_load_ps(ctx.v27.f32)), _mm_load_ps(ctx.v10.f32)));
	// vspltw v24,v7,2
	_mm_store_si128((__m128i*)ctx.v24.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0x55));
	// vmaddfp v30,v2,v29,v30
	_mm_store_ps(ctx.v30.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v2.f32), _mm_load_ps(ctx.v29.f32)), _mm_load_ps(ctx.v30.f32)));
	// vspltw v29,v9,2
	_mm_store_si128((__m128i*)ctx.v29.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0x55));
	// vspltw v9,v9,3
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), 0x0));
	// vand v3,v8,v3
	_mm_store_si128((__m128i*)ctx.v3.u8, _mm_and_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v3.u8)));
	// vspltw v7,v7,3
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), 0x0));
	// vslw v4,v11,v4
	ctx.v4.u32[0] = ctx.v11.u32[0] << (ctx.v4.u8[0] & 0x1F);
	ctx.v4.u32[1] = ctx.v11.u32[1] << (ctx.v4.u8[4] & 0x1F);
	ctx.v4.u32[2] = ctx.v11.u32[2] << (ctx.v4.u8[8] & 0x1F);
	ctx.v4.u32[3] = ctx.v11.u32[3] << (ctx.v4.u8[12] & 0x1F);
	// addi r11,r1,-16
	ctx.r11.s64 = ctx.r1.s64 + -16;
	// vmaddfp v10,v26,v10,v30
	_mm_store_ps(ctx.v10.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v26.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v30.f32)));
	// vcmpgtfp v30,v13,v0
	_mm_store_ps(ctx.v30.f32, _mm_cmpgt_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v12,v12,v10,v1
	_mm_store_ps(ctx.v12.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v1.f32)));
	// vrfim v10,v12
	_mm_store_ps(ctx.v10.f32, _mm_round_ps(_mm_load_ps(ctx.v12.f32), _MM_FROUND_TO_NEG_INF | _MM_FROUND_NO_EXC));
	// vsubfp v12,v12,v10
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v10.f32)));
	// vexptefp v2,v10
	ctx.v2.f32[0] = exp2f(ctx.v10.f32[0]);
	ctx.v2.f32[1] = exp2f(ctx.v10.f32[1]);
	ctx.v2.f32[2] = exp2f(ctx.v10.f32[2]);
	ctx.v2.f32[3] = exp2f(ctx.v10.f32[3]);
	// vmulfp128 v10,v12,v12
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v1,v12,v25,v5
	_mm_store_ps(ctx.v1.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v25.f32)), _mm_load_ps(ctx.v5.f32)));
	// vmaddfp v31,v12,v28,v31
	_mm_store_ps(ctx.v31.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v28.f32)), _mm_load_ps(ctx.v31.f32)));
	// vmulfp128 v12,v12,v10
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v10.f32)));
	// vmaddfp v1,v10,v29,v1
	_mm_store_ps(ctx.v1.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v29.f32)), _mm_load_ps(ctx.v1.f32)));
	// vmaddfp v31,v10,v24,v31
	_mm_store_ps(ctx.v31.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v24.f32)), _mm_load_ps(ctx.v31.f32)));
	// vmulfp128 v10,v10,v10
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v10.f32)));
	// vmaddfp v9,v12,v9,v1
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v9.f32)), _mm_load_ps(ctx.v1.f32)));
	// vmaddfp v12,v12,v7,v31
	_mm_store_ps(ctx.v12.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v7.f32)), _mm_load_ps(ctx.v31.f32)));
	// vctsxs v1,v0,0
	_mm_store_si128((__m128i*)ctx.v1.s32, _mm_vctsxs(_mm_load_ps(ctx.v0.f32)));
	// vcmpeqfp v7,v0,v13
	_mm_store_ps(ctx.v7.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v12,v10,v12,v9
	_mm_store_ps(ctx.v12.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v12.f32)), _mm_load_ps(ctx.v9.f32)));
	// vspltisw v10,1
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_set1_epi32(int(0x1)));
	// vrfiz v9,v0
	_mm_store_ps(ctx.v9.f32, _mm_round_ps(_mm_load_ps(ctx.v0.f32), _MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC));
	// vand v1,v1,v10
	_mm_store_si128((__m128i*)ctx.v1.u8, _mm_and_si128(_mm_load_si128((__m128i*)ctx.v1.u8), _mm_load_si128((__m128i*)ctx.v10.u8)));
	// vsrw v10,v4,v10
	ctx.v10.u32[0] = ctx.v4.u32[0] >> (ctx.v10.u8[0] & 0x1F);
	ctx.v10.u32[1] = ctx.v4.u32[1] >> (ctx.v10.u8[4] & 0x1F);
	ctx.v10.u32[2] = ctx.v4.u32[2] >> (ctx.v10.u8[8] & 0x1F);
	ctx.v10.u32[3] = ctx.v4.u32[3] >> (ctx.v10.u8[12] & 0x1F);
	// vslw v11,v1,v11
	ctx.v11.u32[0] = ctx.v1.u32[0] << (ctx.v11.u8[0] & 0x1F);
	ctx.v11.u32[1] = ctx.v1.u32[1] << (ctx.v11.u8[4] & 0x1F);
	ctx.v11.u32[2] = ctx.v1.u32[2] << (ctx.v11.u8[8] & 0x1F);
	ctx.v11.u32[3] = ctx.v1.u32[3] << (ctx.v11.u8[12] & 0x1F);
	// vor v29,v12,v12
	_mm_store_si128((__m128i*)ctx.v29.u8, _mm_load_si128((__m128i*)ctx.v12.u8));
	// vcmpeqfp v31,v0,v9
	_mm_store_ps(ctx.v31.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v9.f32)));
	// vor v1,v12,v12
	_mm_store_si128((__m128i*)ctx.v1.u8, _mm_load_si128((__m128i*)ctx.v12.u8));
	// vcmpeqfp v9,v8,v13
	_mm_store_ps(ctx.v9.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v13.f32)));
	// vcmpgtfp v8,v13,v8
	_mm_store_ps(ctx.v8.f32, _mm_cmpgt_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v8.f32)));
	// vrefp v0,v12
	_mm_store_ps(ctx.v0.f32, _mm_div_ps(_mm_set1_ps(1), _mm_load_ps(ctx.v12.f32)));
	// vand v12,v3,v11
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_and_si128(_mm_load_si128((__m128i*)ctx.v3.u8), _mm_load_si128((__m128i*)ctx.v11.u8)));
	// vor v13,v13,v12
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v12.u8)));
	// vandc v11,v8,v31
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v31.u8), _mm_load_si128((__m128i*)ctx.v8.u8)));
	// vandc v8,v9,v30
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v30.u8), _mm_load_si128((__m128i*)ctx.v9.u8)));
	// vor v9,v9,v7
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v9.u8), _mm_load_si128((__m128i*)ctx.v7.u8)));
	// vsel v13,v10,v13,v8
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v10.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v13.u8))));
	// vnmsubfp v10,v29,v0,v5
	_mm_store_ps(ctx.v10.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v29.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v5.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vor v11,v11,v9
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)ctx.v9.u8)));
	// vor v9,v0,v0
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vsel v13,v13,v6,v7
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v7.u8), _mm_load_si128((__m128i*)ctx.v13.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v7.u8), _mm_load_si128((__m128i*)ctx.v6.u8))));
	// vmaddfp v0,v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v0.f32)));
	// vnmsubfp v10,v1,v0,v5
	_mm_store_ps(ctx.v10.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v1.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v5.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vcmpeqfp v8,v0,v0
	_mm_store_ps(ctx.v8.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v0,v0,v10,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v0.f32)));
	// vsel v0,v9,v0,v8
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v9.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v0.u8))));
	// vmulfp128 v0,v2,v0
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v2.f32), _mm_load_ps(ctx.v0.f32)));
	// vor v0,v0,v12
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v12.u8)));
	// vsel v0,v0,v13,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)ctx.v0.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)ctx.v13.u8))));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f1,-16(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2DA98"))) PPC_WEAK_FUNC(sub_82B2DA98);
PPC_FUNC_IMPL(__imp__sub_82B2DA98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// stfs f1,20(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 20, temp.u32);
	// addi r10,r1,-32
	ctx.r10.s64 = ctx.r1.s64 + -32;
	// vspltisw v0,1
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_set1_epi32(int(0x1)));
	// addi r9,r1,-24
	ctx.r9.s64 = ctx.r1.s64 + -24;
	// addi r8,r1,20
	ctx.r8.s64 = ctx.r1.s64 + 20;
	// lfs f0,-13892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r1,-28
	ctx.r11.s64 = ctx.r1.s64 + -28;
	// stfs f0,-32(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -32, temp.u32);
	// vcfsx v12,v0,1
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_cvtepi32_ps(_mm_load_si128((__m128i*)ctx.v0.u32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x3F000000)))));
	// stfs f0,-28(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -28, temp.u32);
	// lvlx v13,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,-24(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -24, temp.u32);
	// lvlx v11,0,r11
	temp.u32 = ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r11,r1,-16
	ctx.r11.s64 = ctx.r1.s64 + -16;
	// vrlimi128 v11,v13,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 57), 4));
	// lvlx v10,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v13,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v13,v10,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v10.f32), 57), 4));
	// vrlimi128 v13,v11,3,2
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 78), 3));
	// vrsqrtefp v0,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_div_ps(_mm_set1_ps(1), _mm_sqrt_ps(_mm_load_ps(ctx.v13.f32))));
	// vor v11,v13,v13
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_load_si128((__m128i*)ctx.v13.u8));
	// vmulfp128 v10,v13,v12
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v12.f32)));
	// vmulfp128 v9,v0,v0
	_mm_store_ps(ctx.v9.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vcmpeqfp v8,v0,v0
	_mm_store_ps(ctx.v8.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v0.f32)));
	// vnmsubfp v12,v10,v9,v12
	_mm_store_ps(ctx.v12.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v9.f32)), _mm_load_ps(ctx.v12.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vmaddfp v0,v0,v12,v0
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v12.f32)), _mm_load_ps(ctx.v0.f32)));
	// vcmpeqfp v12,v12,v12
	_mm_store_ps(ctx.v12.f32, _mm_cmpeq_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v12.f32)));
	// vmulfp128 v0,v13,v0
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)));
	// vxor v13,v12,v8
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_xor_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v8.u8)));
	// vsel v0,v0,v11,v13
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)), _mm_and_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v11.u8))));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f1,-16(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2DB20"))) PPC_WEAK_FUNC(sub_82B2DB20);
PPC_FUNC_IMPL(__imp__sub_82B2DB20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B2DB28;
	__savegprlr_26(ctx, base);
	// stwu r1,-992(r1)
	ea = -992 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mullw. r11,r30,r29
	ctx.r11.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r29.s32);
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble 0x82b2db50
	if (!ctx.cr0.gt) goto loc_82B2DB50;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x82e29458
	ctx.lr = 0x82B2DB50;
	sub_82E29458(ctx, base);
loc_82B2DB50:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82b2db78
	if (!ctx.cr6.gt) goto loc_82B2DB78;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// li r10,-1
	ctx.r10.s64 = -1;
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq 0x82b2db78
	if (ctx.cr0.eq) goto loc_82B2DB78;
	// mtctr r30
	ctx.ctr.u64 = ctx.r30.u64;
loc_82B2DB6C:
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82b2db6c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B2DB6C;
loc_82B2DB78:
	// srawi r11,r30,1
	ctx.xer.ca = (ctx.r30.s32 < 0) & ((ctx.r30.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r30.s32 >> 1;
	// addi r10,r30,-1
	ctx.r10.s64 = ctx.r30.s64 + -1;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// li r28,0
	ctx.r28.s64 = 0;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// cmpwi cr6,r30,2
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 2, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// stwx r28,r11,r9
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, ctx.r28.u32);
	// stwx r28,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r28.u32);
	// beq cr6,0x82b2dbe4
	if (ctx.cr6.eq) goto loc_82B2DBE4;
	// addi r11,r30,2
	ctx.r11.s64 = ctx.r30.s64 + 2;
	// addi r10,r30,-3
	ctx.r10.s64 = ctx.r30.s64 + -3;
	// srawi r11,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 1;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r3,r11,r9
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, ctx.r3.u32);
	// stwx r3,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r3.u32);
loc_82B2DBE4:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82b2dc14
	if (!ctx.cr6.gt) goto loc_82B2DC14;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
loc_82B2DBF4:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r9,-1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, -1, ctx.xer);
	// bne cr6,0x82b2dc08
	if (!ctx.cr6.eq) goto loc_82B2DC08;
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
loc_82B2DC08:
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b2dbf4
	if (!ctx.cr0.eq) goto loc_82B2DBF4;
loc_82B2DC14:
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// ble cr6,0x82b2df70
	if (!ctx.cr6.gt) goto loc_82B2DF70;
	// addi r11,r1,288
	ctx.r11.s64 = ctx.r1.s64 + 288;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// subf r4,r31,r11
	ctx.r4.s64 = ctx.r11.s64 - ctx.r31.s64;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lfs f12,-18448(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -18448);
	ctx.f12.f64 = double(temp.f32);
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// lfd f10,-3064(r10)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r10.u32 + -3064);
	// lfs f11,-13892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f11.f64 = double(temp.f32);
loc_82B2DC48:
	// li r7,512
	ctx.r7.s64 = 512;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82b2dd14
	if (!ctx.cr6.gt) goto loc_82B2DD14;
	// addi r9,r1,240
	ctx.r9.s64 = ctx.r1.s64 + 240;
	// rlwinm r8,r29,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r4,r5
	ctx.r10.u64 = ctx.r4.u64 + ctx.r5.u64;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
loc_82B2DC64:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82b2dc64
	if (!ctx.cr0.eq) goto loc_82B2DC64;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
loc_82B2DC84:
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lfsx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// fcmpu cr6,f0,f11
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// addi r27,r10,7
	ctx.r27.s64 = ctx.r10.s64 + 7;
	// slw r27,r3,r27
	ctx.r27.u64 = ctx.r27.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r27.u8 & 0x3F));
	// extsw r27,r27
	ctx.r27.s64 = ctx.r27.s32;
	// ble cr6,0x82b2dcc8
	if (!ctx.cr6.gt) goto loc_82B2DCC8;
	// std r27,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.r27.u64);
	// lfd f13,176(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fadd f0,f0,f10
	ctx.f0.f64 = ctx.f0.f64 + ctx.f10.f64;
	// b 0x82b2dce0
	goto loc_82B2DCE0;
loc_82B2DCC8:
	// std r27,152(r1)
	PPC_STORE_U64(ctx.r1.u32 + 152, ctx.r27.u64);
	// lfd f13,152(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fsub f0,f0,f10
	ctx.f0.f64 = ctx.f0.f64 - ctx.f10.f64;
loc_82B2DCE0:
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r8
	PPC_STORE_U32(ctx.r8.u32, ctx.f0.u32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subfic r8,r10,2
	ctx.xer.ca = ctx.r10.u32 <= 2;
	ctx.r8.s64 = 2 - ctx.r10.s64;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r27,r1,192
	ctx.r27.s64 = ctx.r1.s64 + 192;
	// stwx r10,r11,r27
	PPC_STORE_U32(ctx.r11.u32 + ctx.r27.u32, ctx.r10.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// slw r10,r10,r8
	ctx.r10.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
	// subf r7,r10,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r10.s64;
	// bne 0x82b2dc84
	if (!ctx.cr0.eq) goto loc_82B2DC84;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// ble cr6,0x82b2de04
	if (!ctx.cr6.gt) goto loc_82B2DE04;
loc_82B2DD14:
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// fmr f13,f12
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f12.f64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82b2ddd8
	if (!ctx.cr6.gt) goto loc_82B2DDD8;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
loc_82B2DD2C:
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// lfsx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	ctx.f0.f64 = double(temp.f32);
	// fabs f9,f0
	ctx.f9.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// fcmpu cr6,f9,f11
	ctx.cr6.compare(ctx.f9.f64, ctx.f11.f64);
	// ble cr6,0x82b2dd90
	if (!ctx.cr6.gt) goto loc_82B2DD90;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r27,r1,192
	ctx.r27.s64 = ctx.r1.s64 + 192;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// addi r10,r10,7
	ctx.r10.s64 = ctx.r10.s64 + 7;
	// lwax r27,r11,r27
	ctx.r27.s64 = int32_t(PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32));
	// slw r10,r3,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r10.u8 & 0x3F));
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r27,168(r1)
	PPC_STORE_U64(ctx.r1.u32 + 168, ctx.r27.u64);
	// std r10,160(r1)
	PPC_STORE_U64(ctx.r1.u32 + 160, ctx.r10.u64);
	// lfd f9,168(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 168);
	// fcfid f9,f9
	ctx.f9.f64 = double(ctx.f9.s64);
	// lfd f8,160(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// fcfid f8,f8
	ctx.f8.f64 = double(ctx.f8.s64);
	// frsp f9,f9
	ctx.f9.f64 = double(float(ctx.f9.f64));
	// frsp f8,f8
	ctx.f8.f64 = double(float(ctx.f8.f64));
	// fmuls f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// fdivs f0,f9,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 / ctx.f0.f64));
	// fabs f0,f0
	ctx.f0.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// b 0x82b2dd94
	goto loc_82B2DD94;
loc_82B2DD90:
	// fmr f0,f12
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f12.f64;
loc_82B2DD94:
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,255
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 255, ctx.xer);
	// bge cr6,0x82b2ddc8
	if (!ctx.cr6.lt) goto loc_82B2DDC8;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// sraw r10,r6,r10
	temp.u32 = ctx.r10.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r6.s32 < 0) & (((ctx.r6.s32 >> temp.u32) << temp.u32) != ctx.r6.s32);
	ctx.r10.s64 = ctx.r6.s32 >> temp.u32;
	// cmpw cr6,r7,r10
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82b2ddc8
	if (ctx.cr6.lt) goto loc_82B2DDC8;
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82b2ddc8
	if (!ctx.cr6.lt) goto loc_82B2DDC8;
	// fmr f13,f0
	ctx.f13.f64 = ctx.f0.f64;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
loc_82B2DDC8:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmpw cr6,r9,r30
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r30.s32, ctx.xer);
	// blt cr6,0x82b2dd2c
	if (ctx.cr6.lt) goto loc_82B2DD2C;
loc_82B2DDD8:
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	// sraw r9,r6,r9
	temp.u32 = ctx.r9.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r6.s32 < 0) & (((ctx.r6.s32 >> temp.u32) << temp.u32) != ctx.r6.s32);
	ctx.r9.s64 = ctx.r6.s32 >> temp.u32;
	// subf. r7,r9,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r9.s64;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// bgt 0x82b2dd14
	if (ctx.cr0.gt) goto loc_82B2DD14;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
loc_82B2DE04:
	// bge cr6,0x82b2df20
	if (!ctx.cr6.lt) goto loc_82B2DF20;
loc_82B2DE08:
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// fmr f13,f12
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f12.f64;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82b2def8
	if (!ctx.cr6.gt) goto loc_82B2DEF8;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
loc_82B2DE20:
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// lfsx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	ctx.f0.f64 = double(temp.f32);
	// fabs f9,f0
	ctx.f9.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// fcmpu cr6,f9,f11
	ctx.cr6.compare(ctx.f9.f64, ctx.f11.f64);
	// ble cr6,0x82b2de8c
	if (!ctx.cr6.gt) goto loc_82B2DE8C;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r27,r1,192
	ctx.r27.s64 = ctx.r1.s64 + 192;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// addi r26,r10,7
	ctx.r26.s64 = ctx.r10.s64 + 7;
	// lwzx r10,r11,r27
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r10,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r10.u64);
	// slw r10,r3,r26
	ctx.r10.u64 = ctx.r26.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r26.u8 & 0x3F));
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r10,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r10.u64);
	// lfd f9,136(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f9,f9
	ctx.f9.f64 = double(ctx.f9.s64);
	// frsp f9,f9
	ctx.f9.f64 = double(float(ctx.f9.f64));
	// lfd f8,144(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f8,f8
	ctx.f8.f64 = double(ctx.f8.s64);
	// frsp f8,f8
	ctx.f8.f64 = double(float(ctx.f8.f64));
	// fmuls f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fsubs f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// fdivs f0,f9,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 / ctx.f0.f64));
	// fabs f0,f0
	ctx.f0.u64 = ctx.f0.u64 & ~0x8000000000000000;
	// b 0x82b2de90
	goto loc_82B2DE90;
loc_82B2DE8C:
	// fmr f0,f12
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f12.f64;
loc_82B2DE90:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// sraw r27,r6,r10
	temp.u32 = ctx.r10.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r6.s32 < 0) & (((ctx.r6.s32 >> temp.u32) << temp.u32) != ctx.r6.s32);
	ctx.r27.s64 = ctx.r6.s32 >> temp.u32;
	// neg r27,r27
	ctx.r27.s64 = -ctx.r27.s64;
	// cmpw cr6,r7,r27
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r27.s32, ctx.xer);
	// bgt cr6,0x82b2dee8
	if (ctx.cr6.gt) goto loc_82B2DEE8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82b2dec4
	if (!ctx.cr6.eq) goto loc_82B2DEC4;
	// addi r27,r1,192
	ctx.r27.s64 = ctx.r1.s64 + 192;
	// lwzx r27,r11,r27
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// cmpwi cr6,r27,0
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// bgt cr6,0x82b2ded8
	if (ctx.cr6.gt) goto loc_82B2DED8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
loc_82B2DEC4:
	// ble cr6,0x82b2dee8
	if (!ctx.cr6.gt) goto loc_82B2DEE8;
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r10,-256
	ctx.cr6.compare<int32_t>(ctx.r10.s32, -256, ctx.xer);
	// ble cr6,0x82b2dee8
	if (!ctx.cr6.gt) goto loc_82B2DEE8;
loc_82B2DED8:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82b2dee8
	if (!ctx.cr6.lt) goto loc_82B2DEE8;
	// fmr f13,f0
	ctx.f13.f64 = ctx.f0.f64;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
loc_82B2DEE8:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmpw cr6,r9,r30
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r30.s32, ctx.xer);
	// blt cr6,0x82b2de20
	if (ctx.cr6.lt) goto loc_82B2DE20;
loc_82B2DEF8:
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	// sraw r9,r6,r9
	temp.u32 = ctx.r9.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	ctx.xer.ca = (ctx.r6.s32 < 0) & (((ctx.r6.s32 >> temp.u32) << temp.u32) != ctx.r6.s32);
	ctx.r9.s64 = ctx.r6.s32 >> temp.u32;
	// add. r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 + ctx.r7.u64;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// stwx r9,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// blt 0x82b2de08
	if (ctx.cr0.lt) goto loc_82B2DE08;
loc_82B2DF20:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x82b2df64
	if (!ctx.cr6.gt) goto loc_82B2DF64;
	// rlwinm r8,r29,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
loc_82B2DF38:
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r27,r1,192
	ctx.r27.s64 = ctx.r1.s64 + 192;
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lwzx r7,r11,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r7.u32);
	// lwzx r27,r11,r27
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r27.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// subfic r7,r7,2
	ctx.xer.ca = ctx.r7.u32 <= 2;
	ctx.r7.s64 = 2 - ctx.r7.s64;
	// slw r7,r27,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r7.u8 & 0x3F));
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// bne 0x82b2df38
	if (!ctx.cr0.eq) goto loc_82B2DF38;
loc_82B2DF64:
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// bne 0x82b2dc48
	if (!ctx.cr0.eq) goto loc_82B2DC48;
loc_82B2DF70:
	// addi r1,r1,992
	ctx.r1.s64 = ctx.r1.s64 + 992;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2DF78"))) PPC_WEAK_FUNC(sub_82B2DF78);
PPC_FUNC_IMPL(__imp__sub_82B2DF78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stfd f30,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.f30.u64);
	// stfd f31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fabs f30,f1
	ctx.f30.u64 = ctx.f1.u64 & ~0x8000000000000000;
	// lis r11,-32243
	ctx.r11.s64 = -2113077248;
	// stfs f30,92(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f13,-5404(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -5404);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f30,f13
	ctx.cr6.compare(ctx.f30.f64, ctx.f13.f64);
	// bge cr6,0x82b2e008
	if (!ctx.cr6.lt) goto loc_82B2E008;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f0,-18848(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18848);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f13,-18852(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18852);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f12,-18856(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18856);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f0,f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fmadds f12,f0,f13,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f13,-18860(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18860);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f12,f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,-18864(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18864);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f12,f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,-18868(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18868);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f12,f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,-18872(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18872);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// fmadds f12,f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,-13896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// b 0x82b2e0d8
	goto loc_82B2E0D8;
loc_82B2E008:
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// fdivs f31,f13,f30
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = double(float(ctx.f13.f64 / ctx.f30.f64));
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r9,r1,88
	ctx.r9.s64 = ctx.r1.s64 + 88;
	// addi r8,r1,92
	ctx.r8.s64 = ctx.r1.s64 + 92;
	// lfs f0,-13892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r1,84
	ctx.r11.s64 = ctx.r1.s64 + 84;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lvlx v13,0,r11
	temp.u32 = ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v12,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v0,v12,4,3
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// vor v1,v0,v0
	_mm_store_si128((__m128i*)ctx.v1.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// bl 0x82b2d6c8
	ctx.lr = 0x82B2E054;
	sub_82B2D6C8(ctx, base);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// stvx128 v1,r0,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v1.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x82b2da98
	ctx.lr = 0x82B2E064;
	sub_82B2DA98(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f0,-18876(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18876);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f13,-18880(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18880);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmsubs f13,f31,f0,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f0.f64 - ctx.f13.f64));
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// fdivs f12,f0,f1
	ctx.f12.f64 = double(float(ctx.f0.f64 / ctx.f1.f64));
	// lfs f0,-18884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18884);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f0.f64));
	// lfs f0,-18888(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18888);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmsubs f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f0.f64));
	// lfs f0,-18892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18892);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f0.f64));
	// lfs f0,-18896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18896);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmsubs f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 - ctx.f0.f64));
	// lfs f0,-18900(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18900);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f0.f64));
	// lfs f0,-18904(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18904);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f13,f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f0.f64));
	// lfs f0,-18908(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18908);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f13,f31,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f0.f64));
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
loc_82B2E0D8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f30,-24(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// lfd f31,-16(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2E0F0"))) PPC_WEAK_FUNC(sub_82B2E0F0);
PPC_FUNC_IMPL(__imp__sub_82B2E0F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stfd f31,-16(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.f31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f0,-13892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// bne cr6,0x82b2e11c
	if (!ctx.cr6.eq) goto loc_82B2E11C;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f1,-13896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f1.f64 = double(temp.f32);
	// b 0x82b2e134
	goto loc_82B2E134;
loc_82B2E11C:
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lfs f0,-32640(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -32640);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f31,f1,f0
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82b2d768
	ctx.lr = 0x82B2E130;
	sub_82B2D768(ctx, base);
	// fdivs f1,f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64 / ctx.f31.f64));
loc_82B2E134:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f31,-16(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2E148"))) PPC_WEAK_FUNC(sub_82B2E148);
PPC_FUNC_IMPL(__imp__sub_82B2E148) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82e28f18
	ctx.lr = 0x82B2E158;
	__savefpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f0,-13896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f0.f64 = double(temp.f32);
	// fabs f13,f31
	ctx.f13.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bge cr6,0x82b2e1c0
	if (!ctx.cr6.lt) goto loc_82B2E1C0;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fabs f1,f31
	ctx.f1.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f2,-18308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18308);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x82b2d868
	ctx.lr = 0x82B2E184;
	sub_82B2D868(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// lfs f30,-6956(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6956);
	ctx.f30.f64 = double(temp.f32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f2,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x82b2d868
	ctx.lr = 0x82B2E1A0;
	sub_82B2D868(ctx, base);
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lfs f0,-32636(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -32636);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// fmuls f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmsubs f13,f29,f30,f0
	ctx.f13.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 - ctx.f0.f64));
	// lfs f0,-3044(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -3044);
	ctx.f0.f64 = double(temp.f32);
loc_82B2E1B8:
	// fadds f1,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// b 0x82b2e228
	goto loc_82B2E228;
loc_82B2E1C0:
	// fabs f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f30,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f30.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	ctx.cr6.compare(ctx.f0.f64, ctx.f30.f64);
	// bge cr6,0x82b2e220
	if (!ctx.cr6.lt) goto loc_82B2E220;
	// fmr f2,f30
	ctx.f2.f64 = ctx.f30.f64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82b2d868
	ctx.lr = 0x82B2E1E0;
	sub_82B2D868(ctx, base);
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	ctx.f28.f64 = ctx.f1.f64;
	// fabs f1,f31
	ctx.f1.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f29,-32636(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -32636);
	ctx.f29.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f2,-18308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18308);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x82b2d868
	ctx.lr = 0x82B2E1FC;
	sub_82B2D868(ctx, base);
	// fmuls f13,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fabs f12,f31
	ctx.f12.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f0,-5492(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -5492);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmsubs f13,f28,f29,f13
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 - ctx.f13.f64));
	// fnmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f0,-11512(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11512);
	ctx.f0.f64 = double(temp.f32);
	// b 0x82b2e1b8
	goto loc_82B2E1B8;
loc_82B2E220:
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f1,-13892(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f1.f64 = double(temp.f32);
loc_82B2E228:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82e28f64
	ctx.lr = 0x82B2E234;
	__restfpr_28(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2E240"))) PPC_WEAK_FUNC(sub_82B2E240);
PPC_FUNC_IMPL(__imp__sub_82B2E240) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82e28f18
	ctx.lr = 0x82B2E250;
	__savefpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f1.f64;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f0,-13896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f0.f64 = double(temp.f32);
	// fabs f13,f31
	ctx.f13.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bge cr6,0x82b2e2b8
	if (!ctx.cr6.lt) goto loc_82B2E2B8;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fabs f1,f31
	ctx.f1.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f2,-18308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18308);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x82b2d868
	ctx.lr = 0x82B2E27C;
	sub_82B2D868(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// lfs f30,-6996(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6996);
	ctx.f30.f64 = double(temp.f32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f2,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x82b2d868
	ctx.lr = 0x82B2E298;
	sub_82B2D868(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lfs f0,-23172(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -23172);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmuls f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmsubs f13,f29,f30,f0
	ctx.f13.f64 = double(float(ctx.f29.f64 * ctx.f30.f64 - ctx.f0.f64));
	// lfs f0,-18328(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18328);
	ctx.f0.f64 = double(temp.f32);
loc_82B2E2B0:
	// fadds f1,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// b 0x82b2e320
	goto loc_82B2E320;
loc_82B2E2B8:
	// fabs f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f2,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f2.f64 = double(temp.f32);
	// fcmpu cr6,f0,f2
	ctx.cr6.compare(ctx.f0.f64, ctx.f2.f64);
	// bge cr6,0x82b2e318
	if (!ctx.cr6.lt) goto loc_82B2E318;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82b2d868
	ctx.lr = 0x82B2E2D4;
	sub_82B2D868(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	ctx.f28.f64 = ctx.f1.f64;
	// fabs f1,f31
	ctx.f1.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f29,-23172(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -23172);
	ctx.f29.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f30,-18308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18308);
	ctx.f30.f64 = double(temp.f32);
	// fmr f2,f30
	ctx.f2.f64 = ctx.f30.f64;
	// bl 0x82b2d868
	ctx.lr = 0x82B2E2F4;
	sub_82B2D868(ctx, base);
	// fmuls f13,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fabs f12,f31
	ctx.f12.u64 = ctx.f31.u64 & ~0x8000000000000000;
	// lfs f0,-5284(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -5284);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// fmsubs f13,f28,f29,f13
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 - ctx.f13.f64));
	// fnmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f0,-32636(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -32636);
	ctx.f0.f64 = double(temp.f32);
	// b 0x82b2e2b0
	goto loc_82B2E2B0;
loc_82B2E318:
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f1,-13892(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f1.f64 = double(temp.f32);
loc_82B2E320:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x82e28f64
	ctx.lr = 0x82B2E32C;
	__restfpr_28(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2E338"))) PPC_WEAK_FUNC(sub_82B2E338);
PPC_FUNC_IMPL(__imp__sub_82B2E338) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82B2E340;
	__savegprlr_25(ctx, base);
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82e28f00
	ctx.lr = 0x82B2E348;
	__savefpr_22(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// fmr f25,f1
	ctx.fpscr.disableFlushMode();
	ctx.f25.f64 = ctx.f1.f64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmr f30,f2
	ctx.f30.f64 = ctx.f2.f64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// lfs f23,-13892(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13892);
	ctx.f23.f64 = double(temp.f32);
	// mr r28,r9
	ctx.r28.u64 = ctx.r9.u64;
	// lfs f0,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f0.f64 = double(temp.f32);
	// mullw r31,r27,r25
	ctx.r31.s64 = int64_t(ctx.r27.s32) * int64_t(ctx.r25.s32);
	// cmpwi cr6,r26,0
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// beq cr6,0x82b2e388
	if (ctx.cr6.eq) goto loc_82B2E388;
	// fmr f29,f23
	ctx.f29.f64 = ctx.f23.f64;
	// b 0x82b2e38c
	goto loc_82B2E38C;
loc_82B2E388:
	// fmr f29,f0
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f0.f64;
loc_82B2E38C:
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// lfs f24,-13896(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f24.f64 = double(temp.f32);
	// beq cr6,0x82b2e6cc
	if (ctx.cr6.eq) goto loc_82B2E6CC;
	// cmpwi cr6,r3,2
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 2, ctx.xer);
	// beq cr6,0x82b2e634
	if (ctx.cr6.eq) goto loc_82B2E634;
	// cmpwi cr6,r3,3
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 3, ctx.xer);
	// beq cr6,0x82b2e5b4
	if (ctx.cr6.eq) goto loc_82B2E5B4;
	// cmpwi cr6,r3,4
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 4, ctx.xer);
	// beq cr6,0x82b2e550
	if (ctx.cr6.eq) goto loc_82B2E550;
	// cmpwi cr6,r3,5
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 5, ctx.xer);
	// beq cr6,0x82b2e4d4
	if (ctx.cr6.eq) goto loc_82B2E4D4;
	// cmpwi cr6,r3,6
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 6, ctx.xer);
	// beq cr6,0x82b2e434
	if (ctx.cr6.eq) goto loc_82B2E434;
	// cmpwi cr6,r3,7
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 7, ctx.xer);
	// bne cr6,0x82b2e434
	if (!ctx.cr6.eq) goto loc_82B2E434;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b2e3f4
	if (ctx.cr6.eq) goto loc_82B2E3F4;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82b2e3f4
	if (ctx.cr0.eq) goto loc_82B2E3F4;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
loc_82B2E3E8:
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82b2e3e8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B2E3E8;
loc_82B2E3F4:
	// subf r11,r27,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r27.s64;
	// add r10,r31,r27
	ctx.r10.u64 = ctx.r31.u64 + ctx.r27.u64;
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82b2e72c
	if (!ctx.cr6.lt) goto loc_82B2E72C;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf. r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// add r10,r9,r28
	ctx.r10.u64 = ctx.r9.u64 + ctx.r28.u64;
	// lis r9,16256
	ctx.r9.s64 = 1065353216;
	// beq 0x82b2e72c
	if (ctx.cr0.eq) goto loc_82B2E72C;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_82B2E424:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82b2e424
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B2E424;
	// b 0x82b2e72c
	goto loc_82B2E72C;
loc_82B2E434:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b2e72c
	if (ctx.cr6.eq) goto loc_82B2E72C;
	// rlwinm r11,r31,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 31) & 0x7FFFFFFF;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// subf r6,r27,r11
	ctx.r6.s64 = ctx.r11.s64 - ctx.r27.s64;
	// subf r7,r11,r27
	ctx.r7.s64 = ctx.r27.s64 - ctx.r11.s64;
loc_82B2E450:
	// cmplw cr6,r10,r6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82b2e480
	if (ctx.cr6.lt) goto loc_82B2E480;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82b2e480
	if (!ctx.cr6.lt) goto loc_82B2E480;
	// add r8,r7,r10
	ctx.r8.u64 = ctx.r7.u64 + ctx.r10.u64;
	// clrldi r8,r8,32
	ctx.r8.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// b 0x82b2e4b4
	goto loc_82B2E4B4;
loc_82B2E480:
	// add r8,r11,r27
	ctx.r8.u64 = ctx.r11.u64 + ctx.r27.u64;
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bge cr6,0x82b2e4bc
	if (!ctx.cr6.lt) goto loc_82B2E4BC;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b2e4bc
	if (ctx.cr6.lt) goto loc_82B2E4BC;
	// subf r8,r10,r11
	ctx.r8.s64 = ctx.r11.s64 - ctx.r10.s64;
	// add r8,r8,r27
	ctx.r8.u64 = ctx.r8.u64 + ctx.r27.u64;
	// clrldi r8,r8,32
	ctx.r8.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// std r8,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r8.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f29.f64));
loc_82B2E4B4:
	// stfs f0,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// b 0x82b2e4c0
	goto loc_82B2E4C0;
loc_82B2E4BC:
	// stfs f23,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
loc_82B2E4C0:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r10,r31
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82b2e450
	if (ctx.cr6.lt) goto loc_82B2E450;
	// b 0x82b2e72c
	goto loc_82B2E72C;
loc_82B2E4D4:
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b2e72c
	if (ctx.cr6.eq) goto loc_82B2E72C;
	// clrldi r11,r31,32
	ctx.r11.u64 = ctx.r31.u64 & 0xFFFFFFFF;
	// fdivs f30,f24,f30
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = double(float(ctx.f24.f64 / ctx.f30.f64));
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f28,f13,f0
	ctx.f28.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82B2E500:
	// clrldi r11,r29,32
	ctx.r11.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f28.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f31,f0,f25
	ctx.f31.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f1,f30,f31
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// bl 0x82b2e0f0
	ctx.lr = 0x82B2E528;
	sub_82B2E0F0(ctx, base);
	// fmr f27,f1
	ctx.fpscr.disableFlushMode();
	ctx.f27.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82b2e0f0
	ctx.lr = 0x82B2E534;
	sub_82B2E0F0(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// fmuls f0,f27,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r31
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82b2e500
	if (ctx.cr6.lt) goto loc_82B2E500;
	// b 0x82b2e72c
	goto loc_82B2E72C;
loc_82B2E550:
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b2e72c
	if (ctx.cr6.eq) goto loc_82B2E72C;
	// clrldi r11,r31,32
	ctx.r11.u64 = ctx.r31.u64 & 0xFFFFFFFF;
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f31,f13,f0
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82B2E578:
	// clrldi r11,r29,32
	ctx.r11.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f31.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f1,f0,f25
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// bl 0x82b2e148
	ctx.lr = 0x82B2E59C;
	sub_82B2E148(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// stfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r31
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82b2e578
	if (ctx.cr6.lt) goto loc_82B2E578;
	// b 0x82b2e72c
	goto loc_82B2E72C;
loc_82B2E5B4:
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b2e72c
	if (ctx.cr6.eq) goto loc_82B2E72C;
	// clrldi r11,r31,32
	ctx.r11.u64 = ctx.r31.u64 & 0xFFFFFFFF;
	// fdivs f31,f24,f30
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = double(float(ctx.f24.f64 / ctx.f30.f64));
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f28,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f28.f64 = double(temp.f32);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f30,f13,f0
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82B2E5E8:
	// clrldi r11,r29,32
	ctx.r11.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// fmr f1,f28
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f28.f64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f30.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f0,f0,f25
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f0,f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fneg f2,f0
	ctx.f2.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// bl 0x82b2d868
	ctx.lr = 0x82B2E61C;
	sub_82B2D868(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// stfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r31
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82b2e5e8
	if (ctx.cr6.lt) goto loc_82B2E5E8;
	// b 0x82b2e72c
	goto loc_82B2E72C;
loc_82B2E634:
	// clrldi r11,r31,32
	ctx.r11.u64 = ctx.r31.u64 & 0xFFFFFFFF;
	// li r30,0
	ctx.r30.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f27,f13,f0
	ctx.f27.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fsubs f28,f27,f29
	ctx.f28.f64 = double(float(ctx.f27.f64 - ctx.f29.f64));
	// beq cr6,0x82b2e72c
	if (ctx.cr6.eq) goto loc_82B2E72C;
	// fdivs f26,f24,f28
	ctx.f26.f64 = double(float(ctx.f24.f64 / ctx.f28.f64));
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
loc_82B2E664:
	// clrldi r11,r30,32
	ctx.r11.u64 = ctx.r30.u64 & 0xFFFFFFFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f31,f0
	ctx.f31.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f31,f28
	ctx.f0.f64 = double(float(ctx.f31.f64 - ctx.f28.f64));
	// fmuls f0,f0,f26
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// fnmsubs f1,f0,f0,f24
	ctx.f1.f64 = double(float(-(ctx.f0.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// bl 0x82b2da98
	ctx.lr = 0x82B2E688;
	sub_82B2DA98(ctx, base);
	// fmuls f1,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// bl 0x82b2df78
	ctx.lr = 0x82B2E690;
	sub_82B2DF78(ctx, base);
	// fmr f22,f1
	ctx.fpscr.disableFlushMode();
	ctx.f22.f64 = ctx.f1.f64;
	// fmr f1,f30
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x82b2df78
	ctx.lr = 0x82B2E69C;
	sub_82B2DF78(ctx, base);
	// fsubs f0,f31,f27
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f31.f64 - ctx.f27.f64));
	// fdivs f31,f22,f1
	ctx.f31.f64 = double(float(ctx.f22.f64 / ctx.f1.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f1,f0,f25
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// bl 0x82b2e0f0
	ctx.lr = 0x82B2E6B0;
	sub_82B2E0F0(ctx, base);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// fmuls f0,f31,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f1.f64));
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 0, temp.u32);
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82b2e664
	if (ctx.cr6.lt) goto loc_82B2E664;
	// b 0x82b2e72c
	goto loc_82B2E72C;
loc_82B2E6CC:
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b2e72c
	if (ctx.cr6.eq) goto loc_82B2E72C;
	// clrldi r11,r31,32
	ctx.r11.u64 = ctx.r31.u64 & 0xFFFFFFFF;
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f13,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f31,f13,f0
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82B2E6F4:
	// clrldi r11,r29,32
	ctx.r11.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fsubs f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f31.f64));
	// fadds f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f29.f64));
	// fmuls f1,f0,f25
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// bl 0x82b2e240
	ctx.lr = 0x82B2E718;
	sub_82B2E240(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// stfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r31
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r31.u32, ctx.xer);
	// blt cr6,0x82b2e6f4
	if (ctx.cr6.lt) goto loc_82B2E6F4;
loc_82B2E72C:
	// cmpwi cr6,r26,0
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// beq cr6,0x82b2e738
	if (ctx.cr6.eq) goto loc_82B2E738;
	// stfs f23,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r28.u32 + 0, temp.u32);
loc_82B2E738:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82b2e7a4
	if (ctx.cr6.eq) goto loc_82B2E7A4;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
loc_82B2E748:
	// fmr f0,f23
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f23.f64;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82b2e798
	if (ctx.cr6.eq) goto loc_82B2E798;
	// rlwinm r8,r27,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
loc_82B2E760:
	// lfs f13,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// bne 0x82b2e760
	if (!ctx.cr0.eq) goto loc_82B2E760;
	// fdivs f0,f24,f0
	ctx.f0.f64 = double(float(ctx.f24.f64 / ctx.f0.f64));
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
loc_82B2E780:
	// lfs f13,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f13,0(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// bne 0x82b2e780
	if (!ctx.cr0.eq) goto loc_82B2E780;
loc_82B2E798:
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bne 0x82b2e748
	if (!ctx.cr0.eq) goto loc_82B2E748;
loc_82B2E7A4:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82e28f4c
	ctx.lr = 0x82B2E7B0;
	__restfpr_22(ctx, base);
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2E7B8"))) PPC_WEAK_FUNC(sub_82B2E7B8);
PPC_FUNC_IMPL(__imp__sub_82B2E7B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-784(r1)
	ea = -784 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r8
	ctx.r30.u64 = ctx.r8.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne cr6,0x82b2e7f4
	if (!ctx.cr6.eq) goto loc_82B2E7F4;
	// addi r11,r1,88
	ctx.r11.s64 = ctx.r1.s64 + 88;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
loc_82B2E7F4:
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f0,0(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,-13880(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13880);
	ctx.f9.f64 = double(temp.f32);
	// fcmpu cr6,f0,f9
	ctx.cr6.compare(ctx.f0.f64, ctx.f9.f64);
	// bge cr6,0x82b2e80c
	if (!ctx.cr6.lt) goto loc_82B2E80C;
	// fmr f0,f9
	ctx.f0.f64 = ctx.f9.f64;
loc_82B2E80C:
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f11,-13896(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f0,f11
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// ble cr6,0x82b2e820
	if (!ctx.cr6.gt) goto loc_82B2E820;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82B2E820:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f12,-18808(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18808);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f13,21484(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21484);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f13,f0,f12,f13
	ctx.f13.f64 = double(float(-(ctx.f0.f64 * ctx.f12.f64 - ctx.f13.f64)));
	// fmadds f10,f13,f0,f11
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f11.f64));
	// beq cr6,0x82b2e8d8
	if (ctx.cr6.eq) goto loc_82B2E8D8;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82b2e8d8
	if (ctx.cr6.eq) goto loc_82B2E8D8;
	// lfs f0,4(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f9
	ctx.cr6.compare(ctx.f0.f64, ctx.f9.f64);
	// bge cr6,0x82b2e858
	if (!ctx.cr6.lt) goto loc_82B2E858;
	// fmr f0,f9
	ctx.f0.f64 = ctx.f9.f64;
loc_82B2E858:
	// fcmpu cr6,f0,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// ble cr6,0x82b2e864
	if (!ctx.cr6.gt) goto loc_82B2E864;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82B2E864:
	// lis r11,-32247
	ctx.r11.s64 = -2113339392;
	// lfs f13,-14352(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -14352);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f12,f0,f12,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfd f13,-18816(r11)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18816);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// fcmpu cr6,f1,f13
	ctx.cr6.compare(ctx.f1.f64, ctx.f13.f64);
	// lfs f13,31072(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 31072);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// ble cr6,0x82b2e89c
	if (!ctx.cr6.gt) goto loc_82B2E89C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f0,-18824(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18824);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// blt cr6,0x82b2e8a0
	if (ctx.cr6.lt) goto loc_82B2E8A0;
loc_82B2E89C:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82B2E8A0:
	// fcmpu cr6,f10,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f10.f64, ctx.f11.f64);
	// bge cr6,0x82b2e8ac
	if (!ctx.cr6.lt) goto loc_82B2E8AC;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82B2E8AC:
	// fcmpu cr6,f13,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f13.f64, ctx.f11.f64);
	// bge cr6,0x82b2e8b8
	if (!ctx.cr6.lt) goto loc_82B2E8B8;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82B2E8B8:
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f0,-13884(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
	// fdivs f0,f0,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f1.f64));
	// fcmpu cr6,f0,f11
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// blt cr6,0x82b2e8d0
	if (ctx.cr6.lt) goto loc_82B2E8D0;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82B2E8D0:
	// fmuls f0,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// b 0x82b2e918
	goto loc_82B2E918;
loc_82B2E8D8:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f0,-18832(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18832);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// ble cr6,0x82b2e8f8
	if (!ctx.cr6.gt) goto loc_82B2E8F8;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f0,-18840(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18840);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// blt cr6,0x82b2e8fc
	if (ctx.cr6.lt) goto loc_82B2E8FC;
loc_82B2E8F8:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82B2E8FC:
	// fcmpu cr6,f10,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f10.f64, ctx.f11.f64);
	// bge cr6,0x82b2e908
	if (!ctx.cr6.lt) goto loc_82B2E908;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82B2E908:
	// fdivs f0,f11,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f11.f64 / ctx.f1.f64));
	// fcmpu cr6,f0,f11
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// blt cr6,0x82b2e918
	if (ctx.cr6.lt) goto loc_82B2E918;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82B2E918:
	// fmuls f13,f0,f10
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lfs f0,12124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12124);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32247
	ctx.r11.s64 = -2113339392;
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,4(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// lfs f0,-12628(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -12628);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,31
	ctx.r11.s64 = 2031616;
	// ori r10,r11,65535
	ctx.r10.u64 = ctx.r11.u64 | 65535;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f10,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f0,f1,f0,f10
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f10.f64));
	// fctidz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// stw r11,648(r31)
	PPC_STORE_U32(ctx.r31.u32 + 648, ctx.r11.u32);
	// ble cr6,0x82b2e968
	if (!ctx.cr6.gt) goto loc_82B2E968;
	// stw r10,648(r31)
	PPC_STORE_U32(ctx.r31.u32 + 648, ctx.r10.u32);
loc_82B2E968:
	// lfs f1,4(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// cmpwi cr6,r5,2
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 2, ctx.xer);
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// bne cr6,0x82b2e9b4
	if (!ctx.cr6.eq) goto loc_82B2E9B4;
	// lfs f0,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f9
	ctx.cr6.compare(ctx.f0.f64, ctx.f9.f64);
	// bge cr6,0x82b2e988
	if (!ctx.cr6.lt) goto loc_82B2E988;
	// fmr f0,f9
	ctx.f0.f64 = ctx.f9.f64;
loc_82B2E988:
	// fcmpu cr6,f0,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// ble cr6,0x82b2e994
	if (!ctx.cr6.gt) goto loc_82B2E994;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82B2E994:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,-18308(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18308);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f12,-11276(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11276);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// fmadds f12,f0,f13,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f13,-3044(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -3044);
	ctx.f13.f64 = double(temp.f32);
	// b 0x82b2ea34
	goto loc_82B2EA34;
loc_82B2E9B4:
	// cmpwi cr6,r5,3
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 3, ctx.xer);
	// bne cr6,0x82b2e9f4
	if (!ctx.cr6.eq) goto loc_82B2E9F4;
	// lfs f0,8(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f9
	ctx.cr6.compare(ctx.f0.f64, ctx.f9.f64);
	// bge cr6,0x82b2e9cc
	if (!ctx.cr6.lt) goto loc_82B2E9CC;
	// fmr f0,f9
	ctx.f0.f64 = ctx.f9.f64;
loc_82B2E9CC:
	// fcmpu cr6,f0,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// ble cr6,0x82b2e9d8
	if (!ctx.cr6.gt) goto loc_82B2E9D8;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82B2E9D8:
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lfs f13,-1968(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -1968);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lfs f12,-31552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -31552);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f0,f13,f12
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f2,f13,f0,f10
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f10.f64));
	// b 0x82b2ea44
	goto loc_82B2EA44;
loc_82B2E9F4:
	// cmpwi cr6,r5,5
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 5, ctx.xer);
	// bne cr6,0x82b2ea3c
	if (!ctx.cr6.eq) goto loc_82B2EA3C;
	// lfs f0,8(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f9
	ctx.cr6.compare(ctx.f0.f64, ctx.f9.f64);
	// bge cr6,0x82b2ea0c
	if (!ctx.cr6.lt) goto loc_82B2EA0C;
	// fmr f0,f9
	ctx.f0.f64 = ctx.f9.f64;
loc_82B2EA0C:
	// fcmpu cr6,f0,f11
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f11.f64);
	// ble cr6,0x82b2ea18
	if (!ctx.cr6.gt) goto loc_82B2EA18;
	// fmr f0,f11
	ctx.f0.f64 = ctx.f11.f64;
loc_82B2EA18:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,-18584(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18584);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f12,-19104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19104);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmadds f12,f0,f13,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f13,-11468(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11468);
	ctx.f13.f64 = double(temp.f32);
loc_82B2EA34:
	// fmadds f2,f12,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// b 0x82b2ea44
	goto loc_82B2EA44;
loc_82B2EA3C:
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f2,-13892(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f2.f64 = double(temp.f32);
loc_82B2EA44:
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// li r3,7
	ctx.r3.s64 = 7;
	// bne cr6,0x82b2ea54
	if (!ctx.cr6.eq) goto loc_82B2EA54;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
loc_82B2EA54:
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82b2e338
	ctx.lr = 0x82B2EA68;
	sub_82B2E338(ctx, base);
	// li r6,16
	ctx.r6.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r31,8
	ctx.r4.s64 = ctx.r31.s64 + 8;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b2db20
	ctx.lr = 0x82B2EA7C;
	sub_82B2DB20(ctx, base);
	// addi r1,r1,784
	ctx.r1.s64 = ctx.r1.s64 + 784;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2EA98"))) PPC_WEAK_FUNC(sub_82B2EA98);
PPC_FUNC_IMPL(__imp__sub_82B2EA98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82B2EAA0;
	__savegprlr_14(ctx, base);
	// stfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -168, ctx.f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r26,r7
	ctx.r26.u64 = ctx.r7.u64;
	// mr r21,r8
	ctx.r21.u64 = ctx.r8.u64;
	// mr r15,r9
	ctx.r15.u64 = ctx.r9.u64;
	// mr r14,r10
	ctx.r14.u64 = ctx.r10.u64;
	// bl 0x83158284
	ctx.lr = 0x82B2EAD4;
	__imp__VdQueryVideoMode(ctx, base);
	// lwz r29,120(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// cntlzw r11,r29
	ctx.r11.u64 = ctx.r29.u32 == 0 ? 32 : __builtin_clz(ctx.r29.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 ^ 1;
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// bne cr6,0x82b2eafc
	if (!ctx.cr6.eq) goto loc_82B2EAFC;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82b2eafc
	if (!ctx.cr6.eq) goto loc_82B2EAFC;
	// mr r30,r21
	ctx.r30.u64 = ctx.r21.u64;
loc_82B2EAFC:
	// lwz r20,420(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	// rlwinm r25,r27,16,16,31
	ctx.r25.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 16) & 0xFFFF;
	// lwz r18,21548(r28)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r28.u32 + 21548);
	// rlwinm r19,r31,16,16,31
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 16) & 0xFFFF;
	// lwz r16,21544(r28)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r28.u32 + 21544);
	// clrlwi r17,r31,16
	ctx.r17.u64 = ctx.r31.u32 & 0xFFFF;
	// rlwinm r28,r30,16,16,31
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 16) & 0xFFFF;
	// clrlwi r24,r30,16
	ctx.r24.u64 = ctx.r30.u32 & 0xFFFF;
	// lwz r11,0(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// clrlwi r27,r27,16
	ctx.r27.u64 = ctx.r27.u32 & 0xFFFF;
	// rlwinm r23,r26,16,16,31
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r26.u32 | (ctx.r26.u64 << 32), 16) & 0xFFFF;
	// clrlwi r22,r26,16
	ctx.r22.u64 = ctx.r26.u32 & 0xFFFF;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b2eb58
	if (!ctx.cr6.eq) goto loc_82B2EB58;
	// cmplw cr6,r28,r23
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r23.u32, ctx.xer);
	// bne cr6,0x82b2eb44
	if (!ctx.cr6.eq) goto loc_82B2EB44;
	// li r11,7
	ctx.r11.s64 = 7;
	// b 0x82b2eb54
	goto loc_82B2EB54;
loc_82B2EB44:
	// subfc r11,r23,r28
	ctx.xer.ca = ctx.r28.u32 >= ctx.r23.u32;
	ctx.r11.s64 = ctx.r28.s64 - ctx.r23.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r11,r11,5
	ctx.r11.s64 = ctx.r11.s64 + 5;
loc_82B2EB54:
	// stw r11,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r11.u32);
loc_82B2EB58:
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b2eb9c
	if (!ctx.cr6.eq) goto loc_82B2EB9C;
	// divwu r11,r22,r10
	ctx.r11.u32 = ctx.r22.u32 / ctx.r10.u32;
	// twllei r10,0
	// cmplw cr6,r24,r11
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b2eb88
	if (!ctx.cr6.eq) goto loc_82B2EB88;
	// subfic r11,r29,0
	ctx.xer.ca = ctx.r29.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r29.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,7
	ctx.r11.s64 = ctx.r11.s64 + 7;
	// b 0x82b2eb98
	goto loc_82B2EB98;
loc_82B2EB88:
	// subfc r11,r11,r24
	ctx.xer.ca = ctx.r24.u32 >= ctx.r11.u32;
	ctx.r11.s64 = ctx.r24.s64 - ctx.r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r11,r11,5
	ctx.r11.s64 = ctx.r11.s64 + 5;
loc_82B2EB98:
	// stw r11,0(r15)
	PPC_STORE_U32(ctx.r15.u32 + 0, ctx.r11.u32);
loc_82B2EB9C:
	// clrldi r9,r23,32
	ctx.r9.u64 = ctx.r23.u64 & 0xFFFFFFFF;
	// clrldi r11,r28,32
	ctx.r11.u64 = ctx.r28.u64 & 0xFFFFFFFF;
	// std r9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r9.u64);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f30,f0,f13
	ctx.f30.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// lfs f0,-11468(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11468);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f13,-18784(r11)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18784);
	// fcmpu cr6,f30,f0
	ctx.cr6.compare(ctx.f30.f64, ctx.f0.f64);
	// blt cr6,0x82b2ebec
	if (ctx.cr6.lt) goto loc_82B2EBEC;
	// fcmpu cr6,f30,f13
	ctx.cr6.compare(ctx.f30.f64, ctx.f13.f64);
	// bgt cr6,0x82b2ebec
	if (ctx.cr6.gt) goto loc_82B2EBEC;
	// fmr f30,f0
	ctx.f30.f64 = ctx.f0.f64;
loc_82B2EBEC:
	// clrldi r11,r24,32
	ctx.r11.u64 = ctx.r24.u64 & 0xFFFFFFFF;
	// clrldi r9,r22,32
	ctx.r9.u64 = ctx.r22.u64 & 0xFFFFFFFF;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// std r9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f11,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// lfd f12,88(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lfd f10,96(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fdivs f31,f12,f10
	ctx.f31.f64 = double(float(ctx.f12.f64 / ctx.f10.f64));
	// fcmpu cr6,f31,f0
	ctx.cr6.compare(ctx.f31.f64, ctx.f0.f64);
	// blt cr6,0x82b2ec48
	if (ctx.cr6.lt) goto loc_82B2EC48;
	// fcmpu cr6,f31,f13
	ctx.cr6.compare(ctx.f31.f64, ctx.f13.f64);
	// bgt cr6,0x82b2ec48
	if (ctx.cr6.gt) goto loc_82B2EC48;
	// fmr f31,f0
	ctx.f31.f64 = ctx.f0.f64;
	// b 0x82b2ec8c
	goto loc_82B2EC8C;
loc_82B2EC48:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f13,-18308(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18308);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f31,f13
	ctx.cr6.compare(ctx.f31.f64, ctx.f13.f64);
	// blt cr6,0x82b2ec68
	if (ctx.cr6.lt) goto loc_82B2EC68;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f0,-18792(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18792);
	// fcmpu cr6,f31,f0
	ctx.cr6.compare(ctx.f31.f64, ctx.f0.f64);
	// ble cr6,0x82b2ec88
	if (!ctx.cr6.gt) goto loc_82B2EC88;
loc_82B2EC68:
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f13,-13884(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f31,f13
	ctx.cr6.compare(ctx.f31.f64, ctx.f13.f64);
	// blt cr6,0x82b2ec8c
	if (ctx.cr6.lt) goto loc_82B2EC8C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfd f0,-18824(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18824);
	// fcmpu cr6,f31,f0
	ctx.cr6.compare(ctx.f31.f64, ctx.f0.f64);
	// bgt cr6,0x82b2ec8c
	if (ctx.cr6.gt) goto loc_82B2EC8C;
loc_82B2EC88:
	// fmr f31,f13
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f13.f64;
loc_82B2EC8C:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r9,140(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// twllei r9,0
	// lwz r11,2152(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2152);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// divwu r11,r10,r9
	ctx.r11.u32 = ctx.r10.u32 / ctx.r9.u32;
	// rlwinm r26,r11,1,0,30
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplwi cr6,r26,10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 10, ctx.xer);
	// ble cr6,0x82b2ecb4
	if (!ctx.cr6.gt) goto loc_82B2ECB4;
	// li r26,10
	ctx.r26.s64 = 10;
loc_82B2ECB4:
	// li r11,7680
	ctx.r11.s64 = 7680;
	// twllei r28,0
	// divwu r11,r11,r28
	ctx.r11.u32 = ctx.r11.u32 / ctx.r28.u32;
	// addi r30,r11,-1
	ctx.r30.s64 = ctx.r11.s64 + -1;
	// li r11,6
	ctx.r11.s64 = 6;
	// cmplwi cr6,r30,6
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 6, ctx.xer);
	// bgt cr6,0x82b2ecd4
	if (ctx.cr6.gt) goto loc_82B2ECD4;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
loc_82B2ECD4:
	// clrldi r9,r9,32
	ctx.r9.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// std r9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f0,96(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f0
	ctx.f12.f64 = double(float(ctx.f0.f64));
	// frsp f0,f13
	ctx.f0.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f12,f30
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fdivs f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// fctidz f12,f12
	ctx.f12.s64 = (ctx.f12.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f12.f64));
	// stfiwx f12,0,r8
	PPC_STORE_U32(ctx.r8.u32, ctx.f12.u32);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82b2ed2c
	if (!ctx.cr6.lt) goto loc_82B2ED2C;
	// cmplwi cr6,r30,6
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 6, ctx.xer);
	// ble cr6,0x82b2ed40
	if (!ctx.cr6.gt) goto loc_82B2ED40;
	// li r30,6
	ctx.r30.s64 = 6;
	// b 0x82b2ed40
	goto loc_82B2ED40;
loc_82B2ED2C:
	// fdivs f0,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// fctidz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82B2ED40:
	// lwz r31,436(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	// li r5,1408
	ctx.r5.s64 = 1408;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e29500
	ctx.lr = 0x82B2ED54;
	sub_82E29500(ctx, base);
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r5,0(r15)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// mr r6,r14
	ctx.r6.u64 = ctx.r14.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r30,r31,652
	ctx.r30.s64 = ctx.r31.s64 + 652;
	// bl 0x82b2e7b8
	ctx.lr = 0x82B2ED78;
	sub_82B2E7B8(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// lwz r5,0(r20)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r6,428(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x82b2e7b8
	ctx.lr = 0x82B2ED98;
	sub_82B2E7B8(ctx, base);
	// addi r6,r28,3
	ctx.r6.s64 = ctx.r28.s64 + 3;
	// rlwinm r11,r21,16,16,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r21.u32 | (ctx.r21.u64 << 32), 16) & 0xFFFF;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// rlwinm r5,r6,30,2,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// lwz r8,648(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	// clrlwi r6,r21,16
	ctx.r6.u64 = ctx.r21.u32 & 0xFFFF;
	// addi r10,r11,31
	ctx.r10.s64 = ctx.r11.s64 + 31;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// rlwinm r6,r6,0,0,30
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFE;
	// subf r26,r23,r18
	ctx.r26.s64 = ctx.r18.s64 - ctx.r23.s64;
	// cntlzw r4,r29
	ctx.r4.u64 = ctx.r29.u32 == 0 ? 32 : __builtin_clz(ctx.r29.u32);
	// stw r11,1348(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1348, ctx.r11.u32);
	// subf r3,r22,r16
	ctx.r3.s64 = ctx.r16.s64 - ctx.r22.s64;
	// stw r7,1360(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1360, ctx.r7.u32);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// clrlwi r22,r17,20
	ctx.r22.u64 = ctx.r17.u32 & 0xFFF;
	// stw r6,1344(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1344, ctx.r6.u32);
	// addi r6,r9,-1
	ctx.r6.s64 = ctx.r9.s64 + -1;
	// addi r23,r7,-1
	ctx.r23.s64 = ctx.r7.s64 + -1;
	// stw r11,1332(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1332, ctx.r11.u32);
	// rlwinm r7,r4,27,31,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x1;
	// stw r11,1336(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1336, ctx.r11.u32);
	// rlwimi r6,r23,8,20,23
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r23.u32, 8) & 0xF00) | (ctx.r6.u64 & 0xFFFFFFFFFFFFF0FF);
	// rlwinm r4,r28,16,4,15
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 16) & 0xFFF0000;
	// clrlwi r28,r24,20
	ctx.r28.u64 = ctx.r24.u32 & 0xFFF;
	// rlwinm r24,r19,16,4,15
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r19.u32 | (ctx.r19.u64 << 32), 16) & 0xFFF0000;
	// or r4,r4,r28
	ctx.r4.u64 = ctx.r4.u64 | ctx.r28.u64;
	// clrlwi r5,r5,22
	ctx.r5.u64 = ctx.r5.u32 & 0x3FF;
	// or r28,r24,r22
	ctx.r28.u64 = ctx.r24.u64 | ctx.r22.u64;
	// subf r3,r27,r3
	ctx.r3.s64 = ctx.r3.s64 - ctx.r27.s64;
	// subf r26,r25,r26
	ctx.r26.s64 = ctx.r26.s64 - ctx.r25.s64;
	// stw r4,1356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1356, ctx.r4.u32);
	// rlwinm r10,r10,0,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFE0;
	// stw r5,1404(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1404, ctx.r5.u32);
	// clrlwi r5,r3,20
	ctx.r5.u64 = ctx.r3.u32 & 0xFFF;
	// stw r28,1352(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1352, ctx.r28.u32);
	// clrlwi r4,r27,20
	ctx.r4.u64 = ctx.r27.u32 & 0xFFF;
	// clrlwi r3,r25,20
	ctx.r3.u64 = ctx.r25.u32 & 0xFFF;
	// clrlwi r28,r26,20
	ctx.r28.u64 = ctx.r26.u32 & 0xFFF;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// stw r10,1340(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1340, ctx.r10.u32);
	// stw r10,1320(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1320, ctx.r10.u32);
	// stw r4,1304(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1304, ctx.r4.u32);
	// andi. r6,r6,3847
	ctx.r6.u64 = ctx.r6.u64 & 3847;
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// stw r5,1308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1308, ctx.r5.u32);
	// stw r3,1312(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1312, ctx.r3.u32);
	// stw r28,1316(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1316, ctx.r28.u32);
	// stw r6,1364(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1364, ctx.r6.u32);
	// lwz r10,648(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 648);
	// rlwinm r10,r10,5,6,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0x3FFFFE0;
	// stw r10,1376(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1376, ctx.r10.u32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// slw r7,r8,r7
	ctx.r7.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r7.u8 & 0x3F));
	// clrlwi r7,r7,6
	ctx.r7.u64 = ctx.r7.u32 & 0x3FFFFFF;
	// lfs f11,-18800(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18800);
	ctx.f11.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f0,-27564(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -27564);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,256
	ctx.r10.s64 = 16777216;
	// stw r11,1372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1372, ctx.r11.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r7,1392(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1392, ctx.r7.u32);
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stw r10,1388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1388, ctx.r10.u32);
	// lwz r11,648(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 648);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r11.u64);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// lfd f12,88(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmadds f12,f13,f11,f12
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 + ctx.f12.f64));
	// lfs f13,-13896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fadds f10,f12,f13
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f12,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f10,f10,f0,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f12.f64));
	// fctidz f10,f10
	ctx.f10.s64 = (ctx.f10.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f10.f64));
	// stfiwx f10,0,r6
	PPC_STORE_U32(ctx.r6.u32, ctx.f10.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,9,12,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 9) & 0xFFE00;
	// stw r11,1380(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1380, ctx.r11.u32);
	// beq cr6,0x82b2ef80
	if (ctx.cr6.eq) goto loc_82B2EF80;
	// clrldi r10,r8,32
	ctx.r10.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// clrldi r9,r9,32
	ctx.r9.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// std r10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r10.u64);
	// std r9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r9.u64);
	// lfs f9,-11016(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11016);
	ctx.f9.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f8,-18804(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18804);
	ctx.f8.f64 = double(temp.f32);
	// lfd f11,96(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// lfd f10,88(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// fmadds f9,f11,f9,f10
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f10.f64));
	// fmadds f11,f11,f8,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + ctx.f10.f64));
	// fadds f10,f9,f13
	ctx.f10.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fmadds f11,f10,f0,f12
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f12.f64));
	// fmadds f0,f13,f0,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f12.f64));
	// fctidz f13,f11
	ctx.f13.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f11.f64));
	// stfiwx f13,0,r8
	PPC_STORE_U32(ctx.r8.u32, ctx.f13.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// fctidz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f0.f64));
	// rlwinm r11,r11,9,13,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 9) & 0x7FE00;
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// stw r11,1396(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1396, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,9,13,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 9) & 0x7FE00;
	// stw r11,1400(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1400, ctx.r11.u32);
	// b 0x82b2efcc
	goto loc_82B2EFCC;
loc_82B2EF80:
	// clrldi r11,r8,32
	ctx.r11.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// clrldi r10,r9,32
	ctx.r10.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r11.u64);
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f10,96(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// lfd f9,88(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// fcfid f9,f9
	ctx.f9.f64 = double(ctx.f9.s64);
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// frsp f9,f9
	ctx.f9.f64 = double(float(ctx.f9.f64));
	// fmadds f11,f10,f11,f9
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f9.f64));
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fmadds f0,f13,f0,f12
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f12.f64));
	// fctidz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,9,13,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 9) & 0x7FE00;
	// stw r11,1396(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1396, ctx.r11.u32);
loc_82B2EFCC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// lfd f30,-168(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2EFE0"))) PPC_WEAK_FUNC(sub_82B2EFE0);
PPC_FUNC_IMPL(__imp__sub_82B2EFE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B2EFE8;
	__savegprlr_26(ctx, base);
	// stwu r1,-2464(r1)
	ea = -2464 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r7,r1,128
	ctx.r7.s64 = ctx.r1.s64 + 128;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82b2d4c8
	ctx.lr = 0x82B2F000;
	sub_82B2D4C8(ctx, base);
	// lwz r11,136(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r6,128(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r5,132(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// subf r9,r6,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r6.s64;
	// lwz r11,140(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lwz r10,21548(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21548);
	// lwz r8,21540(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21540);
	// subf r3,r5,r11
	ctx.r3.s64 = ctx.r11.s64 - ctx.r5.s64;
	// lwz r11,144(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x82b2f05c
	if (ctx.cr6.eq) goto loc_82B2F05C;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82b2f040
	if (ctx.cr6.lt) goto loc_82B2F040;
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// bgt cr6,0x82b2f040
	if (ctx.cr6.gt) goto loc_82B2F040;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82B2F040:
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82b2f05c
	if (ctx.cr6.lt) goto loc_82B2F05C;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// bgt cr6,0x82b2f05c
	if (ctx.cr6.gt) goto loc_82B2F05C;
	// subf r8,r11,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r11.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// rlwinm r6,r8,31,1,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 31) & 0x7FFFFFFF;
loc_82B2F05C:
	// subf r7,r11,r10
	ctx.r7.s64 = ctx.r10.s64 - ctx.r11.s64;
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// lwz r8,21544(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 21544);
	// clrlwi r4,r30,16
	ctx.r4.u64 = ctx.r30.u32 & 0xFFFF;
	// rlwinm r27,r11,16,0,15
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 16) & 0xFFFF0000;
	// subf r30,r10,r8
	ctx.r30.s64 = ctx.r8.s64 - ctx.r10.s64;
	// rlwinm r8,r7,31,1,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r7,r30,31,1,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 31) & 0x7FFFFFFF;
	// clrlwi r30,r29,16
	ctx.r30.u64 = ctx.r29.u32 & 0xFFFF;
	// clrlwi r11,r9,16
	ctx.r11.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwimi r30,r4,16,0,15
	ctx.r30.u64 = (__builtin_rotateleft32(ctx.r4.u32, 16) & 0xFFFF0000) | (ctx.r30.u64 & 0xFFFFFFFF0000FFFF);
	// clrlwi r4,r5,16
	ctx.r4.u64 = ctx.r5.u32 & 0xFFFF;
	// clrlwi r5,r3,16
	ctx.r5.u64 = ctx.r3.u32 & 0xFFFF;
	// clrlwi r28,r10,16
	ctx.r28.u64 = ctx.r10.u32 & 0xFFFF;
	// rlwimi r5,r11,16,0,15
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r5.u64 & 0xFFFFFFFF0000FFFF);
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// clrlwi r10,r6,16
	ctx.r10.u64 = ctx.r6.u32 & 0xFFFF;
	// addi r9,r1,992
	ctx.r9.s64 = ctx.r1.s64 + 992;
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// clrlwi r29,r7,16
	ctx.r29.u64 = ctx.r7.u32 & 0xFFFF;
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// rlwimi r4,r10,16,0,15
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r4.u64 & 0xFFFFFFFF0000FFFF);
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// addi r10,r1,156
	ctx.r10.s64 = ctx.r1.s64 + 156;
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// addi r9,r1,116
	ctx.r9.s64 = ctx.r1.s64 + 116;
	// stw r3,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r3.u32);
	// or r7,r28,r27
	ctx.r7.u64 = ctx.r28.u64 | ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// clrlwi r11,r8,16
	ctx.r11.u64 = ctx.r8.u32 & 0xFFFF;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// rlwimi r29,r11,16,0,15
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r29.u64 & 0xFFFFFFFF0000FFFF);
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// bl 0x82b2ea98
	ctx.lr = 0x82B2F0F0;
	sub_82B2EA98(ctx, base);
	// lis r5,-32768
	ctx.r5.s64 = -2147483648;
	// li r4,800
	ctx.r4.s64 = 800;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x83158104
	ctx.lr = 0x82B2F100;
	__imp__RtlFillMemoryUlong(ctx, base);
	// li r4,220
	ctx.r4.s64 = 220;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dd08
	ctx.lr = 0x82B2F10C;
	sub_82B1DD08(ctx, base);
	// lwz r11,128(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// lwz r8,140(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// addi r7,r1,992
	ctx.r7.s64 = ctx.r1.s64 + 992;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// lwz r10,132(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// subf r8,r10,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r10.s64;
	// clrlwi r26,r10,16
	ctx.r26.u64 = ctx.r10.u32 & 0xFFFF;
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// clrlwi r10,r9,16
	ctx.r10.u64 = ctx.r9.u32 & 0xFFFF;
	// stw r7,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r7.u32);
	// li r9,200
	ctx.r9.s64 = 200;
	// clrlwi r4,r8,16
	ctx.r4.u64 = ctx.r8.u32 & 0xFFFF;
	// addi r8,r1,192
	ctx.r8.s64 = ctx.r1.s64 + 192;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwimi r26,r11,16,0,15
	ctx.r26.u64 = (__builtin_rotateleft32(ctx.r11.u32, 16) & 0xFFFF0000) | (ctx.r26.u64 & 0xFFFFFFFF0000FFFF);
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// or r6,r5,r27
	ctx.r6.u64 = ctx.r5.u64 | ctx.r27.u64;
	// rlwimi r4,r10,16,0,15
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r4.u64 & 0xFFFFFFFF0000FFFF);
	// stw r8,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r8.u32);
	// addi r9,r1,156
	ctx.r9.s64 = ctx.r1.s64 + 156;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// lwz r8,116(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x83158364
	ctx.lr = 0x82B2F184;
	__imp__VdInitializeScalerCommandBuffer(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// rlwinm r30,r11,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r28,4
	ctx.r3.s64 = ctx.r28.s64 + 4;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B2F19C;
	sub_82E28FD0(ctx, base);
	// add r11,r30,r28
	ctx.r11.u64 = ctx.r30.u64 + ctx.r28.u64;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r1,r1,2464
	ctx.r1.s64 = ctx.r1.s64 + 2464;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2F1B0"))) PPC_WEAK_FUNC(sub_82B2F1B0);
PPC_FUNC_IMPL(__imp__sub_82B2F1B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B2F1B8;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,14828(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 14828);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b2f1f0
	if (ctx.cr0.eq) goto loc_82B2F1F0;
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// lwz r11,36(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// rlwinm r10,r10,2,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x2;
	// clrlwi r9,r11,19
	ctx.r9.u64 = ctx.r11.u32 & 0x1FFF;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r11,r11,19,19,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 19) & 0x1FFF;
	// add r30,r9,r10
	ctx.r30.u64 = ctx.r9.u64 + ctx.r10.u64;
	// add r29,r11,r10
	ctx.r29.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82b2f1f8
	goto loc_82B2F1F8;
loc_82B2F1F0:
	// lwz r30,13544(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13544);
	// lwz r29,13548(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13548);
loc_82B2F1F8:
	// addi r28,r31,13724
	ctx.r28.s64 = ctx.r31.s64 + 13724;
	// li r5,56
	ctx.r5.s64 = 56;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B2F208;
	sub_82E28FD0(ctx, base);
	// lbz r11,10942(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 10942);
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// ori r11,r11,16
	ctx.r11.u64 = ctx.r11.u64 | 16;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stb r11,10942(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10942, ctx.r11.u8);
	// bl 0x82b2d668
	ctx.lr = 0x82B2F228;
	sub_82B2D668(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2F230"))) PPC_WEAK_FUNC(sub_82B2F230);
PPC_FUNC_IMPL(__imp__sub_82B2F230) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// bl 0x82b2d5f0
	ctx.lr = 0x82B2F244;
	sub_82B2D5F0(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82b2f1b0
	ctx.lr = 0x82B2F24C;
	sub_82B2F1B0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2F260"))) PPC_WEAK_FUNC(sub_82B2F260);
PPC_FUNC_IMPL(__imp__sub_82B2F260) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B2F268;
	__savegprlr_28(ctx, base);
	// stwu r1,-2192(r1)
	ea = -2192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// bl 0x831583a4
	ctx.lr = 0x82B2F27C;
	__imp__KeEnterCriticalRegion(ctx, base);
	// lis r28,-32256
	ctx.r28.s64 = -2113929216;
	// lwz r3,2172(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2172);
	// bl 0x83157d14
	ctx.lr = 0x82B2F288;
	__imp__RtlEnterCriticalSection(ctx, base);
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82b2f298
	if (ctx.cr6.eq) goto loc_82B2F298;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x83158394
	ctx.lr = 0x82B2F298;
	__imp__VdRetrainEDRAMWorker(ctx, base);
loc_82B2F298:
	// li r11,0
	ctx.r11.s64 = 0;
	// li r8,2048
	ctx.r8.s64 = 2048;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// li r5,4096
	ctx.r5.s64 = 4096;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x83158384
	ctx.lr = 0x82B2F2C0;
	__imp__VdRetrainEDRAM(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2f330
	if (ctx.cr0.eq) goto loc_82B2F330;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82b2f2d8
	if (!ctx.cr6.eq) goto loc_82B2F2D8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dd70
	ctx.lr = 0x82B2F2D8;
	sub_82B1DD70(ctx, base);
loc_82B2F2D8:
	// li r4,4096
	ctx.r4.s64 = 4096;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dd08
	ctx.lr = 0x82B2F2E4;
	sub_82B1DD08(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r8,2048
	ctx.r8.s64 = 2048;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// li r5,4096
	ctx.r5.s64 = 4096;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x83158384
	ctx.lr = 0x82B2F30C;
	__imp__VdRetrainEDRAM(ctx, base);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// bl 0x82b1dd70
	ctx.lr = 0x82B2F328;
	sub_82B1DD70(ctx, base);
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82b2f2d8
	if (!ctx.cr6.eq) goto loc_82B2F2D8;
loc_82B2F330:
	// lwz r3,2172(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2172);
	// bl 0x83157d24
	ctx.lr = 0x82B2F338;
	__imp__RtlLeaveCriticalSection(ctx, base);
	// bl 0x83158374
	ctx.lr = 0x82B2F33C;
	__imp__KeLeaveCriticalRegion(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,2192
	ctx.r1.s64 = ctx.r1.s64 + 2192;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2F348"))) PPC_WEAK_FUNC(sub_82B2F348);
PPC_FUNC_IMPL(__imp__sub_82B2F348) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31967
	ctx.r10.s64 = -2094989312;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,29263(r10)
	PPC_STORE_U8(ctx.r10.u32 + 29263, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2F360"))) PPC_WEAK_FUNC(sub_82B2F360);
PPC_FUNC_IMPL(__imp__sub_82B2F360) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31967
	ctx.r10.s64 = -2094989312;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,29263(r10)
	PPC_STORE_U8(ctx.r10.u32 + 29263, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2F378"))) PPC_WEAK_FUNC(sub_82B2F378);
PPC_FUNC_IMPL(__imp__sub_82B2F378) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x82e29e90
	ctx.lr = 0x82B2F388;
	sub_82E29E90(ctx, base);
	// lis r11,1
	ctx.r11.s64 = 65536;
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// subf r11,r3,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r3.s64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2F3B0"))) PPC_WEAK_FUNC(sub_82B2F3B0);
PPC_FUNC_IMPL(__imp__sub_82B2F3B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82e29e90
	ctx.lr = 0x82B2F3C8;
	sub_82E29E90(ctx, base);
	// lis r11,2
	ctx.r11.s64 = 131072;
	// ori r11,r11,32728
	ctx.r11.u64 = ctx.r11.u64 | 32728;
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82b2f3e4
	if (!ctx.cr6.lt) goto loc_82B2F3E4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e29e90
	ctx.lr = 0x82B2F3E0;
	sub_82E29E90(ctx, base);
	// extsw r11,r3
	ctx.r11.s64 = ctx.r3.s32;
loc_82B2F3E4:
	// lis r10,-31975
	ctx.r10.s64 = -2095513600;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,-24476(r10)
	PPC_STORE_U32(ctx.r10.u32 + -24476, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2F408"))) PPC_WEAK_FUNC(sub_82B2F408);
PPC_FUNC_IMPL(__imp__sub_82B2F408) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r31,r11,29000
	ctx.r31.s64 = ctx.r11.s64 + 29000;
	// li r5,260
	ctx.r5.s64 = 260;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e2ab28
	ctx.lr = 0x82B2F430;
	sub_82E2AB28(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,262(r31)
	PPC_STORE_U8(ctx.r31.u32 + 262, ctx.r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2F450"))) PPC_WEAK_FUNC(sub_82B2F450);
PPC_FUNC_IMPL(__imp__sub_82B2F450) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31967
	ctx.r10.s64 = -2094989312;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,29261(r10)
	PPC_STORE_U8(ctx.r10.u32 + 29261, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2F468"))) PPC_WEAK_FUNC(sub_82B2F468);
PPC_FUNC_IMPL(__imp__sub_82B2F468) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-31967
	ctx.r10.s64 = -2094989312;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,29260(r10)
	PPC_STORE_U8(ctx.r10.u32 + 29260, ctx.r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2F480"))) PPC_WEAK_FUNC(sub_82B2F480);
PPC_FUNC_IMPL(__imp__sub_82B2F480) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,21700
	ctx.r11.s64 = ctx.r3.s64 + 21700;
	// li r9,-1
	ctx.r9.s64 = -1;
	// li r10,41
	ctx.r10.s64 = 41;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82B2F490:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82b2f490
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B2F490;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2F4A8"))) PPC_WEAK_FUNC(sub_82B2F4A8);
PPC_FUNC_IMPL(__imp__sub_82B2F4A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82B2F4B0;
	__savegprlr_25(ctx, base);
	// stwu r1,-688(r1)
	ea = -688 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addi r10,r10,-11136
	ctx.r10.s64 = ctx.r10.s64 + -11136;
	// addi r28,r11,6
	ctx.r28.s64 = ctx.r11.s64 + 6;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// lis r25,-32038
	ctx.r25.s64 = -2099642368;
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// li r5,54
	ctx.r5.s64 = 54;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,90
	ctx.r3.s64 = ctx.r1.s64 + 90;
	// ori r25,r25,7
	ctx.r25.u64 = ctx.r25.u64 | 7;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// lhz r11,8(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 8);
	// sth r11,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, ctx.r11.u16);
	// bl 0x82e29500
	ctx.lr = 0x82B2F4FC;
	sub_82E29500(ctx, base);
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r10,-3256
	ctx.r10.s64 = ctx.r10.s64 + -3256;
	// addi r11,r11,-11152
	ctx.r11.s64 = ctx.r11.s64 + -11152;
	// li r5,51
	ctx.r5.s64 = 51;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,161
	ctx.r3.s64 = ctx.r1.s64 + 161;
	// stw r10,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lbz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 12);
	// stw r10,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r10.u32);
	// stb r11,160(r1)
	PPC_STORE_U8(ctx.r1.u32 + 160, ctx.r11.u8);
	// bl 0x82e29500
	ctx.lr = 0x82B2F540;
	sub_82E29500(ctx, base);
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r10,-3232
	ctx.r10.s64 = ctx.r10.s64 + -3232;
	// addi r11,r11,-11164
	ctx.r11.s64 = ctx.r11.s64 + -11164;
	// li r5,54
	ctx.r5.s64 = 54;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,226
	ctx.r3.s64 = ctx.r1.s64 + 226;
	// stw r10,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// stw r10,220(r1)
	PPC_STORE_U32(ctx.r1.u32 + 220, ctx.r10.u32);
	// sth r11,224(r1)
	PPC_STORE_U16(ctx.r1.u32 + 224, ctx.r11.u16);
	// bl 0x82e29500
	ctx.lr = 0x82B2F57C;
	sub_82E29500(ctx, base);
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r10,-3208
	ctx.r10.s64 = ctx.r10.s64 + -3208;
	// addi r11,r11,-11184
	ctx.r11.s64 = ctx.r11.s64 + -11184;
	// addi r9,r1,284
	ctx.r9.s64 = ctx.r1.s64 + 284;
	// stw r10,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r10.u32);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// li r11,19
	ctx.r11.s64 = 19;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_82B2F5A0:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stb r11,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r11.u8);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// bdnz 0x82b2f5a0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B2F5A0;
	// li r5,45
	ctx.r5.s64 = 45;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,303
	ctx.r3.s64 = ctx.r1.s64 + 303;
	// bl 0x82e29500
	ctx.lr = 0x82B2F5C4;
	sub_82E29500(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// addi r4,r11,-11212
	ctx.r4.s64 = ctx.r11.s64 + -11212;
	// addi r11,r10,-3152
	ctx.r11.s64 = ctx.r10.s64 + -3152;
	// addi r3,r1,352
	ctx.r3.s64 = ctx.r1.s64 + 352;
	// li r5,27
	ctx.r5.s64 = 27;
	// stw r11,348(r1)
	PPC_STORE_U32(ctx.r1.u32 + 348, ctx.r11.u32);
	// bl 0x82e28fd0
	ctx.lr = 0x82B2F5E4;
	sub_82E28FD0(ctx, base);
	// li r5,37
	ctx.r5.s64 = 37;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,379
	ctx.r3.s64 = ctx.r1.s64 + 379;
	// bl 0x82e29500
	ctx.lr = 0x82B2F5F4;
	sub_82E29500(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// addi r4,r11,-11240
	ctx.r4.s64 = ctx.r11.s64 + -11240;
	// addi r11,r10,-3064
	ctx.r11.s64 = ctx.r10.s64 + -3064;
	// addi r3,r1,420
	ctx.r3.s64 = ctx.r1.s64 + 420;
	// li r5,25
	ctx.r5.s64 = 25;
	// stw r11,416(r1)
	PPC_STORE_U32(ctx.r1.u32 + 416, ctx.r11.u32);
	// bl 0x82e28fd0
	ctx.lr = 0x82B2F614;
	sub_82E28FD0(ctx, base);
	// li r5,39
	ctx.r5.s64 = 39;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,445
	ctx.r3.s64 = ctx.r1.s64 + 445;
	// bl 0x82e29500
	ctx.lr = 0x82B2F624;
	sub_82E29500(ctx, base);
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r10,-2968
	ctx.r10.s64 = ctx.r10.s64 + -2968;
	// addi r11,r11,-11256
	ctx.r11.s64 = ctx.r11.s64 + -11256;
	// li r5,49
	ctx.r5.s64 = 49;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,503
	ctx.r3.s64 = ctx.r1.s64 + 503;
	// stw r10,484(r1)
	PPC_STORE_U32(ctx.r1.u32 + 484, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,488(r1)
	PPC_STORE_U32(ctx.r1.u32 + 488, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,492(r1)
	PPC_STORE_U32(ctx.r1.u32 + 492, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r10,496(r1)
	PPC_STORE_U32(ctx.r1.u32 + 496, ctx.r10.u32);
	// lhz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 12);
	// lbz r11,14(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 14);
	// sth r10,500(r1)
	PPC_STORE_U16(ctx.r1.u32 + 500, ctx.r10.u16);
	// stb r11,502(r1)
	PPC_STORE_U8(ctx.r1.u32 + 502, ctx.r11.u8);
	// bl 0x82e29500
	ctx.lr = 0x82B2F670;
	sub_82E29500(ctx, base);
	// lis r10,-32077
	ctx.r10.s64 = -2102198272;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r10,-2992
	ctx.r10.s64 = ctx.r10.s64 + -2992;
	// addi r11,r11,-11272
	ctx.r11.s64 = ctx.r11.s64 + -11272;
	// li r5,51
	ctx.r5.s64 = 51;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,569
	ctx.r3.s64 = ctx.r1.s64 + 569;
	// stw r10,552(r1)
	PPC_STORE_U32(ctx.r1.u32 + 552, ctx.r10.u32);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,556(r1)
	PPC_STORE_U32(ctx.r1.u32 + 556, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,560(r1)
	PPC_STORE_U32(ctx.r1.u32 + 560, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lbz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 12);
	// stw r10,564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 564, ctx.r10.u32);
	// stb r11,568(r1)
	PPC_STORE_U8(ctx.r1.u32 + 568, ctx.r11.u8);
	// bl 0x82e29500
	ctx.lr = 0x82B2F6B4;
	sub_82E29500(ctx, base);
	// lis r11,-32077
	ctx.r11.s64 = -2102198272;
	// li r29,0
	ctx.r29.s64 = 0;
	// addi r11,r11,-2968
	ctx.r11.s64 = ctx.r11.s64 + -2968;
	// addi r31,r1,80
	ctx.r31.s64 = ctx.r1.s64 + 80;
	// stw r11,620(r1)
	PPC_STORE_U32(ctx.r1.u32 + 620, ctx.r11.u32);
loc_82B2F6C8:
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B2F6D0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b2f6d0
	if (!ctx.cr6.eq) goto loc_82B2F6D0;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// rotlwi r30,r11,0
	ctx.r30.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82e2efb0
	ctx.lr = 0x82B2F6FC;
	sub_82E2EFB0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2f734
	if (ctx.cr0.eq) goto loc_82B2F734;
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r31,r31,68
	ctx.r31.s64 = ctx.r31.s64 + 68;
	// cmplwi cr6,r29,8
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 8, ctx.xer);
	// blt cr6,0x82b2f6c8
	if (ctx.cr6.lt) goto loc_82B2F6C8;
loc_82B2F714:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r4,r11,-19048
	ctx.r4.s64 = ctx.r11.s64 + -19048;
loc_82B2F71C:
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82e2ab28
	ctx.lr = 0x82B2F728;
	sub_82E2AB28(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
loc_82B2F734:
	// mulli r10,r29,68
	ctx.r10.s64 = ctx.r29.s64 * 68;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// add r11,r30,r28
	ctx.r11.u64 = ctx.r30.u64 + ctx.r28.u64;
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// lwzx r11,r10,r9
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B2F750;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lis r25,730
	ctx.r25.s64 = 47841280;
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b2f714
	if (ctx.cr0.eq) goto loc_82B2F714;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r4,r11,-11280
	ctx.r4.s64 = ctx.r11.s64 + -11280;
	// b 0x82b2f71c
	goto loc_82B2F71C;
}

__attribute__((alias("__imp__sub_82B2F768"))) PPC_WEAK_FUNC(sub_82B2F768);
PPC_FUNC_IMPL(__imp__sub_82B2F768) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82B2F770;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// li r8,4096
	ctx.r8.s64 = 4096;
	// li r7,-1
	ctx.r7.s64 = -1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1028
	ctx.r5.s64 = 1028;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// li r30,0
	ctx.r30.s64 = 0;
	// bl 0x83157ef4
	ctx.lr = 0x82B2F7A4;
	__imp__MmAllocatePhysicalMemoryEx(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne 0x82b2f7d8
	if (!ctx.cr0.eq) goto loc_82B2F7D8;
	// lis r4,-18048
	ctx.r4.s64 = -1182793728;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82547910
	ctx.lr = 0x82B2F7B8;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b2f7c8
	if (ctx.cr0.eq) goto loc_82B2F7C8;
	// li r30,1
	ctx.r30.s64 = 1;
	// b 0x82b2f7d8
	goto loc_82B2F7D8;
loc_82B2F7C8:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b2f7d8
	if (ctx.cr6.eq) goto loc_82B2F7D8;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// li r30,2
	ctx.r30.s64 = 2;
loc_82B2F7D8:
	// stw r3,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r3.u32);
	// stw r30,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r30.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B2F7E8"))) PPC_WEAK_FUNC(sub_82B2F7E8);
PPC_FUNC_IMPL(__imp__sub_82B2F7E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r31,r3,21680
	ctx.r31.s64 = ctx.r3.s64 + 21680;
	// lwz r3,592(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 592);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b2f830
	if (ctx.cr0.eq) goto loc_82B2F830;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// rlwinm. r11,r11,0,4,4
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b2f828
	if (!ctx.cr0.eq) goto loc_82B2F828;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x83157f24
	ctx.lr = 0x82B2F824;
	__imp__MmFreePhysicalMemory(ctx, base);
	// b 0x82b2f830
	goto loc_82B2F830;
loc_82B2F828:
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x82547938
	ctx.lr = 0x82B2F830;
	sub_82547938(ctx, base);
loc_82B2F830:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lis r30,-20096
	ctx.r30.s64 = -1317011456;
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b2f86c
	if (ctx.cr0.eq) goto loc_82B2F86C;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// srawi r11,r11,30
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 30;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82b2f860
	if (ctx.cr6.lt) goto loc_82B2F860;
	// bne cr6,0x82b2f86c
	if (!ctx.cr6.eq) goto loc_82B2F86C;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82547938
	ctx.lr = 0x82B2F85C;
	sub_82547938(ctx, base);
	// b 0x82b2f86c
	goto loc_82B2F86C;
loc_82B2F860:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x83157f24
	ctx.lr = 0x82B2F86C;
	__imp__MmFreePhysicalMemory(ctx, base);
loc_82B2F86C:
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b2f8a8
	if (ctx.cr0.eq) goto loc_82B2F8A8;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// srawi r11,r11,30
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 30;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82b2f89c
	if (ctx.cr6.lt) goto loc_82B2F89C;
	// bne cr6,0x82b2f8a8
	if (!ctx.cr6.eq) goto loc_82B2F8A8;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82547938
	ctx.lr = 0x82B2F898;
	sub_82547938(ctx, base);
	// b 0x82b2f8a8
	goto loc_82B2F8A8;
loc_82B2F89C:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x83157f24
	ctx.lr = 0x82B2F8A8;
	__imp__MmFreePhysicalMemory(ctx, base);
loc_82B2F8A8:
	// li r5,620
	ctx.r5.s64 = 620;
	// lwz r30,616(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 616);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e29500
	ctx.lr = 0x82B2F8BC;
	sub_82E29500(ctx, base);
	// addi r11,r31,20
	ctx.r11.s64 = ctx.r31.s64 + 20;
	// li r9,-1
	ctx.r9.s64 = -1;
	// stw r30,616(r31)
	PPC_STORE_U32(ctx.r31.u32 + 616, ctx.r30.u32);
	// li r10,41
	ctx.r10.s64 = 41;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82B2F8D0:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82b2f8d0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B2F8D0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B2F8F8"))) PPC_WEAK_FUNC(sub_82B2F8F8);
PPC_FUNC_IMPL(__imp__sub_82B2F8F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e48
	ctx.lr = 0x82B2F900;
	__savegprlr_20(ctx, base);
	// stwu r1,-480(r1)
	ea = -480 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r31,r3,21680
	ctx.r31.s64 = ctx.r3.s64 + 21680;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// addi r3,r31,368
	ctx.r3.s64 = ctx.r31.s64 + 368;
	// addi r9,r31,372
	ctx.r9.s64 = ctx.r31.s64 + 372;
	// lwz r10,604(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// clrlwi r10,r10,3
	ctx.r10.u64 = ctx.r10.u32 & 0x1FFFFFFF;
	// srawi. r8,r10,29
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1FFFFFFF) != 0);
	ctx.r8.s64 = ctx.r10.s32 >> 29;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// stw r10,604(r31)
	PPC_STORE_U32(ctx.r31.u32 + 604, ctx.r10.u32);
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// lwz r11,36(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// rlwinm r10,r10,2,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x2;
	// clrlwi r6,r11,19
	ctx.r6.u64 = ctx.r11.u32 & 0x1FFF;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r7,r11,19,19,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 19) & 0x1FFF;
	// add r11,r6,r10
	ctx.r11.u64 = ctx.r6.u64 + ctx.r10.u64;
	// add r10,r7,r10
	ctx.r10.u64 = ctx.r7.u64 + ctx.r10.u64;
	// addi r7,r11,31
	ctx.r7.s64 = ctx.r11.s64 + 31;
	// addi r6,r10,31
	ctx.r6.s64 = ctx.r10.s64 + 31;
	// rlwinm r7,r7,0,16,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFE0;
	// rlwinm r6,r6,0,16,26
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFE0;
	// sth r11,368(r31)
	PPC_STORE_U16(ctx.r31.u32 + 368, ctx.r11.u16);
	// sth r10,370(r31)
	PPC_STORE_U16(ctx.r31.u32 + 370, ctx.r10.u16);
	// sth r7,372(r31)
	PPC_STORE_U16(ctx.r31.u32 + 372, ctx.r7.u16);
	// sth r6,374(r31)
	PPC_STORE_U16(ctx.r31.u32 + 374, ctx.r6.u16);
	// bne 0x82b2fca8
	if (!ctx.cr0.eq) goto loc_82B2FCA8;
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// lhz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// addi r7,r1,92
	ctx.r7.s64 = ctx.r1.s64 + 92;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// lfs f0,12124(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12124);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// std r10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r10.u64);
	// addi r8,r1,84
	ctx.r8.s64 = ctx.r1.s64 + 84;
	// addi r29,r1,88
	ctx.r29.s64 = ctx.r1.s64 + 88;
	// lfs f12,-23588(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -23588);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// stfs f12,92(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// addi r30,r1,88
	ctx.r30.s64 = ctx.r1.s64 + 88;
	// lvlx v13,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// addi r6,r31,408
	ctx.r6.s64 = ctx.r31.s64 + 408;
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// lfs f13,-13896(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13896);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// stfs f13,88(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// lvlx v12,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,424
	ctx.r5.s64 = ctx.r31.s64 + 424;
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// lfs f11,-3200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -3200);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// stfs f11,84(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// addi r23,r1,80
	ctx.r23.s64 = ctx.r1.s64 + 80;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// li r8,12
	ctx.r8.s64 = 12;
	// lfs f0,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfd f0,96(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// addi r10,r11,-11328
	ctx.r10.s64 = ctx.r11.s64 + -11328;
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lvlx v11,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v0,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// li r11,16
	ctx.r11.s64 = 16;
	// addi r28,r10,16
	ctx.r28.s64 = ctx.r10.s64 + 16;
	// li r7,48
	ctx.r7.s64 = 48;
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fdivs f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 / ctx.f0.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v10,0,r3
	temp.u32 = ctx.r3.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// vrlimi128 v10,v12,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// lvlx v0,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r10,32
	ctx.r29.s64 = ctx.r10.s64 + 32;
	// stfs f10,88(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lvlx v12,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// vrlimi128 v0,v12,4,3
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v12,v10,v10
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vor v10,v0,v0
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vrlimi128 v12,v13,3,2
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// vrlimi128 v10,v11,3,2
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 78), 3));
	// vor v0,v12,v12
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v12.u8));
	// vor v13,v10,v10
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r6,r31,440
	ctx.r6.s64 = ctx.r31.s64 + 440;
	// lvlx v12,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvrx v0,r11,r10
	temp.u32 = ctx.r11.u32 + ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// stvlx v0,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r5,r31,472
	ctx.r5.s64 = ctx.r31.s64 + 472;
	// lvrx v0,r11,r28
	temp.u32 = ctx.r11.u32 + ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// li r28,32
	ctx.r28.s64 = 32;
	// lvlx v12,r10,r11
	temp.u32 = ctx.r10.u32 + ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r10,r31,456
	ctx.r10.s64 = ctx.r31.s64 + 456;
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r22,r1,84
	ctx.r22.s64 = ctx.r1.s64 + 84;
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r21,r1,80
	ctx.r21.s64 = ctx.r1.s64 + 80;
	// lvlx v12,r30,r28
	temp.u32 = ctx.r30.u32 + ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r20,r1,84
	ctx.r20.s64 = ctx.r1.s64 + 84;
	// lvrx v0,r11,r29
	temp.u32 = ctx.r11.u32 + ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r3,r31,488
	ctx.r3.s64 = ctx.r31.s64 + 488;
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r30,r1,80
	ctx.r30.s64 = ctx.r1.s64 + 80;
	// addi r29,r1,84
	ctx.r29.s64 = ctx.r1.s64 + 84;
	// addi r28,r1,84
	ctx.r28.s64 = ctx.r1.s64 + 84;
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// lfs f0,-13892(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// lfs f10,-11116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11116);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v11,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// lfs f10,-11120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11120);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v10,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lfs f10,-11468(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11468);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r23
	temp.u32 = ctx.r23.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r21
	temp.u32 = ctx.r21.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f10,-11276(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11276);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r22
	temp.u32 = ctx.r22.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v10,0,r20
	temp.u32 = ctx.r20.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r3
	ea = ctx.r3.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r3,r11
	ea = ctx.r3.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f10,-32636(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -32636);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r6
	temp.u32 = ctx.r6.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r6,r31,520
	ctx.r6.s64 = ctx.r31.s64 + 520;
	// lfs f10,-12288(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -12288);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,536
	ctx.r5.s64 = ctx.r31.s64 + 536;
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v10,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r1,80
	ctx.r29.s64 = ctx.r1.s64 + 80;
	// lfs f10,25288(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 25288);
	ctx.f10.f64 = double(temp.f32);
	// addi r10,r31,504
	ctx.r10.s64 = ctx.r31.s64 + 504;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r3
	temp.u32 = ctx.r3.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f11,-27600(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -27600);
	ctx.f11.f64 = double(temp.f32);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// stfs f11,84(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f13,-6952(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6952);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32243
	ctx.r10.s64 = -2113077248;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v10,0,r28
	temp.u32 = ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// stvlx v13,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v13.u8[15 - i]);
	// stvrx v13,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v13.u8[i]);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,-11988(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11988);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,552
	ctx.r10.s64 = ctx.r31.s64 + 552;
	// lvlx v13,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v12,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v11,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lhz r11,2(r9)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r9.u32 + 2);
	// lhz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,27,5,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFE0;
	// b 0x82b2fff8
	goto loc_82B2FFF8;
loc_82B2FCA8:
	// cmpwi cr6,r8,1
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 1, ctx.xer);
	// bne cr6,0x82b30000
	if (!ctx.cr6.eq) goto loc_82B30000;
	// lhz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lfs f0,-13892(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// addi r30,r1,96
	ctx.r30.s64 = ctx.r1.s64 + 96;
	// std r10,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r10.u64);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lvlx v11,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,424
	ctx.r5.s64 = ctx.r31.s64 + 424;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f11,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// stfs f11,84(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// lvlx v13,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lis r5,-32244
	ctx.r5.s64 = -2113142784;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r7,r1,92
	ctx.r7.s64 = ctx.r1.s64 + 92;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// lfs f10,-3200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -3200);
	ctx.f10.f64 = double(temp.f32);
	// addi r3,r1,92
	ctx.r3.s64 = ctx.r1.s64 + 92;
	// stfs f10,92(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// addi r29,r1,80
	ctx.r29.s64 = ctx.r1.s64 + 80;
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,12124(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 12124);
	ctx.f13.f64 = double(temp.f32);
	// lis r5,-32229
	ctx.r5.s64 = -2112159744;
	// lvlx v12,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// addi r6,r31,408
	ctx.r6.s64 = ctx.r31.s64 + 408;
	// addi r10,r11,-24400
	ctx.r10.s64 = ctx.r11.s64 + -24400;
	// li r11,16
	ctx.r11.s64 = 16;
	// addi r28,r10,16
	ctx.r28.s64 = ctx.r10.s64 + 16;
	// li r8,3
	ctx.r8.s64 = 3;
	// li r7,12
	ctx.r7.s64 = 12;
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,-13896(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -13896);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f9,f13,f12
	ctx.f9.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// stfs f9,92(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fdivs f9,f13,f12
	ctx.f9.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// stfs f9,96(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lvlx v0,0,r3
	temp.u32 = ctx.r3.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lvlx v10,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// vrlimi128 v10,v0,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r10,32
	ctx.r29.s64 = ctx.r10.s64 + 32;
	// vrlimi128 v0,v11,4,3
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v11,v10,v10
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vor v10,v0,v0
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vrlimi128 v11,v13,3,2
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// vrlimi128 v10,v12,3,2
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vor v13,v10,v10
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r6,r31,440
	ctx.r6.s64 = ctx.r31.s64 + 440;
	// lvlx v12,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvrx v0,r11,r10
	temp.u32 = ctx.r11.u32 + ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// stvlx v0,0,r27
	ea = ctx.r27.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// stvrx v0,r26,r11
	ea = ctx.r26.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// lvrx v0,r11,r28
	temp.u32 = ctx.r11.u32 + ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// li r28,32
	ctx.r28.s64 = 32;
	// lvlx v12,r10,r11
	temp.u32 = ctx.r10.u32 + ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r10,r31,456
	ctx.r10.s64 = ctx.r31.s64 + 456;
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// lvlx v12,r30,r28
	temp.u32 = ctx.r30.u32 + ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,472
	ctx.r5.s64 = ctx.r31.s64 + 472;
	// lvrx v0,r11,r29
	temp.u32 = ctx.r11.u32 + ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r23,r1,80
	ctx.r23.s64 = ctx.r1.s64 + 80;
	// vor v0,v12,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// addi r22,r1,84
	ctx.r22.s64 = ctx.r1.s64 + 84;
	// addi r21,r1,80
	ctx.r21.s64 = ctx.r1.s64 + 80;
	// addi r20,r1,84
	ctx.r20.s64 = ctx.r1.s64 + 84;
	// addi r3,r31,488
	ctx.r3.s64 = ctx.r31.s64 + 488;
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r30,r1,80
	ctx.r30.s64 = ctx.r1.s64 + 80;
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r1,84
	ctx.r29.s64 = ctx.r1.s64 + 84;
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// addi r28,r1,84
	ctx.r28.s64 = ctx.r1.s64 + 84;
	// lvlx v12,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// lfs f12,-11116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11116);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v11,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f12,-11120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11120);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v10,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// lfs f12,-11468(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11468);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r23
	temp.u32 = ctx.r23.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r21
	temp.u32 = ctx.r21.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f12,-11276(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11276);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r22
	temp.u32 = ctx.r22.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v10,0,r20
	temp.u32 = ctx.r20.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r3
	ea = ctx.r3.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r3,r11
	ea = ctx.r3.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f12,-32636(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -32636);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r6
	temp.u32 = ctx.r6.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r6,r31,520
	ctx.r6.s64 = ctx.r31.s64 + 520;
	// lfs f12,-12288(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -12288);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,536
	ctx.r5.s64 = ctx.r31.s64 + 536;
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v10,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r1,80
	ctx.r29.s64 = ctx.r1.s64 + 80;
	// lfs f12,25288(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 25288);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r31,504
	ctx.r10.s64 = ctx.r31.s64 + 504;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// lvlx v0,0,r3
	temp.u32 = ctx.r3.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v11,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f12,-27600(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -27600);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v12,v0,4,3
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f13,-6952(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6952);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v10,0,r28
	temp.u32 = ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 57), 4));
	// vor v0,v10,v10
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v10.u8));
	// vrlimi128 v0,v12,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 78), 3));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// stvlx v13,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v13.u8[15 - i]);
	// stvrx v13,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v13.u8[i]);
	// lfs f13,-23588(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -23588);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32243
	ctx.r10.s64 = -2113077248;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,-11988(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11988);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r31,552
	ctx.r10.s64 = ctx.r31.s64 + 552;
	// lvlx v13,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v12,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v11,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lhz r11,2(r9)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r9.u32 + 2);
	// lhz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r11,r11,23,9,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 23) & 0x7FFFFE;
loc_82B2FFF8:
	// stw r11,376(r31)
	PPC_STORE_U32(ctx.r31.u32 + 376, ctx.r11.u32);
	// b 0x82b30364
	goto loc_82B30364;
loc_82B30000:
	// cmpwi cr6,r8,2
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 2, ctx.xer);
	// bne cr6,0x82b3035c
	if (!ctx.cr6.eq) goto loc_82B3035C;
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// addi r9,r31,424
	ctx.r9.s64 = ctx.r31.s64 + 424;
	// addi r10,r11,-24304
	ctx.r10.s64 = ctx.r11.s64 + -24304;
	// li r11,16
	ctx.r11.s64 = 16;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// addi r29,r10,16
	ctx.r29.s64 = ctx.r10.s64 + 16;
	// addi r6,r31,440
	ctx.r6.s64 = ctx.r31.s64 + 440;
	// lvlx v13,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// mr r28,r10
	ctx.r28.u64 = ctx.r10.u64;
	// lvrx v0,r11,r10
	temp.u32 = ctx.r11.u32 + ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r27,r10,32
	ctx.r27.s64 = ctx.r10.s64 + 32;
	// vor v0,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// li r26,32
	ctx.r26.s64 = 32;
	// addi r10,r31,456
	ctx.r10.s64 = ctx.r31.s64 + 456;
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// stvlx v0,0,r9
	ea = ctx.r9.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r23,r1,80
	ctx.r23.s64 = ctx.r1.s64 + 80;
	// stvrx v0,r9,r11
	ea = ctx.r9.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r22,r1,84
	ctx.r22.s64 = ctx.r1.s64 + 84;
	// lvlx v13,r30,r11
	temp.u32 = ctx.r30.u32 + ctx.r11.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r31,472
	ctx.r5.s64 = ctx.r31.s64 + 472;
	// lvrx v0,r11,r29
	temp.u32 = ctx.r11.u32 + ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// vor v0,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// addi r30,r1,80
	ctx.r30.s64 = ctx.r1.s64 + 80;
	// addi r29,r1,84
	ctx.r29.s64 = ctx.r1.s64 + 84;
	// li r8,3
	ctx.r8.s64 = 3;
	// li r7,6
	ctx.r7.s64 = 6;
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// lvlx v13,r28,r26
	temp.u32 = ctx.r28.u32 + ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r28,r1,84
	ctx.r28.s64 = ctx.r1.s64 + 84;
	// lvrx v0,r11,r27
	temp.u32 = ctx.r11.u32 + ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// vor v0,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// lfs f0,-13892(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f13,-11116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11116);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v12,0,r23
	temp.u32 = ctx.r23.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f13,-11120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11120);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v11,0,r22
	temp.u32 = ctx.r22.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r5
	ea = ctx.r5.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r5,r11
	ea = ctx.r5.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lfs f13,-32636(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -32636);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r9,r31,504
	ctx.r9.s64 = ctx.r31.s64 + 504;
	// lfs f13,-5284(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -5284);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r6
	temp.u32 = ctx.r6.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v11,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r1,80
	ctx.r29.s64 = ctx.r1.s64 + 80;
	// lfs f12,-13896(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13896);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r31,488
	ctx.r10.s64 = ctx.r31.s64 + 488;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// addi r6,r31,520
	ctx.r6.s64 = ctx.r31.s64 + 520;
	// lfs f12,-18308(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18308);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lfs f12,-12288(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -12288);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f11,-13884(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -13884);
	ctx.f11.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r29,r1,80
	ctx.r29.s64 = ctx.r1.s64 + 80;
	// lfs f10,-11468(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11468);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32244
	ctx.r10.s64 = -2113142784;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v11,0,r28
	temp.u32 = ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r28,r1,84
	ctx.r28.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r9
	ea = ctx.r9.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r9,r11
	ea = ctx.r9.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// addi r9,r1,84
	ctx.r9.s64 = ctx.r1.s64 + 84;
	// lfs f10,12124(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12124);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r27,r1,80
	ctx.r27.s64 = ctx.r1.s64 + 80;
	// lfs f10,-6952(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6952);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32243
	ctx.r10.s64 = -2113077248;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r26,r1,84
	ctx.r26.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f10,-11988(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11988);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// lfs f10,-23588(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -23588);
	ctx.f10.f64 = double(temp.f32);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v11,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r24,r1,84
	ctx.r24.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r9,r31,408
	ctx.r9.s64 = ctx.r31.s64 + 408;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f12,-28552(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -28552);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lfs f12,-11124(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -11124);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r31,552
	ctx.r10.s64 = ctx.r31.s64 + 552;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v11,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r10
	ea = ctx.r10.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// addi r6,r31,536
	ctx.r6.s64 = ctx.r31.s64 + 536;
	// stvrx v0,r10,r11
	ea = ctx.r10.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f12,-18328(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18328);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32248
	ctx.r10.s64 = -2113404928;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v0,0,r5
	temp.u32 = ctx.r5.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lvlx v12,0,r29
	temp.u32 = ctx.r29.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lfs f12,11400(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 11400);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v13,0,r30
	temp.u32 = ctx.r30.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lfs f12,-6980(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6980);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v11,0,r28
	temp.u32 = ctx.r28.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r9
	ea = ctx.r9.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r9,r11
	ea = ctx.r9.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f13,-31540(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -31540);
	ctx.f13.f64 = double(temp.f32);
	// li r10,48
	ctx.r10.s64 = 48;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v0,0,r27
	temp.u32 = ctx.r27.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
	// lvlx v13,0,r26
	temp.u32 = ctx.r26.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lvlx v12,0,r25
	temp.u32 = ctx.r25.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v11,0,r24
	temp.u32 = ctx.r24.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vor v0,v11,v11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)ctx.v11.u8));
	// vrlimi128 v0,v13,3,2
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stvlx v0,0,r6
	ea = ctx.r6.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// stvrx v0,r6,r11
	ea = ctx.r6.u32 + ctx.r11.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
	// lhz r10,2(r3)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r3.u32 + 2);
	// lhz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 0);
	// addi r10,r10,-48
	ctx.r10.s64 = ctx.r10.s64 + -48;
	// addi r11,r11,-80
	ctx.r11.s64 = ctx.r11.s64 + -80;
	// divwu r10,r10,r9
	ctx.r10.u32 = ctx.r10.u32 / ctx.r9.u32;
	// divwu r11,r11,r5
	ctx.r11.u32 = ctx.r11.u32 / ctx.r5.u32;
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// b 0x82b2fff8
	goto loc_82B2FFF8;
loc_82B3035C:
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82B30364:
	// lis r10,-31975
	ctx.r10.s64 = -2095513600;
	// lwz r11,376(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 376);
	// li r5,260
	ctx.r5.s64 = 260;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// lwz r10,-24476(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -24476);
	// rldicr r30,r10,20,63
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r10.u64, 20) & 0xFFFFFFFFFFFFFFFF;
	// mullw r10,r11,r7
	ctx.r10.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r7.s32);
	// mullw r11,r11,r8
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r8.s32);
	// stw r11,388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 388, ctx.r11.u32);
	// addi r10,r10,511
	ctx.r10.s64 = ctx.r10.s64 + 511;
	// rlwinm r11,r10,23,9,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x7FFFFF;
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// addi r10,r10,172
	ctx.r10.s64 = ctx.r10.s64 + 172;
	// sth r11,14(r31)
	PPC_STORE_U16(ctx.r31.u32 + 14, ctx.r11.u16);
	// rlwinm r28,r10,9,0,22
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 9) & 0xFFFFFE00;
	// bl 0x82e2ab28
	ctx.lr = 0x82B303A8;
	sub_82E2AB28(ctx, base);
	// li r27,0
	ctx.r27.s64 = 0;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// stb r27,371(r1)
	PPC_STORE_U8(ctx.r1.u32 + 371, ctx.r27.u8);
loc_82B303B8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b303b8
	if (!ctx.cr6.eq) goto loc_82B303B8;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82b30408
	if (ctx.cr6.lt) goto loc_82B30408;
loc_82B303EC:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,92
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 92, ctx.xer);
	// beq cr6,0x82b30408
	if (ctx.cr6.eq) goto loc_82B30408;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82b303ec
	if (!ctx.cr6.lt) goto loc_82B303EC;
loc_82B30408:
	// li r6,0
	ctx.r6.s64 = 0;
	// stb r27,1(r11)
	PPC_STORE_U8(ctx.r11.u32 + 1, ctx.r27.u8);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82f66218
	ctx.lr = 0x82B30420;
	sub_82F66218(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b30454
	if (ctx.cr0.eq) goto loc_82B30454;
	// lis r10,640
	ctx.r10.s64 = 41943040;
	// ld r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// add r9,r30,r10
	ctx.r9.u64 = ctx.r30.u64 + ctx.r10.u64;
	// cmpld cr6,r11,r9
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, ctx.r9.u64, ctx.xer);
	// bge cr6,0x82b30454
	if (!ctx.cr6.lt) goto loc_82B30454;
	// cmpld cr6,r11,r10
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, ctx.r10.u64, ctx.xer);
	// ble cr6,0x82b30450
	if (!ctx.cr6.gt) goto loc_82B30450;
	// lis r10,-640
	ctx.r10.s64 = -41943040;
	// add r30,r11,r10
	ctx.r30.u64 = ctx.r11.u64 + ctx.r10.u64;
	// b 0x82b30454
	goto loc_82B30454;
loc_82B30450:
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
loc_82B30454:
	// addi r11,r28,2048
	ctx.r11.s64 = ctx.r28.s64 + 2048;
	// clrldi r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// cmpld cr6,r11,r30
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, ctx.r30.u64, ctx.xer);
	// ble cr6,0x82b30470
	if (!ctx.cr6.gt) goto loc_82B30470;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82b3059c
	goto loc_82B3059C;
loc_82B30470:
	// lis r11,-17
	ctx.r11.s64 = -1114112;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// oris r8,r9,65520
	ctx.r8.u64 = ctx.r9.u64 | 4293918720;
	// clrldi r10,r11,32
	ctx.r10.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// lwz r11,596(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// rotlwi r9,r30,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r30.u32, 0);
	// add r10,r30,r10
	ctx.r10.u64 = ctx.r30.u64 + ctx.r10.u64;
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// divdu r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 / ctx.r8.u64;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// rlwimi r11,r10,14,12,17
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 14) & 0xFC000) | (ctx.r11.u64 & 0xFFFFFFFFFFF03FFF);
	// rlwinm r10,r11,18,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x3F;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r11,596(r31)
	PPC_STORE_U32(ctx.r31.u32 + 596, ctx.r11.u32);
	// rlwinm r10,r10,20,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xFFF00000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,384(r31)
	PPC_STORE_U32(ctx.r31.u32 + 384, ctx.r10.u32);
loc_82B304B8:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b304d4
	if (ctx.cr6.eq) goto loc_82B304D4;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// srawi r11,r11,30
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 30;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82b304d8
	if (ctx.cr6.eq) goto loc_82B304D8;
loc_82B304D4:
	// lwz r4,616(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 616);
loc_82B304D8:
	// rlwinm r11,r29,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// add r30,r11,r31
	ctx.r30.u64 = ctx.r11.u64 + ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82b2f768
	ctx.lr = 0x82B304F0;
	sub_82B2F768(ctx, base);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b30594
	if (ctx.cr6.eq) goto loc_82B30594;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// bne cr6,0x82b30514
	if (!ctx.cr6.eq) goto loc_82B30514;
	// rlwimi r11,r10,30,0,1
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 30) & 0xC0000000) | (ctx.r11.u64 & 0xFFFFFFFF3FFFFFFF);
	// b 0x82b30518
	goto loc_82B30518;
loc_82B30514:
	// rlwimi r11,r10,28,2,3
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 28) & 0x30000000) | (ctx.r11.u64 & 0xFFFFFFFFCFFFFFFF);
loc_82B30518:
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// stw r11,612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 612, ctx.r11.u32);
	// cmplwi cr6,r29,2
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 2, ctx.xer);
	// blt cr6,0x82b304b8
	if (ctx.cr6.lt) goto loc_82B304B8;
	// li r8,4096
	ctx.r8.s64 = 4096;
	// li r7,-1
	ctx.r7.s64 = -1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,1536
	ctx.r4.s64 = 1536;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x83157ef4
	ctx.lr = 0x82B30544;
	__imp__MmAllocatePhysicalMemoryEx(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,592(r31)
	PPC_STORE_U32(ctx.r31.u32 + 592, ctx.r3.u32);
	// beq 0x82b3055c
	if (ctx.cr0.eq) goto loc_82B3055C;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// rlwinm r11,r11,0,5,3
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFF7FFFFFF;
	// b 0x82b3057c
	goto loc_82B3057C;
loc_82B3055C:
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// li r3,1536
	ctx.r3.s64 = 1536;
	// bl 0x82547910
	ctx.lr = 0x82B30568;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,592(r31)
	PPC_STORE_U32(ctx.r31.u32 + 592, ctx.r3.u32);
	// beq 0x82b30594
	if (ctx.cr0.eq) goto loc_82B30594;
	// lwz r11,612(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 612);
	// oris r11,r11,2048
	ctx.r11.u64 = ctx.r11.u64 | 134217728;
loc_82B3057C:
	// stw r11,612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 612, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// ori r11,r11,16
	ctx.r11.u64 = ctx.r11.u64 | 16;
	// stb r11,608(r31)
	PPC_STORE_U8(ctx.r31.u32 + 608, ctx.r11.u8);
	// b 0x82b3059c
	goto loc_82B3059C;
loc_82B30594:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
loc_82B3059C:
	// addi r1,r1,480
	ctx.r1.s64 = ctx.r1.s64 + 480;
	// b 0x82e28e98
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B305A8"))) PPC_WEAK_FUNC(sub_82B305A8);
PPC_FUNC_IMPL(__imp__sub_82B305A8) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,596(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 596);
	// lwz r11,380(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 380);
	// lhz r9,14(r3)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r3.u32 + 14);
	// rlwinm r8,r10,12,26,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0x3F;
	// add r11,r4,r11
	ctx.r11.u64 = ctx.r4.u64 + ctx.r11.u64;
	// rlwinm r10,r10,18,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x3F;
	// addi r9,r9,172
	ctx.r9.s64 = ctx.r9.s64 + 172;
	// addi r7,r10,-1
	ctx.r7.s64 = ctx.r10.s64 + -1;
	// rlwinm r9,r9,9,0,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 9) & 0xFFFFFE00;
	// stw r11,380(r3)
	PPC_STORE_U32(ctx.r3.u32 + 380, ctx.r11.u32);
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// add r10,r9,r11
	ctx.r10.u64 = ctx.r9.u64 + ctx.r11.u64;
	// bne cr6,0x82b305e4
	if (!ctx.cr6.eq) goto loc_82B305E4;
	// lwz r9,384(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 384);
	// b 0x82b305e8
	goto loc_82B305E8;
loc_82B305E4:
	// lis r9,-16
	ctx.r9.s64 = -1048576;
loc_82B305E8:
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b30600
	if (ctx.cr6.lt) goto loc_82B30600;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blelr cr6
	if (!ctx.cr6.gt) return;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82B30600:
	// addi r10,r8,46
	ctx.r10.s64 = ctx.r8.s64 + 46;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r11,r10,r3
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, ctx.r11.u32);
	// lwz r11,596(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 596);
	// rlwinm r10,r11,12,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0x3F;
	// rlwinm r9,r11,18,26,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x3F;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// twllei r9,0
	// divwu r8,r10,r9
	ctx.r8.u32 = ctx.r10.u32 / ctx.r9.u32;
	// mullw r9,r8,r9
	ctx.r9.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r9.s32);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// rlwimi r11,r10,20,6,11
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 20) & 0x3F00000) | (ctx.r11.u64 & 0xFFFFFFFFFC0FFFFF);
	// stw r11,596(r3)
	PPC_STORE_U32(ctx.r3.u32 + 596, ctx.r11.u32);
	// rlwinm. r10,r11,0,6,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x3F00000;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82b30654
	if (!ctx.cr0.eq) goto loc_82B30654;
	// lbz r11,608(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 608);
	// li r10,2048
	ctx.r10.s64 = 2048;
	// ori r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 | 32;
	// stw r10,380(r3)
	PPC_STORE_U32(ctx.r3.u32 + 380, ctx.r10.u32);
	// stb r11,608(r3)
	PPC_STORE_U8(ctx.r3.u32 + 608, ctx.r11.u8);
	// blr 
	return;
loc_82B30654:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,380(r3)
	PPC_STORE_U32(ctx.r3.u32 + 380, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B30660"))) PPC_WEAK_FUNC(sub_82B30660);
PPC_FUNC_IMPL(__imp__sub_82B30660) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82B30668;
	__savegprlr_24(ctx, base);
	// stwu r1,-2320(r1)
	ea = -2320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// addi r31,r25,21680
	ctx.r31.s64 = ctx.r25.s64 + 21680;
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// rlwinm. r10,r11,0,27,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b309ec
	if (ctx.cr0.eq) goto loc_82B309EC;
	// lwz r3,364(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b309c4
	if (ctx.cr0.eq) goto loc_82B309C4;
	// rlwinm. r10,r11,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// li r27,-1
	ctx.r27.s64 = -1;
	// beq 0x82b307b0
	if (ctx.cr0.eq) goto loc_82B307B0;
	// rlwinm. r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b306ac
	if (ctx.cr0.eq) goto loc_82B306AC;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82b07700
	ctx.lr = 0x82B306AC;
	sub_82B07700(ctx, base);
loc_82B306AC:
	// lwz r28,16(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r3,588(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 588);
	// bl 0x82b1d6a8
	ctx.lr = 0x82B306B8;
	sub_82B1D6A8(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// addi r29,r11,-24480
	ctx.r29.s64 = ctx.r11.s64 + -24480;
	// lis r11,-31966
	ctx.r11.s64 = -2094923776;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// addi r11,r11,-10752
	ctx.r11.s64 = ctx.r11.s64 + -10752;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
loc_82B306D0:
	// mfmsr r9
	ctx.r9.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r10,0,r8
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r8.u32);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// stwcx. r11,0,r8
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r8.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b306d0
	if (!ctx.cr0.eq) goto loc_82B306D0;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r9,6144
	ctx.r9.s64 = 6144;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// divwu r10,r11,r9
	ctx.r10.u32 = ctx.r11.u32 / ctx.r9.u32;
	// cmplwi cr6,r10,14
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 14, ctx.xer);
	// blt cr6,0x82b30708
	if (ctx.cr6.lt) goto loc_82B30708;
	// li r10,14
	ctx.r10.s64 = 14;
loc_82B30708:
	// lwz r9,584(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 584);
	// mulli r8,r10,12
	ctx.r8.s64 = ctx.r10.s64 * 12;
	// addi r7,r9,-1
	ctx.r7.s64 = ctx.r9.s64 + -1;
	// lwz r6,380(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 380);
	// lhz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 12);
	// lis r11,-25768
	ctx.r11.s64 = -1688731648;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// ori r24,r11,59162
	ctx.r24.u64 = ctx.r11.u64 | 59162;
	// lwz r11,596(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// rlwinm r7,r7,2,29,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0x4;
	// rlwinm r30,r9,9,0,22
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 9) & 0xFFFFFE00;
	// rlwinm r9,r11,4,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0x3;
	// rlwinm r11,r11,12,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0x3F;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r11,r11,5
	ctx.r11.s64 = ctx.r11.s64 + 5;
	// lwzx r4,r7,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r31.u32);
	// stw r6,356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 356, ctx.r6.u32);
	// addi r7,r31,348
	ctx.r7.s64 = ctx.r31.s64 + 348;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r26,360(r31)
	PPC_STORE_U32(ctx.r31.u32 + 360, ctx.r26.u32);
	// addi r11,r4,-4
	ctx.r11.s64 = ctx.r4.s64 + -4;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwzx r3,r8,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r31.u32);
	// stwu r24,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r24.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r28,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// bl 0x82b07280
	ctx.lr = 0x82B30778;
	sub_82B07280(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b305a8
	ctx.lr = 0x82B30784;
	sub_82B305A8(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,364(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// bl 0x82b07700
	ctx.lr = 0x82B30790;
	sub_82B07700(ctx, base);
	// lis r30,-31966
	ctx.r30.s64 = -2094923776;
	// b 0x82b307a0
	goto loc_82B307A0;
loc_82B30798:
	// li r3,6
	ctx.r3.s64 = 6;
	// bl 0x82b07ad0
	ctx.lr = 0x82B307A0;
	sub_82B07AD0(ctx, base);
loc_82B307A0:
	// lwz r11,-10744(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + -10744);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b30798
	if (!ctx.cr6.eq) goto loc_82B30798;
loc_82B307B0:
	// lwz r11,596(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// rlwinm. r11,r11,0,12,17
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFC000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b3082c
	if (ctx.cr0.eq) goto loc_82B3082C;
	// addi r29,r31,20
	ctx.r29.s64 = ctx.r31.s64 + 20;
loc_82B307C8:
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b307f8
	if (!ctx.cr0.eq) goto loc_82B307F8;
	// lwz r11,596(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// rlwinm r11,r11,12,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0x3F;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b307f8
	if (ctx.cr6.lt) goto loc_82B307F8;
	// ble cr6,0x82b307f0
	if (!ctx.cr6.gt) goto loc_82B307F0;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// b 0x82b307fc
	goto loc_82B307FC;
loc_82B307F0:
	// lwz r4,380(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 380);
	// b 0x82b307fc
	goto loc_82B307FC;
loc_82B307F8:
	// lwz r4,164(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 164);
loc_82B307FC:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// bl 0x82b07f60
	ctx.lr = 0x82B3080C;
	sub_82B07F60(ctx, base);
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// bl 0x82f66328
	ctx.lr = 0x82B30814;
	sub_82F66328(ctx, base);
	// lwz r11,596(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// rlwinm r11,r11,18,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x3F;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b307c8
	if (ctx.cr6.lt) goto loc_82B307C8;
loc_82B3082C:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x83158294
	ctx.lr = 0x82B30834;
	__imp__VdGetCurrentDisplayInformation(ctx, base);
	// lwz r11,604(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 604);
	// srawi. r11,r11,29
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 29;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b3084c
	if (!ctx.cr0.eq) goto loc_82B3084C;
	// lis r10,21415
	ctx.r10.s64 = 1403453440;
	// ori r10,r10,8884
	ctx.r10.u64 = ctx.r10.u64 | 8884;
	// b 0x82b30870
	goto loc_82B30870;
loc_82B3084C:
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b30860
	if (!ctx.cr6.eq) goto loc_82B30860;
	// lis r10,21415
	ctx.r10.s64 = 1403453440;
	// ori r10,r10,8885
	ctx.r10.u64 = ctx.r10.u64 | 8885;
	// b 0x82b30870
	goto loc_82B30870;
loc_82B30860:
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82b30874
	if (!ctx.cr6.eq) goto loc_82B30874;
	// lis r10,21415
	ctx.r10.s64 = 1403453440;
	// ori r10,r10,8886
	ctx.r10.u64 = ctx.r10.u64 | 8886;
loc_82B30870:
	// stw r10,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r10.u32);
loc_82B30874:
	// lis r10,1
	ctx.r10.s64 = 65536;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r10,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r10.u32);
	// beq cr6,0x82b308b0
	if (ctx.cr6.eq) goto loc_82B308B0;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82b308b0
	if (ctx.cr6.eq) goto loc_82B308B0;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82b308d0
	if (!ctx.cr6.eq) goto loc_82B308D0;
	// li r10,400
	ctx.r10.s64 = 400;
	// li r11,224
	ctx.r11.s64 = 224;
	// stw r10,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r10.u32);
	// stw r11,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r11.u32);
	// stw r10,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r10.u32);
	// b 0x82b308cc
	goto loc_82B308CC;
loc_82B308B0:
	// lhz r11,368(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 368);
	// stw r11,208(r1)
	PPC_STORE_U32(ctx.r1.u32 + 208, ctx.r11.u32);
	// lhz r11,370(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 370);
	// stw r11,212(r1)
	PPC_STORE_U32(ctx.r1.u32 + 212, ctx.r11.u32);
	// lhz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 168);
	// stw r11,216(r1)
	PPC_STORE_U32(ctx.r1.u32 + 216, ctx.r11.u32);
	// lhz r11,170(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 170);
loc_82B308CC:
	// stw r11,220(r1)
	PPC_STORE_U32(ctx.r1.u32 + 220, ctx.r11.u32);
loc_82B308D0:
	// bl 0x83157f84
	ctx.lr = 0x82B308D4;
	__imp__KeQueryPerformanceFrequency(ctx, base);
	// lwz r10,596(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
	// stw r3,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r3.u32);
	// rlwinm r11,r10,6,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x3F;
	// stw r9,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r9.u32);
	// clrlwi. r8,r11,31
	ctx.r8.u64 = ctx.r11.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b308f8
	if (ctx.cr0.eq) goto loc_82B308F8;
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r9,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r9.u32);
loc_82B308F8:
	// rlwinm. r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b30908
	if (ctx.cr0.eq) goto loc_82B30908;
	// ori r9,r9,2
	ctx.r9.u64 = ctx.r9.u64 | 2;
	// stw r9,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r9.u32);
loc_82B30908:
	// rlwinm. r11,r10,0,0,0
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b30918
	if (ctx.cr0.eq) goto loc_82B30918;
	// lwz r4,592(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 592);
	// b 0x82b3091c
	goto loc_82B3091C;
loc_82B30918:
	// addi r4,r25,15004
	ctx.r4.s64 = ctx.r25.s64 + 15004;
loc_82B3091C:
	// lbz r11,101(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 101);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bne cr6,0x82b30940
	if (!ctx.cr6.eq) goto loc_82B30940;
	// ori r11,r9,4
	ctx.r11.u64 = ctx.r9.u64 | 4;
	// stw r11,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r11.u32);
	// bl 0x82b2bb68
	ctx.lr = 0x82B3093C;
	sub_82B2BB68(ctx, base);
	// b 0x82b30944
	goto loc_82B30944;
loc_82B30940:
	// bl 0x82b2bad0
	ctx.lr = 0x82B30944;
	sub_82B2BAD0(ctx, base);
loc_82B30944:
	// lwz r30,596(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// addi r3,r1,232
	ctx.r3.s64 = ctx.r1.s64 + 232;
	// li r5,56
	ctx.r5.s64 = 56;
	// addi r4,r25,13724
	ctx.r4.s64 = ctx.r25.s64 + 13724;
	// rlwinm. r11,r30,0,5,5
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x4000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b30960
	if (!ctx.cr0.eq) goto loc_82B30960;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
loc_82B30960:
	// bl 0x82e28fd0
	ctx.lr = 0x82B30964;
	sub_82E28FD0(ctx, base);
	// lbz r11,608(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 608);
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b30984
	if (ctx.cr0.eq) goto loc_82B30984;
	// lwz r11,380(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 380);
	// stw r11,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r11.u32);
	// rlwinm r11,r30,12,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 12) & 0x3F;
	// stw r11,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r11.u32);
	// b 0x82b30990
	goto loc_82B30990;
loc_82B30984:
	// li r11,2048
	ctx.r11.s64 = 2048;
	// stw r26,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r26.u32);
	// stw r11,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r11.u32);
loc_82B30990:
	// addi r7,r31,348
	ctx.r7.s64 = ctx.r31.s64 + 348;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r26,356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 356, ctx.r26.u32);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// stw r26,360(r31)
	PPC_STORE_U32(ctx.r31.u32 + 360, ctx.r26.u32);
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// bl 0x82b07280
	ctx.lr = 0x82B309B0;
	sub_82B07280(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,364(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// bl 0x82b07700
	ctx.lr = 0x82B309BC;
	sub_82B07700(ctx, base);
	// lwz r3,364(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// bl 0x82b07040
	ctx.lr = 0x82B309C4;
	sub_82B07040(ctx, base);
loc_82B309C4:
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// addi r31,r31,20
	ctx.r31.s64 = ctx.r31.s64 + 20;
loc_82B309CC:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82b309ec
	if (ctx.cr6.eq) goto loc_82B309EC;
	// bl 0x82b07040
	ctx.lr = 0x82B309DC;
	sub_82B07040(ctx, base);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r30,41
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 41, ctx.xer);
	// blt cr6,0x82b309cc
	if (ctx.cr6.lt) goto loc_82B309CC;
loc_82B309EC:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2020(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2020);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b30a1c
	if (ctx.cr6.eq) goto loc_82B30A1C;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b30a48
	if (ctx.cr0.eq) goto loc_82B30A48;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b30a48
	if (ctx.cr0.eq) goto loc_82B30A48;
	// b 0x82b30a34
	goto loc_82B30A34;
loc_82B30A1C:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b30a48
	if (ctx.cr0.eq) goto loc_82B30A48;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82B30A34:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// li r3,27
	ctx.r3.s64 = 27;
	// addi r4,r10,-11112
	ctx.r4.s64 = ctx.r10.s64 + -11112;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B30A48;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B30A48:
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82b2f7e8
	ctx.lr = 0x82B30A50;
	sub_82B2F7E8(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// addi r3,r11,-24456
	ctx.r3.s64 = ctx.r11.s64 + -24456;
	// bl 0x831583b4
	ctx.lr = 0x82B30A5C;
	__imp__ObDeleteSymbolicLink(ctx, base);
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// mr r10,r26
	ctx.r10.u64 = ctx.r26.u64;
	// addi r11,r11,29262
	ctx.r11.s64 = ctx.r11.s64 + 29262;
	// stb r10,-2(r11)
	PPC_STORE_U8(ctx.r11.u32 + -2, ctx.r10.u8);
	// stb r10,-1(r11)
	PPC_STORE_U8(ctx.r11.u32 + -1, ctx.r10.u8);
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// addi r1,r1,2320
	ctx.r1.s64 = ctx.r1.s64 + 2320;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B30A80"))) PPC_WEAK_FUNC(sub_82B30A80);
PPC_FUNC_IMPL(__imp__sub_82B30A80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82B30A88;
	__savegprlr_21(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r6,16
	ctx.r6.s64 = 16;
	// li r5,112
	ctx.r5.s64 = 112;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r30,r31,21680
	ctx.r30.s64 = ctx.r31.s64 + 21680;
	// bl 0x82b16a58
	ctx.lr = 0x82B30AA8;
	sub_82B16A58(ctx, base);
	// ld r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// cmpldi cr6,r4,0
	ctx.cr6.compare<uint64_t>(ctx.r4.u64, 0, ctx.xer);
	// beq cr6,0x82b30bc8
	if (ctx.cr6.eq) goto loc_82B30BC8;
	// ld r11,40(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 40);
	// and r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 & ctx.r4.u64;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82b30ad4
	if (ctx.cr6.eq) goto loc_82B30AD4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,10560(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10560);
	// bl 0x82b26628
	ctx.lr = 0x82B30AD0;
	sub_82B26628(ctx, base);
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
loc_82B30AD4:
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// clrldi r10,r11,52
	ctx.r10.u64 = ctx.r11.u64 & 0xFFF;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b30b04
	if (ctx.cr6.eq) goto loc_82B30B04;
	// addi r6,r31,10548
	ctx.r6.s64 = ctx.r31.s64 + 10548;
	// li r5,8704
	ctx.r5.s64 = 8704;
	// rldicr r4,r11,52,11
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 52) & 0xFFF0000000000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b269c0
	ctx.lr = 0x82B30AF8;
	sub_82B269C0(ctx, base);
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// rldicr r11,r11,0,51
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 0) & 0xFFFFFFFFFFFFF000;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
loc_82B30B04:
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// rlwinm r10,r11,0,15,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1F000;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b30b3c
	if (ctx.cr6.eq) goto loc_82B30B3C;
	// addi r6,r31,10528
	ctx.r6.s64 = ctx.r31.s64 + 10528;
	// li r5,8576
	ctx.r5.s64 = 8576;
	// rldicr r4,r11,47,4
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 47) & 0xF800000000000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b269c0
	ctx.lr = 0x82B30B28;
	sub_82B269C0(ctx, base);
	// lis r12,-2
	ctx.r12.s64 = -131072;
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r12,r12,4095
	ctx.r12.u64 = ctx.r12.u64 | 4095;
	// and r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 & ctx.r12.u64;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
loc_82B30B3C:
	// lis r12,0
	ctx.r12.s64 = 0;
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r12,r12,65535
	ctx.r12.u64 = ctx.r12.u64 | 65535;
	// rldicr r12,r12,42,21
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 42) & 0xFFFFFC0000000000;
	// and r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 & ctx.r12.u64;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b30b84
	if (ctx.cr6.eq) goto loc_82B30B84;
	// addi r6,r31,10368
	ctx.r6.s64 = ctx.r31.s64 + 10368;
	// li r5,8192
	ctx.r5.s64 = 8192;
	// rldicr r4,r11,6,15
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 6) & 0xFFFF000000000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b269c0
	ctx.lr = 0x82B30B6C;
	sub_82B269C0(ctx, base);
	// lis r12,-1
	ctx.r12.s64 = -65536;
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r12,r12,0
	ctx.r12.u64 = ctx.r12.u64 | 0;
	// rldicr r12,r12,42,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 42) & 0xFFFFFFFFFFFFFFFF;
	// and r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 & ctx.r12.u64;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
loc_82B30B84:
	// lis r12,-32
	ctx.r12.s64 = -2097152;
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// clrldi r12,r12,22
	ctx.r12.u64 = ctx.r12.u64 & 0x3FFFFFFFFFF;
	// and r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 & ctx.r12.u64;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b30bc8
	if (ctx.cr6.eq) goto loc_82B30BC8;
	// addi r6,r31,10444
	ctx.r6.s64 = ctx.r31.s64 + 10444;
	// li r5,8448
	ctx.r5.s64 = 8448;
	// rldicr r4,r11,22,20
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 22) & 0xFFFFF80000000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b269c0
	ctx.lr = 0x82B30BB0;
	sub_82B269C0(ctx, base);
	// lis r12,-32
	ctx.r12.s64 = -2097152;
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r12,r12,0
	ctx.r12.u64 = ctx.r12.u64 | 0;
	// rldicr r12,r12,21,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 21) & 0xFFFFFFFFFFFFFFFF;
	// and r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 & ctx.r12.u64;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
loc_82B30BC8:
	// ld r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82b30c18
	if (ctx.cr6.eq) goto loc_82B30C18;
	// lis r12,31
	ctx.r12.s64 = 2031616;
	// ori r12,r12,65535
	ctx.r12.u64 = ctx.r12.u64 | 65535;
	// rldicr r12,r12,34,29
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 34) & 0xFFFFFFFC00000000;
	// and r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 & ctx.r12.u64;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b30c18
	if (ctx.cr6.eq) goto loc_82B30C18;
	// addi r6,r31,10596
	ctx.r6.s64 = ctx.r31.s64 + 10596;
	// li r5,8832
	ctx.r5.s64 = 8832;
	// rldicr r4,r11,9,20
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 9) & 0xFFFFF80000000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b269c0
	ctx.lr = 0x82B30C00;
	sub_82B269C0(ctx, base);
	// lis r12,-32
	ctx.r12.s64 = -2097152;
	// ld r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// ori r12,r12,0
	ctx.r12.u64 = ctx.r12.u64 | 0;
	// rldicr r12,r12,34,63
	ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 34) & 0xFFFFFFFFFFFFFFFF;
	// and r11,r11,r12
	ctx.r11.u64 = ctx.r11.u64 & ctx.r12.u64;
	// std r11,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r11.u64);
loc_82B30C18:
	// ld r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82b30c50
	if (ctx.cr6.eq) goto loc_82B30C50;
	// clrldi r10,r11,26
	ctx.r10.u64 = ctx.r11.u64 & 0x3FFFFFFFFF;
	// cmpldi cr6,r10,0
	ctx.cr6.compare<uint64_t>(ctx.r10.u64, 0, ctx.xer);
	// beq cr6,0x82b30c50
	if (ctx.cr6.eq) goto loc_82B30C50;
	// addi r6,r31,10680
	ctx.r6.s64 = ctx.r31.s64 + 10680;
	// li r5,8960
	ctx.r5.s64 = 8960;
	// rldicr r4,r11,26,37
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u64, 26) & 0xFFFFFFFFFC000000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b269c0
	ctx.lr = 0x82B30C44;
	sub_82B269C0(ctx, base);
	// ld r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// rldicr r11,r11,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 0) & 0xFFFFFFC000000000;
	// std r11,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r11.u64);
loc_82B30C50:
	// lwz r11,604(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 604);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// srawi. r11,r11,29
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 29;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// addi r25,r10,-18112
	ctx.r25.s64 = ctx.r10.s64 + -18112;
	// bne 0x82b30c78
	if (!ctx.cr0.eq) goto loc_82B30C78;
	// lis r26,1792
	ctx.r26.s64 = 117440512;
	// li r28,525
	ctx.r28.s64 = 525;
	// mr r27,r25
	ctx.r27.u64 = ctx.r25.u64;
	// ori r26,r26,21
	ctx.r26.u64 = ctx.r26.u64 | 21;
	// b 0x82b30cbc
	goto loc_82B30CBC;
loc_82B30C78:
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b30c94
	if (!ctx.cr6.eq) goto loc_82B30C94;
	// lis r26,1792
	ctx.r26.s64 = 117440512;
	// addi r27,r25,2160
	ctx.r27.s64 = ctx.r25.s64 + 2160;
	// li r28,933
	ctx.r28.s64 = 933;
	// ori r26,r26,19
	ctx.r26.u64 = ctx.r26.u64 | 19;
	// b 0x82b30cbc
	goto loc_82B30CBC;
loc_82B30C94:
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82b30cb0
	if (!ctx.cr6.eq) goto loc_82B30CB0;
	// lis r26,1792
	ctx.r26.s64 = 117440512;
	// addi r27,r25,5896
	ctx.r27.s64 = ctx.r25.s64 + 5896;
	// li r28,210
	ctx.r28.s64 = 210;
	// ori r26,r26,15
	ctx.r26.u64 = ctx.r26.u64 | 15;
	// b 0x82b30cbc
	goto loc_82B30CBC;
loc_82B30CB0:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r27,80(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r26,80(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82B30CBC:
	// addi r4,r28,5
	ctx.r4.s64 = ctx.r28.s64 + 5;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dd08
	ctx.lr = 0x82B30CC8;
	sub_82B1DD08(ctx, base);
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// li r10,768
	ctx.r10.s64 = 768;
	// ori r11,r11,15104
	ctx.r11.u64 = ctx.r11.u64 | 15104;
	// lis r8,-16384
	ctx.r8.s64 = -1073741824;
	// addi r9,r28,1
	ctx.r9.s64 = ctx.r28.s64 + 1;
	// ori r8,r8,11008
	ctx.r8.u64 = ctx.r8.u64 | 11008;
	// li r22,0
	ctx.r22.s64 = 0;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// rlwimi r8,r9,16,2,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 16) & 0x3FFF0000) | (ctx.r8.u64 & 0xFFFFFFFFC000FFFF);
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// clrlwi r9,r28,18
	ctx.r9.u64 = ctx.r28.u32 & 0x3FFF;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// rlwinm r28,r28,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// stwu r7,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r3.u32 = ea;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// addi r3,r27,4
	ctx.r3.s64 = ctx.r27.s64 + 4;
	// bl 0x82e28fd0
	ctx.lr = 0x82B30D1C;
	sub_82E28FD0(ctx, base);
	// add r3,r28,r27
	ctx.r3.u64 = ctx.r28.u64 + ctx.r27.u64;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// ble cr6,0x82b30d38
	if (!ctx.cr6.gt) goto loc_82B30D38;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B30D38;
	sub_82B1DAE8(ctx, base);
loc_82B30D38:
	// lis r11,-16368
	ctx.r11.s64 = -1072693248;
	// li r10,1
	ctx.r10.s64 = 1;
	// ori r11,r11,11008
	ctx.r11.u64 = ctx.r11.u64 | 11008;
	// li r9,15
	ctx.r9.s64 = 15;
	// addi r4,r25,2100
	ctx.r4.s64 = ctx.r25.s64 + 2100;
	// li r5,60
	ctx.r5.s64 = 60;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r3,r28,4
	ctx.r3.s64 = ctx.r28.s64 + 4;
	// bl 0x82e28fd0
	ctx.lr = 0x82B30D68;
	sub_82E28FD0(ctx, base);
	// lis r10,1
	ctx.r10.s64 = 65536;
	// addi r11,r28,60
	ctx.r11.s64 = ctx.r28.s64 + 60;
	// ori r10,r10,8576
	ctx.r10.u64 = ctx.r10.u64 | 8576;
	// oris r9,r26,4096
	ctx.r9.u64 = ctx.r26.u64 | 268435456;
	// mr r8,r22
	ctx.r8.u64 = ctx.r22.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// cmplw cr6,r3,r10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, ctx.xer);
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// ble cr6,0x82b30da4
	if (!ctx.cr6.gt) goto loc_82B30DA4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B30DA4;
	sub_82B1DAE8(ctx, base);
loc_82B30DA4:
	// lis r11,2
	ctx.r11.s64 = 131072;
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// ori r10,r11,8448
	ctx.r10.u64 = ctx.r11.u64 | 8448;
	// lis r11,0
	ctx.r11.s64 = 0;
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// li r6,8851
	ctx.r6.s64 = 8851;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// lis r10,2
	ctx.r10.s64 = 131072;
	// li r27,768
	ctx.r27.s64 = 768;
	// ori r4,r10,8708
	ctx.r4.u64 = ctx.r10.u64 | 8708;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// lis r10,1
	ctx.r10.s64 = 65536;
	// li r26,8978
	ctx.r26.s64 = 8978;
	// mr r28,r10
	ctx.r28.u64 = ctx.r10.u64;
	// li r25,8205
	ctx.r25.s64 = 8205;
	// mr r24,r22
	ctx.r24.u64 = ctx.r22.u64;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// li r23,8704
	ctx.r23.s64 = 8704;
	// mr r21,r22
	ctx.r21.u64 = ctx.r22.u64;
	// stwu r7,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r3.u32 = ea;
	// stwu r6,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r3.u32 = ea;
	// stwu r5,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	ctx.r3.u32 = ea;
	// stwu r4,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	ctx.r3.u32 = ea;
	// stwu r28,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r3.u32 = ea;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r27,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r27.u32);
	ctx.r3.u32 = ea;
	// stwu r26,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r26.u32);
	ctx.r3.u32 = ea;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stwu r25,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r25.u32);
	ctx.r3.u32 = ea;
	// stwu r24,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r24.u32);
	ctx.r3.u32 = ea;
	// stwu r23,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r23.u32);
	ctx.r3.u32 = ea;
	// stwu r21,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r21.u32);
	ctx.r3.u32 = ea;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// ble cr6,0x82b30e48
	if (!ctx.cr6.gt) goto loc_82B30E48;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B30E48;
	sub_82B1DAE8(ctx, base);
loc_82B30E48:
	// lis r11,5
	ctx.r11.s64 = 327680;
	// addi r28,r30,392
	ctx.r28.s64 = ctx.r30.s64 + 392;
	// ori r11,r11,18432
	ctx.r11.u64 = ctx.r11.u64 | 18432;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// lhz r11,372(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 372);
	// rlwinm r10,r10,0,22,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x3FC;
	// rlwinm r11,r11,17,0,9
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 17) & 0xFFC00000;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// oris r11,r11,32768
	ctx.r11.u64 = ctx.r11.u64 | 2147483648;
	// ori r11,r11,18434
	ctx.r11.u64 = ctx.r11.u64 | 18434;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r11,32(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 32);
	// rlwinm r9,r11,12,20,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0xFFF;
	// clrlwi r10,r11,3
	ctx.r10.u64 = ctx.r11.u32 & 0x1FFFFFFF;
	// addi r11,r9,512
	ctx.r11.s64 = ctx.r9.s64 + 512;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r11,40(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	// rotlwi r10,r11,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// rlwinm r11,r11,13,0,18
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 13) & 0xFFFFE000;
	// rlwinm r10,r10,0,19,7
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFF001FFF;
	// srawi r11,r11,13
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1FFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 13;
	// rlwinm r10,r10,0,7,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFF81FFFFFF;
	// rlwimi r11,r9,24,19,12
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 24) & 0xFFFFFFFFFFF81FFF) | (ctx.r11.u64 & 0x7E000);
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r11,44(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 44);
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// lwz r11,48(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// lwz r11,596(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 596);
	// lwz r10,584(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 584);
	// rlwinm r27,r11,2,30,31
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3;
	// lwz r11,604(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 604);
	// rlwinm r10,r10,2,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x4;
	// clrlwi r24,r27,31
	ctx.r24.u64 = ctx.r27.u32 & 0x1;
	// srawi. r11,r11,29
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1FFFFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 29;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// mulli r9,r24,56
	ctx.r9.s64 = ctx.r24.s64 * 56;
	// lwzx r25,r10,r30
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// rlwinm r10,r27,31,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 31) & 0x1;
	// addi r9,r9,527
	ctx.r9.s64 = ctx.r9.s64 + 527;
	// mulli r10,r10,1536
	ctx.r10.s64 = ctx.r10.s64 * 1536;
	// rlwinm r9,r9,0,0,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFE00;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// add r29,r10,r25
	ctx.r29.u64 = ctx.r10.u64 + ctx.r25.u64;
	// bne 0x82b30f40
	if (!ctx.cr0.eq) goto loc_82B30F40;
loc_82B30F18:
	// lwz r8,8(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// rlwinm r9,r29,0,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x1FFFFFFC;
	// rlwinm r10,r29,12,20,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 12) & 0xFFF;
	// addi r10,r10,512
	ctx.r10.s64 = ctx.r10.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// andi. r9,r8,49400
	ctx.r9.u64 = ctx.r8.u64 & 49400;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// oris r9,r9,19200
	ctx.r9.u64 = ctx.r9.u64 | 1258291200;
	// ori r9,r9,1536
	ctx.r9.u64 = ctx.r9.u64 | 1536;
	// b 0x82b30f74
	goto loc_82B30F74;
loc_82B30F40:
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82b30f18
	if (ctx.cr6.eq) goto loc_82B30F18;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82b30f9c
	if (!ctx.cr6.eq) goto loc_82B30F9C;
	// lwz r8,8(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// rlwinm r9,r29,0,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x1FFFFFFC;
	// rlwinm r10,r29,12,20,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 12) & 0xFFF;
	// addi r10,r10,512
	ctx.r10.s64 = ctx.r10.s64 + 512;
	// rlwinm r10,r10,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// andi. r9,r8,49400
	ctx.r9.u64 = ctx.r8.u64 & 49400;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// oris r9,r9,19200
	ctx.r9.u64 = ctx.r9.u64 | 1258291200;
	// ori r9,r9,2560
	ctx.r9.u64 = ctx.r9.u64 | 2560;
loc_82B30F74:
	// lis r7,16384
	ctx.r7.s64 = 1073741824;
	// lwz r11,388(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 388);
	// li r6,75
	ctx.r6.s64 = 75;
	// stw r9,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r9.u32);
	// rlwimi r7,r10,30,2,31
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r10.u32, 30) & 0x3FFFFFFF) | (ctx.r7.u64 & 0xFFFFFFFFC0000000);
	// lis r10,19200
	ctx.r10.s64 = 1258291200;
	// rlwimi r11,r6,24,0,8
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r6.u32, 24) & 0xFF800000) | (ctx.r11.u64 & 0xFFFFFFFF007FFFFF);
	// stw r7,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r7.u32);
	// stw r10,4(r28)
	PPC_STORE_U32(ctx.r28.u32 + 4, ctx.r10.u32);
	// stw r11,12(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12, ctx.r11.u32);
loc_82B30F9C:
	// li r4,49
	ctx.r4.s64 = 49;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dd08
	ctx.lr = 0x82B30FA8;
	sub_82B1DD08(ctx, base);
	// lis r11,47
	ctx.r11.s64 = 3080192;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// ori r11,r11,16384
	ctx.r11.u64 = ctx.r11.u64 | 16384;
	// li r5,192
	ctx.r5.s64 = 192;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r3,r28,4
	ctx.r3.s64 = ctx.r28.s64 + 4;
	// bl 0x82e28fd0
	ctx.lr = 0x82B30FC8;
	sub_82E28FD0(ctx, base);
	// addi r11,r28,192
	ctx.r11.s64 = ctx.r28.s64 + 192;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// lbz r11,608(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 608);
	// rlwinm. r11,r11,0,25,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b30fe8
	if (ctx.cr0.eq) goto loc_82B30FE8;
	// li r4,-1
	ctx.r4.s64 = -1;
	// lwz r3,364(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 364);
	// bl 0x82b07700
	ctx.lr = 0x82B30FE8;
	sub_82B07700(ctx, base);
loc_82B30FE8:
	// lhz r10,14(r30)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r30.u32 + 14);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// rotlwi r10,r10,9
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 9);
	// addi r11,r11,-24480
	ctx.r11.s64 = ctx.r11.s64 + -24480;
	// add r9,r10,r29
	ctx.r9.u64 = ctx.r10.u64 + ctx.r29.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B31000:
	// mfmsr r7
	ctx.r7.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r8,0,r10
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r10.u32);
	ctx.r8.u64 = __builtin_bswap32(ctx.reserved.u32);
	// stwcx. r9,0,r10
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r10.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r9.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r7,1
	ctx.msr = (ctx.r7.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82b31000
	if (!ctx.cr0.eq) goto loc_82B31000;
	// mr r11,r8
	ctx.r11.u64 = ctx.r8.u64;
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// li r7,6144
	ctx.r7.s64 = 6144;
	// subf r11,r8,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r8.s64;
	// divwu r11,r11,r7
	ctx.r11.u32 = ctx.r11.u32 / ctx.r7.u32;
	// cmplwi cr6,r11,14
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 14, ctx.xer);
	// mr r23,r11
	ctx.r23.u64 = ctx.r11.u64;
	// blt cr6,0x82b3103c
	if (ctx.cr6.lt) goto loc_82B3103C;
	// li r23,14
	ctx.r23.s64 = 14;
loc_82B3103C:
	// lwz r11,584(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 584);
	// lis r10,-25768
	ctx.r10.s64 = -1688731648;
	// stw r9,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r9.u32);
	// clrlwi r8,r29,3
	ctx.r8.u64 = ctx.r29.u32 & 0x1FFFFFFF;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lwz r7,596(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 596);
	// ori r6,r10,59162
	ctx.r6.u64 = ctx.r10.u64 | 59162;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// rlwinm r5,r11,2,29,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x4;
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// rlwinm r11,r29,12,20,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 12) & 0xFFF;
	// lwz r4,56(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// rlwinm r7,r7,4,30,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 4) & 0x3;
	// addi r9,r11,512
	ctx.r9.s64 = ctx.r11.s64 + 512;
	// cmplw cr6,r3,r4
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r4.u32, ctx.xer);
	// lwzx r11,r5,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r30.u32);
	// rlwinm r9,r9,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1000;
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// stwu r6,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r11.u32 = ea;
	// stw r9,10392(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10392, ctx.r9.u32);
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r23,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r23.u32);
	ctx.r11.u32 = ea;
	// ble cr6,0x82b310a8
	if (!ctx.cr6.gt) goto loc_82B310A8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B310A8;
	sub_82B1DAE8(ctx, base);
loc_82B310A8:
	// li r11,8198
	ctx.r11.s64 = 8198;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
	// mr r28,r22
	ctx.r28.u64 = ctx.r22.u64;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// lwz r11,13504(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13504);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// stw r11,13504(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13504, ctx.r11.u32);
	// lwz r29,376(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 376);
loc_82B310D0:
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b310ec
	if (!ctx.cr6.gt) goto loc_82B310EC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B310E8;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B310EC:
	// li r9,8450
	ctx.r9.s64 = 8450;
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// cmplwi cr6,r29,65535
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 65535, ctx.xer);
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r28,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r11.u32 = ea;
	// ble cr6,0x82b3110c
	if (!ctx.cr6.gt) goto loc_82B3110C;
	// lis r10,0
	ctx.r10.s64 = 0;
	// ori r10,r10,65534
	ctx.r10.u64 = ctx.r10.u64 | 65534;
loc_82B3110C:
	// lis r9,-16384
	ctx.r9.s64 = -1073741824;
	// li r8,129
	ctx.r8.s64 = 129;
	// ori r9,r9,13825
	ctx.r9.u64 = ctx.r9.u64 | 13825;
	// rlwimi r8,r10,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// subf. r29,r10,r29
	ctx.r29.s64 = ctx.r29.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// beq 0x82b31138
	if (ctx.cr0.eq) goto loc_82B31138;
	// add r28,r10,r28
	ctx.r28.u64 = ctx.r10.u64 + ctx.r28.u64;
	// b 0x82b310d0
	goto loc_82B310D0;
loc_82B31138:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// stw r22,10392(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10392, ctx.r22.u32);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b31154
	if (!ctx.cr6.gt) goto loc_82B31154;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B31154;
	sub_82B1DAE8(ctx, base);
loc_82B31154:
	// li r11,8198
	ctx.r11.s64 = 8198;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
	// stwu r11,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r3.u32 = ea;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// lwz r10,13504(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13504);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// stw r10,13504(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13504, ctx.r10.u32);
	// ble cr6,0x82b31190
	if (!ctx.cr6.gt) goto loc_82B31190;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b1dae8
	ctx.lr = 0x82B3118C;
	sub_82B1DAE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82B31190:
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// li r9,6
	ctx.r9.s64 = 6;
	// ori r10,r10,17920
	ctx.r10.u64 = ctx.r10.u64 | 17920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r11,r11,8
	ctx.r11.u64 = ctx.r11.u64 | 8;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// oris r11,r11,8
	ctx.r11.u64 = ctx.r11.u64 | 524288;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// oris r11,r11,16
	ctx.r11.u64 = ctx.r11.u64 | 1048576;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// ld r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// oris r11,r11,65024
	ctx.r11.u64 = ctx.r11.u64 | 4261412864;
	// std r11,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r11.u64);
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r11,r11,2048
	ctx.r11.u64 = ctx.r11.u64 | 2048;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// ori r11,r11,256
	ctx.r11.u64 = ctx.r11.u64 | 256;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// lwz r26,588(r30)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r30.u32 + 588);
	// bl 0x82b1dbe8
	ctx.lr = 0x82B311F0;
	sub_82B1DBE8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,588(r30)
	PPC_STORE_U32(ctx.r30.u32 + 588, ctx.r11.u32);
	// bl 0x82b16a58
	ctx.lr = 0x82B3120C;
	sub_82B16A58(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b16a58
	ctx.lr = 0x82B31220;
	sub_82B16A58(ctx, base);
	// lwz r11,596(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 596);
	// clrlwi r28,r27,30
	ctx.r28.u64 = ctx.r27.u32 & 0x3;
	// rlwinm r11,r11,0,4,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFCFFFFFFF;
	// rlwinm r10,r28,28,0,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 28) & 0xF0000000;
	// addi r29,r25,16
	ctx.r29.s64 = ctx.r25.s64 + 16;
	// or r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 | ctx.r11.u64;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// stw r11,596(r30)
	PPC_STORE_U32(ctx.r30.u32 + 596, ctx.r11.u32);
	// beq cr6,0x82b31258
	if (ctx.cr6.eq) goto loc_82B31258;
	// li r5,56
	ctx.r5.s64 = 56;
	// addi r4,r31,13724
	ctx.r4.s64 = ctx.r31.s64 + 13724;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B31254;
	sub_82E28FD0(ctx, base);
	// addi r29,r29,56
	ctx.r29.s64 = ctx.r29.s64 + 56;
loc_82B31258:
	// subf r11,r25,r29
	ctx.r11.s64 = ctx.r29.s64 - ctx.r25.s64;
	// rlwinm. r10,r27,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,511
	ctx.r11.s64 = ctx.r11.s64 + 511;
	// rlwinm r11,r11,0,0,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFE00;
	// add r29,r11,r25
	ctx.r29.u64 = ctx.r11.u64 + ctx.r25.u64;
	// beq 0x82b312a8
	if (ctx.cr0.eq) goto loc_82B312A8;
	// lbz r11,600(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 600);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,592(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 592);
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// rlwinm. r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b31290
	if (ctx.cr0.eq) goto loc_82B31290;
	// bl 0x82b2bb68
	ctx.lr = 0x82B3128C;
	sub_82B2BB68(ctx, base);
	// b 0x82b31294
	goto loc_82B31294;
loc_82B31290:
	// bl 0x82b2bad0
	ctx.lr = 0x82B31294;
	sub_82B2BAD0(ctx, base);
loc_82B31294:
	// li r5,1536
	ctx.r5.s64 = 1536;
	// lwz r4,592(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 592);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B312A4;
	sub_82E28FD0(ctx, base);
	// addi r29,r29,1536
	ctx.r29.s64 = ctx.r29.s64 + 1536;
loc_82B312A8:
	// lwz r8,584(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 584);
	// rlwinm r7,r28,26,0,5
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r28.u32 | (ctx.r28.u64 << 32), 26) & 0xFC000000;
	// lhz r9,12(r30)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r30.u32 + 12);
	// mulli r11,r23,12
	ctx.r11.s64 = ctx.r23.s64 * 12;
	// lwz r6,596(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 596);
	// lbz r5,608(r30)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r30.u32 + 608);
	// lhz r10,14(r30)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r30.u32 + 14);
	// rlwinm r8,r8,2,29,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0x4;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// or r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 | ctx.r6.u64;
	// rlwinm r31,r11,9,0,22
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 9) & 0xFFFFFE00;
	// clrlwi r9,r7,2
	ctx.r9.u64 = ctx.r7.u32 & 0x3FFFFFFF;
	// lwzx r8,r8,r30
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// subf r11,r8,r29
	ctx.r11.s64 = ctx.r29.s64 - ctx.r8.s64;
	// rlwinm r11,r11,23,9,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 23) & 0x7FFFFF;
	// stw r9,596(r30)
	PPC_STORE_U32(ctx.r30.u32 + 596, ctx.r9.u32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// sth r11,12(r30)
	PPC_STORE_U16(ctx.r30.u32 + 12, ctx.r11.u16);
	// rlwinm. r7,r5,0,0,24
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFF80;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82b31358
	if (ctx.cr0.eq) goto loc_82B31358;
	// lwz r11,380(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 380);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stw r22,360(r30)
	PPC_STORE_U32(ctx.r30.u32 + 360, ctx.r22.u32);
	// stw r11,356(r30)
	PPC_STORE_U32(ctx.r30.u32 + 356, ctx.r11.u32);
	// bl 0x82b1d6a8
	ctx.lr = 0x82B3130C;
	sub_82B1D6A8(ctx, base);
	// lwz r11,596(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 596);
	// addi r7,r30,348
	ctx.r7.s64 = ctx.r30.s64 + 348;
	// lwz r10,584(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 584);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r11,12,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0x3F;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,5
	ctx.r11.s64 = ctx.r11.s64 + 5;
	// rlwinm r10,r10,2,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0x4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lwzx r4,r10,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// bl 0x82b07280
	ctx.lr = 0x82B31340;
	sub_82B07280(ctx, base);
	// lbz r11,608(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 608);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// ori r11,r11,64
	ctx.r11.u64 = ctx.r11.u64 | 64;
	// stb r11,608(r30)
	PPC_STORE_U8(ctx.r30.u32 + 608, ctx.r11.u8);
	// bl 0x82b305a8
	ctx.lr = 0x82B31358;
	sub_82B305A8(ctx, base);
loc_82B31358:
	// lbz r10,608(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 608);
	// lwz r11,584(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 584);
	// ori r10,r10,128
	ctx.r10.u64 = ctx.r10.u64 | 128;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stb r10,608(r30)
	PPC_STORE_U8(ctx.r30.u32 + 608, ctx.r10.u8);
	// stw r11,584(r30)
	PPC_STORE_U32(ctx.r30.u32 + 584, ctx.r11.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B31378"))) PPC_WEAK_FUNC(sub_82B31378);
PPC_FUNC_IMPL(__imp__sub_82B31378) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x82b30660
	ctx.lr = 0x82B31388;
	sub_82B30660(ctx, base);
	// lis r10,-31967
	ctx.r10.s64 = -2094989312;
	// li r11,0
	ctx.r11.s64 = 0;
	// stb r11,29263(r10)
	PPC_STORE_U8(ctx.r10.u32 + 29263, ctx.r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B313A8"))) PPC_WEAK_FUNC(sub_82B313A8);
PPC_FUNC_IMPL(__imp__sub_82B313A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82B313B0;
	__savegprlr_24(ctx, base);
	// stwu r1,-816(r1)
	ea = -816 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r29,r24,21680
	ctx.r29.s64 = ctx.r24.s64 + 21680;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// lbz r11,608(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 608);
	// rlwinm. r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b313e0
	if (ctx.cr0.eq) goto loc_82B313E0;
loc_82B313D0:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82b30660
	ctx.lr = 0x82B313D8;
	sub_82B30660(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b31734
	goto loc_82B31734;
loc_82B313E0:
	// li r5,260
	ctx.r5.s64 = 260;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82e2ab28
	ctx.lr = 0x82B313EC;
	sub_82E2AB28(ctx, base);
	// li r25,0
	ctx.r25.s64 = 0;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// stb r25,371(r1)
	PPC_STORE_U8(ctx.r1.u32 + 371, ctx.r25.u8);
loc_82B313FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b313fc
	if (!ctx.cr6.eq) goto loc_82B313FC;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r31,r11,-1
	ctx.r31.s64 = ctx.r11.s64 + -1;
	// cmplw cr6,r31,r9
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82b3144c
	if (ctx.cr6.lt) goto loc_82B3144C;
loc_82B31430:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,92
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 92, ctx.xer);
	// beq cr6,0x82b3144c
	if (ctx.cr6.eq) goto loc_82B3144C;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82b31430
	if (!ctx.cr6.lt) goto loc_82B31430;
loc_82B3144C:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,92
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 92, ctx.xer);
	// beq cr6,0x82b31468
	if (ctx.cr6.eq) goto loc_82B31468;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-10984
	ctx.r3.s64 = ctx.r11.s64 + -10984;
	// bl 0x82b28910
	ctx.lr = 0x82B31464;
	sub_82B28910(ctx, base);
	// b 0x82b313d0
	goto loc_82B313D0;
loc_82B31468:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stb r25,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r25.u8);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x83157db4
	ctx.lr = 0x82B31478;
	__imp__RtlInitAnsiString(ctx, base);
	// lis r11,-31975
	ctx.r11.s64 = -2095513600;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// addi r3,r11,-24456
	ctx.r3.s64 = ctx.r11.s64 + -24456;
	// bl 0x831583c4
	ctx.lr = 0x82B31488;
	__imp__ObCreateSymbolicLink(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b314a4
	if (!ctx.cr0.lt) goto loc_82B314A4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-11020
	ctx.r3.s64 = ctx.r11.s64 + -11020;
loc_82B31498:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82b28910
	ctx.lr = 0x82B314A0;
	sub_82B28910(ctx, base);
	// b 0x82b313d0
	goto loc_82B313D0;
loc_82B314A4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r6,r31,1
	ctx.r6.s64 = ctx.r31.s64 + 1;
	// addi r5,r11,-11028
	ctx.r5.s64 = ctx.r11.s64 + -11028;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,480
	ctx.r3.s64 = ctx.r1.s64 + 480;
	// addi r4,r11,-11036
	ctx.r4.s64 = ctx.r11.s64 + -11036;
	// bl 0x83158234
	ctx.lr = 0x82B314C0;
	__imp__sprintf(ctx, base);
	// addi r5,r1,480
	ctx.r5.s64 = ctx.r1.s64 + 480;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82b2f8f8
	ctx.lr = 0x82B314D0;
	sub_82B2F8F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b313d0
	if (ctx.cr0.lt) goto loc_82B313D0;
	// li r5,260
	ctx.r5.s64 = 260;
	// addi r4,r1,480
	ctx.r4.s64 = ctx.r1.s64 + 480;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82e2ab28
	ctx.lr = 0x82B314E8;
	sub_82E2AB28(ctx, base);
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// stb r25,371(r1)
	PPC_STORE_U8(ctx.r1.u32 + 371, ctx.r25.u8);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B314F4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b314f4
	if (!ctx.cr6.eq) goto loc_82B314F4;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82b31554
	if (ctx.cr6.lt) goto loc_82B31554;
loc_82B3152C:
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,46
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 46, ctx.xer);
	// beq cr6,0x82b31554
	if (ctx.cr6.eq) goto loc_82B31554;
	// cmpwi cr6,r10,92
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 92, ctx.xer);
	// beq cr6,0x82b31554
	if (ctx.cr6.eq) goto loc_82B31554;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82b3152c
	if (!ctx.cr6.lt) goto loc_82B3152C;
loc_82B31554:
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,46
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 46, ctx.xer);
	// beq cr6,0x82b31564
	if (ctx.cr6.eq) goto loc_82B31564;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
loc_82B31564:
	// lwz r11,596(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 596);
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
	// rlwinm. r11,r11,0,12,17
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFC000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r27,r11,-5712
	ctx.r27.s64 = ctx.r11.s64 + -5712;
	// beq 0x82b3164c
	if (ctx.cr0.eq) goto loc_82B3164C;
	// addi r28,r29,20
	ctx.r28.s64 = ctx.r29.s64 + 20;
	// lis r26,-31967
	ctx.r26.s64 = -2094989312;
loc_82B31584:
	// lbz r11,29260(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 29260);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b313d0
	if (!ctx.cr0.eq) goto loc_82B313D0;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// addi r10,r1,480
	ctx.r10.s64 = ctx.r1.s64 + 480;
	// subf r11,r11,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r11.s64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// add r6,r11,r10
	ctx.r6.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x83158234
	ctx.lr = 0x82B315B0;
	__imp__sprintf(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// lis r8,26624
	ctx.r8.s64 = 1744830464;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lis r4,16384
	ctx.r4.s64 = 1073741824;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b07088
	ctx.lr = 0x82B315D0;
	sub_82B07088(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// stw r3,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82b3173c
	if (ctx.cr6.eq) goto loc_82B3173C;
	// lwz r11,596(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 596);
	// rlwinm r11,r11,18,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x3F;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b31610
	if (!ctx.cr6.eq) goto loc_82B31610;
	// lwz r11,384(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 384);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b31604
	if (ctx.cr0.eq) goto loc_82B31604;
	// clrldi r11,r11,32
	ctx.r11.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// b 0x82b31618
	goto loc_82B31618;
loc_82B31604:
	// li r11,1
	ctx.r11.s64 = 1;
	// rldicr r11,r11,32,63
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// b 0x82b31618
	goto loc_82B31618;
loc_82B31610:
	// li r11,0
	ctx.r11.s64 = 0;
	// oris r11,r11,65520
	ctx.r11.u64 = ctx.r11.u64 | 4293918720;
loc_82B31618:
	// li r6,0
	ctx.r6.s64 = 0;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x82b07f60
	ctx.lr = 0x82B3162C;
	sub_82B07F60(ctx, base);
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// bl 0x82f66328
	ctx.lr = 0x82B31634;
	sub_82F66328(ctx, base);
	// lwz r11,596(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 596);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// rlwinm r11,r11,18,26,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x3F;
	// addi r28,r28,4
	ctx.r28.s64 = ctx.r28.s64 + 4;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b31584
	if (ctx.cr6.lt) goto loc_82B31584;
loc_82B3164C:
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// addi r10,r1,480
	ctx.r10.s64 = ctx.r1.s64 + 480;
	// subf r11,r11,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r11.s64;
	// add r28,r11,r10
	ctx.r28.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82B3165C:
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x83158234
	ctx.lr = 0x82B31670;
	__imp__sprintf(ctx, base);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// bl 0x82b08608
	ctx.lr = 0x82B3167C;
	sub_82B08608(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b3165c
	if (!ctx.cr0.eq) goto loc_82B3165C;
	// addi r31,r29,348
	ctx.r31.s64 = ctx.r29.s64 + 348;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r25,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r25.u32);
	// stw r25,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r25.u32);
	// stw r25,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r25.u32);
	// stw r25,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r25.u32);
	// stw r25,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r25.u32);
	// bl 0x82b07638
	ctx.lr = 0x82B316AC;
	sub_82B07638(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,364(r29)
	PPC_STORE_U32(ctx.r29.u32 + 364, ctx.r3.u32);
	// beq 0x82b313d0
	if (ctx.cr0.eq) goto loc_82B313D0;
	// li r5,2048
	ctx.r5.s64 = 2048;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r25,356(r29)
	PPC_STORE_U32(ctx.r29.u32 + 356, ctx.r25.u32);
	// stw r25,360(r29)
	PPC_STORE_U32(ctx.r29.u32 + 360, ctx.r25.u32);
	// bl 0x82e29500
	ctx.lr = 0x82B316D0;
	sub_82E29500(ctx, base);
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r5,2048
	ctx.r5.s64 = 2048;
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// bl 0x82b07280
	ctx.lr = 0x82B316E8;
	sub_82B07280(ctx, base);
	// li r4,-1
	ctx.r4.s64 = -1;
	// lwz r3,364(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 364);
	// bl 0x82b07700
	ctx.lr = 0x82B316F4;
	sub_82B07700(ctx, base);
	// addi r3,r1,384
	ctx.r3.s64 = ctx.r1.s64 + 384;
	// bl 0x83158294
	ctx.lr = 0x82B316FC;
	__imp__VdGetCurrentDisplayInformation(ctx, base);
	// lbz r11,389(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 389);
	// lbz r10,600(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 600);
	// li r9,2048
	ctx.r9.s64 = 2048;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lwz r8,596(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 596);
	// stw r25,584(r29)
	PPC_STORE_U32(ctx.r29.u32 + 584, ctx.r25.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r8,r8,0,12,5
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFC0FFFFF;
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// stw r9,380(r29)
	PPC_STORE_U32(ctx.r29.u32 + 380, ctx.r9.u32);
	// rlwimi r10,r11,7,24,24
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 7) & 0x80) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFF7F);
	// stw r8,596(r29)
	PPC_STORE_U32(ctx.r29.u32 + 596, ctx.r8.u32);
	// stb r10,600(r29)
	PPC_STORE_U8(ctx.r29.u32 + 600, ctx.r10.u8);
loc_82B31734:
	// addi r1,r1,816
	ctx.r1.s64 = ctx.r1.s64 + 816;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
loc_82B3173C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,-11092
	ctx.r3.s64 = ctx.r11.s64 + -11092;
	// b 0x82b31498
	goto loc_82B31498;
}

__attribute__((alias("__imp__sub_82B31748"))) PPC_WEAK_FUNC(sub_82B31748);
PPC_FUNC_IMPL(__imp__sub_82B31748) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31967
	ctx.r11.s64 = -2094989312;
	// addi r5,r11,29000
	ctx.r5.s64 = ctx.r11.s64 + 29000;
	// lbz r11,262(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 262);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b31828
	if (ctx.cr0.eq) goto loc_82B31828;
	// lbz r11,22288(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 22288);
	// rlwinm. r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b31804
	if (!ctx.cr0.eq) goto loc_82B31804;
	// bl 0x82b313a8
	ctx.lr = 0x82B31778;
	sub_82B313A8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b31788
	if (ctx.cr0.eq) goto loc_82B31788;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x82b31790
	goto loc_82B31790;
loc_82B31788:
	// lis r6,-32768
	ctx.r6.s64 = -2147483648;
	// ori r6,r6,16389
	ctx.r6.u64 = ctx.r6.u64 | 16389;
loc_82B31790:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r5,r11,-10920
	ctx.r5.s64 = ctx.r11.s64 + -10920;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r4,r11,-10932
	ctx.r4.s64 = ctx.r11.s64 + -10932;
	// bl 0x83158234
	ctx.lr = 0x82B317A8;
	__imp__sprintf(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2020(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2020);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b317d8
	if (ctx.cr6.eq) goto loc_82B317D8;
	// rotlwi r11,r10,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b31828
	if (ctx.cr0.eq) goto loc_82B31828;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b31828
	if (ctx.cr0.eq) goto loc_82B31828;
	// b 0x82b317f0
	goto loc_82B317F0;
loc_82B317D8:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lwz r11,2332(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2332);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b31828
	if (ctx.cr0.eq) goto loc_82B31828;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82B317F0:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,27
	ctx.r3.s64 = 27;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B31800;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82b31828
	goto loc_82B31828;
loc_82B31804:
	// lbz r11,260(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 260);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b31818
	if (ctx.cr0.eq) goto loc_82B31818;
	// bl 0x82b30660
	ctx.lr = 0x82B31814;
	sub_82B30660(ctx, base);
	// b 0x82b31828
	goto loc_82B31828;
loc_82B31818:
	// lbz r11,261(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 261);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b31828
	if (ctx.cr0.eq) goto loc_82B31828;
	// bl 0x82b30a80
	ctx.lr = 0x82B31828;
	sub_82B30A80(ctx, base);
loc_82B31828:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B31838"))) PPC_WEAK_FUNC(sub_82B31838);
PPC_FUNC_IMPL(__imp__sub_82B31838) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// rlwinm r4,r3,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
loc_82B31850:
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// cmplwi cr6,r3,1
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 1, ctx.xer);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// ble cr6,0x82b31898
	if (!ctx.cr6.gt) goto loc_82B31898;
	// addi r8,r5,4
	ctx.r8.s64 = ctx.r5.s64 + 4;
	// addi r7,r10,4
	ctx.r7.s64 = ctx.r10.s64 + 4;
	// addi r9,r3,-1
	ctx.r9.s64 = ctx.r3.s64 + -1;
loc_82B31874:
	// lfs f0,0(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// lfs f13,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// fmadds f0,f0,f13,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// bne 0x82b31874
	if (!ctx.cr0.eq) goto loc_82B31874;
loc_82B31898:
	// addic. r6,r6,-1
	ctx.xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// add r10,r4,r10
	ctx.r10.u64 = ctx.r4.u64 + ctx.r10.u64;
	// bne 0x82b31850
	if (!ctx.cr0.eq) goto loc_82B31850;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B318B0"))) PPC_WEAK_FUNC(sub_82B318B0);
PPC_FUNC_IMPL(__imp__sub_82B318B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82B318B8;
	__savegprlr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28ee0
	ctx.lr = 0x82B318C0;
	__savefpr_14(ctx, base);
	// ld r12,-4096(r1)
	ctx.r12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -4096);
	// stwu r1,-5104(r1)
	ea = -5104 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// addi r6,r31,4
	ctx.r6.s64 = ctx.r31.s64 + 4;
	// lfs f20,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f20.f64 = double(temp.f32);
	// addi r5,r29,4
	ctx.r5.s64 = ctx.r29.s64 + 4;
	// lfs f23,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f23.f64 = double(temp.f32);
	// addi r4,r1,4288
	ctx.r4.s64 = ctx.r1.s64 + 4288;
	// lfs f25,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f25.f64 = double(temp.f32);
	// li r3,3
	ctx.r3.s64 = 3;
	// lfs f17,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f17.f64 = double(temp.f32);
	// stw r31,5124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 5124, ctx.r31.u32);
	// lfs f19,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f19.f64 = double(temp.f32);
	// stw r29,5148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 5148, ctx.r29.u32);
	// lfs f18,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f18.f64 = double(temp.f32);
	// lfs f28,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f31.f64 = double(temp.f32);
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// fneg f0,f25
	ctx.f0.u64 = ctx.f25.u64 ^ 0x8000000000000000;
	// stfs f0,4308(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4308, temp.u32);
	// fneg f0,f18
	ctx.f0.u64 = ctx.f18.u64 ^ 0x8000000000000000;
	// stfs f0,4300(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4300, temp.u32);
	// fneg f0,f28
	ctx.f0.u64 = ctx.f28.u64 ^ 0x8000000000000000;
	// stfs f0,4316(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4316, temp.u32);
	// fneg f0,f30
	ctx.f0.u64 = ctx.f30.u64 ^ 0x8000000000000000;
	// stfs f20,964(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 964, temp.u32);
	// stfs f23,448(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// stfs f25,564(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// stfs f17,1068(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1068, temp.u32);
	// stfs f19,956(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 956, temp.u32);
	// stfs f18,404(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// stfs f20,4320(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4320, temp.u32);
	// stfs f23,4296(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4296, temp.u32);
	// stfs f17,4312(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4312, temp.u32);
	// stfs f19,4288(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4288, temp.u32);
	// stfs f0,4292(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4292, temp.u32);
	// stfs f31,4304(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4304, temp.u32);
	// bl 0x82b31838
	ctx.lr = 0x82B3196C;
	sub_82B31838(ctx, base);
	// cmplwi cr6,r28,2
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 2, ctx.xer);
	// bgt cr6,0x82b31978
	if (ctx.cr6.gt) goto loc_82B31978;
	// b 0x82b43b90
	goto loc_82B43B90;
loc_82B31978:
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// fmuls f4,f30,f20
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// stfs f4,2336(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2336, temp.u32);
	// fmuls f12,f30,f17
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f17.f64));
	// fmuls f2,f17,f23
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f23.f64));
	// stfs f2,104(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f1,f19,f20
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// stfs f1,88(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmuls f3,f19,f25
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// stfs f3,168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfd f0,40(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 40);
	// lis r11,-32247
	ctx.r11.s64 = -2113339392;
	// fsqrts f0,f0
	ctx.f0.f64 = double(float(sqrt(ctx.f0.f64)));
	// stfs f0,212(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fneg f4,f4
	ctx.f4.u64 = ctx.f4.u64 ^ 0x8000000000000000;
	// fneg f16,f12
	ctx.f16.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// lfd f13,-29544(r11)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + -29544);
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f13,f18,f25
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmuls f9,f17,f20
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f20.f64));
	// fmuls f10,f19,f23
	ctx.f10.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// fmuls f7,f28,f17
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f11,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// fmuls f6,f30,f19
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// fmuls f5,f28,f20
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f20.f64));
	// fmuls f29,f20,f20
	ctx.f29.f64 = double(float(ctx.f20.f64 * ctx.f20.f64));
	// fmuls f22,f23,f23
	ctx.f22.f64 = double(float(ctx.f23.f64 * ctx.f23.f64));
	// fmuls f14,f17,f17
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f17.f64));
	// fmuls f15,f0,f30
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f8,f19,f19
	ctx.f8.f64 = double(float(ctx.f19.f64 * ctx.f19.f64));
	// fmuls f26,f28,f28
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmuls f27,f30,f30
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f2,4288(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4288, temp.u32);
	// fmuls f4,f28,f19
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f24,f31,f31
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f12,f0,f31
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fneg f3,f3
	ctx.f3.u64 = ctx.f3.u64 ^ 0x8000000000000000;
	// stfs f13,288(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// fmuls f13,f30,f23
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f23.f64));
	// stfs f9,112(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f10,92(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f7,200(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stfs f6,556(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 556, temp.u32);
	// stfs f5,244(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// stfs f29,452(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// stfs f22,424(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// stfs f14,400(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// stfs f8,268(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// stfs f13,348(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmuls f13,f23,f20
	ctx.f13.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// stfs f13,160(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f13,f19,f17
	ctx.f13.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f13,f18,f23
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// stfs f13,196(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// fmuls f13,f31,f19
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f19.f64));
	// stfs f13,1528(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1528, temp.u32);
	// fmuls f13,f18,f19
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// fsubs f4,f16,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// stfs f13,116(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f4,4292(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4292, temp.u32);
	// fmuls f4,f28,f23
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f13,f25,f23
	ctx.f13.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// lfs f16,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f16.f64 = double(temp.f32);
	// stfs f13,124(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// lfs f13,-16876(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -16876);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f21,-28552(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -28552);
	ctx.f21.f64 = double(temp.f32);
	// stfs f21,304(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fsubs f4,f16,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 - ctx.f4.f64));
	// stfs f4,4300(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4300, temp.u32);
	// lfs f4,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
	// stfs f4,4304(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4304, temp.u32);
	// lfs f4,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fsubs f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 - ctx.f4.f64));
	// stfs f4,4308(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4308, temp.u32);
	// fmuls f4,f30,f18
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// lfs f3,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f1,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f12,f30
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// addi r6,r31,16
	ctx.r6.s64 = ctx.r31.s64 + 16;
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// addi r5,r29,16
	ctx.r5.s64 = ctx.r29.s64 + 16;
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// addi r4,r1,4288
	ctx.r4.s64 = ctx.r1.s64 + 4288;
	// li r3,5
	ctx.r3.s64 = 5;
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f4,4312(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4312, temp.u32);
	// lfs f4,-18520(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18520);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f31,f23
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// stfs f4,356(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fmuls f4,f15,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// stfs f4,4296(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4296, temp.u32);
	// fmuls f4,f30,f25
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// fmuls f15,f26,f0
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f4,4320(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4320, temp.u32);
	// lfs f3,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f3.f64));
	// stfs f4,4324(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4324, temp.u32);
	// fmuls f4,f12,f18
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// fmuls f3,f9,f13
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmsubs f3,f1,f11,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 - ctx.f3.f64));
	// fmuls f1,f10,f13
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,8760(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8760);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// stfs f10,4316(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4316, temp.u32);
	// fmuls f2,f27,f0
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmsubs f10,f7,f13,f4
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 - ctx.f4.f64));
	// fmuls f4,f22,f0
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmsubs f7,f3,f0,f1
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f1.f64));
	// stfs f7,4328(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4328, temp.u32);
	// fadds f3,f8,f14
	ctx.f3.f64 = double(float(ctx.f8.f64 + ctx.f14.f64));
	// fadds f8,f8,f29
	ctx.f8.f64 = double(float(ctx.f8.f64 + ctx.f29.f64));
	// fnmsubs f1,f26,f21,f24
	ctx.f1.f64 = double(float(-(ctx.f26.f64 * ctx.f21.f64 - ctx.f24.f64)));
	// fmadds f10,f6,f13,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f10.f64));
	// stfs f10,4332(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4332, temp.u32);
	// fmuls f6,f17,f25
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// stfs f6,156(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fmuls f6,f18,f17
	ctx.f6.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// stfs f6,144(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmuls f6,f25,f20
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// stfs f6,192(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fmuls f6,f12,f25
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// fmuls f10,f18,f18
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f18.f64));
	// stfs f10,120(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// fmuls f10,f25,f25
	ctx.f10.f64 = double(float(ctx.f25.f64 * ctx.f25.f64));
	// stfs f10,96(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f10,f18,f20
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// stfs f10,132(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f10,32(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// fmuls f7,f29,f10
	ctx.f7.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f11,f6,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f6,f22,f21
	ctx.f6.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// fmsubs f11,f5,f13,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 - ctx.f11.f64));
	// fmuls f5,f12,f28
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f12,-27568(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -27568);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f8,f8,f21,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f21.f64 - ctx.f6.f64));
	// stfs f12,620(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// fnmsubs f6,f27,f21,f1
	ctx.f6.f64 = double(float(-(ctx.f27.f64 * ctx.f21.f64 - ctx.f1.f64)));
	// stfs f6,4336(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4336, temp.u32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmadds f11,f16,f13,f11
	ctx.f11.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f11.f64));
	// stfs f11,4340(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4340, temp.u32);
	// fmsubs f12,f15,f12,f2
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f2.f64));
	// lfs f11,8760(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8760);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f5,f11
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// stfs f11,4356(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4356, temp.u32);
	// lfs f11,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// stfs f11,4368(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4368, temp.u32);
	// lfs f9,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f9.f64 = double(temp.f32);
	// lfs f11,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// stfs f11,4372(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4372, temp.u32);
	// lfs f9,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f9.f64 = double(temp.f32);
	// lfs f11,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f11.f64 = double(temp.f32);
	// stfs f12,4376(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4376, temp.u32);
	// fsubs f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f9.f64));
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// stfs f11,4380(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4380, temp.u32);
	// fmuls f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f12,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f12.f64 = double(temp.f32);
	// fneg f9,f12
	ctx.f9.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fnmsubs f12,f14,f21,f8
	ctx.f12.f64 = double(float(-(ctx.f14.f64 * ctx.f21.f64 - ctx.f8.f64)));
	// stfs f12,4384(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4384, temp.u32);
	// fmuls f12,f28,f18
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f8,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f12,f31,f17,f12
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f17.f64 + ctx.f12.f64));
	// stfs f12,4352(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4352, temp.u32);
	// fmuls f12,f28,f25
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f12,f31,f20,f12
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f20.f64 + ctx.f12.f64));
	// stfs f12,4360(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4360, temp.u32);
	// lfs f12,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f8.f64));
	// stfs f12,4364(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4364, temp.u32);
	// lfs f12,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f12,f12,f13,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f7.f64));
	// lfs f8,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
	// stfs f9,4348(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4348, temp.u32);
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmsubs f0,f11,f13,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f0.f64));
	// fnmsubs f0,f4,f10,f0
	ctx.f0.f64 = double(float(-(ctx.f4.f64 * ctx.f10.f64 - ctx.f0.f64)));
	// fmadds f0,f3,f10,f0
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f0.f64));
	// stfs f0,4344(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4344, temp.u32);
	// bl 0x82b31838
	ctx.lr = 0x82B31CB0;
	sub_82B31838(ctx, base);
	// cmplwi cr6,r28,3
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 3, ctx.xer);
	// bgt cr6,0x82b31cbc
	if (ctx.cr6.gt) goto loc_82B31CBC;
	// b 0x82b43b90
	goto loc_82B43B90;
loc_82B31CBC:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f8,268(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f8.f64 = double(temp.f32);
	// lfd f0,-18560(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -18560);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fsqrts f16,f0
	ctx.f16.f64 = double(float(sqrt(ctx.f0.f64)));
	// stfs f16,280(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// lfd f0,-360(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -360);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fsqrts f15,f0
	ctx.f15.f64 = double(float(sqrt(ctx.f0.f64)));
	// fmuls f11,f15,f16
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfd f0,-368(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -368);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fsqrts f13,f0
	ctx.f13.f64 = double(float(sqrt(ctx.f0.f64)));
	// stfs f15,580(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// fmuls f5,f13,f14
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f14.f64));
	// fmuls f4,f13,f22
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// fmuls f3,f13,f29
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// fmuls f2,f13,f8
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fmuls f6,f13,f16
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f16.f64));
	// lfd f0,-496(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -496);
	// fsqrts f10,f0
	ctx.f10.f64 = double(float(sqrt(ctx.f0.f64)));
	// fmuls f1,f10,f27
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f7,f10,f30
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// stfs f5,136(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f4,228(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stfs f3,596(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// stfs f2,80(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f6,240(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// lfd f0,-376(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -376);
	// fsqrts f9,f0
	ctx.f9.f64 = double(float(sqrt(ctx.f0.f64)));
	// fmuls f0,f14,f19
	ctx.f0.f64 = double(float(ctx.f14.f64 * ctx.f19.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f7,1584(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1584, temp.u32);
	// fmuls f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f0,1172(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1172, temp.u32);
	// stfs f1,1048(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1048, temp.u32);
	// fmuls f1,f22,f23
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f0,f23
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// stfs f1,1212(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1212, temp.u32);
	// lfs f1,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f12,720(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// fmuls f12,f29,f19
	ctx.f12.f64 = double(float(ctx.f29.f64 * ctx.f19.f64));
	// stfs f12,1204(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1204, temp.u32);
	// fmuls f12,f22,f19
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// stfs f1,1592(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1592, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// stfs f12,1608(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1608, temp.u32);
	// fmuls f12,f0,f30
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// stfs f7,520(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f7,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// stfs f0,1180(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1180, temp.u32);
	// fmuls f0,f29,f23
	ctx.f0.f64 = double(float(ctx.f29.f64 * ctx.f23.f64));
	// stfs f1,828(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 828, temp.u32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// stfs f0,1616(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1616, temp.u32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f7,1624(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1624, temp.u32);
	// fmuls f0,f10,f13
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// stfs f0,252(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmuls f7,f26,f23
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// stfs f1,1196(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1196, temp.u32);
	// fmuls f0,f9,f16
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f16.f64));
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// stfs f7,256(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f7,f5,f30
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f12,1600(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1600, temp.u32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f0,216(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmuls f12,f9,f15
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f15.f64));
	// stfs f7,748(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 748, temp.u32);
	// fmuls f0,f13,f11
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// stfs f12,172(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f7,f4,f30
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f0,428(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// stfs f1,332(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// stfs f7,248(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f4,f10,f28
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f7,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f15,f22
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f22.f64));
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f7,1188(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1188, temp.u32);
	// fmuls f7,f3,f30
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// stfs f7,708(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 708, temp.u32);
	// fmuls f7,f2,f30
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f7,716(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 716, temp.u32);
	// fmuls f7,f6,f9
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// stfs f7,220(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f15,f14
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f7,944(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 944, temp.u32);
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f15,f29
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f29.f64));
	// fmuls f13,f7,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f13,1576(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1576, temp.u32);
	// fmuls f13,f10,f16
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f16.f64));
	// stfs f13,316(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// stfs f4,868(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 868, temp.u32);
	// fmuls f4,f15,f8
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// fmuls f13,f15,f18
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f18.f64));
	// fmuls f7,f9,f18
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// stfs f7,1568(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1568, temp.u32);
	// fmuls f6,f9,f25
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// stfs f6,1560(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1560, temp.u32);
	// fmuls f5,f15,f25
	ctx.f5.f64 = double(float(ctx.f15.f64 * ctx.f25.f64));
	// fmuls f10,f10,f26
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fmuls f4,f4,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// stfs f4,968(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 968, temp.u32);
	// fmuls f4,f3,f18
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// stfs f4,936(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 936, temp.u32);
	// lfs f4,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// stfs f4,1032(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1032, temp.u32);
	// fmuls f4,f2,f25
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f4,984(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 984, temp.u32);
	// fmuls f4,f1,f25
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f4,1008(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1008, temp.u32);
	// fmuls f4,f13,f22
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// stfs f4,1024(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1024, temp.u32);
	// fmuls f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// stfs f13,992(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 992, temp.u32);
	// lfs f13,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// stfs f13,188(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f13,f7,f26
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f13,928(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 928, temp.u32);
	// fmuls f13,f7,f27
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f13,920(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 920, temp.u32);
	// fmuls f13,f6,f26
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// stfs f13,976(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 976, temp.u32);
	// fmuls f13,f6,f27
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// stfs f13,896(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 896, temp.u32);
	// fmuls f13,f5,f14
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// stfs f13,912(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 912, temp.u32);
	// fmuls f13,f5,f8
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// stfs f13,904(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 904, temp.u32);
	// lfs f13,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// stfs f13,1036(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1036, temp.u32);
	// fmuls f13,f10,f28
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// stfs f13,1164(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1164, temp.u32);
	// lfs f13,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,880(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 880, temp.u32);
	// lfs f13,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,1000(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1000, temp.u32);
	// lfs f13,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,872(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 872, temp.u32);
	// lfs f13,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,888(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 888, temp.u32);
	// fmuls f13,f29,f20
	ctx.f13.f64 = double(float(ctx.f29.f64 * ctx.f20.f64));
	// stfs f13,1028(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1028, temp.u32);
	// fmuls f13,f14,f20
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f20.f64));
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// stfs f13,952(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 952, temp.u32);
	// fmuls f13,f8,f20
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f20.f64));
	// stfs f13,1016(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1016, temp.u32);
	// fmuls f13,f22,f20
	ctx.f13.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// stfs f13,960(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 960, temp.u32);
	// lfs f13,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f10,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f10.f64 = double(temp.f32);
	// lis r30,-32239
	ctx.r30.s64 = -2112815104;
	// lfs f22,31072(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 31072);
	ctx.f22.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f8,1048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1048);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,1212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1212);
	ctx.f2.f64 = double(temp.f32);
	// lfs f29,-18584(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -18584);
	ctx.f29.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f5,f13,f29
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// lfs f20,1188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1188);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f14,1180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1180);
	ctx.f14.f64 = double(temp.f32);
	// stfs f22,640(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 640, temp.u32);
	// lfs f13,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f9,f10,f13
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// stfs f9,228(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stfs f13,128(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f10,-384(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -384);
	ctx.f10.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// stfs f8,672(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 672, temp.u32);
	// lfs f8,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f8.f64 = double(temp.f32);
	// fadds f4,f8,f7
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f7.f64));
	// stfs f10,184(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmuls f8,f6,f28
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f3,f8,f0
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// stfs f8,100(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f7,-12288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -12288);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f7,140(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f7,1204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1204);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f5,f7,f22,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f22.f64 + ctx.f5.f64));
	// lfs f7,1196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1196);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f1,f7,f0
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f7,f27,f19
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmadds f2,f14,f29,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f29.f64 + ctx.f2.f64));
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmadds f4,f4,f8,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f3.f64));
	// lfs f8,1172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1172);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f5,f8,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f8.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// fmuls f7,f7,f12
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f8,f26,f19
	ctx.f8.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f3,f1,f13
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f1,1624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1624);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f4,f20,f13,f4
	ctx.f4.f64 = double(float(-(ctx.f20.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// lfs f20,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f11,f20,f11
	ctx.f11.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f20,1616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1616);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// lfs f10,-392(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -392);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f2,f20,f22,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 - ctx.f2.f64));
	// fmuls f20,f14,f25
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f14,1608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1608);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f10,f27,f23
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fnmsubs f5,f14,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f14.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// lfs f14,1600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1600);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f0
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// lfs f0,1592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1592);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f9,f0,f13,f9
	ctx.f9.f64 = double(float(-(ctx.f0.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f8,f8,f0,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f7.f64));
	// fmuls f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f0,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f6,f6,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmuls f7,f0,f12
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f13,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,-388(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -388);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f0,f13,f0,f12
	ctx.f0.f64 = double(float(-(ctx.f13.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmr f0,f12
	ctx.f0.f64 = ctx.f12.f64;
	// lfs f13,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f13,f0,f1
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f1.f64));
	// lfs f13,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f4,f11,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f11.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmuls f0,f15,f16
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// fmsubs f11,f9,f13,f3
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 - ctx.f3.f64));
	// fmuls f9,f12,f0
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f12,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f12,f23
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fmadds f3,f0,f22,f2
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f22.f64 + ctx.f2.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f20,f0
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f0,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f20,f0,f13
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f12,f19
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f19.f64));
	// lfs f12,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f0,f13,f5
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f13,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,4288(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4288, temp.u32);
	// fnmsubs f0,f14,f13,f11
	ctx.f0.f64 = double(float(-(ctx.f14.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// stfs f0,4292(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4292, temp.u32);
	// lfs f0,-392(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -392);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f7,f0,f8
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f8.f64));
	// stfs f0,4296(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4296, temp.u32);
	// fmuls f0,f15,f16
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// lfs f8,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f7,f6,f13,f2
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 - ctx.f2.f64));
	// fmuls f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f5,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f6,f20,f23
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// fmuls f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfs f0,4300(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4300, temp.u32);
	// lfs f0,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f0,f1,f0,f10
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 - ctx.f10.f64));
	// lfs f11,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f11.f64 = double(temp.f32);
	// stfs f0,4304(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4304, temp.u32);
	// fnmsubs f0,f9,f11,f4
	ctx.f0.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f4.f64)));
	// stfs f0,4308(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4308, temp.u32);
	// lfs f0,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f0,f0,f22,f3
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f22.f64 - ctx.f3.f64)));
	// stfs f0,4312(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4312, temp.u32);
	// fmuls f0,f10,f12
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f9,f0,f31
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// stfs f9,136(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f9,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f4,f9,f30,f8
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f8.f64));
	// lfs f9,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f9,f18
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// lfs f9,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f5,f9,f30,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f5.f64));
	// lfs f8,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f28,f19
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f2,f8,f12
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f9,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f20,f9,f31
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f9,f28,f23
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f14,f9,f0
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f9,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f9,f30,f4
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64 + ctx.f4.f64));
	// fmuls f4,f2,f25
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f2,f28,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64 + ctx.f9.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f9,f28,f18
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lis r6,-32239
	ctx.r6.s64 = -2112815104;
	// fmadds f8,f8,f31,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f31.f64 + ctx.f5.f64));
	// lfs f5,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f5,f19,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64 + ctx.f3.f64));
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f3,f1,f31
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f20,f20,f30
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f30.f64));
	// fnmsubs f7,f6,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fmuls f14,f14,f31
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f31.f64));
	// fmadds f10,f10,f31,f2
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64 + ctx.f2.f64));
	// fmuls f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f9,f28,f25
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f12,f5,f12
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f5,f4,f13
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f2,f20,f28
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f28.f64));
	// fmuls f4,f1,f30
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f8,f0,f28,f8
	ctx.f8.f64 = double(float(-(ctx.f0.f64 * ctx.f28.f64 - ctx.f8.f64)));
	// lfs f0,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f12,f12,f13,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f5.f64));
	// lfs f13,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f0,f25
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f20,f0,f18
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f18.f64));
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f5,f13,f17
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fnmsubs f8,f1,f30,f8
	ctx.f8.f64 = double(float(-(ctx.f1.f64 * ctx.f30.f64 - ctx.f8.f64)));
	// lfs f1,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f13,f1
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// lfs f13,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,208(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f13,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f19
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// fmuls f11,f0,f11
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f13,f6,f0,f7
	ctx.f13.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// stfs f13,4316(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4316, temp.u32);
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f20,f0,f12
	ctx.f0.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f12.f64));
	// fmadds f13,f13,f31,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64 + ctx.f10.f64));
	// stfs f13,4320(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4320, temp.u32);
	// lfs f13,-396(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -396);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,864(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 864, temp.u32);
	// fmuls f13,f2,f13
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// stfs f13,4328(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4328, temp.u32);
	// lfs f13,16(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f5,f13
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f1,f13
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f0,4340(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4340, temp.u32);
	// lfs f0,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f10,f10,f31,f8
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f31.f64 - ctx.f8.f64)));
	// lfs f12,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f12.f64 = double(temp.f32);
	// stfs f10,4336(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4336, temp.u32);
	// fmuls f10,f0,f12
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// stfs f10,392(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f5,f8,f0,f11
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f11.f64));
	// lfs f11,12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fmsubs f8,f3,f11,f7
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmsubs f11,f14,f11,f6
	ctx.f11.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f6.f64));
	// fnmsubs f8,f4,f13,f8
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// stfs f8,4324(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4324, temp.u32);
	// fnmsubs f13,f9,f13,f11
	ctx.f13.f64 = double(float(-(ctx.f9.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// stfs f13,4332(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4332, temp.u32);
	// lfs f13,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// stfs f11,876(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 876, temp.u32);
	// lfs f11,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// lfs f4,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f8,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f8,f25
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f3,f13,f8
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lis r7,-32239
	ctx.r7.s64 = -2112815104;
	// fmuls f20,f13,f20
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f20.f64));
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f9,568(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// fmuls f7,f12,f11
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f11,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// fmuls f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64));
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmuls f11,f27,f19
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmadds f9,f6,f9,f4
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f4.f64));
	// lfs f4,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f11,f22
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f22.f64));
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f7,f11
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// stfs f11,176(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f11,f31,f30
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lfs f6,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// fmuls f4,f10,f19
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f8,-13884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -13884);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f8,432(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// fmsubs f7,f5,f12,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 - ctx.f7.f64));
	// fmuls f1,f11,f25
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// fmsubs f5,f24,f19,f2
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f19.f64 - ctx.f2.f64));
	// fmuls f2,f11,f18
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// lfs f11,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f14,f11,f24
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f24.f64));
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmadds f9,f9,f12,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 + ctx.f7.f64));
	// fmsubs f8,f1,f8,f6
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 - ctx.f6.f64));
	// lfs f6,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// lfs f13,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f11,f13
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f13,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// fnmsubs f9,f4,f0,f9
	ctx.f9.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f28
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fadds f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// lfs f13,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f5,f2,f13,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f13,1584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1584);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f14,f13
	ctx.f4.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f13,f27,f23
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fnmsubs f8,f13,f22,f8
	ctx.f8.f64 = double(float(-(ctx.f13.f64 * ctx.f22.f64 - ctx.f8.f64)));
	// lfs f13,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f13,f30
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f9,f7,f13,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f9.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// fmuls f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,-4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f14,f11,f13,f14
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f14.f64));
	// lfs f13,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f11,f3,f31,f2
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f31.f64 + ctx.f2.f64));
	// lfs f3,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f5,f13,f21,f5
	ctx.f5.f64 = double(float(-(ctx.f13.f64 * ctx.f21.f64 - ctx.f5.f64)));
	// lfs f2,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f2.f64 = double(temp.f32);
	// lfs f13,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f3,f13,f2,f3
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f3.f64));
	// lfs f13,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f24,f23,f8
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f23.f64 + ctx.f8.f64));
	// fmuls f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f6,f6,f13,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f1.f64));
	// lfs f1,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f2.f64 = double(temp.f32);
	// lis r8,-32239
	ctx.r8.s64 = -2112815104;
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f1,f11,f13
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f11,f7,f11,f9
	ctx.f11.f64 = double(float(-(ctx.f7.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// stfs f11,4344(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4344, temp.u32);
	// fmuls f11,f26,f19
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f9,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f9.f64 = double(temp.f32);
	// lis r5,-32239
	ctx.r5.s64 = -2112815104;
	// fnmsubs f11,f11,f9,f5
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f9.f64 - ctx.f5.f64)));
	// lfs f9,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f9.f64 = double(temp.f32);
	// stfs f11,4352(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4352, temp.u32);
	// fmsubs f11,f3,f9,f4
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 - ctx.f4.f64));
	// stfs f11,4356(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4356, temp.u32);
	// lfs f11,1576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1576);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f9
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// stfs f11,256(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f11,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f11,f9
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f3,f7,f30
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// lfs f7,-8(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -8);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f11,f11,f21,f8
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f21.f64 - ctx.f8.f64)));
	// stfs f11,4360(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4360, temp.u32);
	// lfs f11,-4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f11.f64 = double(temp.f32);
	// fmsubs f11,f10,f11,f1
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f1.f64));
	// lfs f10,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f4,f2,f8,f6
	ctx.f4.f64 = double(float(-(ctx.f2.f64 * ctx.f8.f64 - ctx.f6.f64)));
	// lfs f6,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f6.f64 = double(temp.f32);
	// stfs f7,136(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fnmsubs f11,f20,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f20.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// lfs f20,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f7,f3,f7,f4
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fmadds f11,f14,f10,f11
	ctx.f11.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f11.f64));
	// stfs f11,4348(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4348, temp.u32);
	// lfs f11,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f11,f18
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// lfs f11,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f6,f11
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f9,f6
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfs f9,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f9,f20,f25
	ctx.f9.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// lfs f6,-12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -12);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f11,f15
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// lfs f20,-16(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -16);
	ctx.f20.f64 = double(temp.f32);
	// stfs f20,344(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fnmsubs f6,f14,f6,f7
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f6.f64 - ctx.f7.f64)));
	// lfs f7,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f9,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// lfs f9,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f2,f9
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f9,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f1,f9
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fmuls f9,f15,f18
	ctx.f9.f64 = double(float(ctx.f15.f64 * ctx.f18.f64));
	// fmadds f5,f5,f20,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f20.f64 + ctx.f3.f64));
	// fmuls f2,f9,f11
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f9,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// fmuls f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f9,f7,f23
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f3,f2,f7
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmsubs f4,f9,f8,f4
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 - ctx.f4.f64));
	// lfs f9,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fnmsubs f6,f1,f13,f6
	ctx.f6.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f2,f10,f9
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f9,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f14,f8
	ctx.f8.f64 = double(float(ctx.f14.f64 * ctx.f8.f64));
	// fnmsubs f5,f3,f20,f5
	ctx.f5.f64 = double(float(-(ctx.f3.f64 * ctx.f20.f64 - ctx.f5.f64)));
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// fmadds f4,f13,f9,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 + ctx.f4.f64));
	// lfs f13,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// lfs f9,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f8,f4,f12,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 - ctx.f8.f64));
	// fmuls f1,f13,f9
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fmuls f9,f11,f15
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// fmadds f7,f7,f0,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f1.f64));
	// fmuls f9,f13,f9
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f13,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f3,f13,f30
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f13,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f14,f13,f11
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f13,-4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f6,f2,f13,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f6.f64));
	// lfs f13,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f13,f15
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// lfs f13,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f7,f12,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f8.f64));
	// fmadds f5,f9,f20,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f20.f64 + ctx.f5.f64));
	// lfs f9,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f9,f13
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f9,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f4,f4,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f1,f9,f13
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f9,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f9,f10,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f6,f3,f10,f6
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f10.f64 - ctx.f6.f64)));
	// lfs f10,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f10,f23
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f23.f64));
	// lfs f10,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f5,f14,f10,f5
	ctx.f5.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// lfs f14,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f10
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// lfs f10,-4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f6,f9,f10,f6
	ctx.f6.f64 = double(float(-(ctx.f9.f64 * ctx.f10.f64 - ctx.f6.f64)));
	// lfs f9,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f8,f3,f0,f8
	ctx.f8.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// fmuls f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f9,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f9,f23
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// fmuls f3,f10,f12
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f12,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f7,f7,f12,f5
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f5,f4,f12,f14
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f14.f64));
	// fmsubs f4,f2,f10,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 - ctx.f1.f64));
	// lfs f10,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f2,f10,f13
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,-12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -12);
	ctx.f10.f64 = double(temp.f32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f10,f1,f10,f6
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f6.f64));
	// stfs f10,4364(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4364, temp.u32);
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f6,f10,f13
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f10,f3,f10,f8
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f10.f64 - ctx.f8.f64)));
	// stfs f10,4368(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4368, temp.u32);
	// fmadds f10,f5,f11,f7
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f7.f64));
	// stfs f10,4372(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4372, temp.u32);
	// lfs f10,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f2,f0,f4
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f14,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fmuls f8,f10,f12
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,1568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1568);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f11
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f10,f11
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f12,f9,f31
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f4,f4,f24
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// fmuls f2,f10,f13
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f9,f12,f13
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// lfs f12,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmadds f1,f10,f0,f8
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f8.f64));
	// lfs f10,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f8,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f1,f12,f0,f1
	ctx.f1.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f6,f12,f13
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f12,f8
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f12,-392(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -392);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,384(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f12,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f12.f64 = double(temp.f32);
	// fadds f14,f12,f14
	ctx.f14.f64 = double(float(ctx.f12.f64 + ctx.f14.f64));
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f12,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f3,f10,f12,f3
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfs f12,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f10,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f10.f64 = double(temp.f32);
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f12,f10,f28
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmsubs f11,f1,f13,f5
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 - ctx.f5.f64));
	// lfs f10,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f12,f13
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmadds f1,f10,f31,f12
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f31.f64 + ctx.f12.f64));
	// lfs f12,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f10,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f6,f12,f13
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,-392(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -392);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f8,f8,f12,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 - ctx.f4.f64));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f2,f2,f12,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fmuls f12,f27,f31
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f11,f26,f31
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f4,f14,f10
	ctx.f4.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// fadds f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f3,f14,f12,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f12,f31,f30
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f12,f12,f23
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fmuls f14,f12,f14
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f14.f64));
	// lfs f12,1560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1560);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f12,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f12,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f6,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f13,f6,f30
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f6,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f6.f64 = double(temp.f32);
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f24
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f24.f64));
	// fnmsubs f9,f9,f12,f2
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// fmuls f2,f11,f29
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// fmuls f6,f13,f6
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// lfs f13,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f4,f13,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f8.f64));
	// lfs f4,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f13,f31,f30
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fnmsubs f9,f5,f0,f9
	ctx.f9.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// stfs f7,4376(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4376, temp.u32);
	// fmuls f13,f13,f19
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// fmadds f9,f1,f0,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f1,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f13,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// lfs f13,-392(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -392);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f5,f14,f13,f3
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f3.f64));
	// lfs f14,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f8,f4,f13,f8
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f8.f64));
	// stfs f8,4380(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4380, temp.u32);
	// fnmsubs f13,f10,f13,f5
	ctx.f13.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// stfs f13,4388(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4388, temp.u32);
	// lfs f10,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f8,f24,f31,f2
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f31.f64 - ctx.f2.f64));
	// lfs f13,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f10,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// stfs f8,4384(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4384, temp.u32);
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f3,f11,f31
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmuls f11,f15,f25
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f25.f64));
	// fmuls f11,f11,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f14.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f15
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// fmuls f8,f11,f10
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// fmuls f11,f14,f25
	ctx.f11.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// fnmsubs f10,f3,f0,f9
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// stfs f10,4392(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4392, temp.u32);
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f10,f11,f12,f13
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfs f13,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f13,f17
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// lfs f13,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f13,f28
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f5,f13,f9
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f13,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f13,f17
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f28
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f13,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f7,f5,f12,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f7.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f3,f11,f13
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f13,f11
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f11,1164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1164);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// stfs f11,248(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f11,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f10,f11
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,188(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f10,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f10,f11
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// fmsubs f8,f8,f20,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f20.f64 - ctx.f1.f64));
	// fmuls f9,f10,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f25
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fmsubs f6,f3,f12,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f6.f64));
	// lfs f3,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f3.f64 = double(temp.f32);
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f5,f2,f31
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fmuls f10,f3,f30
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f11,f11,f15
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// stfs f11,136(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// fmuls f12,f28,f18
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// fmuls f3,f12,f31
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f12,f26,f17
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// fmuls f2,f12,f22
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f22.f64));
	// lfs f12,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f18
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// fmuls f11,f12,f11
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f12,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f1,f14,f12,f8
	ctx.f1.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f12,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f8.f64 = double(temp.f32);
	// fadds f14,f12,f8
	ctx.f14.f64 = double(float(ctx.f12.f64 + ctx.f8.f64));
	// lfs f12,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f7,f9,f12,f7
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f7.f64));
	// lfs f12,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// lfs f9,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f4,f8,f9,f4
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f4.f64));
	// lfs f8,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f6,f5,f8,f6
	ctx.f6.f64 = double(float(-(ctx.f5.f64 * ctx.f8.f64 - ctx.f6.f64)));
	// lfs f9,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmsubs f3,f3,f9,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 - ctx.f2.f64));
	// lfs f9,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f2,f11,f20,f1
	ctx.f2.f64 = double(float(-(ctx.f11.f64 * ctx.f20.f64 - ctx.f1.f64)));
	// lfs f11,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f14,f11
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f11.f64));
	// lfs f11,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f11
	ctx.f10.f64 = ctx.f11.f64;
	// lfs f11,-4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f14,f12,f9,f7
	ctx.f14.f64 = double(float(-(ctx.f12.f64 * ctx.f9.f64 - ctx.f7.f64)));
	// lfs f12,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// fmadds f6,f5,f11,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f6.f64));
	// fmadds f2,f1,f9,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f2.f64));
	// lfs f9,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f18
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// lfs f1,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f4,f12,f10,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 + ctx.f4.f64));
	// fmuls f12,f28,f19
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f1,f9,f1
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fnmsubs f3,f12,f21,f3
	ctx.f3.f64 = double(float(-(ctx.f12.f64 * ctx.f21.f64 - ctx.f3.f64)));
	// lfs f12,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f7,f31
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfs f7,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f12
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f7,80(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmr f7,f9
	ctx.f7.f64 = ctx.f9.f64;
	// lfs f9,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f17
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// fnmsubs f8,f5,f8,f6
	ctx.f8.f64 = double(float(-(ctx.f5.f64 * ctx.f8.f64 - ctx.f6.f64)));
	// lfs f5,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f4,f4,f7,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 + ctx.f14.f64));
	// fmuls f7,f9,f7
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f9,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f6,f9,f13
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f9,f27,f17
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// fnmsubs f9,f9,f5,f3
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// fnmsubs f3,f1,f20,f2
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f20.f64 - ctx.f2.f64)));
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f24
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// fmadds f11,f6,f11,f8
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f11.f64 + ctx.f8.f64));
	// stfs f11,4404(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4404, temp.u32);
	// fmadds f11,f24,f17,f9
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 + ctx.f9.f64));
	// stfs f11,4408(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4408, temp.u32);
	// lfs f11,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f7,f7,f10,f4
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f9,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f11,f9,f8
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f8.f64));
	// lfs f11,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f11.f64 = double(temp.f32);
	// stfs f7,4400(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4400, temp.u32);
	// fmuls f7,f5,f11
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f11,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f11,f12
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f5,f11,f13
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f11,f28
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f11,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f11.f64 = double(temp.f32);
	// stfs f3,4396(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4396, temp.u32);
	// fmuls f3,f11,f12
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f9,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f9.f64 = double(temp.f32);
	// lfs f11,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f11,f9
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f0,-8(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -8);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f11,f13
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,-12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -12);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f11,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// fmadds f6,f4,f0,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fmuls f0,f28,f23
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f11,f11,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f14.f64));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f9,f14,f9
	ctx.f9.f64 = double(float(ctx.f14.f64 * ctx.f9.f64));
	// lfs f14,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f10,f14,f10
	ctx.f10.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// lfs f14,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f4,f0,f21
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f21.f64));
	// lfs f0,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f0,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f0,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f14.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f14,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f11,f11,f14,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f14.f64 - ctx.f2.f64));
	// lfs f2,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f2.f64 = double(temp.f32);
	// lfs f0,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f10,f9,f2,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f2.f64 + ctx.f10.f64));
	// fmsubs f9,f5,f0,f6
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f6.f64));
	// stfs f0,188(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f0,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f0.f64 = double(temp.f32);
	// lfs f6,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f0,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f14,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f14.f64 = double(temp.f32);
	// lfs f0,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f5,f24,f14,f4
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f14.f64 - ctx.f4.f64));
	// fmuls f4,f0,f28
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fnmsubs f9,f3,f0,f9
	ctx.f9.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// lfs f3,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f2,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f11,f2,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfs f0,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f10,f2,f0,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f0,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f0,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f0,f26,f14
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// fnmsubs f5,f0,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f0.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// lfs f0,-4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f9,f1,f0,f9
	ctx.f9.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f0,-8(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -8);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f4,f4,f0,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f3.f64));
	// lfs f0,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f11,f10,f0,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f11.f64));
	// lfs f3,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f6,f2,f0,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f6.f64));
	// lfs f0,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f0.f64 = double(temp.f32);
	// lfs f2,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f0,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// lfs f0,-12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -12);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f12,f12,f0,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f9,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f0,f27,f14
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// fmuls f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// fnmsubs f9,f0,f9,f5
	ctx.f9.f64 = double(float(-(ctx.f0.f64 * ctx.f9.f64 - ctx.f5.f64)));
	// fmuls f0,f28,f25
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f5,f0,f31
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// lfs f0,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f11,f10,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfs f10,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f10.f64 = double(temp.f32);
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fnmsubs f13,f13,f10,f12
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f10.f64 - ctx.f12.f64)));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmadds f6,f2,f0,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f10,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fmr f13,f10
	ctx.f13.f64 = ctx.f10.f64;
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// fmuls f2,f12,f13
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f10,f8,f12,f7
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 - ctx.f7.f64));
	// stfs f10,4412(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4412, temp.u32);
	// lfs f10,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f10,f5,f10,f9
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f9.f64));
	// stfs f10,4416(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4416, temp.u32);
	// lfs f10,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// fmr f11,f10
	ctx.f11.f64 = ctx.f10.f64;
	// fmuls f10,f11,f25
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// fmuls f8,f10,f13
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f10,f3,f10,f9
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f10.f64 - ctx.f9.f64)));
	// lfs f9,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f12,f4,f12,f9
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f9.f64));
	// stfs f10,4424(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4424, temp.u32);
	// lfs f10,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f7,f2,f10,f6
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f10,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f12,f1,f10,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,4420(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4420, temp.u32);
	// fmuls f12,f9,f31
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f6,f12,f21
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// lfs f12,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f5,f12,f0
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f12,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fadds f4,f10,f12
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// lfs f10,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f10,f12
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmsubs f6,f10,f21,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f21.f64 - ctx.f6.f64));
	// fmuls f10,f11,f18
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// fmuls f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f13,f9,f17
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f1,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fmuls f9,f13,f22
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// lfs f13,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f5,f13,f0,f5
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fmuls f13,f11,f31
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f11,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fadds f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f13.f64));
	// lfs f13,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f13,f12
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f13,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// lfs f12,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f5,f12,f0,f5
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f5.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f0,f12,f31
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fnmsubs f6,f13,f21,f6
	ctx.f6.f64 = double(float(-(ctx.f13.f64 * ctx.f21.f64 - ctx.f6.f64)));
	// lfs f13,5568(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 5568);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,188(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f13,16(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmadds f6,f0,f21,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f21.f64 + ctx.f6.f64));
	// fmuls f0,f12,f17
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// fmsubs f12,f0,f22,f9
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f22.f64 - ctx.f9.f64));
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// fsubs f9,f4,f0
	ctx.f9.f64 = double(float(ctx.f4.f64 - ctx.f0.f64));
	// lfs f0,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f4,f2,f0,f3
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f3.f64));
	// lfs f0,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f0.f64 = double(temp.f32);
	// lfs f3,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f0,f3
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// lfs f2,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f0,f27,f31
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f2,f0,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// lfs f0,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// fsubs f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f0.f64));
	// fmuls f0,f31,f30
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// stfs f0,388(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fmuls f0,f0,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmsubs f11,f0,f13,f11
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - ctx.f11.f64));
	// lfs f0,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f0,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f10,f5,f0,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f5,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fnmsubs f13,f3,f13,f4
	ctx.f13.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// fnmsubs f12,f0,f29,f12
	ctx.f12.f64 = double(float(-(ctx.f0.f64 * ctx.f29.f64 - ctx.f12.f64)));
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fsubs f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f0.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f7,f8,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f8,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f8
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f8,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f8.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f8,f30
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// lfs f8,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// lfs f0,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmuls f4,f0,f8
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f8,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f0,f26,f31
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f3,f0,f8
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f0,-392(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -392);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,384(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f0,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f0.f64 = double(temp.f32);
	// addi r6,r31,36
	ctx.r6.s64 = ctx.r31.s64 + 36;
	// fmsubs f1,f11,f0,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f1.f64));
	// lfs f11,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f0.f64 = double(temp.f32);
	// addi r5,r29,36
	ctx.r5.s64 = ctx.r29.s64 + 36;
	// fmuls f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f11,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f11.f64 = double(temp.f32);
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f0,f11,f30
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f11,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f11.f64 = double(temp.f32);
	// addi r4,r1,4288
	ctx.r4.s64 = ctx.r1.s64 + 4288;
	// lfs f8,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f8.f64 = double(temp.f32);
	// li r3,7
	ctx.r3.s64 = 7;
	// fadds f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f10,f5,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f18
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f18.f64));
	// fmuls f5,f0,f11
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f0,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f17
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// lfs f11,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f0,f0,f22,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f22.f64 + ctx.f12.f64));
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f12,f12,f8,f7
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f8.f64 - ctx.f7.f64)));
	// stfs f12,4428(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4428, temp.u32);
	// lfs f12,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f12,f30
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f0,f9,f0
	ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// stfs f0,4432(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4432, temp.u32);
	// lfs f0,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f4,f0,f13
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f13.f64));
	// stfs f0,4436(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4436, temp.u32);
	// fmsubs f0,f3,f11,f2
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f2.f64));
	// stfs f0,4440(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4440, temp.u32);
	// lfs f13,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f13,f0,f1
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f1.f64));
	// stfs f0,4444(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4444, temp.u32);
	// lfs f0,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f13,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// lfs f9,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fadds f0,f6,f0
	ctx.f0.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// stfs f0,4448(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4448, temp.u32);
	// fnmsubs f0,f5,f12,f10
	ctx.f0.f64 = double(float(-(ctx.f5.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// stfs f0,4452(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4452, temp.u32);
	// lfs f0,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f17
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// lfs f10,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f0,f0,f13,f10
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// stfs f0,4456(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4456, temp.u32);
	// fmuls f0,f15,f16
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f13,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f13,f0
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f13,f30
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f13,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmuls f6,f10,f13
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f10,f0
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f22
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f22.f64));
	// lfs f10,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fadds f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfs f10,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f3,f10,f13
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f10,f28,f23
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// stfs f10,436(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f7,f10,f11
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f10,f0
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f4,f10,f22,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f22.f64 - ctx.f4.f64));
	// fmuls f10,f28,f19
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// stfs f10,656(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 656, temp.u32);
	// fmadds f8,f6,f12,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f8.f64));
	// fmuls f6,f3,f12
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fmuls f9,f9,f13
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmsubs f9,f9,f12,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f6.f64));
	// lfs f12,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f3,f10,f11
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f11,f27,f17
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// fmuls f6,f12,f13
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f12,f26,f17
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// fmuls f1,f11,f10
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f11,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f27,f14
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// fmadds f10,f10,f11,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f7.f64));
	// lfs f7,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f8,f5,f7,f8
	ctx.f8.f64 = double(float(-(ctx.f5.f64 * ctx.f7.f64 - ctx.f8.f64)));
	// lfs f5,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f5,f5,f22,f4
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f22.f64 - ctx.f4.f64)));
	// lfs f7,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f4,f12,f11,f3
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 - ctx.f3.f64));
	// lfs f12,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f1,f11
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f11,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fnmsubs f8,f2,f12,f8
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f12,-388(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -388);
	ctx.f12.f64 = double(temp.f32);
	// lfs f2,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f2,f11,f12,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 - ctx.f2.f64));
	// lfs f11,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f26,f14
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// fmuls f0,f2,f0
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f0,4468(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4468, temp.u32);
	// fmuls f1,f12,f11
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f12,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f10,f13,f10,f5
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 + ctx.f5.f64));
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f7,f13,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f8.f64));
	// lfs f13,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f0,f1,f0,f11
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 - ctx.f11.f64));
	// stfs f0,4472(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4472, temp.u32);
	// fmadds f9,f6,f13,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f9.f64));
	// stfs f9,4460(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4460, temp.u32);
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f9,f4,f9,f3
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f9.f64 - ctx.f3.f64));
	// stfs f9,4464(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4464, temp.u32);
	// fnmsubs f0,f12,f13,f8
	ctx.f0.f64 = double(float(-(ctx.f12.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// stfs f0,4476(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4476, temp.u32);
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmadds f0,f0,f29,f10
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f29.f64 + ctx.f10.f64));
	// stfs f0,4480(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4480, temp.u32);
	// bl 0x82b31838
	ctx.lr = 0x82B330B4;
	sub_82B31838(ctx, base);
	// cmplwi cr6,r28,4
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 4, ctx.xer);
	// bgt cr6,0x82b330c0
	if (ctx.cr6.gt) goto loc_82B330C0;
	// b 0x82b43b90
	goto loc_82B43B90;
loc_82B330C0:
	// lfs f11,452(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f0,f16,f19
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f19.f64));
	// stfs f0,204(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmuls f0,f11,f14
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f14.f64));
	// lfs f8,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f16,f17
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// stfs f0,180(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f0,f8,f14
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// stfs f0,832(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 832, temp.u32);
	// fmuls f0,f11,f17
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// lfs f10,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f8,f17
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f17.f64));
	// stfs f0,700(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 700, temp.u32);
	// fmuls f0,f10,f28
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// stfs f0,256(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f0,f11,f28
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f15,f16
	ctx.f0.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// stfs f0,164(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f0,f8,f28
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// lfs f9,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f5,f10,f23
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f23.f64));
	// stfs f0,520(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fmuls f0,f9,f28
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// stfs f0,332(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmuls f3,f9,f19
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f19.f64));
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f7,f0,f9
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f6,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f6.f64 = double(temp.f32);
	// stfs f7,708(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 708, temp.u32);
	// fmuls f7,f6,f10
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// stfs f7,1024(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1024, temp.u32);
	// lfs f7,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f7,f30
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f1,136(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f1,f7,f28
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f1,872(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 872, temp.u32);
	// fmuls f1,f11,f30
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f1,716(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 716, temp.u32);
	// fmuls f1,f10,f30
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// stfs f1,724(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 724, temp.u32);
	// fmuls f1,f9,f30
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// stfs f1,384(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f1,f16,f8
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f8.f64));
	// stfs f1,588(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// fmuls f1,f26,f6
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f12,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// stfs f6,228(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f6,f26,f0
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// stfs f6,720(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// fmuls f0,f27,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// stfs f0,828(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 828, temp.u32);
	// lfs f0,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f12,f15
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f15.f64));
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// stfs f0,1120(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1120, temp.u32);
	// fmuls f0,f12,f17
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f0,464(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fmuls f0,f27,f30
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f0,188(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f0,f12,f19
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f19.f64));
	// stfs f0,696(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 696, temp.u32);
	// fmuls f0,f26,f14
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// stfs f0,248(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f0,f12,f14
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f14.f64));
	// lfs f6,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f6.f64 = double(temp.f32);
	// stfs f0,856(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 856, temp.u32);
	// fmuls f0,f12,f23
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f0,1176(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1176, temp.u32);
	// stfs f6,824(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 824, temp.u32);
	// fmuls f0,f27,f7
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// lfs f6,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f6.f64 = double(temp.f32);
	// stfs f2,152(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stfs f4,1164(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1164, temp.u32);
	// stfs f5,896(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 896, temp.u32);
	// stfs f3,1560(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1560, temp.u32);
	// stfs f13,284(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// stfs f1,596(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// stfs f0,1048(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1048, temp.u32);
	// fmuls f0,f6,f27
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// stfs f0,1204(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1204, temp.u32);
	// fmuls f0,f26,f7
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f0,1188(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1188, temp.u32);
	// fmuls f0,f16,f14
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f1,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f8,f30
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// stfs f0,672(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 672, temp.u32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f0,f6,f28
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// stfs f1,928(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 928, temp.u32);
	// stfs f0,1196(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1196, temp.u32);
	// fmuls f0,f16,f23
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f23.f64));
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// stfs f0,364(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f0,f6,f30
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f1,920(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 920, temp.u32);
	// stfs f0,1212(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1212, temp.u32);
	// fmuls f0,f16,f11
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// lfs f1,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f1.f64 = double(temp.f32);
	// stfs f0,692(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 692, temp.u32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f0,f6,f10
	ctx.f0.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// stfs f1,936(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 936, temp.u32);
	// stfs f0,912(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 912, temp.u32);
	// lfs f0,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f0,876(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 876, temp.u32);
	// stfs f1,1032(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1032, temp.u32);
	// fmuls f0,f4,f23
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f1,f16,f5
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f5.f64));
	// stfs f0,868(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 868, temp.u32);
	// stfs f1,1072(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1072, temp.u32);
	// fmuls f0,f5,f17
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// stfs f0,864(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 864, temp.u32);
	// fmuls f1,f16,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// fmuls f0,f3,f14
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f14.f64));
	// stfs f1,1144(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1144, temp.u32);
	// stfs f0,992(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 992, temp.u32);
	// fmuls f1,f9,f14
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// fmuls f0,f16,f3
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// stfs f1,428(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// stfs f0,812(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 812, temp.u32);
	// fmuls f1,f11,f23
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// lfs f0,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f0.f64 = double(temp.f32);
	// stfs f1,1052(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1052, temp.u32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// fmuls f1,f11,f25
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// stfs f0,944(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 944, temp.u32);
	// stfs f1,392(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmuls f1,f10,f25
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f0,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f0.f64 = double(temp.f32);
	// stfs f1,532(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// fmuls f0,f0,f23
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmuls f1,f11,f19
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// stfs f0,748(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 748, temp.u32);
	// stfs f1,728(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 728, temp.u32);
	// fmuls f0,f16,f4
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// fmuls f1,f9,f18
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// stfs f0,844(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 844, temp.u32);
	// stfs f1,264(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f0,f13,f19
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// fmuls f1,f11,f18
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// stfs f0,308(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// stfs f1,380(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fmuls f0,f13,f17
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// fmuls f1,f8,f19
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// stfs f0,604(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// stfs f1,816(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 816, temp.u32);
	// fmuls f1,f8,f18
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f18.f64));
	// lfs f0,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f0.f64 = double(temp.f32);
	// stfs f1,668(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 668, temp.u32);
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f1,f10,f19
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// stfs f0,224(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stfs f1,600(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// stfs f6,968(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 968, temp.u32);
	// lfs f6,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f10,f18
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f18.f64));
	// fmuls f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f6,976(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 976, temp.u32);
	// fmuls f6,f4,f19
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// stfs f6,1000(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1000, temp.u32);
	// fmuls f6,f5,f14
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// stfs f6,880(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 880, temp.u32);
	// stfs f1,220(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f1,f8,f25
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f6,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f6,888(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 888, temp.u32);
	// fmuls f6,f3,f17
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// stfs f6,960(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 960, temp.u32);
	// fmuls f6,f16,f18
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f18.f64));
	// stfs f6,172(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// stfs f1,252(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmuls f6,f16,f9
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fmuls f1,f8,f23
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f23.f64));
	// stfs f6,1080(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1080, temp.u32);
	// stfs f1,1008(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1008, temp.u32);
	// fmuls f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f1,f9,f23
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// stfs f6,1416(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1416, temp.u32);
	// stfs f1,1044(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1044, temp.u32);
	// fmuls f1,f9,f25
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// lfs f6,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f6.f64 = double(temp.f32);
	// stfs f1,524(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// fmuls f1,f6,f18
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// stfs f1,1400(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1400, temp.u32);
	// fmuls f1,f6,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// stfs f6,1324(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1324, temp.u32);
	// lfs f6,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f6,904(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 904, temp.u32);
	// lfs f6,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1500(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1500, temp.u32);
	// lfs f6,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1028(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1028, temp.u32);
	// lfs f6,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,1440(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1440, temp.u32);
	// lfs f6,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,952(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 952, temp.u32);
	// lfs f6,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1036(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1036, temp.u32);
	// lfs f6,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,1432(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1432, temp.u32);
	// lfs f6,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1016(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1016, temp.u32);
	// stfs f1,1360(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1360, temp.u32);
	// fmuls f1,f13,f14
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f14.f64));
	// stfs f1,336(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lfs f6,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,1424(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1424, temp.u32);
	// lfs f6,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f6,f26
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// stfs f1,1180(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1180, temp.u32);
	// fmuls f1,f26,f18
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1352(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1352, temp.u32);
	// fmuls f1,f27,f31
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f1,1376(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1376, temp.u32);
	// fmuls f1,f26,f19
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1384(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1384, temp.u32);
	// fmuls f1,f26,f25
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1408(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1408, temp.u32);
	// fmuls f1,f27,f23
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1616(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1616, temp.u32);
	// lfs f7,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1392(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1392, temp.u32);
	// fmuls f1,f26,f23
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1368(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1368, temp.u32);
	// fmuls f1,f5,f31
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f1,1340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1340, temp.u32);
	// lfs f1,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1596(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1596, temp.u32);
	// lfs f1,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1508(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1508, temp.u32);
	// lfs f1,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1612(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1612, temp.u32);
	// lfs f1,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1692(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1692, temp.u32);
	// lfs f1,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1516(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1516, temp.u32);
	// lfs f1,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1344(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1344, temp.u32);
	// fmuls f1,f30,f28
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,840(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 840, temp.u32);
	// fmuls f1,f31,f18
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f18.f64));
	// stfs f1,480(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f1,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f18
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// stfs f1,504(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fmuls f1,f13,f18
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// stfs f1,1088(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1088, temp.u32);
	// fmuls f1,f12,f16
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f16.f64));
	// stfs f1,232(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f1,f15,f4
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// stfs f1,1492(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1492, temp.u32);
	// fmuls f1,f15,f3
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// stfs f1,1484(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1484, temp.u32);
	// fmuls f1,f9,f17
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// stfs f1,1128(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1128, temp.u32);
	// fmuls f1,f10,f17
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// stfs f1,820(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 820, temp.u32);
	// fmuls f1,f12,f28
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f1,984(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 984, temp.u32);
	// fmuls f1,f16,f25
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// stfs f1,460(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fmuls f1,f10,f14
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f14.f64));
	// stfs f1,216(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmuls f1,f15,f5
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// stfs f1,1604(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1604, temp.u32);
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// stfs f1,1636(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1636, temp.u32);
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f1,1172(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1172, temp.u32);
	// fmuls f1,f15,f18
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f18.f64));
	// stfs f1,852(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 852, temp.u32);
	// fmuls f1,f15,f19
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// stfs f1,808(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 808, temp.u32);
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f1,1624(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1624, temp.u32);
	// fmuls f1,f7,f28
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f1,1608(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1608, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f1,1600(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1600, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1592(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1592, temp.u32);
	// fmuls f1,f7,f30
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f1,1584(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1584, temp.u32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1576(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1576, temp.u32);
	// fmuls f7,f6,f14
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// stfs f7,1700(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1700, temp.u32);
	// fmuls f7,f30,f25
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f6,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1568(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1568, temp.u32);
	// fmuls f7,f16,f10
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// stfs f7,1436(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1436, temp.u32);
	// fmuls f7,f6,f17
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// stfs f7,1152(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1152, temp.u32);
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f7,f18
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f18.f64));
	// stfs f1,316(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fmuls f1,f7,f17
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f17.f64));
	// stfs f1,1208(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1208, temp.u32);
	// fmuls f1,f6,f23
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f1,1168(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1168, temp.u32);
	// fmuls f1,f7,f14
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f14.f64));
	// stfs f1,516(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// fmuls f1,f6,f14
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// stfs f1,800(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 800, temp.u32);
	// fmuls f1,f6,f25
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// stfs f1,1096(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1096, temp.u32);
	// fmuls f1,f6,f18
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// stfs f1,1676(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1676, temp.u32);
	// fmuls f1,f6,f16
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f16.f64));
	// stfs f1,1444(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1444, temp.u32);
	// fmuls f1,f7,f16
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f16.f64));
	// stfs f1,1572(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1572, temp.u32);
	// fmuls f1,f15,f17
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// stfs f1,804(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 804, temp.u32);
	// lfs f1,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f1,f19
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f16,1184(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1184, temp.u32);
	// fmuls f16,f1,f17
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f16,1588(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1588, temp.u32);
	// lfs f16,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f16,1412(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1412, temp.u32);
	// fmuls f16,f6,f19
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// stfs f6,1200(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1200, temp.u32);
	// fmuls f6,f12,f10
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// stfs f6,1112(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1112, temp.u32);
	// fmuls f6,f12,f11
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// stfs f6,1468(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1468, temp.u32);
	// fmuls f6,f7,f12
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f6,1104(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1104, temp.u32);
	// lfs f6,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f16,1420(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1420, temp.u32);
	// lfs f16,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// stfs f16,1652(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1652, temp.u32);
	// fmuls f16,f7,f19
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f16,1668(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1668, temp.u32);
	// fmuls f16,f12,f18
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// stfs f16,1476(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1476, temp.u32);
	// fmuls f16,f26,f19
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f16,1640(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1640, temp.u32);
	// fmuls f16,f26,f23
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f16,1632(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1632, temp.u32);
	// fmuls f16,f12,f9
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// stfs f16,1160(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1160, temp.u32);
	// fmuls f12,f12,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// stfs f12,1644(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1644, temp.u32);
	// lfs f12,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1548(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1548, temp.u32);
	// lfs f12,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f12,1388(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1388, temp.u32);
	// lfs f16,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f12,f6,f28
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// stfs f12,1556(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1556, temp.u32);
	// fmuls f12,f16,f31
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// stfs f12,1380(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1380, temp.u32);
	// lfs f12,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1396(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1396, temp.u32);
	// lfs f12,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f12,1628(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1628, temp.u32);
	// fmuls f12,f7,f23
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f12,1404(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1404, temp.u32);
	// lfs f12,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1684(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1684, temp.u32);
	// fmuls f12,f15,f8
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// stfs f12,1928(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1928, temp.u32);
	// fmuls f12,f8,f8
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// stfs f12,676(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 676, temp.u32);
	// fmuls f12,f11,f11
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// stfs f12,1136(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1136, temp.u32);
	// fmuls f12,f9,f9
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f9.f64));
	// stfs f12,440(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fmuls f12,f10,f10
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// stfs f12,1064(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1064, temp.u32);
	// fmuls f12,f7,f15
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// stfs f12,1452(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1452, temp.u32);
	// fmuls f12,f15,f9
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// stfs f12,1580(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1580, temp.u32);
	// fmuls f12,f15,f11
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// stfs f12,1460(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1460, temp.u32);
	// fmuls f12,f15,f14
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// stfs f12,1428(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1428, temp.u32);
	// lfs f12,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1372(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1372, temp.u32);
	// lfs f12,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1620(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1620, temp.u32);
	// lfs f12,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1540(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1540, temp.u32);
	// fmuls f12,f4,f31
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// stfs f12,1364(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1364, temp.u32);
	// fmuls f12,f27,f31
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,1660(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1660, temp.u32);
	// fmuls f12,f26,f17
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1488(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1488, temp.u32);
	// fmuls f12,f26,f28
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f10,f12,f18
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// stfs f10,1532(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1532, temp.u32);
	// fmuls f10,f12,f31
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f10,1348(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1348, temp.u32);
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfs f12,1336(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1336, temp.u32);
	// lfs f12,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f27,f14
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,1688(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1688, temp.u32);
	// fmuls f12,f16,f28
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// stfs f12,1696(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1696, temp.u32);
	// lfs f12,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1524(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1524, temp.u32);
	// fmuls f12,f6,f31
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f12,1704(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1704, temp.u32);
	// lfs f12,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,1680(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1680, temp.u32);
	// lfs f12,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,1480(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1480, temp.u32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// stfs f10,1496(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1496, temp.u32);
	// lfs f10,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f12,f3,f23
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// stfs f12,1672(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1672, temp.u32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f12,f5,f19
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// stfs f10,1356(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1356, temp.u32);
	// stfs f12,1664(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1664, temp.u32);
	// lfs f12,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,1656(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1656, temp.u32);
	// fmuls f12,f4,f14
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f14.f64));
	// stfs f12,1648(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1648, temp.u32);
	// lfs f12,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f12.f64 = double(temp.f32);
	// lis r9,-32253
	ctx.r9.s64 = -2113732608;
	// fmuls f9,f12,f28
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f12,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f12,f30
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f12,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f10,f2
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// lfs f10,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f10.f64 = double(temp.f32);
	// lfs f4,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f4.f64 = double(temp.f32);
	// fadds f4,f10,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// lfs f3,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// lfs f16,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f17,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f12,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f14,f12,f13
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmsubs f10,f8,f10,f9
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 - ctx.f9.f64));
	// lfs f8,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f9,f4,f21,f3
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f21.f64 - ctx.f3.f64));
	// lfs f4,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f4,f4,f2,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f3,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmsubs f5,f14,f12,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 - ctx.f5.f64));
	// lfs f14,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f10,f7,f29,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f29.f64 + ctx.f10.f64));
	// lfs f7,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f16
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f16.f64));
	// lfs f16,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f16,f16,f21,f9
	ctx.f16.f64 = double(float(-(ctx.f16.f64 * ctx.f21.f64 - ctx.f9.f64)));
	// lfs f9,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f9,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// lfs f9,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f8,f8,f12,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f5.f64));
	// fmuls f5,f27,f9
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fnmsubs f6,f6,f29,f10
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f29.f64 - ctx.f10.f64)));
	// lfs f10,-10664(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -10664);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f10,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// fnmsubs f1,f10,f29,f16
	ctx.f1.f64 = double(float(-(ctx.f10.f64 * ctx.f29.f64 - ctx.f16.f64)));
	// lfs f10,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f10.f64 = double(temp.f32);
	// lfs f16,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f10,f16
	ctx.f16.f64 = double(float(ctx.f10.f64 + ctx.f16.f64));
	// lfs f10,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f9,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f9.f64 = double(temp.f32);
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f10,-10664(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -10664);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f6,f17,f22,f6
	ctx.f6.f64 = double(float(-(ctx.f17.f64 * ctx.f22.f64 - ctx.f6.f64)));
	// fnmsubs f17,f14,f9,f8
	ctx.f17.f64 = double(float(-(ctx.f14.f64 * ctx.f9.f64 - ctx.f8.f64)));
	// lfs f9,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f14,f9,f13
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f8,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f26,f28
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmsubs f5,f5,f10,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 - ctx.f3.f64));
	// lfs f10,-1968(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -1968);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmadds f1,f16,f29,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f29.f64 + ctx.f1.f64));
	// fmuls f3,f9,f8
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmuls f8,f11,f28
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f16,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f6,f4,f22,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 + ctx.f6.f64));
	// lfs f4,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f7,f5,f0,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f7.f64));
	// lfs f5,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f9,f9,f15
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f15.f64));
	// fmuls f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fnmsubs f6,f2,f22,f6
	ctx.f6.f64 = double(float(-(ctx.f2.f64 * ctx.f22.f64 - ctx.f6.f64)));
	// lfs f2,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f4,f14,f12,f17
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f17.f64)));
	// lfs f17,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f3,1544(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1544, temp.u32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f3,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f11,f3,f11
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// stfs f11,1552(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1552, temp.u32);
	// lfs f11,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fnmsubs f11,f11,f29,f1
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// stfs f11,4288(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4288, temp.u32);
	// lfs f11,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f11.f64 = double(temp.f32);
	// lfs f3,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f0
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f1,1196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1196);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,1204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1204);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f16,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmadds f11,f17,f11,f4
	ctx.f11.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f4.f64));
	// stfs f11,4296(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4296, temp.u32);
	// fnmsubs f11,f5,f10,f7
	ctx.f11.f64 = double(float(-(ctx.f5.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// stfs f11,4300(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4300, temp.u32);
	// fmadds f11,f7,f22,f6
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f22.f64 + ctx.f6.f64));
	// lfs f10,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f10.f64 = double(temp.f32);
	// lfs f17,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f0,f17
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// fnmsubs f11,f8,f22,f11
	ctx.f11.f64 = double(float(-(ctx.f8.f64 * ctx.f22.f64 - ctx.f11.f64)));
	// stfs f11,4292(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4292, temp.u32);
	// lfs f11,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f11,f30
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f11,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f11,f22
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f22.f64));
	// lfs f11,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f11,f28
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f11,1048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1048);
	ctx.f11.f64 = double(temp.f32);
	// fadds f5,f11,f10
	ctx.f5.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// lfs f11,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,1212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1212);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f17,f27
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64));
	// fmuls f4,f10,f11
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// fmadds f7,f1,f29,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f7.f64));
	// lfs f1,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fmuls f5,f5,f13
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmsubs f10,f6,f10,f8
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 - ctx.f8.f64));
	// lfs f6,1188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1188);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f8,f3,f30
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// lfs f3,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f3.f64 = double(temp.f32);
	// fadds f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f3.f64));
	// lfs f3,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// lfs f11,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f14,f11,f29
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// lfs f11,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f7,f7,f11,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f10.f64));
	// lfs f10,-10664(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -10664);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f10,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f15,f11,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// fmuls f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// fmsubs f10,f2,f12,f5
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f5.f64));
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fnmsubs f16,f16,f12,f10
	ctx.f16.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f10,-10664(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -10664);
	ctx.f10.f64 = double(temp.f32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f17,f17,f10,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f8.f64));
	// lfs f5,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f7,f4,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f4.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// fmuls f5,f2,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f8,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f15,f28
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// lfs f4,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f11,f8
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f8,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f11,f26,f28
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmsubs f4,f4,f29,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 - ctx.f14.f64));
	// fmadds f6,f6,f12,f16
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f16.f64));
	// lfs f16,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f7,f1,f22,f7
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// fmuls f1,f8,f11
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f26
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f26.f64));
	// fmuls f8,f28,f23
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fnmsubs f4,f16,f29,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f4.f64)));
	// lfs f16,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f7,f3,f22,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f7.f64));
	// fmuls f3,f2,f21
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// fmuls f14,f11,f13
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f11,-1968(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -1968);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f2,f15,f11,f17
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f17.f64));
	// lfs f17,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// lfs f17,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f15,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f7,f5,f22,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// lfs f5,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f9,f9,f21,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f21.f64 - ctx.f3.f64));
	// stfs f9,4304(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4304, temp.u32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// fmadds f5,f5,f21,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f21.f64 + ctx.f4.f64));
	// fnmsubs f6,f14,f12,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f6.f64)));
	// fnmsubs f9,f1,f11,f2
	ctx.f9.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f2.f64)));
	// stfs f9,4308(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4308, temp.u32);
	// fmadds f9,f17,f12,f6
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f6.f64));
	// stfs f9,4312(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4312, temp.u32);
	// lfs f6,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f6.f64 = double(temp.f32);
	// lfs f9,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f9,f9,f22,f7
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// lfs f7,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f4,f7,f21,f5
	ctx.f4.f64 = double(float(-(ctx.f7.f64 * ctx.f21.f64 - ctx.f5.f64)));
	// lfs f7,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f7.f64 = double(temp.f32);
	// lfs f5,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f9,f16,f22,f9
	ctx.f9.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f9.f64));
	// stfs f9,4316(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4316, temp.u32);
	// fmuls f9,f30,f25
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f3,f9,f7
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f7,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// stfs f7,228(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fadds f2,f5,f6
	ctx.f2.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// lfs f6,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f8
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f17,f5,f9
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f9,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f9.f64 = double(temp.f32);
	// lfs f6,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f9,f6
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfs f8,1440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1440);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f9.f64 = double(temp.f32);
	// fadds f14,f9,f8
	ctx.f14.f64 = double(float(ctx.f9.f64 + ctx.f8.f64));
	// lfs f9,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f9,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f15,f7,f29
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// fmuls f9,f28,f25
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f2,f2,f9,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f1.f64));
	// lfs f7,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f3,f17,f29,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 - ctx.f3.f64));
	// fmuls f1,f9,f7
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f9,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f17,f16,f22,f15
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 - ctx.f15.f64));
	// fadds f16,f14,f9
	ctx.f16.f64 = double(float(ctx.f14.f64 + ctx.f9.f64));
	// lfs f9,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f15,f9,f6
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfs f6,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f6,f25
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f6,f31,f23
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// fmadds f3,f2,f29,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f3.f64));
	// lfs f2,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f2,f22,f17
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f22.f64 - ctx.f17.f64)));
	// fmuls f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// fmadds f7,f16,f22,f3
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f3.f64));
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f3,f1,f22,f2
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f22.f64 - ctx.f2.f64)));
	// lfs f2,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f8,f2
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// lfs f1,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f8,f28,f18
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// fmuls f1,f8,f1
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f8,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f17,f8,f9
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f8,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f8,f21,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f21.f64 + ctx.f4.f64));
	// lfs f4,1416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1416);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f7,f4,f16,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f16.f64 + ctx.f7.f64));
	// lfs f16,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f4,f15,f22,f3
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f22.f64 + ctx.f3.f64));
	// lfs f15,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f15.f64 = double(temp.f32);
	// lfs f3,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f9,f16
	ctx.f16.f64 = double(float(ctx.f9.f64 + ctx.f16.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f9,1564(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1564, temp.u32);
	// lfs f9,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f15,f15,f29,f8
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f29.f64 + ctx.f8.f64));
	// lfs f8,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f8,f8,f22,f7
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// stfs f8,80(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f7,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f8,f31,f28
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fnmsubs f4,f14,f7,f4
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// fmuls f3,f3,f18
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fnmsubs f9,f9,f21,f15
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f21.f64 - ctx.f15.f64)));
	// stfs f9,4320(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4320, temp.u32);
	// fmuls f7,f8,f0
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f7,136(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmadds f5,f5,f22,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f4.f64));
	// fmuls f4,f16,f27
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f16,1432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1432);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f9,f6,f29,f15
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f15.f64));
	// lfs f6,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f6,1048(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1048, temp.u32);
	// fnmsubs f9,f16,f22,f9
	ctx.f9.f64 = double(float(-(ctx.f16.f64 * ctx.f22.f64 - ctx.f9.f64)));
	// lfs f16,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f5,f2,f16,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f16.f64 + ctx.f5.f64));
	// lfs f2,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f9,f1,f29,f9
	ctx.f9.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f9.f64)));
	// fnmsubs f5,f17,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f17.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// fnmsubs f9,f2,f22,f9
	ctx.f9.f64 = double(float(-(ctx.f2.f64 * ctx.f22.f64 - ctx.f9.f64)));
	// fmadds f5,f3,f29,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f29.f64 + ctx.f5.f64));
	// stfs f5,4324(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4324, temp.u32);
	// lfs f5,1424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1424);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f9,f5,f22,f9
	ctx.f9.f64 = double(float(-(ctx.f5.f64 * ctx.f22.f64 - ctx.f9.f64)));
	// stfs f9,4328(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4328, temp.u32);
	// fmuls f9,f31,f30
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// lfs f5,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f9,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// lfs f9,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f9.f64 = double(temp.f32);
	// fadds f3,f9,f3
	ctx.f3.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// lfs f9,1564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f9,f26
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// lfs f9,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f1,332(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f1,1400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1400);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lis r6,-32254
	ctx.r6.s64 = -2113798144;
	// fmuls f16,f9,f27
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// lfs f9,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f9,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f15,f0,f9
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f9,f30,f28
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f17,1408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1408);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// fmuls f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmadds f7,f3,f7,f5
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 + ctx.f5.f64));
	// lfs f3,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f5,f1,f11
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f1,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f1,20676(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 20676);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,376(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f9,f9,f14
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// lfs f14,1352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1352);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fmuls f1,f17,f10
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f17,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f31,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64 + ctx.f16.f64));
	// fmuls f16,f15,f31
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f7,f7,f12,f2
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f2.f64));
	// fmuls f2,f9,f0
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f9,f30,f28
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmsubs f5,f14,f10,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 - ctx.f5.f64));
	// lfs f14,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f8,f17,f11,f8
	ctx.f8.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f8.f64));
	// lfs f17,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f7,f4,f11,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 - ctx.f7.f64));
	// fmuls f4,f16,f11
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// lfs f9,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f14,f14,f9
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f9.f64));
	// fnmsubs f7,f6,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f6,1180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1180);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmsubs f8,f8,f0,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 - ctx.f4.f64));
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f2,f2,f12,f7
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f7.f64)));
	// lfs f7,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f3,f3,f9,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64 + ctx.f1.f64));
	// lfs f9,1392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1392);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f9,f13
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f9,f30,f28
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fnmsubs f3,f1,f10,f3
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f3.f64)));
	// lfs f1,1368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1368);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// fmuls f9,f31,f30
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f4,f17,f0
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f9,f9,f15
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f15.f64));
	// lfs f15,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f5,f14,f15,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f15.f64 + ctx.f5.f64));
	// lfs f15,1376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1376);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fmadds f3,f1,f10,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f3.f64));
	// fmuls f17,f9,f0
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f9,1384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1384);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f5,f15,f10,f5
	ctx.f5.f64 = double(float(-(ctx.f15.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// fmuls f15,f9,f13
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f9,1360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1360);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f6,f9,f7,f6
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 - ctx.f6.f64));
	// lfs f9,1324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1324);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f2,f16,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f1,f9,f13
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f9,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f10,f15,f10,f5
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f5.f64));
	// stfs f10,4336(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4336, temp.u32);
	// lfs f10,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f8,f4,f12,f8
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// fmuls f10,f6,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// stfs f10,4340(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4340, temp.u32);
	// fmuls f4,f9,f26
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// lfs f6,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f6.f64 = double(temp.f32);
	// lfs f9,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f9.f64 = double(temp.f32);
	// lfs f15,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f9,f0
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f16,520(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fmadds f10,f17,f12,f2
	ctx.f10.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f2.f64));
	// stfs f10,4332(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4332, temp.u32);
	// fnmsubs f10,f1,f11,f3
	ctx.f10.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// stfs f10,4344(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4344, temp.u32);
	// fmuls f10,f28,f18
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f18.f64));
	// lfs f17,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f9,f26
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmuls f9,f9,f15
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f15.f64));
	// lfs f15,1340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f5,f4,f11,f8
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// lfs f8,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f10,f8
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmuls f8,f28,f19
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f9,f9,f22
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f22.f64));
	// fmuls f3,f6,f8
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f6,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f6.f64 = double(temp.f32);
	// lfs f8,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f8,f6
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// fmuls f8,f4,f29
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// lfs f4,1500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1500);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f4,f4,f22,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f22.f64 - ctx.f8.f64));
	// fmuls f8,f30,f28
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fnmsubs f7,f15,f7,f4
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// lfs f4,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f17,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f8,f30,f18
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// fmadds f4,f4,f31,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64 + ctx.f1.f64));
	// fnmsubs f7,f3,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f3.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// lfs f3,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f17,f12
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f17,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f8,f6
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f8,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f28,f25
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fmuls f3,f0,f3
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmadds f4,f4,f11,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f1.f64));
	// lfs f1,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f10,f1
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// lfs f10,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f8,f15,f8
	ctx.f8.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// lfs f15,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f10,f15
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f15.f64));
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f10,f14
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f14.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f9,f17,f10,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f9.f64));
	// lfs f10,1596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1596);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f10,f22,f7
	ctx.f7.f64 = double(float(-(ctx.f10.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f25
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f17,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f5,f4,f0,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fmuls f4,f3,f31
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f9,f15,f22,f9
	ctx.f9.f64 = double(float(-(ctx.f15.f64 * ctx.f22.f64 - ctx.f9.f64)));
	// fnmsubs f7,f2,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// fmuls f17,f10,f17
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// fmuls f10,f30,f18
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// fmadds f2,f14,f23,f17
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f23.f64 + ctx.f17.f64));
	// fmuls f10,f10,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f3,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fnmsubs f12,f8,f12,f5
	ctx.f12.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// lfs f5,1508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1508);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f7,f5,f22,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// lfs f5,1612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	ctx.f5.f64 = double(temp.f32);
	// lfs f8,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f9,f2,f29,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f9.f64));
	// fmuls f8,f8,f18
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f18.f64));
	// lfs f2,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f2.f64 = double(temp.f32);
	// lfs f15,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f15.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f14,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f14.f64 = double(temp.f32);
	// lis r7,-32239
	ctx.r7.s64 = -2112815104;
	// fnmsubs f12,f4,f11,f12
	ctx.f12.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// fmadds f7,f5,f22,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f22.f64 + ctx.f7.f64));
	// lfs f5,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f5,f8,f5,f9
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 + ctx.f9.f64));
	// lfs f9,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f12,f3,f11,f12
	ctx.f12.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// stfs f12,4348(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4348, temp.u32);
	// lfs f12,1692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1692);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f12,f12,f22,f7
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f22.f64 - ctx.f7.f64)));
	// lfs f11,1516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1516);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f13,f9
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f9,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f9.f64 = double(temp.f32);
	// lfs f3,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f12,f16,f29,f12
	ctx.f12.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f12.f64)));
	// fmadds f12,f6,f29,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f12.f64));
	// fmuls f6,f13,f9
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmadds f12,f11,f22,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f22.f64 + ctx.f12.f64));
	// lfs f11,1344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1344);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f12,f1,f29,f12
	ctx.f12.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f12.f64)));
	// fmadds f12,f10,f29,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f29.f64 + ctx.f12.f64));
	// fmadds f12,f11,f22,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f22.f64 + ctx.f12.f64));
	// stfs f12,4352(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4352, temp.u32);
	// lfs f12,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f13,f12
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f13,f12
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f13,f12
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f12,848(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 848, temp.u32);
	// fmuls f9,f11,f20
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f20.f64));
	// lfs f11,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// stfs f11,544(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f11,f31,f25
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// fmsubs f1,f10,f20,f9
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f20.f64 - ctx.f9.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfs f11,188(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f11,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f13,f11
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f11,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// lfs f11,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f11,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// lfs f11,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f18,f11,f10
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// fmuls f11,f28,f25
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f17,f11,f9
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f16,f11,f9
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f1,f8,f11,f1
	ctx.f1.f64 = double(float(-(ctx.f8.f64 * ctx.f11.f64 - ctx.f1.f64)));
	// fmuls f8,f28,f23
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fnmsubs f5,f16,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f16.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// fmadds f7,f7,f11,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f1.f64));
	// lfs f1,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f18,f15,f8,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f8.f64 + ctx.f18.f64));
	// lfs f15,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f8,f31,f23
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// fmuls f9,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fmuls f1,f18,f0
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fmuls f8,f8,f15
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f15.f64));
	// lfs f15,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// fnmsubs f11,f6,f11,f7
	ctx.f11.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f7,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f5,f15,f22,f5
	ctx.f5.f64 = double(float(-(ctx.f15.f64 * ctx.f22.f64 - ctx.f5.f64)));
	// fmadds f9,f7,f6,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 + ctx.f9.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f10,f12
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// fmuls f6,f6,f12
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f14,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f14.f64 = double(temp.f32);
	// lfs f12,1492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1492);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmuls f12,f12,f14
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f14.f64));
	// stfs f12,524(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// lfs f18,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f4,f4,f12,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f11.f64));
	// lfs f11,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f18,f13,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// fmuls f14,f11,f12
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmadds f9,f9,f22,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f22.f64 + ctx.f5.f64));
	// stfs f9,4356(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4356, temp.u32);
	// lfs f5,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f9,1484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1484);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f9,f9,f5
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// stfs f9,508(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// lfs f9,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f9,748(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 748, temp.u32);
	// lfs f9,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f9.f64 = double(temp.f32);
	// lfs f5,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// lfs f11,-20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f5,f5,f9
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// fnmsubs f9,f3,f11,f4
	ctx.f9.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 - ctx.f4.f64)));
	// stfs f12,136(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f12,-24(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f13,f7
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmadds f9,f6,f12,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f9.f64));
	// fmadds f11,f2,f11,f9
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f9.f64));
	// fnmsubs f11,f14,f12,f11
	ctx.f11.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// lfs f4,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f11,f15,f12,f11
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmsubs f6,f1,f20,f4
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f20.f64 - ctx.f4.f64));
	// fnmsubs f9,f17,f12,f6
	ctx.f9.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f6.f64)));
	// lfs f6,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f6.f64 = double(temp.f32);
	// lfs f17,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f9,f8,f12,f9
	ctx.f9.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// fmadds f8,f16,f12,f9
	ctx.f8.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f9.f64));
	// lfs f9,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f11,f9,f12,f11
	ctx.f11.f64 = double(float(-(ctx.f9.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// lfs f9,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f5,f5,f12,f8
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// fmadds f11,f18,f20,f11
	ctx.f11.f64 = double(float(ctx.f18.f64 * ctx.f20.f64 + ctx.f11.f64));
	// lfs f18,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f8,f31,f28
	ctx.f8.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fnmsubs f11,f7,f20,f11
	ctx.f11.f64 = double(float(-(ctx.f7.f64 * ctx.f20.f64 - ctx.f11.f64)));
	// stfs f11,4360(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4360, temp.u32);
	// fmuls f11,f30,f25
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f7,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f4,f7,f30
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// lfs f7,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f7,f28
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfs f7,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f11,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f8,f11
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmuls f11,f27,f10
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fmuls f11,f11,f21
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f21.f64));
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lis r8,-32255
	ctx.r8.s64 = -2113863680;
	// fmuls f17,f7,f28
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfs f7,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f16,f6,f28
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmuls f6,f7,f28
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfs f7,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f5,f2,f12,f5
	ctx.f5.f64 = double(float(-(ctx.f2.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// fmsubs f2,f1,f7,f11
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 - ctx.f11.f64));
	// lfs f11,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f11,f30
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f11,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f11.f64 = double(temp.f32);
	// fadds f15,f11,f9
	ctx.f15.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// lfs f11,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f30,f28
	ctx.f9.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmadds f18,f18,f30,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f6.f64));
	// lfs f6,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f5,f4,f6,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmuls f4,f11,f9
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// fmuls f11,f26,f10
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fnmsubs f6,f3,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fnmsubs f2,f11,f21,f2
	ctx.f2.f64 = double(float(-(ctx.f11.f64 * ctx.f21.f64 - ctx.f2.f64)));
	// lfs f11,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f14,f11,f0
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f11,f31,f30
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f3,f14,f30
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f5,f15,f11,f4
	ctx.f5.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f4.f64));
	// lfs f11,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f4,f9,f11,f2
	ctx.f4.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f2.f64)));
	// lfs f11,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// stfs f11,596(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fmadds f5,f8,f14,f5
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f14.f64 + ctx.f5.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f9,f9,f14,f4
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f14.f64 - ctx.f4.f64)));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f11,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// stfs f11,228(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmadds f5,f5,f7,f9
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f9.f64));
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f2,f28
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f2,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f11,f0
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f11,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f6,f17,f11,f6
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f17,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f10,f17
	ctx.f17.f64 = double(float(ctx.f10.f64 + ctx.f17.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// fnmsubs f6,f16,f11,f6
	ctx.f6.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f6.f64)));
	// lfs f16,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fmuls f9,f27,f30
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmadds f5,f17,f24,f5
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f24.f64 + ctx.f5.f64));
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// fnmsubs f6,f1,f11,f6
	ctx.f6.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f6.f64)));
	// fmuls f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// lfs f9,-18308(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -18308);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,276(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// fmuls f1,f16,f9
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fmadds f18,f18,f11,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f9,f27,f6
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fnmsubs f3,f3,f20,f18
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f20.f64 - ctx.f18.f64)));
	// fnmsubs f5,f9,f21,f5
	ctx.f5.f64 = double(float(-(ctx.f9.f64 * ctx.f21.f64 - ctx.f5.f64)));
	// fmuls f9,f26,f6
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// fnmsubs f9,f9,f21,f5
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f21.f64 - ctx.f5.f64)));
	// stfs f9,4368(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4368, temp.u32);
	// fmadds f9,f4,f20,f3
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f20.f64 + ctx.f3.f64));
	// fnmsubs f9,f15,f20,f9
	ctx.f9.f64 = double(float(-(ctx.f15.f64 * ctx.f20.f64 - ctx.f9.f64)));
	// fmadds f9,f2,f20,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f20.f64 + ctx.f9.f64));
	// stfs f9,4364(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4364, temp.u32);
	// lfs f9,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f9,f30
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// lfs f9,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f5,f24,f9
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// lfs f9,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f9,f8
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f9,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f9,f30
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// lfs f15,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f9,f31,f30
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f18,f6,f28,f5
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f28.f64 + ctx.f5.f64));
	// lfs f6,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f24,f30
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f17,f6,f9
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// fmuls f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f9,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f6,f26,f28
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmsubs f1,f14,f9,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f9.f64 - ctx.f1.f64));
	// lfs f14,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f18,f24,f15,f18
	ctx.f18.f64 = double(float(-(ctx.f24.f64 * ctx.f15.f64 - ctx.f18.f64)));
	// lfs f15,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// lfs f9,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f17,f14,f8,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f8.f64 + ctx.f17.f64));
	// lfs f14,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f8,f24,f30
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f16,f6,f9
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// fnmsubs f4,f4,f7,f18
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f7.f64 - ctx.f18.f64)));
	// fmuls f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f1,f16,f8,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f8.f64 + ctx.f1.f64));
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f8,f24,f28
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// fnmsubs f4,f3,f28,f4
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f28.f64 - ctx.f4.f64)));
	// lfs f3,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f1,f14,f29,f1
	ctx.f1.f64 = double(float(-(ctx.f14.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// lfs f14,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f5,f16,f8,f5
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f8.f64 + ctx.f5.f64));
	// lfs f8,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f18,f15,f8
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f8.f64));
	// fmuls f8,f27,f28
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fnmsubs f4,f2,f7,f4
	ctx.f4.f64 = double(float(-(ctx.f2.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// fmadds f5,f5,f29,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f29.f64 + ctx.f18.f64));
	// lfs f18,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f8,f9
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f8,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f6,f8
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f8,f27,f30
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmadds f7,f17,f7,f4
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fmadds f1,f16,f22,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f1.f64));
	// fmuls f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// fmuls f8,f26,f30
	ctx.f8.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmadds f16,f15,f30,f14
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f30.f64 + ctx.f14.f64));
	// fmuls f3,f3,f8
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f8,f27
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmsubs f5,f3,f22,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 - ctx.f5.f64));
	// lfs f3,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f3.f64 = double(temp.f32);
	// fadds f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f8.f64));
	// fmuls f8,f24,f28
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// fmuls f2,f9,f8
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// fmuls f8,f27,f28
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fnmsubs f4,f2,f29,f1
	ctx.f4.f64 = double(float(-(ctx.f2.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// lfs f2,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f6,f8,f22,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f22.f64 + ctx.f6.f64));
	// fmuls f8,f26,f30
	ctx.f8.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmuls f1,f16,f21
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f21.f64));
	// fmuls f3,f3,f8
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f8,f24,f30
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f2,f8,f2
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f2.f64));
	// lfs f8,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f6,f6,f8,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 + ctx.f5.f64));
	// lfs f5,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f8,f27,f30
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmuls f5,f5,f8
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f8,f26
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmadds f17,f8,f21,f7
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f21.f64 + ctx.f7.f64));
	// fmadds f8,f3,f22,f4
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f22.f64 + ctx.f4.f64));
	// stfs f8,4372(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4372, temp.u32);
	// lfs f8,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f8,f2,f8,f1
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 - ctx.f1.f64));
	// stfs f8,4376(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4376, temp.u32);
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f8,f5,f8,f6
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 + ctx.f6.f64));
	// stfs f8,4380(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4380, temp.u32);
	// lfs f8,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f26,f8
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// lfs f3,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f7,f7,f21,f17
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f21.f64 - ctx.f17.f64)));
	// fmadds f6,f18,f21,f7
	ctx.f6.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 + ctx.f7.f64));
	// fmuls f7,f27,f8
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fnmsubs f7,f7,f21,f6
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f21.f64 - ctx.f6.f64)));
	// lfs f6,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f2,f6,f21,f7
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f21.f64 + ctx.f7.f64));
	// lfs f7,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f7,f0
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f6,80(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f7,f30,f3
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmuls f5,f7,f4
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f4.f64));
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// fmuls f16,f5,f12
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f5,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f0,f7
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f7,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f7,460(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f0,f5
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// fadds f5,f10,f5
	ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
	// lfs f10,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// lfs f10,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f18,f7,f28
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfs f7,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f7,f0
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f0,f7
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// stfs f7,724(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 724, temp.u32);
	// lfs f7,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f7,f0
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f7,f28,f19
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// fmadds f18,f18,f20,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f20.f64 + ctx.f16.f64));
	// fmuls f16,f15,f28
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// lfs f15,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,1604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f28.f64));
	// fmuls f7,f17,f7
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// lfs f17,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f17,392(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// lfs f17,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f1,f18,f0,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 - ctx.f1.f64));
	// fmuls f18,f13,f10
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f18,716(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 716, temp.u32);
	// lfs f18,1636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f17,f0,f17
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// fmadds f18,f18,f30,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f14.f64));
	// fnmsubs f7,f7,f20,f1
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f20.f64 - ctx.f1.f64)));
	// lfs f1,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f5,f1,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f4.f64));
	// lfs f1,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f1.f64 = double(temp.f32);
	// lfs f4,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f0,f4
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fmuls f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmuls f18,f10,f20
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f20.f64));
	// lfs f10,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f10,f30
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f10,f28,f3
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f3.f64));
	// lfs f3,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f10,f10,f3,f5
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f3.f64 + ctx.f5.f64));
	// fmuls f5,f4,f30
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fnmsubs f7,f6,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f6,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f4,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f8,f8,f4
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f4,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f4,f4,f21,f2
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f21.f64 - ctx.f2.f64)));
	// lfs f2,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f10,f10,f12,f18
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f18.f64));
	// fadds f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// lfs f2,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f18,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f18.f64 = double(temp.f32);
	// lis r8,-32239
	ctx.r8.s64 = -2112815104;
	// fnmsubs f7,f14,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fnmsubs f4,f18,f21,f4
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f21.f64 - ctx.f4.f64)));
	// stfs f4,4384(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4384, temp.u32);
	// fmuls f4,f3,f13
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f3,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f23
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// fmadds f7,f16,f11,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fnmsubs f7,f15,f20,f7
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f20.f64 - ctx.f7.f64)));
	// lfs f15,1652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f4,f4,f20,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f20.f64 - ctx.f3.f64));
	// fmadds f7,f17,f11,f7
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fnmsubs f7,f6,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f6,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f7,f1,f6,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 + ctx.f7.f64));
	// lfs f6,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f7,f2,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fmadds f10,f10,f0,f7
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f7.f64));
	// lfs f7,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f10,f5,f20,f10
	ctx.f10.f64 = double(float(-(ctx.f5.f64 * ctx.f20.f64 - ctx.f10.f64)));
	// lfs f5,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f10,f8,f12,f10
	ctx.f10.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f8,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f8,f11
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f8,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f1,f8,f5
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// lfs f8,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f21,f8,f7
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f8,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f7,f8
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f6,f8
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f17,f7,f8
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// stfs f10,4388(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4388, temp.u32);
	// lfs f10,-28(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -28);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f2,f8,f10,f2
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 + ctx.f2.f64));
	// lfs f8,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f16,f8,f25
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f8,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f8,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmadds f4,f3,f12,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f4.f64));
	// fmuls f3,f18,f13
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f18,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f8,f15
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f15.f64));
	// stfs f15,248(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f15,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// lfs f7,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fnmsubs f4,f3,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fmsubs f3,f2,f25,f1
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f25.f64 - ctx.f1.f64));
	// lfs f1,1172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1172);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f8,f7
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// fmuls f7,f13,f23
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// fmuls f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fmadds f7,f18,f20,f17
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f20.f64 + ctx.f17.f64));
	// fmadds f3,f21,f20,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f3.f64));
	// lfs f21,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f4,f7,f13,f4
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f4.f64));
	// lfs f7,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f15,f0
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f14,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// lfs f15,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f7,f13
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f17,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f7,f0
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f7,136(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f7,-20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -20);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fnmsubs f3,f16,f11,f3
	ctx.f3.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// lfs f16,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f4,f1,f7,f4
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// lfs f7,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f7,f13
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f16,f7,f16
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f16.f64));
	// lfs f7,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f19.f64));
	// fmuls f17,f17,f23
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f23.f64));
	// fnmsubs f6,f6,f12,f3
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// fmuls f3,f7,f13
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,-20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -20);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f7,f15,f7,f4
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// lfs f4,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f8,f4
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f8,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f16,f16,f0
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f8,f8,f23
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f23.f64));
	// fmadds f12,f18,f12,f6
	ctx.f12.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fnmsubs f7,f21,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fmadds f12,f2,f11,f12
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f12.f64));
	// lfs f2,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmadds f12,f17,f11,f12
	ctx.f12.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f12.f64));
	// lfs f17,1600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1600);
	ctx.f17.f64 = double(temp.f32);
	// lfs f6,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f6,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f12,f8,f6,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 + ctx.f12.f64));
	// lfs f8,1624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1624);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f7,f1,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f1,1616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1616);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f0,f3,f0,f7
	ctx.f0.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// stfs f0,4392(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4392, temp.u32);
	// fnmsubs f0,f19,f11,f12
	ctx.f0.f64 = double(float(-(ctx.f19.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// lfs f3,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fnmsubs f0,f5,f11,f0
	ctx.f0.f64 = double(float(-(ctx.f5.f64 * ctx.f11.f64 - ctx.f0.f64)));
	// lfs f5,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f7,f16,f20,f0
	ctx.f7.f64 = double(float(-(ctx.f16.f64 * ctx.f20.f64 - ctx.f0.f64)));
	// lfs f0,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f6,f0,f8
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f8,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f8,f5
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// fmuls f10,f12,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f12,1608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1608);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f21,f0,f12
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f12,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f19,f12,f13
	ctx.f19.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,1440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1440);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f18,f12,f13
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f17,f12,f17
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// fmsubs f10,f6,f20,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f20.f64 - ctx.f10.f64));
	// lfs f6,1592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1592);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f0,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f0,1432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1432);
	ctx.f0.f64 = double(temp.f32);
	// lis r5,-32239
	ctx.r5.s64 = -2112815104;
	// fmuls f16,f0,f13
	ctx.f16.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,1424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1424);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f15,f0,f13
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f14,1584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1584);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f12,f14
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f14.f64));
	// fnmsubs f12,f5,f20,f10
	ctx.f12.f64 = double(float(-(ctx.f5.f64 * ctx.f20.f64 - ctx.f10.f64)));
	// lfs f10,1676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1676);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f10,672(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 672, temp.u32);
	// lfs f10,1416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1416);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f20,f10,f13
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f10.f64 = double(temp.f32);
	// lfs f5,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f27,f23
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fnmsubs f12,f3,f11,f12
	ctx.f12.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// lfs f3,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f5,f0,f22
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f22.f64));
	// fmuls f0,f24,f25
	ctx.f0.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmuls f22,f10,f30
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmadds f12,f2,f11,f12
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f12.f64));
	// fmuls f10,f9,f0
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f0,1576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1576);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f8,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f0,136(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f0,f26,f25
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f11,f0,f9
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// lfs f9,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f0,f26,f23
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// fmadds f9,f0,f9,f5
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 + ctx.f5.f64));
	// lfs f0,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f8,f4,f0
	ctx.f8.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f5,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f5.f64 = double(temp.f32);
	// lfs f0,1700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1700);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f4,f5,f0
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f5,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f5.f64 = double(temp.f32);
	// lfs f0,1568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1568);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f5,f0
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// lfs f5,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f5.f64 = double(temp.f32);
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmr f0,f5
	ctx.f0.f64 = ctx.f5.f64;
	// lfs f5,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f10,f9,f3,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f3.f64 - ctx.f10.f64));
	// lfs f9,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f8,f8,f9,f7
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f9.f64 - ctx.f7.f64)));
	// stfs f8,4396(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4396, temp.u32);
	// fnmsubs f12,f1,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fmadds f11,f11,f5,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64 + ctx.f10.f64));
	// lfs f10,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f10,f30
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f10,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f8,f21,f0,f12
	ctx.f8.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// lfs f12,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f4,f10,f11
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 + ctx.f11.f64));
	// fnmsubs f7,f19,f12,f8
	ctx.f7.f64 = double(float(-(ctx.f19.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f8,-28(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -28);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,184(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmadds f11,f18,f8,f7
	ctx.f11.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f7.f64));
	// fnmsubs f11,f17,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// fnmsubs f11,f6,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfs f6,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f13,-32(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -32);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,384(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmadds f11,f16,f12,f11
	ctx.f11.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fnmsubs f7,f15,f8,f11
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f8.f64 - ctx.f11.f64)));
	// lfs f11,-24(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -24);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,240(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fmadds f7,f6,f11,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fnmsubs f13,f14,f13,f7
	ctx.f13.f64 = double(float(-(ctx.f14.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fmadds f13,f20,f12,f13
	ctx.f13.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f13,f22,f9,f13
	ctx.f13.f64 = double(float(-(ctx.f22.f64 * ctx.f9.f64 - ctx.f13.f64)));
	// fnmsubs f9,f7,f11,f13
	ctx.f9.f64 = double(float(-(ctx.f7.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// lfs f13,-20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f7,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f13,236(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// lfs f14,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f13,f7,f13,f9
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 + ctx.f9.f64));
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f9,f31,f30
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmadds f13,f2,f11,f13
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f13.f64));
	// stfs f13,4400(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4400, temp.u32);
	// lfs f13,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f28,f13
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f4,f9,f13
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f13,f24,f31
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmuls f21,f4,f29
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f6,f7,f13
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f6,532(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// fmuls f6,f30,f25
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f4,f28,f23
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f22,f13,f23
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// fmuls f2,f24,f6
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f6,f28,f25
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fadds f20,f4,f6
	ctx.f20.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f4,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f4,1120(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1120, temp.u32);
	// fmuls f19,f3,f4
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f22,f2,f4,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 + ctx.f22.f64));
	// lfs f4,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f18,f13,f4,f21
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f4.f64 - ctx.f21.f64));
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// lfs f21,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f13,f6
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmuls f13,f24,f21
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// lfs f6,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,-36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -36);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,932(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 932, temp.u32);
	// fmuls f16,f6,f13
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f13,f28,f4
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// lfs f4,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f13,f4
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// lfs f13,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f14,f14,f13,f1
	ctx.f14.f64 = double(float(-(ctx.f14.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// lfs f13,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// lfs f1,1408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1408);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f1,f13,f22
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f22.f64)));
	// fmadds f22,f20,f4,f19
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f19.f64));
	// lfs f20,1400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1400);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f20,f20,f13,f18
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f13.f64 - ctx.f18.f64)));
	// lfs f19,1392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1392);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f18,f17,f10,f16
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f16.f64));
	// fmuls f17,f15,f31
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fnmsubs f19,f19,f2,f1
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f1,1384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1384);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f20,f1,f13,f20
	ctx.f20.f64 = double(float(-(ctx.f1.f64 * ctx.f13.f64 - ctx.f20.f64)));
	// fmuls f1,f24,f23
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// fnmsubs f18,f17,f10,f18
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f18.f64)));
	// fnmsubs f1,f3,f1,f14
	ctx.f1.f64 = double(float(-(ctx.f3.f64 * ctx.f1.f64 - ctx.f14.f64)));
	// lfs f3,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// stfs f3,828(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 828, temp.u32);
	// fmadds f22,f6,f3,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f3.f64 + ctx.f22.f64));
	// lfs f3,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// stfs f3,188(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f16,f3,f29
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f3,f30,f21
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fmuls f15,f24,f3
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// lfs f3,1376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1376);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f2,f3,f2,f20
	ctx.f2.f64 = double(float(-(ctx.f3.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// fmuls f3,f9,f26
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmuls f20,f7,f3
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f3,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f3,f30
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// lfs f3,1368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1368);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f19,f3,f13,f19
	ctx.f19.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f19.f64)));
	// lfs f3,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f1,f22,f10,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f1.f64));
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f20,f13,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 - ctx.f14.f64));
	// fmuls f17,f3,f17
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// fmuls f3,f27,f25
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fmadds f18,f17,f10,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f18.f64));
	// fmadds f22,f3,f13,f16
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f16.f64));
	// lfs f3,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f15,f3,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 + ctx.f2.f64));
	// lfs f3,1360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1360);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f7,f3
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f3,1324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1324);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f19,f3,f13,f19
	ctx.f19.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f19.f64)));
	// lfs f3,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f9,f3
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmuls f3,f28,f21
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// fmadds f3,f22,f6,f1
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f1.f64));
	// lfs f1,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f1.f64 = double(temp.f32);
	// stfs f3,4404(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4404, temp.u32);
	// lfs f3,1352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1352);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f3,f3,f13,f2
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// stfs f3,4408(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4408, temp.u32);
	// fmadds f2,f16,f13,f20
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 + ctx.f20.f64));
	// stfs f2,4412(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4412, temp.u32);
	// fnmsubs f2,f15,f29,f19
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f29.f64 - ctx.f19.f64)));
	// stfs f2,4416(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4416, temp.u32);
	// lfs f2,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,1436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1436);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f9,f3
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fnmsubs f4,f4,f10,f18
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f10.f64 - ctx.f18.f64)));
	// lfs f10,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmadds f17,f3,f13,f4
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f4.f64));
	// lfs f4,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f10,f0
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f10,f1,f25
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fmuls f3,f24,f25
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fmuls f20,f10,f30
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f10,1344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1344);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f19,f10,f8
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f10,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f18,f2,f10
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f10,f27,f21
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fmuls f16,f6,f10
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f10,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmadds f22,f10,f4,f22
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f22.f64));
	// lfs f10,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f10.f64 = double(temp.f32);
	// lfs f4,1340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f4,f10
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f4,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f14,f9,f4
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// lfs f4,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f20,f20,f4,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f19.f64));
	// lfs f4,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f19,f18,f0
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// fnmsubs f18,f4,f3,f17
	ctx.f18.f64 = double(float(-(ctx.f4.f64 * ctx.f3.f64 - ctx.f17.f64)));
	// lfs f3,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f9,f3
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f3.f64));
	// fmuls f3,f10,f23
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f23.f64));
	// fmadds f19,f15,f12,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f19.f64));
	// fnmsubs f18,f16,f13,f18
	ctx.f18.f64 = double(float(-(ctx.f16.f64 * ctx.f13.f64 - ctx.f18.f64)));
	// fmuls f22,f22,f3
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// lfs f3,1612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// stfs f3,80(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f3,f1,f23
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// stfs f3,1168(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1168, temp.u32);
	// fmadds f22,f20,f10,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f22.f64));
	// fmuls f1,f3,f31
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,1516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1516);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f3,f8
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fmuls f3,f26,f21
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// fmuls f3,f3,f6
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f6,1692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1692);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f6,f10
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f6,f26,f25
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmadds f18,f14,f5,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f5.f64 + ctx.f18.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fsubs f22,f22,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 - ctx.f19.f64));
	// fmadds f1,f1,f11,f16
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f16.f64));
	// lfs f16,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f6,f4
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f6,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f9,f6
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// lfs f6,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f18,f17,f5,f18
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f5.f64 - ctx.f18.f64)));
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fnmsubs f22,f14,f12,f22
	ctx.f22.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f22.f64)));
	// fnmsubs f3,f3,f5,f18
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f5.f64 - ctx.f18.f64)));
	// fmuls f2,f2,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f6,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// lfs f6,1508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1508);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f22,f20,f8,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f8.f64 - ctx.f22.f64)));
	// lfs f20,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f1,f6,f12,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f1.f64));
	// fmuls f6,f27,f25
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fmadds f5,f15,f5,f3
	ctx.f5.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fmuls f16,f16,f31
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fmadds f1,f1,f10,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f22.f64));
	// lfs f22,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f4,f6
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f4,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f5,f19,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f19.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fmadds f2,f2,f0,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f1.f64));
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f4,f6
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f4,f23
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// stfs f6,720(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// fmuls f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// fmadds f13,f17,f13,f5
	ctx.f13.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f5,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f5,f16,f5,f2
	ctx.f5.f64 = double(float(-(ctx.f16.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f2,1444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1444);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f10,f6
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// fmuls f4,f10,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// fnmsubs f13,f9,f2,f13
	ctx.f13.f64 = double(float(-(ctx.f9.f64 * ctx.f2.f64 - ctx.f13.f64)));
	// lfs f2,1572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f5,f14,f0,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fmuls f3,f18,f31
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmadds f13,f9,f2,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f2.f64 + ctx.f13.f64));
	// stfs f13,4420(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4420, temp.u32);
	// lfs f13,1604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f9,f22,f8
	ctx.f9.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fmuls f13,f7,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f13,708(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 708, temp.u32);
	// lfs f13,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// fnmsubs f5,f3,f11,f5
	ctx.f5.f64 = double(float(-(ctx.f3.f64 * ctx.f11.f64 - ctx.f5.f64)));
	// fmuls f8,f13,f25
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fmuls f13,f20,f23
	ctx.f13.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// fmuls f19,f8,f12
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f8,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f3,f13,f25
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// lfs f13,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f13,f25
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// lfs f13,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f1,392(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmadds f1,f20,f12,f9
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f9.f64));
	// lfs f9,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f18,f8,f9
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f9,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f25
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// lfs f8,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f17,f9,f8
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f8,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f3,f8,f21,f3
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f21.f64 + ctx.f3.f64));
	// lfs f8,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f16,f8,f21
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// lfs f8,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f7,f8
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f8,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f8,f8,f25
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f14,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f14.f64 = double(temp.f32);
	// stfs f8,596(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fnmsubs f4,f4,f11,f5
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f11.f64 - ctx.f5.f64)));
	// lfs f5,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f14,f14,f8
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f8.f64));
	// lfs f8,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f1,f1,f8,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 + ctx.f19.f64));
	// lfs f8,-40(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -40);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,80(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f8,f17,f8
	ctx.f8.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// lfs f17,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f13,1500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1500);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f15,f13,f10
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f13,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f14,f14,f13,f8
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmuls f13,f5,f28
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f8,f10,f25
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fnmsubs f4,f15,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fmadds f14,f19,f0,f14
	ctx.f14.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f14.f64));
	// lfs f19,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f19,f25
	ctx.f15.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f19,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f8,f13,f8
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// lfs f13,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// stfs f13,228(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f13,1652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f13,f5,f31
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// lfs f5,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f13,f5,f13,f8
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmuls f8,f7,f9
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f9,f7,f6
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 + ctx.f6.f64));
	// lfs f7,1492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1492);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f7,f7,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// fmadds f4,f13,f0,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lfs f13,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f13.f64 = double(temp.f32);
	// lfs f5,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f6,f5,f6,f14
	ctx.f6.f64 = double(float(-(ctx.f5.f64 * ctx.f6.f64 - ctx.f14.f64)));
	// lfs f5,1596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1596);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f10,f5,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// lfs f14,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f5,f15,f12,f1
	ctx.f5.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 - ctx.f1.f64));
	// lfs f15,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f15.f64 = double(temp.f32);
	// lfs f1,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// fmuls f15,f9,f13
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f9,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f13,f22,f23
	ctx.f13.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// fnmsubs f7,f7,f0,f6
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// lfs f6,1484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1484);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f10,f10,f12,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f4.f64));
	// stfs f10,4424(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4424, temp.u32);
	// fnmsubs f5,f2,f14,f5
	ctx.f5.f64 = double(float(-(ctx.f2.f64 * ctx.f14.f64 - ctx.f5.f64)));
	// fmuls f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fmuls f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmadds f10,f13,f0,f7
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fmadds f13,f3,f12,f5
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f5.f64));
	// fnmsubs f13,f18,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f18.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmadds f7,f16,f12,f13
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfs f13,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f7,f17,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f17.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fnmsubs f7,f1,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fnmsubs f13,f8,f13,f7
	ctx.f13.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fmadds f13,f15,f11,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f13.f64));
	// stfs f13,4428(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4428, temp.u32);
	// fnmsubs f6,f6,f0,f10
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f8,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f8.f64 = double(temp.f32);
	// lfs f13,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f8,f13
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f8,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f3,f10,f13
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f10,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f5,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f5.f64 = double(temp.f32);
	// lfs f7,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f7.f64 = double(temp.f32);
	// lfs f15,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f4,f4,f0,f6
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// lfs f6,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmuls f2,f13,f10
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f10,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f5,f10
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// lfs f10,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f5,f14,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmuls f18,f10,f11
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f7,f10
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f10,f20,f25
	ctx.f10.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmsubs f3,f3,f12,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f2.f64));
	// fmadds f18,f8,f12,f18
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f18.f64));
	// fmuls f8,f22,f25
	ctx.f8.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// fmuls f16,f10,f6
	ctx.f16.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f10,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmadds f3,f18,f13,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f3.f64));
	// lfs f18,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f6,f8,f6
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f6.f64));
	// lfs f8,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f8,f0
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f8,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f15,f15,f10
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f10,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f4,f1,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// fmuls f8,f8,f28
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f28.f64));
	// stfs f8,1204(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1204, temp.u32);
	// fmadds f2,f18,f10,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 + ctx.f2.f64));
	// lfs f18,1668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f3,f15,f10,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f3.f64));
	// lfs f15,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f4,f17,f10,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f17,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f13,f8
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fmuls f8,f7,f31
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f17,f9,f17
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// fmuls f15,f13,f15
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// fmuls f18,f13,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// fnmsubs f4,f16,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f16,1560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1560);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmuls f7,f13,f8
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fmuls f8,f20,f23
	ctx.f8.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fnmsubs f6,f6,f10,f4
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f10,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f4,f1,f11,f3
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// lfs f11,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f28
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// stfs f11,1212(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1212, temp.u32);
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f9,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f1,f13,f21
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmuls f3,f13,f11
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f11,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f28
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// fmuls f9,f13,f9
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fadds f14,f10,f11
	ctx.f14.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// lfs f11,1164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1164);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f16,f11,f28,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f28.f64 + ctx.f16.f64));
	// lfs f10,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f11,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f10,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f6,f2,f10,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f10,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f7,f10,f4
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f4,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f11,f4,f28
	ctx.f11.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f4,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f1,f14
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f14.f64));
	// fmuls f1,f16,f13
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmadds f8,f8,f0,f6
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fnmsubs f7,f18,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// lfs f11,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f16,f15,f11
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f11,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f8,f17,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// fmadds f10,f9,f10,f7
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fmadds f2,f2,f11,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fnmsubs f9,f5,f0,f8
	ctx.f9.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// lfs f8,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f10,f3,f8,f10
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f8.f64 - ctx.f10.f64)));
	// fnmsubs f4,f4,f0,f2
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fmadds f3,f1,f12,f10
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f10.f64));
	// lfs f10,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f9,f8,f11,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 + ctx.f9.f64));
	// stfs f9,4432(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4432, temp.u32);
	// lfs f9,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f9.f64 = double(temp.f32);
	// fadds f5,f10,f9
	ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// lfs f9,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f9,f10
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f8,1476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1476);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f10,f26,f25
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f2,f5,f8
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f5,1588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f18,f10,f8
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f10,-18316(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18316);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,188(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f10,f30,f25
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lfs f7,-18456(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18456);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,252(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmuls f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f17,f9,f10
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f10,f28,f25
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f6,f10,f31
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f10,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f16,f10,f6
	ctx.f16.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f6,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f15,f6,f5
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmuls f6,f27,f19
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmadds f4,f15,f11,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f4.f64));
	// lfs f11,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f11,f13
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmuls f11,f28,f23
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f14,f10,f6
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f6,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f5,f6,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// fmuls f6,f26,f23
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// fmuls f15,f10,f11
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f11,1676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1676);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f11,f24,f25
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f10,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f6,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// lfs f6,1420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1420);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f13,f6
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
	// fmuls f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmsubs f8,f1,f10,f7
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 - ctx.f7.f64));
	// fmuls f10,f26,f28
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// stfs f11,228(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmr f11,f7
	ctx.f11.f64 = ctx.f7.f64;
	// fmuls f7,f2,f30
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// fmuls f10,f11,f10
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// stfs f10,256(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fnmsubs f10,f5,f0,f4
	ctx.f10.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// lfs f4,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f0,f27,f30
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f0,f11,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfs f0,136(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f11,f24,f23
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f0,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f5,f0,f13
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f0,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f0,f11
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f8,f18,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// lfs f11,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f10,f6,f11,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f11.f64 + ctx.f10.f64));
	// lfs f6,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f11,f24,f19
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// fmuls f5,f5,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f11,1412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f13,f11
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmuls f11,f27,f23
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fmuls f18,f11,f0
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f0,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f11,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f8,f17,f11,f8
	ctx.f8.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// stfs f0,828(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 828, temp.u32);
	// fmuls f17,f13,f0
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f0,f27,f25
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fnmsubs f13,f7,f12,f10
	ctx.f13.f64 = double(float(-(ctx.f7.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f12,1476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1476);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f10,f16,f11,f8
	ctx.f10.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// lfs f8,21484(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 21484);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,720(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// lfs f8,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f7.f64 = double(temp.f32);
	// lfs f16,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f26,f19
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f12,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f8,f4,f8,f13
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f8.f64 - ctx.f13.f64)));
	// lfs f13,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f12,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f24,f12
	ctx.f12.f64 = double(float(ctx.f24.f64 * ctx.f12.f64));
	// stfs f0,596(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fmuls f4,f12,f13
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f13.f64 = double(temp.f32);
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
	// lfs f13,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f12,f14,f0,f10
	ctx.f12.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f10.f64));
	// fnmsubs f10,f5,f13,f8
	ctx.f10.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// lfs f8,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f8.f64 = double(temp.f32);
	// lfs f5,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f0,f9,f0,f12
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f12.f64));
	// lfs f9,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f9,f1,f9,f10
	ctx.f9.f64 = double(float(-(ctx.f1.f64 * ctx.f9.f64 - ctx.f10.f64)));
	// lfs f10,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// fmadds f1,f15,f10,f0
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f0.f64));
	// lfs f0,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f9,f17,f0,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f9.f64));
	// fmadds f17,f8,f5,f12
	ctx.f17.f64 = double(float(ctx.f8.f64 * ctx.f5.f64 + ctx.f12.f64));
	// fmadds f12,f16,f11,f1
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f1.f64));
	// fadds f11,f3,f9
	ctx.f11.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// lfs f9,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f9.f64 = double(temp.f32);
	// stfs f11,4436(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4436, temp.u32);
	// fnmsubs f12,f2,f9,f12
	ctx.f12.f64 = double(float(-(ctx.f2.f64 * ctx.f9.f64 - ctx.f12.f64)));
	// fnmsubs f11,f6,f9,f12
	ctx.f11.f64 = double(float(-(ctx.f6.f64 * ctx.f9.f64 - ctx.f12.f64)));
	// lfs f12,20676(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 20676);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,376(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmadds f11,f18,f12,f11
	ctx.f11.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f11.f64));
	// lfs f6,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f8,f23
	ctx.f16.f64 = double(float(ctx.f8.f64 * ctx.f23.f64));
	// fmuls f8,f28,f7
	ctx.f8.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// fmuls f7,f27,f21
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fnmsubs f11,f6,f9,f11
	ctx.f11.f64 = double(float(-(ctx.f6.f64 * ctx.f9.f64 - ctx.f11.f64)));
	// lfs f6,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f12,f6,f12,f11
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f12,4440(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4440, temp.u32);
	// lfs f6,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f11,f26,f25
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f12,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f12.f64 = double(temp.f32);
	// fadds f3,f12,f6
	ctx.f3.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
	// lfs f12,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f12,f21
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// fmuls f12,f27,f25
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fmuls f3,f3,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fmuls f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fadds f1,f11,f12
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfs f12,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f18,f27,f12
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// lfs f11,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f28,f23
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmadds f3,f1,f31,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f31.f64 + ctx.f3.f64));
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f15,f11,f12
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f28,f5
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f5,f11,f12
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f27,f8
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// stfs f12,1172(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1172, temp.u32);
	// fmuls f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmuls f3,f3,f11
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmuls f14,f11,f12
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f12,-10664(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -10664);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f18,f18,f12
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f12,612(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// fmadds f2,f17,f12,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f2.f64));
	// lfs f17,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f24,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmsubs f18,f15,f10,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 - ctx.f18.f64));
	// fmuls f15,f7,f31
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfs f7,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f4,f4,f7,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 - ctx.f2.f64));
	// fmuls f2,f24,f8
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// lfs f8,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f3,f3,f7,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 - ctx.f16.f64));
	// lfs f16,1640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1640);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f11,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f16.f64));
	// fnmsubs f5,f5,f10,f18
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f10.f64 - ctx.f18.f64)));
	// fmuls f18,f8,f25
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// lfs f8,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f27,f8
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// stfs f8,80(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f8,f26,f21
	ctx.f8.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// fnmsubs f4,f14,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fnmsubs f3,f1,f12,f3
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// fmadds f17,f17,f10,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f5.f64));
	// lfs f5,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f2,f8,f31,f2
	ctx.f2.f64 = double(float(ctx.f8.f64 * ctx.f31.f64 + ctx.f2.f64));
	// fmuls f8,f24,f26
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmadds f4,f15,f7,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fnmsubs f3,f18,f9,f3
	ctx.f3.f64 = double(float(-(ctx.f18.f64 * ctx.f9.f64 - ctx.f3.f64)));
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fmuls f14,f8,f5
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// fmuls f8,f6,f27
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f6,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f4,f16,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fmuls f1,f11,f8
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f8,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f8.f64 = double(temp.f32);
	// lfs f15,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f17,f15,f10,f17
	ctx.f17.f64 = double(float(-(ctx.f15.f64 * ctx.f10.f64 - ctx.f17.f64)));
	// fmuls f15,f27,f8
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmuls f8,f27,f26
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmsubs f14,f8,f6,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f6.f64 - ctx.f14.f64));
	// fmuls f8,f27,f27
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f27.f64));
	// lfs f18,1632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1632);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f6,f26,f26
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f26.f64));
	// fmuls f18,f11,f18
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// lfs f11,1468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1468);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f16,f24,f11
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// fmuls f11,f24,f27
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// fmadds f7,f2,f7,f4
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 + ctx.f4.f64));
	// stfs f7,4444(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4444, temp.u32);
	// lfs f7,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f17,f15,f12,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmuls f4,f24,f7
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// lfs f15,1588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	ctx.f15.f64 = double(temp.f32);
	// fadds f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// lfs f8,-7796(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -7796);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,688(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 688, temp.u32);
	// fnmsubs f11,f11,f5,f14
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f5.f64 - ctx.f14.f64)));
	// lfs f14,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f5,f1,f12,f3
	ctx.f5.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f11,f24,f24,f11
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f24.f64 + ctx.f11.f64));
	// fnmsubs f7,f18,f12,f5
	ctx.f7.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// stfs f7,4452(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4452, temp.u32);
	// lfs f7,1644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f5,f16,f10,f17
	ctx.f5.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f17.f64)));
	// fmadds f11,f6,f8,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 + ctx.f11.f64));
	// stfs f11,4448(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4448, temp.u32);
	// lfs f11,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f27,f7
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmuls f3,f26,f11
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f11,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f26,f11
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f8,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f11,f28,f25
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fnmsubs f5,f4,f9,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f9.f64 - ctx.f5.f64)));
	// lfs f9,1468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1468);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f27,f9
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fmuls f7,f24,f7
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// stfs f11,228(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f1,f8,f11
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f11,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f30,f25
	ctx.f8.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f11,f11,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// stfs f11,1176(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1176, temp.u32);
	// fmuls f8,f8,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// fmuls f18,f11,f8
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f8,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f11,f28,f21
	ctx.f11.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fmuls f17,f11,f8
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f11,-1968(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -1968);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f16,f6,f11
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f8,f22,f23
	ctx.f8.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// stfs f11,680(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 680, temp.u32);
	// fmadds f5,f4,f11,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f5.f64));
	// fmuls f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64));
	// fmsubs f3,f3,f11,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f16.f64));
	// lfs f11,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f16,f15,f31
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fmuls f15,f26,f9
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fmuls f6,f6,f14
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// lfs f14,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f26,f14
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// fnmsubs f3,f2,f10,f3
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f10.f64 - ctx.f3.f64)));
	// lfs f10,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f25
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f10,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// stfs f10,136(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f8,f8,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fnmsubs f4,f1,f11,f3
	ctx.f4.f64 = double(float(-(ctx.f1.f64 * ctx.f11.f64 - ctx.f3.f64)));
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f10,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f24,f10
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f10,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmuls f10,f24,f10
	ctx.f10.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f11,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f8,f16,f11,f8
	ctx.f8.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f8.f64));
	// lfs f3,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// lfs f1,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f10,f1,f25
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fmadds f8,f6,f13,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmuls f3,f11,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// lfs f11,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f28
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// fmuls f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,1548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1548);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f10,f11
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f11,1644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f26,f11
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f5,f2,f11,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f5.f64));
	// lfs f11,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// fnmsubs f5,f10,f12,f5
	ctx.f5.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - ctx.f5.f64)));
	// lfs f10,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f11,f31
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f11,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f11,f18,f11,f4
	ctx.f11.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f4.f64)));
	// lfs f4,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f18,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f3,f18,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f18,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f26,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// fmadds f17,f17,f10,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f11.f64));
	// lfs f11,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f9,f9,f11,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f11.f64 + ctx.f8.f64));
	// lfs f10,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f4,f2,f11,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f4.f64));
	// lfs f11,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f16,f27,f10
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f8,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f10,f11,f25
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// lfs f11,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f11.f64 = double(temp.f32);
	// stfs f10,1096(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1096, temp.u32);
	// fmadds f9,f1,f8,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 + ctx.f9.f64));
	// lfs f1,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f2,f11,f10
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f10,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f5,f18,f10,f5
	ctx.f5.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// lfs f10,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f7,f7,f10,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64 + ctx.f17.f64));
	// fmadds f9,f3,f0,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f3,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmadds f7,f14,f10,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fmsubs f9,f4,f11,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 - ctx.f9.f64));
	// lfs f4,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f12,f15,f12,f7
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f7.f64));
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f12,f7,f10,f12
	ctx.f12.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f12.f64)));
	// lfs f7,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f2,f2,f7,f9
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f7.f64 - ctx.f9.f64)));
	// lfs f9,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f12,f6,f9,f12
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f9.f64 + ctx.f12.f64));
	// fmadds f12,f16,f10,f12
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f12.f64));
	// lfs f10,1460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1460);
	ctx.f10.f64 = double(temp.f32);
	// fadds f12,f5,f12
	ctx.f12.f64 = double(float(ctx.f5.f64 + ctx.f12.f64));
	// stfs f12,4456(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4456, temp.u32);
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f30
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f5,1396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1396);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f9,f19
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f19.f64));
	// lfs f9,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f28
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// stfs f9,720(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// fadds f5,f5,f9
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// lfs f9,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f4,f4,f9
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// lfs f9,1928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1928);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f3,f9
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// fmuls f18,f7,f0
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,1380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f7,f0
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f7,f10,f28
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f15,f5,f0
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmsubs f18,f3,f13,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 - ctx.f18.f64));
	// lfs f3,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f1,f1,f13,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmadds f16,f7,f23,f6
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f23.f64 + ctx.f6.f64));
	// lfs f6,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f6,f23
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// lfs f7,1580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f22,f7
	ctx.f14.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// fmuls f17,f4,f8
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// lfs f4,1428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1428);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// stfs f5,80(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f3,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f16,f16,f3,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f15.f64));
	// lfs f3,-44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -44);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f10,f4
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// lfs f10,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f18,f14,f10,f18
	ctx.f18.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f18.f64)));
	// lfs f14,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f5,f14,f25
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// fmsubs f1,f1,f11,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 - ctx.f17.f64));
	// fmuls f17,f15,f23
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f23.f64));
	// lfs f15,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f11,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f4,f4,f5,f14
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 + ctx.f14.f64));
	// lfs f5,1628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f16,f5,f10,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f16.f64));
	// lfs f5,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f14,1404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f11,f14
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f14.f64));
	// fmadds f4,f4,f3,f18
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f18.f64));
	// lfs f3,1452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1452);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f1,f16,f11,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f1.f64));
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// fmuls f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f16,f20,f9
	ctx.f16.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// fnmsubs f4,f17,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// lfs f17,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f1,f14,f0,f1
	ctx.f1.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fmuls f18,f5,f30
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmuls f5,f20,f23
	ctx.f5.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// fnmsubs f8,f3,f8,f4
	ctx.f8.f64 = double(float(-(ctx.f3.f64 * ctx.f8.f64 - ctx.f4.f64)));
	// lfs f4,1556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1556);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,1684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1684);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmadds f2,f18,f13,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f2.f64));
	// fmuls f5,f5,f11
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// stfs f5,80(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f5,f17,f28
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// stfs f5,596(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fmuls f17,f12,f9
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fnmsubs f8,f16,f10,f8
	ctx.f8.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f8.f64)));
	// fmuls f16,f22,f9
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// fmuls f5,f11,f5
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmuls f11,f11,f3
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmadds f8,f17,f0,f8
	ctx.f8.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f8.f64));
	// lfs f18,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f30
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// fnmsubs f3,f18,f13,f2
	ctx.f3.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// fnmsubs f2,f15,f13,f1
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// lfs f1,1460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1460);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f22,f1
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmuls f18,f20,f7
	ctx.f18.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fmadds f10,f4,f10,f3
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 + ctx.f3.f64));
	// fnmsubs f5,f5,f0,f2
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fmadds f8,f1,f13,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fnmsubs f11,f11,f0,f5
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f0.f64 - ctx.f5.f64)));
	// fnmsubs f4,f18,f13,f8
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// stfs f11,4460(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4460, temp.u32);
	// lfs f11,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f11.f64 = double(temp.f32);
	// lfs f8,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f10,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmuls f2,f10,f19
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// stfs f11,256(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f11,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f12,f6
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// lfs f5,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f11,f5
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmuls f1,f12,f10
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f10,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f10.f64 = double(temp.f32);
	// lfs f18,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f4,f16,f13,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f13.f64 - ctx.f4.f64)));
	// fadds f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f10.f64));
	// lfs f10,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f10.f64 = double(temp.f32);
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f10,f17
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// lfs f10,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// stfs f5,332(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmuls f5,f3,f10
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f3,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f2,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// lfs f15,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f10,f10,f15
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f15.f64));
	// lfs f15,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f15.f64 = double(temp.f32);
	// fadds f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f15.f64));
	// fmuls f15,f12,f12
	ctx.f15.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// fmuls f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// lfs f7,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f16,f16,f31
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fmadds f5,f5,f0,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f3.f64));
	// lfs f3,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// fmuls f14,f10,f25
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f10,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f10.f64 = double(temp.f32);
	// fadds f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f10.f64));
	// lfs f10,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f10,-48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -48);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f15,f11,f11,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + ctx.f15.f64));
	// fnmsubs f5,f1,f0,f5
	ctx.f5.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f5.f64)));
	// lfs f1,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f10,f18,f10
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// fmuls f8,f8,f1
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f1,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// fadds f18,f22,f20
	ctx.f18.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// fmadds f10,f15,f7,f10
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f10.f64));
	// lfs f7,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f7.f64 = double(temp.f32);
	// lfs f15,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f7,f15,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// lfs f15,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f1,f15,f25,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f25.f64 + ctx.f1.f64));
	// lfs f15,1580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f11,f11,f15
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// lfs f15,1452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1452);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f12,f18,f15,f12
	ctx.f12.f64 = double(float(ctx.f18.f64 * ctx.f15.f64 + ctx.f12.f64));
	// lfs f15,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f21
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// fmsubs f10,f10,f15,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f15.f64 - ctx.f9.f64));
	// lfs f15,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f15.f64 = double(temp.f32);
	// lfs f9,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f21
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// fnmsubs f7,f7,f15,f5
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f15.f64 - ctx.f5.f64)));
	// lfs f15,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f15.f64 = double(temp.f32);
	// lfs f5,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// lfs f15,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// fnmsubs f6,f6,f0,f10
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f10,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f15,f10,f28
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f10,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f7,f17,f10,f7
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fmadds f12,f12,f0,f6
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f6,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f7,f2,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fnmsubs f12,f11,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f11.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// lfs f11,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f7,f14,f11,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fadds f12,f4,f12
	ctx.f12.f64 = double(float(ctx.f4.f64 + ctx.f12.f64));
	// stfs f12,4464(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4464, temp.u32);
	// fnmsubs f12,f3,f13,f7
	ctx.f12.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f12,f8,f13,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f8,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f12,f5,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// lfs f5,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f12,f1,f13,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fnmsubs f12,f18,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// fnmsubs f12,f9,f11,f12
	ctx.f12.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// stfs f12,4468(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4468, temp.u32);
	// lfs f12,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f15,f12
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f9,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f12,f5,f30
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmsubs f17,f16,f0,f4
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 - ctx.f4.f64));
	// lfs f4,1620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f8,f12
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f12,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f12,f28
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fmuls f12,f6,f31
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f10,f7,f28
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// fmuls f1,f9,f12
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmuls f12,f7,f30
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f15,f8,f10
	ctx.f15.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// fmuls f10,f7,f31
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f18,f9,f12
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f12,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f16,f12,f4
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// lfs f4,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f7,f4,f10
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fmuls f10,f6,f30
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f6,f4,f10
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f10,1372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f10,f10,f13,f17
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f17.f64));
	// fmuls f13,f5,f28
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmsubs f10,f10,f12,f3
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 - ctx.f3.f64));
	// lfs f3,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f9,f9,f13
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f13,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f5,f8,f13
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f8,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f12,f13
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,1700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1700);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,1540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1540);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f17,f12,f13
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f13,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmuls f14,f12,f13
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,1196(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1196, temp.u32);
	// fmuls f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmadds f11,f2,f0,f10
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f0,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f0.f64 = double(temp.f32);
	// lfs f10,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f0,f10
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfs f0,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f0,f12
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fmuls f0,f27,f25
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f2,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f8,f3,f29,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f29.f64 + ctx.f8.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f0,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f3,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f3.f64 = double(temp.f32);
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmadds f3,f0,f3,f13
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f3.f64 + ctx.f13.f64));
	// lfs f0,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f11,f1,f0,f11
	ctx.f11.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfs f13,1364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f0,f13
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fmuls f13,f12,f31
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f13,f28,f23
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// stfs f13,436(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// lfs f12,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f10,f10,f12,f8
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f8,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f13,f28,f25
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f13,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f11,f18,f13,f11
	ctx.f11.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// lfs f13,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,824(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 824, temp.u32);
	// fmuls f13,f8,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f2,f2,f8,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 + ctx.f10.f64));
	// lfs f10,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f11,f16,f10,f11
	ctx.f11.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f11.f64)));
	// fmadds f18,f12,f18,f13
	ctx.f18.f64 = double(float(ctx.f12.f64 * ctx.f18.f64 + ctx.f13.f64));
	// lfs f12,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f24,f19
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// fnmsubs f12,f12,f13,f2
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f13.f64 - ctx.f2.f64)));
	// lfs f13,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f2,f15,f13,f11
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// lfs f11,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f24,f25
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fnmsubs f16,f11,f13,f12
	ctx.f16.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// lfs f12,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f12,f7,f12,f2
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f2.f64));
	// lfs f7,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f7.f64 = double(temp.f32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f12,f6,f7,f12
	ctx.f12.f64 = double(float(-(ctx.f6.f64 * ctx.f7.f64 - ctx.f12.f64)));
	// lfs f6,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f12,f9,f7,f12
	ctx.f12.f64 = double(float(-(ctx.f9.f64 * ctx.f7.f64 - ctx.f12.f64)));
	// fmadds f12,f5,f7,f12
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f12.f64));
	// fmuls f5,f28,f21
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fnmsubs f9,f4,f10,f12
	ctx.f9.f64 = double(float(-(ctx.f4.f64 * ctx.f10.f64 - ctx.f12.f64)));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f2,f13
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f13,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f9,f17,f12,f9
	ctx.f9.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// fnmsubs f12,f14,f12,f9
	ctx.f12.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// lfs f9,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f12,f3,f0,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f12.f64));
	// lfs f3,1444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1444);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f12,f6,f9,f12
	ctx.f12.f64 = double(float(-(ctx.f6.f64 * ctx.f9.f64 - ctx.f12.f64)));
	// fmuls f6,f28,f25
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f12,f1,f10,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,4472(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4472, temp.u32);
	// lfs f12,1660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f24,f5
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// fmuls f17,f12,f13
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,1496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1496);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f14,f12,f13
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f12,f31,f28
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f15,f24,f6
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmadds f4,f12,f3,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f4.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f4,f27,f25
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f3,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f1,f1,f3,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64 - ctx.f17.f64));
	// fmsubs f3,f15,f3,f14
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 - ctx.f14.f64));
	// fmuls f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f4,1572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f6,f27
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// fmsubs f17,f12,f4,f17
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f4.f64 - ctx.f17.f64));
	// lfs f15,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f15.f64 = double(temp.f32);
	// lfs f4,1488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1488);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f1,f4,f15,f1
	ctx.f1.f64 = double(float(-(ctx.f4.f64 * ctx.f15.f64 - ctx.f1.f64)));
	// lfs f4,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// lfs f15,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f2,f2,f8,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 + ctx.f17.f64));
	// lfs f17,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f15,f4,f15
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f15.f64));
	// fnmsubs f4,f6,f13,f3
	ctx.f4.f64 = double(float(-(ctx.f6.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// lfs f6,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,188(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmadds f3,f11,f6,f18
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f6.f64 + ctx.f18.f64));
	// fmuls f6,f27,f19
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmuls f18,f6,f8
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fmuls f6,f24,f31
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmadds f1,f6,f17,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f17.f64 + ctx.f1.f64));
	// fmadds f17,f6,f19,f4
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f19.f64 + ctx.f4.f64));
	// lfs f4,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f31,f30
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f14,f6,f4
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f4,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f3,f3,f4,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 + ctx.f16.f64));
	// lfs f16,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f2,f15,f4,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f2.f64));
	// lfs f15,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f4,f26,f19
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f15,f11,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// fnmsubs f17,f14,f29,f17
	ctx.f17.f64 = double(float(-(ctx.f14.f64 * ctx.f29.f64 - ctx.f17.f64)));
	// fmadds f18,f4,f13,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f18.f64));
	// lfs f4,1532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f1,f4,f13,f1
	ctx.f1.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// lfs f4,1348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1348);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// lfs f4,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f4,f24,f21
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fnmsubs f1,f5,f13,f1
	ctx.f1.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f1.f64)));
	// lfs f5,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// fmadds f2,f11,f4,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f4.f64 + ctx.f2.f64));
	// lfs f4,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f3,f18,f4,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f3.f64));
	// fmuls f4,f26,f25
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f18,f6,f5
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f12,f27
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// stfs f6,136(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmadds f4,f4,f13,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f3.f64));
	// stfs f4,4476(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4476, temp.u32);
	// fnmsubs f4,f18,f29,f1
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// stfs f4,4480(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4480, temp.u32);
	// lfs f4,1436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1436);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f12,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// lfs f14,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f16,f16,f13,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64 - ctx.f14.f64));
	// fmuls f14,f5,f6
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,1356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1356);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f17,f6,f5,f17
	ctx.f17.f64 = double(float(-(ctx.f6.f64 * ctx.f5.f64 - ctx.f17.f64)));
	// lfs f5,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f28,f21
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fnmsubs f2,f15,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f15,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f3,f14,f13,f16
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f16.f64));
	// stfs f3,4484(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4484, temp.u32);
	// lfs f3,1336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1336);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f3,f3,f13,f17
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f17.f64)));
	// stfs f3,4488(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4488, temp.u32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f6,f15,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f6.f64));
	// fnmsubs f3,f6,f5,f2
	ctx.f3.f64 = double(float(-(ctx.f6.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f6,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f4,f4,f8,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f3.f64));
	// fmuls f6,f6,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfs f5,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f5.f64 = double(temp.f32);
	// lfs f14,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f2,f6,f28
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f6,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f6,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f6,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f18,f6,f31
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f6,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1180(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1180, temp.u32);
	// fmuls f2,f2,f9
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// fmuls f17,f0,f6
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// fmuls f6,f5,f30
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmsubs f2,f1,f9,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 - ctx.f2.f64));
	// fmuls f16,f6,f7
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmuls f7,f5,f28
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f6,f0,f23
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmuls f5,f18,f9
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// lfs f9,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f7,f6
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// lfs f7,1688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1688);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f0,f7
	ctx.f18.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f7,1696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1696);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f0,f7
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f7,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// fmsubs f5,f2,f0,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f5.f64));
	// lfs f2,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f16,f7,f14,f16
	ctx.f16.f64 = double(float(ctx.f7.f64 * ctx.f14.f64 + ctx.f16.f64));
	// lfs f7,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f9,f7
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f9,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// lfs f7,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f7,f9
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f9,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f9,f31
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// lfs f9,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f30
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fadds f7,f7,f9
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// lfs f9,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f9,f30
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f9,f0,f25
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// fmuls f9,f27,f21
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// fmuls f3,f11,f9
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f9,1704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1704);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f9,f2
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f9,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f4,f1,f9,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f4.f64));
	// lfs f9,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f1,f12,f9
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmuls f9,f0,f23
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmadds f8,f7,f9,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 + ctx.f8.f64));
	// lfs f9,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f7,f17,f10,f5
	ctx.f7.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// lfs f17,1524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1524);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f17,f10,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f2.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f4,f3,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f3,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f5,f12,f9
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// lfs f9,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f12,f3
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// lfs f12,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// stfs f9,1188(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1188, temp.u32);
	// fmadds f7,f16,f12,f7
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f7.f64));
	// lfs f12,1680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1680);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f17,f0,f12
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f16,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f12,f0,f25
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f9,f0,f9
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f9.f64));
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// fmuls f12,f26,f21
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fnmsubs f11,f1,f10,f4
	ctx.f11.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f10,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f10.f64 = double(temp.f32);
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f12,f10,f25
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fnmsubs f5,f5,f13,f11
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// lfs f11,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f11.f64 = double(temp.f32);
	// lfs f4,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f1,f16,f31
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fmuls f10,f12,f28
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f12,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f7,f6,f12,f7
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f7.f64));
	// lfs f12,1480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1480);
	ctx.f12.f64 = double(temp.f32);
	// lfs f6,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f12,f6
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// fmuls f12,f26,f25
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmadds f7,f18,f11,f7
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f7.f64));
	// lfs f18,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f4,f12,f4
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f4.f64));
	// lfs f12,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f6,f10,f12,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fmadds f10,f3,f13,f5
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f5,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f7,f15,f5,f7
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f7.f64)));
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f5,f5,f13,f10
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// lfs f10,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f14,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fmadds f13,f4,f13,f5
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f5.f64));
	// stfs f13,4492(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4492, temp.u32);
	// fmadds f13,f8,f10,f7
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f10.f64 + ctx.f7.f64));
	// lfs f10,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f13,f2,f0,f13
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f13.f64));
	// fnmsubs f13,f9,f11,f13
	ctx.f13.f64 = double(float(-(ctx.f9.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// lfs f9,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f13,f17,f11,f13
	ctx.f13.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// fnmsubs f13,f1,f10,f13
	ctx.f13.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f13.f64)));
	// lfs f10,1636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f13,f6,f0,f13
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 + ctx.f13.f64));
	// stfs f13,4496(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4496, temp.u32);
	// lfs f13,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f10,248(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f10,1428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1428);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f13,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f9,f13,f9
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f13,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f13,f11
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f11,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f7,f11,f13
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f13,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f13,f25
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fmuls f13,f11,f25
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// fmuls f5,f10,f13
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f13
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f13,1672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1672);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f3,f0,f13
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmadds f8,f10,f13,f8
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmuls f10,f18,f25
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// fmadds f8,f8,f25,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f25.f64 + ctx.f7.f64));
	// fmuls f2,f10,f21
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// lfs f10,1664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1664);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f10,f12
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f10,f22
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f22.f64));
	// fmuls f7,f10,f20
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f20.f64));
	// lfs f10,1656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1656);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f16,f10,f0
	ctx.f16.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f25
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// fmsubs f4,f4,f13,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 - ctx.f3.f64));
	// lfs f3,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f2,f13,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f1,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f4,f2,f0,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmuls f11,f11,f1
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// lfs f1,1648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1648);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f12,f1,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f2,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f14,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,1048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1048);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f10,f10,f21
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f25
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f1,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f3,f3,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// fmadds f13,f11,f13,f12
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f12,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f12,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f12,f16,f12,f4
	ctx.f12.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// lfs f11,1564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	ctx.f11.f64 = double(temp.f32);
	// lfs f4,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// lfs f11,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f11,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f16.f64));
	// lfs f11,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f11.f64 = double(temp.f32);
	// fmsubs f5,f14,f11,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 - ctx.f5.f64));
	// lfs f11,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f14,f11,f21
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f21.f64));
	// lfs f11,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f0,f0,f25
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fnmsubs f12,f10,f11,f12
	ctx.f12.f64 = double(float(-(ctx.f10.f64 * ctx.f11.f64 - ctx.f12.f64)));
	// lfs f10,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f16,f10
	ctx.f10.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// lfs f16,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f9,f9,f16,f5
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f16.f64 - ctx.f5.f64)));
	// lfs f5,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f13,f13,f5,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f12.f64));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// fmr f0,f12
	ctx.f0.f64 = ctx.f12.f64;
	// fnmsubs f12,f6,f0,f9
	ctx.f12.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// fnmsubs f9,f2,f11,f13
	ctx.f9.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// lfs f13,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f8,f13,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f9,f12,f11,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f9.f64));
	// lfs f12,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f8,f17,f12,f8
	ctx.f8.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f17,1668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f6,f10,f11,f9
	ctx.f6.f64 = double(float(-(ctx.f10.f64 * ctx.f11.f64 - ctx.f9.f64)));
	// lfs f9,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f0,f7,f0,f8
	ctx.f0.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// lfs f7,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f0,f3,f12,f0
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f0.f64));
	// fnmsubs f10,f1,f12,f0
	ctx.f10.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f0.f64)));
	// lfs f0,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f10,f15,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f15.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fnmsubs f10,f4,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fmadds f12,f14,f12,f10
	ctx.f12.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 + ctx.f10.f64));
	// stfs f12,4500(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4500, temp.u32);
	// lfs f12,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f31,f25
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// fmuls f4,f12,f28
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// lfs f12,1420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1420);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f13,f12
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f12,f28,f25
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmuls f5,f10,f9
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f2,f7,f12
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// fmuls f12,f30,f25
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f5,f5,f13
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f1,f12,f8
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// fmuls f12,f31,f28
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f7,f12,f7
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// lfs f16,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f5,f5,f11,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f11.f64 + ctx.f4.f64));
	// fmadds f1,f10,f16,f1
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f16.f64 + ctx.f1.f64));
	// lfs f15,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f10,f31,f30
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f17,f13,f17
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// fmsubs f5,f3,f0,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f5.f64));
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f16,f10,f8
	ctx.f16.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f8,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f7,f8
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f7,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f10,f15
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f15.f64));
	// lfs f10,1212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1212);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f13,f10
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f10,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fnmsubs f5,f2,f11,f5
	ctx.f5.f64 = double(float(-(ctx.f2.f64 * ctx.f11.f64 - ctx.f5.f64)));
	// lfs f2,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f12,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f4,f24,f9,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f4.f64));
	// fmuls f9,f12,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// lfs f12,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f3,f13,f10
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f10,1412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f7,f13,f7
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmadds f5,f1,f11,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f5.f64));
	// fnmsubs f8,f16,f8,f4
	ctx.f8.f64 = double(float(-(ctx.f16.f64 * ctx.f8.f64 - ctx.f4.f64)));
	// lfs f4,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f10,f4,f31
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfs f4,1204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1204);
	ctx.f4.f64 = double(temp.f32);
	// lfs f16,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f8,f15,f12,f8
	ctx.f8.f64 = double(float(-(ctx.f15.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f12,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f12.f64 = double(temp.f32);
	// fadds f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f4.f64));
	// lfs f4,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fmuls f4,f13,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// lfs f10,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f10,f30
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f10,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fnmsubs f9,f17,f0,f5
	ctx.f9.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f5.f64)));
	// lfs f5,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f8,f5,f27,f8
	ctx.f8.f64 = double(float(-(ctx.f5.f64 * ctx.f27.f64 - ctx.f8.f64)));
	// lfs f17,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f5,f12,f13
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f12,f26,f31
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f12,f24,f30
	ctx.f12.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f16,f12,f16
	ctx.f16.f64 = double(float(ctx.f12.f64 * ctx.f16.f64));
	// fnmsubs f12,f10,f11,f6
	ctx.f12.f64 = double(float(-(ctx.f10.f64 * ctx.f11.f64 - ctx.f6.f64)));
	// stfs f12,4504(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4504, temp.u32);
	// fnmsubs f10,f7,f0,f9
	ctx.f10.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// lfs f12,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f9,f12,f26,f8
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f26.f64 + ctx.f8.f64));
	// lfs f8,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f12,f24,f28
	ctx.f12.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f10,f14,f0,f10
	ctx.f10.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f10.f64));
	// fmadds f6,f8,f12,f17
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f17.f64));
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f9,f24,f12,f9
	ctx.f9.f64 = double(float(-(ctx.f24.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// lfs f8,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f12,f12,f27
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f27.f64));
	// fnmsubs f10,f3,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fmadds f9,f2,f8,f9
	ctx.f9.f64 = double(float(ctx.f2.f64 * ctx.f8.f64 + ctx.f9.f64));
	// fnmsubs f7,f7,f0,f10
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f10,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f26
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fnmsubs f9,f4,f0,f7
	ctx.f9.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,4512(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4512, temp.u32);
	// lfs f10,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f12,f5,f0,f9
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f9.f64));
	// fmadds f12,f1,f10,f12
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,4508(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4508, temp.u32);
	// fmuls f12,f31,f30
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// lfs f10,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f10.f64 = double(temp.f32);
	// lfs f5,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f24,f18
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// lfs f3,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfs f7,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f9,f7,f27
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// lfs f4,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f12,f31,f28
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmadds f7,f7,f26,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64 + ctx.f15.f64));
	// fmsubs f6,f16,f29,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f29.f64 - ctx.f6.f64));
	// lfs f16,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f3,f3,f12,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f10.f64));
	// lfs f10,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f10,f27
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// fmuls f10,f27,f22
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// fmuls f4,f4,f12
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f12,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f9,f12
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmuls f9,f26,f31
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmadds f17,f24,f20,f10
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f20.f64 + ctx.f10.f64));
	// lfs f10,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f25
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// stfs f10,460(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fmsubs f8,f3,f8,f2
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f8.f64 - ctx.f2.f64));
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f14,f9,f10
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f9,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f24,f27
	ctx.f10.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// fmadds f17,f17,f12,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 + ctx.f8.f64));
	// fmuls f8,f24,f26
	ctx.f8.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmuls f15,f14,f29
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f29.f64));
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f3,f10,f9
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f10,f26,f28
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f8,f8,f9
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// lfs f9,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f23
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// stfs f9,364(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fmuls f3,f3,f29
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f2,f2,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmuls f10,f27,f30
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmsubs f3,f8,f29,f3
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f29.f64 - ctx.f3.f64));
	// lfs f8,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f2,f2,f12,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f15.f64));
	// fmuls f14,f10,f14
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f14.f64));
	// fmuls f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f10,f26,f16
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// lfs f9,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f15,f24,f16
	ctx.f15.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// fnmsubs f6,f14,f12,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f6.f64)));
	// fadds f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f10.f64));
	// lfs f10,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f5,f5,f10,f17
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f10.f64 - ctx.f17.f64)));
	// fmuls f10,f27,f31
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f17,f9,f10
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f9,f26,f26
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f26.f64));
	// fmadds f6,f17,f29,f6
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 + ctx.f6.f64));
	// fmuls f14,f8,f9
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// fmuls f9,f24,f28
	ctx.f9.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f2,f8,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f8,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f9,f24,f30
	ctx.f9.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// lfs f8,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f8,f4,f8,f5
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f8.f64 - ctx.f5.f64)));
	// lfs f5,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f5,f9,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmuls f9,f26,f28
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmadds f1,f1,f12,f8
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f8.f64));
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f4,f9,f4
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f4.f64));
	// fmuls f9,f27,f27
	ctx.f9.f64 = double(float(ctx.f27.f64 * ctx.f27.f64));
	// lfs f17,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f3,f14,f8,f3
	ctx.f3.f64 = double(float(-(ctx.f14.f64 * ctx.f8.f64 - ctx.f3.f64)));
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f20
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f20.f64));
	// fmuls f9,f17,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f2,f17,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f17,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f5,f10,f17,f5
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f17.f64 + ctx.f5.f64));
	// lfs f10,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f10,f26
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fmadds f10,f4,f12,f6
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f6.f64));
	// stfs f10,4516(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4516, temp.u32);
	// fmuls f10,f27,f18
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// lfs f4,1396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1396);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f24,f22
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// fmadds f9,f9,f8,f3
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + ctx.f3.f64));
	// stfs f9,4520(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4520, temp.u32);
	// lfs f8,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f9,f5,f29,f2
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f29.f64 + ctx.f2.f64));
	// stfs f9,4524(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4524, temp.u32);
	// lfs f5,1628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f4,1548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1548);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f10,f10,f12,f1
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f4,f13,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// fmadds f10,f7,f12,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f10.f64));
	// lfs f7,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,1404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f13,f7
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fnmsubs f9,f15,f12,f10
	ctx.f9.f64 = double(float(-(ctx.f15.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f15,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f10,f26,f20
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// fmuls f8,f8,f11
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fnmsubs f10,f10,f12,f9
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// fmadds f8,f5,f0,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f8.f64));
	// lfs f5,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f9,f17,f12,f10
	ctx.f9.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f10,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f12,f28,f21
	ctx.f12.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fmuls f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,1556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1556);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f3,f12,f13
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f2,f10,f0
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f10.f64 = double(temp.f32);
	// fadds f1,f10,f12
	ctx.f1.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// lfs f10,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f17,f12,f10
	ctx.f17.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f12,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f15,f12,f15
	ctx.f15.f64 = double(float(ctx.f12.f64 * ctx.f15.f64));
	// fmsubs f3,f3,f11,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f2.f64));
	// lfs f11,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f13,f11
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fmuls f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fnmsubs f7,f7,f0,f3
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// lfs f3,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmuls f11,f11,f5
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// fmsubs f5,f1,f10,f17
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 - ctx.f17.f64));
	// lfs f1,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f10,f15,f10
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f15,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f1,f1,f16,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f17,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f22,f17
	ctx.f17.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// fmadds f8,f8,f13,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f7.f64));
	// lfs f7,1684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1684);
	ctx.f7.f64 = double(temp.f32);
	// fadds f7,f7,f15
	ctx.f7.f64 = double(float(ctx.f7.f64 + ctx.f15.f64));
	// lfs f15,1544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1544);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmsubs f10,f5,f12,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 - ctx.f10.f64));
	// lfs f5,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// fmuls f12,f15,f12
	ctx.f12.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// lfs f15,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmadds f10,f1,f0,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f14,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f14,f13,f14
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f14.f64));
	// lfs f13,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f8,f4,f0,f8
	ctx.f8.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f8.f64)));
	// lfs f4,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f13,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f4.f64));
	// lfs f13,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f20,f13
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f13,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f18,f13
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// fnmsubs f10,f17,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f17,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f17.f64 = double(temp.f32);
	// fmr f13,f17
	ctx.f13.f64 = ctx.f17.f64;
	// fmadds f8,f2,f0,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f8.f64));
	// lfs f2,1380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f12,f12,f0,f10
	ctx.f12.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f10,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f13,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// lfs f13,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f17,f18,f13
	ctx.f17.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f13,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f11,f11,f13,f8
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f8.f64)));
	// fnmsubs f10,f6,f10,f9
	ctx.f10.f64 = double(float(-(ctx.f6.f64 * ctx.f10.f64 - ctx.f9.f64)));
	// stfs f10,4528(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4528, temp.u32);
	// fmadds f10,f15,f0,f12
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f12.f64));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f11,f3,f12,f11
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fnmsubs f10,f1,f0,f10
	ctx.f10.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// fnmsubs f12,f5,f12,f11
	ctx.f12.f64 = double(float(-(ctx.f5.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// fmadds f12,f7,f0,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f0.f64 + ctx.f12.f64));
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f11,f11,f0,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f12,f14,f0,f12
	ctx.f12.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// fnmsubs f9,f17,f0,f11
	ctx.f9.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// lfs f11,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f13,f4,f13,f12
	ctx.f13.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f13,f2,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// stfs f13,4532(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4532, temp.u32);
	// fmuls f13,f28,f25
	ctx.f13.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// lfs f2,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f8,f13,f12
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f12,f30,f21
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fmuls f7,f12,f10
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f12,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// fmuls f6,f12,f11
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f11,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f31,f23
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f23.f64));
	// stfs f12,4788(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4788, temp.u32);
	// fmuls f6,f6,f29
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// fmuls f5,f12,f11
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f12,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f12,f25
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// fmuls f12,f30,f25
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f3,f12,f11
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f12,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f11,f12,f11,f8
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f8.f64));
	// lfs f12,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f2,f12,f2
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// fmuls f8,f12,f8
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f12,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f12,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f18,f25
	ctx.f12.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmuls f17,f11,f29
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// fmuls f11,f22,f25
	ctx.f11.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// fmuls f15,f12,f13
	ctx.f15.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f6,f4,f12,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f6.f64));
	// fmuls f4,f11,f13
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f13,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f11,1540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1540);
	ctx.f11.f64 = double(temp.f32);
	// fmsubs f7,f7,f29,f17
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f29.f64 - ctx.f17.f64));
	// fadds f14,f13,f11
	ctx.f14.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// lfs f11,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,1552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1552);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f12,f8,f12,f6
	ctx.f12.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f6.f64)));
	// fmuls f17,f13,f11
	ctx.f17.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// lfs f8,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// stfs f13,364(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// fnmsubs f7,f5,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// fmadds f9,f17,f0,f9
	ctx.f9.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f17,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f13,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f16,f13
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f13,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f5,f2,f13,f12
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f12,1372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	ctx.f12.f64 = double(temp.f32);
	// lfs f2,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	// fmuls f12,f11,f23
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// fnmsubs f7,f3,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f3.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// lfs f3,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f10,f10,f21
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// fnmsubs f9,f6,f0,f9
	ctx.f9.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// fmuls f0,f30,f25
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fnmsubs f6,f15,f13,f5
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// lfs f5,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// lfs f15,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f12,f17,f12
	ctx.f12.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// lfs f17,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f3,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// lfs f17,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f5,f0,f5
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f0,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f25
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// fmuls f17,f17,f0
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// fmuls f0,f20,f25
	ctx.f0.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmuls f15,f0,f15
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f15.f64));
	// lfs f0,1620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f7,f0,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f0.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f0,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f12,f12,f0,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f9.f64));
	// fmadds f9,f4,f13,f6
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f6.f64));
	// lfs f6,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f4.f64 = double(temp.f32);
	// fadds f6,f4,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// fmadds f7,f1,f29,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f7.f64));
	// fnmsubs f0,f17,f0,f12
	ctx.f0.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f12.f64)));
	// stfs f0,4536(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4536, temp.u32);
	// lfs f0,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f12,f8,f13,f9
	ctx.f12.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// fnmsubs f12,f10,f29,f12
	ctx.f12.f64 = double(float(-(ctx.f10.f64 * ctx.f29.f64 - ctx.f12.f64)));
	// lfs f10,1196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1196);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f0,f0,f13,f7
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// fmadds f12,f3,f13,f12
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f0,f14,f13,f0
	ctx.f0.f64 = double(float(ctx.f14.f64 * ctx.f13.f64 + ctx.f0.f64));
	// fnmsubs f12,f15,f13,f12
	ctx.f12.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// stfs f12,4540(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4540, temp.u32);
	// fnmsubs f0,f10,f13,f0
	ctx.f0.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f0.f64)));
	// lfs f12,1364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f15,f30,f28
	ctx.f15.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmadds f0,f2,f13,f0
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f0.f64));
	// fnmsubs f0,f5,f29,f0
	ctx.f0.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f0.f64)));
	// fnmsubs f0,f12,f10,f0
	ctx.f0.f64 = double(float(-(ctx.f12.f64 * ctx.f10.f64 - ctx.f0.f64)));
	// stfs f0,4544(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4544, temp.u32);
	// fmuls f0,f31,f28
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f15,f31
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fmuls f8,f0,f12
	ctx.f8.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f12,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f7,f0,f12
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// lfs f0,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f31,f30
	ctx.f12.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f5,f12,f0
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f9,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f8,f6,f15,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f15.f64 + ctx.f8.f64));
	// fmuls f4,f10,f9
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f9,f11,f23
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f3,f10,f9
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f9,f22,f28
	ctx.f9.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// fmuls f10,f16,f28
	ctx.f10.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// fadds f2,f10,f9
	ctx.f2.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// lfs f10,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f6,f10,f0
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fadds f1,f9,f10
	ctx.f1.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// lfs f10,1532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f11,f10
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f10,1356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1356);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f11,f10
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f10.f64));
	// lfs f10,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f12,f12,f10,f8
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 + ctx.f8.f64));
	// lfs f10,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f7,f10
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f4,f4,f9
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// fmuls f7,f3,f9
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// lfs f9,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f3,f9,f10
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f9,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f6,f6,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmr f12,f9
	ctx.f12.f64 = ctx.f9.f64;
	// fmuls f9,f28,f21
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fmsubs f8,f5,f10,f8
	ctx.f8.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 - ctx.f8.f64));
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fmsubs f5,f17,f12,f4
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f12.f64 - ctx.f4.f64));
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmsubs f3,f17,f10,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 - ctx.f3.f64));
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// fmuls f4,f11,f9
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f9,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f9.f64 = double(temp.f32);
	// fmsubs f7,f14,f9,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f9.f64 - ctx.f7.f64));
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f9,f28,f25
	ctx.f9.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f3,f3,f15,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f15.f64 + ctx.f2.f64));
	// lfs f2,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f9,f9,f27
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fmuls f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f10,f17,f10,f8
	ctx.f10.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f8.f64));
	// lfs f8,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f27,f8
	ctx.f8.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// lfs f17,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f5,f4,f17,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f17.f64 - ctx.f5.f64)));
	// lfs f4,1660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// lfs f17,1348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1348);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// lfs f14,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f26,f14
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f14.f64));
	// fnmsubs f6,f6,f12,f10
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f10,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f9,f9,f10,f7
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f7,1496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1496);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fnmsubs f5,f4,f10,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// lfs f4,1488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1488);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// fmadds f6,f1,f12,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f6.f64));
	// lfs f1,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f1,f1,f13,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 - ctx.f17.f64));
	// fnmsubs f9,f7,f10,f9
	ctx.f9.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f9.f64)));
	// lfs f7,1336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1336);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmsubs f8,f3,f0,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f8.f64));
	// fmuls f11,f18,f28
	ctx.f11.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f17,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f2,f26
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmadds f10,f4,f10,f5
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 + ctx.f5.f64));
	// stfs f10,4552(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4552, temp.u32);
	// lfs f10,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f6,f14,f12,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f6.f64)));
	// fmuls f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f10,4556(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4556, temp.u32);
	// fmadds f10,f7,f12,f9
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f9.f64));
	// lfs f7,1524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1524);
	ctx.f7.f64 = double(temp.f32);
	// stfs f6,4548(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4548, temp.u32);
	// lfs f6,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f6.f64 = double(temp.f32);
	// stfs f10,4560(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4560, temp.u32);
	// lfs f10,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f5,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f9,f3,f12,f8
	ctx.f9.f64 = double(float(-(ctx.f3.f64 * ctx.f12.f64 - ctx.f8.f64)));
	// lfs f4,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f10,f10,f25
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f25.f64));
	// lfs f1,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f1.f64 = double(temp.f32);
	// lfs f14,1188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1188);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f8,f11,f31
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f11,1480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1480);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fnmsubs f9,f8,f12,f9
	ctx.f9.f64 = double(float(-(ctx.f8.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// lfs f8,1680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1680);
	ctx.f8.f64 = double(temp.f32);
	// fmsubs f7,f7,f13,f11
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 - ctx.f11.f64));
	// fmuls f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fmuls f6,f11,f6
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmuls f11,f16,f25
	ctx.f11.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// fmuls f5,f11,f5
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f5.f64));
	// lfs f11,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f11.f64 = double(temp.f32);
	// fadds f4,f11,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f4.f64));
	// lfs f11,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f3,f10,f11
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f11,1704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1704);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f28,f21
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fnmsubs f7,f11,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f11,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f4,f17
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// lfs f17,1688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1688);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f5,f5,f13,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64 - ctx.f3.f64));
	// lfs f3,1696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1696);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f6,f10,f11,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f11,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f11,f26
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f26.f64));
	// fmuls f11,f31,f30
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fnmsubs f7,f14,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f14.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f14,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f14.f64 = double(temp.f32);
	// fadds f3,f3,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 + ctx.f17.f64));
	// lfs f17,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f21
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f21.f64));
	// fmadds f5,f4,f13,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f5.f64));
	// lfs f4,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f2,f14,f27,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f2.f64));
	// lfs f14,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fnmsubs f8,f8,f13,f7
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f7,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// fmuls f11,f30,f25
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// fmuls f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f14.f64));
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f10,f14
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f14.f64));
	// fmuls f10,f18,f25
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// fmadds f8,f6,f29,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f8.f64));
	// fmuls f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// fmadds f4,f2,f12,f1
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 + ctx.f1.f64));
	// lfs f2,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f11,f2
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// lfs f11,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f5,f17,f11,f5
	ctx.f5.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f5.f64)));
	// lfs f1,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f11,f30,f21
	ctx.f11.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// fadds f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f1.f64));
	// lfs f11,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// lfs f6,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f5,f10,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fmuls f6,f11,f6
	ctx.f6.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmuls f11,f20,f28
	ctx.f11.f64 = double(float(ctx.f20.f64 * ctx.f28.f64));
	// fmadds f8,f3,f13,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f8.f64));
	// fmadds f4,f4,f0,f9
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64 + ctx.f9.f64));
	// lfs f9,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f1,f1,f9,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f17.f64));
	// lfs f9,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f6,f6,f29,f5
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f29.f64 - ctx.f5.f64)));
	// fmuls f10,f0,f11
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f10,f22,f25
	ctx.f10.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// fnmsubs f8,f14,f29,f8
	ctx.f8.f64 = double(float(-(ctx.f14.f64 * ctx.f29.f64 - ctx.f8.f64)));
	// fmuls f14,f17,f9
	ctx.f14.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// lfs f17,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f10,f9
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f7,f10,f4
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f10,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f10.f64 = double(temp.f32);
	// lfs f4,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f8,f2,f29,f8
	ctx.f8.f64 = double(float(-(ctx.f2.f64 * ctx.f29.f64 - ctx.f8.f64)));
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f2,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f9,f3,f13,f6
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f6.f64));
	// lfs f6,1180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1180);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fnmsubs f7,f5,f12,f7
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f12.f64 - ctx.f7.f64)));
	// stfs f7,4564(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4564, temp.u32);
	// fnmsubs f7,f4,f13,f9
	ctx.f7.f64 = double(float(-(ctx.f4.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// lfs f5,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f9,f1,f29,f8
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f8.f64));
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// lfs f1,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f4,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// fmadds f9,f6,f8,f9
	ctx.f9.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 + ctx.f9.f64));
	// stfs f9,4568(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4568, temp.u32);
	// fmuls f9,f18,f28
	ctx.f9.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f6,1672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1672);
	ctx.f6.f64 = double(temp.f32);
	// fadds f9,f9,f11
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// lfs f11,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f9,f9,f10
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// lfs f10,1664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1664);
	ctx.f10.f64 = double(temp.f32);
	// fmsubs f6,f10,f11,f6
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f6.f64));
	// lfs f10,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f10,f26
	ctx.f3.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// fmuls f10,f26,f28
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f9,f9,f13
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// fmuls f10,f22,f30
	ctx.f10.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmsubs f9,f5,f8,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f8.f64 - ctx.f9.f64));
	// lfs f5,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f5.f64 = double(temp.f32);
	// lfs f8,1648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1648);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f10,f10,f1
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// lfs f1,1656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1656);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f6,f1,f11,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f11,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fnmsubs f8,f8,f5,f6
	ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f5.f64 - ctx.f6.f64)));
	// lfs f6,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f11,f29
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f29.f64));
	// lfs f11,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f3,f11,f27,f3
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f27.f64 + ctx.f3.f64));
	// lfs f11,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f6,f6,f18
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmuls f17,f11,f17
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// lfs f11,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f11,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f11,f22,f28
	ctx.f11.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// fmadds f5,f11,f13,f1
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 + ctx.f1.f64));
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// lfs f12,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f13,f29
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// lfs f13,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f9,f4,f13,f9
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f9.f64));
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f27
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f26.f64));
	// fadds f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// lfs f13,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f4,f3,f13
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f13,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f3,f17,f13
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f13,1172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1172);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// stfs f0,136(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f0,f27,f30
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f13,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f13.f64 = double(temp.f32);
	// lfs f17,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f8,f17,f29,f8
	ctx.f8.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f8.f64)));
	// lfs f17,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f16,f23
	ctx.f0.f64 = double(float(ctx.f16.f64 * ctx.f23.f64));
	// lfs f13,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f10,f10,f13,f9
	ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f13.f64 - ctx.f9.f64)));
	// fmadds f9,f0,f17,f6
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f17.f64 + ctx.f6.f64));
	// fmuls f0,f20,f30
	ctx.f0.f64 = double(float(ctx.f20.f64 * ctx.f30.f64));
	// fmadds f9,f9,f29,f8
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f29.f64 + ctx.f8.f64));
	// lfs f8,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f6,f0,f13,f1
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f1.f64));
	// lfs f13,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f4,f4,f13,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f3.f64));
	// lfs f0,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmsubs f4,f11,f13,f4
	ctx.f4.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f4.f64));
	// lfs f13,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,1640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1640);
	ctx.f11.f64 = double(temp.f32);
	// lfs f3,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f3,f3,f12,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 - ctx.f2.f64));
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f1,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f10,f5,f1,f10
	ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f1.f64 + ctx.f10.f64));
	// fmuls f5,f14,f23
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f23.f64));
	// lfs f14,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f1,f8,f22
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// lfs f8,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f14,f8,f14
	ctx.f14.f64 = double(float(ctx.f8.f64 * ctx.f14.f64));
	// lfs f8,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f10,f6,f13,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f10.f64));
	// lfs f13,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f6,f8,f13
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// lfs f13,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f3,f2,f13,f3
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f11
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// fnmsubs f11,f5,f29,f7
	ctx.f11.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// stfs f11,4572(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4572, temp.u32);
	// fnmsubs f11,f1,f29,f9
	ctx.f11.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f9.f64)));
	// stfs f11,4576(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4576, temp.u32);
	// lfs f11,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f26,f18
	ctx.f9.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// fmuls f7,f26,f0
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fnmsubs f10,f14,f11,f10
	ctx.f10.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// stfs f10,4580(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4580, temp.u32);
	// lfs f10,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f10,f6,f10,f4
	ctx.f10.f64 = double(float(-(ctx.f6.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// stfs f10,4584(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4584, temp.u32);
	// fmadds f12,f2,f12,f3
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 + ctx.f3.f64));
	// stfs f12,4588(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4588, temp.u32);
	// lfs f12,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f18,f30
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// fmuls f6,f12,f28
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// fmuls f12,f27,f18
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f5,f12,f13
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f12,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f23
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// fmuls f4,f12,f10
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// lfs f10,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f10.f64 = double(temp.f32);
	// lfs f3,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f27,f16,f9
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f16.f64 + ctx.f9.f64));
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f9,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f16,f28
	ctx.f10.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// fmuls f7,f7,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f22.f64));
	// fmuls f1,f27,f0
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmsubs f5,f2,f13,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 - ctx.f5.f64));
	// fmsubs f6,f3,f11,f6
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f11.f64 - ctx.f6.f64));
	// lfs f3,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f4,f9,f10,f4
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f10,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f14,f10,f30
	ctx.f14.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f10,f26,f28
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f7,f7,f13
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f2,f1,f20
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// fmadds f6,f4,f11,f6
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f11,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f11.f64 = double(temp.f32);
	// lfs f4,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmuls f10,f28,f17
	ctx.f10.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// fmsubs f7,f5,f0,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 - ctx.f7.f64));
	// fmuls f5,f3,f11
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f3,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f7,f2,f13,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f13.f64 - ctx.f7.f64)));
	// lfs f2,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fnmsubs f6,f14,f2,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f6.f64)));
	// lfs f14,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f5,f5,f13
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f8,f8,f10
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// fmuls f13,f16,f30
	ctx.f13.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmuls f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,1632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1632);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fmuls f11,f27,f30
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmuls f1,f12,f10
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f10.f64));
	// fmuls f2,f12,f13
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f13,f27,f27
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f27.f64));
	// fmuls f12,f26,f26
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f26.f64));
	// fmuls f3,f3,f11
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmuls f10,f27,f22
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// fmuls f11,f26,f16
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// fadds f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fmuls f13,f27,f26
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f14,f13,f14
	ctx.f14.f64 = double(float(ctx.f13.f64 * ctx.f14.f64));
	// lfs f13,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f13,f26,f20
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f22,f28
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// lfs f13,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f8,f8,f13,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f7.f64));
	// lfs f13,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f7,f1,f29,f6
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f6.f64)));
	// fmsubs f6,f4,f13,f5
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 - ctx.f5.f64));
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f5,f13,f0
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f13,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// lfs f0,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f4,f12,f0
	ctx.f4.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f0,-6952(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -6952);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,220(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f0,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f14,f0
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f0.f64));
	// fmuls f14,f12,f13
	ctx.f14.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f10,f10,f13,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f8.f64));
	// lfs f12,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f8,f3,f13,f6
	ctx.f8.f64 = double(float(-(ctx.f3.f64 * ctx.f13.f64 - ctx.f6.f64)));
	// lfs f13,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f9,f9,f29,f7
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// addi r6,r31,64
	ctx.r6.s64 = ctx.r31.s64 + 64;
	// fmuls f7,f13,f12
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f18,f28
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// addi r5,r29,64
	ctx.r5.s64 = ctx.r29.s64 + 64;
	// addi r4,r1,4288
	ctx.r4.s64 = ctx.r1.s64 + 4288;
	// li r3,9
	ctx.r3.s64 = 9;
	// fmuls f6,f12,f13
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f12.f64 = double(temp.f32);
	// fadds f3,f13,f12
	ctx.f3.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// lfs f12,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f13,f4,f12,f1
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 - ctx.f1.f64));
	// stfs f13,4592(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4592, temp.u32);
	// lfs f13,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f11,f11,f13,f10
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// fnmsubs f10,f2,f0,f9
	ctx.f10.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f9.f64)));
	// lfs f9,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f9,f14,f9,f8
	ctx.f9.f64 = double(float(ctx.f14.f64 * ctx.f9.f64 + ctx.f8.f64));
	// lfs f8,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// stfs f9,4596(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4596, temp.u32);
	// lfs f9,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f9.f64 = double(temp.f32);
	// lfs f14,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f14.f64 = double(temp.f32);
	// fadds f9,f3,f9
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f9.f64));
	// fmadds f13,f8,f13,f11
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f11.f64));
	// fmadds f11,f5,f0,f10
	ctx.f11.f64 = double(float(ctx.f5.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f10,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f22,f20
	ctx.f8.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// fnmsubs f13,f7,f10,f13
	ctx.f13.f64 = double(float(-(ctx.f7.f64 * ctx.f10.f64 - ctx.f13.f64)));
	// stfs f13,4600(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4600, temp.u32);
	// fnmsubs f13,f6,f0,f11
	ctx.f13.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f11.f64)));
	// stfs f13,4604(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4604, temp.u32);
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f22,f16
	ctx.f10.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// fmuls f13,f14,f13
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f7,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f7.f64 = double(temp.f32);
	// lfs f11,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f11.f64 = double(temp.f32);
	// fadds f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fmuls f9,f18,f20
	ctx.f9.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// fmuls f7,f16,f18
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f18.f64));
	// fmadds f13,f11,f12,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfs f12,1552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1552);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f10,f0,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f13.f64));
	// fnmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f12,1544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1544);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f9,f0,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f13.f64));
	// fnmsubs f13,f8,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fnmsubs f13,f12,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fnmsubs f0,f7,f0,f13
	ctx.f0.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// stfs f0,4608(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4608, temp.u32);
	// bl 0x82b31838
	ctx.lr = 0x82B36E64;
	sub_82B31838(ctx, base);
	// cmplwi cr6,r28,5
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 5, ctx.xer);
	// bgt cr6,0x82b36e70
	if (ctx.cr6.gt) goto loc_82B36E70;
	// b 0x82b43b90
	goto loc_82B43B90;
loc_82B36E70:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f3,280(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f22,f23
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// stfs f4,780(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 780, temp.u32);
	// fmuls f13,f18,f17
	ctx.f13.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// stfs f13,260(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f11,f20,f19
	ctx.f11.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// stfs f11,1308(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1308, temp.u32);
	// fmuls f7,f16,f17
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// stfs f7,364(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// lfd f0,-416(r11)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + -416);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fsqrts f12,f0
	ctx.f12.f64 = double(float(sqrt(ctx.f0.f64)));
	// lfs f0,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f0.f64 = double(temp.f32);
	// stfs f12,1472(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1472, temp.u32);
	// fmuls f10,f16,f0
	ctx.f10.f64 = double(float(ctx.f16.f64 * ctx.f0.f64));
	// fmuls f2,f11,f0
	ctx.f2.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f5,f20,f17
	ctx.f5.f64 = double(float(ctx.f20.f64 * ctx.f17.f64));
	// lfd f9,-408(r11)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r11.u32 + -408);
	// fsqrts f8,f9
	ctx.f8.f64 = double(float(sqrt(ctx.f9.f64)));
	// fmuls f9,f12,f3
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f3.f64));
	// fmuls f6,f10,f19
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// fmuls f1,f13,f28
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f10,456(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// fmuls f10,f10,f28
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// stfs f5,684(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 684, temp.u32);
	// stfs f8,148(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f9,240(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fmuls f9,f20,f20
	ctx.f9.f64 = double(float(ctx.f20.f64 * ctx.f20.f64));
	// stfs f10,256(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f10,f18,f28
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// stfs f9,208(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmuls f9,f22,f22
	ctx.f9.f64 = double(float(ctx.f22.f64 * ctx.f22.f64));
	// stfs f9,496(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// fmuls f9,f16,f16
	ctx.f9.f64 = double(float(ctx.f16.f64 * ctx.f16.f64));
	// stfs f9,484(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// fmuls f9,f18,f18
	ctx.f9.f64 = double(float(ctx.f18.f64 * ctx.f18.f64));
	// stfs f9,512(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// fmuls f9,f18,f0
	ctx.f9.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// stfs f9,344(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// fmuls f9,f4,f17
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f9,f13,f23
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// stfs f9,516(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// fmuls f9,f8,f12
	ctx.f9.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f12,f22,f28
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// stfs f12,416(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f12,f20,f28
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f28.f64));
	// stfs f12,472(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// fmuls f12,f22,f17
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f17.f64));
	// stfs f12,648(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 648, temp.u32);
	// fmuls f12,f13,f16
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f16.f64));
	// stfs f12,4024(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4024, temp.u32);
	// fmuls f12,f13,f20
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f20.f64));
	// stfs f12,360(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// fmuls f12,f22,f13
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// stfs f12,420(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// fmuls f12,f22,f19
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f19.f64));
	// stfs f12,576(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// fmuls f12,f16,f28
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// stfs f12,264(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f12,f18,f30
	ctx.f12.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// stfs f12,252(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmuls f12,f16,f30
	ctx.f12.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// stfs f12,676(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 676, temp.u32);
	// fmuls f12,f22,f30
	ctx.f12.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// stfs f12,184(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fmuls f12,f20,f30
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f30.f64));
	// stfs f12,316(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// fmuls f12,f20,f23
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// stfs f12,368(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// lfs f12,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f12,f26,f13
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f12,4032(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4032, temp.u32);
	// fmuls f12,f7,f20
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f20.f64));
	// stfs f12,2360(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2360, temp.u32);
	// fmuls f12,f6,f23
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f12,2300(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2300, temp.u32);
	// fmuls f12,f2,f23
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f12,100(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmuls f12,f7,f22
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f22.f64));
	// stfs f12,2124(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2124, temp.u32);
	// fmuls f12,f5,f22
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// stfs f12,2024(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2024, temp.u32);
	// fmuls f12,f6,f30
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f12,2540(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2540, temp.u32);
	// lfs f12,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,340(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// lfs f12,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,3880(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3880, temp.u32);
	// lfs f12,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,352(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// lfs f12,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,2140(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2140, temp.u32);
	// fmuls f12,f4,f14
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f14.f64));
	// stfs f12,2208(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2208, temp.u32);
	// lfs f12,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f6,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f12,f6
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f6.f64));
	// stfs f6,1824(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1824, temp.u32);
	// lfs f6,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,4272(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4272, temp.u32);
	// lfs f6,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,3420(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3420, temp.u32);
	// fmuls f6,f28,f17
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// stfs f6,656(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 656, temp.u32);
	// stfs f10,392(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmuls f10,f26,f5
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// stfs f10,2176(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2176, temp.u32);
	// lfs f10,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// stfs f10,1044(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1044, temp.u32);
	// fmuls f10,f26,f12
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// stfs f10,872(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 872, temp.u32);
	// lfs f10,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f30
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// stfs f10,880(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 880, temp.u32);
	// fmuls f10,f26,f7
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f10,2264(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2264, temp.u32);
	// lfs f10,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// stfs f6,2492(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2492, temp.u32);
	// fmuls f6,f28,f0
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// stfs f6,200(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// stfs f10,2076(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2076, temp.u32);
	// fmuls f10,f27,f30
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f10,1284(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1284, temp.u32);
	// fmuls f6,f6,f4
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// stfs f6,2516(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2516, temp.u32);
	// fmuls f6,f1,f19
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f6,3412(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3412, temp.u32);
	// lfs f6,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f23
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f6,2500(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2500, temp.u32);
	// fmuls f6,f2,f30
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfd f2,-440(r11)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + -440);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f6,4096(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4096, temp.u32);
	// fmuls f6,f27,f13
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// stfs f6,4212(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4212, temp.u32);
	// fmuls f6,f9,f0
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// stfs f6,568(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// fsqrts f2,f2
	ctx.f2.f64 = double(float(sqrt(ctx.f2.f64)));
	// stfs f2,332(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfd f1,-456(r11)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -456);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fsqrts f1,f1
	ctx.f1.f64 = double(float(sqrt(ctx.f1.f64)));
	// stfs f1,388(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fmuls f1,f27,f27
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f27.f64));
	// fmuls f6,f26,f28
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f1,752(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 752, temp.u32);
	// lfd f1,-512(r11)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -512);
	// fsqrts f1,f1
	ctx.f1.f64 = double(float(sqrt(ctx.f1.f64)));
	// stfs f1,180(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f1,f26,f26
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f26.f64));
	// fmuls f7,f27,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// stfs f1,772(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 772, temp.u32);
	// fmuls f1,f26,f30
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// stfs f7,2084(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2084, temp.u32);
	// fmuls f7,f27,f5
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// stfs f1,372(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f1,248(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// fmuls f1,f16,f23
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f23.f64));
	// stfs f1,176(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f1,f26,f17
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f17.f64));
	// stfs f1,1292(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1292, temp.u32);
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f1,2788(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2788, temp.u32);
	// fmuls f1,f26,f23
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// stfs f1,292(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fmuls f1,f2,f16
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// stfs f1,584(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// fmuls f1,f26,f20
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// stfs f1,800(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 800, temp.u32);
	// fmuls f1,f26,f16
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// stfs f7,2288(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2288, temp.u32);
	// stfs f1,832(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 832, temp.u32);
	// fmuls f7,f9,f17
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// fmuls f1,f2,f18
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f7,1128(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1128, temp.u32);
	// stfs f1,712(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 712, temp.u32);
	// fmuls f7,f27,f12
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmuls f1,f2,f22
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f7,1016(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1016, temp.u32);
	// stfs f1,500(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fmuls f1,f2,f20
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// lfs f7,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f7.f64 = double(temp.f32);
	// stfs f1,776(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 776, temp.u32);
	// fmuls f5,f2,f7
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f1,f11,f28
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// stfs f1,1220(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1220, temp.u32);
	// stfs f5,1940(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1940, temp.u32);
	// fmuls f5,f10,f14
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f14.f64));
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// stfs f5,2132(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2132, temp.u32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f5,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// stfs f1,2224(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2224, temp.u32);
	// fmuls f5,f6,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f1,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f1.f64 = double(temp.f32);
	// stfs f5,1236(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1236, temp.u32);
	// fmuls f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f5,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f5.f64 = double(temp.f32);
	// stfs f1,2200(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2200, temp.u32);
	// fmuls f1,f6,f5
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// stfs f1,2116(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2116, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f10,f1
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// stfs f1,1300(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1300, temp.u32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// stfs f7,1316(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1316, temp.u32);
	// lfs f7,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f10,f7
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// stfs f7,2148(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2148, temp.u32);
	// lfs f7,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f7,2188(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2188, temp.u32);
	// lfs f7,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f7,2276(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2276, temp.u32);
	// fmuls f7,f6,f12
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// stfs f7,2284(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2284, temp.u32);
	// fmuls f7,f9,f23
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// stfs f7,760(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 760, temp.u32);
	// fmuls f7,f9,f19
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f19.f64));
	// stfs f7,532(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// lfs f7,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f26,f7
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// stfs f1,2308(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2308, temp.u32);
	// fmuls f7,f27,f7
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// stfs f7,2332(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2332, temp.u32);
	// fmuls f7,f18,f23
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f23.f64));
	// stfs f7,476(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// lfs f7,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f7.f64 = double(temp.f32);
	// lfs f1,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f7,f1
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// fmuls f7,f27,f28
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmuls f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f5,4228(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4228, temp.u32);
	// lfs f5,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f7,4220(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4220, temp.u32);
	// fmuls f7,f15,f12
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// stfs f7,840(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 840, temp.u32);
	// lfs f7,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f7.f64 = double(temp.f32);
	// lfs f5,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f5,4236(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4236, temp.u32);
	// fmuls f7,f7,f14
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f14.f64));
	// stfs f7,3484(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3484, temp.u32);
	// lfs f5,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f5.f64 = double(temp.f32);
	// lfs f7,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f7,3404(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3404, temp.u32);
	// lfs f7,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f7,2772(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2772, temp.u32);
	// fmuls f7,f6,f0
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// lfs f5,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,2156(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2156, temp.u32);
	// lfs f7,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f7,2228(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2228, temp.u32);
	// lfs f7,2788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2788);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f26
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f7,2908(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2908, temp.u32);
	// lfs f7,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f7,2828(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2828, temp.u32);
	// fmuls f7,f1,f30
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f7,3556(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3556, temp.u32);
	// lfs f7,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// lfs f5,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f5,2780(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2780, temp.u32);
	// lfs f5,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f7,3548(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3548, temp.u32);
	// lfs f7,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f7,2180(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2180, temp.u32);
	// lfs f7,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,1244(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1244, temp.u32);
	// fmuls f7,f6,f19
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,2164(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2164, temp.u32);
	// lfs f7,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f7,f6
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// stfs f5,2196(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2196, temp.u32);
	// fmuls f5,f27,f28
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmuls f1,f5,f12
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f1,3628(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3628, temp.u32);
	// fmuls f5,f7,f5
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// stfs f5,3980(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3980, temp.u32);
	// lfs f5,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// stfs f5,4144(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4144, temp.u32);
	// lfs f5,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,4128(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4128, temp.u32);
	// lfs f5,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,2932(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2932, temp.u32);
	// lfs f5,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// stfs f5,3620(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3620, temp.u32);
	// lfs f5,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// stfs f5,2916(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2916, temp.u32);
	// lfs f5,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f10
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64));
	// stfs f5,3972(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3972, temp.u32);
	// fmuls f5,f7,f15
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// stfs f5,524(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// lfs f5,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f5,f26
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// stfs f1,2316(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2316, temp.u32);
	// fmuls f5,f5,f27
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// stfs f5,2292(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2292, temp.u32);
	// lfs f5,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,3652(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3652, temp.u32);
	// fmuls f5,f7,f27
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f5,876(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 876, temp.u32);
	// lfs f5,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f5,f23
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f1,308(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fmuls f1,f11,f21
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f21.f64));
	// stfs f1,1984(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1984, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f1,80(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f1,f13,f19
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// stfs f1,756(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 756, temp.u32);
	// fmuls f1,f20,f21
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f21.f64));
	// stfs f1,164(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f1,f22,f25
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// stfs f1,108(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f1,f18,f21
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f21.f64));
	// stfs f1,128(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmuls f1,f20,f0
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// stfs f1,560(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// fmuls f1,f22,f21
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// stfs f1,704(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 704, temp.u32);
	// fmuls f1,f11,f17
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// stfs f1,552(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f1,508(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fmuls f1,f16,f21
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f21.f64));
	// stfs f1,536(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// fmuls f1,f18,f25
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// stfs f1,792(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 792, temp.u32);
	// fmuls f1,f5,f17
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// stfs f1,544(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f1,f4,f0
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// stfs f1,216(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmuls f1,f16,f19
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f19.f64));
	// stfs f1,152(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f1,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,2348(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2348, temp.u32);
	// lfs f1,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// stfs f1,2340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2340, temp.u32);
	// fmuls f1,f7,f26
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f1,708(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 708, temp.u32);
	// lfs f1,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,748(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 748, temp.u32);
	// fmuls f1,f26,f4
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// stfs f1,4152(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4152, temp.u32);
	// fmuls f1,f27,f4
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// stfs f1,2980(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2980, temp.u32);
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// stfs f1,2844(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2844, temp.u32);
	// fmuls f1,f5,f28
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// fmuls f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f1,3580(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3580, temp.u32);
	// lfs f1,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f5,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// fmuls f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// stfs f1,3948(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3948, temp.u32);
	// lfs f1,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// stfs f1,2820(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2820, temp.u32);
	// stfs f5,2296(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2296, temp.u32);
	// fmuls f5,f14,f13
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// stfs f5,2040(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2040, temp.u32);
	// lfs f5,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f18
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// stfs f5,2056(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2056, temp.u32);
	// fmuls f5,f11,f0
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// fmuls f5,f5,f17
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// stfs f5,2216(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2216, temp.u32);
	// lfs f5,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// stfs f5,2900(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2900, temp.u32);
	// fmuls f5,f4,f16
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// stfs f5,3660(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3660, temp.u32);
	// lfs f5,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,2672(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2672, temp.u32);
	// lfs f5,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,3020(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3020, temp.u32);
	// lfs f5,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,3228(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3228, temp.u32);
	// fmuls f5,f4,f18
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// stfs f5,2988(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2988, temp.u32);
	// fmuls f5,f4,f20
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// stfs f5,3988(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3988, temp.u32);
	// lfs f5,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,2048(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2048, temp.u32);
	// fmuls f5,f18,f19
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// stfs f5,204(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// fmuls f5,f18,f20
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f1,f5,f30
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f1,4208(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4208, temp.u32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,1252(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1252, temp.u32);
	// fmuls f5,f16,f20
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// fmuls f1,f16,f20
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,2032(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2032, temp.u32);
	// fmuls f5,f22,f20
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,2804(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2804, temp.u32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,3940(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3940, temp.u32);
	// fmuls f5,f18,f16
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,1840(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1840, temp.u32);
	// fmuls f5,f22,f16
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,3564(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3564, temp.u32);
	// fmuls f5,f22,f18
	ctx.f5.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f5,2836(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2836, temp.u32);
	// lfs f5,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// stfs f5,3304(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3304, temp.u32);
	// lfs f1,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f1.f64 = double(temp.f32);
	// lfs f5,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// stfs f5,2860(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2860, temp.u32);
	// lfs f5,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// stfs f5,3960(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3960, temp.u32);
	// lfs f5,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f25
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// stfs f5,3904(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3904, temp.u32);
	// lfs f5,1984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1984);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f23
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// stfs f5,3936(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3936, temp.u32);
	// lfs f5,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f7
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// stfs f5,2944(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2944, temp.u32);
	// lfs f5,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f5,3976(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3976, temp.u32);
	// lfs f5,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// stfs f5,3992(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3992, temp.u32);
	// lfs f5,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// lfs f1,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f1,3968(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3968, temp.u32);
	// lfs f1,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// stfs f1,3928(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3928, temp.u32);
	// lfs f1,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// stfs f7,3896(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3896, temp.u32);
	// lfs f7,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f3,f17
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// fmuls f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// stfs f7,3944(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3944, temp.u32);
	// lfs f7,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f21
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// stfs f7,3920(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3920, temp.u32);
	// lfs f7,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f12,3848(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3848, temp.u32);
	// lfs f7,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f12,3888(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3888, temp.u32);
	// lfs f12,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f21
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// stfs f12,2384(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2384, temp.u32);
	// lfs f12,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfs f12,3872(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3872, temp.u32);
	// lfs f7,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f12,2696(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2696, temp.u32);
	// lfs f12,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f1,336(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// stfs f12,4008(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4008, temp.u32);
	// fmuls f1,f27,f23
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// lfs f12,1984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1984);
	ctx.f12.f64 = double(temp.f32);
	// stfs f1,320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f7,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f7.f64 = double(temp.f32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// stfs f12,4016(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4016, temp.u32);
	// fmuls f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fmuls f12,f2,f7
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f1,528(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// fmuls f7,f4,f21
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// stfs f7,296(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f7,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f25
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// stfs f7,1812(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1812, temp.u32);
	// fmuls f7,f13,f25
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// stfs f7,1004(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1004, temp.u32);
	// fmuls f7,f3,f0
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// stfs f7,616(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// fmuls f7,f27,f19
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// stfs f7,80(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f7,f26,f25
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// stfs f7,572(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// fmuls f7,f27,f25
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// stfs f7,652(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 652, temp.u32);
	// fmuls f7,f10,f31
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// stfs f7,136(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f7,f22,f31
	ctx.f7.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// stfs f7,1056(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1056, temp.u32);
	// fmuls f7,f22,f0
	ctx.f7.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// stfs f7,988(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 988, temp.u32);
	// fmuls f7,f16,f25
	ctx.f7.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// stfs f7,492(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// lfs f7,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,3912(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3912, temp.u32);
	// fmuls f7,f5,f30
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// stfs f7,1536(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1536, temp.u32);
	// fmuls f7,f18,f31
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// stfs f7,3384(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3384, temp.u32);
	// stfs f12,972(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 972, temp.u32);
	// fmuls f7,f5,f28
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// stfs f7,1080(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1080, temp.u32);
	// lfs f7,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,4000(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4000, temp.u32);
	// lfs f7,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,3952(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3952, temp.u32);
	// fmuls f7,f5,f27
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// stfs f7,1620(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1620, temp.u32);
	// fmuls f7,f28,f25
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// stfs f7,172(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,1108(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1108, temp.u32);
	// fmuls f7,f3,f21
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// stfs f7,1076(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1076, temp.u32);
	// lfs f7,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,3432(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3432, temp.u32);
	// fmuls f7,f3,f16
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// stfs f7,680(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 680, temp.u32);
	// fmuls f7,f28,f21
	ctx.f7.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// stfs f7,232(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,1116(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1116, temp.u32);
	// fmuls f7,f3,f18
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// stfs f7,1280(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1280, temp.u32);
	// lfs f7,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,2204(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2204, temp.u32);
	// lfs f7,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1120(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1120, temp.u32);
	// lfs f7,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,4796(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4796, temp.u32);
	// lfs f7,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1588(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1588, temp.u32);
	// lfs f7,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1644(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1644, temp.u32);
	// lfs f7,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1248(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1248, temp.u32);
	// fmuls f7,f5,f26
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// stfs f7,1364(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1364, temp.u32);
	// lfs f7,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// stfs f7,1296(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1296, temp.u32);
	// fmuls f7,f3,f13
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// stfs f7,692(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 692, temp.u32);
	// lfs f7,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,4188(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4188, temp.u32);
	// lfs f7,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// stfs f7,4040(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4040, temp.u32);
	// lfs f7,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,804(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 804, temp.u32);
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f5,f7,f28
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f5,1336(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1336, temp.u32);
	// fmuls f5,f7,f30
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f5,460(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fmuls f5,f28,f23
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// stfs f5,436(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f5,1088(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1088, temp.u32);
	// fmuls f5,f7,f26
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f5,3472(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3472, temp.u32);
	// fmuls f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f7,3488(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3488, temp.u32);
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// lfs f5,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f7,3416(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3416, temp.u32);
	// fmuls f5,f5,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f7,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f7.f64 = double(temp.f32);
	// stfs f5,3424(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3424, temp.u32);
	// fmuls f5,f7,f19
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// stfs f7,1144(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1144, temp.u32);
	// fmuls f7,f12,f17
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f7,732(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 732, temp.u32);
	// lfs f7,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f7,3984(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3984, temp.u32);
	// lfs f7,1812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1812);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,4772(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4772, temp.u32);
	// lfs f7,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f7,1856(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1856, temp.u32);
	// lfs f7,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// stfs f7,860(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 860, temp.u32);
	// lfs f7,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// stfs f5,464(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fmuls f5,f31,f30
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1096(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1096, temp.u32);
	// fmuls f7,f12,f0
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f7,236(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// fmuls f12,f12,f21
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// stfs f12,728(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 728, temp.u32);
	// lfs f12,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,1980(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1980, temp.u32);
	// lfs f7,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,600(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// fmuls f12,f26,f19
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// stfs f7,820(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 820, temp.u32);
	// lfs f7,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,852(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 852, temp.u32);
	// lfs f7,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,696(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 696, temp.u32);
	// lfs f7,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,4140(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4140, temp.u32);
	// fmuls f7,f12,f31
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f7,1152(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1152, temp.u32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f12,2256(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2256, temp.u32);
	// lfs f12,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f12,4132(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4132, temp.u32);
	// fmuls f12,f1,f17
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f12,1228(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1228, temp.u32);
	// fmuls f12,f27,f28
	ctx.f12.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f7,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f5,f7
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// stfs f7,580(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// lfs f7,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// stfs f7,4180(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4180, temp.u32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1276(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1276, temp.u32);
	// fmuls f12,f1,f0
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f12,764(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 764, temp.u32);
	// fmuls f12,f11,f23
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// stfs f12,836(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 836, temp.u32);
	// fmuls f12,f4,f19
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// stfs f12,376(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmuls f12,f6,f23
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f12,520(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// fmuls f12,f26,f21
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// stfs f12,632(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 632, temp.u32);
	// fmuls f12,f3,f23
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// stfs f12,948(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 948, temp.u32);
	// fmuls f12,f11,f25
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// stfs f12,2352(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2352, temp.u32);
	// fmuls f12,f4,f25
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// stfs f12,892(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 892, temp.u32);
	// lfs f12,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f21
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// stfs f12,2160(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2160, temp.u32);
	// lfs f7,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f13,f21
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,700(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 700, temp.u32);
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,4056(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4056, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// lfs f7,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f1
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// stfs f7,612(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// fmuls f1,f10,f31
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// stfs f12,900(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 900, temp.u32);
	// fmuls f12,f20,f25
	ctx.f12.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// stfs f12,396(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// fmuls f12,f6,f31
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// fmuls f7,f1,f28
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f7,4156(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4156, temp.u32);
	// lfs f7,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f19
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// stfs f7,668(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 668, temp.u32);
	// fmuls f7,f1,f19
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f7,4172(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4172, temp.u32);
	// lfs f7,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,4124(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4124, temp.u32);
	// lfs f7,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f23
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// stfs f12,4148(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4148, temp.u32);
	// stfs f7,1092(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1092, temp.u32);
	// fmuls f7,f27,f17
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// lfs f12,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f12.f64 = double(temp.f32);
	// stfs f7,644(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 644, temp.u32);
	// fmuls f7,f12,f18
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// stfs f7,824(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 824, temp.u32);
	// fmuls f7,f15,f31
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// stfs f7,2212(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2212, temp.u32);
	// fmuls f7,f12,f19
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f19.f64));
	// stfs f7,428(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// stfs f7,1736(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1736, temp.u32);
	// lfs f7,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// stfs f7,1880(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1880, temp.u32);
	// fmuls f7,f12,f23
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// stfs f7,816(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 816, temp.u32);
	// fmuls f7,f12,f20
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f20.f64));
	// stfs f7,1744(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1744, temp.u32);
	// fmuls f12,f12,f16
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f16.f64));
	// stfs f12,312(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fmuls f12,f3,f19
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// stfs f12,1100(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1100, temp.u32);
	// lfs f12,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,3496(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3496, temp.u32);
	// fmuls f12,f3,f25
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// stfs f12,1168(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1168, temp.u32);
	// fmuls f12,f3,f22
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// stfs f12,1104(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1104, temp.u32);
	// fmuls f12,f3,f20
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// stfs f12,604(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// fmuls f12,f18,f28
	ctx.f12.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f7,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// stfs f7,4204(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4204, temp.u32);
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f27
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// stfs f7,1428(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1428, temp.u32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,1460(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1460, temp.u32);
	// lfs f12,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,3504(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3504, temp.u32);
	// fmuls f12,f3,f11
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// stfs f12,1160(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1160, temp.u32);
	// fmuls f12,f3,f4
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f12,1444(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1444, temp.u32);
	// lfs f12,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,4268(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4268, temp.u32);
	// lfs f12,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f30
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f12,620(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// lfs f12,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f28.f64));
	// stfs f12,1580(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1580, temp.u32);
	// lfs f12,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f12,4260(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4260, temp.u32);
	// lfs f12,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,3844(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3844, temp.u32);
	// lfs f13,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f12,4244(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4244, temp.u32);
	// lfs f12,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fmuls f7,f12,f31
	ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// stfs f7,4252(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4252, temp.u32);
	// fmuls f7,f6,f17
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// stfs f13,4284(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4284, temp.u32);
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfs f12,3356(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3356, temp.u32);
	// lfs f12,1812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1812);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,2436(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2436, temp.u32);
	// lfs f12,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f21
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// stfs f12,4184(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4184, temp.u32);
	// lfs f12,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,4108(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4108, temp.u32);
	// fmuls f7,f6,f21
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,4048(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4048, temp.u32);
	// lfs f7,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,4116(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4116, temp.u32);
	// fmuls f7,f6,f25
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,4164(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4164, temp.u32);
	// lfs f7,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,1564(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1564, temp.u32);
	// lfs f7,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f10,f7
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// stfs f7,1816(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1816, temp.u32);
	// lfs f7,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f7,588(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// lfs f7,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f7,1272(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1272, temp.u32);
	// lfs f7,2352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2352);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,4776(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4776, temp.u32);
	// lfs f7,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f7,4784(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4784, temp.u32);
	// lfs f7,2160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2160);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// stfs f7,4800(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4800, temp.u32);
	// lfs f7,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f28
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// stfs f7,4780(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4780, temp.u32);
	// lfs f7,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// stfs f12,4276(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4276, temp.u32);
	// lfs f7,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// stfs f12,2420(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2420, temp.u32);
	// lfs f7,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f12,3380(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3380, temp.u32);
	// lfs f12,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f12,f7
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// stfs f12,2396(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2396, temp.u32);
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,2412(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2412, temp.u32);
	// lfs f12,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,4080(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4080, temp.u32);
	// lfs f12,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,2404(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2404, temp.u32);
	// lfs f13,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f21
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// stfs f13,2428(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2428, temp.u32);
	// lfs f12,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,4072(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4072, temp.u32);
	// lfs f13,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f21
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// stfs f13,3364(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3364, temp.u32);
	// lfs f13,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f21
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// lfs f7,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f7.f64 = double(temp.f32);
	// stfs f13,3372(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3372, temp.u32);
	// fmuls f13,f7,f17
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f17.f64));
	// stfs f13,548(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// fmuls f13,f7,f19
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// stfs f13,608(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// fmuls f13,f7,f23
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f23.f64));
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// stfs f13,796(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 796, temp.u32);
	// fmuls f13,f12,f23
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f23.f64));
	// stfs f13,736(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 736, temp.u32);
	// fmuls f13,f12,f19
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f19.f64));
	// stfs f13,540(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// fmuls f13,f12,f17
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f13,788(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 788, temp.u32);
	// fmuls f13,f7,f0
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f13,980(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 980, temp.u32);
	// fmuls f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f13,1448(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1448, temp.u32);
	// lfs f13,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,3396(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3396, temp.u32);
	// lfs f13,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,2468(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2468, temp.u32);
	// lfs f13,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// stfs f13,3388(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3388, temp.u32);
	// fmuls f13,f9,f21
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// stfs f13,2600(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2600, temp.u32);
	// lfs f13,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,3860(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3860, temp.u32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// stfs f13,2220(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2220, temp.u32);
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,2616(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2616, temp.u32);
	// fmuls f13,f9,f16
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f16.f64));
	// stfs f13,1052(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1052, temp.u32);
	// lfs f13,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// stfs f13,3852(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3852, temp.u32);
	// lfs f13,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// stfs f13,2364(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2364, temp.u32);
	// fmuls f13,f3,f28
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// stfs f13,1504(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1504, temp.u32);
	// lfs f13,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,2252(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2252, temp.u32);
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,1328(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1328, temp.u32);
	// lfs f13,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f13,1912(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1912, temp.u32);
	// fmuls f13,f4,f30
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f13,848(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 848, temp.u32);
	// lfs f13,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,2260(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2260, temp.u32);
	// lfs f13,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f13,1728(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1728, temp.u32);
	// fmuls f13,f11,f30
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f13,2028(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2028, temp.u32);
	// lfs f13,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f30
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f11,2268(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2268, temp.u32);
	// lfs f11,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// stfs f11,1372(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1372, temp.u32);
	// lfs f11,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f25
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// stfs f11,1452(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1452, temp.u32);
	// lfs f11,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// stfs f11,740(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 740, temp.u32);
	// lfs f11,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// stfs f11,2508(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2508, temp.u32);
	// lfs f11,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f11,2236(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2236, temp.u32);
	// lfs f11,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f23
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// stfs f11,3436(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3436, temp.u32);
	// lfs f11,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f19
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// stfs f11,4192(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4192, temp.u32);
	// lfs f11,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f11,1920(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1920, temp.u32);
	// lfs f11,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f11,2244(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2244, temp.u32);
	// lfs f11,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// stfs f11,812(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 812, temp.u32);
	// lfs f11,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f17
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// stfs f11,2484(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2484, temp.u32);
	// lfs f11,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f14
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f14.f64));
	// stfs f11,2532(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2532, temp.u32);
	// lfs f11,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f15
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// stfs f13,2612(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2612, temp.u32);
	// stfs f11,4240(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4240, temp.u32);
	// fmuls f13,f24,f23
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f11,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f11.f64 = double(temp.f32);
	// stfs f13,504(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fmuls f11,f11,f15
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// lfs f13,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,3876(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3876, temp.u32);
	// fmuls f11,f22,f13
	ctx.f11.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f13,f20,f13
	ctx.f13.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// stfs f13,2452(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2452, temp.u32);
	// lfs f13,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f23
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f23.f64));
	// stfs f13,2592(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2592, temp.u32);
	// lfs f13,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,2460(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2460, temp.u32);
	// fmuls f11,f13,f28
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,1520(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1520, temp.u32);
	// stfs f11,1332(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1332, temp.u32);
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// stfs f13,2476(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2476, temp.u32);
	// lfs f13,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f13,2012(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2012, temp.u32);
	// lfs f13,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f28
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// stfs f11,1876(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1876, temp.u32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,1264(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1264, temp.u32);
	// lfs f13,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f13,2548(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2548, temp.u32);
	// lfs f13,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// lfs f11,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f11.f64 = double(temp.f32);
	// stfs f13,2596(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2596, temp.u32);
	// fmuls f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f13,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,2044(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2044, temp.u32);
	// fmuls f11,f27,f13
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fmuls f13,f26,f13
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f13,2572(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2572, temp.u32);
	// lfs f13,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2524(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2524, temp.u32);
	// lfs f13,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,3892(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3892, temp.u32);
	// fmuls f13,f30,f25
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// stfs f13,664(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 664, temp.u32);
	// stfs f11,3444(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3444, temp.u32);
	// lfs f11,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f13,1312(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1312, temp.u32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// stfs f11,3884(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3884, temp.u32);
	// lfs f11,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// stfs f11,1040(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1040, temp.u32);
	// lfs f11,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f15,f11
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// stfs f11,2580(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2580, temp.u32);
	// lfs f11,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// stfs f13,3468(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3468, temp.u32);
	// lfs f13,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f27,f13
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// stfs f11,3452(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3452, temp.u32);
	// fmuls f13,f26,f13
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f13,3428(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3428, temp.u32);
	// lfs f13,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f13,188(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f13,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// lfs f11,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f11.f64 = double(temp.f32);
	// stfs f13,2588(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2588, temp.u32);
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f13,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,3644(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3644, temp.u32);
	// fmuls f13,f14,f13
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// lfs f11,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f11.f64 = double(temp.f32);
	// stfs f13,2556(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2556, temp.u32);
	// fmuls f11,f15,f11
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f13,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,2620(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2620, temp.u32);
	// fmuls f11,f13,f3
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// fmuls f13,f24,f30
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// stfs f13,468(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fmuls f13,f27,f21
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// stfs f13,1084(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1084, temp.u32);
	// fmuls f13,f24,f17
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// stfs f13,272(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// lfs f13,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f20
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f20.f64));
	// stfs f13,2380(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2380, temp.u32);
	// lfs f13,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f14
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f14.f64));
	// stfs f13,4104(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4104, temp.u32);
	// lfs f13,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,2564(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2564, temp.u32);
	// lfs f13,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// stfs f11,380(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,3460(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3460, temp.u32);
	// fmuls f13,f31,f25
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f25.f64));
	// stfs f13,212(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmuls f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f13,1060(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1060, temp.u32);
	// fmuls f13,f26,f31
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// stfs f13,1304(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1304, temp.u32);
	// lfs f13,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// stfs f13,3476(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3476, temp.u32);
	// fmuls f13,f27,f31
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// stfs f13,1288(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1288, temp.u32);
	// fmuls f13,f24,f28
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// stfs f13,1192(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1192, temp.u32);
	// lfs f13,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,2628(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2628, temp.u32);
	// fmuls f13,f1,f21
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f13,2636(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2636, temp.u32);
	// lfs f13,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f24,f13
	ctx.f13.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// stfs f13,3900(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3900, temp.u32);
	// lfs f13,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2644(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2644, temp.u32);
	// lfs f13,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2660(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2660, temp.u32);
	// fmuls f13,f1,f25
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f13,3492(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3492, temp.u32);
	// lfs f13,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2668(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2668, temp.u32);
	// lfs f13,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,3908(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3908, temp.u32);
	// lfs f13,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// stfs f13,2676(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2676, temp.u32);
	// fmuls f13,f2,f12
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f13,1712(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1712, temp.u32);
	// fmuls f13,f2,f7
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f13,2928(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2928, temp.u32);
	// lfs f13,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2684(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2684, temp.u32);
	// lfs f13,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,2708(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2708, temp.u32);
	// lfs f13,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,4120(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4120, temp.u32);
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,3532(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3532, temp.u32);
	// lfs f13,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// stfs f13,3524(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3524, temp.u32);
	// lfs f13,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,2748(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2748, temp.u32);
	// lfs f13,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f15
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f15.f64));
	// stfs f13,1760(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1760, temp.u32);
	// lfs f13,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f13,1832(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1832, temp.u32);
	// lfs f13,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f14,f13
	ctx.f13.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// stfs f13,2692(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2692, temp.u32);
	// lfs f13,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f13,3516(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3516, temp.u32);
	// lfs f13,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// stfs f13,3540(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3540, temp.u32);
	// lfs f13,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// lfs f1,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// stfs f13,2716(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2716, temp.u32);
	// lfs f13,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f27,f13
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// stfs f1,2740(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2740, temp.u32);
	// fmuls f13,f26,f13
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// stfs f13,3924(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3924, temp.u32);
	// lfs f13,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// lfs f1,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f1.f64 = double(temp.f32);
	// stfs f13,2732(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2732, temp.u32);
	// fmuls f13,f26,f1
	ctx.f13.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// stfs f13,1896(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1896, temp.u32);
	// fmuls f13,f30,f21
	ctx.f13.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// stfs f13,284(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f13,2972(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2972, temp.u32);
	// fmuls f13,f27,f1
	ctx.f13.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f13,2724(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2724, temp.u32);
	// lfs f13,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f13,4264(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4264, temp.u32);
	// lfs f13,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f15,f13
	ctx.f13.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// stfs f13,2756(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2756, temp.u32);
	// fmuls f13,f2,f11
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f2,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f11,f2,f11
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f1,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1136(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1136, temp.u32);
	// fmuls f2,f26,f12
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f1,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,4112(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4112, temp.u32);
	// fmuls f2,f24,f20
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2652(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2652, temp.u32);
	// lfs f2,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f2,1064(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1064, temp.u32);
	// fmuls f2,f24,f18
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,4200(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4200, temp.u32);
	// fmuls f2,f7,f30
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// stfs f2,2700(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2700, temp.u32);
	// fmuls f2,f24,f22
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,3508(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3508, temp.u32);
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2764(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2764, temp.u32);
	// lfs f2,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3932(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3932, temp.u32);
	// lfs f2,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3916(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3916, temp.u32);
	// lfs f2,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,724(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 724, temp.u32);
	// fmuls f2,f3,f7
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// stfs f2,1176(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1176, temp.u32);
	// lfs f2,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f30
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f1,2108(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2108, temp.u32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,1544(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1544, temp.u32);
	// lfs f2,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1072(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1072, temp.u32);
	// lfs f2,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1512(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1512, temp.u32);
	// lfs f2,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// lfs f1,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f1.f64 = double(temp.f32);
	// stfs f2,1892(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1892, temp.u32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// stfs f1,1884(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1884, temp.u32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f2,2852(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2852, temp.u32);
	// fmuls f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f2,2924(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2924, temp.u32);
	// lfs f1,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1752(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1752, temp.u32);
	// lfs f2,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3500(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3500, temp.u32);
	// fmuls f2,f13,f19
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f19.f64));
	// stfs f2,300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f2,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,768(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 768, temp.u32);
	// fmuls f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f2,1132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1132, temp.u32);
	// fmuls f2,f7,f25
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// stfs f2,636(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 636, temp.u32);
	// fmuls f1,f12,f25
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfs f1,624(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// fmuls f2,f20,f7
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// stfs f2,884(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 884, temp.u32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f7,f21
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f21.f64));
	// stfs f1,408(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// fmuls f1,f2,f17
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f2,440(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// lfs f2,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f2,4136(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4136, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1900(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1900, temp.u32);
	// lfs f2,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,1320(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1320, temp.u32);
	// lfs f2,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// stfs f2,3408(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3408, temp.u32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,3208(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3208, temp.u32);
	// stfs f1,384(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3612(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3612, temp.u32);
	// lfs f2,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f2,4248(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4248, temp.u32);
	// lfs f2,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f7
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f1,2884(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2884, temp.u32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,2868(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2868, temp.u32);
	// lfs f2,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,2892(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2892, temp.u32);
	// lfs f2,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,2876(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2876, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3216(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3216, temp.u32);
	// lfs f2,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,3604(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3604, temp.u32);
	// lfs f2,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3240(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3240, temp.u32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f2,3232(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3232, temp.u32);
	// fmuls f2,f12,f21
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f21.f64));
	// stfs f2,744(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 744, temp.u32);
	// lfs f1,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,1216(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1216, temp.u32);
	// lfs f1,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1224(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1224, temp.u32);
	// lfs f1,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f1,1956(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1956, temp.u32);
	// lfs f1,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2312(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2312, temp.u32);
	// lfs f2,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,1256(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1256, temp.u32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,2052(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2052, temp.u32);
	// lfs f2,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,2036(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2036, temp.u32);
	// lfs f2,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f2,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3092(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3092, temp.u32);
	// lfs f2,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2280(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2280, temp.u32);
	// lfs f1,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1916(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1916, temp.u32);
	// lfs f1,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2104(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2104, temp.u32);
	// lfs f2,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1844(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1844, temp.u32);
	// fmuls f2,f5,f1
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f2,2120(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2120, temp.u32);
	// lfs f2,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// stfs f2,2016(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2016, temp.u32);
	// lfs f2,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// stfs f2,1232(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1232, temp.u32);
	// fmuls f2,f31,f28
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// stfs f2,224(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,2064(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2064, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f1,2248(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2248, temp.u32);
	// fmuls f1,f24,f25
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// stfs f1,1260(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1260, temp.u32);
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1952(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1952, temp.u32);
	// fmuls f2,f24,f21
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// stfs f2,1140(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1140, temp.u32);
	// fmuls f2,f15,f24
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// stfs f2,4196(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4196, temp.u32);
	// lfs f2,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// stfs f2,1820(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1820, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f0
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f1,1924(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1924, temp.u32);
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f17
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// stfs f2,908(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 908, temp.u32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// lfs f2,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f2.f64 = double(temp.f32);
	// stfs f1,2008(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2008, temp.u32);
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// stfs f2,3956(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3956, temp.u32);
	// fmuls f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// lfs f2,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f2.f64 = double(temp.f32);
	// stfs f1,784(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 784, temp.u32);
	// fmuls f1,f2,f30
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f1,1936(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1936, temp.u32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,2192(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2192, temp.u32);
	// lfs f1,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2092(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2092, temp.u32);
	// lfs f2,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f21
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f1,1972(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1972, temp.u32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,1456(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1456, temp.u32);
	// lfs f1,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,356(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// lfs f2,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f19
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// stfs f1,2020(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2020, temp.u32);
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f2,1996(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1996, temp.u32);
	// lfs f1,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3048(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3048, temp.u32);
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// stfs f2,1960(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1960, temp.u32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f5,f2
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f1,2136(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2136, temp.u32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2304(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2304, temp.u32);
	// fmuls f2,f4,f28
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// stfs f2,1012(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1012, temp.u32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f1,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2184(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2184, temp.u32);
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1932(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1932, temp.u32);
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f5,f2
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f1,2320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2320, temp.u32);
	// fmuls f1,f15,f2
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f1,2080(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2080, temp.u32);
	// lfs f1,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f1,3004(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3004, temp.u32);
	// lfs f1,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// stfs f1,2528(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2528, temp.u32);
	// lfs f1,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// stfs f1,444(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f3,f1,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// stfs f3,592(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// lfs f3,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f3,f0
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// stfs f1,1968(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1968, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f1,256(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f1,248(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f1,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// stfs f1,2356(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2356, temp.u32);
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f1,3012(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3012, temp.u32);
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f1,2372(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2372, temp.u32);
	// lfs f1,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2368(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2368, temp.u32);
	// lfs f1,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,1716(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1716, temp.u32);
	// lfs f2,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f2,2172(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2172, temp.u32);
	// fmuls f2,f3,f17
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// stfs f2,4088(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4088, temp.u32);
	// fmuls f2,f12,f12
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// stfs f2,1124(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1124, temp.u32);
	// fmuls f2,f3,f16
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// stfs f2,2444(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2444, temp.u32);
	// fmuls f2,f7,f7
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f7.f64));
	// stfs f2,1268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1268, temp.u32);
	// lfs f2,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f18
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f1,4280(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4280, temp.u32);
	// fmuls f1,f2,f21
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f1,2112(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2112, temp.u32);
	// fmuls f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// stfs f2,1836(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1836, temp.u32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,2240(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2240, temp.u32);
	// lfs f1,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2272, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1148(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1148, temp.u32);
	// lfs f2,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3868(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3868, temp.u32);
	// lfs f1,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2604(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2604, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2000(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2000, temp.u32);
	// lfs f2,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,856(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 856, temp.u32);
	// lfs f2,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,1184(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1184, temp.u32);
	// lfs f2,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,808(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 808, temp.u32);
	// lfs f2,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f26,f2
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// stfs f1,1908(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1908, temp.u32);
	// fmuls f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// stfs f2,1828(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1828, temp.u32);
	// lfs f2,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2004(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2004, temp.u32);
	// lfs f2,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,2128(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2128, temp.u32);
	// lfs f2,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,2376(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2376, temp.u32);
	// lfs f2,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// stfs f2,1740(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1740, temp.u32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// fmuls f2,f24,f24
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f24.f64));
	// stfs f2,1464(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1464, temp.u32);
	// stfs f1,2072(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2072, temp.u32);
	// lfs f2,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1988(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1988, temp.u32);
	// lfs f2,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f26,f2
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// stfs f1,1756(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1756, temp.u32);
	// fmuls f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// stfs f2,1764(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1764, temp.u32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// stfs f2,628(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,844(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 844, temp.u32);
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,1944(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1944, temp.u32);
	// lfs f1,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,1772(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1772, temp.u32);
	// lfs f2,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f2,2964(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2964, temp.u32);
	// lfs f2,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,1732(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1732, temp.u32);
	// lfs f1,1968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1968);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,1784(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1784, temp.u32);
	// lfs f1,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,924(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 924, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,1992(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1992, temp.u32);
	// lfs f1,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,2144(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2144, temp.u32);
	// lfs f1,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f1,2996(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2996, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f1,136(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,1240(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1240, temp.u32);
	// lfs f1,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3668(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3668, temp.u32);
	// fmuls f2,f22,f12
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// stfs f2,3572(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3572, temp.u32);
	// lfs f1,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,1780(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1780, temp.u32);
	// fmuls f2,f20,f12
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// stfs f2,1864(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1864, temp.u32);
	// fmuls f2,f22,f7
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f7.f64));
	// stfs f2,2324(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2324, temp.u32);
	// fmuls f2,f16,f7
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// stfs f2,1768(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1768, temp.u32);
	// fmuls f2,f16,f12
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// stfs f2,1776(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1776, temp.u32);
	// fmuls f2,f7,f12
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f2,2152(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2152, temp.u32);
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2168(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2168, temp.u32);
	// fmuls f2,f18,f12
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f12.f64));
	// stfs f2,2796(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2796, temp.u32);
	// fmuls f2,f18,f7
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f7.f64));
	// stfs f2,2812(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2812, temp.u32);
	// fmuls f2,f3,f4
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f2,3596(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3596, temp.u32);
	// lfs f2,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f2,3964(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3964, temp.u32);
	// fmuls f2,f3,f23
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// stfs f2,2096(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2096, temp.u32);
	// fmuls f2,f3,f20
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// stfs f2,3588(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3588, temp.u32);
	// lfs f2,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f2,3400(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3400, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f2,3264(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3264, temp.u32);
	// lfs f1,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3312(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3312, temp.u32);
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3360(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3360, temp.u32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3328, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,3676(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3676, temp.u32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f3
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f1,916(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 916, temp.u32);
	// fmuls f1,f3,f21
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// stfs f1,1872(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1872, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1800(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1800, temp.u32);
	// lfs f2,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2100(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2100, temp.u32);
	// lfs f2,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f3,f2
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f2,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f2,3044(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3044, temp.u32);
	// lfs f2,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,332(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1688(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1688, temp.u32);
	// lfs f2,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1640(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1640, temp.u32);
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f2,1680(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1680, temp.u32);
	// fmuls f2,f4,f17
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1672(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1672, temp.u32);
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,3028(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3028, temp.u32);
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// stfs f2,3272(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3272, temp.u32);
	// fmuls f2,f18,f16
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,3336(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3336, temp.u32);
	// lfs f2,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// stfs f2,1552(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1552, temp.u32);
	// fmuls f2,f1,f21
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f2,1648(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1648, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,3036(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3036, temp.u32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3052(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3052, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// lfs f1,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1632(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1632, temp.u32);
	// lfs f2,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,4004(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4004, temp.u32);
	// fmr f2,f1
	ctx.f2.f64 = ctx.f1.f64;
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3684(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3684, temp.u32);
	// lfs f2,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3392(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3392, temp.u32);
	// lfs f1,2444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2444);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3060(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3060, temp.u32);
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3376(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3376, temp.u32);
	// lfs f2,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,4224(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4224, temp.u32);
	// lfs f2,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f12
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f2,3068(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3068, temp.u32);
	// lfs f2,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f0
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f1,1868(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1868, temp.u32);
	// fmuls f1,f2,f21
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f1,1792(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1792, temp.u32);
	// lfs f1,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// stfs f1,2060(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2060, temp.u32);
	// fmuls f1,f2,f23
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f1,2088(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2088, temp.u32);
	// lfs f1,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1496(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1496, temp.u32);
	// fmuls f1,f2,f17
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// stfs f1,1860(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1860, temp.u32);
	// fmuls f1,f2,f19
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// stfs f1,1708(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1708, temp.u32);
	// lfs f1,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f1,4012(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4012, temp.u32);
	// fmuls f1,f16,f2
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// stfs f1,2232(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2232, temp.u32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1848(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1848, temp.u32);
	// fmuls f2,f7,f28
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f28.f64));
	// lfs f1,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,3100(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3100, temp.u32);
	// lfs f1,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f18
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// stfs f1,1976(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1976, temp.u32);
	// lfs f1,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,1948(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1948, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1660(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1660, temp.u32);
	// lfs f2,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f2,2068(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2068, temp.u32);
	// lfs f2,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1488, temp.u32);
	// lfs f2,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,3076(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3076, temp.u32);
	// lfs f2,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,1480(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1480, temp.u32);
	// lfs f2,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1704(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1704, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3700(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3700, temp.u32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// fmuls f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// stfs f2,3084(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3084, temp.u32);
	// fmuls f2,f4,f17
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1524(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1524, temp.u32);
	// lfs f2,1872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1872);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,1348(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1348, temp.u32);
	// lfs f1,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// stfs f1,4160(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4160, temp.u32);
	// lfs f1,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,1656(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1656, temp.u32);
	// lfs f1,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// stfs f1,3692(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3692, temp.u32);
	// lfs f1,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1664(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1664, temp.u32);
	// lfs f2,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,1696(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1696, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// lfs f1,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1356(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1356, temp.u32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1888(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1888, temp.u32);
	// lfs f2,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f2,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,3132(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3132, temp.u32);
	// lfs f2,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,4028(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4028, temp.u32);
	// lfs f2,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,4256(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4256, temp.u32);
	// lfs f1,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3116(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3116, temp.u32);
	// fmr f2,f1
	ctx.f2.f64 = ctx.f1.f64;
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3732(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3732, temp.u32);
	// lfs f2,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,3740(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3740, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,4020(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4020, temp.u32);
	// lfs f2,1800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1800);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f27
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f1,3124(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3124, temp.u32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,3724(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3724, temp.u32);
	// lfs f2,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f24
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f1,3716(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3716, temp.u32);
	// lfs f1,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,4168(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4168, temp.u32);
	// stfs f2,3188(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3188, temp.u32);
	// lfs f1,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,3148(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3148, temp.u32);
	// lfs f1,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// stfs f1,3708(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3708, temp.u32);
	// lfs f1,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,3156(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3156, temp.u32);
	// lfs f1,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f1,3172(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3172, temp.u32);
	// lfs f1,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,3108(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3108, temp.u32);
	// lfs f1,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// stfs f1,3180(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3180, temp.u32);
	// lfs f1,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,4176(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4176, temp.u32);
	// lfs f1,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,4036(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4036, temp.u32);
	// fmuls f2,f27,f20
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// stfs f2,1532(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1532, temp.u32);
	// fmuls f2,f27,f22
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// stfs f2,1208(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1208, temp.u32);
	// fmuls f2,f26,f18
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// stfs f2,1468(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1468, temp.u32);
	// fmuls f2,f27,f16
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// stfs f2,1112(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1112, temp.u32);
	// fmuls f2,f27,f18
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// stfs f2,1200(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1200, temp.u32);
	// lfs f2,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,3140(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3140, temp.u32);
	// lfs f1,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1020(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1020, temp.u32);
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,3748(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3748, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3164(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3164, temp.u32);
	// lfs f2,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f0
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f1,1852(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1852, temp.u32);
	// fmuls f1,f2,f17
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// stfs f1,1964(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1964, temp.u32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1808(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1808, temp.u32);
	// fmuls f2,f24,f31
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmuls f1,f2,f14
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f1,3196(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3196, temp.u32);
	// lfs f1,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// stfs f1,1380(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1380, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,3756(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3756, temp.u32);
	// lfs f1,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f1,1668(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1668, temp.u32);
	// lfs f1,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f1,1412(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1412, temp.u32);
	// lfs f1,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// stfs f1,1540(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1540, temp.u32);
	// lfs f1,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f1,1388(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1388, temp.u32);
	// lfs f1,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// stfs f1,1420(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1420, temp.u32);
	// fmuls f1,f10,f31
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// stfs f1,1684(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1684, temp.u32);
	// lfs f1,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// stfs f1,3236(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3236, temp.u32);
	// lfs f1,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,4064(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4064, temp.u32);
	// fmuls f1,f6,f0
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1628(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1628, temp.u32);
	// lfs f1,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f1,3440(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3440, temp.u32);
	// lfs f1,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// stfs f1,3204(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3204, temp.u32);
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,3220(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3220, temp.u32);
	// lfs f1,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f1,3448(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3448, temp.u32);
	// fmuls f1,f2,f26
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f1,1788(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1788, temp.u32);
	// fmuls f1,f2,f27
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f1,3780(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3780, temp.u32);
	// lfs f1,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,3764(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3764, temp.u32);
	// lfs f1,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f1,1396(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1396, temp.u32);
	// lfs f1,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// stfs f1,1548(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1548, temp.u32);
	// lfs f1,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// stfs f1,3212(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3212, temp.u32);
	// lfs f1,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,4044(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4044, temp.u32);
	// lfs f1,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,3456(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3456, temp.u32);
	// fmuls f1,f10,f31
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// fmuls f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// stfs f1,1556(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1556, temp.u32);
	// fmuls f1,f6,f19
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1404(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1404, temp.u32);
	// lfs f1,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// stfs f1,4076(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4076, temp.u32);
	// lfs f1,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// stfs f1,4216(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4216, temp.u32);
	// lfs f1,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f19
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// stfs f1,2940(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2940, temp.u32);
	// lfs f1,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f1,3480(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3480, temp.u32);
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// stfs f1,1636(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1636, temp.u32);
	// fmuls f1,f7,f31
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// stfs f1,80(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f1,4052(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4052, temp.u32);
	// fmuls f1,f27,f12
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,3788(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3788, temp.u32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f26,f1
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// stfs f1,3244(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3244, temp.u32);
	// fmuls f1,f2,f16
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// stfs f1,3276(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3276, temp.u32);
	// fmuls f1,f26,f12
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,3772(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3772, temp.u32);
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f1,1436(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1436, temp.u32);
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f10
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// stfs f1,1572(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1572, temp.u32);
	// lfs f1,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// stfs f1,1700(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1700, temp.u32);
	// lfs f1,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// stfs f1,3464(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3464, temp.u32);
	// fmuls f1,f2,f22
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f1,3300(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3300, temp.u32);
	// fmuls f1,f2,f18
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f1,3804(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3804, temp.u32);
	// fmuls f2,f2,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// stfs f2,4100(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4100, temp.u32);
	// lfs f2,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// stfs f2,3812(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3812, temp.u32);
	// lfs f2,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,3308(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3308, temp.u32);
	// lfs f2,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,3340(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3340, temp.u32);
	// lfs f2,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,2392(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2392, temp.u32);
	// lfs f2,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f14,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f2.f64));
	// stfs f2,2448(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2448, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2456(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2456, temp.u32);
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,2464(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2464, temp.u32);
	// lfs f1,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f14.f64));
	// stfs f1,3828(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3828, temp.u32);
	// lfs f1,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3324(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3324, temp.u32);
	// lfs f1,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2956(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2956, temp.u32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3268(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3268, temp.u32);
	// lfs f2,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// stfs f2,4084(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4084, temp.u32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,4060(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4060, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,2948(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2948, temp.u32);
	// fmuls f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f2,2344(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2344, temp.u32);
	// fmuls f2,f3,f25
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// stfs f2,224(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// lfs f2,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f2,3996(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3996, temp.u32);
	// fmuls f2,f27,f1
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f2,3332(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3332, temp.u32);
	// lfs f1,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,412(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,2948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2948);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f26,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// stfs f2,4068(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4068, temp.u32);
	// lfs f2,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3260(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3260, temp.u32);
	// lfs f2,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3636(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3636, temp.u32);
	// lfs f2,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,3796(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3796, temp.u32);
	// lfs f2,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f24
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f1,3252(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3252, temp.u32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,4092(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4092, temp.u32);
	// lfs f2,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,3292(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3292, temp.u32);
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,3284(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3284, temp.u32);
	// lfs f2,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,3316(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3316, temp.u32);
	// lfs f2,2372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2372);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2472(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2472, temp.u32);
	// lfs f2,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,1492(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1492, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f1,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// stfs f1,3820(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3820, temp.u32);
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1344(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1344, temp.u32);
	// lfs f2,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,940(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 940, temp.u32);
	// fmuls f2,f18,f20
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3528(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3528, temp.u32);
	// fmuls f2,f22,f20
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3552(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3552, temp.u32);
	// lfs f2,1776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1776);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2480(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2480, temp.u32);
	// lfs f2,3572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3572);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2440(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2440, temp.u32);
	// fmuls f2,f22,f18
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1516(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1516, temp.u32);
	// lfs f2,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1484(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1484, temp.u32);
	// fmuls f2,f16,f20
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,1476(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1476, temp.u32);
	// lfs f2,2812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2812);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2400(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2400, temp.u32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2408(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2408, temp.u32);
	// lfs f2,1864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1864);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2424(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2424, temp.u32);
	// lfs f2,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,1676(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1676, temp.u32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2432(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2432, temp.u32);
	// lfs f2,1768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1768);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2416(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2416, temp.u32);
	// fmuls f2,f22,f16
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3592(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3592, temp.u32);
	// lfs f2,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,4232(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4232, temp.u32);
	// fmuls f2,f18,f16
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3568(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3568, temp.u32);
	// lfs f2,2796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2796);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3836(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3836, temp.u32);
	// lfs f2,2356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2356);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2388(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2388, temp.u32);
	// lfs f2,2324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2324);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,3348(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3348, temp.u32);
	// lfs f2,3964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3964);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1508(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1508, temp.u32);
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,3544(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3544, temp.u32);
	// fmuls f2,f22,f18
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1692(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1692, temp.u32);
	// lfs f2,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1612(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1612, temp.u32);
	// fmuls f2,f22,f16
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3512(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3512, temp.u32);
	// lfs f2,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3600(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3600, temp.u32);
	// lfs f2,2344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2344);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// stfs f2,2512(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2512, temp.u32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1652(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1652, temp.u32);
	// lfs f2,3996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3996);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1368(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1368, temp.u32);
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3584(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3584, temp.u32);
	// lfs f2,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f7
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// stfs f2,2520(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2520, temp.u32);
	// lfs f1,3588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3588);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2488, temp.u32);
	// fmuls f2,f22,f20
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3576(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3576, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f19
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1340(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1340, temp.u32);
	// lfs f2,2324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2324);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,2544(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2544, temp.u32);
	// fmuls f2,f18,f20
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,3520(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3520, temp.u32);
	// lfs f2,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2576(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2576, temp.u32);
	// lfs f1,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2560(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2560, temp.u32);
	// lfs f2,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1604(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1604, temp.u32);
	// lfs f2,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,2552(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2552, temp.u32);
	// fmuls f2,f4,f17
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// fmuls f2,f2,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// stfs f2,1500(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1500, temp.u32);
	// lfs f2,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2568(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2568, temp.u32);
	// lfs f2,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// stfs f2,3536(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3536, temp.u32);
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,1360(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1360, temp.u32);
	// fmuls f2,f3,f19
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// stfs f2,2328(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2328, temp.u32);
	// lfs f1,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,3688(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3688, temp.u32);
	// lfs f2,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// lfs f1,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f1.f64 = double(temp.f32);
	// stfs f2,2584(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2584, temp.u32);
	// fmuls f2,f1,f18
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// stfs f2,3560(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3560, temp.u32);
	// fmuls f2,f16,f20
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// stfs f2,1596(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1596, temp.u32);
	// fmuls f2,f1,f7
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// stfs f2,2536(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2536, temp.u32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// stfs f3,1724(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1724, temp.u32);
	// lfs f3,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f3,f20
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// stfs f2,1376(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1376, temp.u32);
	// fmuls f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f2,1984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1984);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,2632(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2632, temp.u32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f3,2344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2344);
	ctx.f3.f64 = double(temp.f32);
	// stfs f2,2624(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2624, temp.u32);
	// fmuls f2,f3,f18
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// stfs f2,2496(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2496, temp.u32);
	// fmuls f3,f3,f16
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// lfs f2,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2608(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2608, temp.u32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f4
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// stfs f2,1324(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1324, temp.u32);
	// lfs f2,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f3,2504(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2504, temp.u32);
	// stfs f2,1384(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1384, temp.u32);
	// fmuls f3,f27,f24
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// lfs f2,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,80(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmr f3,f2
	ctx.f3.f64 = ctx.f2.f64;
	// fmuls f2,f3,f22
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// stfs f2,2664(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2664, temp.u32);
	// lfs f2,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f3,f3,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,1352(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1352, temp.u32);
	// lfs f2,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f22
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f2,1408(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1408, temp.u32);
	// lfs f2,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f23
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f3,1796(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1796, temp.u32);
	// stfs f2,1400(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1400, temp.u32);
	// lfs f2,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f3,3640(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3640, temp.u32);
	// lfs f3,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// stfs f3,2656(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2656, temp.u32);
	// lfs f3,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// stfs f3,2648(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2648, temp.u32);
	// lfs f3,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f12
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f12.f64));
	// lfs f2,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,2640(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2640, temp.u32);
	// fmuls f3,f2,f23
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// stfs f3,1392(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1392, temp.u32);
	// lfs f3,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f4,3672(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3672, temp.u32);
	// lfs f3,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// stfs f4,3704(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3704, temp.u32);
	// lfs f4,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f1,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f4,f23
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// stfs f4,3656(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3656, temp.u32);
	// lfs f4,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f4,3648(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3648, temp.u32);
	// lfs f4,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// fmuls f4,f4,f19
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// stfs f4,3632(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3632, temp.u32);
	// fmuls f4,f2,f30
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f4,3624(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3624, temp.u32);
	// lfs f4,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// stfs f4,2680(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2680, temp.u32);
	// lfs f4,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f4,3712(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3712, temp.u32);
	// lfs f4,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f4,3680(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3680, temp.u32);
	// lfs f4,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f26
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// stfs f4,1432(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1432, temp.u32);
	// lfs f2,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// stfs f4,2840(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2840, temp.u32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// stfs f4,2704(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2704, temp.u32);
	// lfs f4,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f26,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// stfs f4,2816(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2816, temp.u32);
	// lfs f4,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f15,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// stfs f4,1804(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1804, temp.u32);
	// lfs f4,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f26,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// stfs f4,2784(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2784, temp.u32);
	// fmuls f4,f31,f28
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f1,2800(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2800, temp.u32);
	// lfs f1,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2824(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2824, temp.u32);
	// lfs f2,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// stfs f2,2768(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2768, temp.u32);
	// lfs f2,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f2,2792(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2792, temp.u32);
	// lfs f2,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// stfs f2,2752(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2752, temp.u32);
	// lfs f2,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f24
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f1,2760(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2760, temp.u32);
	// lfs f1,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f1,2808(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2808, temp.u32);
	// lfs f1,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1440(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1440, temp.u32);
	// lfs f1,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// stfs f1,1424(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1424, temp.u32);
	// fmuls f1,f26,f2
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// fmuls f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// stfs f2,1036(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1036, temp.u32);
	// lfs f2,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,952(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 952, temp.u32);
	// lfs f2,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,2848(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2848, temp.u32);
	// stfs f1,1416(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1416, temp.u32);
	// lfs f1,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f2,2744(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2744, temp.u32);
	// stfs f1,2776(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2776, temp.u32);
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,1156(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1156, temp.u32);
	// lfs f2,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f2,2736(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2736, temp.u32);
	// lfs f2,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f4,f2
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// stfs f2,2832(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2832, temp.u32);
	// lfs f1,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2720(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2720, temp.u32);
	// lfs f2,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// stfs f2,2712(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2712, temp.u32);
	// lfs f2,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f4,f2
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// stfs f2,2688(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2688, temp.u32);
	// lfs f2,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f2,1028(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1028, temp.u32);
	// lfs f2,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f1,2728(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2728, temp.u32);
	// fmuls f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// stfs f2,888(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 888, temp.u32);
	// fmuls f2,f6,f14
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// stfs f2,960(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 960, temp.u32);
	// lfs f2,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f6,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// stfs f2,968(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 968, temp.u32);
	// lfs f1,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmuls f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// stfs f2,1000(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1000, temp.u32);
	// stfs f1,2856(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2856, temp.u32);
	// lfs f1,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stfs f2,2864(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2864, temp.u32);
	// lfs f2,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f2,2872(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2872, temp.u32);
	// fmuls f2,f26,f0
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f23,f2,f24
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f23,2880(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2880, temp.u32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f2,928(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 928, temp.u32);
	// fmuls f2,f10,f1
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// stfs f2,904(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 904, temp.u32);
	// fmuls f2,f6,f17
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f1,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,896(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 896, temp.u32);
	// lfs f2,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2888(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2888, temp.u32);
	// fmuls f2,f6,f21
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2896(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2896, temp.u32);
	// fmuls f2,f27,f28
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,2952(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2952, temp.u32);
	// lfs f2,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,1748(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1748, temp.u32);
	// lfs f2,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,912(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 912, temp.u32);
	// fmuls f2,f27,f19
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f2,2904(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2904, temp.u32);
	// fmuls f2,f26,f19
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// fmuls f23,f2,f24
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f23,2920(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2920, temp.u32);
	// fmuls f2,f2,f27
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f23,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f23.f64 = double(temp.f32);
	// stfs f2,944(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 944, temp.u32);
	// fmuls f2,f23,f10
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// stfs f2,984(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 984, temp.u32);
	// fmuls f2,f6,f25
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f2,2936(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2936, temp.u32);
	// lfs f2,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// stfs f2,2968(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2968, temp.u32);
	// lfs f2,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f27,f7
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// stfs f2,2976(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2976, temp.u32);
	// fmuls f2,f24,f22
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// fmuls f1,f24,f16
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,1720(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1720, temp.u32);
	// lfs f2,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// stfs f2,936(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 936, temp.u32);
	// fmuls f2,f24,f20
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,2912(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2912, temp.u32);
	// fmuls f2,f27,f12
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,996(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 996, temp.u32);
	// fmuls f2,f24,f18
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// stfs f2,3032(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3032, temp.u32);
	// lfs f2,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f10,f2,f10
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// stfs f10,920(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 920, temp.u32);
	// lfs f10,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f4,f10
	ctx.f10.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// stfs f10,3040(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3040, temp.u32);
	// fmuls f10,f1,f28
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// stfs f10,3008(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3008, temp.u32);
	// fmuls f10,f23,f28
	ctx.f10.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// stfs f10,3000(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3000, temp.u32);
	// lfs f10,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// lfs f2,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f10,f2
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// stfs f2,3152(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3152, temp.u32);
	// lfs f2,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f2,f24
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// stfs f1,3128(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3128, temp.u32);
	// fmuls f1,f2,f26
	ctx.f1.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// stfs f1,868(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 868, temp.u32);
	// lfs f1,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// stfs f1,3136(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3136, temp.u32);
	// lfs f1,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// stfs f1,3120(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3120, temp.u32);
	// lfs f1,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f1,3112(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3112, temp.u32);
	// lfs f1,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f1,3056(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3056, temp.u32);
	// lfs f1,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f4,f4,f1
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f4,3016(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3016, temp.u32);
	// lfs f4,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// stfs f10,2992(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2992, temp.u32);
	// lfs f4,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f4.f64 = double(temp.f32);
	// lfs f10,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// stfs f10,2984(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2984, temp.u32);
	// lfs f10,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f1,f26,f10
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// stfs f1,3096(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3096, temp.u32);
	// fmuls f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// stfs f10,3088(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3088, temp.u32);
	// lfs f10,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f15
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f15.f64));
	// stfs f10,3024(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3024, temp.u32);
	// lfs f10,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f15,f10
	ctx.f10.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f1,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f1.f64 = double(temp.f32);
	// stfs f10,3160(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3160, temp.u32);
	// fmuls f10,f1,f24
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// stfs f10,3144(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3144, temp.u32);
	// lfs f10,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f27,f10
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// stfs f23,3104(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3104, temp.u32);
	// fmuls f10,f26,f10
	ctx.f10.f64 = double(float(ctx.f26.f64 * ctx.f10.f64));
	// stfs f10,3176(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3176, temp.u32);
	// fmuls f10,f27,f1
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// stfs f10,976(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 976, temp.u32);
	// lfs f10,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f24,f10,f24
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f24.f64));
	// stfs f24,3168(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3168, temp.u32);
	// fmuls f24,f10,f26
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// stfs f24,1008(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1008, temp.u32);
	// lfs f24,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// stfs f24,660(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// lfs f23,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// fmuls f24,f24,f4
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// stfs f23,3072(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3072, temp.u32);
	// stfs f24,3080(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3080, temp.u32);
	// fmuls f15,f18,f28
	ctx.f15.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// lfs f23,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,1012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1012);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f4,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f24,f24,f30
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// stfs f23,3064(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3064, temp.u32);
	// stfs f24,864(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 864, temp.u32);
	// fmuls f23,f26,f1
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// lfs f24,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f24.f64 = double(temp.f32);
	// stfs f23,1032(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1032, temp.u32);
	// fmuls f24,f24,f30
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f23,f2,f27
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// stfs f23,992(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 992, temp.u32);
	// stfs f24,1172(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1172, temp.u32);
	// fmuls f23,f10,f27
	ctx.f23.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lfs f24,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f24.f64 = double(temp.f32);
	// stfs f23,1024(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1024, temp.u32);
	// fmuls f23,f24,f22
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f22.f64));
	// stfs f23,1616(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1616, temp.u32);
	// fmuls f23,f24,f18
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// stfs f23,1568(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1568, temp.u32);
	// lfs f23,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,3184(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3184, temp.u32);
	// lfs f23,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,3224(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3224, temp.u32);
	// fmuls f23,f15,f20
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f20.f64));
	// stfs f23,1576(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1576, temp.u32);
	// lfs f23,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// stfs f23,1592(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1592, temp.u32);
	// lfs f23,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,1560(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1560, temp.u32);
	// lfs f23,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,3192(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3192, temp.u32);
	// lfs f23,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f15,212(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f23,1608(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1608, temp.u32);
	// lfs f23,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,1600(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1600, temp.u32);
	// fmuls f23,f15,f22
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f22.f64));
	// stfs f23,1584(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1584, temp.u32);
	// fmuls f23,f24,f20
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// stfs f23,1624(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1624, temp.u32);
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// lfs f23,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// stfs f23,1180(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1180, temp.u32);
	// lfs f23,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// stfs f23,3256(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3256, temp.u32);
	// lfs f23,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f19
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// stfs f15,256(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmuls f15,f10,f18
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f18.f64));
	// stfs f15,596(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// fmuls f15,f10,f7
	ctx.f15.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// stfs f15,3200(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3200, temp.u32);
	// lfs f15,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f15,f22,f15
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// stfs f15,3352(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3352, temp.u32);
	// lfs f15,1812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1812);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f21.f64));
	// stfs f21,3296(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3296, temp.u32);
	// lfs f21,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f22,f21
	ctx.f21.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// stfs f21,3288(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3288, temp.u32);
	// lfs f21,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// stfs f21,324(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f21,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// stfs f21,248(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f21,f15
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f15.f64));
	// stfs f21,3368(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3368, temp.u32);
	// fmuls f21,f2,f12
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f7,3344(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3344, temp.u32);
	// fmuls f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// stfs f12,3320(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3320, temp.u32);
	// lfs f12,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// stfs f12,720(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// fmuls f12,f10,f22
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f22.f64));
	// stfs f12,332(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// lfs f12,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,672(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 672, temp.u32);
	// lfs f12,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f17
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// stfs f12,716(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 716, temp.u32);
	// fmuls f12,f2,f22
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// stfs f12,520(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f25
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f25.f64));
	// stfs f12,3248(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3248, temp.u32);
	// lfs f12,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f12,3616(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3616, temp.u32);
	// lfs f12,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f12,f18
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f18.f64));
	// stfs f10,3696(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3696, temp.u32);
	// lfs f10,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// stfs f10,3608(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3608, temp.u32);
	// fmuls f10,f23,f0
	ctx.f10.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// stfs f10,3728(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3728, temp.u32);
	// fmuls f10,f12,f22
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f22.f64));
	// stfs f10,3720(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3720, temp.u32);
	// fmuls f10,f12,f20
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f20.f64));
	// stfs f10,3664(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3664, temp.u32);
	// fmuls f10,f27,f12
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// stfs f21,3280(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3280, temp.u32);
	// stfs f10,3768(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3768, temp.u32);
	// fmuls f12,f26,f12
	ctx.f12.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lis r24,-32239
	ctx.r24.s64 = -2112815104;
	// lfs f7,4024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4024);
	ctx.f7.f64 = double(temp.f32);
	// lis r30,-32239
	ctx.r30.s64 = -2112815104;
	// lfs f2,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f2.f64 = double(temp.f32);
	// lfs f25,3880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3880);
	ctx.f25.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fadds f23,f2,f25
	ctx.f23.f64 = double(float(ctx.f2.f64 + ctx.f25.f64));
	// stfs f12,3776(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3776, temp.u32);
	// lfs f2,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f2.f64 = double(temp.f32);
	// lis r31,-32244
	ctx.r31.s64 = -2113142784;
	// lfs f10,-500(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -500);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// lfs f12,-52(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -52);
	ctx.f12.f64 = double(temp.f32);
	// lfs f25,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f25.f64 = double(temp.f32);
	// lis r9,-32244
	ctx.r9.s64 = -2113142784;
	// fmuls f0,f25,f0
	ctx.f0.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// stfs f0,1164(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1164, temp.u32);
	// fmuls f0,f25,f19
	ctx.f0.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// stfs f0,1904(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1904, temp.u32);
	// lfs f0,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f0.f64 = double(temp.f32);
	// lis r8,-32243
	ctx.r8.s64 = -2113077248;
	// fmuls f25,f0,f6
	ctx.f25.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f25,2960(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2960, temp.u32);
	// lfs f17,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,3420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3420);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmsubs f21,f2,f12,f7
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f12.f64 - ctx.f7.f64));
	// lfs f7,-472(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -472);
	ctx.f7.f64 = double(temp.f32);
	// lfs f2,-10648(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -10648);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f25,f23,f12,f21
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f21.f64));
	// lfs f12,4272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4272);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f23,f12,f8
	ctx.f23.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f12,2540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2540);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f21,f12,f8
	ctx.f21.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
	// lfs f12,-56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -56);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f25,f17,f10,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f25.f64));
	// lfs f17,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f0,f17
	ctx.f17.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// lfs f0,2492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2492);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f15,f0,f8
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// lfs f0,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f4
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// stfs f0,3744(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3744, temp.u32);
	// fmuls f0,f27,f28
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f0,f0,f14
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f14.f64));
	// stfs f0,3760(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3760, temp.u32);
	// lfs f0,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f23,f21,f12,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 - ctx.f23.f64));
	// fnmsubs f10,f0,f10,f25
	ctx.f10.f64 = double(float(-(ctx.f0.f64 * ctx.f10.f64 - ctx.f25.f64)));
	// lfs f25,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f0,f27,f28
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f0,f0,f25
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f25.f64));
	// stfs f0,3752(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3752, temp.u32);
	// lfs f0,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f21,f0,f21
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f21.f64));
	// stfs f21,3736(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3736, temp.u32);
	// fmuls f21,f17,f28
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// stfs f21,3856(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3856, temp.u32);
	// lfs f21,1748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1748);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// stfs f21,3864(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3864, temp.u32);
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// stfs f21,3824(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3824, temp.u32);
	// lfs f21,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f0,f0,f21
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f21.f64));
	// stfs f0,3832(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3832, temp.u32);
	// lfs f0,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f0,3808(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3808, temp.u32);
	// lfs f0,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f0,3792(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3792, temp.u32);
	// lfs f21,2140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2140);
	ctx.f21.f64 = double(temp.f32);
	// lfs f0,12124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 12124);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f0,f21,f0,f10
	ctx.f0.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f10,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// stfs f10,3816(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3816, temp.u32);
	// fmadds f10,f20,f12,f23
	ctx.f10.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f23.f64));
	// lfs f23,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// stfs f6,3800(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3800, temp.u32);
	// fmuls f6,f26,f3
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// stfs f6,1196(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1196, temp.u32);
	// fmuls f6,f27,f3
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// stfs f6,1204(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1204, temp.u32);
	// fmuls f6,f3,f18
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// stfs f6,1212(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1212, temp.u32);
	// lfs f6,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f6.f64 = double(temp.f32);
	// lis r7,-32239
	ctx.r7.s64 = -2112815104;
	// fmuls f6,f6,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// stfs f6,828(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 828, temp.u32);
	// lfs f6,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f6.f64 = double(temp.f32);
	// lis r6,-32239
	ctx.r6.s64 = -2112815104;
	// fmuls f6,f6,f19
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// stfs f6,1048(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1048, temp.u32);
	// fmuls f6,f3,f16
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f16.f64));
	// stfs f6,136(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f6,2360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2360);
	ctx.f6.f64 = double(temp.f32);
	// lis r3,-32239
	ctx.r3.s64 = -2112815104;
	// fnmsubs f23,f6,f7,f0
	ctx.f23.f64 = double(float(-(ctx.f6.f64 * ctx.f7.f64 - ctx.f0.f64)));
	// lfs f0,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f19
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// stfs f0,228(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f0,f3,f22
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f6,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f22,f15,f12,f10
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f12.f64 - ctx.f10.f64)));
	// lfs f0,2328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2328);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f0,1188(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1188, temp.u32);
	// lfs f0,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// lfs f10,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f10.f64 = double(temp.f32);
	// lfs f6,1164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1164);
	ctx.f6.f64 = double(temp.f32);
	// stfs f0,4792(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4792, temp.u32);
	// fmuls f0,f10,f6
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// stfs f0,1928(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1928, temp.u32);
	// lfs f0,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f6,f0,f6
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f6,3784(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3784, temp.u32);
	// lfs f6,2960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2960);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// stfs f6,1164(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1164, temp.u32);
	// lfs f6,1904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1904);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f0,f0,f6
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f0,1904(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1904, temp.u32);
	// lfs f0,2208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2208);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f3,f0,f2,f23
	ctx.f3.f64 = double(float(-(ctx.f0.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// fmuls f0,f10,f6
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f10,2300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2300);
	ctx.f10.f64 = double(temp.f32);
	// stfs f0,3840(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 3840, temp.u32);
	// lfs f0,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f0,-60(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -60);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f6,f10,f2,f3
	ctx.f6.f64 = double(float(-(ctx.f10.f64 * ctx.f2.f64 - ctx.f3.f64)));
	// lfs f3,1824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1824);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,-5404(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -5404);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f10,f3,f10,f6
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f6,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f10,f6,f2,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f10.f64));
	// lfs f6,2024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2024);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f10,f6,f7,f10
	ctx.f10.f64 = double(float(-(ctx.f6.f64 * ctx.f7.f64 - ctx.f10.f64)));
	// lfs f6,2124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2124);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f10,f6,f7,f10
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 + ctx.f10.f64));
	// stfs f10,4288(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4288, temp.u32);
	// lfs f10,4212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4212);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f10,f9
	ctx.f2.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,4032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4032);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f10,f9
	ctx.f23.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,2516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2516);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f21,f10,f12
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f20,f10,f3
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f6,-64(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -64);
	ctx.f6.f64 = double(temp.f32);
	// lfs f10,-68(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -68);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f1,f1,f0,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f2,f2,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f18,3412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3412);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,2500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2500);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f7,2176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2176);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f18,f8
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// lis r29,-32239
	ctx.r29.s64 = -2112815104;
	// fmuls f19,f7,f9
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f15,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f17.f64 = double(temp.f32);
	// lis r4,-32239
	ctx.r4.s64 = -2112815104;
	// lfs f16,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f15.f64 = double(temp.f32);
	// lfs f7,-72(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -72);
	ctx.f7.f64 = double(temp.f32);
	// lis r5,-32239
	ctx.r5.s64 = -2112815104;
	// fmadds f1,f1,f8,f22
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f8.f64 + ctx.f22.f64));
	// lfs f22,2264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2264);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f6,f23,f6,f2
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 - ctx.f2.f64));
	// lfs f2,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f8
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// lfs f23,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f24,f24,f0,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lfs f21,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f23,f25
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// fmuls f4,f4,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// lfs f21,2076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2076);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f22,f9
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fmuls f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f16,4096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4096);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f8
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f8.f64));
	// fnmsubs f1,f18,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmadds f6,f20,f10,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f20,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f4,f4,f8
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// fmadds f1,f24,f8,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 + ctx.f1.f64));
	// lfs f24,2200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2200);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f19,f19,f7,f6
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f6.f64));
	// lfs f6,2224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2224);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f18,f6,f9
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// lfs f6,-76(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -76);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// fmuls f24,f24,f9
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// fnmsubs f2,f2,f0,f1
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f1,2084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2084);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f19,f17,f10,f19
	ctx.f19.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f19.f64)));
	// lfs f17,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f15,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f17.f64));
	// lfs f15,2288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2288);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f1,f1,f9
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f9.f64));
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// fnmsubs f2,f23,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f23,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f10,f3,f10,f19
	ctx.f10.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f19.f64));
	// lfs f19,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f3,f25,f8
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// lfs f25,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// lfs f23,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64));
	// fmuls f19,f17,f8
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// fnmsubs f4,f4,f0,f2
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fnmsubs f10,f22,f7,f10
	ctx.f10.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f10.f64)));
	// fmadds f4,f20,f0,f4
	ctx.f4.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fmadds f10,f21,f7,f10
	ctx.f10.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f10.f64));
	// fnmsubs f4,f16,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fnmsubs f10,f18,f6,f10
	ctx.f10.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f10.f64)));
	// fmadds f4,f3,f0,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f4.f64));
	// fnmsubs f10,f24,f7,f10
	ctx.f10.f64 = double(float(-(ctx.f24.f64 * ctx.f7.f64 - ctx.f10.f64)));
	// fnmsubs f4,f19,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmadds f10,f1,f7,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 + ctx.f10.f64));
	// stfs f4,4292(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4292, temp.u32);
	// fnmsubs f4,f15,f7,f10
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f10.f64)));
	// lfs f10,-80(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -80);
	ctx.f10.f64 = double(temp.f32);
	// lis r27,-32239
	ctx.r27.s64 = -2112815104;
	// lfs f22,2196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2196);
	ctx.f22.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f17,2780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2780);
	ctx.f17.f64 = double(temp.f32);
	// lis r28,-32239
	ctx.r28.s64 = -2112815104;
	// lfs f20,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f20.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// lfs f18,3548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3548);
	ctx.f18.f64 = double(temp.f32);
	// lis r26,-32239
	ctx.r26.s64 = -2112815104;
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f19,2228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2228);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,2180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2180);
	ctx.f17.f64 = double(temp.f32);
	// lfs f15,2156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2156);
	ctx.f15.f64 = double(temp.f32);
	// lfs f3,2188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2188);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f1,f25,f10,f4
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f10,3628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3628);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f0
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,1940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1940);
	ctx.f10.f64 = double(temp.f32);
	// lfs f25,4236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4236);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f2,4228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4228);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f25.f64));
	// lfs f25,3484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3484);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f24,3980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3980);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f10
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f16,2276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2276);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f4
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f4.f64));
	// lfs f4,4220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4220);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f4,f0
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f4,4144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4144);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// lfs f4,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fmuls f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// fmuls f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// lfs f4,-476(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -476);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,440(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fmuls f3,f3,f6
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lis r27,-32239
	ctx.r27.s64 = -2112815104;
	// fmuls f2,f2,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// fmsubs f3,f22,f10,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f3.f64));
	// lfs f22,2132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2132);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f12,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f21.f64));
	// lfs f21,4128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4128);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f2,f2,f0,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 - ctx.f25.f64));
	// lfs f25,2932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2932);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f16.f64));
	// lfs f16,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f10
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// fnmsubs f3,f24,f0,f3
	ctx.f3.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// fmuls f24,f19,f4
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f4,2772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2772);
	ctx.f4.f64 = double(temp.f32);
	// lfs f19,3404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3404);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f2,f22,f10,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f2.f64));
	// fadds f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 + ctx.f19.f64));
	// lfs f4,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f4.f64 = double(temp.f32);
	// lfs f22,2828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2828);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f18,f4
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// fmuls f22,f22,f4
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// fnmsubs f2,f16,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f4,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// lfs f4,-84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -84);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f20,f20,f4,f3
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f4,2116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2116);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// stfs f4,1012(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1012, temp.u32);
	// lfs f4,-464(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -464);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f24,f15,f4,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 - ctx.f24.f64));
	// lfs f3,2908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2908);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f16,f3,f4
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,-424(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -424);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f15,1012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1012);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f21,f21,f6,f20
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f20.f64)));
	// fnmsubs f15,f15,f12,f2
	ctx.f15.f64 = double(float(-(ctx.f15.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f2,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
	// stfs f2,1012(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1012, temp.u32);
	// fmuls f22,f22,f3
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// lfs f3,-460(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -460);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f20,f18,f3,f17
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 - ctx.f17.f64));
	// lfs f17,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f24,f19,f3,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f24.f64));
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f3,2148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2148);
	ctx.f3.f64 = double(temp.f32);
	// lfs f17,3620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3620);
	ctx.f17.f64 = double(temp.f32);
	// lis r27,-32239
	ctx.r27.s64 = -2112815104;
	// fmuls f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// fmadds f25,f25,f6,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f21.f64));
	// lfs f21,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f21.f64 = double(temp.f32);
	// fmr f2,f21
	ctx.f2.f64 = ctx.f21.f64;
	// fmuls f21,f3,f2
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f3,-428(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -428);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f22,f16,f3,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f22.f64));
	// lfs f3,3556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3556);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f4
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,-464(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -464);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f20,f18,f3,f20
	ctx.f20.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f20.f64)));
	// lfs f18,2164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2164);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// lfs f2,2916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2916);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f2,f4
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f2,-68(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -68);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,-84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -84);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f1,f23,f2,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// fmadds f25,f17,f4,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f25.f64));
	// stfs f1,4296(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4296, temp.u32);
	// lfs f23,2292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2292);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f23,f23,f9
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f9.f64));
	// lfs f1,1012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1012);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f1,f12,f15
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f15.f64)));
	// stfs f1,4300(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4300, temp.u32);
	// fnmsubs f1,f21,f3,f24
	ctx.f1.f64 = double(float(-(ctx.f21.f64 * ctx.f3.f64 - ctx.f24.f64)));
	// stfs f1,4304(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4304, temp.u32);
	// lfs f1,-400(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -400);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f3,f18,f3,f20
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fnmsubs f1,f19,f1,f22
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f1.f64 - ctx.f22.f64)));
	// stfs f1,4308(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4308, temp.u32);
	// stfs f3,4312(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4312, temp.u32);
	// fnmsubs f1,f16,f4,f25
	ctx.f1.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// lfs f4,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f4,f3
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f24,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// lfs f19,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f19.f64 = double(temp.f32);
	// lfs f24,2316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2316);
	ctx.f24.f64 = double(temp.f32);
	// lfs f22,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f24,f24,f9
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f9.f64));
	// lfs f16,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f4,f22
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f22.f64));
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f3,2308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2308);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f3,f7
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f3,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f4
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// lfs f3,2332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2332);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f9
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// lfs f3,-80(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -80);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f3,f25,f3,f2
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f2.f64));
	// lfs f2,3652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3652);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f2,f6,f21
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f21.f64));
	// lfs f25,4208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4208);
	ctx.f25.f64 = double(temp.f32);
	// lfs f21,2348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2348);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f25,f8
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fnmsubs f3,f24,f7,f3
	ctx.f3.f64 = double(float(-(ctx.f24.f64 * ctx.f7.f64 - ctx.f3.f64)));
	// lfs f24,1840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1840);
	ctx.f24.f64 = double(temp.f32);
	// lfs f15,3940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3940);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lis r5,-32239
	ctx.r5.s64 = -2112815104;
	// fmsubs f6,f15,f6,f19
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f6.f64 - ctx.f19.f64));
	// lfs f19,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f8
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// lfs f15,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// lfs f16,2340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2340);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fmadds f7,f23,f7,f3
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f3.f64));
	// fmadds f3,f17,f0,f24
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f24.f64));
	// lfs f24,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f4
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// lfs f4,3564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3564);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f6,f6,f8,f25
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64 - ctx.f25.f64));
	// lfs f25,2284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2284);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64));
	// lfs f10,-68(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -68);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f4,f8
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// lfs f17,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f4,f19,f30
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// fnmsubs f10,f22,f10,f7
	ctx.f10.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f7,4152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4152);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f22,f7,f9
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f7,2804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2804);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f19,f7,f8
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmadds f7,f3,f8,f6
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f8.f64 + ctx.f6.f64));
	// lfs f6,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f8
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f3,3972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3972);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f1,f25,f12,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// fmuls f3,f3,f17
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// fmadds f2,f2,f9,f10
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f9.f64 + ctx.f10.f64));
	// lfs f10,2980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2980);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f25,f10,f9
	ctx.f25.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f10,-88(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -88);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f17,f4,f10,f7
	ctx.f17.f64 = double(float(-(ctx.f4.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f4,-76(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -76);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f7,f6,f30
	ctx.f7.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f7,1012(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1012, temp.u32);
	// lfs f7,-68(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -68);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,-84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -84);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f6,f3,f6,f1
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f1.f64));
	// stfs f6,4316(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4316, temp.u32);
	// lfs f6,-72(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -72);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f2,f20,f7,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f2.f64));
	// fnmsubs f3,f23,f4,f17
	ctx.f3.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f17.f64)));
	// fnmsubs f2,f18,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// fmadds f3,f19,f4,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 + ctx.f3.f64));
	// fnmsubs f2,f21,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// fmadds f6,f16,f6,f2
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f2.f64));
	// lfs f2,2836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2836);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f2,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f8
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f8.f64));
	// fnmsubs f6,f15,f7,f6
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f1,1012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1012);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f3,f1,f10,f3
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f3.f64)));
	// lfs f1,2296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2296);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f6,f24,f7,f6
	ctx.f6.f64 = double(float(-(ctx.f24.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// lfs f7,-64(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -64);
	ctx.f7.f64 = double(temp.f32);
	// lfs f24,3020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3020);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f6,f22,f7,f6
	ctx.f6.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// fmadds f7,f25,f7,f6
	ctx.f7.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f6.f64));
	// stfs f7,4320(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4320, temp.u32);
	// lfs f6,-10648(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -10648);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,2040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2040);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f6.f64));
	// fmsubs f1,f1,f6,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 - ctx.f7.f64));
	// lfs f7,2844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2844);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f4,f7,f12,f4
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f4.f64));
	// lfs f7,3580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3580);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f7,f8
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f7,3228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3228);
	ctx.f7.f64 = double(temp.f32);
	// fadds f24,f7,f24
	ctx.f24.f64 = double(float(ctx.f7.f64 + ctx.f24.f64));
	// lfs f7,3948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3948);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f7,f8
	ctx.f23.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f7,-472(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -472);
	ctx.f7.f64 = double(temp.f32);
	// lfs f22,2056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2056);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f4,f4,f8,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f3.f64));
	// fnmsubs f1,f22,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// lfs f3,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f3.f64 = double(temp.f32);
	// lfs f22,2672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2672);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f3,f3,f8
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// fadds f24,f24,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f22.f64));
	// lfs f21,3304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3304);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,2860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2860);
	ctx.f22.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// lfs f21,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,2032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2032);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f2,f2,f10,f4
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f4,-92(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -92);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f1,f21,f7,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f1.f64));
	// fmuls f21,f3,f30
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// lfs f3,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f8
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f8.f64));
	// lfs f3,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// fnmsubs f2,f25,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f25,3960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3960);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f7,f18,f7,f1
	ctx.f7.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// lfs f1,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f25,f12
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f18,2216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2216);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f1,f20,f1
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// lfs f20,3936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3936);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fmuls f19,f19,f8
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// fnmsubs f2,f23,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f23,2944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2944);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f6,f18,f6,f7
	ctx.f6.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f7.f64)));
	// lfs f7,3976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3976);
	ctx.f7.f64 = double(temp.f32);
	// fadds f23,f7,f23
	ctx.f23.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// lfs f7,3904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3904);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f25,f7,f12,f25
	ctx.f25.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 - ctx.f25.f64));
	// lfs f7,2820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2820);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f7,f8
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f7,-52(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -52);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f20,f20,f12
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f12.f64));
	// fmadds f7,f24,f7,f6
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f6.f64));
	// fnmsubs f6,f21,f10,f2
	ctx.f6.f64 = double(float(-(ctx.f21.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f10,3992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3992);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f24,f10,f8
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f10,-500(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -500);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f23,f8
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// lfs f23,3660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3660);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f25,f25,f8,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64 - ctx.f20.f64));
	// fmadds f23,f23,f10,f7
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f7.f64));
	// lfs f7,-5404(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -5404);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f6,f22,f4,f6
	ctx.f6.f64 = double(float(-(ctx.f22.f64 * ctx.f4.f64 - ctx.f6.f64)));
	// fmadds f4,f2,f0,f25
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f25.f64));
	// lfs f2,2900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2900);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f7,f2,f7,f23
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 + ctx.f23.f64));
	// lfs f2,2988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2988);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f6,f1,f0,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f1,3928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3928);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f1,f8
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fnmsubs f7,f2,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f2,3988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3988);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f6,f19,f0,f6
	ctx.f6.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// fnmsubs f7,f2,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f2,1336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1336);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f10,f18,f12,f6
	ctx.f10.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f6.f64));
	// stfs f10,4324(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4324, temp.u32);
	// lfs f6,2048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2048);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f2,f14
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// lfs f10,12124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 12124);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f10,f6,f10,f7
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 + ctx.f7.f64));
	// stfs f10,4328(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4328, temp.u32);
	// lfs f10,3968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3968);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f7,f24,f0,f4
	ctx.f7.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmuls f6,f10,f8
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// lfs f4,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f4.f64 = double(temp.f32);
	// lfs f10,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// fnmsubs f7,f6,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f6,3896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3896);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f6,f8
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f1,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f1.f64 = double(temp.f32);
	// lfs f6,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f4,f6,f1,f4
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f4.f64));
	// lfs f6,1536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1536);
	ctx.f6.f64 = double(temp.f32);
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f6,f1,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f6,3944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3944);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f8
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// lfs f6,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f6.f64 = double(temp.f32);
	// lfs f19,3984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3984);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f25,f25,f12,f7
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64 + ctx.f7.f64));
	// lfs f7,3848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3848);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f22,f7,f0
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f4,f6,f7,f4
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f7.f64 + ctx.f4.f64));
	// lfs f7,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f21,f2,f7
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// lfs f2,3384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3384);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f2,f29
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f29.f64));
	// lfs f2,3912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3912);
	ctx.f2.f64 = double(temp.f32);
	// fadds f19,f2,f19
	ctx.f19.f64 = double(float(ctx.f2.f64 + ctx.f19.f64));
	// lfs f2,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f25,f24,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fmuls f24,f10,f2
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// lfs f10,3920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3920);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f22,f10,f12,f22
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + ctx.f22.f64));
	// lfs f10,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f4,f4,f29,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 + ctx.f21.f64));
	// fmadds f21,f10,f7,f20
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f7.f64 + ctx.f20.f64));
	// lfs f10,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f10.f64 = double(temp.f32);
	// lfs f20,3888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3888);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f8
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f8.f64));
	// fnmsubs f25,f23,f12,f25
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// lfs f23,4008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4008);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f6,f6,f18,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f18.f64 + ctx.f24.f64));
	// lfs f24,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// fmuls f24,f24,f14
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f14.f64));
	// fmadds f4,f19,f10,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f19,4016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4016);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f25,f22,f8,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f8.f64 + ctx.f25.f64));
	// lfs f22,2384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2384);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f8
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// fmsubs f23,f6,f29,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 - ctx.f23.f64));
	// lfs f6,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f4,f21,f6,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 - ctx.f4.f64));
	// lfs f6,2696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2696);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f6,f0
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// lfs f6,1856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1856);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f0,f20,f0,f25
	ctx.f0.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f25,3952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3952);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f6,f25
	ctx.f25.f64 = double(float(ctx.f6.f64 + ctx.f25.f64));
	// lfs f20,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f20.f64 = double(temp.f32);
	// lfs f6,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f23,f19,f10,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 + ctx.f23.f64));
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmadds f7,f24,f7,f4
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f4.f64));
	// lfs f4,3872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3872);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f4,f4,f12,f21
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f21.f64));
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// lfs f21,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// fnmsubs f0,f22,f12,f0
	ctx.f0.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f0.f64)));
	// lfs f22,4000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4000);
	ctx.f22.f64 = double(temp.f32);
	// fadds f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f22.f64));
	// lfs f22,4772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4772);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f23,f20,f29,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f29.f64 - ctx.f23.f64)));
	// fnmsubs f7,f22,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fmadds f0,f4,f8,f0
	ctx.f0.f64 = double(float(ctx.f4.f64 * ctx.f8.f64 + ctx.f0.f64));
	// stfs f0,4332(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4332, temp.u32);
	// lfs f0,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f24,f24,f29,f23
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f29.f64 - ctx.f23.f64)));
	// fmadds f25,f25,f10,f7
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f7.f64));
	// lfs f10,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f0,f10
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfs f7,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f7.f64 = double(temp.f32);
	// lfs f0,1620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f0,f7
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f21,f6,f4
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f6,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f6.f64 = double(temp.f32);
	// lfs f4,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f4.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f20,f6,f4
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f4,1588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	ctx.f4.f64 = double(temp.f32);
	// lfs f19,4796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4796);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 + ctx.f19.f64));
	// lfs f4,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f4,f10
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f4,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f4.f64 = double(temp.f32);
	// lfs f10,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fmuls f17,f10,f1
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f1.f64));
	// lfs f1,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// lfs f10,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,-96(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -96);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f21,f1,f10,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f21.f64));
	// lfs f10,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f10.f64 = double(temp.f32);
	// lfs f15,1644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// fmuls f15,f15,f10
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f10.f64));
	// lfs f14,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,3432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3432);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f19,f7
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// fmuls f16,f16,f10
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f10.f64));
	// fmsubs f23,f22,f0,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 - ctx.f23.f64));
	// lfs f22,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f14.f64));
	// lfs f14,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fmadds f24,f21,f29,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfs f21,3472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3472);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f7
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f7.f64));
	// fmuls f19,f19,f0
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64));
	// fnmsubs f3,f20,f0,f23
	ctx.f3.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfs f20,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// lfs f20,3424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3424);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f10
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64));
	// fnmsubs f24,f17,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f17,3488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3488);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f7
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// fmsubs f19,f15,f0,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 - ctx.f19.f64));
	// lfs f15,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f18,f18,f4,f3
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f15,f3
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// fmadds f24,f22,f29,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfs f22,4788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4788);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f22,f2,f23
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 + ctx.f23.f64));
	// fmadds f23,f21,f0,f19
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f19.f64));
	// lfs f21,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f3,f21,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// lfs f19,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f22,f16,f0,f18
	ctx.f22.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f18.f64)));
	// lfs f21,1248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1248);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// lfs f19,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f1,f1,f29,f24
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f24,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f19.f64));
	// lfs f19,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f23,f17,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// fmadds f3,f6,f18,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f18.f64 + ctx.f3.f64));
	// fmadds f22,f14,f0,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f22.f64));
	// fmadds f2,f2,f29,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f1.f64));
	// lfs f1,3416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3416);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f10,f1,f10
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// lfs f1,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f6,f6,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmadds f4,f21,f4,f23
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f23.f64));
	// lfs f23,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f1,f20,f0,f22
	ctx.f1.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// lfs f22,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f10,f10,f0,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lis r8,-32239
	ctx.r8.s64 = -2112815104;
	// fmadds f4,f15,f0,f1
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f1.f64));
	// lfs f16,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f22,2204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2204);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f2,f24,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f17,1980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1980);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f3,f22,f7,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f3.f64));
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f15.f64 = double(temp.f32);
	// lis r6,-32239
	ctx.r6.s64 = -2112815104;
	// lfs f14,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f14.f64 = double(temp.f32);
	// lis r25,-32239
	ctx.r25.s64 = -2112815104;
	// lfs f18,4140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4140);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f1,f6,f0,f10
	ctx.f1.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f10.f64)));
	// lfs f6,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f10,f19,f0,f4
	ctx.f10.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// lfs f4,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f6,f4
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f6,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f6.f64 = double(temp.f32);
	// fadds f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 + ctx.f2.f64));
	// stfs f2,4336(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4336, temp.u32);
	// lfs f2,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f6,f4
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f6,-100(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -100);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f16,f2
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// lfs f19,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fmadds f25,f3,f0,f10
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f10,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f24,f10,f2
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f2.f64));
	// lfs f3,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f3.f64 = double(temp.f32);
	// lfs f10,4188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4188);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// fmuls f22,f10,f3
	ctx.f22.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f10,-104(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -104);
	ctx.f10.f64 = double(temp.f32);
	// lfs f15,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f15.f64 = double(temp.f32);
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f14,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmadds f24,f22,f10,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f24.f64));
	// lfs f22,4132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4132);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f14
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f14.f64));
	// lfs f14,-108(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -108);
	ctx.f14.f64 = double(temp.f32);
	// stfs f14,584(r1)
	temp.f32 = float(ctx.f14.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// lfs f14,1364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f7.f64));
	// lfs f7,4040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4040);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f7,f3
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f7,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f2,f7,f4,f2
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f4.f64 + ctx.f2.f64));
	// lfs f4,-116(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -116);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,-112(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -112);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f15,f7
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// fmsubs f4,f21,f4,f24
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 - ctx.f24.f64));
	// lfs f24,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f1,f23,f24,f1
	ctx.f1.f64 = double(float(ctx.f23.f64 * ctx.f24.f64 + ctx.f1.f64));
	// lfs f23,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f23,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f5,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// fnmsubs f4,f20,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f20.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fnmsubs f1,f14,f0,f1
	ctx.f1.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f0,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f0.f64 = double(temp.f32);
	// lfs f5,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f22,f22,f5,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 + ctx.f15.f64));
	// lfs f5,4108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4108);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f20,f0,f5
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f15,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f5,f31,f28
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f5,f5,f15
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// lfs f15,4180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4180);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f24,f24,f7,f22
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f7.f64 - ctx.f22.f64)));
	// lfs f7,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f6,f19,f6,f4
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f6.f64 + ctx.f4.f64));
	// lfs f22,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f4,f23,f7,f1
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f1.f64));
	// lfs f7,4156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4156);
	ctx.f7.f64 = double(temp.f32);
	// lfs f1,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f1.f64 = double(temp.f32);
	// lis r26,-32239
	ctx.r26.s64 = -2112815104;
	// fmuls f1,f7,f1
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// lfs f7,4124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4124);
	ctx.f7.f64 = double(temp.f32);
	// lfs f23,4172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4172);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f7,f23
	ctx.f23.f64 = double(float(ctx.f7.f64 + ctx.f23.f64));
	// lfs f7,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f7.f64 = double(temp.f32);
	// lfs f14,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f22,f7,f22
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f22.f64));
	// lfs f7,2256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2256);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f19,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f19.f64 = double(temp.f32);
	// lfs f14,4056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4056);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f7,f19
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// lfs f7,4048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4048);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f0,f14
	ctx.f14.f64 = double(float(ctx.f0.f64 * ctx.f14.f64));
	// fmuls f0,f0,f7
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// stfs f0,2204(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2204, temp.u32);
	// lfs f7,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f6,f18,f10,f6
	ctx.f6.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f6.f64)));
	// fnmsubs f24,f20,f7,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// lfs f20,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f5,f5,f20,f4
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f20.f64 - ctx.f4.f64)));
	// lfs f0,-432(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -432);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,4148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4148);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f20,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f20.f64 = double(temp.f32);
	// lfs f0,-112(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -112);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f20,f4,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f0,-100(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -100);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fnmsubs f18,f17,f0,f6
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// fmadds f24,f14,f7,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f7.f64 + ctx.f24.f64));
	// fadds f6,f25,f5
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// stfs f6,4340(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4340, temp.u32);
	// lfs f6,-432(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -432);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f6,f20,f6,f1
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 - ctx.f1.f64));
	// stfs f6,4352(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4352, temp.u32);
	// lfs f20,1880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1880);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f1,f23,f7,f22
	ctx.f1.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 - ctx.f22.f64));
	// lfs f5,2204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2204);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f6,f5,f7,f24
	ctx.f6.f64 = double(float(-(ctx.f5.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// stfs f6,4348(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4348, temp.u32);
	// fnmsubs f6,f16,f0,f18
	ctx.f6.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f18.f64)));
	// fmadds f6,f2,f0,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f2,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f5,f3,f10,f6
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f6,-116(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -116);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f6,f21,f6,f5
	ctx.f6.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// lfs f5,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f6,f15,f10,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f6.f64));
	// fmadds f6,f19,f0,f6
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f6.f64));
	// stfs f6,4344(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4344, temp.u32);
	// lfs f6,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f2,f6
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f6,2212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2212);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f6,f5
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f5,f3
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,1564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f2,f5
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f5,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f21,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// stfs f5,2212(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2212, temp.u32);
	// lfs f5,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,1736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1736);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// fmadds f25,f25,f31,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f31.f64 + ctx.f24.f64));
	// fmuls f24,f23,f0
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// lfs f23,1428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1428);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f25,f25,f0,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 - ctx.f24.f64));
	// fmuls f23,f19,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f23.f64));
	// lfs f18,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f24.f64 = double(temp.f32);
	// lfs f19,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f2,f2,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f17,4204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4204);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,1816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1816);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,1744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1744);
	ctx.f24.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f25,f22,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f22,4116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4116);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f24,f24,f6,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f23.f64));
	// lfs f23,1588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f17.f64));
	// lfs f17,1272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1272);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// fmuls f16,f2,f31
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// lfs f2,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f4,f22
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f22.f64));
	// fmuls f18,f18,f5
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// fmadds f24,f2,f3,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f2,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f2,f3
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f3,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f17,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f2,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fnmsubs f2,f21,f10,f25
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f10.f64 - ctx.f25.f64)));
	// lfs f25,4164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4164);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f1,f22,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// lfs f22,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f4,f4,f25
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// lfs f21,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// lfs f5,3496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3496);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// lfs f5,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f5.f64 = double(temp.f32);
	// lfs f25,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f5,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f2,f20,f10,f2
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f20,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// fnmsubs f4,f4,f7,f1
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// lfs f7,2212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2212);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f22,f6
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// fmadds f23,f27,f7,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f23.f64));
	// fmuls f22,f26,f7
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f7,-112(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -112);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f6,f19,f0,f2
	ctx.f6.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f2,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f2.f64 = double(temp.f32);
	// lfs f19,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f7,f14,f7,f4
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f7.f64 + ctx.f4.f64));
	// stfs f7,4356(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4356, temp.u32);
	// fmuls f2,f19,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// fmadds f7,f24,f0,f6
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f6,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f24,f6,f5,f22
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f6,-96(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -96);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f4,f23,f6,f3
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f3.f64));
	// lfs f3,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f7,f18,f10,f7
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fmsubs f4,f17,f3,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 - ctx.f4.f64));
	// fnmsubs f7,f16,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fmadds f4,f21,f6,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f4.f64));
	// fmadds f7,f15,f0,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fnmsubs f23,f20,f6,f4
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fnmsubs f7,f25,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fnmsubs f0,f1,f0,f7
	ctx.f0.f64 = double(float(-(ctx.f1.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// stfs f0,4360(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4360, temp.u32);
	// lfs f1,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f1.f64 = double(temp.f32);
	// lfs f0,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f4,f0,f1
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f0,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f27,f2,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f18,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f0,f5
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f25,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f18,f18,f5,f4
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 + ctx.f4.f64));
	// fmuls f0,f30,f25
	ctx.f0.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f4,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,1364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmuls f17,f5,f4
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f5,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f30,f5
	ctx.f5.f64 = double(float(ctx.f30.f64 * ctx.f5.f64));
	// lfs f7,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f7.f64 = double(temp.f32);
	// lfs f20,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f19.f64 = double(temp.f32);
	// stfs f5,284(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f15,4776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4776);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f21,f0,f7
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f7,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f20,f7,f20
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f20.f64));
	// lfs f7,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f19,f7,f19
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f19.f64));
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmuls f5,f28,f25
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// lfs f25,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f21,f21,f29
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f29.f64));
	// fmadds f25,f5,f25,f19
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 + ctx.f19.f64));
	// fmuls f19,f18,f6
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fmuls f18,f7,f4
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f4.f64));
	// lfs f7,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f21,f15,f7,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 - ctx.f21.f64));
	// lfs f15,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f0,f15
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f15.f64));
	// fmadds f25,f14,f0,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f25.f64));
	// lfs f0,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f0.f64 = double(temp.f32);
	// fmsubs f22,f22,f6,f19
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 - ctx.f19.f64));
	// lfs f19,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f24,f0,f19,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f19.f64 + ctx.f24.f64));
	// lfs f19,1460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1460);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lfs f14,3504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3504);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f21,f16,f29,f21
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f21.f64)));
	// lfs f16,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f16,1620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f14.f64));
	// lfs f14,2380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2380);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f31
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f31.f64));
	// fmadds f0,f20,f3,f22
	ctx.f0.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f22.f64));
	// lfs f20,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f24,f6,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f23.f64));
	// lfs f23,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// fmadds f25,f25,f29,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f29.f64 + ctx.f21.f64));
	// fmuls f22,f16,f4
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// lfs f4,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f26,f17,f6,f0
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f6.f64 - ctx.f0.f64)));
	// lfs f17,1444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1444);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f0,f31,f30
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// fnmsubs f1,f1,f6,f24
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// fnmsubs f25,f15,f29,f25
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// fmuls f21,f0,f4
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f2,f2,f6,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f6.f64 + ctx.f1.f64));
	// fmuls f24,f0,f4
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// lfs f4,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f20.f64));
	// fmuls f4,f31,f28
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fnmsubs f1,f14,f29,f25
	ctx.f1.f64 = double(float(-(ctx.f14.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// fnmsubs f3,f20,f3,f2
	ctx.f3.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f2.f64)));
	// fmuls f17,f4,f17
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// fmadds f4,f18,f6,f26
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f26,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f0,f26
	ctx.f26.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// fnmsubs f2,f23,f29,f1
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// fnmsubs f4,f27,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fnmsubs f4,f19,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// lfs f23,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f2,f24,f29,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f2.f64));
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f1,f22,f6,f4
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f4.f64));
	// lfs f4,4268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4268);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f2,f4,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f4.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f4,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f4.f64 = double(temp.f32);
	// lfs f22,4184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4184);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f8,f22
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// fnmsubs f1,f21,f4,f1
	ctx.f1.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f1.f64)));
	// fnmsubs f2,f26,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f26,3844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3844);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f4,f17,f4,f1
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f1.f64));
	// lfs f17,4260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4260);
	ctx.f17.f64 = double(temp.f32);
	// fadds f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 + ctx.f4.f64));
	// stfs f4,4364(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4364, temp.u32);
	// lfs f4,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f0,f0,f4
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// lfs f4,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f5,f4
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f5,1580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f1,f4,f5
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// lfs f4,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f5,f4
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f5,3356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3356);
	ctx.f5.f64 = double(temp.f32);
	// fadds f26,f5,f26
	ctx.f26.f64 = double(float(ctx.f5.f64 + ctx.f26.f64));
	// lfs f5,2436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2436);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f25,f8,f5
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f5.f64));
	// lfs f5,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f0,f5
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// lfs f0,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f31,f0
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fmuls f25,f25,f12
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// fmadds f3,f3,f29,f24
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfs f24,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f0,f23
	ctx.f23.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// fmuls f24,f0,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f24.f64));
	// lfs f0,4276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4276);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f21,f8,f0
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// fmuls f20,f0,f4
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// lfs f0,2420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2420);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f19,f8,f0
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// fmsubs f0,f26,f12,f25
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 - ctx.f25.f64));
	// lfs f26,4784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4784);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f3,f26,f7,f3
	ctx.f3.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f3.f64)));
	// lfs f26,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f4
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// lfs f4,3380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3380);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f8,f4
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f4,2396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2396);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f8,f4
	ctx.f18.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// fnmsubs f4,f22,f12,f0
	ctx.f4.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f0.f64)));
	// lfs f0,4284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4284);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f3,f1,f5,f3
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// lfs f22,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f1,f8,f0
	ctx.f1.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f0,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f22,f0,f22
	ctx.f22.f64 = double(float(ctx.f0.f64 * ctx.f22.f64));
	// lfs f0,4244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4244);
	ctx.f0.f64 = double(temp.f32);
	// fadds f17,f0,f17
	ctx.f17.f64 = double(float(ctx.f0.f64 + ctx.f17.f64));
	// lfs f0,-60(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -60);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f21,f21,f0,f4
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lfs f4,2412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2412);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f3,f27,f5,f3
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// fmuls f27,f8,f4
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f4.f64));
	// lfs f4,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f28,f4
	ctx.f4.f64 = double(float(ctx.f28.f64 * ctx.f4.f64));
	// stfs f4,232(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fnmsubs f2,f22,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f22,4080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4080);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f8,f22
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// fnmsubs f21,f19,f0,f21
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f21.f64)));
	// fnmsubs f3,f23,f29,f3
	ctx.f3.f64 = double(float(-(ctx.f23.f64 * ctx.f29.f64 - ctx.f3.f64)));
	// fmuls f4,f4,f16
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// fmadds f3,f24,f29,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f3.f64));
	// lfs f23,2404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2404);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f4,f4,f29,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 + ctx.f2.f64));
	// lis r7,-32239
	ctx.r7.s64 = -2112815104;
	// fmadds f2,f25,f0,f21
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lis r6,-32239
	ctx.r6.s64 = -2112815104;
	// fmuls f23,f8,f23
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f23.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f16,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f16.f64 = double(temp.f32);
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f16,f9,f16
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f16.f64));
	// lfs f15,2592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2592);
	ctx.f15.f64 = double(temp.f32);
	// lis r27,-32239
	ctx.r27.s64 = -2112815104;
	// lfs f19,2428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2428);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f8,f19
	ctx.f19.f64 = double(float(ctx.f8.f64 * ctx.f19.f64));
	// fmadds f3,f20,f5,f3
	ctx.f3.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fnmsubs f2,f18,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f18,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f3,f26,f29,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f29.f64 + ctx.f3.f64));
	// fnmsubs f2,f1,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f1,4800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4800);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f3,f1,f7,f3
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 + ctx.f3.f64));
	// lfs f1,4780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4780);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f27,f0,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f2.f64));
	// fnmsubs f3,f1,f7,f3
	ctx.f3.f64 = double(float(-(ctx.f1.f64 * ctx.f7.f64 - ctx.f3.f64)));
	// lfs f1,2616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2616);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f22,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fmadds f3,f17,f7,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f3.f64));
	// fnmsubs f25,f23,f0,f2
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f2,4252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4252);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f7,f2,f7,f3
	ctx.f7.f64 = double(float(-(ctx.f2.f64 * ctx.f7.f64 - ctx.f3.f64)));
	// lfs f2,2220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2220);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,2452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2452);
	ctx.f3.f64 = double(temp.f32);
	// fadds f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f7.f64));
	// stfs f7,4368(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4368, temp.u32);
	// lfs f7,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f7,f2
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f2.f64));
	// lfs f7,-120(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -120);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f26,f3,f7
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f7,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f24,f9,f7
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f4,-124(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -124);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,2360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2360);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f9,f7
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f7,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f9,f7
	ctx.f3.f64 = double(float(ctx.f9.f64 * ctx.f7.f64));
	// lfs f7,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f22,f7,f1
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// lfs f1,2208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2208);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// fmuls f21,f9,f1
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// lfs f1,-136(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -136);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f20,f27,f4,f26
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f26.f64));
	// lfs f27,-128(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -128);
	ctx.f27.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f27,-140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -140);
	ctx.f27.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f26,-144(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -144);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f24,f20,f9,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 - ctx.f24.f64));
	// fmuls f18,f18,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// lfs f20,2140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2140);
	ctx.f20.f64 = double(temp.f32);
	// lfs f26,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f9,f26
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// lfs f26,-132(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -132);
	ctx.f26.f64 = double(temp.f32);
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmadds f27,f20,f27,f18
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64 + ctx.f18.f64));
	// lfs f20,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f2,f20,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// lfs f20,2364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2364);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f7,f20
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f20.f64));
	// lfs f7,-88(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -88);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f18,f16,f7
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// lfs f7,-76(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -76);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f7,f23,f7,f24
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f23,3880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3880);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,3852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3852);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f9,f24
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fmadds f27,f23,f26,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f27.f64));
	// lfs f26,3396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3396);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f9,f26
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fmadds f7,f22,f4,f7
	ctx.f7.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f7.f64));
	// lfs f22,3364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3364);
	ctx.f22.f64 = double(temp.f32);
	// lfs f4,3372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3372);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f25,f19,f12,f25
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// fadds f4,f4,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f22.f64));
	// lfs f22,4072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4072);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f0,f22,f0
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f14,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f27,f9,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64 - ctx.f18.f64));
	// lfs f18,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f3,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// lfs f16,2468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2468);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f3,f3,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f14.f64));
	// lfs f23,2024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2024);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f9,f16
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f16.f64));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f9,f23
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// lis r28,-32239
	ctx.r28.s64 = -2112815104;
	// fmuls f22,f9,f22
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f22.f64));
	// lis r8,-32230
	ctx.r8.s64 = -2112225280;
	// fnmsubs f7,f21,f1,f7
	ctx.f7.f64 = double(float(-(ctx.f21.f64 * ctx.f1.f64 - ctx.f7.f64)));
	// lfs f1,2300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2300);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f12
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f21,2460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2460);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f9,f21
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// fmadds f19,f4,f12,f0
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f0.f64));
	// lfs f0,-88(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -88);
	ctx.f0.f64 = double(temp.f32);
	// lfs f4,-148(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -148);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f27,f18,f4,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fnmsubs f17,f17,f0,f7
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f7,-84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -84);
	ctx.f7.f64 = double(temp.f32);
	// lfs f0,2124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2124);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f1,f0,f7,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 + ctx.f1.f64));
	// lfs f0,4024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4024);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f14,f9,f0
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// fmadds f0,f19,f8,f25
	ctx.f0.f64 = double(float(ctx.f19.f64 * ctx.f8.f64 + ctx.f25.f64));
	// stfs f0,4372(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4372, temp.u32);
	// lfs f0,-124(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -124);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f4,f3,f4,f27
	ctx.f4.f64 = double(float(-(ctx.f3.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// fnmsubs f25,f15,f0,f17
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f0.f64 - ctx.f17.f64)));
	// fnmsubs f3,f2,f0,f25
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f0,-120(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -120);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f4,f26,f0,f4
	ctx.f4.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lfs f25,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f3,f20,f12,f3
	ctx.f3.f64 = double(float(ctx.f20.f64 * ctx.f12.f64 + ctx.f3.f64));
	// fnmsubs f4,f16,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fmadds f3,f24,f0,f3
	ctx.f3.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f3.f64));
	// fmadds f4,f21,f0,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lfs f0,-144(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -144);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,200(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fnmsubs f7,f23,f7,f3
	ctx.f7.f64 = double(float(-(ctx.f23.f64 * ctx.f7.f64 - ctx.f3.f64)));
	// lfs f3,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f27,f14,f0,f4
	ctx.f27.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// lfs f4,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f0,f22,f12,f7
	ctx.f0.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f7.f64)));
	// lfs f7,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f1,f1,f9,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f0.f64));
	// lfs f0,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f7,f0
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// fmuls f7,f3,f31
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f26,f4,f7
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// lfs f7,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f31,f7
	ctx.f7.f64 = double(float(ctx.f31.f64 * ctx.f7.f64));
	// stfs f7,212(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmuls f25,f25,f7
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// fmuls f7,f3,f28
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f3,1372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f24,f7,f3
	ctx.f24.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f7,-152(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -152);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f2,f7
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f7,f2,f28
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f3,1452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1452);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f7,f3
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f7,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f7.f64 = double(temp.f32);
	// lfs f3,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f3,f7
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f7,1876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1876);
	ctx.f7.f64 = double(temp.f32);
	// lfs f3,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f23,f3,f7,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f7.f64 + ctx.f23.f64));
	// fmuls f7,f2,f31
	ctx.f7.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmadds f22,f4,f7,f22
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 + ctx.f22.f64));
	// stfs f7,1876(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1876, temp.u32);
	// lfs f7,2508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2508);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f20,f7,f0
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f7,2236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2236);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f19,f3,f7
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f7,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f4,f26,f7,f23
	ctx.f4.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// lfs f2,3436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3436);
	ctx.f2.f64 = double(temp.f32);
	// lfs f7,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f7.f64 = double(temp.f32);
	// lis r15,-32239
	ctx.r15.s64 = -2112815104;
	// fmuls f26,f2,f7
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// lfs f2,2476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2476);
	ctx.f2.f64 = double(temp.f32);
	// lfs f23,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f21,f21,f31
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// fmuls f23,f23,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// lfs f2,-156(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -156);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,776(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 776, temp.u32);
	// lfs f2,3388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3388);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f9,f2
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f2,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,2044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2044);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f17,f2,f17,f4
	ctx.f17.f64 = double(float(-(ctx.f2.f64 * ctx.f17.f64 - ctx.f4.f64)));
	// lfs f4,2600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2600);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// lfs f4,1920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1920);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f2,f4
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f4,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f4.f64 = double(temp.f32);
	// lfs f14,4192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4192);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f26,f14,f4,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f14,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f27,f23,f14,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f14.f64 - ctx.f27.f64)));
	// lfs f23,2244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2244);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f2,f23
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f2,3860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3860);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f14,f9,f2
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f2.f64));
	// lfs f2,-19000(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -19000);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f25,f2,f17
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f17.f64)));
	// lfs f17,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f17.f64 = double(temp.f32);
	// lfs f25,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f3,f17
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// lfs f3,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// fmuls f16,f3,f0
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// lfs f3,-160(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -160);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f3,f18,f3,f27
	ctx.f3.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// lfs f27,2484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2484);
	ctx.f27.f64 = double(temp.f32);
	// lfs f18,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f27,f27,f0
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// fmuls f18,f18,f0
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f0.f64));
	// lfs f0,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f2,f24,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f0,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f0.f64 = double(temp.f32);
	// lfs f24,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f0,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 * ctx.f24.f64));
	// lfs f0,-124(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -124);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// fmadds f3,f25,f0,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f3.f64));
	// lfs f0,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f2,f22,f0,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f2.f64));
	// lfs f0,-120(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -120);
	ctx.f0.f64 = double(temp.f32);
	// lfs f22,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f25,f18,f4,f16
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 - ctx.f16.f64));
	// fnmsubs f18,f14,f0,f3
	ctx.f18.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// lfs f3,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f0,f22,f28
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// fnmsubs f2,f3,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f3.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// fadds f0,f1,f18
	ctx.f0.f64 = double(float(ctx.f1.f64 + ctx.f18.f64));
	// stfs f0,4376(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4376, temp.u32);
	// lfs f0,-19000(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -19000);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f21,f0,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f2.f64));
	// lfs f0,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f2,f0,f1,f2
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f1,1264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1264);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f3,f1,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f1,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f20,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// fnmsubs f2,f19,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// fmadds f2,f26,f1,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f1,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f1.f64 = double(temp.f32);
	// lfs f21,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f21.f64 = double(temp.f32);
	// lis r16,-32239
	ctx.r16.s64 = -2112815104;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f16,2612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2612);
	ctx.f16.f64 = double(temp.f32);
	// lis r17,-32239
	ctx.r17.s64 = -2112815104;
	// lfs f26,-164(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -164);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f2,f15,f4,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f2.f64));
	// fnmsubs f2,f23,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// lfs f23,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f21,f23
	ctx.f19.f64 = double(float(ctx.f21.f64 * ctx.f23.f64));
	// lfs f23,1328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1328);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f2,f17,f4,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f2.f64));
	// fnmsubs f20,f27,f7,f2
	ctx.f20.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f27,2336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2336);
	ctx.f27.f64 = double(temp.f32);
	// lfs f2,-152(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -152);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fnmsubs f2,f24,f2,f25
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// lfs f25,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,2532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2532);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// lfs f27,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f0,f27
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// fnmsubs f2,f1,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// lfs f1,2252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2252);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f25,f1,f2
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// lfs f2,-516(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -516);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f1,f25,f23,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f23.f64 + ctx.f1.f64));
	// lfs f23,2076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2076);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f2,f23,f2,f24
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f24.f64));
	// lfs f24,1912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1912);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f1,f0,f24,f1
	ctx.f1.f64 = double(float(-(ctx.f0.f64 * ctx.f24.f64 - ctx.f1.f64)));
	// lfs f24,4240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4240);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f2,f24,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// lfs f24,2028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2028);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f3,f24
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// lfs f24,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f21,f27,f26,f1
	ctx.f21.f64 = double(float(-(ctx.f27.f64 * ctx.f26.f64 - ctx.f1.f64)));
	// lfs f27,3876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3876);
	ctx.f27.f64 = double(temp.f32);
	// lfs f1,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f17,f27,f1,f2
	ctx.f17.f64 = double(float(-(ctx.f27.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// lfs f2,-352(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -352);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f27,f24,f31
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fnmsubs f17,f16,f29,f17
	ctx.f17.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f17.f64)));
	// lfs f16,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f23,f27,f21
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f21.f64));
	// fnmsubs f27,f16,f27,f21
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f27.f64 - ctx.f21.f64)));
	// lfs f21,2548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2548);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f1,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f17.f64));
	// lfs f17,1332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f3,f3,f17,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f17.f64 + ctx.f27.f64));
	// lfs f27,2596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2596);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f27,f27,f7,f21
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f21.f64)));
	// lfs f17,2260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2260);
	ctx.f17.f64 = double(temp.f32);
	// lfs f21,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f3,f17,f21,f3
	ctx.f3.f64 = double(float(-(ctx.f17.f64 * ctx.f21.f64 - ctx.f3.f64)));
	// lfs f17,3444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3444);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f27,f17,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// lfs f17,1520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1520);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f3,f0,f17,f3
	ctx.f3.f64 = double(float(-(ctx.f0.f64 * ctx.f17.f64 - ctx.f3.f64)));
	// lfs f17,2084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2084);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f27,f17,f2,f27
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f27.f64));
	// fmadds f3,f19,f26,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 + ctx.f3.f64));
	// lfs f26,2200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2200);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f26,f26,f2,f27
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f27,1728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1728);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f25,f25,f27,f3
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f27.f64 - ctx.f3.f64)));
	// lfs f3,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f3,f31
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmadds f25,f23,f27,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f25.f64));
	// fmuls f27,f22,f30
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmadds f27,f0,f27,f25
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f27.f64 + ctx.f25.f64));
	// lfs f25,2012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2012);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f27,f18,f4,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fnmsubs f0,f0,f25,f27
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f25.f64 - ctx.f27.f64)));
	// lfs f27,2268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2268);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f0,f27,f21,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f21.f64 + ctx.f0.f64));
	// fadds f0,f20,f0
	ctx.f0.f64 = double(float(ctx.f20.f64 + ctx.f0.f64));
	// stfs f0,4380(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4380, temp.u32);
	// lfs f27,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f27.f64 = double(temp.f32);
	// lis r18,-32239
	ctx.r18.s64 = -2112815104;
	// lfs f0,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f27,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// lfs f22,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f22
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// lfs f16,2572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2572);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,2524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2524);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f23,2556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2556);
	ctx.f23.f64 = double(temp.f32);
	// lfs f16,2580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2580);
	ctx.f16.f64 = double(temp.f32);
	// lfs f25,3468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3468);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f23.f64));
	// lfs f23,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,4032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4032);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f0,f5
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f0,f31,f31
	ctx.f0.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmadds f17,f17,f7,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f26.f64));
	// lfs f26,1312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1312);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f21,f27,f5,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f21.f64));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f0,f23
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f23.f64));
	// lfs f0,3644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3644);
	ctx.f0.f64 = double(temp.f32);
	// lfs f23,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f27,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f18.f64));
	// fmuls f19,f23,f0
	ctx.f19.f64 = double(float(ctx.f23.f64 * ctx.f0.f64));
	// fnmsubs f21,f16,f29,f21
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f21.f64)));
	// fmuls f16,f27,f0
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f0.f64));
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f15,f0,f26
	ctx.f15.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// lfs f0,-168(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -168);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f21,f25,f29,f21
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f29.f64 + ctx.f21.f64));
	// lfs f25,2288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2288);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f17,f25,f2,f17
	ctx.f17.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f17.f64)));
	// lfs f25,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f2,12124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 12124);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f21,f14,f2,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f2.f64 + ctx.f21.f64));
	// lfs f2,2224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2224);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f17,f2,f1,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f1.f64 + ctx.f17.f64));
	// lfs f2,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f26,f2,f22,f26
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 + ctx.f26.f64));
	// lfs f22,4212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4212);
	ctx.f22.f64 = double(temp.f32);
	// lfs f2,-52(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -52);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f22,f2,f21
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// lfs f22,3892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3892);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f29,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 + ctx.f17.f64));
	// lfs f21,2176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2176);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f2,f20,f4,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f2.f64));
	// fnmsubs f22,f21,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fmadds f2,f19,f5,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f2.f64));
	// fmadds f26,f26,f5,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f22,2620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2620);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f22,f29,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 + ctx.f2.f64));
	// lfs f22,3884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3884);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f26,f22,f29,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f29.f64 - ctx.f26.f64)));
	// lfs f22,3452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3452);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f22,f7,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f2.f64));
	// lfs f22,3428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3428);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f2,f22,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f22,2588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2588);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f2,f18,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// fnmsubs f2,f22,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f22,4104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4104);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f16,f5,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 + ctx.f2.f64));
	// fnmsubs f2,f15,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// fnmsubs f2,f22,f1,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// lfs f1,2564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2564);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f1,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f1,2264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2264);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f0,f1,f0,f2
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f2.f64));
	// lfs f2,3460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3460);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f0,f2,f29,f0
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f0.f64));
	// lfs f2,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f2.f64 = double(temp.f32);
	// fadds f0,f26,f0
	ctx.f0.f64 = double(float(ctx.f26.f64 + ctx.f0.f64));
	// stfs f0,4384(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4384, temp.u32);
	// lfs f0,2924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2924);
	ctx.f0.f64 = double(temp.f32);
	// lfs f26,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f2,f0
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f1,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f1.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f18,f1,f13
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f2,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f3,f2
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f17,f3,f1
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f3,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f13,f3
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f21,f0,f26
	ctx.f21.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// lfs f0,-172(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -172);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f16,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f16.f64 = double(temp.f32);
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f26,4220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4220);
	ctx.f26.f64 = double(temp.f32);
	// lis r19,-32239
	ctx.r19.s64 = -2112815104;
	// fmuls f19,f24,f2
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// lis r29,-32239
	ctx.r29.s64 = -2112815104;
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// lis r22,-32239
	ctx.r22.s64 = -2112815104;
	// lis r20,-32239
	ctx.r20.s64 = -2112815104;
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fmadds f22,f16,f3,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f22.f64));
	// lfs f3,-176(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -176);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,3476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3476);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f3,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f3,-180(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -180);
	ctx.f3.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f24,f24,f0
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64));
	// fmuls f22,f22,f3
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64));
	// lfs f3,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f3.f64 = double(temp.f32);
	// fadds f15,f3,f26
	ctx.f15.f64 = double(float(ctx.f3.f64 + ctx.f26.f64));
	// lfs f3,2116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2116);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f17,f17,f0,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f16.f64));
	// lfs f16,2636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2636);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f11
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// lfs f26,-200(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -200);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f3,f13
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f3,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,2628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2628);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f22,f21,f0,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 - ctx.f22.f64));
	// lfs f21,4228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4228);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 + ctx.f21.f64));
	// fmuls f15,f3,f11
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// lfs f3,-184(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -184);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f3,4236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4236);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fnmsubs f22,f20,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fadds f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f3.f64));
	// lfs f3,3900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3900);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f11
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// stfs f3,1312(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1312, temp.u32);
	// lfs f3,-188(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -188);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f27,f13
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fmsubs f16,f15,f3,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 - ctx.f16.f64));
	// lfs f27,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f27.f64 = double(temp.f32);
	// lfs f3,2644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2644);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f22,f19,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// lfs f19,3404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3404);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f26,f21,f26,f24
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 + ctx.f24.f64));
	// fmuls f24,f3,f27
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f3,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f3,f13
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f3,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fnmsubs f22,f18,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f18.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// lfs f18,3484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3484);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,1312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1312);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f16,f15,f27,f16
	ctx.f16.f64 = double(float(-(ctx.f15.f64 * ctx.f27.f64 - ctx.f16.f64)));
	// lfs f27,-192(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -192);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f18,f18,f27,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,1752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1752);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f17,f13,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f22.f64));
	// lfs f27,-188(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -188);
	ctx.f27.f64 = double(temp.f32);
	// lis r22,-32239
	ctx.r22.s64 = -2112815104;
	// fmadds f27,f26,f27,f24
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f27.f64 + ctx.f24.f64));
	// lfs f26,2132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2132);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f24,f26,f13
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f26,2772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2772);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f3
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f26,2156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2156);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f11
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// stfs f26,1312(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1312, temp.u32);
	// lfs f26,-196(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -196);
	ctx.f26.f64 = double(temp.f32);
	// lis r21,-32239
	ctx.r21.s64 = -2112815104;
	// lis r20,-32239
	ctx.r20.s64 = -2112815104;
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// fnmsubs f25,f25,f0,f22
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fmadds f27,f27,f11,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fmadds f22,f19,f26,f27
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 + ctx.f27.f64));
	// lfs f27,-200(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -200);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f25,f14,f27,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f25.f64));
	// lfs f27,-208(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -208);
	ctx.f27.f64 = double(temp.f32);
	// lis r21,-32239
	ctx.r21.s64 = -2112815104;
	// lfs f19,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fnmsubs f22,f15,f27,f22
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// lfs f15,3556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3556);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f25,f23,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fnmsubs f25,f20,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fmadds f23,f18,f13,f25
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f25.f64));
	// lfs f25,-136(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -136);
	ctx.f25.f64 = double(temp.f32);
	// lfs f18,2780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2780);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f23,f21,f25,f23
	ctx.f23.f64 = double(float(-(ctx.f21.f64 * ctx.f25.f64 - ctx.f23.f64)));
	// lfs f25,-204(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -204);
	ctx.f25.f64 = double(temp.f32);
	// lis r22,-32239
	ctx.r22.s64 = -2112815104;
	// fmadds f25,f24,f25,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f25.f64 + ctx.f23.f64));
	// stfs f25,4388(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4388, temp.u32);
	// lfs f25,3548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3548);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f25,f27
	ctx.f24.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f27,2164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2164);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f27,f11
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f27,4200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4200);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f27,f10
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// lfs f25,-212(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -212);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,2180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2180);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f27,f11
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f27,-220(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -220);
	ctx.f27.f64 = double(temp.f32);
	// lis r22,-32239
	ctx.r22.s64 = -2112815104;
	// fmsubs f18,f18,f26,f24
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 - ctx.f24.f64));
	// lfs f26,-216(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -216);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f26.f64));
	// lfs f26,4128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4128);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f26,f13
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f26,2188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2188);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f25,f26,f25,f21
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f25.f64 + ctx.f21.f64));
	// lfs f21,2788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2788);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f26,f31,f31
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// lfs f24,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f24,f2
	ctx.f16.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmsubs f23,f18,f3,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 - ctx.f23.f64));
	// lfs f18,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f1
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f21,f21,f26
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64));
	// lfs f26,-420(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -420);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,500(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// lfs f26,-424(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -424);
	ctx.f26.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// fmuls f26,f15,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// lfs f15,3492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3492);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fnmsubs f23,f20,f27,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f27.f64 - ctx.f23.f64)));
	// lfs f1,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f21,f21,f1,f26
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f26.f64));
	// lfs f26,2828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2828);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f26,f3
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f26,-224(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -224);
	ctx.f26.f64 = double(temp.f32);
	// lfs f1,-448(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -448);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f25,f17,f26,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 - ctx.f25.f64));
	// lfs f26,2668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2668);
	ctx.f26.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// fmuls f17,f26,f11
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f24,f26,f2,f24
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f26,-216(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -216);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f16,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f16,2676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2676);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// lfs f2,-228(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -228);
	ctx.f2.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// fnmsubs f23,f19,f2,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// lfs f19,1312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1312);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f26,f19,f26,f22
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f19,2908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2908);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f19,f1,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f22,2228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2228);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f1,-460(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -460);
	ctx.f1.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// lfs f1,-184(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -184);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f25,f18,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f18,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f23,f15,f1,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// lfs f1,3908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3908);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f1,f11
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f1,3500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	ctx.f1.f64 = double(temp.f32);
	// fadds f16,f1,f16
	ctx.f16.f64 = double(float(ctx.f1.f64 + ctx.f16.f64));
	// lfs f1,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f1,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// lfs f15,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f22,f22,f27,f26
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f27.f64 - ctx.f26.f64)));
	// lfs f1,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,2148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2148);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f24,f15,f1,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f24.f64));
	// fmuls f15,f27,f11
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f27,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f21,f21,f3,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 - ctx.f20.f64));
	// lfs f26,2660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2660);
	ctx.f26.f64 = double(temp.f32);
	// lfs f20,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// lfs f26,-180(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -180);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f23,f17,f27,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fmuls f17,f16,f11
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f11.f64));
	// fnmsubs f26,f18,f26,f25
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f26.f64 - ctx.f25.f64)));
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f24,f13
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// lfs f24,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fnmsubs f2,f15,f2,f22
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// stfs f2,4392(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4392, temp.u32);
	// lfs f2,-432(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -432);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f20,f2,f21
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// stfs f2,4396(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4396, temp.u32);
	// fnmsubs f27,f19,f27,f23
	ctx.f27.f64 = double(float(-(ctx.f19.f64 * ctx.f27.f64 - ctx.f23.f64)));
	// lfs f2,-188(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -188);
	ctx.f2.f64 = double(temp.f32);
	// lfs f20,2928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2928);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,2916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2916);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,3620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3620);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmadds f26,f25,f0,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f26.f64));
	// fmuls f25,f1,f13
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f1,1284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1284);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f2,f17,f2,f27
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f27.f64));
	// stfs f2,4400(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4400, temp.u32);
	// lfs f2,1712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1712);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f1,f2
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,4112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4112);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f2,f13
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f27,-232(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -232);
	ctx.f27.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// lfs f2,4144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4144);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f1,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// lfs f20,2652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2652);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f2,f3
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f27,352(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// lfs f2,-236(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -236);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f17,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f1,f3
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,2732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2732);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f1,f24,f27,f23
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 - ctx.f23.f64));
	// lfs f24,2924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2924);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f3,f3,f7
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f27,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// lfs f24,3972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3972);
	ctx.f24.f64 = double(temp.f32);
	// lfs f15,3628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3628);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f26,f25,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// lfs f14,2348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2348);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,2276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2276);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f25,2196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2196);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmadds f24,f24,f2,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f2.f64 + ctx.f19.f64));
	// lfs f19,2972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2972);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,1896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1896);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f2,f22,f2,f1
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f1,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f17,f17,f7,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 - ctx.f3.f64));
	// lfs f3,2932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2932);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f3,f13
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f3,f31,f31
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f16,f1,f3
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,3508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3508);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,2700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2700);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f3,f1
	ctx.f1.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// lfs f3,-200(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -200);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f15,f3
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// lfs f3,-516(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -516);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f3,f14,f3,f17
	ctx.f3.f64 = double(float(-(ctx.f14.f64 * ctx.f3.f64 - ctx.f17.f64)));
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f2,f21,f17,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f17.f64 - ctx.f2.f64)));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// lfs f21,2284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2284);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f14,2684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2684);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f13
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fmadds f15,f1,f10,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f15.f64));
	// lfs f1,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f3,f19,f5,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f3.f64));
	// lfs f19,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f2,f18,f1,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,3980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3980);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmadds f26,f15,f13,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f26.f64));
	// fnmsubs f16,f16,f4,f3
	ctx.f16.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f2,f20,f10,f2
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f20,3644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3644);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f3,f20
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// lfs f3,-200(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -200);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f26,f18,f3,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// fnmsubs f18,f17,f5,f16
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f5.f64 - ctx.f16.f64)));
	// lfs f17,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f24,f24,f17,f2
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 + ctx.f2.f64));
	// lfs f2,-180(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -180);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f19,f19,f5,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f18.f64)));
	// fmadds f27,f27,f2,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f2,2724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2724);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f24,f2,f7,f19
	ctx.f24.f64 = double(float(-(ctx.f2.f64 * ctx.f7.f64 - ctx.f19.f64)));
	// lfs f2,-212(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -212);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f27,f23,f2,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f27.f64));
	// lfs f2,4264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4264);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f24,f2,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f2.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f2,-224(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -224);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f22,f2,f27
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// fmadds f2,f21,f3,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f2.f64));
	// fnmsubs f3,f25,f3,f2
	ctx.f3.f64 = double(float(-(ctx.f25.f64 * ctx.f3.f64 - ctx.f2.f64)));
	// lfs f2,2332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2332);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f3,f14,f10,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f3.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// stfs f3,4404(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4404, temp.u32);
	// lfs f3,-352(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -352);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f26,f20,f5,f24
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 + ctx.f24.f64));
	// fmuls f2,f2,f3
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f27,4120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4120);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,2708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2708);
	ctx.f24.f64 = double(temp.f32);
	// lfs f23,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f23.f64 = double(temp.f32);
	// fmsubs f27,f27,f29,f2
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 - ctx.f2.f64));
	// lfs f2,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f2,f25
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmadds f27,f24,f7,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfs f24,2972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2972);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f26,f25,f5,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f25,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f23,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f25,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// lfs f23,3532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3532);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f27,f23,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f23,2756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2756);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f26,f23,f29,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f29.f64 + ctx.f26.f64));
	// lfs f23,3524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3524);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f27,f23,f6,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f27.f64));
	// lfs f23,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// fnmsubs f2,f24,f5,f26
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f26,2748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2748);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f26,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f26,1760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1760);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f2,f25,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f5,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f5.f64 = double(temp.f32);
	// lfs f25,4152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4152);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f27,f26,f5,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f27.f64));
	// lfs f26,3932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3932);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f26,f26,f29,f2
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f2,1832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1832);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f27,f2,f5,f27
	ctx.f27.f64 = double(float(-(ctx.f2.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// lfs f2,12124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 12124);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fnmsubs f2,f25,f2,f26
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// lfs f26,2292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2292);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,2980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2980);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f27,f26,f3,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f3.f64 + ctx.f27.f64));
	// fmadds f26,f23,f7,f2
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f2.f64));
	// lfs f2,2692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2692);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f27,f2,f5,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f5.f64 + ctx.f27.f64));
	// lfs f2,-52(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -52);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f26,f25,f2,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f26.f64));
	// lfs f2,2764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2764);
	ctx.f2.f64 = double(temp.f32);
	// lfs f25,2316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2316);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f27,f2,f29,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f27.f64));
	// lfs f2,-168(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -168);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f26,f25,f2,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f26.f64));
	// lfs f25,3652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3652);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f5,f25,f5,f27
	ctx.f5.f64 = double(float(-(ctx.f25.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// lfs f27,3916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3916);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f26,f27,f6,f26
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f6,3516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3516);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f6,f6,f29,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f29.f64 + ctx.f5.f64));
	// lfs f5,2308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2308);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f6,f5,f2,f6
	ctx.f6.f64 = double(float(-(ctx.f5.f64 * ctx.f2.f64 - ctx.f6.f64)));
	// lfs f5,2340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2340);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f6,f5,f3,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f3.f64 + ctx.f6.f64));
	// lfs f5,3540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3540);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f6,f5,f7,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f6.f64));
	// lfs f5,2716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2716);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f25,f5,f29,f6
	ctx.f25.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f6.f64)));
	// lfs f6,1444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1444);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f5,f6
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f5,f6
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,1544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1544);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f5,f6
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f22,f3,f6
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f5,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f5.f64 = double(temp.f32);
	// lis r23,-32239
	ctx.r23.s64 = -2112815104;
	// fmuls f21,f2,f5
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f5,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// lfs f2,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f17,f2,f6
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f2,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f6,f2
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f2,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f2.f64 = double(temp.f32);
	// lfs f15,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// fmuls f20,f3,f5
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f5,-19000(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -19000);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f27,f5
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f5,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f24,f5
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// lfs f27,-240(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -240);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f23,f23,f2,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f19.f64));
	// lfs f2,2108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2108);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f24,f22,f5,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 - ctx.f24.f64));
	// lfs f22,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f18,f30
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfs f18,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// lfs f6,1884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1884);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f15,f15,f6
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f6.f64));
	// lfs f6,1512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1512);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// fnmsubs f23,f6,f14,f23
	ctx.f23.f64 = double(float(-(ctx.f6.f64 * ctx.f14.f64 - ctx.f23.f64)));
	// lfs f6,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f24,f20,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// fmuls f20,f6,f2
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f2,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fnmsubs f27,f21,f27,f23
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f27.f64 - ctx.f23.f64)));
	// lfs f23,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f24,f17,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f17.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// lfs f17,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f15,f23,f20
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 + ctx.f20.f64));
	// lfs f20,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f20.f64));
	// lfs f15,1544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1544);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f6,f2
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// fmuls f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// lfs f6,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,2364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2364);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f6,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// stfs f2,1884(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1884, temp.u32);
	// lfs f21,2380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2380);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f27,f19,f15,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f15.f64 + ctx.f27.f64));
	// lfs f19,2740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2740);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f7,f25
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f25.f64));
	// lfs f25,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f25.f64 = double(temp.f32);
	// fmr f2,f25
	ctx.f2.f64 = ctx.f25.f64;
	// lfs f25,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f24,f16,f5,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 + ctx.f24.f64));
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f20,f20,f30
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f30.f64));
	// fnmsubs f22,f22,f2,f27
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f27,1876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1876);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f24,f18,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f18.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// fmuls f18,f3,f27
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f27,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmadds f22,f14,f2,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f2.f64 + ctx.f22.f64));
	// fmadds f24,f23,f2,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f23,1892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1892);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f16,f25,f27
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f27,3924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3924);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f27,f27,f7,f19
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f19.f64)));
	// lfs f19,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f23,f23,f19,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f19.f64 - ctx.f18.f64));
	// fadds f27,f26,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 + ctx.f27.f64));
	// stfs f27,4408(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4408, temp.u32);
	// lfs f27,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f26,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f23,f16,f5,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 + ctx.f23.f64));
	// lfs f18,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f27,f26,f27,f22
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// lfs f26,1884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1884);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f26,f26,f4,f24
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f4.f64 - ctx.f24.f64)));
	// lfs f24,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f27,f21,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// fmadds f26,f17,f2,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f26.f64));
	// lfs f2,-240(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -240);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f20,f2,f27
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f27,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f27,f24,f27,f26
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f27.f64 - ctx.f26.f64)));
	// lfs f26,1332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f2,f26,f24,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f2.f64));
	// lfs f24,2852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2852);
	ctx.f24.f64 = double(temp.f32);
	// fadds f22,f27,f2
	ctx.f22.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// lfs f27,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f2,f24,f6
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f26,f27,f6
	ctx.f26.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f6,f27
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f27,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f3,f27
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f27,4136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4136);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f27,f6
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f18,f27
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f27,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f3,f27
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fmuls f14,f25,f27
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// fnmsubs f23,f2,f4,f23
	ctx.f23.f64 = double(float(-(ctx.f2.f64 * ctx.f4.f64 - ctx.f23.f64)));
	// lfs f2,-152(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -152);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f26,f2
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// lfs f26,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f15.f64));
	// fmuls f3,f3,f26
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmuls f18,f18,f30
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// fmadds f23,f21,f2,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 + ctx.f23.f64));
	// lfs f2,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f21,f20,f2,f16
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f16,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f16.f64 = double(temp.f32);
	// lfs f20,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// lfs f16,3216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3216);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f7,f19,f7,f23
	ctx.f7.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// lfs f23,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f23,f17,f23,f21
	ctx.f23.f64 = double(float(-(ctx.f17.f64 * ctx.f23.f64 - ctx.f21.f64)));
	// lfs f19,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,3408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3408);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f20,f6
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f6,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f6.f64 = double(temp.f32);
	// lfs f20,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f6,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f6.f64 = double(temp.f32);
	// lfs f17,3956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3956);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f18,f6,f7
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f7.f64));
	// lfs f7,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,3240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3240);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// fmuls f18,f6,f7
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f6,-120(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -120);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fmadds f23,f15,f2,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 + ctx.f23.f64));
	// fmuls f15,f7,f27
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// lfs f7,1900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1900);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f7,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f19.f64));
	// lfs f7,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f20,f20,f7,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f18.f64));
	// lfs f7,2876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2876);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f19,f7,f6,f17
	ctx.f19.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 - ctx.f17.f64));
	// lfs f7,-124(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -124);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f23,f14,f2,f23
	ctx.f23.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// fmuls f18,f16,f7
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// lfs f16,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f23,f3,f2,f23
	ctx.f23.f64 = double(float(-(ctx.f3.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// lfs f17,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f19,f19,f9,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64 - ctx.f18.f64));
	// fmuls f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// lfs f14,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,1320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1320);
	ctx.f16.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// lfs f3,3604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3604);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f16,f14,f16,f27
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f16.f64 + ctx.f27.f64));
	// fmuls f14,f3,f9
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f9.f64));
	// lfs f3,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,3232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3232);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// lfs f27,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f20,f2,f3,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fmuls f2,f27,f28
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f18,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f18.f64 = double(temp.f32);
	// stfs f2,376(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmadds f25,f25,f4,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f23.f64));
	// lfs f4,-500(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -500);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f23,f20,f7,f19
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f19.f64));
	// lfs f19,3612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3612);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f2,f2,f18,f16
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f18.f64 - ctx.f16.f64)));
	// lfs f18,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f20,3228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3228);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f26,f26,f4,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f4,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f20,f20,f9
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64));
	// fmadds f25,f14,f6,f23
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f6.f64 + ctx.f23.f64));
	// lfs f23,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f2,f21,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// fmadds f25,f24,f12,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f25.f64));
	// lfs f24,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f4,f4,f23,f2
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f23.f64 - ctx.f2.f64)));
	// fmadds f2,f15,f5,f26
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 + ctx.f26.f64));
	// lfs f5,-19000(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -19000);
	ctx.f5.f64 = double(temp.f32);
	// fadds f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// fmadds f5,f17,f5,f2
	ctx.f5.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f2,2988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2988);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,2032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2032);
	ctx.f17.f64 = double(temp.f32);
	// fadds f5,f4,f5
	ctx.f5.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// stfs f5,4412(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4412, temp.u32);
	// lfs f5,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f5,f4
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,-128(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -128);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f2,f4
	ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f2,3988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3988);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f2,f9
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f2,3660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3660);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f2,f9
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f2,3020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3020);
	ctx.f2.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// fmuls f21,f2,f9
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// lfs f2,3208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3208);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f5,f9,f5
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f5.f64));
	// fmuls f3,f2,f3
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f2,-148(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -148);
	ctx.f2.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// fmsubs f26,f26,f2,f4
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f4.f64));
	// lfs f4,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fmuls f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// lfs f5,-140(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -140);
	ctx.f5.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// fmsubs f26,f26,f9,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64 - ctx.f23.f64));
	// lfs f23,2048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2048);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lfs f5,2056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2056);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f18,f5,f9
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f5,-76(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -76);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f17,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// lfs f5,-132(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -132);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f25,f24,f2,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// fmadds f26,f22,f4,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f4,2672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2672);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f24,f4,f5,f23
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 + ctx.f23.f64));
	// lfs f5,4248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4248);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f5,f9
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f5,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// lfs f5,2296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2296);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f5,f9
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f5,2216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2216);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f17,f5,f12,f17
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f17.f64));
	// lfs f5,2884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2884);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f5,f9
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f4,-88(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -88);
	ctx.f4.f64 = double(temp.f32);
	// lfs f5,-84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -84);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f26,f21,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fnmsubs f25,f18,f5,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f5.f64 - ctx.f25.f64)));
	// lfs f18,2944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2944);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,2696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2696);
	ctx.f21.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// fadds f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f18.f64));
	// lfs f18,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f9
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f9.f64));
	// lfs f15,2868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2868);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// lfs f14,3848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3848);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fnmsubs f3,f3,f7,f26
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f7,1940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1940);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f26,f17,f9,f25
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f9.f64 + ctx.f25.f64));
	// lfs f25,2008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2008);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f7
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// lfs f17,2040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2040);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f9
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f9.f64));
	// fmuls f14,f14,f7
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f7.f64));
	// fmadds f27,f21,f12,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f27.f64));
	// lfs f21,2892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2892);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fnmsubs f3,f20,f4,f3
	ctx.f3.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f4,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f22,f22,f12,f26
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// fmuls f25,f25,f4
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f4,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f4,f7
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// lfs f4,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f7
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// lfs f4,-156(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -156);
	ctx.f4.f64 = double(temp.f32);
	// stfs f26,1320(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1320, temp.u32);
	// fmuls f27,f27,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fnmsubs f4,f19,f4,f3
	ctx.f4.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,-136(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -136);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f5,f18,f5,f22
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f18,3912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3912);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f27,f25,f2,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 - ctx.f27.f64));
	// fmadds f4,f24,f9,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f9.f64 + ctx.f4.f64));
	// fnmsubs f25,f17,f3,f5
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f3.f64 - ctx.f5.f64)));
	// lfs f17,3920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3920);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f24,f14,f12,f27
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f27.f64)));
	// lfs f27,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f5,f23,f6,f4
	ctx.f5.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fmadds f5,f16,f6,f5
	ctx.f5.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f5.f64));
	// fnmsubs f4,f15,f6,f5
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// lfs f5,-160(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -160);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f5,f21,f5,f4
	ctx.f5.f64 = double(float(-(ctx.f21.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// lfs f4,2384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2384);
	ctx.f4.f64 = double(temp.f32);
	// fadds f5,f25,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// stfs f5,4416(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4416, temp.u32);
	// lfs f5,3872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3872);
	ctx.f5.f64 = double(temp.f32);
	// fadds f25,f5,f4
	ctx.f25.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f5,3888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3888);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,3896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3896);
	ctx.f4.f64 = double(temp.f32);
	// fadds f23,f5,f4
	ctx.f23.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// lfs f5,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f4,f5
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// lfs f5,2312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2312);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f27,f5
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f5,3904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3904);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f5,f7
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// lfs f5,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f18,f5,f18
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// fadds f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 + ctx.f17.f64));
	// fmuls f23,f23,f7
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f7.f64));
	// fmuls f22,f22,f31
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// fmuls f21,f21,f0
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64));
	// lfs f25,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f17,f7
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64));
	// fmuls f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// lfs f25,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f25.f64 = double(temp.f32);
	// lfs f16,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f23,f23,f12
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f12.f64));
	// fmuls f16,f16,f25
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// lfs f14,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f22,f22,f10,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 - ctx.f21.f64));
	// lfs f14,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f26,f15
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f15.f64));
	// fmuls f14,f4,f14
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f14.f64));
	// fmadds f24,f20,f6,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f24.f64));
	// lfs f20,3928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3928);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f23,f17,f3,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 - ctx.f23.f64));
	// fmuls f21,f16,f7
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// lfs f16,3936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3936);
	ctx.f16.f64 = double(temp.f32);
	// fadds f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f16.f64));
	// fmuls f16,f25,f7
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f7.f64));
	// lfs f25,2052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2052);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f27,f25
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f22,f18,f1,f22
	ctx.f22.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f22.f64)));
	// fmuls f18,f26,f25
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fnmsubs f23,f19,f3,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f23.f64)));
	// lfs f19,3960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3960);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f26,f21,f2,f24
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f2.f64 - ctx.f24.f64)));
	// lfs f21,3944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3944);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f20,f7
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// lfs f20,3952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3952);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f19,f7
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f7.f64));
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmadds f22,f14,f10,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f22.f64));
	// lfs f14,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fnmsubs f23,f15,f2,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// fmadds f24,f24,f3,f26
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f26.f64));
	// lfs f26,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f26.f64));
	// lfs f26,3968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3968);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f22,f17,f10,f22
	ctx.f22.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f22.f64)));
	// fmuls f17,f26,f12
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f26,3976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3976);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f21,f26,f12,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f21.f64));
	// lfs f26,3984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3984);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f5,f26
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fnmsubs f3,f19,f3,f24
	ctx.f3.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f24.f64)));
	// fmadds f24,f16,f6,f23
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f23.f64));
	// fnmsubs f23,f20,f1,f22
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f1.f64 - ctx.f22.f64)));
	// fmadds f22,f14,f6,f17
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f6.f64 + ctx.f17.f64));
	// lfs f6,3992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3992);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f6,f7
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f6,4000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4000);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f5,f6
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fnmsubs f2,f18,f2,f24
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f2.f64 - ctx.f24.f64)));
	// lfs f24,2036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2036);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// fnmsubs f23,f15,f1,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// fmadds f3,f22,f7,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f3.f64));
	// lfs f22,1920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1920);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f21,f7,f2
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f2.f64));
	// fmadds f2,f25,f10,f23
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f23.f64));
	// lfs f25,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,4008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4008);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// fnmsubs f7,f20,f12,f7
	ctx.f7.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f7.f64)));
	// fmadds f2,f19,f1,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 + ctx.f2.f64));
	// fadds f7,f3,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 + ctx.f7.f64));
	// lfs f3,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f3.f64 = double(temp.f32);
	// stfs f7,4420(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4420, temp.u32);
	// fmuls f3,f3,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f7,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f7.f64 = double(temp.f32);
	// lfs f25,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f25.f64 = double(temp.f32);
	// fadds f7,f26,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 + ctx.f7.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lfs f20,1580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f3,f3,f0,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 - ctx.f25.f64));
	// fmuls f7,f7,f20
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f20.f64));
	// lfs f17,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f2,f24,f10,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f24,1328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1328);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f4,f24
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f24.f64));
	// lfs f16,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f4,f17
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// lfs f21,4016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4016);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,1856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1856);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// lfs f14,2008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2008);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// lfs f25,1224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1224);
	ctx.f25.f64 = double(temp.f32);
	// lis r14,-32239
	ctx.r14.s64 = -2112815104;
	// lfs f19,1956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1956);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f25,f27,f25
	ctx.f25.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f18,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f27,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f26,f18,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// lfs f18,1728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1728);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f2,f24,f10,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f24,3092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3092);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// lfs f16,1924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1924);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f15,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmuls f15,f5,f15
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// fmuls f18,f4,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// fmadds f7,f3,f4,f7
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 + ctx.f7.f64));
	// lfs f3,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fmuls f5,f5,f14
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// lfs f14,2192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2192);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// fmuls f24,f24,f28
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// fmadds f7,f23,f1,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f7.f64));
	// lfs f1,1916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1916);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// lfs f23,1936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1936);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f4,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fnmsubs f22,f22,f10,f7
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f7,-180(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -180);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f1,f1,f7
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// lfs f7,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f6,f7
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,2280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2280);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f27,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// lfs f7,1844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1844);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f4,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f7.f64));
	// lfs f4,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f4.f64 = double(temp.f32);
	// stfs f7,328(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmr f7,f4
	ctx.f7.f64 = ctx.f4.f64;
	// lfs f4,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f1,f14,f0,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f1.f64));
	// fnmsubs f22,f21,f7,f22
	ctx.f22.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f22.f64)));
	// lfs f21,2104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2104);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// fmsubs f6,f6,f0,f1
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f0.f64 - ctx.f1.f64));
	// fmadds f7,f20,f7,f22
	ctx.f7.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f22.f64));
	// fnmsubs f7,f25,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f25.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fnmsubs f7,f19,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f19.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fadds f7,f2,f7
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f7.f64));
	// lfs f1,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f0,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fmadds f7,f26,f10,f7
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f10.f64 + ctx.f7.f64));
	// fnmsubs f7,f18,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// fmadds f6,f17,f0,f7
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f7.f64));
	// lfs f7,-176(r14)
	temp.u32 = PPC_LOAD_U32(ctx.r14.u32 + -176);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,760(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 760, temp.u32);
	// fnmsubs f6,f3,f7,f6
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// fmadds f6,f24,f10,f6
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f6.f64));
	// fmadds f6,f16,f7,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 + ctx.f6.f64));
	// lfs f3,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f6,f15,f7,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f6.f64));
	// lfs f15,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f13
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// fnmsubs f6,f23,f0,f6
	ctx.f6.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fnmsubs f7,f5,f7,f6
	ctx.f7.f64 = double(float(-(ctx.f5.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// lfs f6,2016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2016);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f31,f30
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f30.f64));
	// stfs f5,388(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fnmsubs f25,f27,f0,f7
	ctx.f25.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fmuls f7,f5,f13
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// stfs f7,1728(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1728, temp.u32);
	// lfs f7,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f5,f7
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// lfs f7,2120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2120);
	ctx.f7.f64 = double(temp.f32);
	// fadds f26,f6,f7
	ctx.f26.f64 = double(float(ctx.f6.f64 + ctx.f7.f64));
	// lfs f7,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f13,f7
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f6,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f6,f7
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fmuls f6,f30,f28
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f23,f3,f6
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f3,f31,f28
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmuls f2,f3,f13
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// lfs f3,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f6,f3,f6,f27
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f27.f64));
	// lfs f3,2064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2064);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f3,f7
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f7,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f13,f7
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f7.f64));
	// lfs f7,2248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2248);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f27.f64 = double(temp.f32);
	// stfs f3,1856(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1856, temp.u32);
	// fmuls f20,f7,f3
	ctx.f20.f64 = double(float(ctx.f7.f64 * ctx.f3.f64));
	// lfs f7,2092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2092);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f24,f26,f7,f24
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f7,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f7.f64 = double(temp.f32);
	// lfs f26,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f27,f7,f6
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f6.f64));
	// fmuls f19,f26,f7
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f7,-180(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -180);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f21,f21,f7,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f1.f64));
	// stfs f7,420(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lfs f7,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f7.f64 = double(temp.f32);
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfs f27,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f27.f64 = double(temp.f32);
	// lfs f1,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f1.f64 = double(temp.f32);
	// stfs f7,1248(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1248, temp.u32);
	// lfs f6,-192(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -192);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// stfs f6,600(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f17,f27,f7
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmuls f7,f1,f31
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fnmsubs f21,f17,f0,f21
	ctx.f21.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f21.f64)));
	// fmuls f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// lfs f7,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f7,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f7,f13
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f7,f7,f30
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f14,f7,f14
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f14.f64));
	// fmuls f7,f1,f30
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmadds f16,f4,f7,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f7.f64 + ctx.f16.f64));
	// lfs f4,1812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1812);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f1,f4,f30
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f7,-224(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + -224);
	ctx.f7.f64 = double(temp.f32);
	// lfs f4,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f24,f18,f7,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 + ctx.f24.f64));
	// fmadds f21,f16,f0,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fmuls f18,f4,f1
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// lfs f1,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// lfs f1,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f24,f23,f6,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f16,1728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1728);
	ctx.f16.f64 = double(temp.f32);
	// lfs f23,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f21,f14,f10,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f21.f64));
	// fmadds f23,f23,f16,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64 + ctx.f22.f64));
	// lfs f22,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// fmuls f2,f16,f2
	ctx.f2.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// lis r9,-32239
	ctx.r9.s64 = -2112815104;
	// fmuls f16,f15,f30
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// fmuls f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f27,1952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1952);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmadds f24,f23,f6,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f24.f64));
	// fmuls f3,f3,f13
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmuls f15,f3,f31
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f23,f18,f3,f21
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f21.f64));
	// lfs f3,-100(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -100);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f24,f20,f3,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f24.f64)));
	// stfs f3,360(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// lfs f20,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f1,f1,f10,f23
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f10.f64 - ctx.f23.f64)));
	// fnmsubs f24,f19,f6,f24
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// fadds f1,f25,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 + ctx.f1.f64));
	// stfs f1,4424(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4424, temp.u32);
	// fmadds f1,f22,f6,f24
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f24.f64));
	// fnmsubs f2,f2,f6,f1
	ctx.f2.f64 = double(float(-(ctx.f2.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// fnmsubs f2,f26,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f26.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// fnmsubs f1,f17,f6,f2
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// lfs f2,-212(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + -212);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,712(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 712, temp.u32);
	// fnmsubs f1,f16,f2,f1
	ctx.f1.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// fnmsubs f3,f27,f3,f1
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f3.f64 - ctx.f1.f64)));
	// lfs f1,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f22,f15,f2,f3
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f3.f64)));
	// lfs f3,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f27,f5,f3
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f5,f3
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f2,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f3.f64 = double(temp.f32);
	// fadds f25,f3,f2
	ctx.f25.f64 = double(float(ctx.f3.f64 + ctx.f2.f64));
	// lfs f3,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f30,f28
	ctx.f2.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f19,f27,f6
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmuls f24,f3,f2
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f3,f31,f28
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// fmadds f25,f25,f27,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f27.f64 + ctx.f24.f64));
	// lfs f27,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f3,f1
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f1,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmadds f24,f5,f27,f23
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f23.f64));
	// lfs f27,-200(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -200);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f1,f30
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f1,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// stfs f27,340(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// fmuls f27,f21,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// lfs f21,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f23,f20,f6,f19
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 - ctx.f19.f64));
	// fmadds f21,f3,f21,f25
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f21.f64 + ctx.f25.f64));
	// lfs f25,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f1,f13
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmadds f24,f24,f7,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfs f27,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f1,f27
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f1,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f26,f23,f13,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f13.f64 - ctx.f26.f64));
	// fmadds f23,f25,f1,f21
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f21.f64));
	// fmuls f21,f20,f27
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// fmadds f17,f24,f13,f26
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f26.f64));
	// lfs f26,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f26.f64 = double(temp.f32);
	// lfs f24,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fadds f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 + ctx.f24.f64));
	// lfs f26,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f23,f26,f1,f23
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f24,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f26.f64 = double(temp.f32);
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// fadds f15,f24,f26
	ctx.f15.f64 = double(float(ctx.f24.f64 + ctx.f26.f64));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f26,f28,f28
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// lfs f18,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f18.f64 = double(temp.f32);
	// fadds f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// fmuls f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// fnmsubs f21,f21,f7,f17
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f17.f64)));
	// fmadds f23,f25,f27,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f27.f64 + ctx.f23.f64));
	// lfs f25,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f26,f31
	ctx.f24.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// stfs f24,1304(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1304, temp.u32);
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fnmsubs f21,f19,f7,f21
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f21.f64)));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmuls f20,f20,f24
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f24.f64));
	// lfs f24,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f2
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f2.f64));
	// fmuls f24,f2,f31
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f17,f15,f24
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// fmuls f15,f3,f25
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// fmuls f25,f30,f30
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// fmuls f3,f25,f28
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// stfs f3,1272(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1272, temp.u32);
	// fmadds f20,f16,f3,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f20.f64));
	// lfs f3,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f17,f3
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// fmuls f3,f26,f30
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f26,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// stfs f3,372(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fmuls f16,f14,f13
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f13.f64));
	// fmuls f17,f15,f13
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f13.f64));
	// lfs f14,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f20,f26,f3,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fmuls f3,f31,f31
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f26,f3,f28
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// stfs f26,1192(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1192, temp.u32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// stfs f3,472(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// fmuls f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// fmuls f14,f14,f26
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f26.f64));
	// fmadds f26,f23,f7,f21
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f21.f64));
	// lfs f21,4040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4040);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f23,f20,f29,f19
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 + ctx.f19.f64));
	// lfs f20,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f20.f64 = double(temp.f32);
	// fadds f19,f1,f27
	ctx.f19.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// fnmsubs f26,f18,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// fmadds f21,f21,f20,f23
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f23.f64));
	// lfs f23,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f3,f30
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fnmsubs f26,f16,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// fmsubs f21,f15,f23,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 - ctx.f21.f64));
	// fnmsubs f26,f17,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// fadds f26,f22,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 + ctx.f26.f64));
	// stfs f26,4428(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4428, temp.u32);
	// lfs f26,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// lfs f22,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f26,f22
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f22.f64));
	// lfs f26,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f26,f24
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f26,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// stfs f26,836(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 836, temp.u32);
	// fmuls f26,f25,f31
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// lfs f22,-18328(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -18328);
	ctx.f22.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f24,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f24.f64 = double(temp.f32);
	// stfs f26,1288(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1288, temp.u32);
	// fmuls f25,f20,f23
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f23.f64));
	// fmuls f16,f27,f26
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f27,-244(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -244);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// lfs f20,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,1820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1820);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f19,f19,f3,f25
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f25.f64));
	// fmuls f23,f23,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f20.f64));
	// lfs f18,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f18.f64 = double(temp.f32);
	// lfs f20,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f20.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f25,-184(r19)
	temp.u32 = PPC_LOAD_U32(ctx.r19.u32 + -184);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f15,4196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4196);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// stfs f25,504(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fmuls f18,f24,f25
	ctx.f18.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f24,1972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1972);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f15,f24
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// lfs f24,-108(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -108);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f24
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// stfs f24,584(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// lfs f24,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f1,f17,f22,f19
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 + ctx.f19.f64));
	// fmuls f24,f28,f24
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// stfs f24,436(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// lfs f22,4048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4048);
	ctx.f22.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f19,4056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4056);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,4124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4124);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f22,f22,f27,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 - ctx.f18.f64));
	// lfs f18,4108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4108);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,4116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4116);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f1,f16,f29,f1
	ctx.f1.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// lfs f16,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f24,f3,f24
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// fmuls f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f24,1996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1996);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// lfs f17,4132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4132);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f22,f17,f27,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f22.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f17,f17,f16,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f14.f64));
	// lfs f16,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f14,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,4140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4140);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f1,f16,f14,f1
	ctx.f1.f64 = double(float(-(ctx.f16.f64 * ctx.f14.f64 - ctx.f1.f64)));
	// fmuls f16,f3,f2
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f3,-468(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -468);
	ctx.f3.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f3,264(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// lfs f3,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,4148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4148);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f23,f22,f3,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f23.f64));
	// lfs f3,-420(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -420);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f2,f3
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stfs f3,500(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// lfs f3,4156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4156);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f20,f20,f29,f1
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// fmuls f14,f2,f3
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f3,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f3.f64));
	// lfs f2,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,656(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 656, temp.u32);
	// lfs f1,-188(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + -188);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,440(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fnmsubs f23,f15,f1,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// fmuls f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f2,4164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4164);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f25,f2,f27,f25
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f27.f64 - ctx.f25.f64));
	// lfs f2,4172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4172);
	ctx.f2.f64 = double(temp.f32);
	// fadds f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f2.f64));
	// lfs f2,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,328(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmr f3,f2
	ctx.f3.f64 = ctx.f2.f64;
	// lfs f2,2020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2020);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f24,f2,f3,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f2,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f21,f17,f2,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f21.f64));
	// lfs f1,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f25,f18,f27,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f25.f64));
	// fmuls f17,f1,f3
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f22,f16,f3,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 - ctx.f22.f64));
	// lfs f3,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f14,f3
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// lfs f1,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,4180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4180);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f20,f3,f1,f20
	ctx.f20.f64 = double(float(-(ctx.f3.f64 * ctx.f1.f64 - ctx.f20.f64)));
	// lfs f3,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f3.f64 = double(temp.f32);
	// lfs f18,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// lfs f15,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f23,f15,f18,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f18.f64 - ctx.f23.f64)));
	// lfs f18,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f22,f22,f18,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64 - ctx.f16.f64));
	// stfs f22,4440(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4440, temp.u32);
	// lfs f22,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f26,f26,f29,f20
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f20.f64)));
	// fmadds f22,f25,f22,f24
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f22.f64 + ctx.f24.f64));
	// lfs f25,4188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4188);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f27,f19,f27,f23
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f23.f64));
	// lfs f23,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f26,f25,f1,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// fmadds f3,f17,f3,f27
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 + ctx.f27.f64));
	// stfs f3,4436(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4436, temp.u32);
	// fadds f3,f21,f26
	ctx.f3.f64 = double(float(ctx.f21.f64 + ctx.f26.f64));
	// stfs f3,4432(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4432, temp.u32);
	// lfs f3,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f26,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f5,f3
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// stfs f3,2260(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2260, temp.u32);
	// fmuls f27,f27,f29
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f29.f64));
	// fmuls f25,f5,f3
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,1272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1272);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f23,f3
	ctx.f21.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f26
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// lfs f3,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fmuls f18,f25,f2
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f25,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f21,f21,f29,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f29.f64 - ctx.f27.f64));
	// lfs f27,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f5,f3
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// fnmsubs f21,f20,f29,f21
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f29.f64 - ctx.f21.f64)));
	// fmuls f17,f5,f3
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f3,f24
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// lfs f3,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f18,f27,f3,f18
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f18.f64));
	// lfs f27,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f3,f25
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// fmuls f14,f27,f25
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f25,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f23,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f25,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// fmadds f21,f17,f29,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 + ctx.f21.f64));
	// fnmsubs f20,f19,f2,f18
	ctx.f20.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f18.f64)));
	// lfs f19,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f26,f19
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f26,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f26,f25
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f26,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmadds f20,f16,f2,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f20.f64));
	// lfs f16,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f5,f26
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f17,f5,f26
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,4196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4196);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f16
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// lfs f26,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f21,f15,f29,f21
	ctx.f21.f64 = double(float(-(ctx.f15.f64 * ctx.f29.f64 - ctx.f21.f64)));
	// fnmsubs f20,f26,f27,f20
	ctx.f20.f64 = double(float(-(ctx.f26.f64 * ctx.f27.f64 - ctx.f20.f64)));
	// lfs f26,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f17,f27,f26,f17
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f26.f64 + ctx.f17.f64));
	// lfs f27,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f16,f27
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f27,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,1272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1272);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f26,f3,f26
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// fmuls f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f15.f64));
	// lfs f27,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f30,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// stfs f27,2336(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2336, temp.u32);
	// fmadds f21,f14,f29,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f29.f64 + ctx.f21.f64));
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f24,f24,f2,f20
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// lfs f20,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// fmuls f27,f30,f28
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fnmsubs f24,f23,f2,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f2.f64 - ctx.f24.f64)));
	// fmuls f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f27.f64));
	// lfs f14,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f22,f16,f14,f22
	ctx.f22.f64 = double(float(-(ctx.f16.f64 * ctx.f14.f64 - ctx.f22.f64)));
	// lfs f16,4204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4204);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f21,f16,f1,f21
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f1.f64 - ctx.f21.f64)));
	// lfs f16,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmadds f2,f25,f2,f24
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f25,1816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1816);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f13
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmuls f23,f27,f13
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// lfs f27,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f27,f20,f27,f22
	ctx.f27.f64 = double(float(-(ctx.f20.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// stfs f27,4444(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4444, temp.u32);
	// fmadds f27,f19,f29,f21
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f21.f64));
	// lfs f22,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// fnmsubs f2,f18,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// fmadds f27,f25,f1,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f25,1736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1736);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmadds f2,f17,f29,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 + ctx.f2.f64));
	// fnmsubs f27,f25,f1,f27
	ctx.f27.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// lfs f25,1880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1880);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f2,f26,f29,f2
	ctx.f2.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f2.f64)));
	// lfs f26,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmadds f1,f25,f1,f27
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f27,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f27.f64 = double(temp.f32);
	// lfs f25,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// fmuls f19,f26,f13
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f26,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f1,f15,f29,f1
	ctx.f1.f64 = double(float(-(ctx.f15.f64 * ctx.f29.f64 - ctx.f1.f64)));
	// lfs f15,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f17,f25,f13
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f25,f26,f27
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fadds f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// stfs f2,4448(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4448, temp.u32);
	// lfs f2,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f13,f2
	ctx.f2.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// lfs f1,2080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2080);
	ctx.f1.f64 = double(temp.f32);
	// stfs f2,300(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// fmuls f1,f27,f13
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// fmuls f21,f2,f6
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f2,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f1,f2
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f31,f28
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmsubs f23,f23,f7,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 - ctx.f21.f64));
	// lfs f21,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f2,f1
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmuls f1,f30,f28
	ctx.f1.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f15,f2,f15
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// fmuls f18,f18,f13
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64));
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// fnmsubs f23,f20,f7,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// lfs f20,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f27,f20,f27,f16
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f16,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f2,f2,f16
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// lfs f16,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f14,f25,f13
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// fmuls f20,f15,f7
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// lfs f15,2136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2136);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmadds f23,f19,f7,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f23.f64));
	// lfs f19,1960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1960);
	ctx.f19.f64 = double(temp.f32);
	// fadds f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 + ctx.f19.f64));
	// fmuls f15,f2,f13
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lfs f2,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// fmadds f20,f27,f6,f20
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f20.f64));
	// lfs f27,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// stfs f27,1012(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1012, temp.u32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fnmsubs f23,f17,f7,f23
	ctx.f23.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// fmuls f17,f2,f1
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f2,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f2,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f2,2028(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2028, temp.u32);
	// fmuls f1,f1,f13
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fnmsubs f24,f24,f7,f23
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// fmuls f23,f17,f13
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// lfs f17,2184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2184);
	ctx.f17.f64 = double(temp.f32);
	// fadds f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// lfs f27,3048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3048);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f19,f27,f16
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f19,1932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1932);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f1,f17
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// lfs f16,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,2304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2304);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f24,f22,f7,f24
	ctx.f24.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// lfs f22,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmadds f27,f17,f16,f27
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f27.f64));
	// fnmsubs f24,f18,f7,f24
	ctx.f24.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fmsubs f27,f2,f22,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f22.f64 - ctx.f27.f64));
	// lfs f22,2184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2184);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f2,f14,f7,f24
	ctx.f2.f64 = double(float(-(ctx.f14.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// lfs f24,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f2,f21,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f21,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f2,f20,f13,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f2.f64));
	// fnmsubs f2,f26,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f26,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f27,f19,f26,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f26.f64 + ctx.f27.f64));
	// lfs f26,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f5,f26
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f5,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// fnmsubs f2,f15,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// fnmsubs f2,f25,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// fnmsubs f2,f23,f7,f2
	ctx.f2.f64 = double(float(-(ctx.f23.f64 * ctx.f7.f64 - ctx.f2.f64)));
	// lfs f23,2320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2320);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// fmadds f25,f1,f7,f2
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 + ctx.f2.f64));
	// lfs f2,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f28
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f1,3012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3012);
	ctx.f1.f64 = double(temp.f32);
	// stfs f2,1900(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1900, temp.u32);
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// fmuls f2,f2,f13
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f22,f2,f30
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f2,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f2.f64 = double(temp.f32);
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f26,f26,f13
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f18,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f21,f2
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f17,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f27,f22,f17,f27
	ctx.f27.f64 = double(float(-(ctx.f22.f64 * ctx.f17.f64 - ctx.f27.f64)));
	// lfs f22,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f1,f22
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// lfs f1,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1736(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1736, temp.u32);
	// lfs f2,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f24,f31
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmuls f20,f2,f3
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f2,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f2.f64 = double(temp.f32);
	// lfs f19,1916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1916);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f2
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// lfs f14,2368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2368);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmadds f15,f26,f7,f27
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfs f26,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f5,f1
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,2372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2372);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f4,f1
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// fmuls f1,f31,f28
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmuls f20,f20,f7
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f7.f64));
	// fmadds f24,f24,f0,f22
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 + ctx.f22.f64));
	// fmuls f16,f16,f28
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// fmuls f27,f1,f13
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmadds f20,f18,f6,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f20.f64));
	// lfs f18,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f26,f27
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmuls f27,f30,f28
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// fmuls f27,f18,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f18,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f14,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f18.f64));
	// lfs f14,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f23,f23,f14,f15
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f14.f64 + ctx.f15.f64));
	// lfs f15,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f24,f19,f15,f24
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f15.f64 - ctx.f24.f64)));
	// lfs f15,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// lfs f14,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f27,f13
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f13.f64));
	// lfs f27,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// stfs f27,1336(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1336, temp.u32);
	// fnmsubs f23,f21,f7,f23
	ctx.f23.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// lfs f21,1728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1728);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f24,f17,f0,f24
	ctx.f24.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fmuls f14,f27,f14
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f14.f64));
	// lfs f27,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f28,f27
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f27.f64));
	// fmadds f23,f20,f13,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f23.f64));
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// stfs f27,328(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmuls f27,f26,f31
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// lfs f26,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// stfs f27,1844(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1844, temp.u32);
	// lfs f21,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f1,f21,f19
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64 + ctx.f19.f64));
	// lfs f1,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f5,f1
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f24,f16,f1,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f24.f64));
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// lfs f16,3004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3004);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f4,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// fmuls f27,f27,f2
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmuls f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64));
	// lfs f20,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f27,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f27.f64 = double(temp.f32);
	// stfs f1,1080(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1080, temp.u32);
	// fmuls f17,f1,f27
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fnmsubs f23,f22,f6,f23
	ctx.f23.f64 = double(float(-(ctx.f22.f64 * ctx.f6.f64 - ctx.f23.f64)));
	// lfs f22,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f24,f18,f22,f24
	ctx.f24.f64 = double(float(-(ctx.f18.f64 * ctx.f22.f64 - ctx.f24.f64)));
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f22,f16,f30
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmadds f23,f15,f6,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f6.f64 + ctx.f23.f64));
	// fnmsubs f24,f14,f10,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f24.f64)));
	// fmuls f3,f3,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fnmsubs f26,f26,f6,f23
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f6.f64 - ctx.f23.f64)));
	// fmadds f24,f20,f0,f24
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f24.f64));
	// fmuls f3,f3,f10
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmadds f6,f21,f6,f26
	ctx.f6.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fnmsubs f26,f19,f0,f24
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fadds f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// stfs f6,4452(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4452, temp.u32);
	// lfs f6,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f25,f17,f10,f26
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f26.f64));
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f26,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f24,f5,f6
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,1744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1744);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f1,f6
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f6,f26,f30
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// stfs f6,1816(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1816, temp.u32);
	// fmuls f21,f5,f6
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,2528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2528);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f1,f6
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f6,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f1,f22,f6,f3
	ctx.f1.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f3.f64));
	// lfs f6,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,1936(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1936, temp.u32);
	// fnmsubs f24,f24,f10,f1
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f10.f64 - ctx.f1.f64)));
	// lfs f1,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f5,f1
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmuls f1,f26,f28
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f1,1224(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1224, temp.u32);
	// fmuls f22,f6,f2
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f6,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f6,f28
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f6,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f6.f64 = double(temp.f32);
	// stfs f3,1744(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1744, temp.u32);
	// lfs f26,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f24,f23,f10,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f10.f64 - ctx.f24.f64)));
	// fmuls f15,f6,f1
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// stfs f1,1328(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1328, temp.u32);
	// fmuls f19,f6,f3
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f3,2356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2356);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f4,f3
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fmuls f14,f1,f2
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f1,2352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2352);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f18,f18,f28
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f28.f64));
	// fmadds f21,f3,f17,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f17.f64 + ctx.f21.f64));
	// lfs f17,1248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1248);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f3,f3,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fmadds f27,f16,f31,f15
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f31.f64 + ctx.f15.f64));
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmuls f23,f14,f10
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f10.f64));
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// stfs f1,328(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmuls f1,f26,f30
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmadds f24,f21,f10,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f10.f64 + ctx.f24.f64));
	// lfs f21,1716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmsubs f27,f27,f10,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 - ctx.f23.f64));
	// fmuls f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fmuls f5,f26,f28
	ctx.f5.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f5,1880(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1880, temp.u32);
	// lfs f26,4244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4244);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f4,f26
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// fmuls f5,f6,f5
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f6,4252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4252);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f4,f6
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmuls f23,f4,f6
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f6.f64 = double(temp.f32);
	// lfs f15,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f24,f20,f0,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fmuls f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// lfs f6,4260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4260);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f4,f6
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,4268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4268);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f4,f6
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmadds f3,f3,f10,f27
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f10.f64 + ctx.f27.f64));
	// fnmsubs f24,f22,f0,f24
	ctx.f24.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// lfs f22,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f2,f15,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// fmuls f27,f4,f6
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f6,2160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2160);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f15,f4,f6
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f4,f26,f6,f3
	ctx.f4.f64 = double(float(-(ctx.f26.f64 * ctx.f6.f64 - ctx.f3.f64)));
	// lfs f26,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f3,f19,f0,f24
	ctx.f3.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fnmsubs f4,f16,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// lfs f16,4080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4080);
	ctx.f16.f64 = double(temp.f32);
	// fadds f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// lfs f25,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f4,f20,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f20.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fmadds f3,f18,f26,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 + ctx.f3.f64));
	// fnmsubs f4,f14,f6,f4
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f6.f64 - ctx.f4.f64)));
	// fnmsubs f3,f17,f0,f3
	ctx.f3.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f3.f64)));
	// lfs f17,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f26,f22,f10,f4
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f4.f64));
	// fnmsubs f4,f25,f6,f3
	ctx.f4.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f3.f64)));
	// lfs f3,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f4,f1,f10,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f1,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f5,f10,f4
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f4,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f5,f21,f0,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fnmsubs f5,f23,f6,f5
	ctx.f5.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// lfs f23,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// lfs f1,4276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4276);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f2,f0,f5
	ctx.f5.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f5.f64));
	// fnmsubs f27,f27,f6,f5
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// lfs f5,1940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1940);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f4,f5
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// lfs f4,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f4,f3
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f4,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f24,f4,f5
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// fmuls f22,f5,f1
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,-148(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -148);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f25,f1
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// stfs f1,272(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// lfs f3,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f23,f4,f3,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f23.f64));
	// lfs f4,4284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4284);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f5,f4
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f3,-120(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -120);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,4072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4072);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f22,f12
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f12.f64));
	// fmuls f20,f5,f4
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,-136(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + -136);
	ctx.f4.f64 = double(temp.f32);
	// stfs f3,148(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f4,292(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// fmuls f19,f2,f3
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f2,3356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3356);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f25,f2,f4,f25
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 - ctx.f25.f64));
	// lfs f2,2396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2396);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f5,f2
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f2,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// fmuls f17,f2,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// fmsubs f24,f24,f3,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 - ctx.f19.f64));
	// lfs f14,2404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2404);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f25,f25,f5,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 - ctx.f22.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fnmsubs f22,f15,f6,f26
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// lfs f6,3364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3364);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f5,f6
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,2412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2412);
	ctx.f6.f64 = double(temp.f32);
	// lfs f26,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f17,f31
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f31.f64));
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// fmadds f3,f23,f3,f24
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f24.f64));
	// fmuls f24,f6,f12
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f6,3844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3844);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f5,f6
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// fmuls f6,f30,f26
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// stfs f6,664(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 664, temp.u32);
	// fmadds f25,f21,f4,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f21,3372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3372);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f3,f20,f12,f3
	ctx.f3.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f21,f4,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f24.f64));
	// lfs f21,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f6,f2,f6
	ctx.f6.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// fmadds f2,f17,f10,f22
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f22.f64));
	// lfs f22,2420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2420);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f25,f18,f12,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// lfs f18,2436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2436);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// fmadds f17,f16,f12,f3
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfs f3,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// lfs f6,2428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2428);
	ctx.f6.f64 = double(temp.f32);
	// fadds f2,f27,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 + ctx.f2.f64));
	// fmuls f27,f5,f6
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,4184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4184);
	ctx.f6.f64 = double(temp.f32);
	// fadds f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 + ctx.f18.f64));
	// lfs f6,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f6,f3,f31
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fnmsubs f25,f14,f12,f25
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// fnmsubs f19,f19,f4,f17
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f17.f64)));
	// lfs f17,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f20,f0,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f2.f64));
	// lfs f20,3380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3380);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmuls f18,f18,f5
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// fmuls f6,f6,f16
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f16.f64));
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f25,f23,f4,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f23,1320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1320);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fmadds f6,f6,f10,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 + ctx.f2.f64));
	// stfs f6,4456(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4456, temp.u32);
	// fmadds f6,f24,f5,f19
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f19.f64));
	// lfs f24,-248(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -248);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f3,f22,f12,f25
	ctx.f3.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// lfs f25,2172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2172);
	ctx.f25.f64 = double(temp.f32);
	// stfs f24,312(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// fnmsubs f6,f27,f4,f6
	ctx.f6.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f6.f64)));
	// lfs f27,4088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4088);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f3,f21,f1,f3
	ctx.f3.f64 = double(float(-(ctx.f21.f64 * ctx.f1.f64 - ctx.f3.f64)));
	// fmadds f22,f18,f4,f6
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f6.f64));
	// lfs f6,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f21,f20,f12,f3
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// lfs f3,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f6,f27
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f6,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f6,f3
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f3,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f6
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f25
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f3,-132(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -132);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,544(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f3,2444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2444);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f3,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f2,f3
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f20,f20,f4
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f4.f64));
	// lfs f2,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f6,f2
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// stfs f2,460(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fmuls f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// lfs f14,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f18,f3
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f18,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f18.f64 = double(temp.f32);
	// lfs f2,-140(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -140);
	ctx.f2.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f2,280(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// fmadds f18,f18,f2,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64 + ctx.f17.f64));
	// lfs f2,-144(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -144);
	ctx.f2.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmadds f1,f15,f1,f20
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f20.f64));
	// lfs f20,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f16,f2
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// lfs f16,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// lfs f15,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f20,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f15,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f15.f64 = double(temp.f32);
	// stfs f2,200(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,2460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2460);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f1,f26,f24,f1
	ctx.f1.f64 = double(float(-(ctx.f26.f64 * ctx.f24.f64 - ctx.f1.f64)));
	// lfs f24,3852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3852);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f27,f18,f27,f17
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f17.f64));
	// lfs f18,2452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2452);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f25,f3
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// fmuls f26,f20,f3
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f20,f16,f6
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fmuls f17,f15,f6
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f6.f64));
	// lfs f15,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fnmsubs f2,f19,f2,f1
	ctx.f2.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f1,1924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1924);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// lfs f5,3388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3388);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f6,f5
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f5,f6
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,2140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2140);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f15,f5
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// lfs f5,-60(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -60);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,260(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// fmuls f5,f14,f5
	ctx.f5.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// lfs f14,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f14.f64 = double(temp.f32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fnmsubs f23,f23,f14,f21
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f14.f64 - ctx.f21.f64)));
	// lfs f21,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f21.f64 = double(temp.f32);
	// lfs f14,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f2,f27,f3,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f2.f64));
	// lfs f27,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f1,f1,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f27,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f16,f27
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f16,4088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4088);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfs f16,2172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2172);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f16.f64));
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f14
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64));
	// lfs f14,2468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2468);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f14,f14,f12,f5
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f12.f64 + ctx.f5.f64));
	// lfs f5,-128(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -128);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,508(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fnmsubs f5,f25,f5,f2
	ctx.f5.f64 = double(float(-(ctx.f25.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f2,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f2,f1,f2,f23
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f23.f64));
	// lfs f1,3396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3396);
	ctx.f1.f64 = double(temp.f32);
	// lfs f25,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f23,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// fmuls f23,f21,f3
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmadds f21,f16,f12,f15
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f12.f64 + ctx.f15.f64));
	// lfs f15,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f26,f15,f5
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f15.f64 + ctx.f5.f64));
	// lfs f15,2112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2112);
	ctx.f15.f64 = double(temp.f32);
	// fadds f5,f22,f2
	ctx.f5.f64 = double(float(ctx.f22.f64 + ctx.f2.f64));
	// stfs f5,4460(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4460, temp.u32);
	// lfs f5,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f14,f6
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// lfs f14,2300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2300);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fnmsubs f2,f20,f5,f26
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f26,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f21,f3,f16
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f16.f64));
	// fnmsubs f2,f25,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f25.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// fnmsubs f22,f1,f12,f22
	ctx.f22.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f22.f64)));
	// fmadds f2,f17,f26,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f2.f64));
	// fnmsubs f2,f24,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// fmadds f2,f18,f12,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f2.f64));
	// fnmsubs f2,f19,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f19,2484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2484);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f5,f27,f5,f2
	ctx.f5.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f2,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f26,f23,f2,f5
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f5.f64));
	// lfs f5,2476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2476);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,1784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1784);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f5,f2
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f5,3860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3860);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f6,f5
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f6,f5
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,2124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2124);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f23,f6,f5
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f5,f31
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// lfs f5,4280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4280);
	ctx.f5.f64 = double(temp.f32);
	// stfs f2,2252(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2252, temp.u32);
	// fmuls f21,f2,f5
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f5,2024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2024);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f20,f6,f5
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f5,f28
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// stfs f1,1284(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1284, temp.u32);
	// fmuls f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f1,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f27,f1
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f1,1824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1824);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f6,f1
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f27,2172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2172);
	ctx.f27.f64 = double(temp.f32);
	// lfs f1,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f1,f27
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f1,-124(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -124);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f25,f25,f1,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f22.f64));
	// lfs f22,1328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1328);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,-116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -116);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f22,f15
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f15.f64));
	// lfs f15,1836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1836);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f21,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// fmuls f2,f2,f15
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// lfs f15,2240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2240);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f5,f15
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stfs f27,100(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f1,320(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f25,f24,f3,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f3.f64 - ctx.f25.f64)));
	// lfs f3,-252(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -252);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,372(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fmsubs f21,f19,f10,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f10.f64 - ctx.f21.f64));
	// lfs f24,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// fmuls f19,f15,f30
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// lfs f15,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f3,f15,f3
	ctx.f3.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// lfs f15,2208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2208);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// fnmsubs f1,f18,f1,f25
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// fmadds f27,f22,f27,f21
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 + ctx.f21.f64));
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f24,f31
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// fmadds f21,f21,f0,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f3.f64));
	// lfs f3,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f3.f64 = double(temp.f32);
	// lfs f18,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f3,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// lfs f22,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f3,f2,f0,f27
	ctx.f3.f64 = double(float(-(ctx.f2.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// stfs f3,328(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f25,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f25.f64));
	// lfs f27,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f27.f64 = double(temp.f32);
	// lfs f2,-84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -84);
	ctx.f2.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f1,f23,f2,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f22,2360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2360);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// stfs f2,180(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f25,f25,f27
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f27,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f3,f27,f30
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f27,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f27.f64 = double(temp.f32);
	// stfs f3,756(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 756, temp.u32);
	// fmadds f20,f20,f2,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f1.f64));
	// lfs f1,2112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2112);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f23,f3,f27
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f27,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f20,f17,f12,f20
	ctx.f20.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f20.f64)));
	// lfs f3,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f19,f19,f27,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f3.f64));
	// lfs f3,-92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -92);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f25,f18,f3,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f25.f64));
	// stfs f3,296(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// lfs f3,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f18,f5,f3
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// stfs f3,1824(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1824, temp.u32);
	// lfs f3,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fnmsubs f24,f24,f27,f19
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f27.f64 - ctx.f19.f64)));
	// fmuls f19,f18,f31
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// fmadds f23,f3,f0,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f23.f64));
	// lfs f3,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmadds f24,f21,f31,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f31.f64 + ctx.f24.f64));
	// fnmsubs f21,f16,f12,f20
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f20.f64)));
	// lfs f20,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// stfs f3,328(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmr f3,f20
	ctx.f3.f64 = ctx.f20.f64;
	// fmadds f24,f23,f3,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f24.f64));
	// fnmsubs f23,f14,f4,f21
	ctx.f23.f64 = double(float(-(ctx.f14.f64 * ctx.f4.f64 - ctx.f21.f64)));
	// fnmsubs f24,f19,f0,f24
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// fmadds f4,f15,f4,f23
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fnmsubs f4,f22,f2,f4
	ctx.f4.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f4.f64)));
	// fmadds f6,f25,f6,f4
	ctx.f6.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f4.f64));
	// lfs f4,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f4.f64 = double(temp.f32);
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fadds f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// stfs f6,4464(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4464, temp.u32);
	// fmuls f6,f4,f30
	ctx.f6.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// stfs f6,1520(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1520, temp.u32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// stfs f4,1332(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1332, temp.u32);
	// lfs f26,-256(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -256);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,784(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 784, temp.u32);
	// fmuls f2,f3,f6
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f6,1844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1844);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f1
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f6,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f4,f6
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f31,f4
	ctx.f4.f64 = double(float(ctx.f31.f64 * ctx.f4.f64));
	// fmuls f21,f4,f25
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// lfs f4,1824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1824);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f30
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f4,2492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2492);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f5,f4
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// lfs f4,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f2,f25
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// fmuls f2,f4,f28
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f15,1836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1836);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f14,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmadds f26,f23,f26,f18
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f18.f64));
	// fmuls f17,f3,f2
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f2,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f4,f6
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmsubs f26,f14,f0,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 - ctx.f26.f64));
	// fmuls f23,f3,f4
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,4272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4272);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f5,f4
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f27,f21,f4,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f4,2500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2500);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,3412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3412);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f3,f2
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fadds f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 + ctx.f21.f64));
	// lfs f4,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfs f2,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// stfs f4,2244(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2244, temp.u32);
	// fnmsubs f26,f22,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// lfs f22,3868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3868);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f27,f16,f25,f27
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f25.f64 - ctx.f27.f64));
	// lfs f16,1284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1284);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f25,f21,f5
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f15,f4,f15
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f15.f64));
	// lfs f4,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// fmuls f1,f4,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// lfs f4,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmadds f27,f20,f0,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f27.f64));
	// fmuls f14,f4,f6
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f5,f4,f30
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fmuls f21,f5,f6
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// lfs f5,2508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2508);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmuls f5,f4,f28
	ctx.f5.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// fmuls f4,f3,f5
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f5,2272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2272);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f20,f5,f6
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f26,f19,f5,f26
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f5,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f19,3868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3868);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// fmadds f26,f17,f0,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f26.f64));
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// lfs f5,2104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2104);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f5.f64 = double(temp.f32);
	// stfs f6,328(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmuls f6,f5,f30
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmadds f16,f3,f6,f16
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f16.f64));
	// lfs f6,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f27,f18,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// lfs f6,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f6,f28
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f6,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f6.f64 = double(temp.f32);
	// stfs f5,376(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fmuls f18,f5,f6
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f30
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// fmuls f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,2516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2516);
	ctx.f5.f64 = double(temp.f32);
	// lfs f3,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f4,f16,f10,f4
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 - ctx.f4.f64));
	// fmuls f5,f3,f5
	ctx.f5.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f27,f25,f3,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 + ctx.f27.f64));
	// lfs f17,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f2,f0,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f26.f64));
	// lfs f26,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f26.f64 = double(temp.f32);
	// lfs f16,3876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3876);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f4,f18,f0,f4
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f4.f64));
	// lfs f18,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// lfs f17,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f27,f14,f10,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f27.f64));
	// fmadds f2,f23,f26,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f2.f64));
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f22,f26,f27
	ctx.f27.f64 = double(float(-(ctx.f22.f64 * ctx.f26.f64 - ctx.f27.f64)));
	// fnmsubs f26,f6,f10,f4
	ctx.f26.f64 = double(float(-(ctx.f6.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// lfs f4,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f6,f15,f0,f2
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f15,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f2,f19,f0,f27
	ctx.f2.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// lfs f19,2532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2532);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f5,f5,f3,f26
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// lfs f26,4096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4096);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f6,f1,f4,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f6.f64));
	// lfs f1,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f11,f19
	ctx.f19.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// fmadds f2,f1,f4,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f2.f64));
	// fnmsubs f6,f21,f0,f6
	ctx.f6.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f6.f64)));
	// lfs f21,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f6,f20,f4,f6
	ctx.f6.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f6.f64)));
	// lfs f20,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f20.f64 = double(temp.f32);
	// fadds f6,f24,f6
	ctx.f6.f64 = double(float(ctx.f24.f64 + ctx.f6.f64));
	// fadds f25,f6,f2
	ctx.f25.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// lfs f6,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f6,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f6,2224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2224);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f27,f6,f11
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,3420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3420);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f26,f6,f26
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmuls f24,f6,f2
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f2,2264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2264);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f2,f11
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f2,-260(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -260);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,416(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f22,f1,f30
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fmuls f1,f31,f31
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f20,f27,f20
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f20.f64));
	// lfs f27,2524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2524);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmadds f24,f24,f17,f5
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 + ctx.f5.f64));
	// lfs f5,3428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3428);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f5,f7
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f7.f64));
	// lfs f5,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f22,f0
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// fmuls f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// fnmsubs f24,f26,f3,f24
	ctx.f24.f64 = double(float(-(ctx.f26.f64 * ctx.f3.f64 - ctx.f24.f64)));
	// lfs f26,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f15,f26,f18
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f26.f64 + ctx.f18.f64));
	// lfs f26,2176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2176);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f17,f26,f2,f17
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 + ctx.f17.f64));
	// lfs f26,3436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3436);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f22,f16,f7,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 - ctx.f22.f64));
	// lfs f16,2548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2548);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f21,f5,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 + ctx.f27.f64));
	// lfs f21,2540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2540);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmuls f16,f11,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f16.f64));
	// fmsubs f22,f22,f11,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 - ctx.f20.f64));
	// fmuls f15,f27,f11
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fmuls f27,f6,f28
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fmadds f24,f21,f3,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f3,2556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2556);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f18,f11
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fmuls f18,f11,f3
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f3.f64));
	// fmuls f14,f26,f27
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f26,2604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2604);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f1,f26
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// fmuls f3,f30,f30
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmsubs f17,f17,f11,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 - ctx.f15.f64));
	// fnmsubs f23,f23,f2,f22
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// fnmsubs f24,f14,f10,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f24.f64)));
	// fmuls f15,f3,f26
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// lfs f3,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f30
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// lfs f26,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f26.f64 = double(temp.f32);
	// stfs f3,812(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 812, temp.u32);
	// fmadds f23,f19,f7,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f23.f64));
	// fmuls f22,f26,f3
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f3,4192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4192);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f3,f27
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f3,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f3.f64 = double(temp.f32);
	// lfs f26,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f18,f18,f3,f17
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f17.f64)));
	// fmuls f17,f15,f26
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// lfs f27,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f26,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f19,f27,f26
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f27,2564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2564);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,3444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3444);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f23,f16,f7,f23
	ctx.f23.f64 = double(float(-(ctx.f16.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// fmuls f15,f11,f26
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f26.f64));
	// lfs f16,1932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1932);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f24,f22,f10,f24
	ctx.f24.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f24.f64)));
	// fmuls f22,f11,f27
	ctx.f22.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// lfs f27,-264(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -264);
	ctx.f27.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f27,740(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 740, temp.u32);
	// lfs f26,-268(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -268);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,300(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f26,-88(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + -88);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,308(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// fnmsubs f26,f17,f26,f18
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f26.f64 - ctx.f18.f64)));
	// lfs f18,2572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2572);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f24,f14,f10,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f24.f64)));
	// fmuls f18,f11,f18
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// lfs f14,3460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3460);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,2588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2588);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f11,f17
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// fnmsubs f26,f22,f27,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f27.f64 - ctx.f26.f64)));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f21,f22,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f22.f64 + ctx.f23.f64));
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfs f25,4468(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4468, temp.u32);
	// fnmsubs f24,f18,f7,f26
	ctx.f24.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f18,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f26,f20,f7,f23
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f23.f64));
	// lfs f20,2248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2248);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f25,f19,f5,f26
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f19,2064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2064);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,3452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3452);
	ctx.f18.f64 = double(temp.f32);
	// lfs f26,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f23,f15,f26,f25
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f26.f64 - ctx.f25.f64)));
	// lfs f25,3884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3884);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f11,f25
	ctx.f22.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// lfs f25,2580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2580);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f18,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// lfs f15,2596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2596);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f11,f25
	ctx.f21.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// lfs f25,1992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1992);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f20,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// fmuls f25,f16,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f25.f64));
	// lfs f16,4104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4104);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f26,f17,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f26.f64));
	// lfs f17,2000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2000);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// fmuls f15,f11,f15
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f15.f64));
	// fmuls f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// fmadds f18,f14,f27,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f18.f64));
	// lfs f14,2288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2288);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f27,f28,f28
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmsubs f22,f21,f3,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 - ctx.f22.f64));
	// lfs f21,2604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2604);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f27,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f21.f64));
	// lfs f27,1732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f17,f27
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmsubs f26,f18,f11,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 - ctx.f26.f64));
	// lfs f18,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f24,f17,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f17.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// fmuls f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// fnmsubs f22,f20,f5,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f5.f64 - ctx.f22.f64)));
	// lfs f20,2200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2200);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f16,f14,f2,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f14,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,-272(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -272);
	ctx.f18.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f18,1040(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1040, temp.u32);
	// fmuls f20,f20,f2
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// fmuls f14,f14,f27
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f27.f64));
	// lfs f18,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f27
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f27.f64));
	// lfs f17,-276(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -276);
	ctx.f17.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f17,1056(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1056, temp.u32);
	// lfs f17,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f22,f19,f5,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f22.f64)));
	// lfs f19,2076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2076);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f26,f16,f11,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f11.f64 + ctx.f26.f64));
	// lfs f27,-64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -64);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f11,f17
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f17.f64));
	// stfs f27,216(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmadds f27,f19,f27,f20
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f20.f64));
	// lfs f20,3892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3892);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f11,f20
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f20.f64));
	// fmadds f25,f25,f5,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f22,2084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2084);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f26,f14,f3,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f3.f64 + ctx.f26.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmadds f25,f15,f7,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f25.f64));
	// fnmsubs f26,f22,f2,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// lfs f2,1952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1952);
	ctx.f2.f64 = double(temp.f32);
	// lfs f22,1992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1992);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// lfs f2,4240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4240);
	ctx.f2.f64 = double(temp.f32);
	// lfs f16,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f21,f16,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f16.f64 - ctx.f25.f64)));
	// lfs f21,1980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1980);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f24,f18,f19,f24
	ctx.f24.f64 = double(float(-(ctx.f18.f64 * ctx.f19.f64 - ctx.f24.f64)));
	// lfs f18,2612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2612);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f27,f18,f3,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f27.f64));
	// lfs f18,3468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3468);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f17,f1
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// lfs f17,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f11,f18
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f18.f64));
	// fmadds f27,f2,f7,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f7.f64 + ctx.f27.f64));
	// lfs f2,1972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1972);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f24,f19,f5,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f24.f64));
	// lfs f19,2620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2620);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f11,f19
	ctx.f19.f64 = double(float(ctx.f11.f64 * ctx.f19.f64));
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// fmadds f27,f27,f11,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f26.f64));
	// fnmsubs f26,f20,f3,f25
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f25.f64)));
	// fadds f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 + ctx.f24.f64));
	// lfs f23,2256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2256);
	ctx.f23.f64 = double(temp.f32);
	// fadds f21,f23,f21
	ctx.f21.f64 = double(float(ctx.f23.f64 + ctx.f21.f64));
	// fnmsubs f26,f18,f3,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// lfs f24,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f3,f19,f3,f26
	ctx.f3.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// fnmsubs f5,f22,f5,f3
	ctx.f5.f64 = double(float(-(ctx.f22.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// fadds f5,f27,f5
	ctx.f5.f64 = double(float(ctx.f27.f64 + ctx.f5.f64));
	// stfs f5,4472(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4472, temp.u32);
	// lfs f5,2072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2072);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f3,f2,f5
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f5,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f27,f5,f2
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f5,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f26,f5,f2
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f5,2628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2628);
	ctx.f5.f64 = double(temp.f32);
	// lfs f2,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f5,f2
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f5,2116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2116);
	ctx.f5.f64 = double(temp.f32);
	// fadds f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 + ctx.f24.f64));
	// lfs f5,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f5.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f23,3476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3476);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f5,f23
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f23,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f3,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f5
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f19,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f19.f64 = double(temp.f32);
	// lfs f3,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f25,f19,f3,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 - ctx.f25.f64));
	// lfs f3,-500(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + -500);
	ctx.f3.f64 = double(temp.f32);
	// lfs f19,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// stfs f3,1236(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1236, temp.u32);
	// lfs f3,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f3.f64 = double(temp.f32);
	// lfs f14,2636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2636);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f3.f64));
	// lfs f3,2132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2132);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f27,f27,f4,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f4.f64 - ctx.f23.f64));
	// lfs f23,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f23.f64 = double(temp.f32);
	// fadds f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 + ctx.f3.f64));
	// lfs f3,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f3,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f25,f14,f2,f25
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// lfs f14,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f20,f20,f3
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// lfs f3,1740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1740);
	ctx.f3.f64 = double(temp.f32);
	// lfs f16,2376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2376);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f3,f16
	ctx.f16.f64 = double(float(ctx.f3.f64 + ctx.f16.f64));
	// lfs f3,1820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1820);
	ctx.f3.f64 = double(temp.f32);
	// lfs f15,2128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2128);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f3,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f15.f64));
	// fnmsubs f27,f26,f14,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f14.f64 - ctx.f27.f64)));
	// lfs f26,-19104(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -19104);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,1300(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1300, temp.u32);
	// lfs f14,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f14,f26,f19
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f19.f64));
	// lfs f14,2156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2156);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f18,f3
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f18,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f24,f24,f18,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 + ctx.f23.f64));
	// lfs f23,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f18,f16,f23,f15
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f23.f64 + ctx.f15.f64));
	// lfs f15,1828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1828);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,2004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2004);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f22,f0,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfs f22,3900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3900);
	ctx.f22.f64 = double(temp.f32);
	// fadds f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 + ctx.f15.f64));
	// lfs f15,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f25,f22,f15,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f15.f64 - ctx.f25.f64)));
	// fmadds f22,f21,f23,f19
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f23.f64 + ctx.f19.f64));
	// fmuls f21,f24,f5
	ctx.f21.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// lfs f24,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f20,f20,f24,f27
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f24.f64 - ctx.f27.f64)));
	// lfs f27,2644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2644);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f16,f3
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// fnmsubs f25,f27,f29,f25
	ctx.f25.f64 = double(float(-(ctx.f27.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// lfs f27,1908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1908);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f3,f27
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f27,1972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1972);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f22,f22,f10,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f21.f64));
	// lfs f21,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f15,f21,f27
	ctx.f15.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// lfs f21,2148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2148);
	ctx.f21.f64 = double(temp.f32);
	// fadds f14,f21,f14
	ctx.f14.f64 = double(float(ctx.f21.f64 + ctx.f14.f64));
	// fmadds f21,f18,f0,f20
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f20.f64));
	// lfs f20,1752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1752);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f20,f20,f2,f25
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// lfs f25,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f25,f27
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f25,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// stfs f25,696(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 696, temp.u32);
	// fmsubs f22,f17,f0,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 - ctx.f22.f64));
	// fmadds f16,f25,f27,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f27,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f30,f27
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f27.f64));
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f25,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f25,f27
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// stfs f27,284(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// fmadds f22,f16,f0,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f22.f64));
	// lfs f16,4112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4112);
	ctx.f16.f64 = double(temp.f32);
	// lfs f27,-11468(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -11468);
	ctx.f27.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f27,1004(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1004, temp.u32);
	// lfs f27,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f19,f19,f27,f21
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f21.f64));
	// lfs f21,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f20,f14,f21,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f21.f64 + ctx.f20.f64));
	// lfs f14,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f27,f15,f27,f19
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f27.f64 + ctx.f19.f64));
	// lfs f15,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f27,f18,f4,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// stfs f27,4476(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4476, temp.u32);
	// lfs f22,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,2164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2164);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f17,f19,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f20,f26,f19,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 + ctx.f20.f64));
	// fadds f19,f27,f22
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f22.f64));
	// lfs f27,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f26,f27
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f27,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f26,-432(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + -432);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f1,f26
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// stfs f26,1752(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1752, temp.u32);
	// stfs f22,1320(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1320, temp.u32);
	// fmadds f21,f19,f21,f18
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64 + ctx.f18.f64));
	// lfs f19,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f17,f27,f1
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f27,2652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2652);
	ctx.f27.f64 = double(temp.f32);
	// fadds f16,f27,f16
	ctx.f16.f64 = double(float(ctx.f27.f64 + ctx.f16.f64));
	// lfs f27,1988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1988);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f15.f64));
	// stfs f15,1244(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1244, temp.u32);
	// lfs f15,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// fmuls f18,f17,f4
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// lfs f17,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f15,2180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2180);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f15,f14,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f14.f64 + ctx.f21.f64));
	// fmadds f18,f16,f10,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f18.f64));
	// lfs f16,2660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2660);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f26
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// lfs f26,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmuls f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// fmadds f24,f19,f24,f18
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f18,2020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2020);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f15,f26,f27
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f26,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f25,f26
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f26,3492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3492);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f26,f2,f21
	ctx.f25.f64 = double(float(-(ctx.f26.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// lfs f26,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f23,f26
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f26.f64));
	// lfs f26,1996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1996);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,1908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1908);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f26,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// lfs f26,-448(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -448);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,552(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// fmsubs f24,f24,f5,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 - ctx.f17.f64));
	// fmuls f19,f15,f26
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// lfs f26,2668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2668);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f26,f26,f29,f25
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// lfs f25,2376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2376);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f21,f18,f25,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f21.f64));
	// lfs f25,2188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2188);
	ctx.f25.f64 = double(temp.f32);
	// lfs f18,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f25,f18
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f18.f64));
	// lfs f25,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f25,f27
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f25,3908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3908);
	ctx.f25.f64 = double(temp.f32);
	// lfs f15,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f15.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f15,f25,f15,f26
	ctx.f15.f64 = double(float(-(ctx.f25.f64 * ctx.f15.f64 - ctx.f26.f64)));
	// fmuls f25,f28,f28
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fnmsubs f24,f23,f4,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f24.f64)));
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// lfs f26,-464(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -464);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,384(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fnmsubs f25,f25,f26,f22
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f22,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f24,f21,f0,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f24.f64));
	// lfs f21,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f5,f26
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,2196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2196);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f26,f22,f18
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 + ctx.f18.f64));
	// lfs f26,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f26,f30
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f26,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f15,f14,f26,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f15.f64));
	// fmuls f26,f30,f30
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// fmuls f23,f23,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// lfs f1,2228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2228);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f21,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f21.f64 + ctx.f20.f64));
	// stfs f1,4480(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4480, temp.u32);
	// lfs f1,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f1.f64 = double(temp.f32);
	// lfs f21,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// stfs f26,1284(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1284, temp.u32);
	// fmadds f21,f1,f21,f15
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64 + ctx.f15.f64));
	// lfs f20,1764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1764);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f25,f25,f26,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f26.f64 + ctx.f16.f64));
	// lfs f16,4200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4200);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f1,f5,f26
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// fmadds f26,f22,f5,f24
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f5.f64 + ctx.f24.f64));
	// lfs f24,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f27,f25,f27,f19
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f27.f64 - ctx.f19.f64));
	// lfs f25,2676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2676);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f2,f21
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// lfs f19,1980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1980);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f26,f23,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fnmsubs f27,f18,f24,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f24.f64 - ctx.f27.f64)));
	// lfs f24,3500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3500);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f2,f24,f2,f25
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// stfs f2,4488(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4488, temp.u32);
	// lfs f2,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f2.f64 = double(temp.f32);
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f2,f17,f2,f27
	ctx.f2.f64 = double(float(-(ctx.f17.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// stfs f2,4484(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4484, temp.u32);
	// lfs f2,1756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1756);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f3,f2
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f27,1828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1828);
	ctx.f27.f64 = double(temp.f32);
	// lfs f2,1996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1996);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f3,f3,f20
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// fmuls f24,f2,f27
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f2,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f2.f64 = double(temp.f32);
	// lfs f27,2020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2020);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f27,f2
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f2.f64));
	// lfs f2,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f22,f1,f2
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f20,2276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2276);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// lfs f17,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,2284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2284);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmuls f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f17,f1,f17
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// fmuls f21,f5,f2
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// lfs f2,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// fmsubs f25,f24,f18,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f18.f64 - ctx.f25.f64));
	// lfs f18,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f18,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f24.f64));
	// lfs f18,2684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2684);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f5,f18
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// fmuls f2,f5,f2
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f2.f64));
	// fmadds f25,f23,f4,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f4,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f23,f24,f28
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// fmuls f24,f1,f4
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// lfs f4,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f26,f17,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f15,2692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2692);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f17,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// lfs f4,-204(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -204);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,676(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 676, temp.u32);
	// fmuls f17,f17,f4
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f4.f64));
	// lfs f4,3508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3508);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f14,f5,f4
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// fnmsubs f25,f22,f10,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f25.f64)));
	// fmadds f26,f24,f10,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f26.f64));
	// lfs f24,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f15,f7
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f7.f64));
	// lfs f15,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f24,f24,f15,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f15.f64 + ctx.f17.f64));
	// lfs f17,2700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2700);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f5,f17
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// lfs f5,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f4,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fnmsubs f25,f21,f5,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f5.f64 - ctx.f25.f64)));
	// lfs f5,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f5.f64 = double(temp.f32);
	// lfs f21,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f5,3916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3916);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f5,f11
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f5,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f4,f4,f5,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f5.f64 - ctx.f22.f64));
	// fnmsubs f4,f15,f7,f4
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f4.f64)));
	// lfs f5,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f1,f1,f5,f26
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f5,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f24,f5
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// lfs f5,2292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2292);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f5,f11
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f11.f64));
	// lfs f5,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f25,f2,f5,f25
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f5.f64 + ctx.f25.f64));
	// fmuls f2,f31,f31
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f15,f11,f2
	ctx.f15.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// stfs f15,328(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// lfs f15,1284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1284);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f21,f2
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// fmadds f1,f26,f15,f1
	ctx.f1.f64 = double(float(ctx.f26.f64 * ctx.f15.f64 + ctx.f1.f64));
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f3,f3,f26,f25
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f26.f64 - ctx.f25.f64)));
	// lfs f21,2708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2708);
	ctx.f21.f64 = double(temp.f32);
	// lfs f25,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fnmsubs f4,f24,f25,f4
	ctx.f4.f64 = double(float(-(ctx.f24.f64 * ctx.f25.f64 - ctx.f4.f64)));
	// lfs f24,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f5,f20,f5,f3
	ctx.f5.f64 = double(float(-(ctx.f20.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// lfs f3,3516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3516);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f21,f21,f24,f4
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 + ctx.f4.f64));
	// lfs f4,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f5,f27,f10,f5
	ctx.f5.f64 = double(float(-(ctx.f27.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// fnmsubs f5,f19,f4,f5
	ctx.f5.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f5.f64)));
	// fmadds f5,f23,f10,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f10.f64 + ctx.f5.f64));
	// fnmsubs f4,f18,f10,f5
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f5.f64)));
	// lfs f5,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f4,f16,f5,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// fmadds f4,f14,f5,f4
	ctx.f4.f64 = double(float(ctx.f14.f64 * ctx.f5.f64 + ctx.f4.f64));
	// fnmsubs f4,f17,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// fnmsubs f4,f22,f0,f4
	ctx.f4.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// fadds f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// stfs f4,4492(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4492, temp.u32);
	// lfs f4,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f3,f4
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f1,2304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2304);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,2080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2080);
	ctx.f3.f64 = double(temp.f32);
	// fadds f22,f3,f1
	ctx.f22.f64 = double(float(ctx.f3.f64 + ctx.f1.f64));
	// lfs f1,2144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2144);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,1932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1932);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f1
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f26,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f3,f30,f30
	ctx.f3.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// lfs f27,2996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2996);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f26,f2
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// lfs f16,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f19,f3,f26
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// lfs f3,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f27
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// lfs f3,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f3,2716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2716);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f23,f3,f4,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f4.f64 - ctx.f23.f64));
	// lfs f3,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f22,f22,f3,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f20.f64));
	// lfs f3,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f2,f3
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f3,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmuls f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f16,4120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4120);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f15,2308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2308);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f25,f15,f25,f23
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f25.f64 + ctx.f23.f64));
	// lfs f15,3524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3524);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// lfs f23,2724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2724);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fmuls f23,f23,f11
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmadds f19,f19,f2,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 + ctx.f18.f64));
	// lfs f2,2732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2732);
	ctx.f2.f64 = double(temp.f32);
	// lfs f18,3924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3924);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 + ctx.f18.f64));
	// lfs f2,2740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2740);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// lfs f2,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f21,f17,f2,f21
	ctx.f21.f64 = double(float(-(ctx.f17.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// fmuls f2,f28,f28
	ctx.f2.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmadds f25,f25,f11,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 + ctx.f22.f64));
	// fmadds f20,f20,f5,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 + ctx.f16.f64));
	// fnmsubs f22,f15,f7,f19
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f19.f64)));
	// fmuls f19,f14,f3
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// fmadds f24,f18,f7,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f18,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// lfs f26,3532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3532);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f23,f18,f25
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f18.f64 - ctx.f25.f64)));
	// lfs f18,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f26,f26,f11
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// fmadds f23,f20,f11,f21
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 + ctx.f21.f64));
	// fnmsubs f22,f19,f7,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f22.f64)));
	// lfs f19,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f2,f3
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f2,2748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2748);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f2,f11
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// lfs f2,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f19,f19,f2
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f2.f64));
	// lfs f2,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f26,f26,f2,f25
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// lfs f25,4264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4264);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f25,f4,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f24.f64));
	// lfs f24,2756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2756);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// fmadds f23,f21,f18,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f18.f64 + ctx.f23.f64));
	// lfs f21,1952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1952);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,2320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2320);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// fmuls f1,f18,f1
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmadds f26,f20,f4,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f20,2764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2764);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f25,f25,f11,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 + ctx.f22.f64));
	// lfs f22,3540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3540);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fnmsubs f23,f19,f5,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f23.f64)));
	// lfs f19,1944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1944);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f26,f24,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f24,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f1,f1,f5,f23
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 + ctx.f23.f64));
	// lfs f23,1864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1864);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f25,f21,f5,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f5.f64 - ctx.f25.f64)));
	// lfs f21,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f19,f27
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f24,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// lfs f17,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// lfs f18,1896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1896);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// lfs f14,2272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2272);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fnmsubs f26,f22,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f22,2316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2316);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmadds f2,f20,f2,f25
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f25.f64));
	// lfs f25,3932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3932);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f4
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f20,1760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1760);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f4,f27,f4
	ctx.f4.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fmuls f27,f24,f30
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fmuls f24,f23,f30
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// lfs f23,2324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2324);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fadds f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// lfs f26,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f31
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmadds f2,f19,f5,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f19,1832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1832);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fmuls f27,f27,f10
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64));
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fadds f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fmsubs f27,f24,f10,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 - ctx.f27.f64));
	// fmadds f26,f26,f0,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f25.f64));
	// fmuls f25,f21,f31
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// lfs f21,1768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1768);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmsubs f26,f26,f11,f4
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 - ctx.f4.f64));
	// lfs f4,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// stfs f4,1512(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1512, temp.u32);
	// fmuls f24,f21,f30
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// fmadds f27,f25,f0,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f27.f64));
	// fmuls f16,f4,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// lfs f4,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f6,f4
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// lfs f4,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f26,f22,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f4,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f22,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f27,f23,f5,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// lfs f23,2356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2356);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fnmsubs f26,f20,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f20,2348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2348);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f4,f22
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f22.f64));
	// lfs f4,2332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2332);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f15,f4,f11
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f4,2340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2340);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f4,f11
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// lfs f4,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f14,f14,f4
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f4.f64));
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fmadds f1,f19,f7,f26
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f26.f64));
	// lfs f26,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f21,f31,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f31.f64 + ctx.f22.f64));
	// lfs f21,1776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1776);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmuls f26,f6,f26
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fmadds f27,f24,f10,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f27.f64));
	// lfs f24,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// stfs f24,1760(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1760, temp.u32);
	// lfs f24,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f1,f18,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// stfs f24,1864(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1864, temp.u32);
	// fmuls f24,f23,f31
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// lfs f23,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f23,1896(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1896, temp.u32);
	// lfs f23,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// stfs f23,1776(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1776, temp.u32);
	// lfs f23,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f23.f64 = double(temp.f32);
	// stfs f2,628(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmr f2,f23
	ctx.f2.f64 = ctx.f23.f64;
	// stfs f26,1832(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1832, temp.u32);
	// fmuls f26,f21,f30
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// lfs f21,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// stfs f21,1768(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1768, temp.u32);
	// fnmsubs f27,f16,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// fnmsubs f2,f17,f2,f1
	ctx.f2.f64 = double(float(-(ctx.f17.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f1,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f22,f0,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f27.f64));
	// fmadds f23,f15,f1,f2
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f2,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f27,f14,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// fnmsubs f1,f25,f1,f23
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// lfs f25,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f27,f26,f10,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f10.f64 - ctx.f27.f64)));
	// lfs f26,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f1,f20,f26,f1
	ctx.f1.f64 = double(float(-(ctx.f20.f64 * ctx.f26.f64 - ctx.f1.f64)));
	// lfs f26,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f24,f24,f26,f27
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f26.f64 - ctx.f27.f64)));
	// lfs f27,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f27.f64 = double(temp.f32);
	// fadds f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// stfs f1,4496(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4496, temp.u32);
	// lfs f1,1772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f1,f4
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// lfs f1,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f27,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f27.f64 = double(temp.f32);
	// stfs f1,328(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmuls f23,f27,f1
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f1,3668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3668);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f1,f25
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f1,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f21,f27,f1
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f1,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f27,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f1,2796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2796);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f1,f5
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// lfs f1,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f1,f4
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// lfs f1,3940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3940);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f27,f26,f2
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// lfs f26,3564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3564);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f6,f1
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,2804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2804);
	ctx.f1.f64 = double(temp.f32);
	// fadds f16,f1,f26
	ctx.f16.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// lfs f1,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f26,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// stfs f1,1312(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1312, temp.u32);
	// fmuls f15,f1,f26
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f26,1332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f4
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// lfs f26,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f23,f23,f26,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfs f27,2812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2812);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f19,f27,f5,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 - ctx.f19.f64));
	// lfs f27,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// lfs f25,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f17,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// lfs f17,4208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4208);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f16,f6,f1
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fnmsubs f23,f22,f2,f23
	ctx.f23.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f23.f64)));
	// fmuls f22,f19,f6
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// lfs f19,1836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1836);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f26,f15,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// lfs f15,2364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2364);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f19,f1,f19
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f19.f64));
	// fmuls f1,f6,f28
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// stfs f1,1284(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1284, temp.u32);
	// fmsubs f25,f22,f30,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 - ctx.f25.f64));
	// lfs f22,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f23,f21,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfs f21,2820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2820);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmadds f22,f16,f22,f19
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f22.f64 + ctx.f19.f64));
	// lfs f19,3572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3572);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f1,f15,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// lfs f15,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f17,f15,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f15.f64 + ctx.f26.f64));
	// lfs f16,1840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1840);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f19,f6,f19
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// lfs f17,2152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2152);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f23,f20,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfs f20,2168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f15,2372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2372);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// fmuls f16,f6,f16
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f16.f64));
	// fmadds f26,f26,f6,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f25.f64));
	// fmuls f25,f19,f30
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// lfs f19,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64));
	// lfs f19,-280(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -280);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,1840(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1840, temp.u32);
	// fmadds f23,f18,f0,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f23.f64));
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// lfs f18,2836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2836);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f19,f15,f31
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// lfs f15,1780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1780);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f4,f15,f4
	ctx.f4.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmadds f1,f1,f10,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 + ctx.f26.f64));
	// lfs f26,3948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3948);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f6,f26
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// fnmsubs f23,f14,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// fmadds f24,f17,f2,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f17,3580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3580);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// fnmsubs f27,f27,f0,f23
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// lfs f23,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f27,f22,f0,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfs f15,1840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1840);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f24,f20,f15,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f15.f64 - ctx.f24.f64)));
	// lfs f20,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f1,f16,f20,f1
	ctx.f1.f64 = double(float(-(ctx.f16.f64 * ctx.f20.f64 - ctx.f1.f64)));
	// fnmsubs f23,f19,f23,f1
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f23.f64 - ctx.f1.f64)));
	// lfs f1,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f27,f21,f1,f27
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// fnmsubs f26,f26,f1,f23
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// fmadds f5,f25,f5,f27
	ctx.f5.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f27.f64));
	// fmadds f26,f18,f12,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f26.f64));
	// fnmsubs f5,f4,f2,f5
	ctx.f5.f64 = double(float(-(ctx.f4.f64 * ctx.f2.f64 - ctx.f5.f64)));
	// lfs f4,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f4.f64 = double(temp.f32);
	// fadds f27,f24,f5
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f5.f64));
	// lfs f5,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f31,f5
	ctx.f5.f64 = double(float(ctx.f31.f64 * ctx.f5.f64));
	// fmuls f25,f5,f4
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f5,2844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2844);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f6,f5
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f6,4136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4136);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,2852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2852);
	ctx.f5.f64 = double(temp.f32);
	// fadds f23,f6,f5
	ctx.f23.f64 = double(float(ctx.f6.f64 + ctx.f5.f64));
	// lfs f4,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f4.f64 = double(temp.f32);
	// lfs f6,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f4,f6
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f5,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f5.f64 = double(temp.f32);
	// stfs f6,1072(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1072, temp.u32);
	// fnmsubs f1,f17,f1,f26
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// lfs f19,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,2380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2380);
	ctx.f18.f64 = double(temp.f32);
	// fadds f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f18.f64));
	// lfs f18,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,2860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2860);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f16.f64 = double(temp.f32);
	// lfs f26,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f26.f64 = double(temp.f32);
	// lfs f15,1864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1864);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,1896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1896);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f30
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// fmuls f21,f5,f6
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f5,3596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3596);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// fmuls f20,f5,f6
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,3588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3588);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f6,f19
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// lfs f6,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fmuls f18,f18,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fmuls f6,f20,f3
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f20,f19,f3
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f19,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f5,f5,f19
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmadds f2,f25,f2,f24
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f24,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f22,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// lfs f25,1284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1284);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// lfs f22,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f22,1832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1832);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmuls f19,f5,f3
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f2,f21,f5,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f5,1768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1768);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f5,f30
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f5,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f6,f6,f5,f24
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f5.f64 + ctx.f24.f64));
	// lfs f24,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f16,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64 + ctx.f23.f64));
	// lfs f16,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f16.f64 = double(temp.f32);
	// lfs f23,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f16,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f23.f64));
	// lfs f16,1760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1760);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmsubs f2,f25,f10,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f2.f64));
	// lfs f25,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f4
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// fmsubs f20,f20,f5,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64 - ctx.f6.f64));
	// lfs f6,2096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2096);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fmadds f2,f18,f0,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f2.f64));
	// lfs f18,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f25,f18
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f18.f64));
	// lfs f18,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f20,f19,f18,f20
	ctx.f20.f64 = double(float(-(ctx.f19.f64 * ctx.f18.f64 - ctx.f20.f64)));
	// lfs f18,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// lfs f6,1776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1776);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,628(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmr f6,f26
	ctx.f6.f64 = ctx.f26.f64;
	// lfs f26,2032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2032);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f4
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f4.f64));
	// fmadds f24,f24,f3,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f20.f64));
	// fnmsubs f2,f22,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// lfs f22,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f22.f64 = double(temp.f32);
	// fadds f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f27,f21,f6,f2
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// lfs f6,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f24,f23,f6,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f24.f64));
	// lfs f23,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f18,f3
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// lfs f17,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f22,f4
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f4.f64));
	// lfs f18,4248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4248);
	ctx.f18.f64 = double(temp.f32);
	// lfs f2,-236(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -236);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f18,f4
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// stfs f2,1252(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1252, temp.u32);
	// fnmsubs f27,f16,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f16,2096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2096);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f25,f6,f24
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// lfs f6,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f6.f64 = double(temp.f32);
	// lfs f24,2296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2296);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f27,f15,f5,f27
	ctx.f27.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// lfs f15,2216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2216);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f25,f19,f6,f25
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f25.f64)));
	// lfs f19,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f5,f14,f5,f27
	ctx.f5.f64 = double(float(-(ctx.f14.f64 * ctx.f5.f64 - ctx.f27.f64)));
	// lfs f27,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f20,f27,f25
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64 + ctx.f25.f64));
	// lfs f25,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f5,f25,f2,f5
	ctx.f5.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f5.f64)));
	// lfs f2,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f27,f26,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f26,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,2040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2040);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f24,2048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2048);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f23,2876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2876);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fadds f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f5.f64));
	// stfs f5,4500(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4500, temp.u32);
	// lfs f5,3956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3956);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f27,f22,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f1,2868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2868);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f5,f1
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// lfs f5,3596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3596);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f5,f26
	ctx.f26.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f22,3604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3604);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fmuls f21,f1,f12
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmuls f20,f1,f4
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// fmuls f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// fmadds f25,f25,f17,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f17.f64 + ctx.f21.f64));
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f5,f5,f21
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// lfs f17,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f26,f26,f12
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64));
	// lfs f21,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// lfs f16,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64));
	// lfs f20,2884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2884);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f4
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f4.f64));
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// fmadds f25,f22,f16,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f25.f64));
	// lfs f22,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f16,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f26,f24,f22,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 - ctx.f26.f64));
	// lfs f22,3964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3964);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f16,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f24,2892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2892);
	ctx.f24.f64 = double(temp.f32);
	// lfs f16,2900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2900);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f24,f24,f4
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// fmadds f27,f5,f12,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f12.f64 + ctx.f27.f64));
	// lfs f5,2964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2964);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f26,f25,f4,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f25,3264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3264);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f5
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// lfs f14,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f14.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f14.f64));
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f22,f22,f14,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f14.f64 + ctx.f17.f64));
	// lfs f17,2056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2056);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// lfs f2,3612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3612);
	ctx.f2.f64 = double(temp.f32);
	// lfs f14,1784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1784);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f26,f23,f12,f26
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// fmuls f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// lfs f2,3400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3400);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f23,f2,f5
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// lfs f2,-284(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -284);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,480(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// fnmsubs f27,f16,f12,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f27.f64)));
	// fmuls f2,f25,f2
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f16,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f15,f15,f4
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f4.f64));
	// lfs f25,3312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3312);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f16
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// lfs f16,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f17,f1,f16,f17
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f16.f64 + ctx.f17.f64));
	// lfs f1,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f1.f64 = double(temp.f32);
	// lfs f16,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f21,f6,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f26.f64));
	// fmuls f16,f1,f16
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f16.f64));
	// lfs f1,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f1.f64 = double(temp.f32);
	// lfs f21,3360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3360);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fnmsubs f27,f15,f1,f27
	ctx.f27.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// lfs f1,-288(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -288);
	ctx.f1.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f1,644(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 644, temp.u32);
	// fnmsubs f26,f19,f6,f26
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// fmadds f4,f17,f4,f27
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f15,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f23,f23,f15,f2
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f15.f64 - ctx.f2.f64));
	// lfs f2,1968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1968);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f2,-292(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -292);
	ctx.f2.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f15,3328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3328);
	ctx.f15.f64 = double(temp.f32);
	// stfs f2,212(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmuls f15,f15,f5
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// fmadds f27,f25,f1,f23
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f25,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f26,f18,f25,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f25.f64 - ctx.f26.f64)));
	// fnmsubs f25,f21,f2,f27
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// fnmsubs f27,f20,f12,f26
	ctx.f27.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// lfs f26,3052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3052);
	ctx.f26.f64 = double(temp.f32);
	// lfs f20,1632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1632);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f27,f24,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// fmadds f3,f22,f3,f27
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f27.f64));
	// lfs f27,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f27.f64 = double(temp.f32);
	// lfs f22,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f3,f14,f27,f3
	ctx.f3.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f3.f64));
	// fmadds f3,f16,f6,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f3.f64));
	// fadds f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// stfs f4,4504(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4504, temp.u32);
	// lfs f3,1872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1872);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f27,f3,f4
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,-296(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -296);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// stfs f3,892(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 892, temp.u32);
	// lfs f3,3676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3676);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f24,f3,f5
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,4004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4004);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f3,f5
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,-300(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -300);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f3,1872(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1872, temp.u32);
	// fmuls f22,f27,f22
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f22.f64));
	// lfs f27,3044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3044);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f27,f4
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// lfs f27,-304(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -304);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f26,f20,f2,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f26.f64));
	// stfs f27,780(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 780, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f25,f15,f2,f25
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// fmuls f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// lfs f19,1688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1688);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// lfs f20,3684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3684);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// lfs f17,1640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1640);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// lfs f18,3392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3392);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,-308(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -308);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f16,900(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 900, temp.u32);
	// fmuls f18,f18,f5
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// lfs f16,1348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f4
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f4.f64));
	// lfs f15,-312(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -312);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f1,f24,f1,f25
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f25.f64));
	// stfs f15,908(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 908, temp.u32);
	// fmsubs f26,f26,f5,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 - ctx.f22.f64));
	// lfs f25,4160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4160);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,1648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1648);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f25,f25,f4
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// fmuls f24,f24,f4
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64));
	// lfs f22,1680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1680);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// fmadds f1,f21,f27,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 * ctx.f27.f64 + ctx.f1.f64));
	// lfs f27,3060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3060);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f27,f4
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// lfs f27,1672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1672);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f5
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f27,1656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1656);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f14,f27,f4
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// fnmsubs f27,f23,f3,f26
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// lfs f23,3692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3692);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// lfs f26,3028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3028);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f5
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// fnmsubs f1,f19,f2,f1
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f19,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f4,f19,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f19,3272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3272);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f5
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64));
	// fnmsubs f3,f20,f3,f27
	ctx.f3.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// lfs f27,3336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3336);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f27,f5
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f27,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f1,f17,f2,f1
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f1.f64));
	// fmuls f17,f4,f27
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f4,1552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1552);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f3,f18,f2,f3
	ctx.f3.f64 = double(float(ctx.f18.f64 * ctx.f2.f64 + ctx.f3.f64));
	// lfs f2,1664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1664);
	ctx.f2.f64 = double(temp.f32);
	// lfs f18,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// lfs f2,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f24,f2,f1
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f1.f64)));
	// lfs f24,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f24.f64 = double(temp.f32);
	// lfs f1,3036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3036);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f4,f4,f27
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f27,3376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3376);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f5
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// stfs f27,628(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmr f27,f24
	ctx.f27.f64 = ctx.f24.f64;
	// fmadds f24,f1,f27,f4
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 + ctx.f4.f64));
	// lfs f4,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f1,f25,f4,f3
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f22,f3,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f2.f64));
	// lfs f3,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f3.f64 = double(temp.f32);
	// lfs f22,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f25,f16,f3,f1
	ctx.f25.f64 = double(float(-(ctx.f16.f64 * ctx.f3.f64 - ctx.f1.f64)));
	// lfs f1,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f15,f1,f2
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// fmadds f25,f21,f4,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f25.f64));
	// fnmsubs f26,f26,f22,f2
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f22.f64 - ctx.f2.f64)));
	// lfs f2,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f25,f14,f3,f25
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f3.f64 - ctx.f25.f64)));
	// fmadds f26,f19,f2,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f2.f64 + ctx.f26.f64));
	// fnmsubs f4,f23,f4,f25
	ctx.f4.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// fnmsubs f2,f20,f2,f26
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// fmadds f4,f17,f27,f4
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f4.f64));
	// lfs f25,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f24,f5,f2
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f2,1868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1868);
	ctx.f2.f64 = double(temp.f32);
	// lfs f16,1496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1496);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,1704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1704);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f4,f25,f1,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f4.f64));
	// lfs f1,2088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2088);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f25,f18,f3,f4
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f4,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f27,f1,f4
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// lfs f4,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f3,2232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2232);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,1876(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1876, temp.u32);
	// fmuls f24,f4,f3
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f4,1248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1248);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,1860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1860);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f3,f4
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f4,2312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2312);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f2,f4
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f4.f64));
	// lfs f4,1792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1792);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f24,f27,f31,f24
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f31.f64 + ctx.f24.f64));
	// lfs f27,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f27,f31
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// lfs f27,-316(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -316);
	ctx.f27.f64 = double(temp.f32);
	// stfs f27,1148(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1148, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f21,f4,f3
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,2060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2060);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f4
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f28,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f3.f64));
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmuls f19,f1,f3
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f3.f64 = double(temp.f32);
	// lfs f1,1480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1480);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f15,f3
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// fmuls f18,f1,f3
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f1,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f22,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmuls f19,f19,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f14.f64));
	// lfs f14,3700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3700);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// fmadds f22,f20,f6,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f22.f64));
	// fmadds f20,f17,f27,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f27,3084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3084);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f27,f17
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// lfs f27,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f16,f4,f27
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f27,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// lfs f4,-156(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -156);
	ctx.f4.f64 = double(temp.f32);
	// fmsubs f24,f23,f4,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 - ctx.f24.f64));
	// stfs f4,776(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 776, temp.u32);
	// fnmsubs f23,f19,f1,f22
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f1.f64 - ctx.f22.f64)));
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f2,f19
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f19.f64));
	// lfs f22,1524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1524);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f22,f22,f6,f17
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f17.f64));
	// lfs f17,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fnmsubs f24,f21,f4,f24
	ctx.f24.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f24.f64)));
	// lfs f21,4224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4224);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f23,f20,f3,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f23.f64));
	// lfs f20,1696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1696);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f20,f20,f3
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64));
	// fmadds f27,f17,f1,f27
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f1,3068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3068);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f1,f5
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fmadds f1,f18,f6,f24
	ctx.f1.f64 = double(float(ctx.f18.f64 * ctx.f6.f64 + ctx.f24.f64));
	// lfs f24,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f25,f21,f24,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 + ctx.f25.f64));
	// lfs f18,1844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1844);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f24,f16,f4,f23
	ctx.f24.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f23.f64)));
	// lfs f23,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f16,f15,f6,f1
	ctx.f16.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// lfs f1,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f15,1848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1848);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// lfs f5,1356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1356);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f5,f3
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,1860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1860);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f18,f5,f18
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// fmadds f27,f27,f5,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f24.f64));
	// lfs f24,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f1,f1,f15
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// lfs f15,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f25,f17,f15,f25
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f15.f64 - ctx.f25.f64)));
	// lfs f17,4012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4012);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f23,1708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1708);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f17,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f23.f64));
	// lfs f17,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f17,f14,f17,f16
	ctx.f17.f64 = double(float(-(ctx.f14.f64 * ctx.f17.f64 - ctx.f16.f64)));
	// fnmsubs f27,f19,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// lfs f19,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f25,f24,f19,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f19.f64 - ctx.f25.f64)));
	// fmadds f24,f22,f3,f17
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f17.f64));
	// lfs f22,2232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2232);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f27,f18,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// fadds f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f25.f64));
	// stfs f26,4508(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4508, temp.u32);
	// lfs f26,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f20,f6,f24
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// fnmsubs f27,f23,f26,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f26.f64 - ctx.f27.f64)));
	// lfs f23,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f25,f21,f6,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f25.f64)));
	// fmadds f1,f1,f4,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f25.f64));
	// fadds f24,f1,f27
	ctx.f24.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// lfs f1,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f27,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f27.f64 = double(temp.f32);
	// stfs f1,1892(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1892, temp.u32);
	// fmuls f25,f1,f27
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f27,1792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1792);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f1,f22
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// lfs f1,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fmuls f18,f25,f3
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// fmuls f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// fmuls f21,f2,f1
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,2068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2068);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f1,3100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3100);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f1,f3
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f1,1660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f1,f3
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f1,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fmsubs f22,f21,f6,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 - ctx.f22.f64));
	// lfs f21,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f2,f1
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,1328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1328);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f5,f1
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f2,f1
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f1,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f1,f31
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmadds f23,f18,f26,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 + ctx.f23.f64));
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// stfs f25,628(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmuls f25,f21,f31
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// fmadds f23,f20,f6,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f23.f64));
	// fmuls f21,f2,f25
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f25,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f14,f25
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f25,1936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1936);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f5,f25
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// lfs f25,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f22,f19,f25,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f25.f64 + ctx.f22.f64));
	// lfs f25,1976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1976);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f25,f2
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f25,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// fmadds f26,f16,f26,f22
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f26.f64 + ctx.f22.f64));
	// lfs f22,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f25,f5,f25,f21
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64 + ctx.f21.f64));
	// lfs f5,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// lfs f21,1948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1948);
	ctx.f21.f64 = double(temp.f32);
	// fadds f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f5.f64));
	// lfs f5,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f31
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f5,2280(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2280, temp.u32);
	// fmuls f2,f2,f5
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64));
	// fmuls f5,f1,f28
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmadds f1,f17,f6,f23
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 + ctx.f23.f64));
	// lfs f17,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f27,f5
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f5,1488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1488);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f27,f17
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// lfs f17,1848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1848);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f21,f17,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f17.f64 + ctx.f2.f64));
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f5,f3
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f1,f15,f21,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f21.f64 - ctx.f1.f64));
	// lfs f21,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// lfs f17,2240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2240);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f26,f21,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f21,3076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3076);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// lfs f15,1888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1888);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f3,f17,f3
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f17,1800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1800);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f22,f22,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f16.f64));
	// lfs f16,2016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2016);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f15,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f18,f18,f15,f1
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f15.f64 - ctx.f1.f64)));
	// lfs f1,3716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3716);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f26,f25,f6,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f25,4168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4168);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fadds f15,f25,f1
	ctx.f15.f64 = double(float(ctx.f25.f64 + ctx.f1.f64));
	// lfs f1,-76(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -76);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f31,f31
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// stfs f1,516(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// fmuls f22,f22,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// fmadds f18,f14,f4,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f4.f64 + ctx.f18.f64));
	// fnmsubs f26,f20,f6,f26
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// fmuls f20,f15,f5
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// fmuls f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fnmsubs f19,f19,f4,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f18.f64)));
	// fmadds f26,f2,f4,f26
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f2,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f22,f17,f6,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 - ctx.f22.f64));
	// fmadds f23,f23,f6,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f19.f64));
	// fmadds f27,f27,f6,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f26,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f22,f16,f2,f22
	ctx.f22.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// fnmsubs f26,f21,f26,f23
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f26.f64 - ctx.f23.f64)));
	// lfs f21,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f21.f64 = double(temp.f32);
	// fadds f27,f24,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 + ctx.f27.f64));
	// lfs f24,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f3,f3,f24,f26
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f24.f64 - ctx.f26.f64)));
	// lfs f26,704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 704);
	ctx.f26.f64 = double(temp.f32);
	// fadds f3,f27,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// stfs f3,4512(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4512, temp.u32);
	// fmuls f3,f31,f28
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// lfs f27,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f3,f27
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f27.f64));
	// fmuls f27,f28,f28
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmuls f23,f26,f27
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f26,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f21,f26,f21
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// fmuls f26,f30,f30
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// lfs f19,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f20,f2,f22
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f22.f64));
	// lfs f20,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,3140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3140);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f21,f3,f20,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f20.f64 + ctx.f21.f64));
	// lfs f18,4036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4036);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// fadds f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 + ctx.f18.f64));
	// lfs f3,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f15,2120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2120);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,3172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3172);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f19,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// fnmsubs f23,f23,f3,f22
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f3.f64 - ctx.f22.f64)));
	// lfs f22,3188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3188);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// fmuls f20,f19,f3
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f19,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// lfs f19,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f25
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f25,-68(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -68);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f24,f18,f25,f24
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f24.f64));
	// lfs f18,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f18.f64 = double(temp.f32);
	// stfs f25,1216(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1216, temp.u32);
	// fmsubs f21,f21,f1,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 - ctx.f20.f64));
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f18,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f18,f18,f26,f27
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 + ctx.f27.f64));
	// lfs f27,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,4176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4176);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f19,f19,f27,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f24.f64));
	// fmuls f17,f26,f27
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// lfs f24,1020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1020);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,2064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2064);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f26,-72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -72);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f22,f22,f26,f23
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f26.f64 - ctx.f23.f64)));
	// lfs f23,1888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1888);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f23,f15
	ctx.f15.f64 = double(float(ctx.f23.f64 * ctx.f15.f64));
	// stfs f26,884(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 884, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f21,f14,f27,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f27.f64 + ctx.f21.f64));
	// fmuls f20,f20,f5
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// fmadds f18,f18,f3,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f17.f64));
	// lfs f3,3748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3748);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f19,f3,f2,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f2.f64 + ctx.f19.f64));
	// lfs f3,3148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3148);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f16,f2
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f2.f64));
	// fmuls f16,f3,f5
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,3156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3156);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f22,f15,f2,f22
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// fmuls f15,f3,f26
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// lfs f3,2100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2100);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// lfs f26,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// fmadds f19,f19,f5,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f17.f64));
	// lfs f17,3708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3708);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f22,f16,f27,f22
	ctx.f22.f64 = double(float(-(ctx.f16.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// lfs f16,3108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3108);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f17,f17,f2,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f15.f64));
	// lfs f15,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f3,f1,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f3,3180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3180);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f18,f3,f2,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f2.f64 + ctx.f18.f64));
	// lfs f3,2000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2000);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f26,f3
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f3,-320(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -320);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,1800(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1800, temp.u32);
	// fmuls f24,f15,f24
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// fmsubs f21,f21,f5,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 - ctx.f20.f64));
	// lfs f20,3164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3164);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f18,f16,f1,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f18.f64));
	// lfs f16,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmuls f16,f26,f16
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// fmsubs f19,f14,f3,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f3.f64 - ctx.f19.f64));
	// fnmsubs f25,f20,f25,f19
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f25.f64 - ctx.f19.f64)));
	// lfs f19,1964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1964);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f18,f5,f21
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 + ctx.f21.f64));
	// lfs f15,3732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3732);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f22,f17,f5,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f14,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,4256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4256);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// fmadds f25,f16,f3,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f25.f64));
	// lfs f3,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f3,1960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1960);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f3,3132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3132);
	ctx.f3.f64 = double(temp.f32);
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f16,3116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3116);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f3,f5
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f3,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f3,f6
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// lfs f3,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f3.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f3,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// stfs f18,1232(r1)
	temp.f32 = float(ctx.f18.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1232, temp.u32);
	// lfs f18,4028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4028);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f5
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f5.f64));
	// fmuls f26,f26,f2
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// fnmsubs f25,f24,f2,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// fmadds f20,f15,f14,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f14.f64 + ctx.f20.f64));
	// lfs f15,1808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1808);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// lfs f19,1828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1828);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64));
	// lfs f15,1852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1852);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,4020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4020);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f5
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f5.f64));
	// fmuls f14,f14,f5
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f5.f64));
	// fmsubs f26,f23,f2,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f26.f64));
	// lfs f23,3196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3196);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// fmadds f27,f20,f15,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f15.f64 + ctx.f27.f64));
	// lfs f20,1380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f3,f20
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// lfs f15,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f21,f15,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f15.f64 + ctx.f26.f64));
	// lfs f21,3740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3740);
	ctx.f21.f64 = double(temp.f32);
	// lfs f15,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f15,f15,f5
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// lfs f5,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f19,f19,f4,f27
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f27,1964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1964);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f20,f5,f27,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f27.f64 + ctx.f20.f64));
	// lfs f5,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f26,f18,f5,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f5,3124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3124);
	ctx.f5.f64 = double(temp.f32);
	// lfs f18,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f5,f18
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// lfs f5,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f24,f15,f5
	ctx.f24.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// lfs f5,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// lfs f15,1852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1852);
	ctx.f15.f64 = double(temp.f32);
	// stfs f5,1848(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1848, temp.u32);
	// fnmsubs f25,f24,f1,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f1,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f5,f15
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// lfs f5,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f23,f23,f5,f19
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f19.f64)));
	// lfs f5,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f26,f17,f5,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f5.f64 - ctx.f26.f64)));
	// lfs f17,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,3724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3724);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f17.f64));
	// lfs f17,2072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2072);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f27
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64));
	// fmadds f24,f20,f6,f23
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f23.f64));
	// lfs f23,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f20,f16,f5,f26
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f5.f64 + ctx.f26.f64));
	// lfs f5,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f28
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f28.f64));
	// lfs f26,1852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1852);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f23,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64));
	// lfs f1,1808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1808);
	ctx.f1.f64 = double(temp.f32);
	// fadds f25,f22,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 + ctx.f25.f64));
	// lfs f22,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64));
	// lfs f16,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f1
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f5,f5,f26
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f23,f26,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 + ctx.f24.f64));
	// lfs f23,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f24,f21,f2,f20
	ctx.f24.f64 = double(float(-(ctx.f21.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// fmadds f5,f23,f27,f5
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f5.f64));
	// lfs f23,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f26,f15,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f15.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f15,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f24,f14,f23,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f23.f64 - ctx.f24.f64)));
	// lfs f23,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f23,f1,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f5.f64));
	// fnmsubs f5,f17,f4,f26
	ctx.f5.f64 = double(float(-(ctx.f17.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f17,3236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3236);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f26,f18,f12,f24
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f24.f64)));
	// fmadds f24,f16,f6,f5
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f5.f64));
	// lfs f16,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f5,f19,f12,f26
	ctx.f5.f64 = double(float(-(ctx.f19.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// lfs f26,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f26.f64 = double(temp.f32);
	// fadds f5,f25,f5
	ctx.f5.f64 = double(float(ctx.f25.f64 + ctx.f5.f64));
	// stfs f5,4516(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4516, temp.u32);
	// lfs f5,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f26,f5
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f5.f64));
	// lfs f5,1908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1908);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f20,f5,f1
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f26,1420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1420);
	ctx.f26.f64 = double(temp.f32);
	// lfs f5,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f5.f64 = double(temp.f32);
	// fadds f19,f26,f5
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f5.f64));
	// lfs f26,-324(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -324);
	ctx.f26.f64 = double(temp.f32);
	// lfs f5,4064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4064);
	ctx.f5.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f18,f5,f26
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f5,1988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1988);
	ctx.f5.f64 = double(temp.f32);
	// lfs f25,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// stfs f25,1888(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1888, temp.u32);
	// stfs f26,488(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f25,-328(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -328);
	ctx.f25.f64 = double(temp.f32);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// stfs f25,1020(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1020, temp.u32);
	// fmuls f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// fmuls f21,f20,f4
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f4.f64));
	// lfs f20,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f27,f20,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f27.f64));
	// lfs f20,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// stfs f20,1808(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1808, temp.u32);
	// lfs f20,2004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2004);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f18,f17,f16,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f18.f64));
	// lfs f16,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// lfs f17,1628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f5,f17
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// fmadds f25,f19,f16,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f25.f64));
	// lfs f19,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f22,f22,f19,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f19.f64 - ctx.f21.f64));
	// lfs f21,2128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2128);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// lfs f19,1540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1540);
	ctx.f19.f64 = double(temp.f32);
	// lfs f1,1412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f19,f1
	ctx.f1.f64 = double(float(ctx.f19.f64 + ctx.f1.f64));
	// lfs f16,1684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1684);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,3440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3440);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmadds f25,f16,f15,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 + ctx.f25.f64));
	// fmadds f23,f23,f6,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f22.f64));
	// lfs f22,3220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3220);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64));
	// lfs f26,-3044(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -3044);
	ctx.f26.f64 = double(temp.f32);
	// lfs f16,1788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1788);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32243
	ctx.r11.s64 = -2113077248;
	// lfs f14,1668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f16,f16,f26
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f26.f64));
	// fadds f14,f1,f14
	ctx.f14.f64 = double(float(ctx.f1.f64 + ctx.f14.f64));
	// lfs f1,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f27,f1,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f1,3204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3204);
	ctx.f1.f64 = double(temp.f32);
	// lfs f23,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f25,f5
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// fmadds f23,f1,f23,f22
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f23.f64 + ctx.f22.f64));
	// lfs f1,-5404(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -5404);
	ctx.f1.f64 = double(temp.f32);
	// lfs f22,3448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3448);
	ctx.f22.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f1,1784(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1784, temp.u32);
	// lfs f15,3756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3756);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f3,f15
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f15.f64));
	// fmsubs f22,f22,f1,f16
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64 - ctx.f16.f64));
	// lfs f1,1396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1396);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f5,f1
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f20,f20,f4,f27
	ctx.f20.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f27,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,1148(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1148, temp.u32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// stfs f27,1792(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1792, temp.u32);
	// fmsubs f25,f18,f5,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 - ctx.f25.f64));
	// fmuls f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// fnmsubs f21,f21,f4,f20
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f20.f64)));
	// fadds f27,f27,f1
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// lfs f1,3764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3764);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f18,f5,f1
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,3780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3780);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f26,f1,f26,f22
	ctx.f26.f64 = double(float(-(ctx.f1.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f1,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f16,f1
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// lfs f1,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f1.f64 = double(temp.f32);
	// lfs f16,1888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1888);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f1
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// lfs f1,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f25,f17,f1,f25
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f1,1548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1548);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f5,f1
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 956);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,1808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1808);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f1
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f1.f64));
	// lfs f1,-472(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -472);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,2220(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2220, temp.u32);
	// fmadds f27,f27,f1,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f26.f64));
	// lfs f26,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f26.f64 = double(temp.f32);
	// lfs f1,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f22,f18,f1,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f1.f64 - ctx.f22.f64));
	// fnmsubs f25,f19,f26,f25
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f25.f64)));
	// lfs f19,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f21,f15,f19,f21
	ctx.f21.f64 = double(float(-(ctx.f15.f64 * ctx.f19.f64 - ctx.f21.f64)));
	// lfs f19,4044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4044);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f1,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f1,f31,f27
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64 + ctx.f27.f64));
	// stfs f1,4528(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4528, temp.u32);
	// lfs f1,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f22,f20,f1,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f1.f64 - ctx.f22.f64)));
	// lfs f1,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f23,f5,f25
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f25.f64));
	// fmadds f25,f14,f6,f21
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f6.f64 + ctx.f21.f64));
	// fnmsubs f27,f16,f1,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f25,4520(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4520, temp.u32);
	// fnmsubs f1,f17,f1,f27
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// stfs f1,4524(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4524, temp.u32);
	// lfs f1,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f27,f1,f31
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f1,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fadds f27,f1,f27
	ctx.f27.f64 = double(float(ctx.f1.f64 + ctx.f27.f64));
	// lfs f1,1468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1468);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f25,f3,f1
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f1,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f18,3212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3212);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f25,f12
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f12.f64));
	// lfs f17,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f18,f17,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f17.f64 + ctx.f19.f64));
	// lfs f17,3456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3456);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f3,f1
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// lfs f16,1404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f5,f17
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f17.f64));
	// lfs f15,1808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1808);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// lfs f24,3276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3276);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f3,f24
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f24.f64));
	// lfs f23,3772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3772);
	ctx.f23.f64 = double(temp.f32);
	// lfs f21,1436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1436);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f20,1572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f3,f21
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f21.f64));
	// lfs f18,1700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1700);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f3,f20
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// fmuls f18,f3,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// lfs f14,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f27,f2,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 - ctx.f25.f64));
	// lfs f2,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f22,f19,f5,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f25,1556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1556);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// lfs f19,3464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3464);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// lfs f5,3300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3300);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// fnmsubs f1,f1,f12,f27
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f27.f64)));
	// fmuls f27,f3,f5
	ctx.f27.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f5,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f15,f15,f5
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// lfs f5,3804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3804);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f26,f17,f26,f22
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f17,1888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1888);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f3,f5
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f5.f64));
	// lfs f5,2940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2940);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f3,1848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1848);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f5,f3
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f17,f17,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// lfs f5,-160(r15)
	temp.u32 = PPC_LOAD_U32(ctx.r15.u32 + -160);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,916(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 916, temp.u32);
	// fmadds f5,f24,f5,f1
	ctx.f5.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f1.f64));
	// lfs f1,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// lfs f24,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// lfs f1,4216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4216);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f14,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f1.f64));
	// lfs f14,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f26,f25,f14,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f14.f64 - ctx.f26.f64)));
	// lfs f14,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f14.f64 = double(temp.f32);
	// lfs f25,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f3,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f14,1852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1852);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f5,f23,f3,f5
	ctx.f5.f64 = double(float(-(ctx.f23.f64 * ctx.f3.f64 - ctx.f5.f64)));
	// lfs f3,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f3.f64 = double(temp.f32);
	// lfs f23,1232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1232);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,3480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3480);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f14
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f14.f64));
	// lfs f14,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f26,f16,f14,f26
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f14.f64 - ctx.f26.f64)));
	// lfs f14,1988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1988);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,4076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4076);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f4,f1,f6,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 - ctx.f4.f64));
	// lfs f1,4100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4100);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f14,f16
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f16.f64));
	// lfs f14,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f1
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f1.f64));
	// lfs f1,1964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1964);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f21,f6,f5
	ctx.f5.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f5.f64));
	// lfs f6,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f30
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// stfs f6,1564(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1564, temp.u32);
	// fmuls f21,f6,f1
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f6,f31,f31
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f1,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f1.f64 = double(temp.f32);
	// stfs f6,488(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmr f6,f1
	ctx.f6.f64 = ctx.f1.f64;
	// lfs f1,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f3,f3,f1,f4
	ctx.f3.f64 = double(float(-(ctx.f3.f64 * ctx.f1.f64 - ctx.f4.f64)));
	// lfs f4,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f5,f20,f4,f5
	ctx.f5.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f5.f64)));
	// fnmsubs f26,f15,f6,f26
	ctx.f26.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// lfs f15,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f21,f21,f4,f3
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,1020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1020);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f5,f18,f4,f5
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f5.f64));
	// fnmsubs f6,f17,f6,f26
	ctx.f6.f64 = double(float(-(ctx.f17.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// lfs f26,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f6,f25,f3,f6
	ctx.f6.f64 = double(float(-(ctx.f25.f64 * ctx.f3.f64 - ctx.f6.f64)));
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f5,f2,f3,f5
	ctx.f5.f64 = double(float(-(ctx.f2.f64 * ctx.f3.f64 - ctx.f5.f64)));
	// lfs f2,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f6,f16,f2,f6
	ctx.f6.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f6.f64));
	// stfs f6,4532(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4532, temp.u32);
	// fmadds f5,f19,f12,f5
	ctx.f5.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f5.f64));
	// lfs f6,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f5,f27,f6,f5
	ctx.f5.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// fmadds f2,f22,f6,f5
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f5.f64));
	// lfs f5,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f2,f24,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// fmadds f5,f23,f5,f2
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f2,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f25,f14,f6,f5
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f6.f64 - ctx.f5.f64)));
	// lfs f6,1964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1964);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f27,f2,f6
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f5,2940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2940);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f6,f5
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f2,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f6,f30,f30
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// fmuls f23,f6,f2
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f2,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f22,f2,f26
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// lfs f2,2072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2072);
	ctx.f2.f64 = double(temp.f32);
	// lfs f26,4216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4216);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f2,f26
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// lfs f2,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f19,f2,f6
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f6,1428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1428);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,1852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1852);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f18,f6,f2
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f26,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f6,f31,f28
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmadds f21,f27,f26,f21
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f26.f64 + ctx.f21.f64));
	// lfs f27,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f6,f27
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f6,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f27,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f24,f24,f1,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f1,3260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3260);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f23,f23,f27,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f22.f64));
	// fmuls f16,f6,f5
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f6,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f6,f1
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f5,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f31,f31
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f22,f19,f6
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// lfs f19,3788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3788);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fmuls f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// fnmsubs f26,f20,f26,f24
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f26.f64 - ctx.f24.f64)));
	// fmuls f15,f15,f1
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// lfs f1,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmuls f14,f5,f1
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,1532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f1,2236(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2236, temp.u32);
	// fmuls f24,f5,f1
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,2304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2304);
	ctx.f1.f64 = double(temp.f32);
	// lfs f20,3636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3636);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f27,f22,f27,f23
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 - ctx.f23.f64));
	// fmuls f20,f1,f20
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// lfs f1,2948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2948);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f23,f15,f1
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f1.f64));
	// lfs f1,1636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f5,f1
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// lfs f1,4052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4052);
	ctx.f1.f64 = double(temp.f32);
	// lfs f15,3244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3244);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f26,f18,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// fadds f15,f15,f1
	ctx.f15.f64 = double(float(ctx.f15.f64 + ctx.f1.f64));
	// lfs f1,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fmadds f4,f16,f4,f26
	ctx.f4.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 + ctx.f26.f64));
	// fmuls f18,f6,f1
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f1,f2
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f1,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f1,f17,f1,f27
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// lfs f27,3796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3796);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f15,f5
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f5.f64));
	// lfs f5,3252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3252);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f26,f6,f5
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,3292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3292);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f16,f6,f5
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f27,f6,f27
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// fmuls f15,f2,f28
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// fnmsubs f2,f21,f5,f1
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f5.f64 - ctx.f1.f64)));
	// lfs f5,3820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3820);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f21,f6,f5
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f1,792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 792);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f5,f28,f28
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmuls f1,f1,f5
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// lfs f5,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f19,f19,f5,f4
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// lfs f5,3284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3284);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f5,f5,f3
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f4,4092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4092);
	ctx.f4.f64 = double(temp.f32);
	// stfs f5,488(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f4,f6,f4
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f4.f64));
	// stfs f4,1020(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1020, temp.u32);
	// fmuls f3,f16,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// fmr f5,f16
	ctx.f5.f64 = ctx.f16.f64;
	// fnmsubs f23,f23,f5,f2
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f2,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f2.f64 = double(temp.f32);
	// fmr f4,f2
	ctx.f4.f64 = ctx.f2.f64;
	// lfs f2,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f19,f14,f4,f19
	ctx.f19.f64 = double(float(-(ctx.f14.f64 * ctx.f4.f64 - ctx.f19.f64)));
	// fmadds f23,f20,f4,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f23.f64));
	// lfs f20,2456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2456);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f24,f12,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f19.f64));
	// fnmsubs f24,f22,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f22.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// lfs f5,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f5.f64 = double(temp.f32);
	// lfs f16,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f16,f1,f2,f16
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f16.f64));
	// lfs f14,1020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1020);
	ctx.f14.f64 = double(temp.f32);
	// lfs f1,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f1.f64 = double(temp.f32);
	// fmsubs f14,f14,f1,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f1.f64 - ctx.f3.f64));
	// lfs f3,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f23,f18,f3,f23
	ctx.f23.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f23.f64)));
	// fmadds f24,f17,f5,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f24.f64));
	// fnmsubs f27,f27,f4,f23
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f23.f64)));
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f27,f26,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f26,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f15,f26,f24
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f26.f64 + ctx.f24.f64));
	// lfs f24,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f22,f21,f4,f27
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f21,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f21.f64 = double(temp.f32);
	// fadds f27,f25,f26
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// stfs f27,4536(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4536, temp.u32);
	// fmuls f27,f28,f28
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// fmadds f25,f16,f6,f14
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f14.f64));
	// fmuls f26,f23,f27
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// lfs f27,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// fmuls f21,f21,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f27.f64));
	// lfs f19,2464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2464);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// fmuls f18,f26,f6
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f26,3324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3324);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f6,f26
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// lfs f26,1800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1800);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f16,f24,f26,f25
	ctx.f16.f64 = double(float(-(ctx.f24.f64 * ctx.f26.f64 - ctx.f25.f64)));
	// lfs f25,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f31,f28
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// lfs f24,2956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2956);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f18,f2
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64));
	// lfs f2,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f26,f25
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f26,1960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1960);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f24,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f21.f64));
	// lfs f25,2448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2448);
	ctx.f25.f64 = double(temp.f32);
	// fadds f21,f20,f25
	ctx.f21.f64 = double(float(ctx.f20.f64 + ctx.f25.f64));
	// lfs f25,3316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3316);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f20,f19,f3
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmuls f19,f6,f25
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// lfs f25,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f25,f2
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f2,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f18,f17,f2,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 - ctx.f18.f64));
	// fmuls f17,f15,f6
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f6.f64));
	// fmadds f16,f26,f4,f16
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f4.f64 + ctx.f16.f64));
	// lfs f26,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f21,f21,f26,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 + ctx.f20.f64));
	// lfs f20,3308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3308);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f2
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// fmuls f15,f14,f6
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// fmadds f18,f17,f3,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f3.f64 + ctx.f18.f64));
	// lfs f17,2080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2080);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f19,f19,f4,f16
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f16.f64)));
	// lfs f16,3340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3340);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f16,f1,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f16,3812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3812);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f20,f16,f1,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f20.f64));
	// lfs f16,2136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2136);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f24,f16,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f24.f64));
	// lfs f16,3636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3636);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f25,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// lfs f25,2392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2392);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f19,f15,f3,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 + ctx.f19.f64));
	// lfs f15,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f25,f2,f21
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f21.f64));
	// fmuls f25,f31,f31
	ctx.f25.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fmadds f24,f24,f4,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f18.f64));
	// fmuls f18,f16,f6
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fmadds f4,f17,f4,f19
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f19.f64));
	// lfs f17,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,3828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3828);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f6,f19
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmuls f25,f15,f25
	ctx.f25.f64 = double(float(ctx.f15.f64 * ctx.f25.f64));
	// lfs f15,3268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3268);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// fmsubs f21,f21,f6,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 - ctx.f20.f64));
	// lfs f20,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f17.f64));
	// lfs f17,4084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4084);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// fnmsubs f4,f18,f3,f4
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f18,4060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4060);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// fnmsubs f24,f15,f2,f24
	ctx.f24.f64 = double(float(-(ctx.f15.f64 * ctx.f2.f64 - ctx.f24.f64)));
	// fnmsubs f2,f19,f2,f21
	ctx.f2.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f21.f64)));
	// lfs f21,3332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3332);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// fadds f4,f22,f4
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f4.f64));
	// fmadds f3,f20,f3,f25
	ctx.f3.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f25.f64));
	// lfs f25,1944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1944);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// fmadds f26,f17,f26,f24
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f24.f64));
	// fmadds f6,f3,f6,f2
	ctx.f6.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f2.f64));
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f3,f18,f1,f26
	ctx.f3.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// lfs f1,1708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1708);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f1,f2
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// fadds f26,f4,f6
	ctx.f26.f64 = double(float(ctx.f4.f64 + ctx.f6.f64));
	// lfs f6,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f28,f6
	ctx.f6.f64 = double(float(ctx.f28.f64 * ctx.f6.f64));
	// lfs f4,2088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2088);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f25,f21,f12,f3
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfs f3,2408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2408);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f24,f4,f6
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f3,f6
	ctx.f21.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// fmuls f3,f23,f28
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,2424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2424);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f3,f6
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f20,f3,f6
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// lfs f3,1676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1676);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f3,f6
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmuls f3,f2,f30
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f2,2232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2232);
	ctx.f2.f64 = double(temp.f32);
	// stfs f3,460(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// fmuls f2,f3,f2
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// lfs f3,2432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2432);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f6
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f4,f3
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f20,f20,f3
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// lfs f3,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f24,f22,f3,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f3,2152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2152);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f3,f6
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,2416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2416);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f3,f6
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f4
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f3,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,1536(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1536, temp.u32);
	// fmadds f24,f24,f5,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f21.f64));
	// lfs f21,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f22,f31
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64));
	// fmuls f14,f4,f3
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f4,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f30
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f3,1860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1860);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f3,f4
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// stfs f4,412(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmuls f4,f21,f28
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// lfs f3,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f2,f3,f20
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f3.f64 + ctx.f20.f64));
	// lfs f21,1868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1868);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f20,f14,f6
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// fmsubs f3,f1,f3,f24
	ctx.f3.f64 = double(float(ctx.f1.f64 * ctx.f3.f64 - ctx.f24.f64));
	// lfs f24,2016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2016);
	ctx.f24.f64 = double(temp.f32);
	// lfs f1,3592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3592);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f4,f21,f4
	ctx.f4.f64 = double(float(ctx.f21.f64 * ctx.f4.f64));
	// fmuls f21,f15,f30
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// lfs f15,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f2,f17,f15,f2
	ctx.f2.f64 = double(float(-(ctx.f17.f64 * ctx.f15.f64 - ctx.f2.f64)));
	// lfs f15,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,2956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2956);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f24,f24,f17
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// lfs f17,4232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4232);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fmadds f20,f4,f15,f20
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f15.f64 + ctx.f20.f64));
	// lfs f4,1800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1800);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f27,f27,f4,f25
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// lfs f4,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f2,f22,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// lfs f4,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f25,f23,f5,f3
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// fmuls f4,f4,f28
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f3,1708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1708);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,2192(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2192, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f23,f3,f4
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,4068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4068);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f3,f4
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,1716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,1868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1868);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f4
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// lfs f4,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f27,f24,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f4,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f2,f21,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// lfs f21,1916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1916);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f25,f19,f4,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f19,2088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2088);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f19,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f21.f64));
	// lfs f19,-332(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -332);
	ctx.f19.f64 = double(temp.f32);
	// stfs f19,1716(r1)
	temp.f32 = float(ctx.f19.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1716, temp.u32);
	// lfs f19,1744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1744);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f3,f19
	ctx.f19.f64 = double(float(ctx.f3.f64 * ctx.f19.f64));
	// lfs f3,1492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1492);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f3,f6
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f24,2472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2472);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// fmadds f3,f22,f12,f27
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f27.f64));
	// lfs f22,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f27,f20,f4,f2
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f4.f64 + ctx.f2.f64));
	// lfs f2,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f25,f18,f2,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f2.f64 - ctx.f25.f64)));
	// lfs f20,2440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2440);
	ctx.f20.f64 = double(temp.f32);
	// lfs f18,2388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2388);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fmuls f18,f18,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fadds f3,f26,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 + ctx.f3.f64));
	// stfs f3,4540(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4540, temp.u32);
	// lfs f3,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f27,f23,f3,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f27.f64));
	// lfs f23,1536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1536);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f26,f16,f5,f25
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f5.f64 - ctx.f25.f64)));
	// lfs f25,1860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1860);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// lfs f16,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,3528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3528);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f16,f31
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// fmuls f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// fnmsubs f2,f24,f2,f27
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f27,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f27,f27,f4,f26
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f24,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// fmadds f26,f19,f3,f2
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f2.f64));
	// lfs f19,1516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1516);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f2,f1,f12,f27
	ctx.f2.f64 = double(float(-(ctx.f1.f64 * ctx.f12.f64 - ctx.f27.f64)));
	// fmuls f19,f19,f6
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// fmadds f2,f17,f5,f2
	ctx.f2.f64 = double(float(ctx.f17.f64 * ctx.f5.f64 + ctx.f2.f64));
	// lfs f17,1484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1484);
	ctx.f17.f64 = double(temp.f32);
	// lfs f1,1716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f17,f6
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// fnmsubs f2,f15,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f15,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f27,f21,f1,f2
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f2.f64));
	// lfs f2,1224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1224);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,1868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1868);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,1736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1736);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// lfs f21,3552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3552);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f2,1708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1708);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fmuls f1,f1,f4
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// fmsubs f1,f25,f3,f1
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f3.f64 - ctx.f1.f64));
	// lfs f25,2480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2480);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f25,f25,f5,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f21.f64));
	// lfs f21,3568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3568);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fnmsubs f1,f24,f15,f1
	ctx.f1.f64 = double(float(-(ctx.f24.f64 * ctx.f15.f64 - ctx.f1.f64)));
	// lfs f15,3836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3836);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f15,f5,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f5.f64 + ctx.f21.f64));
	// lfs f15,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f15.f64 = double(temp.f32);
	// lfs f24,3348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3348);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64));
	// fmuls f24,f24,f5
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f5.f64));
	// lfs f15,1976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1976);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f14,f4,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f14,1476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1476);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f2
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f2.f64));
	// fmuls f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// fmadds f3,f23,f3,f1
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f1.f64));
	// lfs f1,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f1.f64 = double(temp.f32);
	// lfs f23,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f2,f23
	ctx.f23.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// fmadds f24,f16,f1,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f24.f64));
	// lfs f16,1816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1816);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f21,f21,f6,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 - ctx.f18.f64));
	// lfs f18,1344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1344);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f26,f15,f4,f26
	ctx.f26.f64 = double(float(-(ctx.f15.f64 * ctx.f4.f64 - ctx.f26.f64)));
	// lfs f15,1860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1860);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// fmuls f18,f18,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// fnmsubs f22,f22,f12,f3
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// lfs f3,2400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2400);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f3,f6
	ctx.f15.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,1880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1880);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f24,f24,f6,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f21.f64));
	// lfs f21,1868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1868);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// lfs f3,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f31,f3
	ctx.f3.f64 = double(float(ctx.f31.f64 * ctx.f3.f64));
	// fmadds f26,f18,f4,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f26.f64));
	// fmadds f25,f25,f6,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f22.f64));
	// fnmsubs f24,f23,f5,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// lfs f23,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f2,f3
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f3,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f3,f3,f31
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fadds f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f20,f5,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f5.f64 - ctx.f25.f64)));
	// fmuls f26,f18,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f26.f64));
	// fadds f22,f2,f3
	ctx.f22.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f2,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f3,f2,f31
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f3,412(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmuls f3,f23,f31
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// fadds f23,f22,f3
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f3.f64));
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f25,f19,f3,f25
	ctx.f25.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f25.f64)));
	// fmadds f4,f17,f4,f25
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f4.f64 + ctx.f25.f64));
	// lfs f25,2560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2560);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f4,f14,f3,f4
	ctx.f4.f64 = double(float(-(ctx.f14.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f3,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f3.f64 = double(temp.f32);
	// lfs f22,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f1.f64));
	// lfs f1,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f24,f21,f1,f24
	ctx.f24.f64 = double(float(-(ctx.f21.f64 * ctx.f1.f64 - ctx.f24.f64)));
	// lfs f21,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f4,f16,f1,f4
	ctx.f4.f64 = double(float(-(ctx.f16.f64 * ctx.f1.f64 - ctx.f4.f64)));
	// fmadds f23,f23,f21,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f21.f64 + ctx.f22.f64));
	// lfs f22,1500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1500);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f26,f26,f5,f24
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f5.f64 - ctx.f24.f64)));
	// lfs f24,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f5,f15,f5,f4
	ctx.f5.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// lfs f24,2552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2552);
	ctx.f24.f64 = double(temp.f32);
	// fadds f1,f27,f5
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f5.f64));
	// lfs f5,2544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2544);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f3
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f5,2964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2964);
	ctx.f5.f64 = double(temp.f32);
	// lfs f27,2576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2576);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f5,f24
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f24.f64));
	// fmuls f27,f5,f27
	ctx.f27.f64 = double(float(ctx.f5.f64 * ctx.f27.f64));
	// fmuls f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// lfs f20,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f6,f23,f6,f26
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f21,3520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3520);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f21,f21,f20,f4
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 - ctx.f4.f64));
	// lfs f4,1872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1872);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f27,f27,f4
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// lfs f4,2568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2568);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f5,f4
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// lfs f4,1604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f25,f4,f19,f25
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f19.f64 + ctx.f25.f64));
	// lfs f16,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f16.f64 = double(temp.f32);
	// lfs f4,3536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3536);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f5,f4
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f4.f64 = double(temp.f32);
	// lfs f23,1708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1708);
	ctx.f23.f64 = double(temp.f32);
	// lfs f26,2368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2368);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f23,f26
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f26.f64));
	// lfs f23,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,1360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1360);
	ctx.f18.f64 = double(temp.f32);
	// fmsubs f27,f21,f5,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f5.f64 - ctx.f27.f64));
	// lfs f21,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f2,f21,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// lfs f21,2344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2344);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f16.f64));
	// lfs f17,3688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3688);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,2504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2504);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f18,f4,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// fmuls f17,f4,f17
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f17.f64));
	// lfs f15,2328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2328);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f16,f4,f16
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f16.f64));
	// lfs f14,3560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3560);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// fmadds f27,f25,f5,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f5.f64 + ctx.f27.f64));
	// lfs f25,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f2,f2,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f25,1652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f4,f25
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f25.f64));
	// fmuls f17,f17,f15
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f15.f64));
	// lfs f15,2584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2584);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f5,f15
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// fnmsubs f27,f24,f3,f27
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// lfs f24,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f24.f64 = double(temp.f32);
	// fmsubs f2,f21,f24,f2
	ctx.f2.f64 = double(float(ctx.f21.f64 * ctx.f24.f64 - ctx.f2.f64));
	// lfs f24,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// lfs f21,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,1596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1596);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// lfs f21,1508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1508);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// fmadds f27,f22,f23,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f27.f64));
	// lfs f23,2512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2512);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f2,f23,f22,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f2.f64));
	// lfs f22,2536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2536);
	ctx.f22.f64 = double(temp.f32);
	// lfs f23,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f24,f22,f3,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f3,2496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2496);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f22,f4,f3
	ctx.f22.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,1368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1368);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,1716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1716);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// fmadds f6,f26,f3,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 * ctx.f3.f64 + ctx.f6.f64));
	// lfs f3,1872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1872);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f26,f20,f3,f27
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// lfs f27,444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 444);
	ctx.f27.f64 = double(temp.f32);
	// lfs f3,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f2,f2,f27,f25
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f27.f64 - ctx.f25.f64));
	// fmuls f25,f23,f3
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,1692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1692);
	ctx.f3.f64 = double(temp.f32);
	// lfs f23,908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 908);
	ctx.f23.f64 = double(temp.f32);
	// fadds f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// fmuls f23,f3,f23
	ctx.f23.f64 = double(float(ctx.f3.f64 * ctx.f23.f64));
	// lfs f3,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f1,f19,f3,f26
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// stfs f6,4544(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4544, temp.u32);
	// lfs f6,900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 900);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f2,f21,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f21.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// fnmsubs f1,f18,f6,f1
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f1.f64)));
	// stfs f4,412(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f26,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f26.f64 = double(temp.f32);
	// fmr f4,f26
	ctx.f4.f64 = ctx.f26.f64;
	// lfs f26,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f1,f17,f26,f1
	ctx.f1.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f1.f64));
	// lfs f19,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,1968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1968);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// lfs f18,3544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3544);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f18,f3,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f3.f64 + ctx.f23.f64));
	// lfs f21,1376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1376);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f2,f22,f4,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f4.f64 - ctx.f2.f64)));
	// lfs f26,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f22,f26,f6,f2
	ctx.f22.f64 = double(float(-(ctx.f26.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// lfs f26,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f6,f16,f4,f1
	ctx.f6.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f1.f64)));
	// lfs f4,892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 892);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f2.f64 = double(temp.f32);
	// lfs f16,2608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2608);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f23,f23,f5,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f22,2624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2624);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f6,f15,f4,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f6.f64));
	// lfs f4,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f4.f64 = double(temp.f32);
	// lfs f15,3576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3576);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f5,f15
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f15.f64));
	// fnmsubs f6,f14,f26,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f26.f64 - ctx.f6.f64)));
	// lfs f14,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f6,f24,f5,f6
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f6.f64));
	// fnmsubs f25,f25,f2,f6
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f6.f64)));
	// lfs f6,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f4,f6
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,1724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	ctx.f4.f64 = double(temp.f32);
	// lfs f6,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fmuls f24,f4,f6
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f20,f2
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f2.f64));
	// lfs f20,3512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3512);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// stfs f1,628(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmuls f26,f20,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f20,2632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2632);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmuls f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// lfs f18,1612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f5,f18
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f18.f64));
	// fmadds f2,f19,f12,f2
	ctx.f2.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f2.f64));
	// lfs f19,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// lfs f4,3584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3584);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// fmuls f17,f5,f4
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f4.f64));
	// lfs f4,3600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3600);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f26,f4,f3,f26
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 + ctx.f26.f64));
	// lfs f4,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f4.f64 = double(temp.f32);
	// fnmsubs f3,f18,f3,f23
	ctx.f3.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f23.f64)));
	// lfs f18,2096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2096);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f16
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f16.f64));
	// lfs f23,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f4,f23
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f23.f64));
	// lfs f4,2488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2488);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f27,f27,f4
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// lfs f4,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f16,2520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2520);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f5,f16
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f16.f64));
	// fmadds f3,f26,f5,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f3.f64));
	// fmuls f4,f18,f4
	ctx.f4.f64 = double(float(ctx.f18.f64 * ctx.f4.f64));
	// lfs f18,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f1,f14,f18,f1
	ctx.f1.f64 = double(float(ctx.f14.f64 * ctx.f18.f64 + ctx.f1.f64));
	// lfs f18,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f26,f23,f6
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// lfs f23,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fnmsubs f3,f17,f18,f3
	ctx.f3.f64 = double(float(-(ctx.f17.f64 * ctx.f18.f64 - ctx.f3.f64)));
	// lfs f18,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f14,1324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1324);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// lfs f14,736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 736);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f23,f14
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f14.f64));
	// lfs f14,1340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// lfs f5,1384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1384);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f5,1968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1968);
	ctx.f5.f64 = double(temp.f32);
	// stfs f6,412(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmr f6,f5
	ctx.f6.f64 = ctx.f5.f64;
	// lfs f5,780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 780);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f3,f27,f5,f3
	ctx.f3.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f3.f64));
	// lfs f5,624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 624);
	ctx.f5.f64 = double(temp.f32);
	// lfs f27,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f5
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f5.f64));
	// lfs f5,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f1,f1,f6,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f6.f64 + ctx.f24.f64));
	// fmadds f24,f18,f5,f17
	ctx.f24.f64 = double(float(ctx.f18.f64 * ctx.f5.f64 + ctx.f17.f64));
	// lfs f5,2664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2664);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f18,f5,f12
	ctx.f18.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f5,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f5.f64 = double(temp.f32);
	// fmsubs f1,f1,f5,f21
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f5.f64 - ctx.f21.f64));
	// lfs f21,644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 644);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f3,f16,f21,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f21.f64 + ctx.f3.f64));
	// lfs f21,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f2,f2,f5,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f5.f64 + ctx.f1.f64));
	// lfs f5,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f5.f64 = double(temp.f32);
	// fnmsubs f3,f15,f5,f3
	ctx.f3.f64 = double(float(-(ctx.f15.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// lfs f5,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f5.f64 = double(temp.f32);
	// lfs f1,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f22,f5,f2
	ctx.f2.f64 = double(float(-(ctx.f22.f64 * ctx.f5.f64 - ctx.f2.f64)));
	// lfs f22,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f3,f14,f1,f3
	ctx.f3.f64 = double(float(-(ctx.f14.f64 * ctx.f1.f64 - ctx.f3.f64)));
	// fmuls f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// fnmsubs f2,f20,f12,f2
	ctx.f2.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f1,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f1.f64 = double(temp.f32);
	// fadds f3,f25,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 + ctx.f3.f64));
	// stfs f3,4548(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4548, temp.u32);
	// lfs f3,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f3.f64 = double(temp.f32);
	// lfs f25,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f6,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f6.f64 = double(temp.f32);
	// lfs f20,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f3,f19,f3,f2
	ctx.f3.f64 = double(float(-(ctx.f19.f64 * ctx.f3.f64 - ctx.f2.f64)));
	// lfs f2,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f3,f26,f5,f3
	ctx.f3.f64 = double(float(-(ctx.f26.f64 * ctx.f5.f64 - ctx.f3.f64)));
	// lfs f26,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f4,f4,f2,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64 + ctx.f3.f64));
	// lfs f3,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f4,f23,f5,f4
	ctx.f4.f64 = double(float(-(ctx.f23.f64 * ctx.f5.f64 - ctx.f4.f64)));
	// lfs f5,1316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1316);
	ctx.f5.f64 = double(temp.f32);
	// lfs f23,1352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1352);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f4,f24,f5,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f4.f64));
	// lfs f24,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f23,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// fnmsubs f1,f1,f3,f4
	ctx.f1.f64 = double(float(-(ctx.f1.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f4,1724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f26,f4,f26
	ctx.f26.f64 = double(float(ctx.f4.f64 * ctx.f26.f64));
	// fmuls f26,f26,f6
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f6,1408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1408);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f6,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f6,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64));
	// lfs f6,796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// lfs f6,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f26,f25,f6,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 - ctx.f26.f64));
	// lfs f25,1400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1400);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f3,f25,f20,f3
	ctx.f3.f64 = double(float(ctx.f25.f64 * ctx.f20.f64 + ctx.f3.f64));
	// lfs f25,3640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3640);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f2,f23,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f2.f64));
	// lfs f20,2656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2656);
	ctx.f20.f64 = double(temp.f32);
	// lfs f23,2008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2008);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// fmuls f20,f5,f20
	ctx.f20.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// fmadds f6,f24,f6,f26
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f24,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f24.f64 = double(temp.f32);
	// lfs f26,1796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1796);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f26,f26,f24,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f3.f64));
	// lfs f19,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f17.f64 = double(temp.f32);
	// lfs f3,2648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2648);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f21,f17,f19,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f19.f64 + ctx.f21.f64));
	// fmuls f24,f5,f3
	ctx.f24.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,3672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3672);
	ctx.f3.f64 = double(temp.f32);
	// lfs f19,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f3,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f3,2640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2640);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f5,f3
	ctx.f17.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f22,f22,f3,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 + ctx.f6.f64));
	// lfs f6,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f6,f31
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f6,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f16,f3,f6
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,1392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1392);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f5,f3
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f3,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f4,f3
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f4,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfs f3,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f19,f16,f0,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 - ctx.f19.f64));
	// lfs f16,1924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1924);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f22,f22,f3,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f3.f64 - ctx.f2.f64));
	// lfs f3,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,488(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f4,f3,f28
	ctx.f4.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f3,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,2012(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2012, temp.u32);
	// lfs f2,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f26,f26,f5,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f5.f64 + ctx.f22.f64));
	// lfs f22,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f4,f4,f3
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// stfs f4,412(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// lfs f3,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f22,f30
	ctx.f4.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// fmadds f27,f27,f3,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64 + ctx.f18.f64));
	// stfs f4,2268(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2268, temp.u32);
	// fmuls f18,f14,f2
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f2.f64));
	// lfs f2,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f16,f2,f16
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// fnmsubs f26,f25,f12,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// lfs f25,1984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1984);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f1,f27,f5,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f5.f64 + ctx.f1.f64));
	// fmuls f16,f16,f31
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f31.f64));
	// lfs f27,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f27.f64 = double(temp.f32);
	// lfs f22,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f4,f4,f10,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64 + ctx.f22.f64));
	// fnmsubs f22,f27,f0,f19
	ctx.f22.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f19.f64)));
	// lfs f27,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,2008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2008);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f27
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// fmadds f4,f4,f6,f22
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f6.f64 + ctx.f22.f64));
	// fmadds f22,f25,f0,f19
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f19.f64));
	// lfs f25,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f21,f25,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f25.f64 + ctx.f26.f64));
	// fnmsubs f21,f16,f27,f4
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f27.f64 - ctx.f4.f64)));
	// fnmsubs f4,f23,f3,f26
	ctx.f4.f64 = double(float(-(ctx.f23.f64 * ctx.f3.f64 - ctx.f26.f64)));
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f4,f20,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f20.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fmadds f4,f24,f12,f4
	ctx.f4.f64 = double(float(ctx.f24.f64 * ctx.f12.f64 + ctx.f4.f64));
	// fnmsubs f4,f17,f3,f4
	ctx.f4.f64 = double(float(-(ctx.f17.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f3,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f4,f15,f3,f4
	ctx.f4.f64 = double(float(-(ctx.f15.f64 * ctx.f3.f64 - ctx.f4.f64)));
	// lfs f3,3704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3704);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f4,f18,f12,f4
	ctx.f4.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f4.f64)));
	// fadds f4,f1,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 + ctx.f4.f64));
	// stfs f4,4552(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4552, temp.u32);
	// lfs f4,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f22,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// lfs f23,3632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3632);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f1,f3,f4
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f4.f64));
	// fmuls f23,f23,f4
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// lfs f4,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f4,f6
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfs f3,3648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3648);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f26,f2,f3
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// lfs f3,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f3.f64 = double(temp.f32);
	// lfs f25,1948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1948);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f3
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// lfs f24,2240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2240);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f28
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// fmadds f22,f22,f31,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f31.f64 + ctx.f21.f64));
	// lfs f21,2060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2060);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f19,f4,f3
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f26,f3
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f4,3656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3656);
	ctx.f4.f64 = double(temp.f32);
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f18,f4,f3,f1
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f3.f64 - ctx.f1.f64));
	// lfs f4,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fmuls f1,f4,f30
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f30.f64));
	// lfs f4,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f24,f24,f27,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 + ctx.f23.f64));
	// stfs f1,1264(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1264, temp.u32);
	// fmsubs f18,f18,f2,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f2.f64 - ctx.f17.f64));
	// fmsubs f20,f20,f0,f25
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 - ctx.f25.f64));
	// lfs f25,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f4,f1
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// fmuls f1,f25,f31
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// fnmsubs f19,f19,f26,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f18.f64)));
	// fnmsubs f23,f23,f0,f20
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f20.f64)));
	// fmuls f17,f1,f0
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f1,3624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3624);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f24,f1,f3,f24
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f3.f64 + ctx.f24.f64));
	// lfs f3,2680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2680);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f16,f4,f3
	ctx.f16.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,2104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2104);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f15,f4,f3
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f1,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,2312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2312);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f20,f3,f1,f17
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f1.f64 + ctx.f17.f64));
	// lfs f3,2168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2168);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f18,f3,f6
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f3,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// stfs f3,2036(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2036, temp.u32);
	// fmadds f24,f24,f2,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f2.f64 + ctx.f19.f64));
	// lfs f19,1520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1520);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f6
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f6.f64));
	// fmuls f17,f4,f3
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f3.f64));
	// lfs f3,1824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1824);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f14,f3,f28
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// lfs f3,2112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2112);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f23,f20,f3,f23
	ctx.f23.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f23.f64));
	// lfs f20,1812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1812);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f16,f10,f24
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f24.f64));
	// lfs f16,2068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2068);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f20,f2,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fnmsubs f22,f14,f27,f22
	ctx.f22.f64 = double(float(-(ctx.f14.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f27,1884(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1884, temp.u32);
	// fmadds f23,f15,f1,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f15,1836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1836);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f20,f20,f31
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f31.f64));
	// fnmsubs f18,f18,f1,f24
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f24.f64)));
	// fmuls f15,f27,f15
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f15.f64));
	// lfs f27,1976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1976);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f14,f27,f3
	ctx.f14.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// lfs f27,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f27,2044(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2044, temp.u32);
	// fmuls f27,f4,f27
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// stfs f27,412(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fnmsubs f23,f17,f10,f23
	ctx.f23.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f23.f64)));
	// lfs f24,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f22,f20,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fmuls f27,f24,f30
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f30.f64));
	// stfs f27,812(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 812, temp.u32);
	// fnmsubs f21,f21,f10,f18
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f10.f64 - ctx.f18.f64)));
	// lfs f18,2720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2720);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,2688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2688);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f23,f19,f0,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f23.f64)));
	// fnmsubs f22,f14,f0,f22
	ctx.f22.f64 = double(float(-(ctx.f14.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// fmuls f20,f27,f6
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f27,f28
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// stfs f24,1956(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1956, temp.u32);
	// fmadds f21,f16,f10,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f21.f64));
	// lfs f16,2248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2248);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// stfs f27,1912(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1912, temp.u32);
	// fmadds f23,f15,f10,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f23.f64));
	// lfs f15,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f24,f24,f3
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f3.f64));
	// fnmsubs f23,f20,f10,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f23.f64)));
	// fmadds f23,f24,f26,f23
	ctx.f23.f64 = double(float(ctx.f24.f64 * ctx.f26.f64 + ctx.f23.f64));
	// lfs f24,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f31,f24
	ctx.f24.f64 = double(float(ctx.f31.f64 * ctx.f24.f64));
	// stfs f24,480(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// lfs f19,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f21,f19,f0,f21
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fadds f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f21.f64));
	// lfs f21,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f21,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f24.f64));
	// fmuls f21,f27,f6
	ctx.f21.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f4,f27
	ctx.f20.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f27,1512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1512);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f27,f6
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fmuls f27,f25,f30
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// stfs f27,1920(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1920, temp.u32);
	// fmuls f25,f4,f27
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f27.f64));
	// lfs f27,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// stfs f27,1020(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1020, temp.u32);
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f6,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f24,f6
	ctx.f6.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// lfs f24,3712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3712);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// lfs f2,2832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2832);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f18,f2
	ctx.f2.f64 = double(float(ctx.f18.f64 + ctx.f2.f64));
	// lfs f18,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// lfs f17,1952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1952);
	ctx.f17.f64 = double(temp.f32);
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// lfs f16,2120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2120);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f6,1332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f15,f4,f6
	ctx.f15.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f4,980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 980);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f6,f31,f31
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmsubs f1,f21,f26,f1
	ctx.f1.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 - ctx.f1.f64));
	// lfs f26,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f14,f4,f6
	ctx.f14.f64 = double(float(ctx.f4.f64 * ctx.f6.f64));
	// lfs f6,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f4,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f2,f2,f4,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f4.f64 + ctx.f18.f64));
	// stfs f6,2052(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 2052, temp.u32);
	// fmuls f18,f6,f3
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f6,1732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f17,f17,f6,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 + ctx.f16.f64));
	// fmuls f6,f30,f30
	ctx.f6.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// fmuls f26,f26,f6
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f6,1416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1416);
	ctx.f6.f64 = double(temp.f32);
	// fadds f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// lfs f6,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f16,f14,f6
	ctx.f16.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// lfs f14,2712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2712);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f2,f14,f7,f2
	ctx.f2.f64 = double(float(ctx.f14.f64 * ctx.f7.f64 + ctx.f2.f64));
	// fmuls f6,f17,f6
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// lfs f14,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f1,f20,f0,f1
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f1.f64));
	// lfs f20,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// lfs f20,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f21,f21,f20,f16
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f20.f64 + ctx.f16.f64));
	// lfs f17,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// lfs f20,3680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3680);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f20.f64));
	// lfs f17,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fadds f23,f22,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 + ctx.f23.f64));
	// fmadds f2,f2,f11,f6
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f6,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f6,1224(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1224, temp.u32);
	// fnmsubs f1,f19,f0,f1
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// fmuls f19,f6,f3
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f6,1992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1992);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f1,f25,f10,f1
	ctx.f1.f64 = double(float(-(ctx.f25.f64 * ctx.f10.f64 - ctx.f1.f64)));
	// fmuls f16,f3,f6
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f6,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,2776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2776);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f3,f3,f6,f21
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f6.f64 + ctx.f21.f64));
	// lfs f6,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f6,f11
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f2,f26,f6,f2
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 + ctx.f2.f64));
	// lfs f6,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f26,2728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2728);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f26,f11
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f3,f3,f11
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fmsubs f25,f17,f26,f2
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 - ctx.f2.f64));
	// lfs f26,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f6,f6,f11
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f2,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f1,f27,f26,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 * ctx.f26.f64 + ctx.f1.f64));
	// lfs f17,2704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2704);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f27,f21,f2,f3
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f2.f64 - ctx.f3.f64));
	// lfs f3,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f21,f16,f3,f25
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f25.f64));
	// lfs f25,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// lfs f16,1804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1804);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f1,f24,f25,f1
	ctx.f1.f64 = double(float(-(ctx.f24.f64 * ctx.f25.f64 - ctx.f1.f64)));
	// fadds f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 + ctx.f17.f64));
	// lfs f16,2816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2816);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f21,f22,f4,f21
	ctx.f21.f64 = double(float(-(ctx.f22.f64 * ctx.f4.f64 - ctx.f21.f64)));
	// lfs f22,744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 744);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f24,f6,f0,f27
	ctx.f24.f64 = double(float(-(ctx.f6.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// lfs f27,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f6,f15,f0,f1
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f1,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f1.f64 = double(temp.f32);
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f6,f18,f0,f6
	ctx.f6.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f6.f64));
	// lfs f18,2840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2840);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fnmsubs f6,f14,f27,f6
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f27.f64 - ctx.f6.f64)));
	// fmadds f6,f20,f25,f6
	ctx.f6.f64 = double(float(ctx.f20.f64 * ctx.f25.f64 + ctx.f6.f64));
	// lfs f20,1448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1448);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f6,f19,f26,f6
	ctx.f6.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f6.f64)));
	// lfs f19,2848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2848);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fadds f6,f23,f6
	ctx.f6.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// stfs f6,4556(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4556, temp.u32);
	// lfs f6,2016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2016);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f6,1432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1432);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f11
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f6,f31,f28
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// stfs f6,224(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f6,f31,f31
	ctx.f6.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmuls f20,f20,f6
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// fnmsubs f24,f19,f7,f24
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// lfs f19,2744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2744);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f23,f23,f2,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f1.f64));
	// lfs f14,2768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2768);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// lfs f1,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f15,2824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2824);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 + ctx.f15.f64));
	// fmuls f20,f20,f3
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmuls f14,f1,f6
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f6,2752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2752);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f23,f22,f27,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f22,f19,f4,f24
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f24.f64)));
	// fmuls f24,f28,f28
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f28.f64));
	// stfs f24,924(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 924, temp.u32);
	// fmadds f17,f17,f7,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f16.f64));
	// fmadds f20,f15,f7,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f7.f64 + ctx.f20.f64));
	// fmuls f16,f6,f11
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f14,f6
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// fmuls f24,f1,f24
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// lfs f1,2784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2784);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f1,f11
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// lfs f1,2792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2792);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f20,f1,f4,f20
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f4.f64 + ctx.f20.f64));
	// lfs f1,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f23,f18,f1,f23
	ctx.f23.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f23.f64)));
	// lfs f18,2760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2760);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f16,f16,f7
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f7.f64));
	// fmuls f18,f18,f7
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64));
	// fmadds f22,f19,f7,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f22.f64));
	// lfs f19,2000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2000);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// lfs f6,1992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1992);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f19,f6,f19
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmadds f23,f17,f11,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f11.f64 + ctx.f23.f64));
	// lfs f17,2736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2736);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f20,f20,f11,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64 - ctx.f16.f64));
	// lfs f16,2808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2808);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f1,f16,f1,f18
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f18.f64));
	// lfs f16,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f18,2800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2800);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fnmsubs f24,f24,f16,f22
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f16.f64 - ctx.f22.f64)));
	// lfs f22,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f16,f22,f6
	ctx.f16.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// lfs f22,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f6,f6,f22
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f22,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f23,f15,f22,f23
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f22.f64 - ctx.f23.f64)));
	// lfs f22,1440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1440);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f1,f1,f11,f20
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f20.f64));
	// fmuls f20,f22,f11
	ctx.f20.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// lfs f22,1260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1260);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f17,f17,f7,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f15,f22,f24
	ctx.f15.f64 = double(float(ctx.f22.f64 * ctx.f24.f64));
	// lfs f22,1424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1424);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f2,f22,f2
	ctx.f2.f64 = double(float(ctx.f22.f64 * ctx.f2.f64));
	// lfs f22,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f23,f19,f22,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f22.f64 - ctx.f23.f64)));
	// lfs f19,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f19.f64 = double(temp.f32);
	// lfs f22,1908(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1908);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f1,f16,f4,f1
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f4.f64 + ctx.f1.f64));
	// fmuls f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// stfs f22,488(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fadds f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f17.f64));
	// fmadds f2,f15,f27,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f27.f64 + ctx.f2.f64));
	// fmadds f23,f18,f4,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 * ctx.f4.f64 + ctx.f23.f64));
	// fnmsubs f1,f20,f19,f1
	ctx.f1.f64 = double(float(-(ctx.f20.f64 * ctx.f19.f64 - ctx.f1.f64)));
	// fnmsubs f6,f6,f3,f23
	ctx.f6.f64 = double(float(-(ctx.f6.f64 * ctx.f3.f64 - ctx.f23.f64)));
	// fmadds f2,f2,f11,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f1.f64));
	// lfs f1,1972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1972);
	ctx.f1.f64 = double(temp.f32);
	// fadds f6,f21,f6
	ctx.f6.f64 = double(float(ctx.f21.f64 + ctx.f6.f64));
	// fadds f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// stfs f6,4560(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4560, temp.u32);
	// lfs f6,1456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1456);
	ctx.f6.f64 = double(temp.f32);
	// lfs f2,1828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1828);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f21,f6,f2
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// lfs f2,1848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1848);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f1,f2
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 768);
	ctx.f2.f64 = double(temp.f32);
	// lfs f23,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f2,f23
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f16,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f16,f1,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f23,2856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2856);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f18,f2,f23
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f23,2004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2004);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f6,f23
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// lfs f23,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f16,2376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2376);
	ctx.f16.f64 = double(temp.f32);
	// lfs f15,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f2,f15
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f15.f64));
	// fmuls f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f26,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f19,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f19,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f26,f19,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f26.f64));
	// stfs f26,1156(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1156, temp.u32);
	// lfs f26,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f19,f2,f26
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// lfs f26,1820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1820);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f16
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// fmsubs f21,f21,f0,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 - ctx.f20.f64));
	// lfs f20,1980(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1980);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// fmsubs f25,f18,f0,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 - ctx.f25.f64));
	// lfs f18,2128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2128);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f18,f27,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f22.f64));
	// lfs f27,2256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2256);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f27,f26
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f27,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// stfs f27,600(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// fmadds f21,f17,f0,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lfs f17,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f25,f24,f17,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f17.f64 - ctx.f25.f64)));
	// lfs f24,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f17,f6,f24
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// lfs f24,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f14,f24,f23
	ctx.f14.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f23,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f27,f27,f1
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f1.f64));
	// lfs f24,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// stfs f24,412(r1)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fnmsubs f23,f19,f23,f21
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f23.f64 - ctx.f21.f64)));
	// lfs f19,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f26,f26,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64));
	// lfs f19,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f25,f22,f6,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f6.f64 + ctx.f25.f64));
	// lfs f21,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f19,f19,f1
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f22,2864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2864);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// lfs f21,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f2,f21
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f21.f64));
	// fmadds f23,f16,f0,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f0.f64 + ctx.f23.f64));
	// lfs f16,1820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1820);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f20,f10,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f25.f64)));
	// lfs f20,1740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1740);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// lfs f16,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f1,f16,f1,f26
	ctx.f1.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fnmsubs f26,f18,f10,f23
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f23.f64)));
	// lfs f23,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f27,f27,f0,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f25.f64));
	// lfs f25,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f25.f64 = double(temp.f32);
	// fadds f18,f23,f25
	ctx.f18.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// lfs f25,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f25.f64 = double(temp.f32);
	// lfs f23,1464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1464);
	ctx.f23.f64 = double(temp.f32);
	// fadds f16,f23,f25
	ctx.f16.f64 = double(float(ctx.f23.f64 + ctx.f25.f64));
	// lfs f25,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f25.f64 = double(temp.f32);
	// fmr f24,f25
	ctx.f24.f64 = ctx.f25.f64;
	// lfs f25,1068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1068);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f27,f17,f10,f27
	ctx.f27.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f27.f64)));
	// fmsubs f22,f16,f25,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f25.f64 - ctx.f22.f64));
	// fnmsubs f26,f15,f24,f26
	ctx.f26.f64 = double(float(-(ctx.f15.f64 * ctx.f24.f64 - ctx.f26.f64)));
	// lfs f17,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f26,f14,f17,f26
	ctx.f26.f64 = double(float(-(ctx.f14.f64 * ctx.f17.f64 - ctx.f26.f64)));
	// lfs f17,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f27,f17,f10,f27
	ctx.f27.f64 = double(float(-(ctx.f17.f64 * ctx.f10.f64 - ctx.f27.f64)));
	// lfs f17,2872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2872);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f17,f17,f29,f22
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f22.f64)));
	// lfs f22,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f26,f21,f24,f26
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f24.f64 - ctx.f26.f64)));
	// fmadds f21,f19,f22,f27
	ctx.f21.f64 = double(float(ctx.f19.f64 * ctx.f22.f64 + ctx.f27.f64));
	// lfs f22,1300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1300);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,2880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2880);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f19,f27,f22,f17
	ctx.f19.f64 = double(float(-(ctx.f27.f64 * ctx.f22.f64 - ctx.f17.f64)));
	// lfs f27,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f1,f1,f27,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 + ctx.f26.f64));
	// fmadds f26,f20,f0,f21
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lfs f21,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f20,f18,f21,f19
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 + ctx.f19.f64));
	// fadds f1,f1,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// stfs f1,4564(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4564, temp.u32);
	// lfs f1,2904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2904);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f1,f29
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// lfs f1,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// lfs f26,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f26.f64 = double(temp.f32);
	// stfs f1,172(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f18,f26,f1
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// lfs f1,772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f17,f1,f25
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f25,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f19,f25,f21,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f21.f64 - ctx.f19.f64));
	// lfs f25,1988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1988);
	ctx.f25.f64 = double(temp.f32);
	// lfs f21,752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 752);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f21,f25
	ctx.f16.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// lfs f21,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f28,f21
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// stfs f21,232(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// fmuls f15,f26,f21
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f21.f64));
	// lfs f21,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f19,f18,f21,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f21.f64 + ctx.f19.f64));
	// lfs f26,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f21,f30,f30
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f30.f64));
	// lfs f18,1320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1320);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f20,f17,f26,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f20.f64));
	// lfs f17,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f26,f1,f26,f23
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64 + ctx.f23.f64));
	// stfs f21,1732(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1732, temp.u32);
	// fmuls f1,f31,f31
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// lfs f23,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f21,f21,f17,f18
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f17.f64 - ctx.f18.f64)));
	// lfs f17,2952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2952);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,1752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1752);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// fmuls f17,f16,f28
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// fmuls f16,f1,f23
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// lfs f23,2920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2920);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f22,f23,f22,f19
	ctx.f22.f64 = double(float(-(ctx.f23.f64 * ctx.f22.f64 - ctx.f19.f64)));
	// lfs f23,1004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1004);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f20,f15,f23,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f23.f64 + ctx.f20.f64));
	// lfs f23,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f28
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// lfs f19,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f14,f6,f1
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// stfs f23,1740(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1740, temp.u32);
	// fmuls f19,f17,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f19.f64));
	// fmuls f17,f16,f28
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfs f16,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f21,f21,f23,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f23.f64 + ctx.f18.f64));
	// lfs f18,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f26,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// lfs f26,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f22,f26,f16,f22
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f16.f64 + ctx.f22.f64));
	// lfs f26,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f24
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f24.f64));
	// lfs f26,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f14,f26
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f26.f64));
	// lfs f26,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f26.f64 = double(temp.f32);
	// lfs f14,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f14,f26,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f20.f64));
	// fmsubs f21,f21,f25,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f25.f64 - ctx.f19.f64));
	// lfs f19,1244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1244);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// lfs f14,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f17,f17,f27,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f27.f64 + ctx.f16.f64));
	// fmadds f22,f14,f26,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f22.f64));
	// lfs f26,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f15,f0
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f0.f64));
	// lfs f15,2888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2888);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f20,f15,f26,f20
	ctx.f20.f64 = double(float(-(ctx.f15.f64 * ctx.f26.f64 - ctx.f20.f64)));
	// lfs f15,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f21,f19,f15,f21
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f15.f64 - ctx.f21.f64)));
	// lfs f19,2936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2936);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f22,f19,f26,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f19,1748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1748);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f25
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f25,1996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1996);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f17,f17,f2,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 - ctx.f16.f64));
	// lfs f16,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f25,f16
	ctx.f16.f64 = double(float(ctx.f25.f64 * ctx.f16.f64));
	// lfs f25,2896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2896);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f26,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f26.f64 - ctx.f20.f64)));
	// stfs f25,4568(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4568, temp.u32);
	// fmuls f25,f2,f23
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f23,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f23.f64 = double(temp.f32);
	// lfs f20,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f22,f18,f23,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f23.f64 + ctx.f22.f64));
	// lfs f23,1720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1720);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f21,f19,f20,f21
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f20.f64 - ctx.f21.f64)));
	// lfs f19,2968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2968);
	ctx.f19.f64 = double(temp.f32);
	// stfs f21,4572(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4572, temp.u32);
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f21,996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// stfs f21,1748(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1748, temp.u32);
	// lfs f20,1820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1820);
	ctx.f20.f64 = double(temp.f32);
	// lfs f21,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f20,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f21.f64));
	// stfs f23,1320(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1320, temp.u32);
	// fmadds f20,f16,f27,f17
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f27.f64 + ctx.f17.f64));
	// fnmsubs f22,f19,f26,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f19,2976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2976);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f21,f21,f27,f20
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f27.f64 - ctx.f20.f64)));
	// fnmsubs f26,f19,f26,f22
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// stfs f26,4576(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4576, temp.u32);
	// fmuls f26,f2,f1
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// lfs f22,1756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1756);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f6,f22
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f22,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f19,f26,f22
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f22.f64));
	// lfs f26,2004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2004);
	ctx.f26.f64 = double(temp.f32);
	// lfs f22,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f18,f26,f0,f22
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f22.f64));
	// lfs f26,2912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2912);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f26,f3
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// lfs f26,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// lfs f22,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f22.f64 = double(temp.f32);
	// stfs f26,1156(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1156, temp.u32);
	// fmuls f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// fmadds f16,f26,f22,f23
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f22.f64 + ctx.f23.f64));
	// lfs f26,2020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2020);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f26,f23
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f23,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f21,f20,f23,f21
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f23.f64 - ctx.f21.f64)));
	// lfs f23,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f20,f2,f23
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f23.f64));
	// lfs f23,1828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1828);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f14,f26,f23
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f23,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f28
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// stfs f23,1756(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1756, temp.u32);
	// fmuls f27,f19,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// fnmsubs f21,f15,f10,f21
	ctx.f21.f64 = double(float(-(ctx.f15.f64 * ctx.f10.f64 - ctx.f21.f64)));
	// fmadds f23,f23,f22,f17
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64 + ctx.f17.f64));
	// lfs f22,1764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1764);
	ctx.f22.f64 = double(temp.f32);
	// lfs f17,1292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1292);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f6,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// stfs f6,1764(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1764, temp.u32);
	// fmuls f19,f2,f6
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f6,1748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1748);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fadds f23,f23,f6
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f6.f64));
	// lfs f15,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f15.f64 = double(temp.f32);
	// lfs f6,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f21,f14,f0,f21
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f21.f64));
	// fmuls f6,f6,f15
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// lfs f15,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f30,f18,f26,f27
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 - ctx.f27.f64));
	// lfs f26,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f27,3032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3032);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f2,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f18,3008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3008);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// lfs f14,3000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3000);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f2,f14
	ctx.f14.f64 = double(float(ctx.f2.f64 * ctx.f14.f64));
	// fnmsubs f22,f22,f0,f21
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f21.f64)));
	// fmadds f6,f15,f10,f6
	ctx.f6.f64 = double(float(ctx.f15.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f15,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f21,f16,f2,f30
	ctx.f21.f64 = double(float(ctx.f16.f64 * ctx.f2.f64 + ctx.f30.f64));
	// lfs f30,836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f25,f15
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f15.f64));
	// lfs f16,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// fmadds f22,f17,f10,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f22.f64));
	// lfs f17,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f6,f6,f2
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64));
	// stfs f6,996(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 996, temp.u32);
	// fnmsubs f24,f20,f24,f21
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f24.f64 - ctx.f21.f64)));
	// lfs f21,1532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f6,f21,f28
	ctx.f6.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// stfs f6,1724(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1724, temp.u32);
	// fmuls f17,f25,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// fmuls f21,f2,f6
	ctx.f21.f64 = double(float(ctx.f2.f64 * ctx.f6.f64));
	// lfs f6,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// lfs f6,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f30,f6
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// lfs f30,1740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1740);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f6,f26,f10,f22
	ctx.f6.f64 = double(float(-(ctx.f26.f64 * ctx.f10.f64 - ctx.f22.f64)));
	// fmadds f26,f23,f2,f24
	ctx.f26.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f23,996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f24,f23,f30,f6
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f30.f64 + ctx.f6.f64));
	// lfs f30,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f26,f19,f30,f26
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f30.f64 - ctx.f26.f64)));
	// lfs f6,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f6.f64 = double(temp.f32);
	// lfs f19,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f24,f15,f6,f24
	ctx.f24.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f24.f64)));
	// fnmsubs f27,f27,f10,f26
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f10.f64 - ctx.f26.f64)));
	// lfs f26,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f26,f17,f26,f24
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f26.f64 - ctx.f24.f64)));
	// fnmsubs f27,f18,f3,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// fmadds f25,f25,f6,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f6,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f6.f64 = double(temp.f32);
	// fnmsubs f27,f16,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// lfs f26,3152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3152);
	ctx.f26.f64 = double(temp.f32);
	// lfs f16,1732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f27,f14,f10,f27
	ctx.f27.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f27.f64)));
	// fnmsubs f30,f21,f30,f27
	ctx.f30.f64 = double(float(-(ctx.f21.f64 * ctx.f30.f64 - ctx.f27.f64)));
	// fmadds f24,f20,f6,f30
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f30.f64));
	// lfs f6,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f27,f6,f11
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f6.f64 = double(temp.f32);
	// lfs f30,2144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2144);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f6,f30
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f6,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f26,f6
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f26,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f21,f26,f11
	ctx.f21.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f27,f26
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f27,2136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2136);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f27,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// lfs f27,3168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3168);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f27,f11
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// lfs f27,3128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3128);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f22,f27,f7,f22
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f22.f64));
	// lfs f27,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f11,f27
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// lfs f27,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f23,f23,f3,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64 + ctx.f20.f64));
	// lfs f15,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f3,f19,f3
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// lfs f19,3040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3040);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f22,f19,f6,f22
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f6.f64 - ctx.f22.f64)));
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f15,f15,f11
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// lfs f6,3136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3136);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// fmuls f16,f16,f27
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// fmuls f19,f6,f11
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// lfs f6,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f6.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// stfs f25,4580(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4580, temp.u32);
	// lfs f25,3104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3104);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f11
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// fnmsubs f26,f21,f26,f23
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f26.f64 - ctx.f23.f64)));
	// lfs f23,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f27,f23,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// lfs f23,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f3,f22,f11,f3
	ctx.f3.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f3.f64));
	// lfs f22,3120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3120);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// fmuls f21,f20,f6
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f6.f64));
	// lfs f20,3080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3080);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmuls f20,f11,f20
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f20.f64));
	// fmadds f26,f18,f14,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f14.f64 + ctx.f26.f64));
	// lfs f18,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f6,f27,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,1900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1900);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f3,f15,f18,f3
	ctx.f3.f64 = double(float(-(ctx.f15.f64 * ctx.f18.f64 - ctx.f3.f64)));
	// lfs f15,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmuls f18,f18,f15
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f15.f64));
	// lfs f15,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f30,f30,f15
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f15.f64));
	// lfs f15,540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f1,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// lfs f1,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f26,f17,f1,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// lfs f1,3112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3112);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f19,f19,f4,f3
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f3.f64)));
	// lfs f3,3024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3024);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f17,f1,f17
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f17.f64));
	// lfs f1,2996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2996);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f3,f7
	ctx.f14.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// lfs f3,1932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1932);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f1
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f1.f64));
	// stfs f3,660(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// fmadds f27,f27,f0,f18
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 + ctx.f18.f64));
	// lfs f18,1040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1040);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f26,f16,f18,f26
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f18.f64 + ctx.f26.f64));
	// lfs f18,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f18.f64 = double(temp.f32);
	// fmr f3,f18
	ctx.f3.f64 = ctx.f18.f64;
	// fnmsubs f23,f23,f4,f19
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f19.f64)));
	// lfs f19,3160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3160);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f19,f4,f14
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 - ctx.f14.f64));
	// fnmsubs f26,f21,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// fmadds f18,f15,f3,f17
	ctx.f18.f64 = double(float(ctx.f15.f64 * ctx.f3.f64 + ctx.f17.f64));
	// lfs f17,3144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3144);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f24,f22,f7,f23
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f23.f64));
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fmadds f6,f6,f22,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f22.f64 + ctx.f26.f64));
	// fnmsubs f30,f30,f3,f24
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f3.f64 - ctx.f24.f64)));
	// fnmsubs f6,f20,f7,f6
	ctx.f6.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f6.f64)));
	// fmadds f30,f18,f11,f30
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f30.f64));
	// fmadds f6,f27,f11,f6
	ctx.f6.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f6.f64));
	// lfs f16,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// fadds f27,f6,f30
	ctx.f27.f64 = double(float(ctx.f6.f64 + ctx.f30.f64));
	// lfs f6,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f30,f6,f28
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f6,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f6.f64 = double(temp.f32);
	// stfs f30,264(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmadds f23,f19,f11,f16
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f16.f64));
	// fnmsubs f26,f17,f7,f23
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f23.f64)));
	// lfs f24,2320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2320);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f26,f25,f7,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 + ctx.f26.f64));
	// fmuls f1,f24,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64));
	// lfs f23,1944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1944);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,2144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2144);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f30,f6,f30
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// fmuls f24,f23,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f24.f64));
	// lfs f19,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f19.f64 = double(temp.f32);
	// lfs f25,636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 636);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f19,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f25.f64));
	// lfs f18,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,1960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1960);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,1140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1140);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f21,2992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2992);
	ctx.f21.f64 = double(temp.f32);
	// lfs f17,1056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1056);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f1,f1,f3
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f23,3056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3056);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,3016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3016);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f23,f11
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fadds f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 + ctx.f22.f64));
	// lfs f21,3072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3072);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f20,3064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3064);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// lfs f16,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f25,f25,f11
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// stfs f30,1720(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1720, temp.u32);
	// fmadds f1,f24,f17,f1
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f17.f64 + ctx.f1.f64));
	// lfs f17,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f17.f64 = double(temp.f32);
	// lfs f24,3192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3192);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fnmsubs f26,f21,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// fmuls f21,f18,f11
	ctx.f21.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// lfs f18,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fmuls f24,f17,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f24.f64));
	// lfs f17,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f1,f23,f4,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f1.f64)));
	// lfs f23,1836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1836);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f26,f20,f7,f26
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f20,1608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1608);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmadds f24,f23,f17,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f17.f64 + ctx.f24.f64));
	// lfs f23,2984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2984);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f23,f23,f11
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64));
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// fmadds f22,f22,f4,f1
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f1.f64));
	// fmuls f1,f31,f31
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmadds f3,f19,f3,f22
	ctx.f3.f64 = double(float(ctx.f19.f64 * ctx.f3.f64 + ctx.f22.f64));
	// fmuls f1,f11,f1
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fmuls f16,f1,f16
	ctx.f16.f64 = double(float(ctx.f1.f64 * ctx.f16.f64));
	// lfs f1,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f26,f25,f1,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// lfs f1,1600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1600);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f6,f1
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f28
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f25,3176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3176);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f25,f11
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// lfs f25,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// stfs f1,472(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// lfs f25,3096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3096);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f22,f25,f11
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// lfs f25,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f18,f25,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f25.f64 + ctx.f26.f64));
	// lfs f25,3088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3088);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f25,f11
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// lfs f25,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f1,f6,f1
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmuls f18,f1,f25
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f25,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f25.f64 = double(temp.f32);
	// lfs f1,1772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1772);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f25,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f25,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f21,f21,f25,f3
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f25.f64 - ctx.f3.f64)));
	// lfs f25,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f25.f64 = double(temp.f32);
	// lfs f3,1584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1584);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f17,f17,f25,f26
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f25.f64 - ctx.f26.f64)));
	// fmuls f3,f6,f3
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f26,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f26.f64 = double(temp.f32);
	// stfs f3,996(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 996, temp.u32);
	// fmuls f3,f26,f28
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f3,212(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmadds f30,f24,f10,f30
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f30.f64));
	// stfs f1,660(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// fmadds f24,f23,f4,f21
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f21.f64));
	// fmuls f26,f6,f3
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f3,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f3,f28
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f28.f64));
	// stfs f3,1772(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1772, temp.u32);
	// stfs f26,488(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f25,f6,f3
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f3,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f3.f64 = double(temp.f32);
	// fmr f1,f3
	ctx.f1.f64 = ctx.f3.f64;
	// lfs f3,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f21,f20,f3,f30
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f3.f64 - ctx.f30.f64)));
	// lfs f30,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f24,f16,f30,f24
	ctx.f24.f64 = double(float(-(ctx.f16.f64 * ctx.f30.f64 - ctx.f24.f64)));
	// stfs f25,412(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// fmadds f23,f14,f1,f17
	ctx.f23.f64 = double(float(ctx.f14.f64 * ctx.f1.f64 + ctx.f17.f64));
	// lfs f17,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f1,f22,f1,f24
	ctx.f1.f64 = double(float(-(ctx.f22.f64 * ctx.f1.f64 - ctx.f24.f64)));
	// lfs f24,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f27,f23
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f23.f64));
	// fnmsubs f23,f15,f3,f21
	ctx.f23.f64 = double(float(-(ctx.f15.f64 * ctx.f3.f64 - ctx.f21.f64)));
	// fnmsubs f1,f19,f7,f1
	ctx.f1.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f1.f64)));
	// fmadds f30,f18,f30,f23
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f23.f64));
	// lfs f23,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f23.f64 = double(temp.f32);
	// fadds f1,f27,f1
	ctx.f1.f64 = double(float(ctx.f27.f64 + ctx.f1.f64));
	// stfs f1,4584(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4584, temp.u32);
	// lfs f1,1172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1172);
	ctx.f1.f64 = double(temp.f32);
	// lfs f27,996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f24,f23,f24,f30
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f24.f64 - ctx.f30.f64)));
	// lfs f30,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f1,f3
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f3,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f1,f3,f31
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// lfs f3,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f24,f27,f30,f24
	ctx.f24.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f24.f64));
	// lfs f27,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f26,f27
	ctx.f19.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fmuls f22,f1,f3
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// lfs f1,1568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1568);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f6,f1
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,1720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1720);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f1,f27
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f27.f64));
	// lfs f1,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f1,f31
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f1,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f1.f64 = double(temp.f32);
	// stfs f26,1240(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1240, temp.u32);
	// fmuls f18,f26,f1
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// lfs f26,1616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1616);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f23,f26,f30,f23
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f30.f64 - ctx.f23.f64));
	// lfs f26,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64));
	// lfs f26,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f31,f26
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// fmsubs f23,f23,f6,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f6.f64 - ctx.f22.f64));
	// fmuls f17,f17,f26
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f26.f64));
	// lfs f26,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f25,f26
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f26,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// stfs f26,416(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// fmuls f22,f17,f3
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f17,2152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2152);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f28
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f28.f64));
	// fmuls f16,f6,f26
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// lfs f26,3004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3004);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f6,f26
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f26.f64));
	// lfs f26,3184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3184);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f1,f26
	ctx.f14.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f26,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f31
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// fmuls f26,f26,f1
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// fmuls f27,f16,f27
	ctx.f27.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f16,1624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1624);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f30,f21,f30,f23
	ctx.f30.f64 = double(float(-(ctx.f21.f64 * ctx.f30.f64 - ctx.f23.f64)));
	// lfs f21,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f16,f16,f12
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f12.f64));
	// lfs f23,2352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2352);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// lfs f21,3224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3224);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f1,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f21.f64));
	// lfs f1,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f26,f26,f1,f24
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f1.f64 - ctx.f24.f64)));
	// lfs f1,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fmuls f15,f15,f31
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f31.f64));
	// fmadds f24,f17,f1,f16
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 + ctx.f16.f64));
	// lfs f16,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f30,f20,f16,f30
	ctx.f30.f64 = double(float(-(ctx.f20.f64 * ctx.f16.f64 - ctx.f30.f64)));
	// lfs f16,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f22,f14,f10,f22
	ctx.f22.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 - ctx.f22.f64));
	// lfs f20,4280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4280);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// lfs f17,1576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1576);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f14,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f23,f31
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f31.f64));
	// lfs f16,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// lfs f14,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f14,f3
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f3.f64));
	// fmadds f26,f24,f6,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f6.f64 + ctx.f26.f64));
	// lfs f24,1592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1592);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f30,f19,f10,f30
	ctx.f30.f64 = double(float(-(ctx.f19.f64 * ctx.f10.f64 - ctx.f30.f64)));
	// lfs f19,1520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1520);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f21,f0,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f22.f64));
	// lfs f21,2160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2160);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f6,f21
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f21.f64));
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmadds f26,f20,f10,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f26.f64));
	// fmadds f20,f18,f0,f30
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f30.f64));
	// lfs f30,3012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3012);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f18,f6,f30
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f30,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f22,f17,f30,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f22.f64));
	// lfs f17,1560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1560);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// lfs f6,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f21,f21,f31
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f31.f64));
	// fnmsubs f26,f19,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// lfs f19,1840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1840);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f6,f25,f6,f20
	ctx.f6.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f20.f64)));
	// lfs f20,2168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2168);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f25,f18,f31
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f31.f64));
	// fnmsubs f30,f24,f30,f22
	ctx.f30.f64 = double(float(-(ctx.f24.f64 * ctx.f30.f64 - ctx.f22.f64)));
	// lfs f22,3256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3256);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f20,f20,f3
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f3.f64));
	// fmadds f27,f27,f10,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f10.f64 + ctx.f6.f64));
	// lfs f6,372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f30,f21,f0,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f0.f64 + ctx.f30.f64));
	// lfs f21,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f27,f15,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// fnmsubs f25,f25,f6,f30
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f30.f64)));
	// fmadds f6,f23,f0,f27
	ctx.f6.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfs f27,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f6,f16,f10,f6
	ctx.f6.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f6.f64)));
	// fmadds f6,f14,f0,f6
	ctx.f6.f64 = double(float(ctx.f14.f64 * ctx.f0.f64 + ctx.f6.f64));
	// fadds f26,f26,f6
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// lfs f6,3668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3668);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f30,f6,f3
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f6,1180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1180);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f3,f6
	ctx.f24.f64 = double(float(ctx.f3.f64 * ctx.f6.f64));
	// lfs f6,2272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2272);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f27
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f6,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f21,f21,f6
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f6.f64));
	// fmuls f19,f30,f19
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// lfs f30,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f31
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// stfs f30,740(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 740, temp.u32);
	// fmuls f18,f30,f3
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmsubs f24,f24,f0,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 - ctx.f19.f64));
	// lfs f30,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f30.f64 = double(temp.f32);
	// lfs f19,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f19.f64 = double(temp.f32);
	// lfs f16,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f17,f19,f25
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f19.f64 - ctx.f25.f64)));
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f14,1780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1780);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f27,f14,f27
	ctx.f27.f64 = double(float(ctx.f14.f64 * ctx.f27.f64));
	// lfs f14,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f30,f30,f12
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64));
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// stfs f17,1780(r1)
	temp.f32 = float(ctx.f17.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1780, temp.u32);
	// lfs f17,1512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1512);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f3
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f3.f64));
	// lfs f15,1776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1776);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,1896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1896);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// fnmsubs f24,f23,f1,f24
	ctx.f24.f64 = double(float(-(ctx.f23.f64 * ctx.f1.f64 - ctx.f24.f64)));
	// lfs f23,1020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1020);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f3,f23,f3
	ctx.f3.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f14,1768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1768);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,1832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1832);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f19,f19,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// fmadds f25,f16,f10,f25
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f25.f64));
	// lfs f16,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f6
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64));
	// lfs f6,1760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1760);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f6,f6,f28
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// stfs f6,660(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// fmuls f14,f14,f28
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f28.f64));
	// fmuls f23,f23,f28
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// fnmsubs f24,f22,f0,f24
	ctx.f24.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f24.f64)));
	// lfs f22,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f1,f27,f1,f25
	ctx.f1.f64 = double(float(-(ctx.f27.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f25,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f25.f64 = double(temp.f32);
	// lfs f27,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f25,1472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1472);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f22
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f22.f64));
	// lfs f22,1864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1864);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f28
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f28.f64));
	// lfs f28,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f21,f28,f24
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f28.f64 + ctx.f24.f64));
	// lfs f21,408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 408);
	ctx.f21.f64 = double(temp.f32);
	// lfs f24,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f21.f64));
	// lfs f21,1268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1268);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f1,f17,f0,f1
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f17,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f27,f21,f17,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f17.f64 + ctx.f27.f64));
	// lfs f21,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f21.f64 = double(temp.f32);
	// fmr f6,f21
	ctx.f6.f64 = ctx.f21.f64;
	// lfs f21,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f30,f21,f6,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f30.f64));
	// lfs f21,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f21.f64));
	// lfs f21,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f28,f20,f21,f28
	ctx.f28.f64 = double(float(-(ctx.f20.f64 * ctx.f21.f64 - ctx.f28.f64)));
	// lfs f21,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// stfs f21,996(r1)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r1.u32 + 996, temp.u32);
	// lfs f21,784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 784);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f1,f3,f21,f1
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f21.f64 + ctx.f1.f64));
	// lfs f3,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f3.f64 = double(temp.f32);
	// fadds f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f3.f64));
	// lfs f3,3200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3200);
	ctx.f3.f64 = double(temp.f32);
	// lfs f20,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f5,f3
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// lfs f3,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f30,f30,f3
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmuls f25,f25,f20
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f20.f64));
	// fmadds f20,f18,f0,f28
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f28.f64));
	// lfs f28,312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f18,f16,f0,f1
	ctx.f18.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f1.f64)));
	// lfs f1,1780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1780);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f24,f24,f28,f1
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f28.f64 + ctx.f1.f64));
	// lfs f1,2328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2328);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f17,f27,f1,f30
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f30.f64));
	// fnmsubs f27,f15,f6,f20
	ctx.f27.f64 = double(float(-(ctx.f15.f64 * ctx.f6.f64 - ctx.f20.f64)));
	// fadds f26,f26,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 + ctx.f18.f64));
	// lfs f30,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f25,f24,f5,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f5.f64 + ctx.f25.f64));
	// fnmsubs f24,f19,f30,f27
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f30.f64 - ctx.f27.f64)));
	// lfs f27,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f27.f64 = double(temp.f32);
	// lfs f19,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f24,f14,f27,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f27.f64 - ctx.f24.f64)));
	// fnmsubs f27,f23,f27,f24
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f27.f64 - ctx.f24.f64)));
	// lfs f24,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f6,f24,f6,f27
	ctx.f6.f64 = double(float(-(ctx.f24.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// fnmsubs f6,f22,f30,f6
	ctx.f6.f64 = double(float(-(ctx.f22.f64 * ctx.f30.f64 - ctx.f6.f64)));
	// fadds f6,f26,f6
	ctx.f6.f64 = double(float(ctx.f26.f64 + ctx.f6.f64));
	// stfs f6,4588(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4588, temp.u32);
	// lfs f6,396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 396);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f30,f5,f6
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,3368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3368);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f27,f1,f6
	ctx.f27.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// lfs f6,1924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1924);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f24,f6,f5
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f5.f64));
	// lfs f6,592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 592);
	ctx.f6.f64 = double(temp.f32);
	// lfs f26,3996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3996);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f26,f6
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// lfs f26,608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 608);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f22,f5,f26
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f26.f64));
	// lfs f26,996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// fmuls f30,f30,f19
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// fmuls f19,f27,f6
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f27,268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f18,f27,f6
	ctx.f18.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// lfs f27,964(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 964);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f23,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f27.f64));
	// lfs f27,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f25,f21,f27,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f27.f64 - ctx.f25.f64)));
	// lfs f21,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f21.f64 = double(temp.f32);
	// lfs f27,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// fmuls f27,f27,f6
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f6.f64));
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// lfs f30,3352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3352);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f5,f30
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f30,3280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3280);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f5,f30
	ctx.f15.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f30,3296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3296);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f5,f30
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f30,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fnmsubs f25,f22,f30,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f30.f64 - ctx.f25.f64)));
	// lfs f22,3344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3344);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fmuls f22,f5,f22
	ctx.f22.f64 = double(float(ctx.f5.f64 * ctx.f22.f64));
	// fmadds f30,f19,f30,f21
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// lfs f19,3288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3288);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fnmsubs f25,f16,f12,f25
	ctx.f25.f64 = double(float(-(ctx.f16.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// lfs f16,548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 548);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f26,f26,f16
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f16.f64));
	// fnmsubs f28,f24,f28,f30
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f28.f64 - ctx.f30.f64)));
	// lfs f30,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f21,f30
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// lfs f30,400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 400);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f30,f6
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// lfs f30,3320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3320);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f16,f5,f30
	ctx.f16.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f30,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f25,f14,f30,f25
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f30.f64 - ctx.f25.f64)));
	// lfs f14,1124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1124);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f1,f1,f14
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f14.f64));
	// lfs f14,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f28,f23,f14,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f14.f64 + ctx.f28.f64));
	// lfs f23,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f5,f23
	ctx.f23.f64 = double(float(ctx.f5.f64 * ctx.f23.f64));
	// fmuls f3,f21,f3
	ctx.f3.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// lfs f21,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f5,f21
	ctx.f21.f64 = double(float(ctx.f5.f64 * ctx.f21.f64));
	// fmuls f14,f5,f14
	ctx.f14.f64 = double(float(ctx.f5.f64 * ctx.f14.f64));
	// fmadds f25,f19,f12,f25
	ctx.f25.f64 = double(float(ctx.f19.f64 * ctx.f12.f64 + ctx.f25.f64));
	// fmuls f19,f1,f6
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmadds f1,f20,f30,f28
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f30.f64 + ctx.f28.f64));
	// lfs f30,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f5,f30
	ctx.f28.f64 = double(float(ctx.f5.f64 * ctx.f30.f64));
	// lfs f30,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f30.f64 = double(temp.f32);
	// lfs f20,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f30,f20
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// lfs f30,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f27,f27,f12,f25
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// fnmsubs f1,f18,f30,f1
	ctx.f1.f64 = double(float(-(ctx.f18.f64 * ctx.f30.f64 - ctx.f1.f64)));
	// lfs f18,3052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3052);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f25,f20,f5
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f5.f64));
	// lfs f20,3044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3044);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f6,f17,f6,f27
	ctx.f6.f64 = double(float(ctx.f17.f64 * ctx.f6.f64 + ctx.f27.f64));
	// lfs f27,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f27.f64 = double(temp.f32);
	// lfs f17,1656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1656);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f1,f15,f12,f1
	ctx.f1.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f1.f64));
	// lfs f15,1640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1640);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f6,f3,f27,f6
	ctx.f6.f64 = double(float(-(ctx.f3.f64 * ctx.f27.f64 - ctx.f6.f64)));
	// lfs f3,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f3.f64 = double(temp.f32);
	// fnmsubs f27,f22,f12,f1
	ctx.f27.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f1.f64)));
	// lfs f1,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f22,f19,f1,f6
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f1.f64 + ctx.f6.f64));
	// lfs f6,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f6.f64 = double(temp.f32);
	// lfs f19,3684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3684);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f27,f24,f3,f27
	ctx.f27.f64 = double(float(ctx.f24.f64 * ctx.f3.f64 + ctx.f27.f64));
	// fmadds f24,f14,f6,f22
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f6.f64 + ctx.f22.f64));
	// lfs f22,4160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4160);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f6
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f6.f64));
	// lfs f14,3060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3060);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f3,f26,f3,f27
	ctx.f3.f64 = double(float(-(ctx.f26.f64 * ctx.f3.f64 - ctx.f27.f64)));
	// lfs f27,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,3036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3036);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f30,f17,f30,f22
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f22.f64));
	// lfs f17,1648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1648);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f3,f16,f27,f3
	ctx.f3.f64 = double(float(ctx.f16.f64 * ctx.f27.f64 + ctx.f3.f64));
	// lfs f27,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f27.f64 = double(temp.f32);
	// lfs f16,1688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1688);
	ctx.f16.f64 = double(temp.f32);
	// fadds f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 + ctx.f16.f64));
	// lfs f15,1680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1680);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f12
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f12.f64));
	// fnmsubs f3,f23,f12,f3
	ctx.f3.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f3.f64)));
	// lfs f23,1672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1672);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f3,f21,f27,f3
	ctx.f3.f64 = double(float(-(ctx.f21.f64 * ctx.f27.f64 - ctx.f3.f64)));
	// lfs f27,3676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3676);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f28,f28,f6,f3
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f6.f64 + ctx.f3.f64));
	// lfs f3,3028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3028);
	ctx.f3.f64 = double(temp.f32);
	// fadds f27,f3,f27
	ctx.f27.f64 = double(float(ctx.f3.f64 + ctx.f27.f64));
	// lfs f3,1940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1940);
	ctx.f3.f64 = double(temp.f32);
	// lfs f6,1552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1552);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f26,f26,f3
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f3.f64));
	// fmuls f21,f6,f3
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// lfs f6,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmuls f17,f6,f17
	ctx.f17.f64 = double(float(ctx.f6.f64 * ctx.f17.f64));
	// fmuls f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fmuls f23,f23,f3
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fmuls f22,f21,f12
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// lfs f21,4004(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4004);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmuls f27,f27,f12
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f12.f64));
	// fmsubs f30,f30,f6,f22
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f6.f64 - ctx.f22.f64));
	// lfs f22,1348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1348);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// lfs f6,1328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1328);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f27,f26,f1,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 - ctx.f27.f64));
	// lfs f1,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f1.f64 = double(temp.f32);
	// lfs f26,1844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1844);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f6,f1,f6
	ctx.f6.f64 = double(float(ctx.f1.f64 * ctx.f6.f64));
	// fmuls f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f1,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f1.f64 = double(temp.f32);
	// stfs f6,324(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmr f6,f1
	ctx.f6.f64 = ctx.f1.f64;
	// lfs f1,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f28,f25,f1,f28
	ctx.f28.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f28.f64)));
	// fmadds f16,f16,f6,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f6.f64 + ctx.f15.f64));
	// fnmsubs f30,f18,f6,f30
	ctx.f30.f64 = double(float(-(ctx.f18.f64 * ctx.f6.f64 - ctx.f30.f64)));
	// fnmsubs f27,f23,f6,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// lfs f6,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f25,f5,f6
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f6.f64));
	// lfs f6,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f6.f64 = double(temp.f32);
	// lfs f1,3692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3692);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f26,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f0.f64));
	// fmuls f23,f6,f1
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,3068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3068);
	ctx.f1.f64 = double(temp.f32);
	// lfs f18,4224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4224);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f1,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 + ctx.f18.f64));
	// lfs f1,1664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1664);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f6,f1
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f17,f17,f1,f30
	ctx.f17.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f30.f64)));
	// lfs f6,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f6.f64 = double(temp.f32);
	// lfs f30,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f27,f20,f6,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f6.f64 + ctx.f27.f64));
	// lfs f20,1912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1912);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f28,f25,f6,f28
	ctx.f28.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f28.f64)));
	// lfs f25,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f26,f30,f0,f26
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 - ctx.f26.f64));
	// lfs f30,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f20,f30,f20
	ctx.f20.f64 = double(float(ctx.f30.f64 * ctx.f20.f64));
	// fmuls f25,f5,f25
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// fmuls f18,f18,f3
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f3.f64));
	// fmadds f17,f16,f3,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f3.f64 + ctx.f17.f64));
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f19,f16,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f16.f64 + ctx.f27.f64));
	// lfs f16,824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 824);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,1632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1632);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f3
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f3.f64));
	// fmadds f26,f20,f0,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f26.f64));
	// lfs f20,1892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1892);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f16.f64));
	// lfs f16,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f25,f16,f28
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f16.f64 - ctx.f28.f64)));
	// lfs f28,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f30,f28
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f28,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f23,f23,f6,f17
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f17.f64)));
	// fnmsubs f27,f21,f28,f27
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f28.f64 - ctx.f27.f64)));
	// lfs f28,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f28.f64 = double(temp.f32);
	// lfs f21,1956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1956);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f28,f21
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// fnmsubs f26,f20,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// lfs f20,1356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1356);
	ctx.f20.f64 = double(temp.f32);
	// fadds f25,f24,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 + ctx.f25.f64));
	// stfs f25,4592(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4592, temp.u32);
	// lfs f24,1496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1496);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f25,f18,f12,f23
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f12.f64 + ctx.f23.f64));
	// lfs f23,1480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1480);
	ctx.f23.f64 = double(temp.f32);
	// lfs f18,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f6,f14,f6,f27
	ctx.f6.f64 = double(float(-(ctx.f14.f64 * ctx.f6.f64 - ctx.f27.f64)));
	// fnmsubs f27,f16,f0,f26
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// fmadds f6,f22,f1,f6
	ctx.f6.f64 = double(float(ctx.f22.f64 * ctx.f1.f64 + ctx.f6.f64));
	// lfs f22,1704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1704);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f6,f15,f1,f6
	ctx.f6.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f6.f64)));
	// lfs f1,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f6,f19,f1,f6
	ctx.f6.f64 = double(float(-(ctx.f19.f64 * ctx.f1.f64 - ctx.f6.f64)));
	// lfs f1,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f1.f64 = double(temp.f32);
	// lfs f19,3084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3084);
	ctx.f19.f64 = double(temp.f32);
	// fadds f6,f25,f6
	ctx.f6.f64 = double(float(ctx.f25.f64 + ctx.f6.f64));
	// stfs f6,4596(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4596, temp.u32);
	// lfs f6,3076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3076);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f26,f6,f1
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f6,972(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 972);
	ctx.f6.f64 = double(temp.f32);
	// lfs f25,1488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1488);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// fmuls f25,f6,f25
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f19,f6,f19
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmsubs f26,f20,f1,f26
	ctx.f26.f64 = double(float(ctx.f20.f64 * ctx.f1.f64 - ctx.f26.f64));
	// lfs f20,1224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1224);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f28,f28,f20
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f20.f64));
	// lfs f20,3700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3700);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f25,f25,f1
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmsubs f25,f26,f6,f25
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 - ctx.f25.f64));
	// lfs f26,4012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4012);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f26,f18,f28
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64 + ctx.f28.f64));
	// fnmsubs f21,f21,f0,f27
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// lfs f28,1248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1248);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f25,f24,f1,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f26,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f26,f28
	ctx.f17.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// lfs f24,1936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1936);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmadds f26,f26,f24,f18
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f24.f64 + ctx.f18.f64));
	// lfs f28,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f30,f28
	ctx.f16.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// lfs f28,3092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3092);
	ctx.f28.f64 = double(temp.f32);
	// lfs f24,1948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1948);
	ctx.f24.f64 = double(temp.f32);
	// lfs f14,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f24,f24,f28
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// stfs f27,660(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// lfs f18,1524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1524);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,1660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmadds f25,f23,f1,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f25.f64));
	// lfs f23,1696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1696);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f15,f6,f15
	ctx.f15.f64 = double(float(ctx.f6.f64 * ctx.f15.f64));
	// fmuls f27,f27,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// fmadds f28,f14,f28,f26
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f28.f64 + ctx.f26.f64));
	// lfs f26,2012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2012);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f30,f30,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// lfs f26,3708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3708);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f14,3100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3100);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// fmuls f14,f6,f14
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f14.f64));
	// fnmsubs f25,f22,f1,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f22,2280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2280);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f28,f28,f0,f21
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f0.f64 + ctx.f21.f64));
	// lfs f21,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// lfs f21,4168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4168);
	ctx.f21.f64 = double(temp.f32);
	// fmsubs f26,f21,f7,f26
	ctx.f26.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 - ctx.f26.f64));
	// lfs f21,3108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3108);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f13,f21
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmadds f25,f20,f1,f25
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f1.f64 + ctx.f25.f64));
	// lfs f20,3132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3132);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fnmsubs f28,f27,f0,f28
	ctx.f28.f64 = double(float(-(ctx.f27.f64 * ctx.f0.f64 - ctx.f28.f64)));
	// lfs f27,3716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3716);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f7,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64 + ctx.f26.f64));
	// fnmsubs f26,f19,f1,f25
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f1.f64 - ctx.f25.f64)));
	// lfs f25,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f21,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// lfs f21,3116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3116);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f28,f18,f1,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f1.f64 + ctx.f28.f64));
	// lfs f18,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f27,f21,f4,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f21,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f17,f0,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f26.f64));
	// fnmsubs f28,f23,f1,f28
	ctx.f28.f64 = double(float(-(ctx.f23.f64 * ctx.f1.f64 - ctx.f28.f64)));
	// lfs f23,3124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3124);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f26,f16,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// fmadds f28,f14,f1,f28
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f1.f64 + ctx.f28.f64));
	// fnmsubs f26,f24,f0,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f26.f64)));
	// fmadds f26,f15,f1,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f26.f64));
	// fmadds f30,f30,f0,f26
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f26.f64));
	// fnmsubs f30,f22,f0,f30
	ctx.f30.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f30.f64)));
	// lfs f22,3724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3724);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 + ctx.f30.f64));
	// stfs f30,4600(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4600, temp.u32);
	// lfs f30,4020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4020);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f26,f30,f13
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfs f30,856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 856);
	ctx.f30.f64 = double(temp.f32);
	// lfs f28,1856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1856);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f28,f30
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f30,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// fmuls f22,f22,f30
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f30.f64));
	// lfs f30,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fmuls f30,f19,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// lfs f19,4256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4256);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f13
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// fmuls f26,f26,f7
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f7.f64));
	// lfs f17,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f17.f64 = double(temp.f32);
	// fmsubs f27,f27,f13,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f25.f64));
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// lfs f17,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f21,f21,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f17.f64));
	// lfs f17,2000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2000);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f28,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f26,f24,f28,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f28.f64 + ctx.f26.f64));
	// lfs f28,3140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3140);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f13,f28
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f28,3732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3732);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f13
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,3148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3148);
	ctx.f28.f64 = double(temp.f32);
	// lfs f15,4028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4028);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f28,f15
	ctx.f15.f64 = double(float(ctx.f28.f64 + ctx.f15.f64));
	// lfs f28,3156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3156);
	ctx.f28.f64 = double(temp.f32);
	// lfs f14,3740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3740);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 + ctx.f14.f64));
	// lfs f28,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f28.f64 = double(temp.f32);
	// lfs f25,4176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4176);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f21,f30,f28,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f28.f64 - ctx.f21.f64));
	// lfs f28,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,3164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3164);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f13,f25
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fnmsubs f26,f23,f28,f26
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f28.f64 - ctx.f26.f64)));
	// lfs f23,3172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3172);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f30,f13,f30
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// stfs f30,324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fadds f23,f15,f23
	ctx.f23.f64 = double(float(ctx.f15.f64 + ctx.f23.f64));
	// fmuls f15,f14,f7
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f7.f64));
	// lfs f14,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f14.f64 = double(temp.f32);
	// fmr f30,f14
	ctx.f30.f64 = ctx.f14.f64;
	// fnmsubs f27,f25,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f25.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// fmadds f28,f22,f28,f26
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f26.f64));
	// lfs f26,3180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3180);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f13,f26
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f26.f64));
	// lfs f22,4036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4036);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f13,f22
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// fmadds f25,f23,f4,f15
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f15.f64));
	// lfs f23,1540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1540);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f21,f18,f30,f21
	ctx.f21.f64 = double(float(-(ctx.f18.f64 * ctx.f30.f64 - ctx.f21.f64)));
	// lfs f15,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f15.f64 = double(temp.f32);
	// lfs f18,3748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3748);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f13,f18
	ctx.f18.f64 = double(float(ctx.f13.f64 * ctx.f18.f64));
	// fnmsubs f27,f26,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// lfs f26,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f26.f64 = double(temp.f32);
	// fsubs f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 - ctx.f23.f64));
	// fnmsubs f21,f20,f7,f28
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// lfs f28,3188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3188);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f28,f13
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f28,f26
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f28,2100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2100);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f31,f28
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f28.f64));
	// fmadds f28,f28,f15,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f15.f64 + ctx.f25.f64));
	// lfs f25,3756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3756);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 - ctx.f25.f64));
	// lfs f15,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f23,f19,f4,f21
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f4.f64 - ctx.f21.f64)));
	// lfs f19,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f19
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64));
	// lfs f19,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64));
	// fmadds f28,f28,f13,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 + ctx.f27.f64));
	// lfs f27,1412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	ctx.f27.f64 = double(temp.f32);
	// fadds f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 + ctx.f27.f64));
	// lfs f25,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f17,f25,f23
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f25.f64 - ctx.f23.f64)));
	// lfs f23,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f23.f64 = double(temp.f32);
	// lfs f17,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f23,f17,f21
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f17.f64 + ctx.f21.f64));
	// lfs f21,1668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	ctx.f21.f64 = double(temp.f32);
	// fadds f27,f27,f21
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f21.f64));
	// fnmsubs f25,f24,f4,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// lfs f24,3196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3196);
	ctx.f24.f64 = double(temp.f32);
	// fadds f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 + ctx.f24.f64));
	// lfs f24,1380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f25,f16,f4,f25
	ctx.f25.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// fsubs f27,f27,f24
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f24.f64));
	// lfs f24,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f27,f26,f30,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f30.f64 - ctx.f27.f64)));
	// fnmsubs f25,f24,f4,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// lfs f17,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f17.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f16,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f23,f23,f30,f27
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64 + ctx.f27.f64));
	// fnmsubs f26,f18,f7,f25
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// fnmsubs f23,f19,f30,f23
	ctx.f23.f64 = double(float(-(ctx.f19.f64 * ctx.f30.f64 - ctx.f23.f64)));
	// fmadds f27,f22,f4,f26
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f26.f64));
	// lfs f26,1628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f20,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfs f28,4604(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4604, temp.u32);
	// lfs f28,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fmuls f27,f28,f29
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// lfs f28,4064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4064);
	ctx.f28.f64 = double(temp.f32);
	// fadds f25,f26,f28
	ctx.f25.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f28,3204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3204);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f2,f28
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f26,1404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,3764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3764);
	ctx.f28.f64 = double(temp.f32);
	// fadds f22,f26,f28
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f26,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f26.f64 = double(temp.f32);
	// lfs f28,3212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3212);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f21,f28,f26
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f28,1556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1556);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f2,f28
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f28,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// stfs f28,488(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// fmuls f25,f25,f2
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f2.f64));
	// fmuls f24,f24,f26
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// fmsubs f27,f28,f29,f27
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f29.f64 - ctx.f27.f64));
	// lfs f28,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f2,f28
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f28.f64));
	// lfs f28,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f22,f22,f28,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f28.f64 + ctx.f21.f64));
	// fmuls f21,f20,f28
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f28.f64));
	// lfs f20,1700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1700);
	ctx.f20.f64 = double(temp.f32);
	// fmsubs f25,f25,f28,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f28.f64 - ctx.f24.f64));
	// lfs f24,3220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3220);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fsubs f27,f27,f20
	ctx.f27.f64 = double(float(ctx.f27.f64 - ctx.f20.f64));
	// lfs f20,4044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4044);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f2,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// fmsubs f22,f22,f2,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 - ctx.f21.f64));
	// lfs f21,3772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3772);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f29,f27
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f29.f64 + ctx.f27.f64));
	// lfs f27,1788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1788);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f27,f17
	ctx.f17.f64 = double(float(ctx.f27.f64 * ctx.f17.f64));
	// lfs f27,1792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1792);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f16,f16,f27
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f27.f64));
	// lfs f27,-228(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -228);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f25,f18,f27,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f27.f64 - ctx.f25.f64)));
	// lfs f18,4076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4076);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f22,f20,f28,f22
	ctx.f22.f64 = double(float(-(ctx.f20.f64 * ctx.f28.f64 - ctx.f22.f64)));
	// lfs f20,1436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1436);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// stfs f27,1788(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1788, temp.u32);
	// fadds f21,f21,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 + ctx.f20.f64));
	// lfs f20,1684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1684);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f2,f20
	ctx.f20.f64 = double(float(ctx.f2.f64 * ctx.f20.f64));
	// fnmsubs f15,f24,f28,f25
	ctx.f15.f64 = double(float(-(ctx.f24.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f25,1420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1420);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f14,f25,f27
	ctx.f14.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f24,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f22,f18,f26,f22
	ctx.f22.f64 = double(float(-(ctx.f18.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// fmadds f17,f25,f24,f17
	ctx.f17.f64 = double(float(ctx.f25.f64 * ctx.f24.f64 + ctx.f17.f64));
	// lfs f25,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// stfs f25,1020(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1020, temp.u32);
	// fmuls f16,f16,f24
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f24.f64));
	// lfs f24,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f21,f25,f29,f21
	ctx.f21.f64 = double(float(-(ctx.f25.f64 * ctx.f29.f64 - ctx.f21.f64)));
	// lfs f25,1548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1548);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f2,f25
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f25,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f19,f24,f25
	ctx.f19.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f24,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f22,f18,f27,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f22.f64));
	// fmuls f24,f24,f31
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// lfs f18,1396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1396);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// fmadds f23,f19,f30,f23
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f23.f64));
	// stfs f23,4608(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4608, temp.u32);
	// lfs f23,4084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4084);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,4092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4092);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f24,f24,f29,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f21.f64));
	// fnmsubs f21,f20,f28,f15
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f28.f64 - ctx.f15.f64)));
	// lfs f28,3236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3236);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f26,f28,f26,f14
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f26.f64 + ctx.f14.f64));
	// lfs f28,356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f20,f17,f28,f16
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 - ctx.f16.f64));
	// lfs f17,3780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3780);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f28,f28,f17
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f17,3244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3244);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f24,f17,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f17,1944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1944);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f26,f2,f21
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 + ctx.f21.f64));
	// stfs f2,4612(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4612, temp.u32);
	// lfs f2,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f2,f28,f2,f20
	ctx.f2.f64 = double(float(-(ctx.f28.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// stfs f2,4616(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4616, temp.u32);
	// fnmsubs f2,f18,f27,f22
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f27.f64 - ctx.f22.f64)));
	// stfs f2,4620(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4620, temp.u32);
	// lfs f2,4052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4052);
	ctx.f2.f64 = double(temp.f32);
	// lfs f28,1636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	ctx.f28.f64 = double(temp.f32);
	// lfs f26,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,3252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3252);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f2,f2,f29,f24
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfs f22,3268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3268);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f27,f13,f27
	ctx.f27.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// lfs f24,3788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3788);
	ctx.f24.f64 = double(temp.f32);
	// fadds f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,3796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3796);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,3276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3276);
	ctx.f21.f64 = double(temp.f32);
	// lfs f20,3804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3804);
	ctx.f20.f64 = double(temp.f32);
	// fadds f28,f2,f28
	ctx.f28.f64 = double(float(ctx.f2.f64 + ctx.f28.f64));
	// lfs f2,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmuls f27,f27,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f7.f64));
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fnmsubs f28,f24,f29,f28
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f29.f64 - ctx.f28.f64)));
	// lfs f24,3260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3260);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f2,f2,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f26.f64));
	// fmuls f24,f13,f24
	ctx.f24.f64 = double(float(ctx.f13.f64 * ctx.f24.f64));
	// fmsubs f22,f22,f7,f2
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 - ctx.f2.f64));
	// lfs f2,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f28,f21,f2,f28
	ctx.f28.f64 = double(float(-(ctx.f21.f64 * ctx.f2.f64 - ctx.f28.f64)));
	// lfs f21,4060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4060);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f13,f21
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmsubs f27,f22,f13,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 - ctx.f27.f64));
	// lfs f22,3284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3284);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f20,f20,f2,f28
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f28.f64));
	// lfs f28,3292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3292);
	ctx.f28.f64 = double(temp.f32);
	// fadds f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 + ctx.f19.f64));
	// lfs f28,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f25,f28
	ctx.f18.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// lfs f28,2184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2184);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// fmuls f22,f13,f22
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// fnmsubs f24,f24,f4,f27
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f27,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmadds f24,f23,f4,f24
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f4.f64 + ctx.f24.f64));
	// fmuls f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// lfs f26,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f25.f64));
	// lfs f25,3300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3300);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f25,f25,f2,f20
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// lfs f20,3812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3812);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,844(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f28,3308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3308);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f23,f13,f28
	ctx.f23.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f28,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f16,f28
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// lfs f15,4100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4100);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f27,f20,f7,f27
	ctx.f27.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f27.f64));
	// fmadds f2,f15,f2,f25
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 + ctx.f25.f64));
	// lfs f25,3316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3316);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f24,f21,f7,f24
	ctx.f24.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f24.f64)));
	// lfs f21,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f28
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// fmuls f28,f23,f4
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f4.f64));
	// fmuls f25,f13,f25
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fnmsubs f23,f18,f30,f2
	ctx.f23.f64 = double(float(-(ctx.f18.f64 * ctx.f30.f64 - ctx.f2.f64)));
	// lfs f2,3820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3820);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f27,f2,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f2.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// lfs f2,3324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3324);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f20,f13,f2
	ctx.f20.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// lfs f2,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f24,f22,f7,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f18,4068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4068);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,3332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3332);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f18,f2,f18
	ctx.f18.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// lfs f2,3828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3828);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f15,f13,f2
	ctx.f15.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmadds f2,f26,f30,f23
	ctx.f2.f64 = double(float(ctx.f26.f64 * ctx.f30.f64 + ctx.f23.f64));
	// fmsubs f27,f27,f13,f28
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f13.f64 - ctx.f28.f64));
	// lfs f28,3340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3340);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f13,f28
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f28.f64));
	// lfs f28,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f24,f17,f28,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 + ctx.f24.f64));
	// lfs f17,2408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2408);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f23,f16,f30,f2
	ctx.f23.f64 = double(float(-(ctx.f16.f64 * ctx.f30.f64 - ctx.f2.f64)));
	// lfs f2,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f27,f18,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f18,1880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1880);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,2424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2424);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f28,f19,f28,f24
	ctx.f28.f64 = double(float(-(ctx.f19.f64 * ctx.f28.f64 - ctx.f24.f64)));
	// lfs f19,2192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2192);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f30,f21,f30,f23
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 + ctx.f23.f64));
	// lfs f23,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f23.f64 = double(temp.f32);
	// lfs f21,2368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2368);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f27,f15,f4,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fnmsubs f28,f25,f7,f28
	ctx.f28.f64 = double(float(-(ctx.f25.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// lfs f25,1572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	ctx.f25.f64 = double(temp.f32);
	// fsubs f30,f30,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 - ctx.f25.f64));
	// stfs f30,4624(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4624, temp.u32);
	// fnmsubs f27,f26,f7,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// lfs f26,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f30,f20,f4,f28
	ctx.f30.f64 = double(float(-(ctx.f20.f64 * ctx.f4.f64 - ctx.f28.f64)));
	// lfs f20,3836(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3836);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmadds f28,f22,f2,f30
	ctx.f28.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 + ctx.f30.f64));
	// lfs f30,1744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1744);
	ctx.f30.f64 = double(temp.f32);
	// lfs f2,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f2,f30
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f30,4232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4232);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f6,f30
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f30,1916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1916);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f23,f30,f23
	ctx.f23.f64 = double(float(ctx.f30.f64 * ctx.f23.f64));
	// lfs f30,3348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3348);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f6,f30
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f30,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// fmuls f2,f2,f18
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f18.f64));
	// lfs f18,2400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2400);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f6,f18
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f18.f64));
	// fmadds f30,f19,f30,f25
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f25.f64));
	// lfs f19,1476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1476);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f25,f24,f10
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f10.f64));
	// lfs f24,2388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2388);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f19,f19,f10
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f10.f64));
	// fmuls f24,f6,f24
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f24.f64));
	// fmadds f30,f30,f0,f25
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f25.f64));
	// lfs f25,2392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2392);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f19,f17,f1,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 + ctx.f19.f64));
	// lfs f17,2416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2416);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f25,f13,f25
	ctx.f25.f64 = double(float(ctx.f13.f64 * ctx.f25.f64));
	// fadds f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f16.f64));
	// fmsubs f30,f23,f26,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f26.f64 - ctx.f30.f64));
	// lfs f26,2432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2432);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,2440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2440);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f26,f26,f1
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// fmuls f23,f6,f23
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f23.f64));
	// lfs f16,2448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2448);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f25,f4,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f27.f64));
	// fmuls f16,f13,f16
	ctx.f16.f64 = double(float(ctx.f13.f64 * ctx.f16.f64));
	// lfs f14,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f30,f22,f10,f30
	ctx.f30.f64 = double(float(ctx.f22.f64 * ctx.f10.f64 + ctx.f30.f64));
	// lfs f15,1736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1736);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f14,1676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1676);
	ctx.f14.f64 = double(temp.f32);
	// lfs f25,1492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1492);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f26,f17,f10,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f10.f64 + ctx.f26.f64));
	// fadds f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 + ctx.f25.f64));
	// lfs f22,2456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2456);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f23,f23,f10
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f10.f64));
	// lfs f17,1816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1816);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f22,f13,f22
	ctx.f22.f64 = double(float(ctx.f13.f64 * ctx.f22.f64));
	// lfs f14,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// fnmsubs f27,f16,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f16.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// lfs f16,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f30,f21,f16,f30
	ctx.f30.f64 = double(float(-(ctx.f21.f64 * ctx.f16.f64 - ctx.f30.f64)));
	// lfs f16,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f16.f64 = double(temp.f32);
	// lfs f21,2464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2464);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f13,f21
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f21.f64));
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fmsubs f26,f26,f6,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f6.f64 - ctx.f23.f64));
	// lfs f23,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f16,1484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1484);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f6,f16
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f16.f64));
	// fmadds f27,f22,f4,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f4.f64 + ctx.f27.f64));
	// lfs f22,1344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1344);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f30,f20,f10,f30
	ctx.f30.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f30.f64));
	// lfs f20,2480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2480);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f6,f22
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f22.f64));
	// fmuls f20,f6,f20
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f20.f64));
	// fmadds f26,f25,f1,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f26.f64));
	// lfs f25,2472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2472);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f6,f25
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f25.f64));
	// fnmsubs f27,f21,f4,f27
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f4.f64 - ctx.f27.f64)));
	// fnmsubs f30,f24,f1,f30
	ctx.f30.f64 = double(float(-(ctx.f24.f64 * ctx.f1.f64 - ctx.f30.f64)));
	// fnmsubs f26,f16,f1,f26
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// stfs f28,4628(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4628, temp.u32);
	// fmadds f30,f19,f6,f30
	ctx.f30.f64 = double(float(ctx.f19.f64 * ctx.f6.f64 + ctx.f30.f64));
	// lfs f27,1508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1508);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f28,f25,f1,f26
	ctx.f28.f64 = double(float(-(ctx.f25.f64 * ctx.f1.f64 - ctx.f26.f64)));
	// fmadds f2,f2,f0,f30
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f30.f64));
	// lfs f30,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f28,f20,f10,f28
	ctx.f28.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f28.f64)));
	// lfs f20,2528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2528);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f2,f18,f10,f2
	ctx.f2.f64 = double(float(-(ctx.f18.f64 * ctx.f10.f64 - ctx.f2.f64)));
	// lfs f18,1536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1536);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f20,f18,f20
	ctx.f20.f64 = double(float(ctx.f18.f64 * ctx.f20.f64));
	// lfs f18,1596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1596);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f3,f18
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f18.f64));
	// fmadds f2,f15,f0,f2
	ctx.f2.f64 = double(float(ctx.f15.f64 * ctx.f0.f64 + ctx.f2.f64));
	// fnmsubs f2,f17,f0,f2
	ctx.f2.f64 = double(float(-(ctx.f17.f64 * ctx.f0.f64 - ctx.f2.f64)));
	// lfs f17,2536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2536);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f2,f23,f0,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f2.f64));
	// fnmsubs f23,f22,f1,f2
	ctx.f23.f64 = double(float(-(ctx.f22.f64 * ctx.f1.f64 - ctx.f2.f64)));
	// lfs f2,2488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2488);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,2496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2496);
	ctx.f1.f64 = double(temp.f32);
	// fadds f1,f2,f1
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// lfs f2,1368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1368);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f26,f2,f30
	ctx.f26.f64 = double(float(ctx.f2.f64 * ctx.f30.f64));
	// lfs f2,1132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1132);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f25,f2,f27
	ctx.f25.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f27,1652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f2,f27
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f27,2504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2504);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f22,f2,f27
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f27,1516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1516);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f21,f6,f27
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f27,2512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2512);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f2,f27
	ctx.f19.f64 = double(float(ctx.f2.f64 * ctx.f27.f64));
	// lfs f27,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f1,f1,f27,f26
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f27.f64 + ctx.f26.f64));
	// lfs f26,2520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2520);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f3,f26
	ctx.f26.f64 = double(float(ctx.f3.f64 * ctx.f26.f64));
	// fmuls f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f27.f64));
	// fmuls f1,f1,f2
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// fnmsubs f28,f21,f10,f28
	ctx.f28.f64 = double(float(-(ctx.f21.f64 * ctx.f10.f64 - ctx.f28.f64)));
	// lfs f16,1500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1500);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f26,f12,f22
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f22.f64));
	// lfs f21,1340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f17,f3,f17
	ctx.f17.f64 = double(float(ctx.f3.f64 * ctx.f17.f64));
	// lfs f15,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f15.f64 = double(temp.f32);
	// fadds f21,f16,f21
	ctx.f21.f64 = double(float(ctx.f16.f64 + ctx.f21.f64));
	// lfs f16,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f25,f25,f30,f1
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64 - ctx.f1.f64));
	// lfs f1,2552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2552);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f16,f15
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f15.f64));
	// lfs f15,1692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1692);
	ctx.f15.f64 = double(temp.f32);
	// fadds f15,f1,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 + ctx.f15.f64));
	// lfs f1,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f1.f64 = double(temp.f32);
	// lfs f22,2544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2544);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f3,f22
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// fmadds f20,f20,f0,f28
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64 + ctx.f28.f64));
	// lfs f28,2560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2560);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f26,f17,f12,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// fmuls f17,f28,f1
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// lfs f28,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// stfs f28,628(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// fmuls f21,f21,f3
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f3.f64));
	// fmadds f17,f15,f12,f17
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f17.f64));
	// fmuls f14,f6,f28
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// fnmsubs f28,f24,f30,f25
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f30.f64 - ctx.f25.f64)));
	// lfs f25,2568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2568);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f3,f25
	ctx.f25.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// stfs f25,324(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmadds f21,f21,f1,f26
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f26.f64));
	// lfs f26,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f25,f26,f31
	ctx.f25.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// lfs f26,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f31
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f31.f64));
	// stfs f26,1900(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1900, temp.u32);
	// fnmsubs f24,f16,f0,f20
	ctx.f24.f64 = double(float(-(ctx.f16.f64 * ctx.f0.f64 - ctx.f20.f64)));
	// lfs f20,1604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f3,f20
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f20.f64));
	// stfs f25,328(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// fmadds f19,f19,f27,f28
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f28.f64));
	// lfs f28,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// stfs f28,1224(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1224, temp.u32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f25,1360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1360);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f2,f25
	ctx.f15.f64 = double(float(ctx.f2.f64 * ctx.f25.f64));
	// lfs f25,2576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2576);
	ctx.f25.f64 = double(temp.f32);
	// lfs f2,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f21,f20,f1,f21
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f1.f64 - ctx.f21.f64)));
	// fmadds f20,f25,f2,f17
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f17.f64));
	// lfs f25,2584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2584);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f19,f18,f12,f19
	ctx.f19.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f19.f64)));
	// fmuls f16,f6,f28
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f28.f64));
	// lfs f28,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f24,f14,f28,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f28.f64 - ctx.f24.f64)));
	// fmuls f18,f3,f25
	ctx.f18.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f25,1612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f26,f26,f6
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f6.f64));
	// fmadds f21,f20,f3,f21
	ctx.f21.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f21.f64));
	// lfs f20,2592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2592);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f22,f22,f12,f19
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f19.f64)));
	// fnmsubs f17,f16,f28,f24
	ctx.f17.f64 = double(float(-(ctx.f16.f64 * ctx.f28.f64 - ctx.f24.f64)));
	// lfs f24,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f3,f25
	ctx.f16.f64 = double(float(ctx.f3.f64 * ctx.f25.f64));
	// lfs f25,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f9,f25
	ctx.f25.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// fmuls f20,f24,f20
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f20.f64));
	// fmadds f28,f26,f28,f17
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f28.f64 + ctx.f17.f64));
	// fnmsubs f26,f16,f1,f21
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f1.f64 - ctx.f21.f64)));
	// lfs f21,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f22,f21,f2,f22
	ctx.f22.f64 = double(float(-(ctx.f21.f64 * ctx.f2.f64 - ctx.f22.f64)));
	// fadds f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 + ctx.f28.f64));
	// stfs f28,4632(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4632, temp.u32);
	// fmadds f28,f15,f30,f22
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f30.f64 + ctx.f22.f64));
	// fnmsubs f28,f18,f1,f28
	ctx.f28.f64 = double(float(-(ctx.f18.f64 * ctx.f1.f64 - ctx.f28.f64)));
	// fadds f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f26.f64));
	// stfs f28,4636(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4636, temp.u32);
	// lfs f28,1352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1352);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f28,f9
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f9.f64));
	// lfs f28,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f28.f64 = double(temp.f32);
	// lfs f23,3248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3248);
	ctx.f23.f64 = double(temp.f32);
	// lfs f19,536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f23,f28,f23
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// fmuls f28,f19,f28
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f28.f64));
	// lfs f18,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f26,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// lfs f26,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,2600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2600);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// lfs f21,1392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1392);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// lfs f15,2608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2608);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,1400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1400);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f9
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// lfs f14,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,1324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1324);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f12
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f12.f64));
	// fmuls f16,f28,f26
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f28,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f9,f28
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f22,f22,f26
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f26.f64));
	// fmuls f21,f21,f12
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f12.f64));
	// fmuls f15,f28,f15
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f15.f64));
	// lfs f28,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f20,f20,f28,f18
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f28.f64 - ctx.f18.f64));
	// lfs f18,2616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2616);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f24,f24,f18
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f18.f64));
	// lfs f18,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f14,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f27,f19,f27,f21
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 - ctx.f21.f64));
	// lfs f19,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f19.f64 = double(temp.f32);
	// lfs f21,2624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2624);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f19,f17
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,3608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3608);
	ctx.f17.f64 = double(temp.f32);
	// lfs f19,2632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2632);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f9,f19
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f19.f64));
	// fmadds f23,f23,f28,f20
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 + ctx.f20.f64));
	// lfs f20,3616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3616);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f17,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 + ctx.f20.f64));
	// lfs f17,2640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2640);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f18,f14
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64));
	// lfs f14,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f27,f15,f14,f27
	ctx.f27.f64 = double(float(ctx.f15.f64 * ctx.f14.f64 + ctx.f27.f64));
	// lfs f14,2656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2656);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f17,f2
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f2.f64));
	// lfs f15,2648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2648);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f14,f14,f9
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f9.f64));
	// fmuls f15,f15,f9
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f9.f64));
	// fnmsubs f23,f22,f28,f23
	ctx.f23.f64 = double(float(-(ctx.f22.f64 * ctx.f28.f64 - ctx.f23.f64)));
	// lfs f22,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f27,f24,f28,f27
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f28.f64 - ctx.f27.f64)));
	// lfs f24,1384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1384);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f22,f20,f22,f17
	ctx.f22.f64 = double(float(ctx.f20.f64 * ctx.f22.f64 + ctx.f17.f64));
	// lfs f17,3696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3696);
	ctx.f17.f64 = double(temp.f32);
	// lfs f20,1376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1376);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f24,f9,f24
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fmuls f20,f9,f20
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f20.f64));
	// fnmsubs f28,f16,f28,f23
	ctx.f28.f64 = double(float(-(ctx.f16.f64 * ctx.f28.f64 - ctx.f23.f64)));
	// lfs f23,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f25,f23
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f23.f64));
	// lfs f16,1796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1796);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f9
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f9.f64));
	// fnmsubs f27,f18,f12,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f27.f64)));
	// lfs f18,3728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3728);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f22,f17,f30,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f22.f64));
	// lfs f17,2664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2664);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f9,f17
	ctx.f17.f64 = double(float(ctx.f9.f64 * ctx.f17.f64));
	// fmuls f18,f9,f18
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f18.f64));
	// fmadds f28,f21,f9,f28
	ctx.f28.f64 = double(float(ctx.f21.f64 * ctx.f9.f64 + ctx.f28.f64));
	// lfs f21,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f25,f21
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f21.f64));
	// lfs f21,1408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1408);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f9
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f9.f64));
	// fnmsubs f27,f14,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f14,3720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3720);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f9,f14
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f14.f64));
	// fnmsubs f28,f19,f2,f28
	ctx.f28.f64 = double(float(-(ctx.f19.f64 * ctx.f2.f64 - ctx.f28.f64)));
	// fmadds f27,f22,f9,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 + ctx.f27.f64));
	// fmadds f22,f15,f2,f28
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f2.f64 + ctx.f28.f64));
	// fnmsubs f27,f23,f1,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f1.f64 - ctx.f27.f64)));
	// lfs f28,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f23,f20,f28,f22
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f28.f64 - ctx.f22.f64)));
	// lfs f22,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f22.f64 = double(temp.f32);
	// lfs f19,2336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2336);
	ctx.f19.f64 = double(temp.f32);
	// lfs f15,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f27,f18,f22,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f22.f64 - ctx.f27.f64)));
	// lfs f22,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f24,f24,f22,f23
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f22.f64 - ctx.f23.f64)));
	// lfs f22,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f1,f25,f1,f27
	ctx.f1.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f27.f64));
	// fmadds f27,f17,f2,f24
	ctx.f27.f64 = double(float(ctx.f17.f64 * ctx.f2.f64 + ctx.f24.f64));
	// lfs f17,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f25,f14,f30,f1
	ctx.f25.f64 = double(float(-(ctx.f14.f64 * ctx.f30.f64 - ctx.f1.f64)));
	// lfs f1,1912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1912);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f16,f2,f27
	ctx.f2.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f30,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f18,f30,f18
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f18.f64));
	// lfs f16,1920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1920);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,2044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2044);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f27,f21,f28,f2
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f28.f64 + ctx.f2.f64));
	// lfs f2,2012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2012);
	ctx.f2.f64 = double(temp.f32);
	// fadds f28,f2,f1
	ctx.f28.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// lfs f1,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f31,f26
	ctx.f2.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// lfs f21,1536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1536);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f26,f30,f2
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// lfs f2,1884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1884);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f24,f1,f2
	ctx.f24.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f1,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,812(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 812);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f28,f28,f1
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// fmuls f23,f1,f2
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// lfs f2,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// lfs f30,1312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1312);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f15,f1,f15
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f15.f64));
	// fmuls f22,f2,f22
	ctx.f22.f64 = double(float(ctx.f2.f64 * ctx.f22.f64));
	// lfs f2,1372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f21,f21,f2
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// lfs f2,-19000(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -19000);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f26,f26,f2,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f28.f64));
	// stfs f2,1256(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1256, temp.u32);
	// lfs f2,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f2.f64 = double(temp.f32);
	// lfs f28,1012(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1012);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f2,f16
	ctx.f16.f64 = double(float(ctx.f2.f64 * ctx.f16.f64));
	// fmuls f20,f28,f2
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f2.f64));
	// lfs f28,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmadds f30,f17,f30,f21
	ctx.f30.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f21.f64));
	// lfs f21,436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 436);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f28,f21
	ctx.f21.f64 = double(float(ctx.f28.f64 * ctx.f21.f64));
	// lfs f28,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f2,f28,f26
	ctx.f28.f64 = double(float(ctx.f2.f64 * ctx.f28.f64 + ctx.f26.f64));
	// lfs f26,1512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1512);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f26.f64));
	// lfs f1,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f1.f64 = double(temp.f32);
	// lfs f17,2028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2028);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f2,f17
	ctx.f17.f64 = double(float(ctx.f2.f64 * ctx.f17.f64));
	// fmadds f1,f24,f1,f28
	ctx.f1.f64 = double(float(ctx.f24.f64 * ctx.f1.f64 + ctx.f28.f64));
	// lfs f24,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f24.f64 = double(temp.f32);
	// lfs f28,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f24,f28
	ctx.f28.f64 = double(float(ctx.f24.f64 * ctx.f28.f64));
	// lfs f24,2036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2036);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f2,f24
	ctx.f24.f64 = double(float(ctx.f2.f64 * ctx.f24.f64));
	// fmsubs f2,f2,f14,f26
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f14.f64 - ctx.f26.f64));
	// lfs f14,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f14.f64 = double(temp.f32);
	// lfs f26,3664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3664);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f9,f26
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// fnmsubs f1,f23,f14,f1
	ctx.f1.f64 = double(float(-(ctx.f23.f64 * ctx.f14.f64 - ctx.f1.f64)));
	// lfs f14,1220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1220);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f23,f28,f31
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// lfs f28,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f14.f64));
	// lfs f28,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f2,f16,f28,f2
	ctx.f2.f64 = double(float(-(ctx.f16.f64 * ctx.f28.f64 - ctx.f2.f64)));
	// lfs f28,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f28.f64 = double(temp.f32);
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f28,f16
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// lfs f28,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f26,f28,f25
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f28.f64 + ctx.f25.f64));
	// lfs f26,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,1956(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1956);
	ctx.f25.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f1,f26,f25,f1
	ctx.f1.f64 = double(float(-(ctx.f26.f64 * ctx.f25.f64 - ctx.f1.f64)));
	// lfs f25,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f25.f64 = double(temp.f32);
	// lfs f26,2268(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2268);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f25,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f2,f24,f25,f2
	ctx.f2.f64 = double(float(-(ctx.f24.f64 * ctx.f25.f64 - ctx.f2.f64)));
	// lfs f25,1452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1452);
	ctx.f25.f64 = double(temp.f32);
	// lfs f24,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f25
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f25,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f25.f64 = double(temp.f32);
	// fadds f28,f27,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 + ctx.f28.f64));
	// stfs f28,4640(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4640, temp.u32);
	// lfs f28,2052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2052);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f1,f22,f25,f1
	ctx.f1.f64 = double(float(-(ctx.f22.f64 * ctx.f25.f64 - ctx.f1.f64)));
	// lfs f27,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f2,f27,f28,f2
	ctx.f2.f64 = double(float(ctx.f27.f64 * ctx.f28.f64 + ctx.f2.f64));
	// lfs f28,1520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1520);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f30,f30,f25,f1
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f25.f64 + ctx.f1.f64));
	// lfs f1,616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 616);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f28,f1,f28,f2
	ctx.f28.f64 = double(float(-(ctx.f1.f64 * ctx.f28.f64 - ctx.f2.f64)));
	// lfs f2,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// fmadds f22,f27,f2,f30
	ctx.f22.f64 = double(float(ctx.f27.f64 * ctx.f2.f64 + ctx.f30.f64));
	// lfs f2,640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 640);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f30,f26,f2,f28
	ctx.f30.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 + ctx.f28.f64));
	// lfs f28,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f28.f64 = double(temp.f32);
	// stfs f30,324(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmr f30,f28
	ctx.f30.f64 = ctx.f28.f64;
	// fnmsubs f28,f20,f30,f22
	ctx.f28.f64 = double(float(-(ctx.f20.f64 * ctx.f30.f64 - ctx.f22.f64)));
	// fmadds f26,f19,f30,f28
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f28.f64));
	// lfs f28,-164(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -164);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f26,f18,f28,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f28.f64 - ctx.f26.f64)));
	// fmadds f22,f21,f30,f26
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 + ctx.f26.f64));
	// lfs f26,-152(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + -152);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f21.f64 = double(temp.f32);
	// stfs f26,1796(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1796, temp.u32);
	// fnmsubs f22,f17,f26,f22
	ctx.f22.f64 = double(float(-(ctx.f17.f64 * ctx.f26.f64 - ctx.f22.f64)));
	// lfs f19,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f24,f24,f25,f19
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f25.f64 - ctx.f19.f64)));
	// lfs f25,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f25.f64 = double(temp.f32);
	// lfs f19,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f25,f19
	ctx.f19.f64 = double(float(ctx.f25.f64 * ctx.f19.f64));
	// lfs f25,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f31
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f31.f64));
	// lfs f17,2680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2680);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f22,f15,f30,f22
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f30.f64 - ctx.f22.f64)));
	// fnmsubs f23,f23,f21,f22
	ctx.f23.f64 = double(float(-(ctx.f23.f64 * ctx.f21.f64 - ctx.f22.f64)));
	// lfs f21,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f18,f21,f25
	ctx.f18.f64 = double(float(ctx.f21.f64 * ctx.f25.f64));
	// fmadds f28,f14,f28,f23
	ctx.f28.f64 = double(float(ctx.f14.f64 * ctx.f28.f64 + ctx.f23.f64));
	// lfs f23,456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	ctx.f23.f64 = double(temp.f32);
	// lfs f14,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f16,f26,f28
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f26.f64 + ctx.f28.f64));
	// lfs f28,2060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2060);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f1,f28
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// fmuls f28,f31,f31
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fnmsubs f26,f26,f30,f24
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f30.f64 - ctx.f24.f64)));
	// lfs f24,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f28,f23,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64));
	// lfs f23,2068(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2068);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f22,f1,f23
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f23.f64));
	// lfs f23,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f21,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f23.f64));
	// fmuls f17,f24,f17
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f17.f64));
	// fmuls f28,f28,f30
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// fmadds f26,f22,f30,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 + ctx.f26.f64));
	// fmsubs f16,f23,f2,f28
	ctx.f16.f64 = double(float(ctx.f23.f64 * ctx.f2.f64 - ctx.f28.f64));
	// lfs f28,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f23,f28,f31
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// lfs f28,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f28,f23
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// lfs f28,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fmadds f18,f14,f28,f18
	ctx.f18.f64 = double(float(ctx.f14.f64 * ctx.f28.f64 + ctx.f18.f64));
	// lfs f28,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f22,f19,f28,f16
	ctx.f22.f64 = double(float(-(ctx.f19.f64 * ctx.f28.f64 - ctx.f16.f64)));
	// lfs f19,1264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1264);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f26,f24,f19,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f19.f64 - ctx.f26.f64)));
	// lfs f19,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f22,f18,f28,f22
	ctx.f22.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 + ctx.f22.f64));
	// lfs f18,1804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1804);
	ctx.f18.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f16,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f26,f1,f19,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f19.f64 + ctx.f26.f64));
	// lfs f19,1948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1948);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f22,f15,f28,f22
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f28.f64 - ctx.f22.f64)));
	// lfs f15,2092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2092);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f26,f17,f30,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f26.f64));
	// lfs f30,2688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2688);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f22,f30,f29,f22
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f29.f64 + ctx.f22.f64));
	// lfs f30,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f30.f64 = double(temp.f32);
	// lfs f17,2704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2704);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f19,f30,f26
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f30.f64 + ctx.f26.f64));
	// lfs f26,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f18,f18,f26,f22
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f26.f64 + ctx.f22.f64));
	// lfs f22,1976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1976);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f19,f27,f22,f19
	ctx.f19.f64 = double(float(-(ctx.f27.f64 * ctx.f22.f64 - ctx.f19.f64)));
	// lfs f22,-96(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -96);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f18,f17,f22,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f22.f64 + ctx.f18.f64));
	// lfs f17,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f17.f64 = double(temp.f32);
	// stfs f22,1804(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1804, temp.u32);
	// fmadds f19,f1,f17,f19
	ctx.f19.f64 = double(float(ctx.f1.f64 * ctx.f17.f64 + ctx.f19.f64));
	// lfs f17,2712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2712);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f18,f17,f26,f18
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f26.f64 - ctx.f18.f64)));
	// lfs f17,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f19,f17,f30,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f30.f64 + ctx.f19.f64));
	// lfs f17,2720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2720);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f18,f17,f29,f18
	ctx.f18.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f18.f64)));
	// lfs f17,1332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f24,f24,f17,f19
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f17.f64 - ctx.f19.f64)));
	// lfs f19,2728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2728);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f19,f19,f29,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f29.f64 - ctx.f18.f64)));
	// lfs f18,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f30,f18,f30,f24
	ctx.f30.f64 = double(float(-(ctx.f18.f64 * ctx.f30.f64 - ctx.f24.f64)));
	// lfs f24,2736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2736);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f24,f22,f19
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f22.f64 + ctx.f19.f64));
	// lfs f22,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f22.f64 = double(temp.f32);
	// lfs f18,1440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1440);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,2800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2800);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f30,f27,f22,f30
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f22.f64 + ctx.f30.f64));
	// lfs f27,2744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2744);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f24,f27,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f27.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f22,1432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1432);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f20,f30
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// stfs f30,4644(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4644, temp.u32);
	// lfs f30,2752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2752);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f27,f30,f2
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f2.f64));
	// lfs f30,-352(r17)
	temp.u32 = PPC_LOAD_U32(ctx.r17.u32 + -352);
	ctx.f30.f64 = double(temp.f32);
	// lfs f20,2768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2768);
	ctx.f20.f64 = double(temp.f32);
	// stfs f30,1720(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1720, temp.u32);
	// fmsubs f27,f22,f30,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f30.f64 - ctx.f27.f64));
	// lfs f22,2760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2760);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f20.f64));
	// lfs f20,2776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2776);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f2,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f2.f64 + ctx.f27.f64));
	// lfs f27,2784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2784);
	ctx.f27.f64 = double(temp.f32);
	// fadds f22,f22,f27
	ctx.f22.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// lfs f27,2792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2792);
	ctx.f27.f64 = double(temp.f32);
	// fadds f19,f27,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 + ctx.f19.f64));
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f23,f27,f23
	ctx.f23.f64 = double(float(ctx.f27.f64 * ctx.f23.f64));
	// fmuls f27,f27,f16
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f16.f64));
	// lfs f16,2816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2816);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f20,f18,f26,f20
	ctx.f20.f64 = double(float(-(ctx.f18.f64 * ctx.f26.f64 - ctx.f20.f64)));
	// lfs f18,2808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2808);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f18,f18,f29,f24
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f24,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f24.f64 = double(temp.f32);
	// fadds f17,f17,f24
	ctx.f17.f64 = double(float(ctx.f17.f64 + ctx.f24.f64));
	// fnmsubs f20,f16,f2,f20
	ctx.f20.f64 = double(float(-(ctx.f16.f64 * ctx.f2.f64 - ctx.f20.f64)));
	// lfs f16,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f19,f19,f29,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f18.f64));
	// lfs f18,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f25
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f25.f64));
	// lfs f25,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f17,f17,f25,f27
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64 + ctx.f27.f64));
	// lfs f25,-168(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + -168);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// lfs f27,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f17,f17,f13
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f13.f64));
	// fnmsubs f20,f27,f25,f20
	ctx.f20.f64 = double(float(-(ctx.f27.f64 * ctx.f25.f64 - ctx.f20.f64)));
	// lfs f15,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f15.f64 = double(temp.f32);
	// lfs f27,1856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1856);
	ctx.f27.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f16,f15,f27,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f27.f64 + ctx.f16.f64));
	// lfs f27,2824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2824);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f19,f27,f26,f19
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f26.f64 + ctx.f19.f64));
	// lfs f27,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f31
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// lfs f26,-516(r16)
	temp.u32 = PPC_LOAD_U32(ctx.r16.u32 + -516);
	ctx.f26.f64 = double(temp.f32);
	// lfs f14,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f14.f64 = double(temp.f32);
	// stfs f26,412(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// stfs f27,1248(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1248, temp.u32);
	// stfs f25,376(r1)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// fnmsubs f26,f14,f26,f20
	ctx.f26.f64 = double(float(-(ctx.f14.f64 * ctx.f26.f64 - ctx.f20.f64)));
	// lfs f20,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f16,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f20.f64));
	// lfs f16,2832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2832);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f19,f16,f29,f19
	ctx.f19.f64 = double(float(-(ctx.f16.f64 * ctx.f29.f64 - ctx.f19.f64)));
	// fmuls f15,f27,f24
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f24.f64));
	// lfs f27,1304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1304);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// fmadds f26,f22,f2,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f2.f64 + ctx.f26.f64));
	// fmadds f22,f17,f0,f20
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f20.f64));
	// lfs f20,2840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2840);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f29,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 + ctx.f19.f64));
	// lfs f19,1424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1424);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f24,f24,f13
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmadds f26,f19,f25,f26
	ctx.f26.f64 = double(float(ctx.f19.f64 * ctx.f25.f64 + ctx.f26.f64));
	// lfs f19,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f25,f24,f0,f22
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f22.f64)));
	// lfs f24,1416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1416);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f26,f24,f30,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f30.f64 - ctx.f26.f64)));
	// lfs f24,2848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2848);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f26,f24,f2,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// lfs f24,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f26,f24,f30,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f30.f64 + ctx.f26.f64));
	// lfs f30,12124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 12124);
	ctx.f30.f64 = double(temp.f32);
	// lfs f24,3768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3768);
	ctx.f24.f64 = double(temp.f32);
	// stfs f30,300(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fnmsubs f30,f24,f30,f26
	ctx.f30.f64 = double(float(-(ctx.f24.f64 * ctx.f30.f64 - ctx.f26.f64)));
	// lfs f24,3776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3776);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f26,f23,f28,f30
	ctx.f26.f64 = double(float(-(ctx.f23.f64 * ctx.f28.f64 - ctx.f30.f64)));
	// lfs f30,-52(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -52);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,1264(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1264, temp.u32);
	// fmadds f30,f24,f30,f26
	ctx.f30.f64 = double(float(ctx.f24.f64 * ctx.f30.f64 + ctx.f26.f64));
	// fnmsubs f30,f18,f28,f30
	ctx.f30.f64 = double(float(-(ctx.f18.f64 * ctx.f28.f64 - ctx.f30.f64)));
	// fnmsubs f30,f15,f28,f30
	ctx.f30.f64 = double(float(-(ctx.f15.f64 * ctx.f28.f64 - ctx.f30.f64)));
	// lfs f28,3760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3760);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f28,f13
	ctx.f26.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,2856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2856);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f28,f13
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f23,f28,f13
	ctx.f23.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f22,f28,f13
	ctx.f22.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f28.f64 = double(temp.f32);
	// fadds f30,f20,f30
	ctx.f30.f64 = double(float(ctx.f20.f64 + ctx.f30.f64));
	// stfs f30,4648(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4648, temp.u32);
	// lfs f30,3744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3744);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f20,f28,f13
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// fmuls f30,f30,f13
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfs f28,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f25,f30,f28,f25
	ctx.f25.f64 = double(float(-(ctx.f30.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f30,-220(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -220);
	ctx.f30.f64 = double(temp.f32);
	// stfs f30,940(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 940, temp.u32);
	// fmuls f19,f19,f30
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// lfs f30,2864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2864);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f18,f30,f11
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// lfs f30,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f17,f30,f13
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfs f30,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f25,f26,f28,f25
	ctx.f25.f64 = double(float(-(ctx.f26.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f26,1928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1928);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f30
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f26,3752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3752);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f26,f13
	ctx.f15.f64 = double(float(ctx.f26.f64 * ctx.f13.f64));
	// lfs f26,-216(r21)
	temp.u32 = PPC_LOAD_U32(ctx.r21.u32 + -216);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,324(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f14,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f14.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f26,f14,f26,f19
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f26.f64 + ctx.f19.f64));
	// lfs f19,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f18,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// lfs f18,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f25,f24,f18,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f18.f64 - ctx.f25.f64)));
	// lfs f14,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,2880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2880);
	ctx.f18.f64 = double(temp.f32);
	// lfs f24,2872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2872);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f11
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// fmadds f18,f18,f14,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f14.f64 + ctx.f26.f64));
	// lfs f26,-208(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -208);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,996(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 996, temp.u32);
	// fmsubs f26,f16,f26,f19
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f26.f64 - ctx.f19.f64));
	// lfs f16,1192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1192);
	ctx.f16.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f25,f23,f28,f25
	ctx.f25.f64 = double(float(-(ctx.f23.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f23,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f16
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f16.f64));
	// lfs f14,1788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1788);
	ctx.f14.f64 = double(temp.f32);
	// lfs f16,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// lfs f19,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f27
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f27.f64));
	// fmadds f18,f16,f14,f18
	ctx.f18.f64 = double(float(ctx.f16.f64 * ctx.f14.f64 + ctx.f18.f64));
	// lfs f16,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f26,f24,f16,f26
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f16.f64 - ctx.f26.f64)));
	// lfs f16,676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 676);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f25,f22,f16,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f16.f64 - ctx.f25.f64)));
	// lfs f22,1272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1272);
	ctx.f22.f64 = double(temp.f32);
	// lfs f16,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f23,f22,f16,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f16.f64 + ctx.f23.f64));
	// lfs f22,3736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3736);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f13
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f13.f64));
	// fmuls f24,f19,f13
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f13.f64));
	// lfs f19,3784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3784);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f30
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// fmadds f18,f18,f11,f26
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64 + ctx.f26.f64));
	// lfs f26,2888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2888);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f16,f26,f11
	ctx.f16.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f25,f20,f28,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f20,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f23,f26,f20,f23
	ctx.f23.f64 = double(float(ctx.f26.f64 * ctx.f20.f64 + ctx.f23.f64));
	// lfs f26,552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 552);
	ctx.f26.f64 = double(temp.f32);
	// lfs f20,1164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1164);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f26
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// lfs f26,2896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2896);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f14,f26,f11
	ctx.f14.f64 = double(float(ctx.f26.f64 * ctx.f11.f64));
	// lfs f26,-196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -196);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,660(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fnmsubs f19,f19,f26,f18
	ctx.f19.f64 = double(float(-(ctx.f19.f64 * ctx.f26.f64 - ctx.f18.f64)));
	// lfs f26,3864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3864);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f26,f30
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f26,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f25,f17,f26,f25
	ctx.f25.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f25.f64));
	// lfs f17,3856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3856);
	ctx.f17.f64 = double(temp.f32);
	// lfs f26,-424(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -424);
	ctx.f26.f64 = double(temp.f32);
	// stfs f26,1892(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1892, temp.u32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// fmadds f26,f17,f26,f20
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f26.f64 + ctx.f20.f64));
	// lfs f20,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f20,f16,f20,f19
	ctx.f20.f64 = double(float(-(ctx.f16.f64 * ctx.f20.f64 - ctx.f19.f64)));
	// lfs f19,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f25,f15,f4,f25
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f4.f64 - ctx.f25.f64)));
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmadds f20,f14,f19,f20
	ctx.f20.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 + ctx.f20.f64));
	// stfs f20,4656(r1)
	temp.f32 = float(ctx.f20.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4656, temp.u32);
	// fnmsubs f25,f21,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fnmsubs f25,f24,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// fnmsubs f28,f22,f28,f25
	ctx.f28.f64 = double(float(-(ctx.f22.f64 * ctx.f28.f64 - ctx.f25.f64)));
	// lfs f25,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f28,f23,f0,f28
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f28.f64));
	// stfs f28,4652(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4652, temp.u32);
	// lfs f28,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// lfs f25,3792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3792);
	ctx.f25.f64 = double(temp.f32);
	// lfs f21,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// lfs f22,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f22.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f22,f22,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f21.f64));
	// lfs f21,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f28,f27,f21,f28
	ctx.f28.f64 = double(float(ctx.f27.f64 * ctx.f21.f64 + ctx.f28.f64));
	// lfs f24,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f24.f64 = double(temp.f32);
	// lfs f21,2904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2904);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f24,f24,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f27.f64));
	// lfs f19,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f21,f11
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// lfs f17,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f17.f64 = double(temp.f32);
	// lfs f27,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f27.f64 = double(temp.f32);
	// lfs f15,2920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2920);
	ctx.f15.f64 = double(temp.f32);
	// lfs f14,1788(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1788);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f27,f25,f27
	ctx.f27.f64 = double(float(ctx.f25.f64 * ctx.f27.f64));
	// lfs f23,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f13
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f13.f64));
	// lfs f25,1764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1764);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f22,f19,f17,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f17.f64 + ctx.f22.f64));
	// lfs f20,2912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2912);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f19,f28,f13
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f11
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// lfs f28,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f16,f28,f13
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f13.f64));
	// lfs f28,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f21,f21,f28
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// fmuls f24,f24,f13
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f13.f64));
	// fmuls f25,f25,f13
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fmadds f22,f15,f28,f22
	ctx.f22.f64 = double(float(ctx.f15.f64 * ctx.f28.f64 + ctx.f22.f64));
	// lfs f28,1740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1740);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f27,f19,f0,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfs f19,2928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2928);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f15,1904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1904);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f30
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f30.f64));
	// fmsubs f21,f17,f14,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 - ctx.f21.f64));
	// lfs f17,2936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2936);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 504);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f22,f17,f14,f22
	ctx.f22.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 + ctx.f22.f64));
	// lfs f17,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f27,f24,f0,f27
	ctx.f27.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// lfs f24,1320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1320);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f24,f17,f7,f24
	ctx.f24.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f14,3816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3816);
	ctx.f14.f64 = double(temp.f32);
	// lfs f17,3840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3840);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f19,f19,f30
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fmuls f14,f14,f30
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// lfs f30,1712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1712);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f28,f30
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f30,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f22,f22,f11,f21
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f21.f64));
	// lfs f21,2960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2960);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f27,f23,f30,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f30.f64 + ctx.f27.f64));
	// lfs f30,-460(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -460);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f26,f18,f30,f26
	ctx.f26.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 - ctx.f26.f64));
	// stfs f30,1712(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1712, temp.u32);
	// lfs f30,1136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1136);
	ctx.f30.f64 = double(temp.f32);
	// lfs f23,2952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2952);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f30
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// lfs f30,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f21,f21,f30
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64));
	// lfs f18,2968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2968);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f30,f28,f30
	ctx.f30.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// lfs f28,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f18,f11
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f11.f64));
	// fnmsubs f22,f15,f28,f22
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f28.f64 - ctx.f22.f64)));
	// lfs f28,2976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2976);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f7,f25,f7,f27
	ctx.f7.f64 = double(float(-(ctx.f25.f64 * ctx.f7.f64 - ctx.f27.f64)));
	// fmuls f25,f28,f11
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// lfs f11,1752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1752);
	ctx.f11.f64 = double(temp.f32);
	// lfs f28,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f27,f23,f11,f26
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f26.f64));
	// lfs f26,3800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3800);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f11,f31,f31
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f26,f26,f28
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f28.f64));
	// fmuls f11,f21,f11
	ctx.f11.f64 = double(float(ctx.f21.f64 * ctx.f11.f64));
	// fnmsubs f7,f20,f10,f7
	ctx.f7.f64 = double(float(-(ctx.f20.f64 * ctx.f10.f64 - ctx.f7.f64)));
	// lfs f23,996(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 996);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f23,f17,f23,f22
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f23.f64 + ctx.f22.f64));
	// lfs f22,500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 500);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f11,f11,f22,f27
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f22.f64 - ctx.f27.f64)));
	// lfs f27,340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	ctx.f27.f64 = double(temp.f32);
	// stfs f11,4660(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4660, temp.u32);
	// lfs f11,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f11.f64 = double(temp.f32);
	// lfs f21,3808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3808);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f28
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f28.f64));
	// lfs f28,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f28.f64 = double(temp.f32);
	// lfs f20,468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,1756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1756);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f7,f16,f27,f7
	ctx.f7.f64 = double(float(-(ctx.f16.f64 * ctx.f27.f64 - ctx.f7.f64)));
	// lfs f16,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f23,f18,f11,f23
	ctx.f23.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f23.f64)));
	// fmadds f7,f24,f13,f7
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f13.f64 + ctx.f7.f64));
	// fnmsubs f11,f25,f11,f23
	ctx.f11.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f23.f64)));
	// stfs f11,4664(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4664, temp.u32);
	// lfs f11,352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	ctx.f11.f64 = double(temp.f32);
	// lfs f25,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f7,f19,f11,f7
	ctx.f7.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f7.f64));
	// lfs f19,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f7,f14,f25,f7
	ctx.f7.f64 = double(float(-(ctx.f14.f64 * ctx.f25.f64 - ctx.f7.f64)));
	// lfs f14,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f11,f30,f11,f7
	ctx.f11.f64 = double(float(-(ctx.f30.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// lfs f7,1252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1252);
	ctx.f7.f64 = double(temp.f32);
	// lfs f30,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f26,f26,f7,f11
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f11.f64)));
	// lfs f7,3824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3824);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f24,f7,f13
	ctx.f24.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f11,1288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1288);
	ctx.f11.f64 = double(temp.f32);
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f11,f13
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmuls f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f7,3832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3832);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f7,f13
	ctx.f23.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f25,f25,f28
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f28.f64));
	// lfs f28,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f28,f20
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f20.f64));
	// lfs f28,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f28,f28,f31
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fmuls f22,f30,f7
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// fmuls f18,f11,f13
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f11,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f25,f25,f0
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// fmuls f20,f20,f13
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f13.f64));
	// fmuls f19,f28,f19
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// fmuls f22,f22,f11
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f11.f64));
	// fmsubs f25,f24,f27,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f27.f64 - ctx.f25.f64));
	// lfs f24,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f7
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// lfs f7,1724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	ctx.f7.f64 = double(temp.f32);
	// fmsubs f22,f19,f11,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 - ctx.f22.f64));
	// lfs f19,1748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1748);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f17,f16,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f16.f64 + ctx.f19.f64));
	// lfs f16,2992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2992);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f7,f13
	ctx.f17.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,2984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2984);
	ctx.f7.f64 = double(temp.f32);
	// fadds f16,f7,f16
	ctx.f16.f64 = double(float(ctx.f7.f64 + ctx.f16.f64));
	// lfs f7,3000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3000);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f15,f7,f13
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// lfs f7,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f25,f18,f0,f25
	ctx.f25.f64 = double(float(ctx.f18.f64 * ctx.f0.f64 + ctx.f25.f64));
	// fmadds f22,f7,f14,f22
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f14.f64 + ctx.f22.f64));
	// lfs f7,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f14,f7,f30
	ctx.f14.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// lfs f7,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// lfs f30,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f30.f64 = double(temp.f32);
	// stfs f7,1272(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1272, temp.u32);
	// fmadds f7,f30,f7,f24
	ctx.f7.f64 = double(float(ctx.f30.f64 * ctx.f7.f64 + ctx.f24.f64));
	// lfs f30,3008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3008);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f30,f13
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f13.f64));
	// lfs f30,3016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3016);
	ctx.f30.f64 = double(temp.f32);
	// fadds f18,f16,f30
	ctx.f18.f64 = double(float(ctx.f16.f64 + ctx.f30.f64));
	// lfs f16,3024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3024);
	ctx.f16.f64 = double(temp.f32);
	// lfs f30,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f22,f16,f30,f22
	ctx.f22.f64 = double(float(-(ctx.f16.f64 * ctx.f30.f64 - ctx.f22.f64)));
	// fnmsubs f27,f23,f27,f25
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f27.f64 - ctx.f25.f64)));
	// lfs f23,2092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2092);
	ctx.f23.f64 = double(temp.f32);
	// lfs f25,1064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1064);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f7,f7,f11,f22
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f11.f64 + ctx.f22.f64));
	// fmuls f25,f23,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f25.f64));
	// lfs f23,3040(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3040);
	ctx.f23.f64 = double(temp.f32);
	// fadds f23,f18,f23
	ctx.f23.f64 = double(float(ctx.f18.f64 + ctx.f23.f64));
	// lfs f18,1060(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1060);
	ctx.f18.f64 = double(temp.f32);
	// lfs f22,3048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3048);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f22,f18
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f18.f64));
	// lfs f18,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f18.f64 = double(temp.f32);
	// lfs f16,3032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3032);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f13
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f13.f64));
	// fmadds f27,f21,f18,f27
	ctx.f27.f64 = double(float(ctx.f21.f64 * ctx.f18.f64 + ctx.f27.f64));
	// lfs f18,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f7,f14,f2,f7
	ctx.f7.f64 = double(float(-(ctx.f14.f64 * ctx.f2.f64 - ctx.f7.f64)));
	// fnmsubs f0,f20,f0,f27
	ctx.f0.f64 = double(float(-(ctx.f20.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// lfs f27,3064(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3064);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f7,f23,f29,f7
	ctx.f7.f64 = double(float(ctx.f23.f64 * ctx.f29.f64 + ctx.f7.f64));
	// lfs f20,1240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1240);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f0,f19,f13,f0
	ctx.f0.f64 = double(float(ctx.f19.f64 * ctx.f13.f64 + ctx.f0.f64));
	// lfs f13,3056(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3056);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f13,f13,f29,f7
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// lfs f7,712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 712);
	ctx.f7.f64 = double(temp.f32);
	// lfs f19,2108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2108);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f0,f17,f7,f0
	ctx.f0.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f0.f64)));
	// lfs f7,1804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1804);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f13,f27,f7,f13
	ctx.f13.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f13.f64)));
	// lfs f27,3072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3072);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f0,f15,f10,f0
	ctx.f0.f64 = double(float(-(ctx.f15.f64 * ctx.f10.f64 - ctx.f0.f64)));
	// fnmsubs f13,f27,f7,f13
	ctx.f13.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f13.f64)));
	// lfs f27,3080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3080);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f0,f24,f10,f0
	ctx.f0.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f0.f64));
	// fnmsubs f27,f27,f30,f13
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f30.f64 - ctx.f13.f64)));
	// fnmsubs f13,f16,f10,f0
	ctx.f13.f64 = double(float(-(ctx.f16.f64 * ctx.f10.f64 - ctx.f0.f64)));
	// lfs f0,420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 420);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f13,f25,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f25,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f0,f22,f0,f13
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,3096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3096);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f26,f0
	ctx.f0.f64 = double(float(ctx.f26.f64 + ctx.f0.f64));
	// stfs f0,4668(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4668, temp.u32);
	// lfs f0,3088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3088);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// lfs f26,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f26.f64 = double(temp.f32);
	// fmsubs f13,f13,f2,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 - ctx.f0.f64));
	// lfs f0,1720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1720);
	ctx.f0.f64 = double(temp.f32);
	// fnmsubs f26,f26,f0,f13
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f13,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f24,f25,f13
	ctx.f24.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f13,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// lfs f25,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f25,f13
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f13,3104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3104);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f2,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f26.f64));
	// lfs f26,3112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3112);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f26,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f26,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f28,f28,f26
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f26,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f26,f26,f0,f13
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmuls f13,f31,f31
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmuls f22,f25,f13
	ctx.f22.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f13,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f13.f64 = double(temp.f32);
	// lfs f25,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f21,f25,f13
	ctx.f21.f64 = double(float(ctx.f25.f64 * ctx.f13.f64));
	// lfs f13,3120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3120);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f27,f13,f30,f27
	ctx.f27.f64 = double(float(ctx.f13.f64 * ctx.f30.f64 + ctx.f27.f64));
	// lfs f13,3128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3128);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f26,f13,f2,f26
	ctx.f26.f64 = double(float(ctx.f13.f64 * ctx.f2.f64 + ctx.f26.f64));
	// lfs f13,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fmuls f21,f21,f2
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f2.f64));
	// fadds f13,f20,f13
	ctx.f13.f64 = double(float(ctx.f20.f64 + ctx.f13.f64));
	// lfs f20,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f20.f64));
	// lfs f19,3136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3136);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f27,f19,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f19.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f19,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f18.f64));
	// lfs f18,3144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3144);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f26,f18,f2,f26
	ctx.f26.f64 = double(float(-(ctx.f18.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// lfs f18,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f21,f13,f1,f21
	ctx.f21.f64 = double(float(ctx.f13.f64 * ctx.f1.f64 + ctx.f21.f64));
	// lfs f13,3152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3152);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f27,f13,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f13.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f13,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f13.f64 = double(temp.f32);
	// lfs f17,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f17.f64 = double(temp.f32);
	// lfs f16,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f16.f64 = double(temp.f32);
	// lfs f14,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f26,f13,f18,f26
	ctx.f26.f64 = double(float(-(ctx.f13.f64 * ctx.f18.f64 - ctx.f26.f64)));
	// lfs f13,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f21,f20,f13,f21
	ctx.f21.f64 = double(float(-(ctx.f20.f64 * ctx.f13.f64 - ctx.f21.f64)));
	// lfs f20,3160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3160);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f20,f20,f29,f27
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 + ctx.f27.f64));
	// lfs f18,412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 412);
	ctx.f18.f64 = double(temp.f32);
	// lfs f27,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f27,f27,f18,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f18.f64 + ctx.f26.f64));
	// lfs f26,3168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3168);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f27,f26,f2,f27
	ctx.f27.f64 = double(float(-(ctx.f26.f64 * ctx.f2.f64 - ctx.f27.f64)));
	// lfs f26,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f0,f26,f0,f27
	ctx.f0.f64 = double(float(ctx.f26.f64 * ctx.f0.f64 + ctx.f27.f64));
	// lfs f27,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f15,f15,f26
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f26.f64));
	// fmadds f0,f27,f30,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 * ctx.f30.f64 + ctx.f0.f64));
	// lfs f30,3176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3176);
	ctx.f30.f64 = double(temp.f32);
	// lfs f27,1264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1264);
	ctx.f27.f64 = double(temp.f32);
	// fnmsubs f0,f30,f2,f0
	ctx.f0.f64 = double(float(-(ctx.f30.f64 * ctx.f2.f64 - ctx.f0.f64)));
	// lfs f30,1196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1196);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f0,f24,f11,f0
	ctx.f0.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f0.f64));
	// lfs f24,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f16,f24
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f24.f64));
	// fnmsubs f0,f23,f11,f0
	ctx.f0.f64 = double(float(-(ctx.f23.f64 * ctx.f11.f64 - ctx.f0.f64)));
	// fnmsubs f0,f30,f27,f0
	ctx.f0.f64 = double(float(-(ctx.f30.f64 * ctx.f27.f64 - ctx.f0.f64)));
	// lfs f27,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f27.f64 = double(temp.f32);
	// lfs f30,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f0,f28,f11,f0
	ctx.f0.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 + ctx.f0.f64));
	// lfs f11,1204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1204);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f0,f22,f27,f0
	ctx.f0.f64 = double(float(ctx.f22.f64 * ctx.f27.f64 + ctx.f0.f64));
	// fmadds f0,f11,f30,f0
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f30.f64 + ctx.f0.f64));
	// lfs f30,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f30.f64 = double(temp.f32);
	// lfs f11,848(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 848);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f22,f30,f26
	ctx.f22.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// fadds f0,f20,f0
	ctx.f0.f64 = double(float(ctx.f20.f64 + ctx.f0.f64));
	// stfs f0,4672(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4672, temp.u32);
	// lfs f0,1772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1772);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f28,f0,f30
	ctx.f28.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// lfs f0,2100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2100);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f23,f1,f0
	ctx.f23.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f0,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f20,f11,f0
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// lfs f11,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f18,f11,f24
	ctx.f18.f64 = double(float(ctx.f11.f64 * ctx.f24.f64));
	// lfs f11,1796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1796);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f21,f19,f11,f21
	ctx.f21.f64 = double(float(-(ctx.f19.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// lfs f11,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f24,f14,f24
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f24.f64));
	// lfs f14,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f19,f28,f11
	ctx.f19.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// lfs f28,2260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2260);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// fmuls f25,f28,f25
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f25.f64));
	// fmadds f23,f23,f27,f19
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f27.f64 + ctx.f19.f64));
	// lfs f19,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f14,f19
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f19.f64));
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f21,f17,f11,f21
	ctx.f21.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// fmuls f17,f15,f11
	ctx.f17.f64 = double(float(ctx.f15.f64 * ctx.f11.f64));
	// fmuls f15,f28,f30
	ctx.f15.f64 = double(float(ctx.f28.f64 * ctx.f30.f64));
	// fmsubs f23,f22,f14,f23
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f14.f64 - ctx.f23.f64));
	// lfs f22,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f19,f22
	ctx.f22.f64 = double(float(ctx.f19.f64 * ctx.f22.f64));
	// lfs f19,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f26,f26,f19,f21
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f19.f64 + ctx.f21.f64));
	// lfs f21,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f30,f21
	ctx.f21.f64 = double(float(ctx.f30.f64 * ctx.f21.f64));
	// fnmsubs f25,f25,f11,f26
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f11.f64 - ctx.f26.f64)));
	// lfs f26,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f31,f26
	ctx.f26.f64 = double(float(ctx.f31.f64 * ctx.f26.f64));
	// lfs f14,1504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1504);
	ctx.f14.f64 = double(temp.f32);
	// fmsubs f19,f19,f0,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f0.f64 - ctx.f17.f64));
	// lfs f17,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f23,f20,f27,f23
	ctx.f23.f64 = double(float(-(ctx.f20.f64 * ctx.f27.f64 - ctx.f23.f64)));
	// lfs f20,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// lfs f14,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f14,f30,f14
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f14.f64));
	// fmuls f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// fmadds f20,f15,f11,f19
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f19.f64));
	// lfs f19,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f28,f28,f19
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64));
	// lfs f15,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f15.f64 = double(temp.f32);
	// lfs f19,2252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2252);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f15,f19
	ctx.f19.f64 = double(float(ctx.f15.f64 * ctx.f19.f64));
	// lfs f15,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f23,f18,f15,f23
	ctx.f23.f64 = double(float(-(ctx.f18.f64 * ctx.f15.f64 - ctx.f23.f64)));
	// lfs f18,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f25,f21,f18,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f18.f64 - ctx.f25.f64)));
	// lfs f18,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f18.f64 = double(temp.f32);
	// lfs f21,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f21,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f18.f64));
	// lfs f18,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f18.f64 = double(temp.f32);
	// lfs f15,1176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1176);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f20,f14,f18,f20
	ctx.f20.f64 = double(float(-(ctx.f14.f64 * ctx.f18.f64 - ctx.f20.f64)));
	// lfs f14,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f15,f15,f14,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f14.f64 + ctx.f28.f64));
	// lfs f28,-240(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + -240);
	ctx.f28.f64 = double(temp.f32);
	// lfs f14,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f14.f64 = double(temp.f32);
	// lfs f18,3184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3184);
	ctx.f18.f64 = double(temp.f32);
	// fmadds f23,f16,f28,f23
	ctx.f23.f64 = double(float(ctx.f16.f64 * ctx.f28.f64 + ctx.f23.f64));
	// lfs f16,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// lfs f14,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f26,f26,f14,f25
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f14.f64 - ctx.f25.f64)));
	// lfs f14,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f14.f64 = double(temp.f32);
	// lfs f25,480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 480);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f18,f1,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f18.f64));
	// fmuls f25,f14,f25
	ctx.f25.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f14,1796(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1796);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f21,f21,f14,f20
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f14.f64 - ctx.f20.f64)));
	// lfs f14,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f14.f64 = double(temp.f32);
	// lfs f20,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f14
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f14.f64));
	// lfs f14,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f24,f24,f14,f23
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f14.f64 - ctx.f23.f64)));
	// lfs f23,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f26,f15,f11,f26
	ctx.f26.f64 = double(float(ctx.f15.f64 * ctx.f11.f64 + ctx.f26.f64));
	// fnmsubs f23,f16,f23,f21
	ctx.f23.f64 = double(float(-(ctx.f16.f64 * ctx.f23.f64 - ctx.f21.f64)));
	// lfs f21,1772(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1772);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f21,f21,f11,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f20.f64));
	// lfs f20,1048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1048);
	ctx.f20.f64 = double(temp.f32);
	// fmadds f24,f22,f11,f24
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f24.f64));
	// lfs f22,1256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1256);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f23,f25,f22,f23
	ctx.f23.f64 = double(float(-(ctx.f25.f64 * ctx.f22.f64 - ctx.f23.f64)));
	// fmadds f28,f17,f28,f24
	ctx.f28.f64 = double(float(ctx.f17.f64 * ctx.f28.f64 + ctx.f24.f64));
	// lfs f24,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f24.f64 = double(temp.f32);
	// lfs f17,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f28,f19,f13,f28
	ctx.f28.f64 = double(float(-(ctx.f19.f64 * ctx.f13.f64 - ctx.f28.f64)));
	// lfs f19,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f19.f64 = double(temp.f32);
	// fadds f20,f19,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 + ctx.f20.f64));
	// lfs f19,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f9
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// fmadds f28,f18,f27,f28
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f27.f64 + ctx.f28.f64));
	// lfs f18,2244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2244);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// fadds f22,f26,f28
	ctx.f22.f64 = double(float(ctx.f26.f64 + ctx.f28.f64));
	// lfs f28,3192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3192);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f26,f1,f28
	ctx.f26.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f28,1512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1512);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f25,f28,f0
	ctx.f25.f64 = double(float(ctx.f28.f64 * ctx.f0.f64));
	// lfs f28,1308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1308);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f24,f28,f24
	ctx.f24.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// fmsubs f26,f26,f2,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f25.f64));
	// lfs f25,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f24,f25
	ctx.f17.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// lfs f24,3200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3200);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f16,f9,f24
	ctx.f16.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// lfs f24,544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 544);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f28,f9,f28
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fmuls f19,f19,f24
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// lfs f24,2108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2108);
	ctx.f24.f64 = double(temp.f32);
	// lfs f15,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f24
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f24.f64));
	// lfs f24,1072(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1072);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f26,f1,f24,f26
	ctx.f26.f64 = double(float(-(ctx.f1.f64 * ctx.f24.f64 - ctx.f26.f64)));
	// lfs f24,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f20,f20,f24,f17
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f24.f64 + ctx.f17.f64));
	// lfs f17,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f17.f64 = double(temp.f32);
	// lfs f14,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f28,f17
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f17.f64));
	// lfs f28,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f19,f16,f28,f19
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f28.f64 - ctx.f19.f64));
	// lfs f28,508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 508);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f18,f18,f13,f26
	ctx.f18.f64 = double(float(-(ctx.f18.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// lfs f26,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f20,f26,f28,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 * ctx.f28.f64 + ctx.f20.f64));
	// lfs f26,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f9,f26
	ctx.f26.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// lfs f28,3208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3208);
	ctx.f28.f64 = double(temp.f32);
	// stfs f26,760(r1)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 760, temp.u32);
	// fnmsubs f19,f17,f25,f19
	ctx.f19.f64 = double(float(-(ctx.f17.f64 * ctx.f25.f64 - ctx.f19.f64)));
	// lfs f25,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f25.f64 = double(temp.f32);
	// lfs f17,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f18,f15,f13,f18
	ctx.f18.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f18.f64)));
	// lfs f15,3216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3216);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f20,f25,f17,f20
	ctx.f20.f64 = double(float(ctx.f25.f64 * ctx.f17.f64 + ctx.f20.f64));
	// lfs f25,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f16,f28,f26
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f28,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f28,f14
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f14.f64));
	// lfs f17,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f23,f21,f25,f23
	ctx.f23.f64 = double(float(ctx.f21.f64 * ctx.f25.f64 + ctx.f23.f64));
	// lfs f25,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f15,f15,f28
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f28.f64));
	// fmadds f20,f20,f9,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f9.f64 + ctx.f19.f64));
	// lfs f19,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f30,f19
	ctx.f19.f64 = double(float(ctx.f30.f64 * ctx.f19.f64));
	// lfs f30,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f31
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// fmuls f21,f14,f25
	ctx.f21.f64 = double(float(ctx.f14.f64 * ctx.f25.f64));
	// lfs f14,3224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3224);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f18,f1,f14,f18
	ctx.f18.f64 = double(float(ctx.f1.f64 * ctx.f14.f64 + ctx.f18.f64));
	// lfs f25,1544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1544);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f17,f17,f25
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f25.f64));
	// fmadds f23,f30,f0,f23
	ctx.f23.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f23.f64));
	// lfs f30,1144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1144);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f30,f25
	ctx.f25.f64 = double(float(ctx.f30.f64 * ctx.f25.f64));
	// lfs f30,3232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3232);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f26,f30,f26
	ctx.f26.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// lfs f30,740(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 740);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f18,f30,f0,f18
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f0.f64 + ctx.f18.f64));
	// lfs f30,320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f20,f16,f30,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f30.f64 + ctx.f20.f64));
	// lfs f16,3240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3240);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f28
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f28.f64));
	// fmadds f27,f19,f27,f23
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f27.f64 + ctx.f23.f64));
	// lfs f23,3248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3248);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f28,f28,f23
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f23.f64));
	// lfs f23,3256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3256);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f23,f1,f23,f18
	ctx.f23.f64 = double(float(-(ctx.f1.f64 * ctx.f23.f64 - ctx.f18.f64)));
	// fnmsubs f21,f21,f12,f20
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f12.f64 - ctx.f20.f64)));
	// fadds f27,f22,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 + ctx.f27.f64));
	// fmadds f23,f17,f13,f23
	ctx.f23.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f23.f64));
	// fnmsubs f22,f15,f30,f21
	ctx.f22.f64 = double(float(-(ctx.f15.f64 * ctx.f30.f64 - ctx.f21.f64)));
	// fnmsubs f13,f25,f13,f23
	ctx.f13.f64 = double(float(-(ctx.f25.f64 * ctx.f13.f64 - ctx.f23.f64)));
	// lfs f25,1520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1520);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f26,f26,f30,f22
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f30.f64 - ctx.f22.f64)));
	// fnmsubs f0,f25,f0,f13
	ctx.f0.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// fmadds f13,f16,f30,f26
	ctx.f13.f64 = double(float(ctx.f16.f64 * ctx.f30.f64 + ctx.f26.f64));
	// fadds f0,f27,f0
	ctx.f0.f64 = double(float(ctx.f27.f64 + ctx.f0.f64));
	// stfs f0,4676(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4676, temp.u32);
	// fnmsubs f28,f28,f30,f13
	ctx.f28.f64 = double(float(-(ctx.f28.f64 * ctx.f30.f64 - ctx.f13.f64)));
	// lfs f13,1552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1552);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,3264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3264);
	ctx.f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f13,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f27,f13,f12
	ctx.f27.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f13,1632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1632);
	ctx.f13.f64 = double(temp.f32);
	// lfs f30,1640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1640);
	ctx.f30.f64 = double(temp.f32);
	// fadds f26,f13,f30
	ctx.f26.f64 = double(float(ctx.f13.f64 + ctx.f30.f64));
	// lfs f13,516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	ctx.f13.f64 = double(temp.f32);
	// lfs f30,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f25,1648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1648);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// lfs f23,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f23.f64 = double(temp.f32);
	// lfs f22,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f27,f22,f23,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f23.f64 + ctx.f27.f64));
	// lfs f20,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,3312(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3312);
	ctx.f19.f64 = double(temp.f32);
	// lfs f17,3328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3328);
	ctx.f17.f64 = double(temp.f32);
	// lfs f23,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f9,f23
	ctx.f23.f64 = double(float(ctx.f9.f64 * ctx.f23.f64));
	// lfs f16,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f16.f64 = double(temp.f32);
	// lfs f22,3272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3272);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f26,f26,f12,f0
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f0.f64));
	// lfs f0,3280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3280);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f22,f22,f8
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f8.f64));
	// lfs f21,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f24.f64));
	// lfs f24,3288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3288);
	ctx.f24.f64 = double(temp.f32);
	// fadds f24,f0,f24
	ctx.f24.f64 = double(float(ctx.f0.f64 + ctx.f24.f64));
	// lfs f0,1212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1212);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f27,f0,f20,f27
	ctx.f27.f64 = double(float(ctx.f0.f64 * ctx.f20.f64 + ctx.f27.f64));
	// lfs f0,3296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3296);
	ctx.f0.f64 = double(temp.f32);
	// lfs f20,916(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 916);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f21,f9,f21
	ctx.f21.f64 = double(float(ctx.f9.f64 * ctx.f21.f64));
	// fmuls f20,f0,f20
	ctx.f20.f64 = double(float(ctx.f0.f64 * ctx.f20.f64));
	// lfs f0,3304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3304);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f19,f0,f19
	ctx.f19.f64 = double(float(ctx.f0.f64 * ctx.f19.f64));
	// lfs f0,3320(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3320);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f18,f9,f0
	ctx.f18.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	// lfs f0,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f0.f64 = double(temp.f32);
	// lfs f14,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f26,f17,f0,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f0.f64 + ctx.f26.f64));
	// lfs f15,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f15.f64 = double(temp.f32);
	// lfs f17,3336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3336);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f8
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f8.f64));
	// fmuls f27,f27,f9
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fmadds f24,f24,f16,f20
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64 + ctx.f20.f64));
	// lfs f16,1656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1656);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f30
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f30.f64));
	// lfs f20,3344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3344);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f9,f20
	ctx.f20.f64 = double(float(ctx.f9.f64 * ctx.f20.f64));
	// fmsubs f26,f26,f8,f25
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64 - ctx.f25.f64));
	// lfs f25,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f25.f64 = double(temp.f32);
	// fmsubs f27,f23,f25,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f25.f64 - ctx.f27.f64));
	// lfs f25,1664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1664);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// lfs f30,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f12,f24
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f12.f64 + ctx.f24.f64));
	// lfs f23,1672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1672);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,3352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3352);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f24,f9,f24
	ctx.f24.f64 = double(float(ctx.f9.f64 * ctx.f24.f64));
	// fnmsubs f26,f22,f13,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f13.f64 - ctx.f26.f64)));
	// lfs f22,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f27,f21,f22,f27
	ctx.f27.f64 = double(float(-(ctx.f21.f64 * ctx.f22.f64 - ctx.f27.f64)));
	// lfs f22,1780(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1780);
	ctx.f22.f64 = double(temp.f32);
	// lfs f21,3368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3368);
	ctx.f21.f64 = double(temp.f32);
	// fadds f22,f30,f22
	ctx.f22.f64 = double(float(ctx.f30.f64 + ctx.f22.f64));
	// lfs f30,3360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3360);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f21,f15,f21
	ctx.f21.f64 = double(float(ctx.f15.f64 * ctx.f21.f64));
	// lfs f15,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f9,f15
	ctx.f15.f64 = double(float(ctx.f9.f64 * ctx.f15.f64));
	// fnmsubs f26,f19,f14,f26
	ctx.f26.f64 = double(float(-(ctx.f19.f64 * ctx.f14.f64 - ctx.f26.f64)));
	// lfs f19,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f27,f18,f19,f27
	ctx.f27.f64 = double(float(-(ctx.f18.f64 * ctx.f19.f64 - ctx.f27.f64)));
	// lfs f18,1680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1680);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,3376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3376);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f8
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f8.f64));
	// fmadds f18,f18,f13,f30
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f13.f64 + ctx.f30.f64));
	// lfs f30,1688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1688);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f14,f30,f8
	ctx.f14.f64 = double(float(ctx.f30.f64 * ctx.f8.f64));
	// lfs f30,776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 776);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f21,f21,f30,f28
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f30.f64 + ctx.f28.f64));
	// lfs f30,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f26,f17,f13,f26
	ctx.f26.f64 = double(float(ctx.f17.f64 * ctx.f13.f64 + ctx.f26.f64));
	// fnmsubs f27,f20,f30,f27
	ctx.f27.f64 = double(float(-(ctx.f20.f64 * ctx.f30.f64 - ctx.f27.f64)));
	// lfs f28,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f26,f16,f28,f26
	ctx.f26.f64 = double(float(-(ctx.f16.f64 * ctx.f28.f64 - ctx.f26.f64)));
	// lfs f20,1704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1704);
	ctx.f20.f64 = double(temp.f32);
	// lfs f16,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f16.f64 = double(temp.f32);
	// lfs f17,492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,1336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1336);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f22,f9,f27
	ctx.f27.f64 = double(float(ctx.f22.f64 * ctx.f9.f64 + ctx.f27.f64));
	// fnmsubs f26,f25,f28,f26
	ctx.f26.f64 = double(float(-(ctx.f25.f64 * ctx.f28.f64 - ctx.f26.f64)));
	// lfs f25,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f30,f24,f30,f27
	ctx.f30.f64 = double(float(-(ctx.f24.f64 * ctx.f30.f64 - ctx.f27.f64)));
	// fnmsubs f27,f23,f12,f26
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f26.f64)));
	// lfs f26,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f25,f26
	ctx.f23.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f26,460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	ctx.f26.f64 = double(temp.f32);
	// lfs f25,684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 684);
	ctx.f25.f64 = double(temp.f32);
	// fnmsubs f30,f15,f13,f30
	ctx.f30.f64 = double(float(-(ctx.f15.f64 * ctx.f13.f64 - ctx.f30.f64)));
	// lfs f15,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f27,f18,f8,f27
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f8.f64 + ctx.f27.f64));
	// lfs f18,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f18.f64 = double(temp.f32);
	// fadds f30,f21,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 + ctx.f30.f64));
	// stfs f30,4680(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4680, temp.u32);
	// lfs f30,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f24,f19,f0,f27
	ctx.f24.f64 = double(float(-(ctx.f19.f64 * ctx.f0.f64 - ctx.f27.f64)));
	// fmuls f27,f30,f31
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// lfs f30,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f22,f26,f30
	ctx.f22.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// lfs f26,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f26.f64 = double(temp.f32);
	// lfs f21,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f21.f64 = double(temp.f32);
	// lfs f19,1480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1480);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f24,f14,f12,f24
	ctx.f24.f64 = double(float(-(ctx.f14.f64 * ctx.f12.f64 - ctx.f24.f64)));
	// lfs f14,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmadds f22,f16,f15,f22
	ctx.f22.f64 = double(float(ctx.f16.f64 * ctx.f15.f64 + ctx.f22.f64));
	// lfs f15,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f16.f64 = double(temp.f32);
	// fmadds f27,f26,f25,f27
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f25.f64 + ctx.f27.f64));
	// lfs f26,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f21,f21,f26
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64));
	// lfs f26,1696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1696);
	ctx.f26.f64 = double(temp.f32);
	// fadds f20,f26,f20
	ctx.f20.f64 = double(float(ctx.f26.f64 + ctx.f20.f64));
	// lfs f26,1524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1524);
	ctx.f26.f64 = double(temp.f32);
	// fadds f19,f26,f19
	ctx.f19.f64 = double(float(ctx.f26.f64 + ctx.f19.f64));
	// lfs f26,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f18,f26,f18
	ctx.f18.f64 = double(float(ctx.f26.f64 * ctx.f18.f64));
	// fmadds f16,f15,f16,f27
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64 + ctx.f27.f64));
	// lfs f27,3384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3384);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f30
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f27,1488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1488);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fadds f19,f19,f27
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f27.f64));
	// lfs f27,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f31,f27
	ctx.f27.f64 = double(float(ctx.f31.f64 * ctx.f27.f64));
	// fmsubs f20,f17,f29,f20
	ctx.f20.f64 = double(float(ctx.f17.f64 * ctx.f29.f64 - ctx.f20.f64));
	// lfs f17,1496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1496);
	ctx.f17.f64 = double(temp.f32);
	// fadds f19,f19,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,1528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1528);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f27,f27,f25
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f25.f64));
	// fmuls f25,f16,f29
	ctx.f25.f64 = double(float(ctx.f16.f64 * ctx.f29.f64));
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f17,f17,f16
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f16.f64));
	// lfs f16,1348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f14
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f14.f64));
	// lfs f14,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f19,f11,f20
	ctx.f20.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f20.f64));
	// lfs f19,648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 648);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f25,f23,f29,f25
	ctx.f25.f64 = double(float(ctx.f23.f64 * ctx.f29.f64 - ctx.f25.f64));
	// lfs f23,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f19,f14,f19,f17
	ctx.f19.f64 = double(float(ctx.f14.f64 * ctx.f19.f64 + ctx.f17.f64));
	// lfs f17,1080(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1080);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f28,f16,f28,f24
	ctx.f28.f64 = double(float(-(ctx.f16.f64 * ctx.f28.f64 - ctx.f24.f64)));
	// lfs f24,1660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f26,f26,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f23.f64));
	// lfs f14,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f14.f64 = double(temp.f32);
	// lfs f23,3392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3392);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f17,f17,f14
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f14.f64));
	// lfs f16,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fnmsubs f25,f24,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f24.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// lfs f24,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f16
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f16.f64));
	// lfs f16,1356(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1356);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f20,f16,f11,f20
	ctx.f20.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f20.f64)));
	// lfs f11,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f11.f64 = double(temp.f32);
	// lfs f16,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f28,f23,f0,f28
	ctx.f28.f64 = double(float(-(ctx.f23.f64 * ctx.f0.f64 - ctx.f28.f64)));
	// fmuls f16,f11,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f16.f64));
	// lfs f11,3400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3400);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f14,f11,f8
	ctx.f14.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f11,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f25,f22,f11,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f11.f64 + ctx.f25.f64));
	// lfs f23,1536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1536);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 * ctx.f30.f64));
	// lfs f22,988(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 988);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f23,f19,f29,f20
	ctx.f23.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f20.f64));
	// lfs f20,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f22,f22,f20
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f20.f64));
	// lfs f19,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f19.f64 = double(temp.f32);
	// lfs f20,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f28,f14,f13,f28
	ctx.f28.f64 = double(float(-(ctx.f14.f64 * ctx.f13.f64 - ctx.f28.f64)));
	// stfs f28,4684(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4684, temp.u32);
	// fnmsubs f25,f21,f29,f25
	ctx.f25.f64 = double(float(-(ctx.f21.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// lfs f14,424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	ctx.f14.f64 = double(temp.f32);
	// fmadds f20,f20,f19,f16
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f19.f64 + ctx.f16.f64));
	// fnmsubs f28,f24,f29,f23
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f29.f64 - ctx.f23.f64)));
	// fnmsubs f25,f18,f29,f25
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f29.f64 - ctx.f25.f64)));
	// fmadds f24,f20,f29,f28
	ctx.f24.f64 = double(float(ctx.f20.f64 * ctx.f29.f64 + ctx.f28.f64));
	// fmadds f28,f15,f29,f25
	ctx.f28.f64 = double(float(ctx.f15.f64 * ctx.f29.f64 + ctx.f25.f64));
	// fnmsubs f28,f27,f29,f28
	ctx.f28.f64 = double(float(-(ctx.f27.f64 * ctx.f29.f64 - ctx.f28.f64)));
	// lfs f27,680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 680);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f28,f26,f29,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f29.f64 + ctx.f28.f64));
	// lfs f26,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f28,f17,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// fnmsubs f23,f30,f11,f28
	ctx.f23.f64 = double(float(-(ctx.f30.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// lfs f11,3408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3408);
	ctx.f11.f64 = double(temp.f32);
	// lfs f30,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f11
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// lfs f11,3416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3416);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f25,f11,f1
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// lfs f28,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f28.f64 = double(temp.f32);
	// lfs f11,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f21,f11,f28
	ctx.f21.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f11,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f11.f64 = double(temp.f32);
	// lfs f28,1296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1296);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f11,f28
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f28.f64));
	// lfs f11,632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 632);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f19,f27,f11
	ctx.f19.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fmuls f18,f30,f26
	ctx.f18.f64 = double(float(ctx.f30.f64 * ctx.f26.f64));
	// lfs f30,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f28,f30,f31
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f31.f64));
	// lfs f30,336(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 336);
	ctx.f30.f64 = double(temp.f32);
	// fmsubs f21,f21,f26,f18
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f26.f64 - ctx.f18.f64));
	// lfs f26,800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 800);
	ctx.f26.f64 = double(temp.f32);
	// fmadds f17,f28,f30,f25
	ctx.f17.f64 = double(float(ctx.f28.f64 * ctx.f30.f64 + ctx.f25.f64));
	// lfs f25,1280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1280);
	ctx.f25.f64 = double(temp.f32);
	// lfs f28,1272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1272);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f15,f25,f11
	ctx.f15.f64 = double(float(ctx.f25.f64 * ctx.f11.f64));
	// fmuls f16,f27,f28
	ctx.f16.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f11,692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 692);
	ctx.f11.f64 = double(temp.f32);
	// lfs f28,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f20,f11,f28,f20
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f28.f64 + ctx.f20.f64));
	// lfs f11,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// lfs f28,1076(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1076);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f18,f28,f26
	ctx.f18.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// lfs f26,1084(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1084);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f27,f27,f26
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f26.f64));
	// fmuls f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f26.f64));
	// lfs f25,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f21,f17,f7,f21
	ctx.f21.f64 = double(float(ctx.f17.f64 * ctx.f7.f64 + ctx.f21.f64));
	// lfs f17,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f17.f64 = double(temp.f32);
	// fmadds f25,f20,f25,f19
	ctx.f25.f64 = double(float(ctx.f20.f64 * ctx.f25.f64 + ctx.f19.f64));
	// lfs f19,1532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f17,f14,f19
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f14.f64 + ctx.f19.f64));
	// lfs f20,1460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1460);
	ctx.f20.f64 = double(temp.f32);
	// lfs f17,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f20,f1,f20
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// lfs f14,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// fnmsubs f21,f16,f7,f21
	ctx.f21.f64 = double(float(-(ctx.f16.f64 * ctx.f7.f64 - ctx.f21.f64)));
	// fnmsubs f25,f15,f11,f25
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// lfs f16,1208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1208);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f27,f27,f11,f25
	ctx.f27.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f25.f64)));
	// fmuls f16,f28,f16
	ctx.f16.f64 = double(float(ctx.f28.f64 * ctx.f16.f64));
	// lfs f15,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f28,f19,f28,f26
	ctx.f28.f64 = double(float(ctx.f19.f64 * ctx.f28.f64 + ctx.f26.f64));
	// lfs f19,1248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1248);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f19,f15,f17
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64 + ctx.f17.f64));
	// lfs f14,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f14.f64 = double(temp.f32);
	// lfs f15,1372(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f25,f18,f11,f21
	ctx.f25.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f21.f64)));
	// fmuls f15,f14,f15
	ctx.f15.f64 = double(float(ctx.f14.f64 * ctx.f15.f64));
	// lfs f21,3424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3424);
	ctx.f21.f64 = double(temp.f32);
	// lfs f18,3432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3432);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f21,f1
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64));
	// lfs f14,1644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f18,f18,f1
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f1.f64));
	// fmuls f14,f14,f1
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f1.f64));
	// lfs f1,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f1,f31
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// lfs f26,1364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	ctx.f26.f64 = double(temp.f32);
	// lfs f17,1620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f26,f26,f30
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f30.f64));
	// fmuls f17,f30,f17
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f17.f64));
	// fmadds f28,f28,f11,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64 + ctx.f27.f64));
	// fnmsubs f27,f20,f7,f25
	ctx.f27.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// lfs f25,1540(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1540);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// fnmsubs f30,f22,f29,f24
	ctx.f30.f64 = double(float(-(ctx.f22.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// lfs f24,1380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	ctx.f24.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// lfs f22,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f28,f16,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// lfs f11,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f11.f64 = double(temp.f32);
	// lfs f24,1088(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1088);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f27,f19,f11,f27
	ctx.f27.f64 = double(float(ctx.f19.f64 * ctx.f11.f64 + ctx.f27.f64));
	// lfs f19,1548(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1548);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f24,f22,f24,f15
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f24.f64 + ctx.f15.f64));
	// lfs f22,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f22.f64 = double(temp.f32);
	// fadds f30,f23,f30
	ctx.f30.f64 = double(float(ctx.f23.f64 + ctx.f30.f64));
	// stfs f30,4688(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4688, temp.u32);
	// lfs f23,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f25,f25,f6
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f6.f64));
	// fnmsubs f30,f17,f7,f28
	ctx.f30.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// fmadds f28,f26,f7,f27
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f27.f64));
	// fnmsubs f30,f18,f7,f30
	ctx.f30.f64 = double(float(-(ctx.f18.f64 * ctx.f7.f64 - ctx.f30.f64)));
	// lfs f18,1396(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1396);
	ctx.f18.f64 = double(temp.f32);
	// fadds f19,f19,f18
	ctx.f19.f64 = double(float(ctx.f19.f64 + ctx.f18.f64));
	// lfs f18,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f28,f21,f7,f28
	ctx.f28.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// fmadds f11,f24,f11,f30
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f30.f64));
	// fmadds f30,f14,f7,f28
	ctx.f30.f64 = double(float(ctx.f14.f64 * ctx.f7.f64 + ctx.f28.f64));
	// fnmsubs f7,f1,f7,f30
	ctx.f7.f64 = double(float(-(ctx.f1.f64 * ctx.f7.f64 - ctx.f30.f64)));
	// lfs f30,1684(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1684);
	ctx.f30.f64 = double(temp.f32);
	// fadds f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f7.f64));
	// stfs f11,4692(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4692, temp.u32);
	// lfs f7,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f7.f64 = double(temp.f32);
	// lfs f11,820(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f1,f11,f7
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f11,852(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f28,f11,f7
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f11,804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f27,f11,f7
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f11,528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 528);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f26,f11,f30
	ctx.f26.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f30,696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 696);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f24,f30,f7
	ctx.f24.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// lfs f7,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f23,f23,f7,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f1.f64));
	// lfs f1,1228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1228);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f1,f22
	ctx.f22.f64 = double(float(ctx.f1.f64 * ctx.f22.f64));
	// lfs f1,1152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1152);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f28,f1,f7,f28
	ctx.f28.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 + ctx.f28.f64));
	// lfs f1,1096(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1096);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f7,f1
	ctx.f21.f64 = double(float(ctx.f7.f64 * ctx.f1.f64));
	// lfs f1,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f11,f1
	ctx.f20.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// lfs f1,584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 584);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f26,f26,f1
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64));
	// fmuls f23,f23,f18
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f18.f64));
	// lfs f18,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f7
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f7.f64));
	// lfs f7,1628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	ctx.f7.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f17,f11,f7
	ctx.f17.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f7,1404(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	ctx.f7.f64 = double(temp.f32);
	// lfs f16,1556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1556);
	ctx.f16.f64 = double(temp.f32);
	// fmsubs f25,f25,f10,f23
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 - ctx.f23.f64));
	// fadds f16,f7,f16
	ctx.f16.f64 = double(float(ctx.f7.f64 + ctx.f16.f64));
	// lfs f7,-112(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + -112);
	ctx.f7.f64 = double(temp.f32);
	// lfs f15,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f15.f64 = double(temp.f32);
	// fmsubs f26,f22,f7,f26
	ctx.f26.f64 = double(float(ctx.f22.f64 * ctx.f7.f64 - ctx.f26.f64));
	// fmuls f19,f19,f15
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f15.f64));
	// lfs f15,-336(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -336);
	ctx.f15.f64 = double(temp.f32);
	// stfs f7,660(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stfs f15,324(r1)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lfs f7,728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 728);
	ctx.f7.f64 = double(temp.f32);
	// lfs f22,808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 808);
	ctx.f22.f64 = double(temp.f32);
	// lfs f15,1184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1184);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f22,f7,f22
	ctx.f22.f64 = double(float(ctx.f7.f64 * ctx.f22.f64));
	// fmuls f15,f7,f15
	ctx.f15.f64 = double(float(ctx.f7.f64 * ctx.f15.f64));
	// lfs f7,1412(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	ctx.f7.f64 = double(temp.f32);
	// lfs f14,1668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	ctx.f14.f64 = double(temp.f32);
	// fadds f14,f7,f14
	ctx.f14.f64 = double(float(ctx.f7.f64 + ctx.f14.f64));
	// lfs f7,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f7,f20,f7,f26
	ctx.f7.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// lfs f20,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f20.f64 = double(temp.f32);
	// lfs f26,764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f20
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f20.f64));
	// lfs f23,3440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3440);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f20,f16,f1,f19
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f1.f64 + ctx.f19.f64));
	// lfs f19,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f28,f28,f19,f25
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f19.f64 + ctx.f25.f64));
	// lfs f19,1148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1148);
	ctx.f19.f64 = double(temp.f32);
	// lfs f25,1792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1792);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f23,f11,f23
	ctx.f23.f64 = double(float(ctx.f11.f64 * ctx.f23.f64));
	// fadds f25,f25,f19
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f19.f64));
	// lfs f16,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f16.f64 = double(temp.f32);
	// lfs f19,3448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3448);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f16
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f16.f64));
	// lfs f16,3456(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3456);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f11,f16
	ctx.f16.f64 = double(float(ctx.f11.f64 * ctx.f16.f64));
	// fnmsubs f1,f17,f1,f7
	ctx.f1.f64 = double(float(-(ctx.f17.f64 * ctx.f1.f64 - ctx.f7.f64)));
	// lfs f7,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f7.f64 = double(temp.f32);
	// lfs f17,488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 488);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f14,f14,f6
	ctx.f14.f64 = double(float(ctx.f14.f64 * ctx.f6.f64));
	// fmuls f20,f20,f11
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f11.f64));
	// fnmsubs f28,f27,f7,f28
	ctx.f28.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// lfs f7,668(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 668);
	ctx.f7.f64 = double(temp.f32);
	// lfs f27,1276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1276);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f7,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f27.f64));
	// lfs f7,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fadds f17,f7,f17
	ctx.f17.f64 = double(float(ctx.f7.f64 + ctx.f17.f64));
	// lfs f7,816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 816);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f30,f30,f7
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// lfs f7,1420(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1420);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f11,f11,f7
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f7.f64));
	// lfs f7,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f23,f23,f7,f1
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f7.f64 + ctx.f1.f64));
	// lfs f1,612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 612);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f25,f1
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f1.f64));
	// lfs f1,360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	ctx.f1.f64 = double(temp.f32);
	// stfs f11,324(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmr f11,f1
	ctx.f11.f64 = ctx.f1.f64;
	// lfs f1,-480(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -480);
	ctx.f1.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmsubs f20,f16,f7,f20
	ctx.f20.f64 = double(float(ctx.f16.f64 * ctx.f7.f64 - ctx.f20.f64));
	// lfs f7,1092(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1092);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f28,f24,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f24.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// fmuls f24,f19,f1
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f1,700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 700);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f7,f1,f27
	ctx.f27.f64 = double(float(ctx.f7.f64 * ctx.f1.f64 + ctx.f27.f64));
	// lfs f7,-476(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -476);
	ctx.f7.f64 = double(temp.f32);
	// lfs f1,660(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 660);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f17,f6
	ctx.f19.f64 = double(float(ctx.f17.f64 * ctx.f6.f64));
	// stfs f7,440(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fmadds f26,f26,f1,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f23.f64));
	// fmuls f30,f30,f11
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fnmsubs f28,f21,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f21.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// fmsubs f7,f25,f7,f24
	ctx.f7.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 - ctx.f24.f64));
	// stfs f7,4704(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4704, temp.u32);
	// fmadds f7,f27,f1,f20
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f1.f64 + ctx.f20.f64));
	// stfs f7,4708(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4708, temp.u32);
	// lfs f27,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f27.f64 = double(temp.f32);
	// fmsubs f1,f19,f4,f30
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 - ctx.f30.f64));
	// lfs f7,940(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 940);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f7,f27,f7,f26
	ctx.f7.f64 = double(float(-(ctx.f27.f64 * ctx.f7.f64 - ctx.f26.f64)));
	// stfs f7,4700(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4700, temp.u32);
	// fnmsubs f7,f18,f11,f28
	ctx.f7.f64 = double(float(-(ctx.f18.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// lfs f30,732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 732);
	ctx.f30.f64 = double(temp.f32);
	// lfs f24,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f24.f64 = double(temp.f32);
	// lfs f20,1160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1160);
	ctx.f20.f64 = double(temp.f32);
	// fnmsubs f7,f22,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f22.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fnmsubs f7,f15,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fmadds f7,f14,f10,f7
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f10.f64 + ctx.f7.f64));
	// stfs f7,4696(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4696, temp.u32);
	// lfs f7,3464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3464);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f28,f6,f7
	ctx.f28.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,1564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f27,f30,f7
	ctx.f27.f64 = double(float(ctx.f30.f64 * ctx.f7.f64));
	// lfs f30,428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 428);
	ctx.f30.f64 = double(temp.f32);
	// lfs f7,600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 600);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f26,f7,f30
	ctx.f26.f64 = double(float(ctx.f7.f64 * ctx.f30.f64));
	// lfs f7,1468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1468);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmuls f25,f6,f7
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,1428(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1428);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f24,f24,f7
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f7.f64));
	// lfs f7,2236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2236);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f23,f6,f7
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fnmsubs f7,f28,f4,f1
	ctx.f7.f64 = double(float(-(ctx.f28.f64 * ctx.f4.f64 - ctx.f1.f64)));
	// lfs f1,1636(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f22,f6,f1
	ctx.f22.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f28,1104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	ctx.f28.f64 = double(temp.f32);
	// lfs f1,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f1,f28
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f1,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f1,f20
	ctx.f20.f64 = double(float(ctx.f1.f64 * ctx.f20.f64));
	// lfs f1,1020(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1020);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f6,f1
	ctx.f19.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 832);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f27,f27,f11,f7
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64 + ctx.f7.f64));
	// fmuls f7,f1,f31
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// fnmsubs f26,f26,f11,f27
	ctx.f26.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f27.f64)));
	// fmuls f18,f6,f7
	ctx.f18.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f17,f1,f7
	ctx.f17.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// lfs f1,1112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f21,f1,f7,f21
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 + ctx.f21.f64));
	// lfs f1,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f20,f20,f1
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f1.f64));
	// lfs f1,1436(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1436);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f16,f6,f1
	ctx.f16.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f1,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f15,f1,f28
	ctx.f15.f64 = double(float(ctx.f1.f64 * ctx.f28.f64));
	// lfs f1,1572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f14,f6,f1
	ctx.f14.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f28,388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	ctx.f28.f64 = double(temp.f32);
	// lfs f1,1444(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1444);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f1,f28,f1
	ctx.f1.f64 = double(float(ctx.f28.f64 * ctx.f1.f64));
	// lfs f28,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f28.f64 = double(temp.f32);
	// stfs f1,324(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmr f1,f28
	ctx.f1.f64 = ctx.f28.f64;
	// lfs f28,1200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1200);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f26,f25,f4,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f4.f64 + ctx.f26.f64));
	// fmuls f27,f28,f31
	ctx.f27.f64 = double(float(ctx.f28.f64 * ctx.f31.f64));
	// fmuls f28,f28,f7
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f7.f64));
	// lfs f7,1700(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1700);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f25,f6,f7
	ctx.f25.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f7,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// fmadds f21,f21,f1,f20
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f1.f64 + ctx.f20.f64));
	// fmadds f11,f24,f11,f26
	ctx.f11.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f26.f64));
	// fmuls f27,f6,f27
	ctx.f27.f64 = double(float(ctx.f6.f64 * ctx.f27.f64));
	// lfs f6,860(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f20,f6,f7
	ctx.f20.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f6,580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	ctx.f6.f64 = double(temp.f32);
	// fmsubs f7,f17,f1,f21
	ctx.f7.f64 = double(float(ctx.f17.f64 * ctx.f1.f64 - ctx.f21.f64));
	// fmuls f21,f6,f30
	ctx.f21.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f6,3472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3472);
	ctx.f6.f64 = double(temp.f32);
	// lfs f30,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f26,f6,f30
	ctx.f26.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f6,1732(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1732);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f7,f15,f1,f7
	ctx.f7.f64 = double(float(ctx.f15.f64 * ctx.f1.f64 + ctx.f7.f64));
	// lfs f30,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f30.f64 = double(temp.f32);
	// fnmsubs f11,f23,f4,f11
	ctx.f11.f64 = double(float(-(ctx.f23.f64 * ctx.f4.f64 - ctx.f11.f64)));
	// fmuls f30,f6,f30
	ctx.f30.f64 = double(float(ctx.f6.f64 * ctx.f30.f64));
	// lfs f6,3480(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3480);
	ctx.f6.f64 = double(temp.f32);
	// lfs f24,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f6
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f6.f64));
	// lfs f1,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f1.f64 = double(temp.f32);
	// lfs f6,3488(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3488);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f23,f6,f1
	ctx.f23.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// lfs f6,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// lfs f1,3496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3496);
	ctx.f1.f64 = double(temp.f32);
	// lfs f15,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f15.f64 = double(temp.f32);
	// fnmsubs f11,f22,f10,f11
	ctx.f11.f64 = double(float(-(ctx.f22.f64 * ctx.f10.f64 - ctx.f11.f64)));
	// fmuls f17,f30,f6
	ctx.f17.f64 = double(float(ctx.f30.f64 * ctx.f6.f64));
	// lfs f30,924(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 924);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f30,f30,f6,f1
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f6.f64 + ctx.f1.f64));
	// lfs f1,688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 688);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f7,f15,f1,f7
	ctx.f7.f64 = double(float(-(ctx.f15.f64 * ctx.f1.f64 - ctx.f7.f64)));
	// lfs f1,1100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1100);
	ctx.f1.f64 = double(temp.f32);
	// lfs f15,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f15.f64 = double(temp.f32);
	// fmadds f11,f19,f4,f11
	ctx.f11.f64 = double(float(ctx.f19.f64 * ctx.f4.f64 + ctx.f11.f64));
	// lfs f19,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f23,f30,f1,f23
	ctx.f23.f64 = double(float(ctx.f30.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f30,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f28,f28,f30,f7
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f30.f64 + ctx.f7.f64));
	// lfs f7,932(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 932);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f22,f18,f4,f11
	ctx.f22.f64 = double(float(-(ctx.f18.f64 * ctx.f4.f64 - ctx.f11.f64)));
	// lfs f11,1804(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1804);
	ctx.f11.f64 = double(temp.f32);
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// fnmsubs f28,f20,f7,f28
	ctx.f28.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f28.f64)));
	// fnmsubs f28,f26,f11,f28
	ctx.f28.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// fmadds f26,f16,f10,f22
	ctx.f26.f64 = double(float(ctx.f16.f64 * ctx.f10.f64 + ctx.f22.f64));
	// lfs f16,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f16.f64 = double(temp.f32);
	// fnmsubs f22,f17,f11,f28
	ctx.f22.f64 = double(float(-(ctx.f17.f64 * ctx.f11.f64 - ctx.f28.f64)));
	// lfs f17,1452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1452);
	ctx.f17.f64 = double(temp.f32);
	// fnmsubs f28,f14,f10,f26
	ctx.f28.f64 = double(float(-(ctx.f14.f64 * ctx.f10.f64 - ctx.f26.f64)));
	// lfs f26,588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 588);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f17,f16,f17
	ctx.f17.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// lfs f16,1580(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f15,f16
	ctx.f16.f64 = double(float(ctx.f15.f64 * ctx.f16.f64));
	// fnmsubs f4,f27,f4,f28
	ctx.f4.f64 = double(float(-(ctx.f27.f64 * ctx.f4.f64 - ctx.f28.f64)));
	// lfs f28,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f4,f25,f10,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f10.f64 + ctx.f4.f64));
	// lfs f10,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f4,f21,f10,f4
	ctx.f4.f64 = double(float(-(ctx.f21.f64 * ctx.f10.f64 - ctx.f4.f64)));
	// fmadds f10,f24,f10,f4
	ctx.f10.f64 = double(float(ctx.f24.f64 * ctx.f10.f64 + ctx.f4.f64));
	// stfs f10,4712(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4712, temp.u32);
	// lfs f4,572(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 572);
	ctx.f4.f64 = double(temp.f32);
	// lfs f10,604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 604);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f27,f4,f10
	ctx.f27.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f4,1108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f4,f1
	ctx.f25.f64 = double(float(ctx.f4.f64 * ctx.f1.f64));
	// lfs f4,3504(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3504);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f24,f4,f28
	ctx.f24.f64 = double(float(ctx.f4.f64 * ctx.f28.f64));
	// lfs f4,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f31
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// lfs f28,1116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1116);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f20,f28,f26
	ctx.f20.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// fmuls f27,f27,f30
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// fmuls f21,f4,f10
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f4,448(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 448);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f25,f25,f4
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f4.f64));
	// lfs f4,656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 656);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f19,f19,f4
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f4.f64));
	// lfs f4,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f18,f4,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// fmadds f24,f24,f11,f27
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f11.f64 + ctx.f27.f64));
	// lfs f27,464(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 464);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f15,f27,f28
	ctx.f15.f64 = double(float(ctx.f27.f64 * ctx.f28.f64));
	// lfs f27,1876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1876);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f14,f28,f31,f27
	ctx.f14.f64 = double(float(ctx.f28.f64 * ctx.f31.f64 + ctx.f27.f64));
	// lfs f31,564(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 564);
	ctx.f31.f64 = double(temp.f32);
	// lfs f27,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f19,f19,f31
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f31.f64));
	// lfs f31,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f18,f18,f29
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f29.f64));
	// fmuls f31,f27,f31
	ctx.f31.f64 = double(float(ctx.f27.f64 * ctx.f31.f64));
	// fmsubs f25,f25,f7,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f7.f64 - ctx.f24.f64));
	// stfs f31,324(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fmadds f25,f21,f11,f25
	ctx.f25.f64 = double(float(ctx.f21.f64 * ctx.f11.f64 + ctx.f25.f64));
	// lfs f24,1120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1120);
	ctx.f24.f64 = double(temp.f32);
	// fmadds f23,f23,f11,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f11.f64 + ctx.f22.f64));
	// fmuls f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// lfs f24,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f24.f64 = double(temp.f32);
	// fmr f31,f24
	ctx.f31.f64 = ctx.f24.f64;
	// lfs f21,620(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 620);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f25,f20,f7,f25
	ctx.f25.f64 = double(float(-(ctx.f20.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// fmadds f24,f14,f31,f19
	ctx.f24.f64 = double(float(ctx.f14.f64 * ctx.f31.f64 + ctx.f19.f64));
	// lfs f19,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f19.f64 = double(temp.f32);
	// fmsubs f19,f16,f19,f18
	ctx.f19.f64 = double(float(ctx.f16.f64 * ctx.f19.f64 - ctx.f18.f64));
	// lfs f18,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f18,f6
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f6.f64));
	// lfs f16,1460(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1460);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f1
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f1.f64));
	// lfs f14,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f14.f64 = double(temp.f32);
	// fnmsubs f25,f17,f7,f25
	ctx.f25.f64 = double(float(-(ctx.f17.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// lfs f17,652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 652);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f10,f17,f10
	ctx.f10.f64 = double(float(ctx.f17.f64 * ctx.f10.f64));
	// lfs f17,364(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f14,f17
	ctx.f17.f64 = double(float(ctx.f14.f64 * ctx.f17.f64));
	// fmadds f24,f21,f6,f24
	ctx.f24.f64 = double(float(ctx.f21.f64 * ctx.f6.f64 + ctx.f24.f64));
	// fnmsubs f25,f15,f7,f25
	ctx.f25.f64 = double(float(-(ctx.f15.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// fnmsubs f7,f26,f7,f25
	ctx.f7.f64 = double(float(-(ctx.f26.f64 * ctx.f7.f64 - ctx.f25.f64)));
	// lfs f21,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f7,f16,f11,f7
	ctx.f7.f64 = double(float(-(ctx.f16.f64 * ctx.f11.f64 - ctx.f7.f64)));
	// fnmsubs f21,f21,f29,f19
	ctx.f21.f64 = double(float(-(ctx.f21.f64 * ctx.f29.f64 - ctx.f19.f64)));
	// lfs f19,1644(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f1,f19,f1
	ctx.f1.f64 = double(float(ctx.f19.f64 * ctx.f1.f64));
	// lfs f19,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f19,f4,f19,f18
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f19.f64 + ctx.f18.f64));
	// lfs f4,576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 576);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f20,f27,f4
	ctx.f20.f64 = double(float(ctx.f27.f64 * ctx.f4.f64));
	// lfs f4,1468(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1468);
	ctx.f4.f64 = double(temp.f32);
	// lfs f18,1168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1168);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f18,f4,f18
	ctx.f18.f64 = double(float(ctx.f4.f64 * ctx.f18.f64));
	// lfs f4,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f24,f24,f4,f21
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f4.f64 + ctx.f21.f64));
	// lfs f4,1588(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,948(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 948);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f1,f4,f21,f1
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f21.f64 + ctx.f1.f64));
	// lfs f4,664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 664);
	ctx.f4.f64 = double(temp.f32);
	// lfs f21,476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f4,f21
	ctx.f21.f64 = double(float(ctx.f4.f64 * ctx.f21.f64));
	// fmadds f24,f19,f29,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f29.f64 + ctx.f24.f64));
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f27,f27,f19
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f19.f64));
	// lfs f19,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f19.f64 = double(temp.f32);
	// fmadds f11,f1,f11,f7
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f11.f64 + ctx.f7.f64));
	// lfs f1,1676(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1676);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f19,f4,f19
	ctx.f19.f64 = double(float(ctx.f4.f64 * ctx.f19.f64));
	// fnmsubs f24,f20,f29,f24
	ctx.f24.f64 = double(float(-(ctx.f20.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// fnmsubs f11,f18,f30,f11
	ctx.f11.f64 = double(float(-(ctx.f18.f64 * ctx.f30.f64 - ctx.f11.f64)));
	// fnmsubs f26,f21,f29,f24
	ctx.f26.f64 = double(float(-(ctx.f21.f64 * ctx.f29.f64 - ctx.f24.f64)));
	// fmadds f11,f10,f30,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f30.f64 + ctx.f11.f64));
	// lfs f30,1484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1484);
	ctx.f30.f64 = double(temp.f32);
	// fadds f1,f1,f30
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// lfs f10,3512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3512);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// lfs f30,1596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1596);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f8,f30
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fnmsubs f26,f17,f29,f26
	ctx.f26.f64 = double(float(-(ctx.f17.f64 * ctx.f29.f64 - ctx.f26.f64)));
	// fadds f11,f23,f11
	ctx.f11.f64 = double(float(ctx.f23.f64 + ctx.f11.f64));
	// stfs f11,4716(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4716, temp.u32);
	// lfs f11,1476(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1476);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f2
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f2.f64));
	// fmuls f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmadds f7,f27,f29,f26
	ctx.f7.f64 = double(float(ctx.f27.f64 * ctx.f29.f64 + ctx.f26.f64));
	// lfs f26,3528(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3528);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,3520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3520);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f8,f27
	ctx.f27.f64 = double(float(ctx.f8.f64 * ctx.f27.f64));
	// fmsubs f11,f26,f2,f11
	ctx.f11.f64 = double(float(ctx.f26.f64 * ctx.f2.f64 - ctx.f11.f64));
	// lfs f26,1492(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1492);
	ctx.f26.f64 = double(temp.f32);
	// fadds f26,f1,f26
	ctx.f26.f64 = double(float(ctx.f1.f64 + ctx.f26.f64));
	// lfs f1,3536(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3536);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f25,f8,f1
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f1,3544(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3544);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f24,f8,f1
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f1.f64));
	// lfs f1,3552(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3552);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f23,f1,f2,f11
	ctx.f23.f64 = double(float(-(ctx.f1.f64 * ctx.f2.f64 - ctx.f11.f64)));
	// fmsubs f10,f30,f13,f10
	ctx.f10.f64 = double(float(ctx.f30.f64 * ctx.f13.f64 - ctx.f10.f64));
	// lfs f1,1652(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	ctx.f1.f64 = double(temp.f32);
	// lfs f11,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f7,f19,f29,f7
	ctx.f7.f64 = double(float(-(ctx.f19.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// fmuls f30,f11,f1
	ctx.f30.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// lfs f1,1500(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1500);
	ctx.f1.f64 = double(temp.f32);
	// lfs f22,1604(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	ctx.f22.f64 = double(temp.f32);
	// fadds f22,f1,f22
	ctx.f22.f64 = double(float(ctx.f1.f64 + ctx.f22.f64));
	// lfs f1,3560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3560);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f21,f1,f13
	ctx.f21.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// lfs f1,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f26,f26,f1,f23
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f1.f64 + ctx.f23.f64));
	// lfs f19,1900(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1900);
	ctx.f19.f64 = double(temp.f32);
	// fnmsubs f10,f27,f13,f10
	ctx.f10.f64 = double(float(-(ctx.f27.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// lfs f27,1508(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1508);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f11,f27
	ctx.f27.f64 = double(float(ctx.f11.f64 * ctx.f27.f64));
	// fmadds f23,f22,f12,f21
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f12.f64 + ctx.f21.f64));
	// lfs f22,3568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3568);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f26,f22,f2,f26
	ctx.f26.f64 = double(float(-(ctx.f22.f64 * ctx.f2.f64 - ctx.f26.f64)));
	// lfs f22,1692(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1692);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f25,f25,f0,f10
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f0.f64 + ctx.f10.f64));
	// lfs f10,3576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3576);
	ctx.f10.f64 = double(temp.f32);
	// fadds f22,f10,f22
	ctx.f22.f64 = double(float(ctx.f10.f64 + ctx.f22.f64));
	// lfs f10,3584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3584);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f21,f10,f0
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f10,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f4,f10
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f10.f64));
	// lfs f10,472(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f20,f10,f6
	ctx.f20.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f6,3592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3592);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f6,f6,f2,f26
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f2.f64 + ctx.f26.f64));
	// fnmsubs f26,f24,f0,f25
	ctx.f26.f64 = double(float(-(ctx.f24.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f24,328(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 328);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,628(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 628);
	ctx.f25.f64 = double(temp.f32);
	// fadds f25,f25,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 + ctx.f24.f64));
	// fmadds f24,f22,f13,f21
	ctx.f24.f64 = double(float(ctx.f22.f64 * ctx.f13.f64 + ctx.f21.f64));
	// lfs f21,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	ctx.f22.f64 = double(temp.f32);
	// fmadds f7,f4,f29,f7
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f29.f64 + ctx.f7.f64));
	// lfs f4,1516(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1516);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f22,f21,f22
	ctx.f22.f64 = double(float(ctx.f21.f64 * ctx.f22.f64));
	// fnmsubs f4,f4,f2,f6
	ctx.f4.f64 = double(float(-(ctx.f4.f64 * ctx.f2.f64 - ctx.f6.f64)));
	// lfs f6,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f6.f64 = double(temp.f32);
	// lfs f21,1340(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f8,f21
	ctx.f21.f64 = double(float(ctx.f8.f64 * ctx.f21.f64));
	// fnmsubs f2,f30,f6,f26
	ctx.f2.f64 = double(float(-(ctx.f30.f64 * ctx.f6.f64 - ctx.f26.f64)));
	// lfs f26,1224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1224);
	ctx.f26.f64 = double(temp.f32);
	// lfs f30,1612(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	ctx.f30.f64 = double(temp.f32);
	// fadds f26,f25,f26
	ctx.f26.f64 = double(float(ctx.f25.f64 + ctx.f26.f64));
	// lfs f25,3600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3600);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f30,f8,f30
	ctx.f30.f64 = double(float(ctx.f8.f64 * ctx.f30.f64));
	// fmuls f25,f8,f25
	ctx.f25.f64 = double(float(ctx.f8.f64 * ctx.f25.f64));
	// fnmsubs f22,f22,f29,f7
	ctx.f22.f64 = double(float(-(ctx.f22.f64 * ctx.f29.f64 - ctx.f7.f64)));
	// lfs f7,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f4,f19,f7,f4
	ctx.f4.f64 = double(float(ctx.f19.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fmadds f2,f23,f8,f2
	ctx.f2.f64 = double(float(ctx.f23.f64 * ctx.f8.f64 + ctx.f2.f64));
	// lfs f23,1344(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1344);
	ctx.f23.f64 = double(temp.f32);
	// fmadds f4,f23,f1,f4
	ctx.f4.f64 = double(float(ctx.f23.f64 * ctx.f1.f64 + ctx.f4.f64));
	// lfs f1,3616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3616);
	ctx.f1.f64 = double(temp.f32);
	// fnmsubs f2,f27,f6,f2
	ctx.f2.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 - ctx.f2.f64)));
	// fnmsubs f4,f20,f29,f4
	ctx.f4.f64 = double(float(-(ctx.f20.f64 * ctx.f29.f64 - ctx.f4.f64)));
	// lfs f29,1784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1784);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f2,f24,f8,f2
	ctx.f2.f64 = double(float(ctx.f24.f64 * ctx.f8.f64 + ctx.f2.f64));
	// fmadds f7,f26,f7,f4
	ctx.f7.f64 = double(float(ctx.f26.f64 * ctx.f7.f64 + ctx.f4.f64));
	// fnmsubs f4,f30,f12,f2
	ctx.f4.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f2.f64)));
	// lfs f2,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f2.f64 = double(temp.f32);
	// fadds f7,f22,f7
	ctx.f7.f64 = double(float(ctx.f22.f64 + ctx.f7.f64));
	// stfs f7,4720(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4720, temp.u32);
	// fnmsubs f7,f25,f0,f4
	ctx.f7.f64 = double(float(-(ctx.f25.f64 * ctx.f0.f64 - ctx.f4.f64)));
	// lfs f4,1352(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1352);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f4,f4,f2
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// lfs f2,3608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3608);
	ctx.f2.f64 = double(temp.f32);
	// fadds f30,f2,f1
	ctx.f30.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// lfs f1,3632(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3632);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,3624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3624);
	ctx.f2.f64 = double(temp.f32);
	// fadds f2,f2,f1
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f1.f64));
	// lfs f1,3640(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3640);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f4,f1,f29,f4
	ctx.f4.f64 = double(float(ctx.f1.f64 * ctx.f29.f64 + ctx.f4.f64));
	// lfs f1,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f1.f64 = double(temp.f32);
	// lfs f29,416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 416);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f1,f1,f8
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmuls f29,f29,f31
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f31.f64));
	// lfs f27,3648(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3648);
	ctx.f27.f64 = double(temp.f32);
	// lis r11,-32244
	ctx.r11.s64 = -2113142784;
	// fadds f27,f2,f27
	ctx.f27.f64 = double(float(ctx.f2.f64 + ctx.f27.f64));
	// lfs f2,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f2.f64 = double(temp.f32);
	// fnmsubs f7,f21,f12,f7
	ctx.f7.f64 = double(float(-(ctx.f21.f64 * ctx.f12.f64 - ctx.f7.f64)));
	// lfs f26,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f2
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f2.f64));
	// lfs f25,1324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1324);
	ctx.f25.f64 = double(temp.f32);
	// lfs f2,-10648(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -10648);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f4,f25,f2,f4
	ctx.f4.f64 = double(float(ctx.f25.f64 * ctx.f2.f64 + ctx.f4.f64));
	// lfs f25,556(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 556);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f1,f25
	ctx.f25.f64 = double(float(ctx.f1.f64 * ctx.f25.f64));
	// lfs f1,1236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1236);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f29,f10,f28,f29
	ctx.f29.f64 = double(float(ctx.f10.f64 * ctx.f28.f64 + ctx.f29.f64));
	// lfs f10,3656(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3656);
	ctx.f10.f64 = double(temp.f32);
	// fadds f10,f27,f10
	ctx.f10.f64 = double(float(ctx.f27.f64 + ctx.f10.f64));
	// fmuls f27,f26,f8
	ctx.f27.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// lfs f26,3664(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3664);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f4,f26,f1,f4
	ctx.f4.f64 = double(float(-(ctx.f26.f64 * ctx.f1.f64 - ctx.f4.f64)));
	// fmuls f26,f25,f0
	ctx.f26.f64 = double(float(ctx.f25.f64 * ctx.f0.f64));
	// lfs f25,3672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3672);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f8
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f8.f64));
	// fmuls f24,f10,f12
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,1360(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1360);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f10,f11
	ctx.f23.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,1264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1264);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f4,f30,f10,f4
	ctx.f4.f64 = double(float(ctx.f30.f64 * ctx.f10.f64 + ctx.f4.f64));
	// fmsubs f30,f27,f0,f26
	ctx.f30.f64 = double(float(ctx.f27.f64 * ctx.f0.f64 - ctx.f26.f64));
	// lfs f26,3688(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3688);
	ctx.f26.f64 = double(temp.f32);
	// lfs f27,3680(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3680);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f8
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmadds f29,f29,f0,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f24.f64));
	// lfs f24,1188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1188);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f26,f24,f26
	ctx.f26.f64 = double(float(ctx.f24.f64 * ctx.f26.f64));
	// lfs f24,3696(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3696);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f7,f23,f6,f7
	ctx.f7.f64 = double(float(-(ctx.f23.f64 * ctx.f6.f64 - ctx.f7.f64)));
	// fnmsubs f24,f24,f1,f4
	ctx.f24.f64 = double(float(-(ctx.f24.f64 * ctx.f1.f64 - ctx.f4.f64)));
	// lfs f4,3704(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3704);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f23,f4,f8
	ctx.f23.f64 = double(float(ctx.f4.f64 * ctx.f8.f64));
	// lfs f4,1368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1368);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f11,f11,f4
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f4.f64));
	// lfs f4,2220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 2220);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f30,f29,f8,f30
	ctx.f30.f64 = double(float(ctx.f29.f64 * ctx.f8.f64 + ctx.f30.f64));
	// lfs f29,1376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1376);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f29,f29,f4,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f4.f64 + ctx.f24.f64));
	// lfs f24,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f24.f64 = double(temp.f32);
	// fnmsubs f7,f26,f24,f7
	ctx.f7.f64 = double(float(-(ctx.f26.f64 * ctx.f24.f64 - ctx.f7.f64)));
	// lfs f24,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f8
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f8.f64));
	// lfs f26,3712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3712);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f8
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f8.f64));
	// fnmsubs f30,f25,f12,f30
	ctx.f30.f64 = double(float(-(ctx.f25.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// lfs f25,3720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3720);
	ctx.f25.f64 = double(temp.f32);
	// fmadds f29,f25,f1,f29
	ctx.f29.f64 = double(float(ctx.f25.f64 * ctx.f1.f64 + ctx.f29.f64));
	// fnmsubs f11,f11,f6,f7
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f6.f64 - ctx.f7.f64)));
	// stfs f11,4724(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4724, temp.u32);
	// fmuls f7,f24,f31
	ctx.f7.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// lfs f31,3728(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3728);
	ctx.f31.f64 = double(temp.f32);
	// fnmsubs f11,f27,f12,f30
	ctx.f11.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// lfs f30,1440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1440);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f9
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64));
	// fmadds f10,f31,f10,f29
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f10.f64 + ctx.f29.f64));
	// lfs f31,1384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1384);
	ctx.f31.f64 = double(temp.f32);
	// lfs f29,1028(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1028);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f9
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// fnmsubs f11,f23,f12,f11
	ctx.f11.f64 = double(float(-(ctx.f23.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// fnmsubs f10,f31,f4,f10
	ctx.f10.f64 = double(float(-(ctx.f31.f64 * ctx.f4.f64 - ctx.f10.f64)));
	// fnmsubs f31,f26,f12,f11
	ctx.f31.f64 = double(float(-(ctx.f26.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// lfs f11,1392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1392);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f11,f11,f2,f10
	ctx.f11.f64 = double(float(-(ctx.f11.f64 * ctx.f2.f64 - ctx.f10.f64)));
	// lfs f10,1400(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1400);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f11,f10,f2,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f2.f64 - ctx.f11.f64)));
	// lfs f10,1408(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1408);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f11,f10,f4,f11
	ctx.f11.f64 = double(float(-(ctx.f10.f64 * ctx.f4.f64 - ctx.f11.f64)));
	// stfs f11,4728(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4728, temp.u32);
	// lfs f10,1424(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1424);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,1416(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1416);
	ctx.f11.f64 = double(temp.f32);
	// fadds f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// lfs f10,1432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1432);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// fmuls f25,f11,f9
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,884(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f24,f10,f11
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f10,3736(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3736);
	ctx.f10.f64 = double(temp.f32);
	// lfs f23,3744(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3744);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f7,f7,f0,f31
	ctx.f7.f64 = double(float(-(ctx.f7.f64 * ctx.f0.f64 - ctx.f31.f64)));
	// fadds f23,f10,f23
	ctx.f23.f64 = double(float(ctx.f10.f64 + ctx.f23.f64));
	// lfs f10,3752(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3752);
	ctx.f10.f64 = double(temp.f32);
	// lfs f19,1044(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1044);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f3,f10
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// lfs f20,1016(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1016);
	ctx.f20.f64 = double(temp.f32);
	// fadds f20,f20,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 + ctx.f19.f64));
	// lfs f18,724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 724);
	ctx.f18.f64 = double(temp.f32);
	// lfs f19,1052(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1052);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f18,f19
	ctx.f19.f64 = double(float(ctx.f18.f64 * ctx.f19.f64));
	// lfs f17,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f18.f64 = double(temp.f32);
	// lfs f10,1128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1128);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f17.f64));
	// fmsubs f25,f25,f11,f24
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f11.f64 - ctx.f24.f64));
	// lfs f21,872(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 872);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f21,f10,f21
	ctx.f21.f64 = double(float(ctx.f10.f64 * ctx.f21.f64));
	// lfs f27,1036(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1036);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f24,f23,f3
	ctx.f24.f64 = double(float(ctx.f23.f64 * ctx.f3.f64));
	// lfs f26,952(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 952);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f23,f22,f0
	ctx.f23.f64 = double(float(ctx.f22.f64 * ctx.f0.f64));
	// lfs f22,3760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3760);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f3,f22
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f22.f64));
	// fmuls f27,f27,f9
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f9.f64));
	// fmuls f26,f26,f9
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fmadds f20,f20,f10,f19
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f10.f64 + ctx.f19.f64));
	// lfs f19,880(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 880);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f10,f19
	ctx.f19.f64 = double(float(ctx.f10.f64 * ctx.f19.f64));
	// fmuls f31,f18,f8
	ctx.f31.f64 = double(float(ctx.f18.f64 * ctx.f8.f64));
	// fnmsubs f10,f30,f13,f25
	ctx.f10.f64 = double(float(-(ctx.f30.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// lfs f30,960(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 960);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f30,f30,f3
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f3.f64));
	// fmsubs f25,f24,f0,f23
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f0.f64 - ctx.f23.f64));
	// lfs f24,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f28,f28,f24
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f24.f64));
	// lfs f23,568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 568);
	ctx.f23.f64 = double(temp.f32);
	// lfs f24,840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 840);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f24,f23
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f23.f64));
	// lfs f23,560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 560);
	ctx.f23.f64 = double(temp.f32);
	// fnmsubs f7,f31,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f31.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// fmadds f10,f29,f11,f10
	ctx.f10.f64 = double(float(ctx.f29.f64 * ctx.f11.f64 + ctx.f10.f64));
	// lfs f29,888(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 888);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f29,f3
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// fmadds f25,f22,f0,f25
	ctx.f25.f64 = double(float(ctx.f22.f64 * ctx.f0.f64 + ctx.f25.f64));
	// lfs f22,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f31,f28,f8
	ctx.f31.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// lfs f28,3768(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3768);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f23,f23,f22
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f22.f64));
	// fmuls f28,f9,f28
	ctx.f28.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// fnmsubs f10,f27,f11,f10
	ctx.f10.f64 = double(float(-(ctx.f27.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// lfs f27,1000(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1000);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f3
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f3.f64));
	// fnmsubs f30,f30,f12,f25
	ctx.f30.f64 = double(float(-(ctx.f30.f64 * ctx.f12.f64 - ctx.f25.f64)));
	// lfs f25,896(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 896);
	ctx.f25.f64 = double(temp.f32);
	// fmuls f25,f25,f5
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f5.f64));
	// fnmsubs f7,f31,f0,f7
	ctx.f7.f64 = double(float(-(ctx.f31.f64 * ctx.f0.f64 - ctx.f7.f64)));
	// lfs f31,3776(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3776);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f23,f23,f8
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f8.f64));
	// fmuls f22,f9,f31
	ctx.f22.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fnmsubs f31,f26,f11,f10
	ctx.f31.f64 = double(float(-(ctx.f26.f64 * ctx.f11.f64 - ctx.f10.f64)));
	// lfs f10,968(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 968);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f26,f10,f3
	ctx.f26.f64 = double(float(ctx.f10.f64 * ctx.f3.f64));
	// lfs f10,904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 904);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f18,f10,f5
	ctx.f18.f64 = double(float(ctx.f10.f64 * ctx.f5.f64));
	// fnmsubs f29,f29,f12,f30
	ctx.f29.f64 = double(float(-(ctx.f29.f64 * ctx.f12.f64 - ctx.f30.f64)));
	// lfs f30,384(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 384);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f25,f25,f30
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f30.f64));
	// fmadds f10,f23,f0,f7
	ctx.f10.f64 = double(float(ctx.f23.f64 * ctx.f0.f64 + ctx.f7.f64));
	// stfs f10,4732(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4732, temp.u32);
	// lfs f7,3784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3784);
	ctx.f7.f64 = double(temp.f32);
	// lfs f10,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f23,f7,f10
	ctx.f23.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// lfs f7,1216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1216);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f31,f21,f7,f31
	ctx.f31.f64 = double(float(-(ctx.f21.f64 * ctx.f7.f64 - ctx.f31.f64)));
	// fnmsubs f29,f27,f12,f29
	ctx.f29.f64 = double(float(-(ctx.f27.f64 * ctx.f12.f64 - ctx.f29.f64)));
	// fmsubs f27,f18,f30,f25
	ctx.f27.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 - ctx.f25.f64));
	// fmadds f31,f20,f7,f31
	ctx.f31.f64 = double(float(ctx.f20.f64 * ctx.f7.f64 + ctx.f31.f64));
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmadds f29,f26,f12,f29
	ctx.f29.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f29.f64));
	// stfs f29,4740(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4740, temp.u32);
	// lfs f17,1904(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1904);
	ctx.f17.f64 = double(temp.f32);
	// lfs f18,3840(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3840);
	ctx.f18.f64 = double(temp.f32);
	// fadds f18,f18,f17
	ctx.f18.f64 = double(float(ctx.f18.f64 + ctx.f17.f64));
	// lfs f17,912(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 912);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f17,f5
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f5.f64));
	// lfs f20,3832(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3832);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f20,f20,f0
	ctx.f20.f64 = double(float(ctx.f20.f64 * ctx.f0.f64));
	// lfs f15,1156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1156);
	ctx.f15.f64 = double(temp.f32);
	// lfs f16,1764(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1764);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f16,f16,f3
	ctx.f16.f64 = double(float(ctx.f16.f64 * ctx.f3.f64));
	// fnmsubs f29,f19,f7,f31
	ctx.f29.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f31.f64)));
	// lfs f31,-80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -80);
	ctx.f31.f64 = double(temp.f32);
	// stfs f31,324(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lfs f19,1032(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1032);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f19,f19,f9
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// fmuls f18,f18,f10
	ctx.f18.f64 = double(float(ctx.f18.f64 * ctx.f10.f64));
	// fmuls f17,f17,f30
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f30.f64));
	// fmadds f20,f15,f13,f20
	ctx.f20.f64 = double(float(ctx.f15.f64 * ctx.f13.f64 + ctx.f20.f64));
	// lfs f15,920(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 920);
	ctx.f15.f64 = double(temp.f32);
	// fmuls f15,f15,f3
	ctx.f15.f64 = double(float(ctx.f15.f64 * ctx.f3.f64));
	// fnmsubs f29,f24,f31,f29
	ctx.f29.f64 = double(float(-(ctx.f24.f64 * ctx.f31.f64 - ctx.f29.f64)));
	// lfs f31,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f19,f19,f11
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f11.f64));
	// fmadds f29,f28,f31,f29
	ctx.f29.f64 = double(float(ctx.f28.f64 * ctx.f31.f64 + ctx.f29.f64));
	// fnmsubs f29,f22,f31,f29
	ctx.f29.f64 = double(float(-(ctx.f22.f64 * ctx.f31.f64 - ctx.f29.f64)));
	// stfs f29,4736(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4736, temp.u32);
	// lfs f29,3792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3792);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f29,f10
	ctx.f28.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,3800(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3800);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f26,f29,f10
	ctx.f26.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,3808(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3808);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f25,f29,f10
	ctx.f25.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,3816(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3816);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f24,f29,f10
	ctx.f24.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,3824(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3824);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f22,f3,f29
	ctx.f22.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// lfs f29,1756(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1756);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f21,f29,f3
	ctx.f21.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// lfs f29,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f28,f29
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f29.f64));
	// fmsubs f28,f26,f29,f28
	ctx.f28.f64 = double(float(ctx.f26.f64 * ctx.f29.f64 - ctx.f28.f64));
	// lfs f26,976(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 976);
	ctx.f26.f64 = double(temp.f32);
	// fmuls f26,f26,f9
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f9.f64));
	// fnmsubs f25,f25,f29,f28
	ctx.f25.f64 = double(float(-(ctx.f25.f64 * ctx.f29.f64 - ctx.f28.f64)));
	// lfs f28,1008(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1008);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f14,f9,f28
	ctx.f14.f64 = double(float(ctx.f9.f64 * ctx.f28.f64));
	// lfs f28,1712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1712);
	ctx.f28.f64 = double(temp.f32);
	// fmsubs f26,f26,f11,f19
	ctx.f26.f64 = double(float(ctx.f26.f64 * ctx.f11.f64 - ctx.f19.f64));
	// fmadds f27,f23,f28,f27
	ctx.f27.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 + ctx.f27.f64));
	// lfs f23,928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 928);
	ctx.f23.f64 = double(temp.f32);
	// fmuls f23,f23,f5
	ctx.f23.f64 = double(float(ctx.f23.f64 * ctx.f5.f64));
	// fmsubs f28,f18,f28,f17
	ctx.f28.f64 = double(float(ctx.f18.f64 * ctx.f28.f64 - ctx.f17.f64));
	// fmadds f25,f24,f29,f25
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f29.f64 + ctx.f25.f64));
	// lfs f29,-400(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -400);
	ctx.f29.f64 = double(temp.f32);
	// lfs f24,3856(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3856);
	ctx.f24.f64 = double(temp.f32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// fmuls f24,f24,f29
	ctx.f24.f64 = double(float(ctx.f24.f64 * ctx.f29.f64));
	// lfs f29,3864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 3864);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f19,f29,f10
	ctx.f19.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,984(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 984);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f18,f29,f5
	ctx.f18.f64 = double(float(ctx.f29.f64 * ctx.f5.f64));
	// lfs f29,936(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 936);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f17,f29,f3
	ctx.f17.f64 = double(float(ctx.f29.f64 * ctx.f3.f64));
	// lfs f29,1024(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1024);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f26,f14,f11,f26
	ctx.f26.f64 = double(float(-(ctx.f14.f64 * ctx.f11.f64 - ctx.f26.f64)));
	// fmuls f14,f29,f9
	ctx.f14.f64 = double(float(ctx.f29.f64 * ctx.f9.f64));
	// lfs f29,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f27,f23,f29,f27
	ctx.f27.f64 = double(float(-(ctx.f23.f64 * ctx.f29.f64 - ctx.f27.f64)));
	// lfs f29,1928(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1928);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f23,f29,f10
	ctx.f23.f64 = double(float(ctx.f29.f64 * ctx.f10.f64));
	// lfs f29,-428(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -428);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f25,f22,f0,f25
	ctx.f25.f64 = double(float(-(ctx.f22.f64 * ctx.f0.f64 - ctx.f25.f64)));
	// lfs f22,1164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1164);
	ctx.f22.f64 = double(temp.f32);
	// fmsubs f29,f22,f29,f24
	ctx.f29.f64 = double(float(ctx.f22.f64 * ctx.f29.f64 - ctx.f24.f64));
	// lfs f24,1892(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1892);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f19,f24
	ctx.f24.f64 = double(float(ctx.f19.f64 * ctx.f24.f64));
	// fmadds f30,f18,f30,f28
	ctx.f30.f64 = double(float(ctx.f18.f64 * ctx.f30.f64 + ctx.f28.f64));
	// lfs f28,944(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 944);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// lfs f22,992(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 992);
	ctx.f22.f64 = double(temp.f32);
	// fnmsubs f28,f21,f13,f25
	ctx.f28.f64 = double(float(-(ctx.f21.f64 * ctx.f13.f64 - ctx.f25.f64)));
	// lfs f25,1724(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1724);
	ctx.f25.f64 = double(temp.f32);
	// lfs f21,864(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 864);
	ctx.f21.f64 = double(temp.f32);
	// fmadds f26,f14,f11,f26
	ctx.f26.f64 = double(float(ctx.f14.f64 * ctx.f11.f64 + ctx.f26.f64));
	// fmuls f25,f25,f3
	ctx.f25.f64 = double(float(ctx.f25.f64 * ctx.f3.f64));
	// lfs f19,392(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 392);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f22,f22,f9
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f9.f64));
	// lfs f18,1180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1180);
	ctx.f18.f64 = double(temp.f32);
	// fmuls f21,f21,f13
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f13.f64));
	// fmsubs f29,f29,f10,f24
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f10.f64 - ctx.f24.f64));
	// stfs f29,4748(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4748, temp.u32);
	// lfs f29,440(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 440);
	ctx.f29.f64 = double(temp.f32);
	// fnmsubs f5,f5,f29,f30
	ctx.f5.f64 = double(float(-(ctx.f5.f64 * ctx.f29.f64 - ctx.f30.f64)));
	// lfs f30,868(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	ctx.f30.f64 = double(temp.f32);
	// fmadds f3,f20,f3,f28
	ctx.f3.f64 = double(float(ctx.f20.f64 * ctx.f3.f64 + ctx.f28.f64));
	// stfs f5,4752(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4752, temp.u32);
	// lfs f28,1712(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1712);
	ctx.f28.f64 = double(temp.f32);
	// fmadds f28,f23,f28,f27
	ctx.f28.f64 = double(float(ctx.f23.f64 * ctx.f28.f64 + ctx.f27.f64));
	// stfs f28,4744(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4744, temp.u32);
	// fnmsubs f5,f22,f11,f26
	ctx.f5.f64 = double(float(-(ctx.f22.f64 * ctx.f11.f64 - ctx.f26.f64)));
	// lfs f27,1592(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1592);
	ctx.f27.f64 = double(temp.f32);
	// fmadds f30,f30,f11,f21
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f11.f64 + ctx.f21.f64));
	// lfs f29,1576(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1576);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,1584(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1584);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f29,f8,f29
	ctx.f29.f64 = double(float(ctx.f8.f64 * ctx.f29.f64));
	// fadds f28,f28,f27
	ctx.f28.f64 = double(float(ctx.f28.f64 + ctx.f27.f64));
	// lfs f22,876(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	ctx.f22.f64 = double(temp.f32);
	// lfs f27,512(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 512);
	ctx.f27.f64 = double(temp.f32);
	// lfs f21,708(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 708);
	ctx.f21.f64 = double(temp.f32);
	// fmuls f27,f10,f27
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lfs f26,1600(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1600);
	ctx.f26.f64 = double(temp.f32);
	// fnmsubs f11,f16,f13,f3
	ctx.f11.f64 = double(float(-(ctx.f16.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// lfs f3,1568(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1568);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f3,f8,f3
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f3.f64));
	// lfs f20,1624(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1624);
	ctx.f20.f64 = double(temp.f32);
	// fmuls f26,f8,f26
	ctx.f26.f64 = double(float(ctx.f8.f64 * ctx.f26.f64));
	// fmuls f20,f8,f20
	ctx.f20.f64 = double(float(ctx.f8.f64 * ctx.f20.f64));
	// fmadds f30,f30,f9,f5
	ctx.f30.f64 = double(float(ctx.f30.f64 * ctx.f9.f64 + ctx.f5.f64));
	// lfs f5,760(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 760);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f22,f22,f5
	ctx.f22.f64 = double(float(ctx.f22.f64 * ctx.f5.f64));
	// fmuls f28,f28,f8
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f8.f64));
	// fmuls f21,f21,f5
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f5.f64));
	// fmuls f19,f5,f19
	ctx.f19.f64 = double(float(ctx.f5.f64 * ctx.f19.f64));
	// fmadds f11,f15,f12,f11
	ctx.f11.f64 = double(float(ctx.f15.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fnmsubs f30,f22,f7,f30
	ctx.f30.f64 = double(float(-(ctx.f22.f64 * ctx.f7.f64 - ctx.f30.f64)));
	// lfs f22,1172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1172);
	ctx.f22.f64 = double(temp.f32);
	// fmuls f22,f8,f22
	ctx.f22.f64 = double(float(ctx.f8.f64 * ctx.f22.f64));
	// fnmsubs f11,f17,f12,f11
	ctx.f11.f64 = double(float(-(ctx.f17.f64 * ctx.f12.f64 - ctx.f11.f64)));
	// lfs f17,1188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1188);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f18,f17,f18
	ctx.f18.f64 = double(float(ctx.f17.f64 * ctx.f18.f64));
	// lfs f17,484(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 484);
	ctx.f17.f64 = double(temp.f32);
	// fmuls f17,f10,f17
	ctx.f17.f64 = double(float(ctx.f10.f64 * ctx.f17.f64));
	// fmadds f30,f21,f7,f30
	ctx.f30.f64 = double(float(ctx.f21.f64 * ctx.f7.f64 + ctx.f30.f64));
	// fmadds f11,f25,f13,f11
	ctx.f11.f64 = double(float(ctx.f25.f64 * ctx.f13.f64 + ctx.f11.f64));
	// stfs f11,4756(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4756, temp.u32);
	// lfs f11,1560(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1560);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f8,f11
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmuls f25,f11,f12
	ctx.f25.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f11,496(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 496);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f24,f10,f11
	ctx.f24.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f11,1608(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1608);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f23,f8,f11
	ctx.f23.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// lfs f11,4792(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 4792);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f27,f27,f11
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fmsubs f3,f3,f13,f25
	ctx.f3.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 - ctx.f25.f64));
	// fmuls f25,f24,f11
	ctx.f25.f64 = double(float(ctx.f24.f64 * ctx.f11.f64));
	// lfs f24,1616(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1616);
	ctx.f24.f64 = double(temp.f32);
	// fmuls f24,f8,f24
	ctx.f24.f64 = double(float(ctx.f8.f64 * ctx.f24.f64));
	// fnmsubs f3,f29,f13,f3
	ctx.f3.f64 = double(float(-(ctx.f29.f64 * ctx.f13.f64 - ctx.f3.f64)));
	// lfs f29,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f29,f9,f29
	ctx.f29.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// fmadds f3,f28,f13,f3
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f13.f64 + ctx.f3.f64));
	// lfs f28,748(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f5,f28,f5
	ctx.f5.f64 = double(float(ctx.f28.f64 * ctx.f5.f64));
	// lfs f28,452(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	ctx.f28.f64 = double(temp.f32);
	// fmuls f29,f29,f28
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f28.f64));
	// lfs f28,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f28.f64 = double(temp.f32);
	// fnmsubs f3,f27,f6,f3
	ctx.f3.f64 = double(float(-(ctx.f27.f64 * ctx.f6.f64 - ctx.f3.f64)));
	// lfs f21,532(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	ctx.f21.f64 = double(temp.f32);
	// fnmsubs f30,f19,f7,f30
	ctx.f30.f64 = double(float(-(ctx.f19.f64 * ctx.f7.f64 - ctx.f30.f64)));
	// lfs f27,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f28,f10,f28
	ctx.f28.f64 = double(float(ctx.f10.f64 * ctx.f28.f64));
	// lfs f10,524(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 524);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f17,f17,f11
	ctx.f17.f64 = double(float(ctx.f17.f64 * ctx.f11.f64));
	// lfs f19,1196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1196);
	ctx.f19.f64 = double(temp.f32);
	// fmuls f21,f21,f10
	ctx.f21.f64 = double(float(ctx.f21.f64 * ctx.f10.f64));
	// lfs f10,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f27,f10,f27
	ctx.f27.f64 = double(float(ctx.f10.f64 * ctx.f27.f64));
	// lwz r31,5124(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 5124);
	// fmuls f19,f19,f9
	ctx.f19.f64 = double(float(ctx.f19.f64 * ctx.f9.f64));
	// lwz r11,5148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 5148);
	// addi r6,r31,100
	ctx.r6.s64 = ctx.r31.s64 + 100;
	// addi r5,r11,100
	ctx.r5.s64 = ctx.r11.s64 + 100;
	// addi r4,r1,4288
	ctx.r4.s64 = ctx.r1.s64 + 4288;
	// fmadds f3,f26,f12,f3
	ctx.f3.f64 = double(float(ctx.f26.f64 * ctx.f12.f64 + ctx.f3.f64));
	// li r3,11
	ctx.r3.s64 = 11;
	// fnmsubs f30,f29,f7,f30
	ctx.f30.f64 = double(float(-(ctx.f29.f64 * ctx.f7.f64 - ctx.f30.f64)));
	// fmuls f28,f28,f11
	ctx.f28.f64 = double(float(ctx.f28.f64 * ctx.f11.f64));
	// lfs f11,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f10,f11
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f11,1204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1204);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f9,f11,f9
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f9.f64));
	// lfs f11,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f29,f27,f8
	ctx.f29.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// lfs f27,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f27,f27,f11
	ctx.f27.f64 = double(float(ctx.f27.f64 * ctx.f11.f64));
	// fnmsubs f3,f25,f6,f3
	ctx.f3.f64 = double(float(-(ctx.f25.f64 * ctx.f6.f64 - ctx.f3.f64)));
	// fmadds f7,f5,f7,f30
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f7.f64 + ctx.f30.f64));
	// fmuls f10,f10,f8
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f8.f64));
	// fmadds f5,f23,f12,f3
	ctx.f5.f64 = double(float(ctx.f23.f64 * ctx.f12.f64 + ctx.f3.f64));
	// lfs f3,324(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f7,f21,f3,f7
	ctx.f7.f64 = double(float(ctx.f21.f64 * ctx.f3.f64 + ctx.f7.f64));
	// fnmsubs f5,f24,f13,f5
	ctx.f5.f64 = double(float(-(ctx.f24.f64 * ctx.f13.f64 - ctx.f5.f64)));
	// fmadds f7,f19,f31,f7
	ctx.f7.f64 = double(float(ctx.f19.f64 * ctx.f31.f64 + ctx.f7.f64));
	// fmadds f13,f20,f13,f5
	ctx.f13.f64 = double(float(ctx.f20.f64 * ctx.f13.f64 + ctx.f5.f64));
	// fnmsubs f9,f9,f31,f7
	ctx.f9.f64 = double(float(-(ctx.f9.f64 * ctx.f31.f64 - ctx.f7.f64)));
	// stfs f9,4760(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4760, temp.u32);
	// lfs f9,1212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1212);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,828(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	ctx.f7.f64 = double(temp.f32);
	// fnmsubs f13,f22,f12,f13
	ctx.f13.f64 = double(float(-(ctx.f22.f64 * ctx.f12.f64 - ctx.f13.f64)));
	// lfs f12,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f13,f18,f12,f13
	ctx.f13.f64 = double(float(-(ctx.f18.f64 * ctx.f12.f64 - ctx.f13.f64)));
	// lfs f12,716(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 716);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f13,f17,f6,f13
	ctx.f13.f64 = double(float(-(ctx.f17.f64 * ctx.f6.f64 - ctx.f13.f64)));
	// fnmsubs f13,f28,f6,f13
	ctx.f13.f64 = double(float(-(ctx.f28.f64 * ctx.f6.f64 - ctx.f13.f64)));
	// fmadds f13,f29,f0,f13
	ctx.f13.f64 = double(float(ctx.f29.f64 * ctx.f0.f64 + ctx.f13.f64));
	// fnmsubs f13,f10,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f10.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// lfs f10,672(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 672);
	ctx.f10.f64 = double(temp.f32);
	// fadds f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// lfs f10,520(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f10,f10,f4
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f4.f64));
	// fmadds f12,f12,f2,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 + ctx.f10.f64));
	// fmuls f10,f27,f8
	ctx.f10.f64 = double(float(ctx.f27.f64 * ctx.f8.f64));
	// fmsubs f12,f9,f1,f12
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f1.f64 - ctx.f12.f64));
	// lfs f9,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
	// lfs f9,1048(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1048);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f13,f10,f0,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f10,332(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	ctx.f10.f64 = double(temp.f32);
	// fadds f9,f9,f7
	ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// fmadds f12,f10,f4,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f4.f64 + ctx.f12.f64));
	// lfs f10,720(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 720);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
	// lfs f8,1784(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1784);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f12,f10,f8,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f8.f64 + ctx.f12.f64));
	// fnmsubs f0,f11,f0,f13
	ctx.f0.f64 = double(float(-(ctx.f11.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// stfs f0,4764(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4764, temp.u32);
	// lfs f0,596(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 596);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f13,f0,f4,f12
	ctx.f13.f64 = double(float(-(ctx.f0.f64 * ctx.f4.f64 - ctx.f12.f64)));
	// lfs f12,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,1264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1264);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f13,f12,f0,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f12,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f12,f2,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f2.f64 + ctx.f13.f64));
	// lfs f12,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f12,f11,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f13.f64));
	// lfs f12,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f13,f12,f1,f13
	ctx.f13.f64 = double(float(-(ctx.f12.f64 * ctx.f1.f64 - ctx.f13.f64)));
	// fmadds f0,f9,f0,f13
	ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f13,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f0,f13,f1,f0
	ctx.f0.f64 = double(float(-(ctx.f13.f64 * ctx.f1.f64 - ctx.f0.f64)));
	// stfs f0,4768(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 4768, temp.u32);
	// bl 0x82b31838
	ctx.lr = 0x82B43B90;
	sub_82B31838(ctx, base);
loc_82B43B90:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,5104
	ctx.r1.s64 = ctx.r1.s64 + 5104;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x82e28f2c
	ctx.lr = 0x82B43BA0;
	__restfpr_14(ctx, base);
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B43BA8"))) PPC_WEAK_FUNC(sub_82B43BA8);
PPC_FUNC_IMPL(__imp__sub_82B43BA8) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// b 0x82b4abe0
	sub_82B4ABE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B43BC8"))) PPC_WEAK_FUNC(sub_82B43BC8);
PPC_FUNC_IMPL(__imp__sub_82B43BC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,-25788
	ctx.r11.s64 = ctx.r11.s64 + -25788;
	// clrlwi. r10,r4,31
	ctx.r10.u64 = ctx.r4.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// beq 0x82b43bf4
	if (ctx.cr0.eq) goto loc_82B43BF4;
	// bl 0x82545ee8
	ctx.lr = 0x82B43BF4;
	sub_82545EE8(ctx, base);
loc_82B43BF4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B43C10"))) PPC_WEAK_FUNC(sub_82B43C10);
PPC_FUNC_IMPL(__imp__sub_82B43C10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,118
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 118, ctx.xer);
	// bne cr6,0x82b43ca4
	if (!ctx.cr6.eq) goto loc_82B43CA4;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B43C34:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b43c34
	if (!ctx.cr6.eq) goto loc_82B43C34;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// subf r10,r3,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r3.s64;
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// ble cr6,0x82b43ca4
	if (!ctx.cr6.gt) goto loc_82B43CA4;
	// addi r31,r11,-3
	ctx.r31.s64 = ctx.r11.s64 + -3;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r11,1024
	ctx.r4.s64 = ctx.r11.s64 + 1024;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e2efb0
	ctx.lr = 0x82B43C78;
	sub_82E2EFB0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b43c9c
	if (ctx.cr0.eq) goto loc_82B43C9C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r11,1020
	ctx.r4.s64 = ctx.r11.s64 + 1020;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e2efb0
	ctx.lr = 0x82B43C94;
	sub_82E2EFB0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b43ca4
	if (!ctx.cr0.eq) goto loc_82B43CA4;
loc_82B43C9C:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82b43ca8
	goto loc_82B43CA8;
loc_82B43CA4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B43CA8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B43CC0"))) PPC_WEAK_FUNC(sub_82B43CC0);
PPC_FUNC_IMPL(__imp__sub_82B43CC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B43CC8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,118
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 118, ctx.xer);
	// bne cr6,0x82b43d68
	if (!ctx.cr6.eq) goto loc_82B43D68;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B43CE8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b43ce8
	if (!ctx.cr6.eq) goto loc_82B43CE8;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// subf r10,r31,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r31.s64;
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// ble cr6,0x82b43d68
	if (!ctx.cr6.gt) goto loc_82B43D68;
	// addi r30,r11,-3
	ctx.r30.s64 = ctx.r11.s64 + -3;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r11,1024
	ctx.r4.s64 = ctx.r11.s64 + 1024;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82e2efb0
	ctx.lr = 0x82B43D2C;
	sub_82E2EFB0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b43d40
	if (!ctx.cr0.eq) goto loc_82B43D40;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,52
	ctx.r3.s64 = ctx.r11.s64 + 52;
	// b 0x82b43da0
	goto loc_82B43DA0;
loc_82B43D40:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,3
	ctx.r5.s64 = 3;
	// addi r4,r11,1020
	ctx.r4.s64 = ctx.r11.s64 + 1020;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82e2efb0
	ctx.lr = 0x82B43D54;
	sub_82E2EFB0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b43d68
	if (!ctx.cr0.eq) goto loc_82B43D68;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,40
	ctx.r3.s64 = ctx.r11.s64 + 40;
	// b 0x82b43da0
	goto loc_82B43DA0;
loc_82B43D68:
	// rlwinm. r11,r29,0,11,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x100000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b43d9c
	if (!ctx.cr0.eq) goto loc_82B43D9C;
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,118
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 118, ctx.xer);
	// bne cr6,0x82b43d8c
	if (!ctx.cr6.eq) goto loc_82B43D8C;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r31,r11,12940
	ctx.r31.s64 = ctx.r11.s64 + 12940;
	// b 0x82b43d9c
	goto loc_82B43D9C;
loc_82B43D8C:
	// cmpwi cr6,r11,112
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 112, ctx.xer);
	// bne cr6,0x82b43d9c
	if (!ctx.cr6.eq) goto loc_82B43D9C;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r31,r11,12932
	ctx.r31.s64 = ctx.r11.s64 + 12932;
loc_82B43D9C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82B43DA0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B43DA8"))) PPC_WEAK_FUNC(sub_82B43DA8);
PPC_FUNC_IMPL(__imp__sub_82B43DA8) {
	PPC_FUNC_PROLOGUE();
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82b43dc4
	if (!ctx.cr6.eq) goto loc_82B43DC4;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82b43e38
	goto loc_82B43E38;
loc_82B43DC4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r31,0
	ctx.r31.s64 = 0;
	// li r6,49
	ctx.r6.s64 = 49;
	// addi r30,r11,392
	ctx.r30.s64 = ctx.r11.s64 + 392;
loc_82B43DD4:
	// add r11,r6,r31
	ctx.r11.u64 = ctx.r6.u64 + ctx.r31.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// rlwinm r9,r11,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// lwzx r11,r11,r30
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
loc_82B43DE8:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b43e0c
	if (ctx.cr0.eq) goto loc_82B43E0C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b43de8
	if (ctx.cr6.eq) goto loc_82B43DE8;
loc_82B43E0C:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82b43e44
	if (ctx.cr0.eq) goto loc_82B43E44;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bge cr6,0x82b43e24
	if (!ctx.cr6.lt) goto loc_82B43E24;
	// addi r31,r9,1
	ctx.r31.s64 = ctx.r9.s64 + 1;
	// b 0x82b43e28
	goto loc_82B43E28;
loc_82B43E24:
	// mr r6,r9
	ctx.r6.u64 = ctx.r9.u64;
loc_82B43E28:
	// cmplw cr6,r31,r6
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82b43dd4
	if (ctx.cr6.lt) goto loc_82B43DD4;
loc_82B43E30:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_82B43E38:
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
loc_82B43E44:
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// addi r10,r30,8
	ctx.r10.s64 = ctx.r30.s64 + 8;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// and r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 & ctx.r4.u64;
	// cmplw cr6,r10,r4
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, ctx.xer);
	// bne cr6,0x82b43e30
	if (!ctx.cr6.eq) goto loc_82B43E30;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82b43e80
	if (ctx.cr6.eq) goto loc_82B43E80;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r10.u32);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r11,8(r5)
	PPC_STORE_U32(ctx.r5.u32 + 8, ctx.r11.u32);
loc_82B43E80:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b43e38
	goto loc_82B43E38;
}

__attribute__((alias("__imp__sub_82B43E88"))) PPC_WEAK_FUNC(sub_82B43E88);
PPC_FUNC_IMPL(__imp__sub_82B43E88) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r9,49
	ctx.r9.s64 = 49;
	// addi r10,r11,392
	ctx.r10.s64 = ctx.r11.s64 + 392;
	// addi r11,r10,596
	ctx.r11.s64 = ctx.r10.s64 + 596;
loc_82B43E98:
	// addi r11,r11,-12
	ctx.r11.s64 = ctx.r11.s64 + -12;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// lwz r8,-4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// cmplw cr6,r8,r3
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r3.u32, ctx.xer);
	// bne cr6,0x82b43ebc
	if (!ctx.cr6.eq) goto loc_82B43EBC;
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// and r8,r8,r4
	ctx.r8.u64 = ctx.r8.u64 & ctx.r4.u64;
	// cmplw cr6,r8,r4
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x82b43ed4
	if (ctx.cr6.eq) goto loc_82B43ED4;
loc_82B43EBC:
	// addi r8,r10,8
	ctx.r8.s64 = ctx.r10.s64 + 8;
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// bgt cr6,0x82b43e98
	if (ctx.cr6.gt) goto loc_82B43E98;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// blr 
	return;
loc_82B43ED4:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82b43efc
	if (ctx.cr6.eq) goto loc_82B43EFC;
	// mulli r11,r9,12
	ctx.r11.s64 = ctx.r9.s64 * 12;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r10.u32);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r11,8(r5)
	PPC_STORE_U32(ctx.r5.u32 + 8, ctx.r11.u32);
loc_82B43EFC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B43F08"))) PPC_WEAK_FUNC(sub_82B43F08);
PPC_FUNC_IMPL(__imp__sub_82B43F08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B43F10;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r28,0
	ctx.r28.s64 = 0;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82b43f34
	if (!ctx.cr6.eq) goto loc_82B43F34;
	// lis r29,-32761
	ctx.r29.s64 = -2147024896;
	// ori r29,r29,87
	ctx.r29.u64 = ctx.r29.u64 | 87;
	// b 0x82b43f68
	goto loc_82B43F68;
loc_82B43F34:
	// addi r31,r4,-1
	ctx.r31.s64 = ctx.r4.s64 + -1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82e2d1c0
	ctx.lr = 0x82B43F44;
	sub_82E2D1C0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b43f5c
	if (ctx.cr0.lt) goto loc_82B43F5C;
	// cmplw cr6,r3,r31
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r31.u32, ctx.xer);
	// bgt cr6,0x82b43f5c
	if (ctx.cr6.gt) goto loc_82B43F5C;
	// bne cr6,0x82b43f68
	if (!ctx.cr6.eq) goto loc_82B43F68;
	// b 0x82b43f64
	goto loc_82B43F64;
loc_82B43F5C:
	// lis r29,-32761
	ctx.r29.s64 = -2147024896;
	// ori r29,r29,122
	ctx.r29.u64 = ctx.r29.u64 | 122;
loc_82B43F64:
	// stbx r28,r31,r30
	PPC_STORE_U8(ctx.r31.u32 + ctx.r30.u32, ctx.r28.u8);
loc_82B43F68:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B43F78"))) PPC_WEAK_FUNC(sub_82B43F78);
PPC_FUNC_IMPL(__imp__sub_82B43F78) {
	PPC_FUNC_PROLOGUE();
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// b 0x82547910
	sub_82547910(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B43F80"))) PPC_WEAK_FUNC(sub_82B43F80);
PPC_FUNC_IMPL(__imp__sub_82B43F80) {
	PPC_FUNC_PROLOGUE();
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// b 0x82547938
	sub_82547938(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B43F88"))) PPC_WEAK_FUNC(sub_82B43F88);
PPC_FUNC_IMPL(__imp__sub_82B43F88) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lis r10,-32229
	ctx.r10.s64 = -2112159744;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r4,r10,-29761
	ctx.r4.s64 = ctx.r10.s64 + -29761;
	// lwz r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r6,8(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// b 0x82b4ace0
	sub_82B4ACE0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B43FB0"))) PPC_WEAK_FUNC(sub_82B43FB0);
PPC_FUNC_IMPL(__imp__sub_82B43FB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B43FB8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r31,0
	ctx.r31.s64 = 0;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b43fd4
	if (ctx.cr6.eq) goto loc_82B43FD4;
	// stw r31,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r31.u32);
loc_82B43FD4:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82b43fe8
	if (!ctx.cr6.eq) goto loc_82B43FE8;
loc_82B43FDC:
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82b44090
	goto loc_82B44090;
loc_82B43FE8:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b43fdc
	if (ctx.cr6.eq) goto loc_82B43FDC;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lis r10,4138
	ctx.r10.s64 = 271187968;
	// ori r10,r10,4352
	ctx.r10.u64 = ctx.r10.u64 | 4352;
	// rlwinm r9,r11,0,0,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF00;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b44024
	if (ctx.cr6.eq) goto loc_82B44024;
	// rlwinm r11,r11,0,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFF0000;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b44024
	if (ctx.cr6.eq) goto loc_82B44024;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82b44088
	if (!ctx.cr6.eq) goto loc_82B44088;
loc_82B44024:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,32
	ctx.r3.s64 = 32;
	// bl 0x82547910
	ctx.lr = 0x82B44030;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b44040
	if (ctx.cr0.eq) goto loc_82B44040;
	// bl 0x82b513c0
	ctx.lr = 0x82B4403C;
	sub_82B513C0(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
loc_82B44040:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82b44054
	if (!ctx.cr6.eq) goto loc_82B44054;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b44090
	goto loc_82B44090;
loc_82B44054:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b518e8
	ctx.lr = 0x82B44064;
	sub_82B518E8(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bge 0x82b44088
	if (!ctx.cr0.lt) goto loc_82B44088;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b505a8
	ctx.lr = 0x82B44074;
	sub_82B505A8(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82547938
	ctx.lr = 0x82B44080;
	sub_82547938(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// b 0x82b44090
	goto loc_82B44090;
loc_82B44088:
	// stw r31,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r31.u32);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B44090:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B44098"))) PPC_WEAK_FUNC(sub_82B44098);
PPC_FUNC_IMPL(__imp__sub_82B44098) {
	PPC_FUNC_PROLOGUE();
	// b 0x82b43fb0
	sub_82B43FB0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B440A0"))) PPC_WEAK_FUNC(sub_82B440A0);
PPC_FUNC_IMPL(__imp__sub_82B440A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82B440A8;
	__savegprlr_19(ctx, base);
	// stwu r1,-1152(r1)
	ea = -1152 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r20,0
	ctx.r20.s64 = 0;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r24,r5
	ctx.r24.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r20.u32);
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// stw r20,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r20.u32);
	// mr r19,r8
	ctx.r19.u64 = ctx.r8.u64;
	// mr r21,r9
	ctx.r21.u64 = ctx.r9.u64;
	// mr r27,r10
	ctx.r27.u64 = ctx.r10.u64;
	// bl 0x82b48a70
	ctx.lr = 0x82B440E0;
	sub_82B48A70(ctx, base);
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82b440ec
	if (ctx.cr6.eq) goto loc_82B440EC;
	// stw r20,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r20.u32);
loc_82B440EC:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82b440f8
	if (ctx.cr6.eq) goto loc_82B440F8;
	// stw r20,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r20.u32);
loc_82B440F8:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82b44118
	if (ctx.cr6.eq) goto loc_82B44118;
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b44118
	if (ctx.cr6.eq) goto loc_82B44118;
	// lis r30,-30602
	ctx.r30.s64 = -2005532672;
	// ori r30,r30,2156
	ctx.r30.u64 = ctx.r30.u64 | 2156;
	// b 0x82b446e8
	goto loc_82B446E8;
loc_82B44118:
	// lis r12,-863
	ctx.r12.s64 = -56557568;
	// ori r12,r12,57792
	ctx.r12.u64 = ctx.r12.u64 | 57792;
	// and. r11,r29,r12
	ctx.r11.u64 = ctx.r29.u64 & ctx.r12.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b44134
	if (ctx.cr0.eq) goto loc_82B44134;
loc_82B44128:
	// lis r30,-30602
	ctx.r30.s64 = -2005532672;
	// ori r30,r30,2156
	ctx.r30.u64 = ctx.r30.u64 | 2156;
	// b 0x82b446cc
	goto loc_82B446CC;
loc_82B44134:
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b44128
	if (ctx.cr6.eq) goto loc_82B44128;
	// mr r31,r20
	ctx.r31.u64 = ctx.r20.u64;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82b4457c
	if (ctx.cr6.eq) goto loc_82B4457C;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// rlwinm. r11,r11,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b4457c
	if (ctx.cr0.eq) goto loc_82B4457C;
	// bl 0x82e55b98
	ctx.lr = 0x82B4415C;
	sub_82E55B98(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// stw r31,20(r27)
	PPC_STORE_U32(ctx.r27.u32 + 20, ctx.r31.u32);
	// bne 0x82b44174
	if (!ctx.cr0.eq) goto loc_82B44174;
	// lis r30,-32761
	ctx.r30.s64 = -2147024896;
	// ori r30,r30,14
	ctx.r30.u64 = ctx.r30.u64 | 14;
	// b 0x82b446cc
	goto loc_82B446CC;
loc_82B44174:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r11,1308
	ctx.r4.s64 = ctx.r11.s64 + 1308;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e53de8
	ctx.lr = 0x82B44188;
	sub_82E53DE8(ctx, base);
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B4419C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b441dc
	if (ctx.cr0.eq) goto loc_82B441DC;
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B441B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// b 0x82b441d0
	goto loc_82B441D0;
loc_82B441C0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,4(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x82e564f0
	ctx.lr = 0x82B441CC;
	sub_82E564F0(ctx, base);
	// addi r30,r30,8
	ctx.r30.s64 = ctx.r30.s64 + 8;
loc_82B441D0:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi r4,0
	ctx.cr0.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne 0x82b441c0
	if (!ctx.cr0.eq) goto loc_82B441C0;
loc_82B441DC:
	// clrlwi. r11,r29,31
	ctx.r11.u64 = ctx.r29.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// addi r28,r11,-27152
	ctx.r28.s64 = ctx.r11.s64 + -27152;
	// lis r11,-32245
	ctx.r11.s64 = -2113208320;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r26,r11,2824
	ctx.r26.s64 = ctx.r11.s64 + 2824;
	// bne 0x82b441fc
	if (!ctx.cr0.eq) goto loc_82B441FC;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B441FC:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1184
	ctx.r4.s64 = ctx.r11.s64 + 1184;
	// bl 0x82e55be0
	ctx.lr = 0x82B4420C;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x2;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b4421c
	if (!ctx.cr0.eq) goto loc_82B4421C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B4421C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1180
	ctx.r4.s64 = ctx.r11.s64 + 1180;
	// bl 0x82e55be0
	ctx.lr = 0x82B4422C;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,11,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x100000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b4423c
	if (!ctx.cr0.eq) goto loc_82B4423C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B4423C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1164
	ctx.r4.s64 = ctx.r11.s64 + 1164;
	// bl 0x82e55be0
	ctx.lr = 0x82B4424C;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,14,14
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x20000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b4425c
	if (!ctx.cr0.eq) goto loc_82B4425C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B4425C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1148
	ctx.r4.s64 = ctx.r11.s64 + 1148;
	// bl 0x82e55be0
	ctx.lr = 0x82B4426C;
	sub_82E55BE0(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r11,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44280
	if (!ctx.cr0.eq) goto loc_82B44280;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B44280:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1140
	ctx.r4.s64 = ctx.r11.s64 + 1140;
	// bl 0x82e55be0
	ctx.lr = 0x82B44290;
	sub_82E55BE0(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r11,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b442a4
	if (!ctx.cr0.eq) goto loc_82B442A4;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B442A4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1132
	ctx.r4.s64 = ctx.r11.s64 + 1132;
	// bl 0x82e55be0
	ctx.lr = 0x82B442B4;
	sub_82E55BE0(ctx, base);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// li r4,16
	ctx.r4.s64 = 16;
	// lwz r6,16(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// addi r30,r11,-27624
	ctx.r30.s64 = ctx.r11.s64 + -27624;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82b528d0
	ctx.lr = 0x82B442D0;
	sub_82B528D0(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,1116
	ctx.r4.s64 = ctx.r11.s64 + 1116;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e55be0
	ctx.lr = 0x82B442E4;
	sub_82E55BE0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,32(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 32);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b528d0
	ctx.lr = 0x82B442F8;
	sub_82B528D0(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,1104
	ctx.r4.s64 = ctx.r11.s64 + 1104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e55be0
	ctx.lr = 0x82B4430C;
	sub_82E55BE0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,36(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b528d0
	ctx.lr = 0x82B44320;
	sub_82B528D0(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,1092
	ctx.r4.s64 = ctx.r11.s64 + 1092;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e55be0
	ctx.lr = 0x82B44334;
	sub_82E55BE0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,40(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 40);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b528d0
	ctx.lr = 0x82B44348;
	sub_82B528D0(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,1080
	ctx.r4.s64 = ctx.r11.s64 + 1080;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e55be0
	ctx.lr = 0x82B4435C;
	sub_82E55BE0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,44(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 44);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b528d0
	ctx.lr = 0x82B44370;
	sub_82B528D0(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,1068
	ctx.r4.s64 = ctx.r11.s64 + 1068;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e55be0
	ctx.lr = 0x82B44384;
	sub_82E55BE0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,52(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 52);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b528d0
	ctx.lr = 0x82B44398;
	sub_82B528D0(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,1056
	ctx.r4.s64 = ctx.r11.s64 + 1056;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e55be0
	ctx.lr = 0x82B443AC;
	sub_82E55BE0(ctx, base);
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,48(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 48);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b528d0
	ctx.lr = 0x82B443C0;
	sub_82B528D0(ctx, base);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r11,1044
	ctx.r4.s64 = ctx.r11.s64 + 1044;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e55be0
	ctx.lr = 0x82B443D4;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b443e4
	if (!ctx.cr0.eq) goto loc_82B443E4;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B443E4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1304
	ctx.r4.s64 = ctx.r11.s64 + 1304;
	// bl 0x82e55be0
	ctx.lr = 0x82B443F4;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44404
	if (!ctx.cr0.eq) goto loc_82B44404;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B44404:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1296
	ctx.r4.s64 = ctx.r11.s64 + 1296;
	// bl 0x82e55be0
	ctx.lr = 0x82B44414;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44424
	if (!ctx.cr0.eq) goto loc_82B44424;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B44424:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1288
	ctx.r4.s64 = ctx.r11.s64 + 1288;
	// bl 0x82e55be0
	ctx.lr = 0x82B44434;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44444
	if (!ctx.cr0.eq) goto loc_82B44444;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B44444:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1280
	ctx.r4.s64 = ctx.r11.s64 + 1280;
	// bl 0x82e55be0
	ctx.lr = 0x82B44454;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x100;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44464
	if (!ctx.cr0.eq) goto loc_82B44464;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B44464:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1276
	ctx.r4.s64 = ctx.r11.s64 + 1276;
	// bl 0x82e55be0
	ctx.lr = 0x82B44474;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,22,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x200;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44484
	if (!ctx.cr0.eq) goto loc_82B44484;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B44484:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1268
	ctx.r4.s64 = ctx.r11.s64 + 1268;
	// bl 0x82e55be0
	ctx.lr = 0x82B44494;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,21,21
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x400;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b444a4
	if (!ctx.cr0.eq) goto loc_82B444A4;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B444A4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1260
	ctx.r4.s64 = ctx.r11.s64 + 1260;
	// bl 0x82e55be0
	ctx.lr = 0x82B444B4;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,13,13
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x40000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b444c4
	if (!ctx.cr0.eq) goto loc_82B444C4;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B444C4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1244
	ctx.r4.s64 = ctx.r11.s64 + 1244;
	// bl 0x82e55be0
	ctx.lr = 0x82B444D4;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,9,9
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x400000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b444e4
	if (!ctx.cr0.eq) goto loc_82B444E4;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B444E4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1236
	ctx.r4.s64 = ctx.r11.s64 + 1236;
	// bl 0x82e55be0
	ctx.lr = 0x82B444F4;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,6,6
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x2000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44504
	if (!ctx.cr0.eq) goto loc_82B44504;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B44504:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1228
	ctx.r4.s64 = ctx.r11.s64 + 1228;
	// bl 0x82e55be0
	ctx.lr = 0x82B44514;
	sub_82E55BE0(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r29,0,7,7
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 0) & 0x1000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44524
	if (!ctx.cr0.eq) goto loc_82B44524;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B44524:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1220
	ctx.r4.s64 = ctx.r11.s64 + 1220;
	// bl 0x82e55be0
	ctx.lr = 0x82B44534;
	sub_82E55BE0(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r11,0,28,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44548
	if (!ctx.cr0.eq) goto loc_82B44548;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B44548:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1200
	ctx.r4.s64 = ctx.r11.s64 + 1200;
	// bl 0x82e55be0
	ctx.lr = 0x82B44558;
	sub_82E55BE0(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// rlwinm. r11,r11,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b4456c
	if (!ctx.cr0.eq) goto loc_82B4456C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
loc_82B4456C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,1188
	ctx.r4.s64 = ctx.r11.s64 + 1188;
	// bl 0x82e55be0
	ctx.lr = 0x82B4457C;
	sub_82E55BE0(ctx, base);
loc_82B4457C:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82b43cc0
	ctx.lr = 0x82B44588;
	sub_82B43CC0(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stw r27,1028(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1028, ctx.r27.u32);
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// stw r11,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r11.u32);
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B445AC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b446cc
	if (ctx.cr0.lt) goto loc_82B446CC;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// bl 0x82b43c10
	ctx.lr = 0x82B445BC;
	sub_82B43C10(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// beq 0x82b445d4
	if (ctx.cr0.eq) goto loc_82B445D4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r4,r11,1008
	ctx.r4.s64 = ctx.r11.s64 + 1008;
	// b 0x82b445dc
	goto loc_82B445DC;
loc_82B445D4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r4,r11,992
	ctx.r4.s64 = ctx.r11.s64 + 992;
loc_82B445DC:
	// bl 0x82b49c68
	ctx.lr = 0x82B445E0;
	sub_82B49C68(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b59f90
	ctx.lr = 0x82B445EC;
	sub_82B59F90(ctx, base);
	// addi r11,r1,100
	ctx.r11.s64 = ctx.r1.s64 + 100;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwz r8,0(r24)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// ori r9,r29,256
	ctx.r9.u64 = ctx.r29.u64 | 256;
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b6fec8
	ctx.lr = 0x82B4461C;
	sub_82B6FEC8(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bge 0x82b44630
	if (!ctx.cr0.lt) goto loc_82B44630;
	// bl 0x82b5bf08
	ctx.lr = 0x82B4462C;
	sub_82B5BF08(ctx, base);
	// b 0x82b446cc
	goto loc_82B446CC;
loc_82B44630:
	// bl 0x82b5bf08
	ctx.lr = 0x82B44634;
	sub_82B5BF08(ctx, base);
	// addi r3,r1,360
	ctx.r3.s64 = ctx.r1.s64 + 360;
	// bl 0x82266898
	ctx.lr = 0x82B4463C;
	sub_82266898(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b44650
	if (ctx.cr0.eq) goto loc_82B44650;
	// lis r30,-30602
	ctx.r30.s64 = -2005532672;
	// ori r30,r30,2905
	ctx.r30.u64 = ctx.r30.u64 | 2905;
	// b 0x82b446cc
	goto loc_82B446CC;
loc_82B44650:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b446a4
	if (ctx.cr6.eq) goto loc_82B446A4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e56668
	ctx.lr = 0x82B44660;
	sub_82E56668(ctx, base);
	// addi r28,r27,12
	ctx.r28.s64 = ctx.r27.s64 + 12;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82b4ca90
	ctx.lr = 0x82B44670;
	sub_82B4CA90(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b446a4
	if (ctx.cr0.lt) goto loc_82B446A4;
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B4468C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e56670
	ctx.lr = 0x82B446A0;
	sub_82E56670(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82B446A4:
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82b446b8
	if (ctx.cr6.eq) goto loc_82B446B8;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r20.u32);
	// stw r11,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r11.u32);
loc_82B446B8:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82b446cc
	if (ctx.cr6.eq) goto loc_82B446CC;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r20,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r20.u32);
	// stw r11,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r11.u32);
loc_82B446CC:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82b446e8
	if (ctx.cr6.eq) goto loc_82B446E8;
	// lwz r3,20(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b446e8
	if (ctx.cr0.eq) goto loc_82B446E8;
	// bl 0x82269ef8
	ctx.lr = 0x82B446E4;
	sub_82269EF8(ctx, base);
	// stw r20,20(r27)
	PPC_STORE_U32(ctx.r27.u32 + 20, ctx.r20.u32);
loc_82B446E8:
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82b446fc
	if (ctx.cr6.eq) goto loc_82B446FC;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// addi r3,r1,360
	ctx.r3.s64 = ctx.r1.s64 + 360;
	// bl 0x82b51d38
	ctx.lr = 0x82B446FC;
	sub_82B51D38(ctx, base);
loc_82B446FC:
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b4471c
	if (ctx.cr6.eq) goto loc_82B4471C;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44718;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r20,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r20.u32);
loc_82B4471C:
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b4473c
	if (ctx.cr6.eq) goto loc_82B4473C;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44738;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r20.u32);
loc_82B4473C:
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// bl 0x82b48b80
	ctx.lr = 0x82B44744;
	sub_82B48B80(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,1152
	ctx.r1.s64 = ctx.r1.s64 + 1152;
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B44750"))) PPC_WEAK_FUNC(sub_82B44750);
PPC_FUNC_IMPL(__imp__sub_82B44750) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e38
	ctx.lr = 0x82B44758;
	__savegprlr_16(ctx, base);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-31967
	ctx.r30.s64 = -2094989312;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// lbz r11,29265(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 29265);
	// mr r24,r7
	ctx.r24.u64 = ctx.r7.u64;
	// mr r22,r8
	ctx.r22.u64 = ctx.r8.u64;
	// mr r21,r9
	ctx.r21.u64 = ctx.r9.u64;
	// mr r23,r10
	ctx.r23.u64 = ctx.r10.u64;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lis r29,-31967
	ctx.r29.s64 = -2094989312;
	// bne 0x82b447c0
	if (!ctx.cr0.eq) goto loc_82B447C0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,1544
	ctx.r3.s64 = ctx.r11.s64 + 1544;
	// bl 0x82b086c0
	ctx.lr = 0x82B4479C;
	sub_82B086C0(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82b447b8
	if (ctx.cr6.eq) goto loc_82B447B8;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,1456
	ctx.r3.s64 = ctx.r11.s64 + 1456;
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,29264(r29)
	PPC_STORE_U8(ctx.r29.u32 + 29264, ctx.r11.u8);
	// bl 0x82b067c0
	ctx.lr = 0x82B447B8;
	sub_82B067C0(ctx, base);
loc_82B447B8:
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,29265(r30)
	PPC_STORE_U8(ctx.r30.u32 + 29265, ctx.r11.u8);
loc_82B447C0:
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// mr r8,r22
	ctx.r8.u64 = ctx.r22.u64;
	// mr r7,r24
	ctx.r7.u64 = ctx.r24.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b440a0
	ctx.lr = 0x82B447E4;
	sub_82B440A0(ctx, base);
	// mr. r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// blt 0x82b44c10
	if (ctx.cr0.lt) goto loc_82B44C10;
	// lbz r11,29264(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 29264);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b44c10
	if (ctx.cr0.eq) goto loc_82B44C10;
	// rlwinm. r11,r31,0,6,6
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x2000000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44c10
	if (!ctx.cr0.eq) goto loc_82B44C10;
	// rlwinm. r11,r31,0,11,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x100000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44c10
	if (!ctx.cr0.eq) goto loc_82B44C10;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82b44c10
	if (ctx.cr6.eq) goto loc_82B44C10;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b44c10
	if (ctx.cr6.eq) goto loc_82B44C10;
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// oris r6,r31,16
	ctx.r6.u64 = ctx.r31.u64 | 1048576;
	// oris r26,r31,512
	ctx.r26.u64 = ctx.r31.u64 | 33554432;
	// stw r29,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r29.u32);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r29.u32);
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r29.u32);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r29.u32);
	// cmplwi cr6,r11,118
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 118, ctx.xer);
	// bne cr6,0x82b44854
	if (!ctx.cr6.eq) goto loc_82B44854;
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r11,r11,12940
	ctx.r11.s64 = ctx.r11.s64 + 12940;
	// b 0x82b4485c
	goto loc_82B4485C;
loc_82B44854:
	// lis r11,-32240
	ctx.r11.s64 = -2112880640;
	// addi r11,r11,12932
	ctx.r11.s64 = ctx.r11.s64 + 12932;
loc_82B4485C:
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r11.u32);
	// addi r9,r1,120
	ctx.r9.s64 = ctx.r1.s64 + 120;
	// addi r8,r1,116
	ctx.r8.s64 = ctx.r1.s64 + 116;
	// addi r7,r1,124
	ctx.r7.s64 = ctx.r1.s64 + 124;
	// addi r5,r1,132
	ctx.r5.s64 = ctx.r1.s64 + 132;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b440a0
	ctx.lr = 0x82B44880;
	sub_82B440A0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b4489c
	if (!ctx.cr0.lt) goto loc_82B4489C;
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
loc_82B4488C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b44c10
	if (ctx.cr6.eq) goto loc_82B44C10;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// b 0x82b44c04
	goto loc_82B44C04;
loc_82B4489C:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lis r3,1
	ctx.r3.s64 = 65536;
	// bl 0x82b4ca90
	ctx.lr = 0x82B448A8;
	sub_82B4CA90(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b448f4
	if (!ctx.cr0.lt) goto loc_82B448F4;
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b448d0
	if (ctx.cr6.eq) goto loc_82B448D0;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B448CC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r29.u32);
loc_82B448D0:
	// lwz r3,124(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b448ec
	if (ctx.cr6.eq) goto loc_82B448EC;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B448EC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B448EC:
	// lwz r3,120(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// b 0x82b4488c
	goto loc_82B4488C;
loc_82B448F4:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r29,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r29.u32);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B4490C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44928;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// bl 0x82e29500
	ctx.lr = 0x82B44934;
	sub_82E29500(ctx, base);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82b44944
	if (ctx.cr6.eq) goto loc_82B44944;
	// lwz r30,16(r23)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r23.u32 + 16);
	// b 0x82b44948
	goto loc_82B44948;
loc_82B44944:
	// mr r30,r29
	ctx.r30.u64 = ctx.r29.u64;
loc_82B44948:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lis r11,-32219
	ctx.r11.s64 = -2111504384;
	// lwz r28,120(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// addi r19,r1,128
	ctx.r19.s64 = ctx.r1.s64 + 128;
	// addi r27,r11,-21176
	ctx.r27.s64 = ctx.r11.s64 + -21176;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,16(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B4496C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r18,r3
	ctx.r18.u64 = ctx.r3.u64;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44988;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r31,124(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// mr r17,r3
	ctx.r17.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B449A4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B449BC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r16
	ctx.r4.u64 = ctx.r16.u64;
	// mr r5,r17
	ctx.r5.u64 = ctx.r17.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// mr r6,r18
	ctx.r6.u64 = ctx.r18.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// mr r7,r19
	ctx.r7.u64 = ctx.r19.u64;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// bl 0x82e5a890
	ctx.lr = 0x82B449E8;
	sub_82E5A890(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b44a48
	if (!ctx.cr0.lt) goto loc_82B44A48;
loc_82B449F0:
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b44a10
	if (ctx.cr6.eq) goto loc_82B44A10;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44A0C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r29.u32);
loc_82B44A10:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44A24;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82b44a40
	if (ctx.cr6.eq) goto loc_82B44A40;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44A40;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B44A40:
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// b 0x82b4488c
	goto loc_82B4488C;
loc_82B44A48:
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,118
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 118, ctx.xer);
	// bne cr6,0x82b44a74
	if (!ctx.cr6.eq) goto loc_82B44A74;
	// bl 0x82f591c0
	ctx.lr = 0x82B44A70;
	sub_82F591C0(ctx, base);
	// b 0x82b44a78
	goto loc_82B44A78;
loc_82B44A74:
	// bl 0x82f591c0
	ctx.lr = 0x82B44A78;
	sub_82F591C0(ctx, base);
loc_82B44A78:
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82b44ba8
	if (!ctx.cr6.eq) goto loc_82B44BA8;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r3,r11,1320
	ctx.r3.s64 = ctx.r11.s64 + 1320;
	// bl 0x82b067c0
	ctx.lr = 0x82B44A8C;
	sub_82B067C0(ctx, base);
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// lwz r3,128(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r29.u32);
	// bl 0x82b4ca90
	ctx.lr = 0x82B44A9C;
	sub_82B4CA90(ctx, base);
	// mr. r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// blt 0x82b449f0
	if (ctx.cr0.lt) goto loc_82B449F0;
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r30,128(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44ABC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44AD8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B44AE4;
	sub_82E28FD0(ctx, base);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b44b00
	if (ctx.cr6.eq) goto loc_82B44B00;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44B00;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B44B00:
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44B1C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44B30;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r11,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r11.u32);
	// lwz r3,0(r22)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b44b54
	if (ctx.cr0.eq) goto loc_82B44B54;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44B54;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B44B54:
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r11,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r11.u32);
	// lwz r3,0(r21)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b44b78
	if (ctx.cr0.eq) goto loc_82B44B78;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44B78;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B44B78:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// stw r28,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r28.u32);
	// beq cr6,0x82b44c10
	if (ctx.cr6.eq) goto loc_82B44C10;
	// lwz r3,12(r23)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r23.u32 + 12);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b44c10
	if (ctx.cr0.eq) goto loc_82B44C10;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44BA0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r29,12(r23)
	PPC_STORE_U32(ctx.r23.u32 + 12, ctx.r29.u32);
	// b 0x82b44c10
	goto loc_82B44C10;
loc_82B44BA8:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44BBC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b44bd8
	if (ctx.cr6.eq) goto loc_82B44BD8;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44BD8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B44BD8:
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b44bf4
	if (ctx.cr6.eq) goto loc_82B44BF4;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44BF4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B44BF4:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82b44c10
	if (ctx.cr6.eq) goto loc_82B44C10;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
loc_82B44C04:
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44C10;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B44C10:
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x82e28e88
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B44C20"))) PPC_WEAK_FUNC(sub_82B44C20);
PPC_FUNC_IMPL(__imp__sub_82B44C20) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82B44C28;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// mr r25,r9
	ctx.r25.u64 = ctx.r9.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// bl 0x82b44750
	ctx.lr = 0x82B44C50;
	sub_82B44750(ctx, base);
	// lis r11,-30602
	ctx.r11.s64 = -2005532672;
	// ori r11,r11,2924
	ctx.r11.u64 = ctx.r11.u64 | 2924;
	// cmpw cr6,r3,r11
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82b44c8c
	if (!ctx.cr6.eq) goto loc_82B44C8C;
	// rlwinm. r11,r31,0,29,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x4;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44c8c
	if (!ctx.cr0.eq) goto loc_82B44C8C;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// ori r6,r31,4
	ctx.r6.u64 = ctx.r31.u64 | 4;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b44750
	ctx.lr = 0x82B44C8C;
	sub_82B44750(ctx, base);
loc_82B44C8C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B44C98"))) PPC_WEAK_FUNC(sub_82B44C98);
PPC_FUNC_IMPL(__imp__sub_82B44C98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B44CA0;
	__savegprlr_26(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r31,0
	ctx.r31.s64 = 0;
	// stw r5,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r5.u32);
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// mr r30,r9
	ctx.r30.u64 = ctx.r9.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r31.u32);
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r31.u32);
	// bne cr6,0x82b44cec
	if (!ctx.cr6.eq) goto loc_82B44CEC;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82B44CDC:
	// std r9,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r9.u64);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bdnz 0x82b44cdc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B44CDC;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
loc_82B44CEC:
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82b44d18
	if (ctx.cr6.eq) goto loc_82B44D18;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,118
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 118, ctx.xer);
	// beq cr6,0x82b44d18
	if (ctx.cr6.eq) goto loc_82B44D18;
	// cmpwi cr6,r11,112
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 112, ctx.xer);
	// beq cr6,0x82b44d18
	if (ctx.cr6.eq) goto loc_82B44D18;
	// li r9,1
	ctx.r9.s64 = 1;
	// oris r6,r6,16
	ctx.r6.u64 = ctx.r6.u64 | 1048576;
loc_82B44D18:
	// clrlwi. r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44dec
	if (!ctx.cr0.eq) goto loc_82B44DEC;
	// rlwinm. r11,r6,0,11,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x100000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b44dec
	if (!ctx.cr0.eq) goto loc_82B44DEC;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// bl 0x82b44c20
	ctx.lr = 0x82B44D3C;
	sub_82B44C20(ctx, base);
	// mr. r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// blt 0x82b44d78
	if (ctx.cr0.lt) goto loc_82B44D78;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82b44d5c
	if (ctx.cr6.eq) goto loc_82B44D5C;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// b 0x82b44d60
	goto loc_82B44D60;
loc_82B44D5C:
	// lwz r29,80(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82B44D60:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82b44d7c
	if (ctx.cr6.eq) goto loc_82B44D7C;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// b 0x82b44d80
	goto loc_82B44D80;
loc_82B44D78:
	// lwz r29,80(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82B44D7C:
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82B44D80:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82b44d94
	if (ctx.cr6.eq) goto loc_82B44D94;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r31.u32);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
loc_82B44D94:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b44dac
	if (ctx.cr6.eq) goto loc_82B44DAC;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44DAC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B44DAC:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b44dc8
	if (ctx.cr6.eq) goto loc_82B44DC8;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44DC8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B44DC8:
	// lwz r3,88(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b44de4
	if (ctx.cr6.eq) goto loc_82B44DE4;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B44DE4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B44DE4:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// b 0x82b44e00
	goto loc_82B44E00;
loc_82B44DEC:
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// bl 0x82b44c20
	ctx.lr = 0x82B44E00;
	sub_82B44C20(ctx, base);
loc_82B44E00:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B44E08"))) PPC_WEAK_FUNC(sub_82B44E08);
PPC_FUNC_IMPL(__imp__sub_82B44E08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B44E10;
	__savegprlr_28(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r31.u32);
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// addi r28,r10,1028
	ctx.r28.s64 = ctx.r10.s64 + 1028;
	// mr r5,r8
	ctx.r5.u64 = ctx.r8.u64;
	// lwz r8,228(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// mr r6,r9
	ctx.r6.u64 = ctx.r9.u64;
	// lwz r9,236(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r29.u32);
	// bl 0x82b44c98
	ctx.lr = 0x82B44E64;
	sub_82B44C98(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B44E70"))) PPC_WEAK_FUNC(sub_82B44E70);
PPC_FUNC_IMPL(__imp__sub_82B44E70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B44E78;
	__savegprlr_29(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r6,r8
	ctx.r6.u64 = ctx.r8.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// addi r29,r10,980
	ctx.r29.s64 = ctx.r10.s64 + 980;
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// lwz r9,228(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r29.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x82b44c98
	ctx.lr = 0x82B44ECC;
	sub_82B44C98(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B44ED8"))) PPC_WEAK_FUNC(sub_82B44ED8);
PPC_FUNC_IMPL(__imp__sub_82B44ED8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// vspltisw v0,1
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_set1_epi32(int(0x1)));
	// vspltisw v10,-1
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_set1_epi32(int(0xFFFFFFFF)));
	// vmulfp128 v8,v1,v1
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v8.f32, _mm_mul_ps(_mm_load_ps(ctx.v1.f32), _mm_load_ps(ctx.v1.f32)));
	// addi r11,r11,1584
	ctx.r11.s64 = ctx.r11.s64 + 1584;
	// vcfsx v11,v0,1
	_mm_store_ps(ctx.v11.f32, _mm_mul_ps(_mm_cvtepi32_ps(_mm_load_si128((__m128i*)ctx.v0.u32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x3F000000)))));
	// lvx128 v9,r0,r11
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// addi r11,r11,-29936
	ctx.r11.s64 = ctx.r11.s64 + -29936;
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// vspltw v7,v0,3
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x0));
	// addi r11,r11,-29952
	ctx.r11.s64 = ctx.r11.s64 + -29952;
	// vspltw v5,v0,2
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x55));
	// vspltw v31,v0,1
	_mm_store_si128((__m128i*)ctx.v31.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xAA));
	// vspltw v29,v0,0
	_mm_store_si128((__m128i*)ctx.v29.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vslw v0,v10,v10
	ctx.v0.u32[0] = ctx.v10.u32[0] << (ctx.v10.u8[0] & 0x1F);
	ctx.v0.u32[1] = ctx.v10.u32[1] << (ctx.v10.u8[4] & 0x1F);
	ctx.v0.u32[2] = ctx.v10.u32[2] << (ctx.v10.u8[8] & 0x1F);
	ctx.v0.u32[3] = ctx.v10.u32[3] << (ctx.v10.u8[12] & 0x1F);
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// vandc v0,v1,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_andnot_si128(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v1.u8)));
	// vspltw v6,v13,3
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x0));
	// addi r11,r11,-29920
	ctx.r11.s64 = ctx.r11.s64 + -29920;
	// vspltw v4,v13,2
	_mm_store_si128((__m128i*)ctx.v4.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x55));
	// vspltw v30,v13,1
	_mm_store_si128((__m128i*)ctx.v30.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xAA));
	// vspltw v13,v13,0
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xFF));
	// vmulfp128 v10,v8,v0
	_mm_store_ps(ctx.v10.f32, _mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v8,v4,v0,v5
	_mm_store_ps(ctx.v8.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v4.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v5.f32)));
	// lvx128 v12,r0,r11
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// vspltw v3,v12,3
	_mm_store_si128((__m128i*)ctx.v3.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0x0));
	// vmaddfp v13,v13,v0,v29
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v29.f32)));
	// vspltw v2,v12,2
	_mm_store_si128((__m128i*)ctx.v2.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0x55));
	// addi r11,r11,-29888
	ctx.r11.s64 = ctx.r11.s64 + -29888;
	// vspltw v28,v12,1
	_mm_store_si128((__m128i*)ctx.v28.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0xAA));
	// vspltw v27,v12,0
	_mm_store_si128((__m128i*)ctx.v27.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v12.u32), 0xFF));
	// vsubfp v12,v9,v0
	_mm_store_ps(ctx.v12.f32, _mm_sub_ps(_mm_load_ps(ctx.v9.f32), _mm_load_ps(ctx.v0.f32)));
	// vmaddfp v9,v6,v0,v7
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v6.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v7.f32)));
	// vmaddfp v7,v30,v0,v31
	_mm_store_ps(ctx.v7.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v30.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v31.f32)));
	// vmaddfp v8,v8,v0,v2
	_mm_store_ps(ctx.v8.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v2.f32)));
	// vmaddfp v6,v13,v0,v27
	_mm_store_ps(ctx.v6.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v27.f32)));
	// vrsqrtefp v13,v12
	_mm_store_ps(ctx.v13.f32, _mm_div_ps(_mm_set1_ps(1), _mm_sqrt_ps(_mm_load_ps(ctx.v12.f32))));
	// vmaddfp v9,v9,v0,v3
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v9.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v3.f32)));
	// vmulfp128 v12,v12,v11
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v11.f32)));
	// vmaddfp v7,v7,v0,v28
	_mm_store_ps(ctx.v7.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v7.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v28.f32)));
	// vmaddfp v9,v8,v10,v9
	_mm_store_ps(ctx.v9.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v9.f32)));
	// vmulfp128 v8,v13,v13
	_mm_store_ps(ctx.v8.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v9,v1,v9
	_mm_store_ps(ctx.v9.f32, _mm_mul_ps(_mm_load_ps(ctx.v1.f32), _mm_load_ps(ctx.v9.f32)));
	// vnmsubfp v12,v12,v8,v11
	_mm_store_ps(ctx.v12.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v8.f32)), _mm_load_ps(ctx.v11.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vor v8,v0,v0
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// lvx128 v0,r0,r11
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// vmulfp128 v0,v0,v11
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32)));
	// vmaddfp v13,v13,v12,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v12.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmaddfp v12,v6,v10,v7
	_mm_store_ps(ctx.v12.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v6.f32), _mm_load_ps(ctx.v10.f32)), _mm_load_ps(ctx.v7.f32)));
	// vnmsubfp v10,v8,v1,v1
	_mm_store_ps(ctx.v10.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v1.f32)), _mm_load_ps(ctx.v1.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vmulfp128 v12,v10,v12
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v12.f32)));
	// vmaddfp v13,v12,v13,v9
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v13.f32)), _mm_load_ps(ctx.v9.f32)));
	// vsubfp v1,v0,v13
	_mm_store_ps(ctx.v1.f32, _mm_sub_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B44FC8"))) PPC_WEAK_FUNC(sub_82B44FC8);
PPC_FUNC_IMPL(__imp__sub_82B44FC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82B44FD8:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r9,r1,-12
	ctx.r9.s64 = ctx.r1.s64 + -12;
	// stfs f0,-12(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -12, temp.u32);
	// addi r8,r1,-12
	ctx.r8.s64 = ctx.r1.s64 + -12;
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lvsl v7,r0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v7.u8, _mm_load_si128((__m128i*)&VectorShiftTableL[(temp.u32 & 0xF) * 16]));
	// lvx128 v0,r0,r8
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r8.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r8,r1,-16
	ctx.r8.s64 = ctx.r1.s64 + -16;
	// vperm v0,v0,v0,v7
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_perm_epi8_(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v7.u8)));
	// vor v13,v0,v0
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// vpkd3d128 v13,v0,5,2,2
	ctx.fpscr.enableFlushModeUnconditional();
	__builtin_debugtrap();
	// vsplth v0,v13,0
	_mm_store_si128((__m128i*)ctx.v0.u16, _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u16), _mm_set1_epi16(short(0xF0E))));
	// stvehx v0,r0,r8
	ea = (ctx.r8.u32) & ~0x1;
	PPC_STORE_U16(ea, ctx.v0.u16[7 - ((ea & 0xF) >> 1)]);
	// lhz r9,-16(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + -16);
	// sth r9,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r9.u16);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// bne 0x82b44fd8
	if (!ctx.cr0.eq) goto loc_82B44FD8;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B45028"))) PPC_WEAK_FUNC(sub_82B45028);
PPC_FUNC_IMPL(__imp__sub_82B45028) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82B45038:
	// lhz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// addi r9,r1,-16
	ctx.r9.s64 = ctx.r1.s64 + -16;
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// sth r8,-16(r1)
	PPC_STORE_U16(ctx.r1.u32 + -16, ctx.r8.u16);
	// addi r8,r1,-16
	ctx.r8.s64 = ctx.r1.s64 + -16;
	// lvsl v0,r0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_load_si128((__m128i*)&VectorShiftTableL[(temp.u32 & 0xF) * 16]));
	// vsldoi v0,v0,v0,4
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_alignr_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v0.u8), 12));
	// lvx128 v13,r0,r8
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((ctx.r8.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r8,r1,-12
	ctx.r8.s64 = ctx.r1.s64 + -12;
	// vperm v0,v13,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_perm_epi8_(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// vupkd3d128 v0,v0,12
	__builtin_debugtrap();
	// vspltw v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0xFF));
	// stvewx v0,r0,r8
	ea = (ctx.r8.u32) & ~0x3;
	PPC_STORE_U32(ea, ctx.v0.u32[3 - ((ea & 0xF) >> 2)]);
	// lfs f0,-12(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -12);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82b45038
	if (!ctx.cr0.eq) goto loc_82B45038;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B45088"))) PPC_WEAK_FUNC(sub_82B45088);
PPC_FUNC_IMPL(__imp__sub_82B45088) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lis r9,-31975
	ctx.r9.s64 = -2095513600;
	// addi r10,r11,1600
	ctx.r10.s64 = ctx.r11.s64 + 1600;
	// addi r8,r10,40
	ctx.r8.s64 = ctx.r10.s64 + 40;
	// addi r11,r10,40
	ctx.r11.s64 = ctx.r10.s64 + 40;
	// lwz r9,-24252(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24252);
	// cmplw cr6,r8,r9
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82b450c0
	if (!ctx.cr6.lt) goto loc_82B450C0;
loc_82B450A8:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r3,r8
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r8.s32, ctx.xer);
	// beq cr6,0x82b450c8
	if (ctx.cr6.eq) goto loc_82B450C8;
	// addi r11,r11,36
	ctx.r11.s64 = ctx.r11.s64 + 36;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82b450a8
	if (ctx.cr6.lt) goto loc_82B450A8;
loc_82B450C0:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// blr 
	return;
loc_82B450C8:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B450D0"))) PPC_WEAK_FUNC(sub_82B450D0);
PPC_FUNC_IMPL(__imp__sub_82B450D0) {
	PPC_FUNC_PROLOGUE();
	// addis r11,r3,-13873
	ctx.r11.s64 = ctx.r3.s64 + -909180928;
	// addic. r11,r11,-19521
	ctx.xer.ca = ctx.r11.u32 > 19520;
	ctx.r11.s64 = ctx.r11.s64 + -19521;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b450f0
	if (ctx.cr0.eq) goto loc_82B450F0;
	// cmplwi cr6,r11,1503
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1503, ctx.xer);
	// bnelr cr6
	if (!ctx.cr6.eq) return;
	// lis r3,10280
	ctx.r3.s64 = 673710080;
	// ori r3,r3,134
	ctx.r3.u64 = ctx.r3.u64 | 134;
	// blr 
	return;
loc_82B450F0:
	// lis r3,2048
	ctx.r3.s64 = 134217728;
	// ori r3,r3,74
	ctx.r3.u64 = ctx.r3.u64 | 74;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B45100"))) PPC_WEAK_FUNC(sub_82B45100);
PPC_FUNC_IMPL(__imp__sub_82B45100) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,1
	ctx.r3.s64 = 1;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// bl 0x8224ad48
	ctx.lr = 0x82B4511C;
	sub_8224AD48(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82b4512c
	if (!ctx.cr6.eq) goto loc_82B4512C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82b45148
	goto loc_82B45148;
loc_82B4512C:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// rlwinm r10,r11,0,26,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFE3F;
	// cmpwi cr6,r10,-449
	ctx.cr6.compare<int32_t>(ctx.r10.s32, -449, ctx.xer);
	// bne cr6,0x82b45144
	if (!ctx.cr6.eq) goto loc_82B45144;
	// lis r11,6184
	ctx.r11.s64 = 405274624;
	// ori r11,r11,390
	ctx.r11.u64 = ctx.r11.u64 | 390;
loc_82B45144:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
loc_82B45148:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B45160"))) PPC_WEAK_FUNC(sub_82B45160);
PPC_FUNC_IMPL(__imp__sub_82B45160) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82B45168;
	__savegprlr_14(ctx, base);
	// stwu r1,-736(r1)
	ea = -736 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// stw r9,804(r1)
	PPC_STORE_U32(ctx.r1.u32 + 804, ctx.r9.u32);
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r16,r6
	ctx.r16.u64 = ctx.r6.u64;
	// stw r25,772(r1)
	PPC_STORE_U32(ctx.r1.u32 + 772, ctx.r25.u32);
	// mr r18,r7
	ctx.r18.u64 = ctx.r7.u64;
	// mr r19,r8
	ctx.r19.u64 = ctx.r8.u64;
	// mr r21,r10
	ctx.r21.u64 = ctx.r10.u64;
	// bl 0x82b74068
	ctx.lr = 0x82B45198;
	sub_82B74068(ctx, base);
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82b778c0
	ctx.lr = 0x82B451A0;
	sub_82B778C0(ctx, base);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// mr r20,r28
	ctx.r20.u64 = ctx.r28.u64;
	// mr r26,r28
	ctx.r26.u64 = ctx.r28.u64;
	// mr r23,r28
	ctx.r23.u64 = ctx.r28.u64;
	// stw r28,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r28.u32);
	// mr r27,r28
	ctx.r27.u64 = ctx.r28.u64;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r28.u32);
	// mr r31,r28
	ctx.r31.u64 = ctx.r28.u64;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r28.u32);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r28.u32);
	// mr r15,r28
	ctx.r15.u64 = ctx.r28.u64;
	// stw r28,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r28.u32);
	// mr r14,r28
	ctx.r14.u64 = ctx.r28.u64;
	// stw r28,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r28.u32);
	// bne cr6,0x82b45204
	if (!ctx.cr6.eq) goto loc_82B45204;
loc_82B451E4:
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82b77b30
	ctx.lr = 0x82B451EC;
	sub_82B77B30(ctx, base);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b74a48
	ctx.lr = 0x82B451F4;
	sub_82B74A48(ctx, base);
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
loc_82B451FC:
	// addi r1,r1,736
	ctx.r1.s64 = ctx.r1.s64 + 736;
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
loc_82B45204:
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x82b451e4
	if (ctx.cr6.eq) goto loc_82B451E4;
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// bne cr6,0x82b45234
	if (!ctx.cr6.eq) goto loc_82B45234;
loc_82B45214:
	// lis r31,-30602
	ctx.r31.s64 = -2005532672;
	// ori r31,r31,2156
	ctx.r31.u64 = ctx.r31.u64 | 2156;
loc_82B4521C:
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82b77b30
	ctx.lr = 0x82B45224;
	sub_82B77B30(ctx, base);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b74a48
	ctx.lr = 0x82B4522C;
	sub_82B74A48(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82b451fc
	goto loc_82B451FC;
loc_82B45234:
	// lwz r11,844(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82b4524c
	if (!ctx.cr6.eq) goto loc_82B4524C;
	// lis r11,8
	ctx.r11.s64 = 524288;
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stw r11,844(r1)
	PPC_STORE_U32(ctx.r1.u32 + 844, ctx.r11.u32);
loc_82B4524C:
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// addi r4,r1,352
	ctx.r4.s64 = ctx.r1.s64 + 352;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82b77b38
	ctx.lr = 0x82B4526C;
	sub_82B77B38(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b4527c
	if (!ctx.cr0.lt) goto loc_82B4527C;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82b4521c
	goto loc_82B4521C;
loc_82B4527C:
	// addi r5,r1,288
	ctx.r5.s64 = ctx.r1.s64 + 288;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82b048c8
	ctx.lr = 0x82B4528C;
	sub_82B048C8(ctx, base);
	// lwz r11,340(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// rlwinm r22,r18,24,31,31
	ctx.r22.u64 = __builtin_rotateleft64(ctx.r18.u32 | (ctx.r18.u64 << 32), 24) & 0x1;
	// clrlwi r30,r11,31
	ctx.r30.u64 = ctx.r11.u32 & 0x1;
	// rlwinm r11,r11,31,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r30.u32);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,820(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 820);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b452d0
	if (ctx.cr6.eq) goto loc_82B452D0;
	// lwz r11,8(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// cmpwi cr6,r11,16
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 16, ctx.xer);
	// ble cr6,0x82b452c8
	if (!ctx.cr6.gt) goto loc_82B452C8;
	// lwz r11,12(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 12);
	// cmpwi cr6,r11,16
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 16, ctx.xer);
	// bgt cr6,0x82b452d0
	if (ctx.cr6.gt) goto loc_82B452D0;
loc_82B452C8:
	// li r17,1
	ctx.r17.s64 = 1;
	// b 0x82b452d4
	goto loc_82B452D4;
loc_82B452D0:
	// mr r17,r28
	ctx.r17.u64 = ctx.r28.u64;
loc_82B452D4:
	// cmpwi cr6,r22,0
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// beq cr6,0x82b4542c
	if (ctx.cr6.eq) goto loc_82B4542C;
	// clrlwi r25,r18,26
	ctx.r25.u64 = ctx.r18.u32 & 0x3F;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82b04df0
	ctx.lr = 0x82B452F0;
	sub_82B04DF0(ctx, base);
	// cmpwi cr6,r17,0
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// bne cr6,0x82b45308
	if (!ctx.cr6.eq) goto loc_82B45308;
	// lwz r27,8(r21)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// lwz r31,12(r21)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r21.u32 + 12);
	// b 0x82b45408
	goto loc_82B45408;
loc_82B45308:
	// lwz r26,828(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	// addi r11,r26,-1
	ctx.r11.s64 = ctx.r26.s64 + -1;
	// cmplwi cr6,r11,8191
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8191, ctx.xer);
	// bgt cr6,0x82b45214
	if (ctx.cr6.gt) goto loc_82B45214;
	// lwz r29,836(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// addi r11,r29,-1
	ctx.r11.s64 = ctx.r29.s64 + -1;
	// cmplwi cr6,r11,8191
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8191, ctx.xer);
	// bgt cr6,0x82b45214
	if (ctx.cr6.gt) goto loc_82B45214;
	// lwz r11,8(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// lwz r10,12(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 12);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82b4533c
	if (!ctx.cr6.gt) goto loc_82B4533C;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B4533C:
	// cmplw cr6,r26,r29
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r29.u32, ctx.xer);
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// bgt cr6,0x82b4534c
	if (ctx.cr6.gt) goto loc_82B4534C;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82B4534C:
	// mr r27,r28
	ctx.r27.u64 = ctx.r28.u64;
	// b 0x82b4535c
	goto loc_82B4535C;
loc_82B45354:
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
loc_82B4535C:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x82b45354
	if (ctx.cr6.gt) goto loc_82B45354;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82b04bc0
	ctx.lr = 0x82B45374;
	sub_82B04BC0(ctx, base);
	// addi r11,r26,-1
	ctx.r11.s64 = ctx.r26.s64 + -1;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// subfic r11,r3,32
	ctx.xer.ca = ctx.r3.u32 <= 32;
	ctx.r11.s64 = 32 - ctx.r3.s64;
	// subf. r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bge 0x82b4538c
	if (!ctx.cr0.lt) goto loc_82B4538C;
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
loc_82B4538C:
	// addi r9,r29,-1
	ctx.r9.s64 = ctx.r29.s64 + -1;
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// subf. r31,r9,r11
	ctx.r31.s64 = ctx.r11.s64 - ctx.r9.s64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// slw r30,r11,r10
	ctx.r30.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r11.u32 << (ctx.r10.u8 & 0x3F));
	// bge 0x82b453a8
	if (!ctx.cr0.lt) goto loc_82B453A8;
	// mr r31,r28
	ctx.r31.u64 = ctx.r28.u64;
loc_82B453A8:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r29,1
	ctx.r29.s64 = 1;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r11,r11,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r22
	ctx.r8.u64 = ctx.r22.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// andc r27,r30,r11
	ctx.r27.u64 = ctx.r30.u64 & ~ctx.r11.u64;
	// slw r31,r29,r31
	ctx.r31.u64 = ctx.r31.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r31.u8 & 0x3F));
	// add r31,r31,r10
	ctx.r31.u64 = ctx.r31.u64 + ctx.r10.u64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// andc r31,r31,r10
	ctx.r31.u64 = ctx.r31.u64 & ~ctx.r10.u64;
	// bl 0x82b04dc8
	ctx.lr = 0x82B45400;
	sub_82B04DC8(ctx, base);
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
loc_82B45408:
	// addi r11,r31,31
	ctx.r11.s64 = ctx.r31.s64 + 31;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r25,772(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	// rlwinm r11,r11,0,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// twllei r10,0
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// mullw r11,r11,r19
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r19.s32);
	// addi r11,r11,4095
	ctx.r11.s64 = ctx.r11.s64 + 4095;
	// rlwinm r26,r11,0,0,19
	ctx.r26.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFF000;
loc_82B4542C:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82b454fc
	if (ctx.cr6.eq) goto loc_82B454FC;
	// lwz r11,108(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b45450
	if (!ctx.cr6.eq) goto loc_82B45450;
	// lwz r15,292(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// lwz r14,296(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	// stw r28,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r28.u32);
	// b 0x82b454a0
	goto loc_82B454A0;
loc_82B45450:
	// addi r5,r1,448
	ctx.r5.s64 = ctx.r1.s64 + 448;
	// lwz r3,24(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82b048c8
	ctx.lr = 0x82B45460;
	sub_82B048C8(ctx, base);
	// addi r4,r1,512
	ctx.r4.s64 = ctx.r1.s64 + 512;
	// lwz r3,24(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// bl 0x82b048d0
	ctx.lr = 0x82B4546C;
	sub_82B048D0(ctx, base);
	// lwz r11,28(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// lwz r10,304(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// lwz r5,460(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 460);
	// clrlwi r7,r10,26
	ctx.r7.u64 = ctx.r10.u32 & 0x3F;
	// lwz r4,456(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 456);
	// rlwinm r6,r11,4,28,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xF;
	// lwz r3,452(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 452);
	// lwz r15,516(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 516);
	// lwz r14,520(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 520);
	// bl 0x82b04dc8
	ctx.lr = 0x82B4549C;
	sub_82B04DC8(ctx, base);
	// stw r3,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r3.u32);
loc_82B454A0:
	// lwz r11,304(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// clrlwi r3,r11,26
	ctx.r3.u64 = ctx.r11.u32 & 0x3F;
	// bl 0x82b04df0
	ctx.lr = 0x82B454B4;
	sub_82B04DF0(ctx, base);
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r11,r15,r10
	ctx.r11.u64 = ctx.r15.u64 + ctx.r10.u64;
	// lwz r7,316(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// add r11,r14,r9
	ctx.r11.u64 = ctx.r14.u64 + ctx.r9.u64;
	// andc r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 & ~ctx.r10.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r8,r9,-1
	ctx.r8.s64 = ctx.r9.s64 + -1;
	// mullw r10,r10,r7
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// andc r8,r11,r8
	ctx.r8.u64 = ctx.r11.u64 & ~ctx.r8.u64;
	// rlwinm r11,r10,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// mullw r10,r8,r11
	ctx.r10.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// stw r11,360(r1)
	PPC_STORE_U32(ctx.r1.u32 + 360, ctx.r11.u32);
	// addi r10,r10,4095
	ctx.r10.s64 = ctx.r10.s64 + 4095;
	// rlwinm r23,r10,0,0,19
	ctx.r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFF000;
loc_82B454FC:
	// add. r3,r23,r26
	ctx.r3.u64 = ctx.r23.u64 + ctx.r26.u64;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b45520
	if (ctx.cr0.eq) goto loc_82B45520;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// bl 0x82547910
	ctx.lr = 0x82B4550C;
	sub_82547910(ctx, base);
	// mr. r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// bne 0x82b45520
	if (!ctx.cr0.eq) goto loc_82B45520;
	// lis r31,-32761
	ctx.r31.s64 = -2147024896;
	// ori r31,r31,14
	ctx.r31.u64 = ctx.r31.u64 | 14;
	// b 0x82b4521c
	goto loc_82B4521C;
loc_82B45520:
	// cmpwi cr6,r22,0
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 0, ctx.xer);
	// beq cr6,0x82b455ec
	if (ctx.cr6.eq) goto loc_82B455EC;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r17,0
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// beq cr6,0x82b45544
	if (ctx.cr6.eq) goto loc_82B45544;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// b 0x82b4555c
	goto loc_82B4555C;
loc_82B45544:
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// twllei r11,0
	// lwz r9,4(r21)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r21.u32 + 4);
	// twllei r8,0
	// divwu r4,r10,r11
	ctx.r4.u32 = ctx.r10.u32 / ctx.r11.u32;
	// divwu r5,r9,r8
	ctx.r5.u32 = ctx.r9.u32 / ctx.r8.u32;
loc_82B4555C:
	// add r9,r31,r8
	ctx.r9.u64 = ctx.r31.u64 + ctx.r8.u64;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// add r10,r27,r11
	ctx.r10.u64 = ctx.r27.u64 + ctx.r11.u64;
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// divwu r7,r9,r8
	ctx.r7.u32 = ctx.r9.u32 / ctx.r8.u32;
	// divwu r6,r10,r11
	ctx.r6.u32 = ctx.r10.u32 / ctx.r11.u32;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// twllei r8,0
	// twllei r11,0
	// bl 0x82b08b30
	ctx.lr = 0x82B4558C;
	sub_82B08B30(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// clrlwi r7,r18,26
	ctx.r7.u64 = ctx.r18.u32 & 0x3F;
	// addi r10,r11,-28864
	ctx.r10.s64 = ctx.r11.s64 + -28864;
	// lwz r11,92(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// add r8,r31,r11
	ctx.r8.u64 = ctx.r31.u64 + ctx.r11.u64;
	// twllei r11,0
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// lbzx r10,r7,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r10.u32);
	// subf r6,r29,r16
	ctx.r6.s64 = ctx.r16.s64 - ctx.r29.s64;
	// divwu r8,r8,r11
	ctx.r8.u32 = ctx.r8.u32 / ctx.r11.u32;
	// mullw r11,r10,r11
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// rlwinm r10,r11,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// divwu r7,r19,r10
	ctx.r7.u32 = ctx.r19.u32 / ctx.r10.u32;
	// twllei r10,0
	// bl 0x82b05850
	ctx.lr = 0x82B455E0;
	sub_82B05850(ctx, base);
	// add r11,r29,r20
	ctx.r11.u64 = ctx.r29.u64 + ctx.r20.u64;
	// stw r11,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r11.u32);
	// b 0x82b455f0
	goto loc_82B455F0;
loc_82B455EC:
	// stw r16,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r16.u32);
loc_82B455F0:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82b4566c
	if (ctx.cr6.eq) goto loc_82B4566C;
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r9,352(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// add r11,r10,r26
	ctx.r11.u64 = ctx.r10.u64 + ctx.r26.u64;
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// add r11,r11,r20
	ctx.r11.u64 = ctx.r11.u64 + ctx.r20.u64;
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// stw r11,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, ctx.r11.u32);
	// lwz r11,108(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b4566c
	if (ctx.cr6.eq) goto loc_82B4566C;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r10,332(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// divwu r7,r15,r11
	ctx.r7.u32 = ctx.r15.u32 / ctx.r11.u32;
	// lwz r6,112(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// twllei r11,0
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r3,r26,r20
	ctx.r3.u64 = ctx.r26.u64 + ctx.r20.u64;
	// lwz r4,360(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	// divwu r8,r14,r11
	ctx.r8.u32 = ctx.r14.u32 / ctx.r11.u32;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// twllei r11,0
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// stw r28,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r28.u32);
	// stw r28,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r28.u32);
	// stw r7,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r7.u32);
	// stw r8,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r8.u32);
	// bl 0x82b05850
	ctx.lr = 0x82B4566C;
	sub_82B05850(ctx, base);
loc_82B4566C:
	// rlwinm r10,r18,0,24,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r18.u32 | (ctx.r18.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// lwz r9,4(r21)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r21.u32 + 4);
	// addi r11,r1,208
	ctx.r11.s64 = ctx.r1.s64 + 208;
	// lwz r8,8(r21)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// lwz r7,12(r21)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r21.u32 + 12);
	// addi r3,r1,232
	ctx.r3.s64 = ctx.r1.s64 + 232;
	// stw r19,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r19.u32);
	// addi r4,r1,208
	ctx.r4.s64 = ctx.r1.s64 + 208;
	// stw r28,204(r1)
	PPC_STORE_U32(ctx.r1.u32 + 204, ctx.r28.u32);
	// li r5,24
	ctx.r5.s64 = 24;
	// stw r10,196(r1)
	PPC_STORE_U32(ctx.r1.u32 + 196, ctx.r10.u32);
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
	// stw r7,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r7.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r28,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r28.u32);
	// stw r11,228(r1)
	PPC_STORE_U32(ctx.r1.u32 + 228, ctx.r11.u32);
	// bl 0x82e28fd0
	ctx.lr = 0x82B456BC;
	sub_82E28FD0(ctx, base);
	// lwz r11,424(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 424);
	// addi r5,r1,192
	ctx.r5.s64 = ctx.r1.s64 + 192;
	// addi r4,r1,352
	ctx.r4.s64 = ctx.r1.s64 + 352;
	// lwz r6,844(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// stw r11,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r11.u32);
	// lwz r11,852(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	// stw r11,268(r1)
	PPC_STORE_U32(ctx.r1.u32 + 268, ctx.r11.u32);
	// lwz r11,804(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r11.u32);
	// lwz r11,356(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// rlwinm r11,r11,0,24,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// stw r11,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, ctx.r11.u32);
	// bl 0x82b77718
	ctx.lr = 0x82B456F4;
	sub_82B77718(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82b457d4
	if (ctx.cr6.eq) goto loc_82B457D4;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82b45750
	if (ctx.cr6.eq) goto loc_82B45750;
	// lwz r11,108(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b45750
	if (!ctx.cr6.eq) goto loc_82B45750;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r10,12(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// lwz r7,0(r25)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// twllei r11,0
	// add r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r6,4(r25)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// divwu r4,r7,r10
	ctx.r4.u32 = ctx.r7.u32 / ctx.r10.u32;
	// lwz r9,8(r25)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	// divwu r5,r6,r11
	ctx.r5.u32 = ctx.r6.u32 / ctx.r11.u32;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// twllei r10,0
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// b 0x82b45770
	goto loc_82B45770;
loc_82B45750:
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r4,0
	ctx.r4.s64 = 0;
	// add r8,r14,r11
	ctx.r8.u64 = ctx.r14.u64 + ctx.r11.u64;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// add r9,r15,r10
	ctx.r9.u64 = ctx.r15.u64 + ctx.r10.u64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
loc_82B45770:
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// divwu r7,r8,r11
	ctx.r7.u32 = ctx.r8.u32 / ctx.r11.u32;
	// divwu r6,r9,r10
	ctx.r6.u32 = ctx.r9.u32 / ctx.r10.u32;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// twllei r11,0
	// twllei r10,0
	// bl 0x82b08b30
	ctx.lr = 0x82B45790;
	sub_82B08B30(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// add r7,r26,r20
	ctx.r7.u64 = ctx.r26.u64 + ctx.r20.u64;
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// add r9,r14,r11
	ctx.r9.u64 = ctx.r14.u64 + ctx.r11.u64;
	// lwz r8,360(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 360);
	// add r10,r15,r4
	ctx.r10.u64 = ctx.r15.u64 + ctx.r4.u64;
	// addi r5,r9,-1
	ctx.r5.s64 = ctx.r9.s64 + -1;
	// addi r3,r10,-1
	ctx.r3.s64 = ctx.r10.s64 + -1;
	// lwz r10,332(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// twllei r4,0
	// divwu r4,r3,r4
	ctx.r4.u32 = ctx.r3.u32 / ctx.r4.u32;
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// divwu r5,r5,r11
	ctx.r5.u32 = ctx.r5.u32 / ctx.r11.u32;
	// twllei r11,0
	// bl 0x82b05848
	ctx.lr = 0x82B457D4;
	sub_82B05848(ctx, base);
loc_82B457D4:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82b4521c
	if (ctx.cr6.eq) goto loc_82B4521C;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82547938
	ctx.lr = 0x82B457E8;
	sub_82547938(ctx, base);
	// b 0x82b4521c
	goto loc_82B4521C;
}

__attribute__((alias("__imp__sub_82B457F0"))) PPC_WEAK_FUNC(sub_82B457F0);
PPC_FUNC_IMPL(__imp__sub_82B457F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82B457F8;
	__savegprlr_14(ctx, base);
	// stwu r1,-752(r1)
	ea = -752 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// stw r10,828(r1)
	PPC_STORE_U32(ctx.r1.u32 + 828, ctx.r10.u32);
	// mr r22,r7
	ctx.r22.u64 = ctx.r7.u64;
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r14,r5
	ctx.r14.u64 = ctx.r5.u64;
	// stw r27,796(r1)
	PPC_STORE_U32(ctx.r1.u32 + 796, ctx.r27.u32);
	// stw r22,804(r1)
	PPC_STORE_U32(ctx.r1.u32 + 804, ctx.r22.u32);
	// mr r21,r8
	ctx.r21.u64 = ctx.r8.u64;
	// mr r18,r9
	ctx.r18.u64 = ctx.r9.u64;
	// bl 0x82b74068
	ctx.lr = 0x82B4582C;
	sub_82B74068(ctx, base);
	// addi r3,r1,132
	ctx.r3.s64 = ctx.r1.s64 + 132;
	// bl 0x82b778e0
	ctx.lr = 0x82B45834;
	sub_82B778E0(ctx, base);
	// li r26,0
	ctx.r26.s64 = 0;
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// mr r17,r26
	ctx.r17.u64 = ctx.r26.u64;
	// mr r24,r26
	ctx.r24.u64 = ctx.r26.u64;
	// mr r19,r26
	ctx.r19.u64 = ctx.r26.u64;
	// stw r26,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r26.u32);
	// mr r28,r26
	ctx.r28.u64 = ctx.r26.u64;
	// stw r26,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r26.u32);
	// mr r31,r26
	ctx.r31.u64 = ctx.r26.u64;
	// stw r26,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r26.u32);
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// stw r26,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r26.u32);
	// mr r25,r26
	ctx.r25.u64 = ctx.r26.u64;
	// stw r26,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r26.u32);
	// mr r15,r26
	ctx.r15.u64 = ctx.r26.u64;
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r26.u32);
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r26.u32);
	// stw r26,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r26.u32);
	// bne cr6,0x82b458a0
	if (!ctx.cr6.eq) goto loc_82B458A0;
loc_82B45880:
	// addi r3,r1,132
	ctx.r3.s64 = ctx.r1.s64 + 132;
	// bl 0x82b78028
	ctx.lr = 0x82B45888;
	sub_82B78028(ctx, base);
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x82b74a48
	ctx.lr = 0x82B45890;
	sub_82B74A48(ctx, base);
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
loc_82B45898:
	// addi r1,r1,752
	ctx.r1.s64 = ctx.r1.s64 + 752;
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
loc_82B458A0:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82b45880
	if (ctx.cr6.eq) goto loc_82B45880;
	// lwz r27,836(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x82b458d4
	if (!ctx.cr6.eq) goto loc_82B458D4;
loc_82B458B4:
	// lis r31,-30602
	ctx.r31.s64 = -2005532672;
	// ori r31,r31,2156
	ctx.r31.u64 = ctx.r31.u64 | 2156;
loc_82B458BC:
	// addi r3,r1,132
	ctx.r3.s64 = ctx.r1.s64 + 132;
	// bl 0x82b78028
	ctx.lr = 0x82B458C4;
	sub_82B78028(ctx, base);
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x82b74a48
	ctx.lr = 0x82B458CC;
	sub_82B74A48(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82b45898
	goto loc_82B45898;
loc_82B458D4:
	// lwz r11,876(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82b458ec
	if (!ctx.cr6.eq) goto loc_82B458EC;
	// lis r11,8
	ctx.r11.s64 = 524288;
	// ori r11,r11,4
	ctx.r11.u64 = ctx.r11.u64 | 4;
	// stw r11,876(r1)
	PPC_STORE_U32(ctx.r1.u32 + 876, ctx.r11.u32);
loc_82B458EC:
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r14
	ctx.r7.u64 = ctx.r14.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// addi r4,r1,272
	ctx.r4.s64 = ctx.r1.s64 + 272;
	// addi r3,r1,132
	ctx.r3.s64 = ctx.r1.s64 + 132;
	// bl 0x82b78030
	ctx.lr = 0x82B4590C;
	sub_82B78030(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b4591c
	if (!ctx.cr0.lt) goto loc_82B4591C;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82b458bc
	goto loc_82B458BC;
loc_82B4591C:
	// addi r5,r1,208
	ctx.r5.s64 = ctx.r1.s64 + 208;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82b048c8
	ctx.lr = 0x82B4592C;
	sub_82B048C8(ctx, base);
	// lwz r11,260(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// rlwinm r16,r22,24,31,31
	ctx.r16.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 24) & 0x1;
	// clrlwi r29,r11,31
	ctx.r29.u64 = ctx.r11.u32 & 0x1;
	// rlwinm r11,r11,31,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
	// li r23,1
	ctx.r23.s64 = 1;
	// stw r29,188(r1)
	PPC_STORE_U32(ctx.r1.u32 + 188, ctx.r29.u32);
	// stw r11,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r11.u32);
	// lwz r11,844(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 844);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b45974
	if (ctx.cr6.eq) goto loc_82B45974;
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// ble cr6,0x82b4596c
	if (!ctx.cr6.gt) goto loc_82B4596C;
	// lwz r11,12(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// cmplwi cr6,r11,16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 16, ctx.xer);
	// bgt cr6,0x82b45974
	if (ctx.cr6.gt) goto loc_82B45974;
loc_82B4596C:
	// stw r23,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r23.u32);
	// b 0x82b45978
	goto loc_82B45978;
loc_82B45974:
	// stw r26,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r26.u32);
loc_82B45978:
	// cmpwi cr6,r16,0
	ctx.cr6.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// beq cr6,0x82b45b1c
	if (ctx.cr6.eq) goto loc_82B45B1C;
	// clrlwi r22,r22,26
	ctx.r22.u64 = ctx.r22.u32 & 0x3F;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// addi r4,r1,180
	ctx.r4.s64 = ctx.r1.s64 + 180;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82b04df0
	ctx.lr = 0x82B45994;
	sub_82B04DF0(ctx, base);
	// lwz r11,176(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b459c0
	if (!ctx.cr6.eq) goto loc_82B459C0;
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// mr r25,r26
	ctx.r25.u64 = ctx.r26.u64;
	// lwz r28,8(r27)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// lwz r31,12(r27)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// rlwinm r30,r11,0,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// mullw r11,r30,r18
	ctx.r11.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r18.s32);
	// b 0x82b45b10
	goto loc_82B45B10;
loc_82B459C0:
	// lwz r25,852(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 852);
	// addi r11,r25,-1
	ctx.r11.s64 = ctx.r25.s64 + -1;
	// cmplwi cr6,r11,8191
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8191, ctx.xer);
	// bgt cr6,0x82b458b4
	if (ctx.cr6.gt) goto loc_82B458B4;
	// lwz r27,860(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 860);
	// addi r11,r27,-1
	ctx.r11.s64 = ctx.r27.s64 + -1;
	// cmplwi cr6,r11,8191
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8191, ctx.xer);
	// bgt cr6,0x82b458b4
	if (ctx.cr6.gt) goto loc_82B458B4;
	// lwz r24,868(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 868);
	// addi r11,r24,-1
	ctx.r11.s64 = ctx.r24.s64 + -1;
	// cmplwi cr6,r11,1023
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1023, ctx.xer);
	// bgt cr6,0x82b458b4
	if (ctx.cr6.gt) goto loc_82B458B4;
	// lwz r10,836(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// lwz r11,8(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b45a08
	if (!ctx.cr6.gt) goto loc_82B45A08;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B45A08:
	// cmplw cr6,r25,r27
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r27.u32, ctx.xer);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bgt cr6,0x82b45a18
	if (ctx.cr6.gt) goto loc_82B45A18;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
loc_82B45A18:
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// b 0x82b45a28
	goto loc_82B45A28;
loc_82B45A20:
	// rlwinm r11,r11,31,1,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82B45A28:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x82b45a20
	if (ctx.cr6.gt) goto loc_82B45A20;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82b04bc0
	ctx.lr = 0x82B45A40;
	sub_82B04BC0(ctx, base);
	// addi r11,r25,-1
	ctx.r11.s64 = ctx.r25.s64 + -1;
	// subfic r10,r3,32
	ctx.xer.ca = ctx.r3.u32 <= 32;
	ctx.r10.s64 = 32 - ctx.r3.s64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// mr r9,r26
	ctx.r9.u64 = ctx.r26.u64;
	// subf. r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt 0x82b45a5c
	if (ctx.cr0.lt) goto loc_82B45A5C;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
loc_82B45A5C:
	// addi r11,r27,-1
	ctx.r11.s64 = ctx.r27.s64 + -1;
	// slw r29,r23,r9
	ctx.r29.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r23.u32 << (ctx.r9.u8 & 0x3F));
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// subf. r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge 0x82b45a74
	if (!ctx.cr0.lt) goto loc_82B45A74;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
loc_82B45A74:
	// addi r9,r24,-1
	ctx.r9.s64 = ctx.r24.s64 + -1;
	// slw r28,r23,r11
	ctx.r28.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r23.u32 << (ctx.r11.u8 & 0x3F));
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// subf. r31,r9,r10
	ctx.r31.s64 = ctx.r10.s64 - ctx.r9.s64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bge 0x82b45a8c
	if (!ctx.cr0.lt) goto loc_82B45A8C;
	// mr r31,r26
	ctx.r31.u64 = ctx.r26.u64;
loc_82B45A8C:
	// slw r31,r23,r31
	ctx.r31.u64 = ctx.r31.u8 & 0x20 ? 0 : (ctx.r23.u32 << (ctx.r31.u8 & 0x3F));
	// lwz r11,180(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// rlwinm r11,r11,5,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r30,r31,0,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFFC;
	// add r31,r10,r28
	ctx.r31.u64 = ctx.r10.u64 + ctx.r28.u64;
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r29,r29,-1
	ctx.r29.s64 = ctx.r29.s64 + -1;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r16
	ctx.r8.u64 = ctx.r16.u64;
	// mr r7,r22
	ctx.r7.u64 = ctx.r22.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// andc r28,r29,r11
	ctx.r28.u64 = ctx.r29.u64 & ~ctx.r11.u64;
	// andc r31,r31,r10
	ctx.r31.u64 = ctx.r31.u64 & ~ctx.r10.u64;
	// bl 0x82b04dc8
	ctx.lr = 0x82B45AE8;
	sub_82B04DC8(ctx, base);
	// addi r11,r31,31
	ctx.r11.s64 = ctx.r31.s64 + 31;
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r27,836(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// rlwinm r11,r11,0,0,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// lwz r29,188(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// twllei r10,0
	// divwu r11,r11,r10
	ctx.r11.u32 = ctx.r11.u32 / ctx.r10.u32;
	// mullw r11,r11,r30
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
	// mullw r11,r11,r21
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r21.s32);
loc_82B45B10:
	// addi r11,r11,4095
	ctx.r11.s64 = ctx.r11.s64 + 4095;
	// lwz r22,804(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	// rlwinm r24,r11,0,0,19
	ctx.r24.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFF000;
loc_82B45B1C:
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82b45c14
	if (ctx.cr6.eq) goto loc_82B45C14;
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b45b4c
	if (!ctx.cr6.eq) goto loc_82B45B4C;
	// lwz r11,212(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// lwz r15,220(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// stw r26,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r26.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// lwz r11,216(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// b 0x82b45ba8
	goto loc_82B45BA8;
loc_82B45B4C:
	// addi r5,r1,464
	ctx.r5.s64 = ctx.r1.s64 + 464;
	// lwz r3,24(r20)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r20.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82b048c8
	ctx.lr = 0x82B45B5C;
	sub_82B048C8(ctx, base);
	// addi r4,r1,528
	ctx.r4.s64 = ctx.r1.s64 + 528;
	// lwz r3,24(r20)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r20.u32 + 24);
	// bl 0x82b048d0
	ctx.lr = 0x82B45B68;
	sub_82B048D0(ctx, base);
	// lwz r11,28(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 28);
	// lwz r10,224(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r6,r11,4,28,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xF;
	// lwz r11,532(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 532);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// lwz r5,476(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 476);
	// clrlwi r7,r10,26
	ctx.r7.u64 = ctx.r10.u32 & 0x3F;
	// lwz r4,472(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 472);
	// lwz r3,468(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 468);
	// lwz r15,540(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 540);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// lwz r11,536(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 536);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// bl 0x82b04dc8
	ctx.lr = 0x82B45BA4;
	sub_82B04DC8(ctx, base);
	// stw r3,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r3.u32);
loc_82B45BA8:
	// lwz r11,224(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// clrlwi r3,r11,26
	ctx.r3.u64 = ctx.r11.u32 & 0x3F;
	// bl 0x82b04df0
	ctx.lr = 0x82B45BBC;
	sub_82B04DF0(ctx, base);
	// lwz r9,104(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r8,124(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// addi r10,r9,-1
	ctx.r10.s64 = ctx.r9.s64 + -1;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r7,r11,-1
	ctx.r7.s64 = ctx.r11.s64 + -1;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// andc r10,r7,r10
	ctx.r10.u64 = ctx.r7.u64 & ~ctx.r10.u64;
	// andc r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 & ~ctx.r8.u64;
	// lwz r8,236(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// mullw r11,r11,r8
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r8.s32);
	// rlwinm r11,r11,29,3,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// mullw r10,r11,r10
	ctx.r10.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// stw r10,284(r1)
	PPC_STORE_U32(ctx.r1.u32 + 284, ctx.r10.u32);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// stw r11,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r11.u32);
	// mullw r11,r10,r15
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r15.s32);
	// addi r11,r11,4095
	ctx.r11.s64 = ctx.r11.s64 + 4095;
	// rlwinm r19,r11,0,0,19
	ctx.r19.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFF000;
loc_82B45C14:
	// add. r3,r19,r24
	ctx.r3.u64 = ctx.r19.u64 + ctx.r24.u64;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b45c38
	if (ctx.cr0.eq) goto loc_82B45C38;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// bl 0x82547910
	ctx.lr = 0x82B45C24;
	sub_82547910(ctx, base);
	// mr. r17,r3
	ctx.r17.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// bne 0x82b45c38
	if (!ctx.cr0.eq) goto loc_82B45C38;
	// lis r31,-32761
	ctx.r31.s64 = -2147024896;
	// ori r31,r31,14
	ctx.r31.u64 = ctx.r31.u64 | 14;
	// b 0x82b458bc
	goto loc_82B458BC;
loc_82B45C38:
	// cmpwi cr6,r16,0
	ctx.cr6.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// beq cr6,0x82b45d34
	if (ctx.cr6.eq) goto loc_82B45D34;
	// lwz r11,176(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b45c5c
	if (ctx.cr6.eq) goto loc_82B45C5C;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// mr r27,r26
	ctx.r27.u64 = ctx.r26.u64;
	// b 0x82b45c68
	goto loc_82B45C68;
loc_82B45C5C:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r8,4(r27)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// lwz r27,16(r27)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
loc_82B45C68:
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// lwz r5,128(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// subf r6,r11,r28
	ctx.r6.s64 = ctx.r28.s64 - ctx.r11.s64;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// addi r9,r10,-28864
	ctx.r9.s64 = ctx.r10.s64 + -28864;
	// lwz r10,804(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	// subf r7,r8,r31
	ctx.r7.s64 = ctx.r31.s64 - ctx.r8.s64;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
	// clrlwi r4,r10,26
	ctx.r4.u64 = ctx.r10.u32 & 0x3F;
	// lwz r10,180(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// add r7,r7,r5
	ctx.r7.u64 = ctx.r7.u64 + ctx.r5.u64;
	// stw r8,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r8.u32);
	// add r6,r6,r10
	ctx.r6.u64 = ctx.r6.u64 + ctx.r10.u64;
	// stw r8,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r8.u32);
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// stw r27,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r27.u32);
	// addi r6,r6,-1
	ctx.r6.s64 = ctx.r6.s64 + -1;
	// stw r27,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r27.u32);
	// lbzx r9,r4,r9
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + ctx.r9.u32);
	// divwu r29,r7,r5
	ctx.r29.u32 = ctx.r7.u32 / ctx.r5.u32;
	// divwu r28,r6,r10
	ctx.r28.u32 = ctx.r6.u32 / ctx.r10.u32;
	// lwz r7,796(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 796);
	// mullw r9,r9,r5
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r5.s32);
	// stw r30,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r30.u32);
	// add r11,r28,r11
	ctx.r11.u64 = ctx.r28.u64 + ctx.r11.u64;
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r11.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// rlwinm r31,r9,29,3,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFF;
	// add r11,r29,r8
	ctx.r11.u64 = ctx.r29.u64 + ctx.r8.u64;
	// twllei r10,0
	// twllei r5,0
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// divwu r9,r18,r21
	ctx.r9.u32 = ctx.r18.u32 / ctx.r21.u32;
	// subf r7,r25,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r25.s64;
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r11.u32);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// divwu r8,r21,r31
	ctx.r8.u32 = ctx.r21.u32 / ctx.r31.u32;
	// twllei r21,0
	// twllei r31,0
	// bl 0x82b061a8
	ctx.lr = 0x82B45D20;
	sub_82B061A8(ctx, base);
	// lwz r27,836(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 836);
	// add r11,r25,r17
	ctx.r11.u64 = ctx.r25.u64 + ctx.r17.u64;
	// lwz r29,188(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// lwz r22,804(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 804);
	// b 0x82b45d38
	goto loc_82B45D38;
loc_82B45D34:
	// lwz r11,796(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 796);
loc_82B45D38:
	// stw r11,368(r1)
	PPC_STORE_U32(ctx.r1.u32 + 368, ctx.r11.u32);
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82b45ddc
	if (ctx.cr6.eq) goto loc_82B45DDC;
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lwz r9,272(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// add r11,r10,r24
	ctx.r11.u64 = ctx.r10.u64 + ctx.r24.u64;
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// add r11,r11,r17
	ctx.r11.u64 = ctx.r11.u64 + ctx.r17.u64;
	// stw r10,184(r1)
	PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r10.u32);
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r11.u32);
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b45ddc
	if (ctx.cr6.eq) goto loc_82B45DDC;
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// add r3,r24,r17
	ctx.r3.u64 = ctx.r24.u64 + ctx.r17.u64;
	// twllei r11,0
	// lwz r7,184(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// divwu r8,r10,r11
	ctx.r8.u32 = ctx.r10.u32 / ctx.r11.u32;
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// twllei r11,0
	// lwz r5,284(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// divwu r9,r10,r11
	ctx.r9.u32 = ctx.r10.u32 / ctx.r11.u32;
	// lwz r11,252(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// mr r10,r15
	ctx.r10.u64 = ctx.r15.u64;
	// lwz r4,280(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r26.u32);
	// stw r26,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r26.u32);
	// stw r26,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r26.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// stw r26,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r26.u32);
	// stw r26,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r26.u32);
	// stw r26,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r26.u32);
	// stw r15,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r15.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// stw r8,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r8.u32);
	// stw r9,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r9.u32);
	// bl 0x82b061a8
	ctx.lr = 0x82B45DDC;
	sub_82B061A8(ctx, base);
loc_82B45DDC:
	// rlwinm r11,r22,0,24,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r22.u32 | (ctx.r22.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// stw r21,376(r1)
	PPC_STORE_U32(ctx.r1.u32 + 376, ctx.r21.u32);
	// addi r3,r1,384
	ctx.r3.s64 = ctx.r1.s64 + 384;
	// stw r18,380(r1)
	PPC_STORE_U32(ctx.r1.u32 + 380, ctx.r18.u32);
	// li r5,24
	ctx.r5.s64 = 24;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// stw r11,372(r1)
	PPC_STORE_U32(ctx.r1.u32 + 372, ctx.r11.u32);
	// bl 0x82e28fd0
	ctx.lr = 0x82B45DFC;
	sub_82E28FD0(ctx, base);
	// addi r3,r1,408
	ctx.r3.s64 = ctx.r1.s64 + 408;
	// li r5,24
	ctx.r5.s64 = 24;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B45E0C;
	sub_82E28FD0(ctx, base);
	// lwz r11,344(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 344);
	// addi r5,r1,368
	ctx.r5.s64 = ctx.r1.s64 + 368;
	// lwz r6,876(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 876);
	// addi r4,r1,272
	ctx.r4.s64 = ctx.r1.s64 + 272;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// stw r11,440(r1)
	PPC_STORE_U32(ctx.r1.u32 + 440, ctx.r11.u32);
	// lwz r11,884(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 884);
	// stw r11,444(r1)
	PPC_STORE_U32(ctx.r1.u32 + 444, ctx.r11.u32);
	// lwz r11,828(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 828);
	// stw r11,448(r1)
	PPC_STORE_U32(ctx.r1.u32 + 448, ctx.r11.u32);
	// lwz r11,276(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// rlwinm r11,r11,0,24,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// stw r11,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, ctx.r11.u32);
	// bl 0x82b77718
	ctx.lr = 0x82B45E44;
	sub_82B77718(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82b45f7c
	if (ctx.cr6.eq) goto loc_82B45F7C;
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x82b45ed4
	if (ctx.cr6.eq) goto loc_82B45ED4;
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b45ed4
	if (!ctx.cr6.eq) goto loc_82B45ED4;
	// lwz r9,4(r14)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r14.u32 + 4);
	// lwz r10,0(r14)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r14.u32 + 0);
	// extsw r6,r9
	ctx.r6.s64 = ctx.r9.s32;
	// lwz r11,8(r14)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r14.u32 + 8);
	// lwz r7,12(r14)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r14.u32 + 12);
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// subf r7,r9,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r9.s64;
	// lwz r8,16(r14)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r14.u32 + 16);
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// stw r6,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r6.u32);
	// add r7,r7,r5
	ctx.r7.u64 = ctx.r7.u64 + ctx.r5.u64;
	// lwz r6,20(r14)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r14.u32 + 20);
	// stw r10,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r10.u32);
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// stw r8,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r8.u32);
	// divwu r7,r7,r5
	ctx.r7.u32 = ctx.r7.u32 / ctx.r5.u32;
	// stw r9,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r9.u32);
	// stw r8,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r8.u32);
	// stw r6,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r6.u32);
	// subf r6,r10,r11
	ctx.r6.s64 = ctx.r11.s64 - ctx.r10.s64;
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// add r6,r6,r11
	ctx.r6.u64 = ctx.r6.u64 + ctx.r11.u64;
	// addi r6,r6,-1
	ctx.r6.s64 = ctx.r6.s64 + -1;
	// divwu r6,r6,r11
	ctx.r6.u32 = ctx.r6.u32 / ctx.r11.u32;
	// add r10,r6,r10
	ctx.r10.u64 = ctx.r6.u64 + ctx.r10.u64;
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
	// add r10,r7,r9
	ctx.r10.u64 = ctx.r7.u64 + ctx.r9.u64;
	// b 0x82b45f1c
	goto loc_82B45F1C;
loc_82B45ED4:
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r26.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// stw r26,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r26.u32);
	// add r10,r10,r5
	ctx.r10.u64 = ctx.r10.u64 + ctx.r5.u64;
	// stw r26,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r26.u32);
	// divwu r9,r9,r11
	ctx.r9.u32 = ctx.r9.u32 / ctx.r11.u32;
	// stw r26,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r26.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r26,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r26.u32);
	// stw r26,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r26.u32);
	// divwu r10,r10,r5
	ctx.r10.u32 = ctx.r10.u32 / ctx.r5.u32;
	// stw r15,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r15.u32);
	// stw r9,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r9.u32);
loc_82B45F1C:
	// stw r10,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r10.u32);
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// twllei r5,0
	// twllei r5,0
	// add r9,r10,r5
	ctx.r9.u64 = ctx.r10.u64 + ctx.r5.u64;
	// lwz r10,252(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	// add r8,r24,r17
	ctx.r8.u64 = ctx.r24.u64 + ctx.r17.u64;
	// addi r4,r9,-1
	ctx.r4.s64 = ctx.r9.s64 + -1;
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// lwz r9,280(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// divwu r5,r4,r5
	ctx.r5.u32 = ctx.r4.u32 / ctx.r5.u32;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// mr r6,r15
	ctx.r6.u64 = ctx.r15.u64;
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// twllei r11,0
	// twllei r11,0
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r3,r10,-1
	ctx.r3.s64 = ctx.r10.s64 + -1;
	// lwz r10,284(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// divwu r4,r3,r11
	ctx.r4.u32 = ctx.r3.u32 / ctx.r11.u32;
	// lwz r3,184(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	// bl 0x82b06178
	ctx.lr = 0x82B45F7C;
	sub_82B06178(ctx, base);
loc_82B45F7C:
	// cmplwi cr6,r17,0
	ctx.cr6.compare<uint32_t>(ctx.r17.u32, 0, ctx.xer);
	// beq cr6,0x82b458bc
	if (ctx.cr6.eq) goto loc_82B458BC;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82547938
	ctx.lr = 0x82B45F90;
	sub_82547938(ctx, base);
	// b 0x82b458bc
	goto loc_82B458BC;
}

__attribute__((alias("__imp__sub_82B45F98"))) PPC_WEAK_FUNC(sub_82B45F98);
PPC_FUNC_IMPL(__imp__sub_82B45F98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e44
	ctx.lr = 0x82B45FA0;
	__savegprlr_19(ctx, base);
	// stwu r1,-496(r1)
	ea = -496 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r5
	ctx.r22.u64 = ctx.r5.u64;
	// li r5,304
	ctx.r5.s64 = 304;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r21,r6
	ctx.r21.u64 = ctx.r6.u64;
	// mr r20,r7
	ctx.r20.u64 = ctx.r7.u64;
	// mr r31,r8
	ctx.r31.u64 = ctx.r8.u64;
	// mr r19,r9
	ctx.r19.u64 = ctx.r9.u64;
	// bl 0x82e29500
	ctx.lr = 0x82B45FD0;
	sub_82E29500(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82b45fe4
	if (!ctx.cr6.eq) goto loc_82B45FE4;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82b463b8
	goto loc_82B463B8;
loc_82B45FE4:
	// cmpwi cr6,r31,-1
	ctx.cr6.compare<int32_t>(ctx.r31.s32, -1, ctx.xer);
	// bne cr6,0x82b45ff0
	if (!ctx.cr6.eq) goto loc_82B45FF0;
	// li r31,0
	ctx.r31.s64 = 0;
loc_82B45FF0:
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82b46000
	if (ctx.cr6.eq) goto loc_82B46000;
	// lwz r3,0(r19)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	// b 0x82b46004
	goto loc_82B46004;
loc_82B46000:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82B46004:
	// bl 0x82b45088
	ctx.lr = 0x82B46008;
	sub_82B45088(ctx, base);
	// lwz r26,580(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 580);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b45100
	ctx.lr = 0x82B46020;
	sub_82B45100(ctx, base);
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// rlwinm r28,r24,0,26,22
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0xFFFFFFFFFFFFFE3F;
	// cmpwi cr6,r28,-449
	ctx.cr6.compare<int32_t>(ctx.r28.s32, -449, ctx.xer);
	// bne cr6,0x82b4603c
	if (!ctx.cr6.eq) goto loc_82B4603C;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2154
	ctx.r3.u64 = ctx.r3.u64 | 2154;
	// b 0x82b463b8
	goto loc_82B463B8;
loc_82B4603C:
	// li r11,-1
	ctx.r11.s64 = -1;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82b46050
	if (ctx.cr6.eq) goto loc_82B46050;
	// lwz r31,0(r23)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	// b 0x82b46054
	goto loc_82B46054;
loc_82B46050:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
loc_82B46054:
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82b46064
	if (ctx.cr6.eq) goto loc_82B46064;
	// lwz r29,0(r22)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// b 0x82b46068
	goto loc_82B46068;
loc_82B46064:
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
loc_82B46068:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82b46078
	if (ctx.cr6.eq) goto loc_82B46078;
	// lwz r27,0(r21)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// b 0x82b4607c
	goto loc_82B4607C;
loc_82B46078:
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
loc_82B4607C:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82b4608c
	if (ctx.cr6.eq) goto loc_82B4608C;
	// lwz r25,0(r20)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// b 0x82b46090
	goto loc_82B46090;
loc_82B4608C:
	// mr r25,r11
	ctx.r25.u64 = ctx.r11.u64;
loc_82B46090:
	// cmpwi cr6,r31,-1
	ctx.cr6.compare<int32_t>(ctx.r31.s32, -1, ctx.xer);
	// bne cr6,0x82b460b4
	if (!ctx.cr6.eq) goto loc_82B460B4;
	// cmpwi cr6,r29,-1
	ctx.cr6.compare<int32_t>(ctx.r29.s32, -1, ctx.xer);
	// bne cr6,0x82b460ac
	if (!ctx.cr6.eq) goto loc_82B460AC;
	// li r29,256
	ctx.r29.s64 = 256;
	// li r31,256
	ctx.r31.s64 = 256;
	// b 0x82b460d8
	goto loc_82B460D8;
loc_82B460AC:
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
	// b 0x82b460c0
	goto loc_82B460C0;
loc_82B460B4:
	// cmpwi cr6,r29,-1
	ctx.cr6.compare<int32_t>(ctx.r29.s32, -1, ctx.xer);
	// bne cr6,0x82b460c0
	if (!ctx.cr6.eq) goto loc_82B460C0;
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82B460C0:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82b460cc
	if (!ctx.cr6.eq) goto loc_82B460CC;
	// li r31,1
	ctx.r31.s64 = 1;
loc_82B460CC:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82b460d8
	if (!ctx.cr6.eq) goto loc_82B460D8;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82B460D8:
	// cmpwi cr6,r26,18
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 18, ctx.xer);
	// bne cr6,0x82b460f0
	if (!ctx.cr6.eq) goto loc_82B460F0;
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// ble cr6,0x82b460ec
	if (!ctx.cr6.gt) goto loc_82B460EC;
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82B460EC:
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
loc_82B460F0:
	// cmpwi cr6,r27,-1
	ctx.cr6.compare<int32_t>(ctx.r27.s32, -1, ctx.xer);
	// beq cr6,0x82b46100
	if (ctx.cr6.eq) goto loc_82B46100;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x82b46104
	if (!ctx.cr6.eq) goto loc_82B46104;
loc_82B46100:
	// li r27,1
	ctx.r27.s64 = 1;
loc_82B46104:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b0faf8
	ctx.lr = 0x82B46110;
	sub_82B0FAF8(ctx, base);
	// lwz r9,140(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmpwi cr6,r26,17
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 17, ctx.xer);
	// bne cr6,0x82b46144
	if (!ctx.cr6.eq) goto loc_82B46144;
	// cmplwi cr6,r27,1024
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 1024, ctx.xer);
	// ble cr6,0x82b46128
	if (!ctx.cr6.gt) goto loc_82B46128;
	// li r27,1024
	ctx.r27.s64 = 1024;
loc_82B46128:
	// cmplwi cr6,r31,2048
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 2048, ctx.xer);
	// ble cr6,0x82b46134
	if (!ctx.cr6.gt) goto loc_82B46134;
	// li r31,2048
	ctx.r31.s64 = 2048;
loc_82B46134:
	// cmplwi cr6,r29,2048
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 2048, ctx.xer);
	// ble cr6,0x82b461a4
	if (!ctx.cr6.gt) goto loc_82B461A4;
	// li r29,2048
	ctx.r29.s64 = 2048;
	// b 0x82b461a4
	goto loc_82B461A4;
loc_82B46144:
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b46154
	if (!ctx.cr6.gt) goto loc_82B46154;
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
loc_82B46154:
	// lwz r11,172(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b46164
	if (!ctx.cr6.gt) goto loc_82B46164;
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
loc_82B46164:
	// cmpwi cr6,r26,3
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 3, ctx.xer);
	// bne cr6,0x82b461a4
	if (!ctx.cr6.eq) goto loc_82B461A4;
	// rlwinm. r11,r9,0,26,26
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x20;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// bne 0x82b4617c
	if (!ctx.cr0.eq) goto loc_82B4617C;
	// lwz r10,184(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 184);
loc_82B4617C:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b461a4
	if (ctx.cr6.eq) goto loc_82B461A4;
	// mullw r11,r10,r29
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r29.s32);
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b46194
	if (!ctx.cr6.gt) goto loc_82B46194;
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
loc_82B46194:
	// mullw r11,r10,r31
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r31.s32);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b461a4
	if (!ctx.cr6.gt) goto loc_82B461A4;
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
loc_82B461A4:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r26,3
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 3, ctx.xer);
	// beq cr6,0x82b461d0
	if (ctx.cr6.eq) goto loc_82B461D0;
	// cmpwi cr6,r26,17
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 17, ctx.xer);
	// beq cr6,0x82b461c8
	if (ctx.cr6.eq) goto loc_82B461C8;
	// cmpwi cr6,r26,18
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 18, ctx.xer);
	// bne cr6,0x82b461d4
	if (!ctx.cr6.eq) goto loc_82B461D4;
	// lis r11,2
	ctx.r11.s64 = 131072;
	// b 0x82b461d4
	goto loc_82B461D4;
loc_82B461C8:
	// lis r11,4
	ctx.r11.s64 = 262144;
	// b 0x82b461d4
	goto loc_82B461D4;
loc_82B461D0:
	// li r11,2
	ctx.r11.s64 = 2;
loc_82B461D4:
	// lis r10,6688
	ctx.r10.s64 = 438304768;
	// cmplwi cr6,r25,1
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 1, ctx.xer);
	// ori r10,r10,18
	ctx.r10.u64 = ctx.r10.u64 | 18;
	// bne cr6,0x82b46208
	if (!ctx.cr6.eq) goto loc_82B46208;
	// rlwinm. r8,r9,0,23,23
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b46208
	if (ctx.cr0.eq) goto loc_82B46208;
	// cmpw cr6,r28,r10
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r10.s32, ctx.xer);
	// blt cr6,0x82b46204
	if (ctx.cr6.lt) goto loc_82B46204;
	// lis r8,6688
	ctx.r8.s64 = 438304768;
	// ori r8,r8,20
	ctx.r8.u64 = ctx.r8.u64 | 20;
	// cmpw cr6,r28,r8
	ctx.cr6.compare<int32_t>(ctx.r28.s32, ctx.r8.s32, ctx.xer);
	// ble cr6,0x82b46208
	if (!ctx.cr6.gt) goto loc_82B46208;
loc_82B46204:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82B46208:
	// and. r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 & ctx.r9.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b46264
	if (ctx.cr0.eq) goto loc_82B46264;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// li r31,1
	ctx.r31.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// ble cr6,0x82b4622c
	if (!ctx.cr6.gt) goto loc_82B4622C;
loc_82B46220:
	// rlwinm r31,r31,1,0,30
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b46220
	if (ctx.cr6.lt) goto loc_82B46220;
loc_82B4622C:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// li r29,1
	ctx.r29.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// ble cr6,0x82b46248
	if (!ctx.cr6.gt) goto loc_82B46248;
loc_82B4623C:
	// rlwinm r29,r29,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b4623c
	if (ctx.cr6.lt) goto loc_82B4623C;
loc_82B46248:
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// li r27,1
	ctx.r27.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// ble cr6,0x82b46264
	if (!ctx.cr6.gt) goto loc_82B46264;
loc_82B46258:
	// rlwinm r27,r27,1,0,30
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b46258
	if (ctx.cr6.lt) goto loc_82B46258;
loc_82B46264:
	// subf r11,r10,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r10.s64;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bgt cr6,0x82b46280
	if (ctx.cr6.gt) goto loc_82B46280;
	// addi r11,r31,3
	ctx.r11.s64 = ctx.r31.s64 + 3;
	// addi r10,r29,3
	ctx.r10.s64 = ctx.r29.s64 + 3;
	// rlwinm r31,r11,0,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r29,r10,0,0,29
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
loc_82B46280:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r26,3
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 3, ctx.xer);
	// beq cr6,0x82b462b0
	if (ctx.cr6.eq) goto loc_82B462B0;
	// cmpwi cr6,r26,17
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 17, ctx.xer);
	// beq cr6,0x82b462a4
	if (ctx.cr6.eq) goto loc_82B462A4;
	// cmpwi cr6,r26,18
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 18, ctx.xer);
	// bne cr6,0x82b462b4
	if (!ctx.cr6.eq) goto loc_82B462B4;
	// lis r11,1
	ctx.r11.s64 = 65536;
	// b 0x82b462b4
	goto loc_82B462B4;
loc_82B462A4:
	// lis r11,0
	ctx.r11.s64 = 0;
	// ori r11,r11,32768
	ctx.r11.u64 = ctx.r11.u64 | 32768;
	// b 0x82b462b4
	goto loc_82B462B4;
loc_82B462B0:
	// li r11,16384
	ctx.r11.s64 = 16384;
loc_82B462B4:
	// and. r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 & ctx.r9.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b462e8
	if (ctx.cr0.eq) goto loc_82B462E8;
	// rlwinm. r11,r9,0,23,23
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x100;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b462f0
	if (ctx.cr0.eq) goto loc_82B462F0;
	// addi r11,r31,-1
	ctx.r11.s64 = ctx.r31.s64 + -1;
	// and. r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 & ctx.r31.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b462e8
	if (!ctx.cr0.eq) goto loc_82B462E8;
	// addi r11,r29,-1
	ctx.r11.s64 = ctx.r29.s64 + -1;
	// and. r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 & ctx.r29.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b462e8
	if (!ctx.cr0.eq) goto loc_82B462E8;
	// addi r11,r27,-1
	ctx.r11.s64 = ctx.r27.s64 + -1;
	// and. r11,r11,r27
	ctx.r11.u64 = ctx.r11.u64 & ctx.r27.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b462f0
	if (ctx.cr0.eq) goto loc_82B462F0;
loc_82B462E8:
	// li r25,1
	ctx.r25.s64 = 1;
	// b 0x82b46378
	goto loc_82B46378;
loc_82B462F0:
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b4630c
	if (ctx.cr6.eq) goto loc_82B4630C;
loc_82B46300:
	// rlwinm. r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// bne 0x82b46300
	if (!ctx.cr0.eq) goto loc_82B46300;
loc_82B4630C:
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b46328
	if (ctx.cr6.eq) goto loc_82B46328;
loc_82B4631C:
	// rlwinm. r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// bne 0x82b4631c
	if (!ctx.cr0.eq) goto loc_82B4631C;
loc_82B46328:
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82b46344
	if (ctx.cr6.eq) goto loc_82B46344;
loc_82B46338:
	// rlwinm. r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// bne 0x82b46338
	if (!ctx.cr0.eq) goto loc_82B46338;
loc_82B46344:
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b46350
	if (!ctx.cr6.gt) goto loc_82B46350;
	// mr r11,r8
	ctx.r11.u64 = ctx.r8.u64;
loc_82B46350:
	// cmpwi cr6,r26,17
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 17, ctx.xer);
	// bne cr6,0x82b46364
	if (!ctx.cr6.eq) goto loc_82B46364;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82b46364
	if (!ctx.cr6.gt) goto loc_82B46364;
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
loc_82B46364:
	// cmplw cr6,r25,r11
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r11.u32, ctx.xer);
	// bgt cr6,0x82b46374
	if (ctx.cr6.gt) goto loc_82B46374;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// bne cr6,0x82b46378
	if (!ctx.cr6.eq) goto loc_82B46378;
loc_82B46374:
	// mr r25,r11
	ctx.r25.u64 = ctx.r11.u64;
loc_82B46378:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82b46384
	if (ctx.cr6.eq) goto loc_82B46384;
	// stw r31,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r31.u32);
loc_82B46384:
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82b46390
	if (ctx.cr6.eq) goto loc_82B46390;
	// stw r29,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r29.u32);
loc_82B46390:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82b4639c
	if (ctx.cr6.eq) goto loc_82B4639C;
	// stw r27,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r27.u32);
loc_82B4639C:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82b463a8
	if (ctx.cr6.eq) goto loc_82B463A8;
	// stw r25,0(r20)
	PPC_STORE_U32(ctx.r20.u32 + 0, ctx.r25.u32);
loc_82B463A8:
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82b463b4
	if (ctx.cr6.eq) goto loc_82B463B4;
	// stw r24,0(r19)
	PPC_STORE_U32(ctx.r19.u32 + 0, ctx.r24.u32);
loc_82B463B4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B463B8:
	// addi r1,r1,496
	ctx.r1.s64 = ctx.r1.s64 + 496;
	// b 0x82e28e94
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B463C0"))) PPC_WEAK_FUNC(sub_82B463C0);
PPC_FUNC_IMPL(__imp__sub_82B463C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82B463C8;
	__savegprlr_24(ctx, base);
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// mr r25,r9
	ctx.r25.u64 = ctx.r9.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// bl 0x82b778c0
	ctx.lr = 0x82B463F4;
	sub_82B778C0(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82b46414
	if (!ctx.cr6.eq) goto loc_82B46414;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82b77b30
	ctx.lr = 0x82B46404;
	sub_82B77B30(ctx, base);
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
loc_82B4640C:
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
loc_82B46414:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82b46434
	if (!ctx.cr6.eq) goto loc_82B46434;
	// lis r31,-30602
	ctx.r31.s64 = -2005532672;
	// ori r31,r31,2156
	ctx.r31.u64 = ctx.r31.u64 | 2156;
loc_82B46424:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82b77b30
	ctx.lr = 0x82B4642C;
	sub_82B77B30(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82b4640c
	goto loc_82B4640C;
loc_82B46434:
	// li r9,1
	ctx.r9.s64 = 1;
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82b46448
	if (!ctx.cr6.eq) goto loc_82B46448;
	// lis r9,1
	ctx.r9.s64 = 65536;
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
loc_82B46448:
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82b77b38
	ctx.lr = 0x82B46464;
	sub_82B77B38(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b46474
	if (!ctx.cr0.lt) goto loc_82B46474;
loc_82B4646C:
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82b46424
	goto loc_82B46424;
loc_82B46474:
	// addi r5,r1,256
	ctx.r5.s64 = ctx.r1.s64 + 256;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82b048c8
	ctx.lr = 0x82B46484;
	sub_82B048C8(ctx, base);
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r7,264(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// addi r10,r1,200
	ctx.r10.s64 = ctx.r1.s64 + 200;
	// lwz r6,260(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// lwz r8,168(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// stw r24,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r24.u32);
	// lwz r11,48(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r7,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
	// rlwinm r11,r11,21,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x1;
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// lwz r7,164(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r6,160(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// stw r25,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r25.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82b45160
	ctx.lr = 0x82B464D0;
	sub_82B45160(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4646c
	if (ctx.cr0.lt) goto loc_82B4646C;
	// li r31,0
	ctx.r31.s64 = 0;
	// b 0x82b46424
	goto loc_82B46424;
}

__attribute__((alias("__imp__sub_82B464E0"))) PPC_WEAK_FUNC(sub_82B464E0);
PPC_FUNC_IMPL(__imp__sub_82B464E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82B464E8;
	__savegprlr_24(ctx, base);
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// mr r25,r9
	ctx.r25.u64 = ctx.r9.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// bl 0x82b778e0
	ctx.lr = 0x82B46514;
	sub_82B778E0(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82b46534
	if (!ctx.cr6.eq) goto loc_82B46534;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b78028
	ctx.lr = 0x82B46524;
	sub_82B78028(ctx, base);
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
loc_82B4652C:
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
loc_82B46534:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82b46554
	if (!ctx.cr6.eq) goto loc_82B46554;
	// lis r31,-30602
	ctx.r31.s64 = -2005532672;
	// ori r31,r31,2156
	ctx.r31.u64 = ctx.r31.u64 | 2156;
loc_82B46544:
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b78028
	ctx.lr = 0x82B4654C;
	sub_82B78028(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82b4652c
	goto loc_82B4652C;
loc_82B46554:
	// li r9,1
	ctx.r9.s64 = 1;
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82b46568
	if (!ctx.cr6.eq) goto loc_82B46568;
	// lis r9,1
	ctx.r9.s64 = 65536;
	// ori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 | 1;
loc_82B46568:
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82b78030
	ctx.lr = 0x82B46584;
	sub_82B78030(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b46594
	if (!ctx.cr0.lt) goto loc_82B46594;
loc_82B4658C:
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82b46544
	goto loc_82B46544;
loc_82B46594:
	// addi r5,r1,256
	ctx.r5.s64 = ctx.r1.s64 + 256;
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82b048c8
	ctx.lr = 0x82B465A4;
	sub_82B048C8(ctx, base);
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r4,260(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// addi r5,r1,200
	ctx.r5.s64 = ctx.r1.s64 + 200;
	// lwz r8,268(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// lwz r7,264(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r9,172(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lwz r11,48(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	// stw r4,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r4.u32);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// rlwinm r11,r11,21,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x1;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// stw r8,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r8.u32);
	// stw r7,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r7.u32);
	// lwz r8,168(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lwz r7,164(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r6,160(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// stw r24,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r24.u32);
	// stw r25,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r25.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// bl 0x82b457f0
	ctx.lr = 0x82B46600;
	sub_82B457F0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4658c
	if (ctx.cr0.lt) goto loc_82B4658C;
	// li r31,0
	ctx.r31.s64 = 0;
	// b 0x82b46544
	goto loc_82B46544;
}

__attribute__((alias("__imp__sub_82B46610"))) PPC_WEAK_FUNC(sub_82B46610);
PPC_FUNC_IMPL(__imp__sub_82B46610) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82B46618;
	__savegprlr_14(ctx, base);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r14,r4
	ctx.r14.u64 = ctx.r4.u64;
	// mr r18,r5
	ctx.r18.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82b46640
	if (!ctx.cr6.eq) goto loc_82B46640;
loc_82B46634:
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82b46a2c
	goto loc_82B46A2C;
loc_82B46640:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b0ec88
	ctx.lr = 0x82B46648;
	sub_82B0EC88(ctx, base);
	// mr r19,r3
	ctx.r19.u64 = ctx.r3.u64;
	// cmpwi cr6,r19,3
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 3, ctx.xer);
	// beq cr6,0x82b46680
	if (ctx.cr6.eq) goto loc_82B46680;
	// cmpwi cr6,r19,17
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 17, ctx.xer);
	// beq cr6,0x82b46670
	if (ctx.cr6.eq) goto loc_82B46670;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// bne cr6,0x82b46634
	if (!ctx.cr6.eq) goto loc_82B46634;
	// lwz r16,80(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r17,r30
	ctx.r17.u64 = ctx.r30.u64;
	// b 0x82b46688
	goto loc_82B46688;
loc_82B46670:
	// lwz r16,80(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r15,r30
	ctx.r15.u64 = ctx.r30.u64;
	// lwz r17,80(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x82b4668c
	goto loc_82B4668C;
loc_82B46680:
	// lwz r17,80(r1)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r16,r30
	ctx.r16.u64 = ctx.r30.u64;
loc_82B46688:
	// lwz r15,80(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82B4668C:
	// cmpwi cr6,r31,-1
	ctx.cr6.compare<int32_t>(ctx.r31.s32, -1, ctx.xer);
	// bne cr6,0x82b466e4
	if (!ctx.cr6.eq) goto loc_82B466E4;
	// cmpwi cr6,r19,3
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 3, ctx.xer);
	// beq cr6,0x82b467e4
	if (ctx.cr6.eq) goto loc_82B467E4;
	// cmpwi cr6,r19,17
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 17, ctx.xer);
	// beq cr6,0x82b467ac
	if (ctx.cr6.eq) goto loc_82B467AC;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// bne cr6,0x82b4681c
	if (!ctx.cr6.eq) goto loc_82B4681C;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b140f8
	ctx.lr = 0x82B466BC;
	sub_82B140F8(ctx, base);
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b466dc
	if (!ctx.cr0.eq) goto loc_82B466DC;
	// lwz r11,156(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
loc_82B466D0:
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b46828
	if (ctx.cr0.eq) goto loc_82B46828;
loc_82B466DC:
	// lis r31,8
	ctx.r31.s64 = 524288;
	// ori r31,r31,4
	ctx.r31.u64 = ctx.r31.u64 | 4;
loc_82B466E4:
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// bne cr6,0x82b466f0
	if (!ctx.cr6.eq) goto loc_82B466F0;
	// oris r31,r31,7
	ctx.r31.u64 = ctx.r31.u64 | 458752;
loc_82B466F0:
	// rlwinm. r11,r31,0,9,9
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x400000;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// oris r21,r31,96
	ctx.r21.u64 = ctx.r31.u64 | 6291456;
	// bne 0x82b46700
	if (!ctx.cr0.eq) goto loc_82B46700;
	// rlwinm r21,r31,0,11,8
	ctx.r21.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFFFFF9FFFFF;
loc_82B46700:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b13dd8
	ctx.lr = 0x82B46708;
	sub_82B13DD8(ctx, base);
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// cmpwi cr6,r18,-1
	ctx.cr6.compare<int32_t>(ctx.r18.s32, -1, ctx.xer);
	// bne cr6,0x82b46718
	if (!ctx.cr6.eq) goto loc_82B46718;
	// li r18,0
	ctx.r18.s64 = 0;
loc_82B46718:
	// cmplw cr6,r18,r20
	ctx.cr6.compare<uint32_t>(ctx.r18.u32, ctx.r20.u32, ctx.xer);
	// bge cr6,0x82b46634
	if (!ctx.cr6.lt) goto loc_82B46634;
	// li r29,0
	ctx.r29.s64 = 0;
	// li r26,0
	ctx.r26.s64 = 0;
	// li r28,0
	ctx.r28.s64 = 0;
	// li r25,0
	ctx.r25.s64 = 0;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// li r22,6
	ctx.r22.s64 = 6;
	// beq cr6,0x82b46740
	if (ctx.cr6.eq) goto loc_82B46740;
	// li r22,1
	ctx.r22.s64 = 1;
loc_82B46740:
	// clrlwi r11,r21,24
	ctx.r11.u64 = ctx.r21.u32 & 0xFF;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82b46758
	if (ctx.cr6.eq) goto loc_82B46758;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// li r23,0
	ctx.r23.s64 = 0;
	// bne cr6,0x82b4675c
	if (!ctx.cr6.eq) goto loc_82B4675C;
loc_82B46758:
	// li r23,1
	ctx.r23.s64 = 1;
loc_82B4675C:
	// li r27,0
	ctx.r27.s64 = 0;
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82b469e4
	if (ctx.cr6.eq) goto loc_82B469E4;
	// lis r11,-32761
	ctx.r11.s64 = -2147024896;
	// lwz r31,80(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// ori r24,r11,14
	ctx.r24.u64 = ctx.r11.u64 | 14;
loc_82B46774:
	// cmpwi cr6,r19,3
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 3, ctx.xer);
	// beq cr6,0x82b46844
	if (ctx.cr6.eq) goto loc_82B46844;
	// cmpwi cr6,r19,17
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 17, ctx.xer);
	// beq cr6,0x82b46830
	if (ctx.cr6.eq) goto loc_82B46830;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// bne cr6,0x82b4685c
	if (!ctx.cr6.eq) goto loc_82B4685C;
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b13f78
	ctx.lr = 0x82B4679C;
	sub_82B13F78(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
loc_82B467A0:
	// beq 0x82b46a34
	if (ctx.cr0.eq) goto loc_82B46A34;
loc_82B467A4:
	// li r31,0
	ctx.r31.s64 = 0;
	// b 0x82b46864
	goto loc_82B46864;
loc_82B467AC:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
	// bl 0x82b14038
	ctx.lr = 0x82B467BC;
	sub_82B14038(ctx, base);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b466dc
	if (!ctx.cr0.eq) goto loc_82B466DC;
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b466dc
	if (!ctx.cr0.eq) goto loc_82B466DC;
	// lwz r11,120(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// b 0x82b466d0
	goto loc_82B466D0;
loc_82B467E4:
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82b140f8
	ctx.lr = 0x82B467F4;
	sub_82B140F8(ctx, base);
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b46814
	if (!ctx.cr0.eq) goto loc_82B46814;
	// lwz r11,156(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// and. r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b46828
	if (ctx.cr0.eq) goto loc_82B46828;
loc_82B46814:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82b46820
	goto loc_82B46820;
loc_82B4681C:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82B46820:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b466dc
	if (ctx.cr6.eq) goto loc_82B466DC;
loc_82B46828:
	// li r31,5
	ctx.r31.s64 = 5;
	// b 0x82b466e4
	goto loc_82B466E4;
loc_82B46830:
	// mr r4,r18
	ctx.r4.u64 = ctx.r18.u64;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
	// bl 0x82b14040
	ctx.lr = 0x82B4683C;
	sub_82B14040(ctx, base);
	// mr. r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// b 0x82b467a0
	goto loc_82B467A0;
loc_82B46844:
	// mr r4,r18
	ctx.r4.u64 = ctx.r18.u64;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82b13ea8
	ctx.lr = 0x82B46850;
	sub_82B13EA8(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// bne 0x82b467a4
	if (!ctx.cr0.eq) goto loc_82B467A4;
	// mr r31,r24
	ctx.r31.u64 = ctx.r24.u64;
loc_82B4685C:
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt cr6,0x82b469e8
	if (ctx.cr6.lt) goto loc_82B469E8;
loc_82B46864:
	// addi r30,r18,1
	ctx.r30.s64 = ctx.r18.s64 + 1;
	// b 0x82b469a8
	goto loc_82B469A8;
loc_82B4686C:
	// cmpwi cr6,r19,3
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 3, ctx.xer);
	// beq cr6,0x82b46940
	if (ctx.cr6.eq) goto loc_82B46940;
	// cmpwi cr6,r19,17
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 17, ctx.xer);
	// beq cr6,0x82b46904
	if (ctx.cr6.eq) goto loc_82B46904;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// bne cr6,0x82b46958
	if (!ctx.cr6.eq) goto loc_82B46958;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b13f78
	ctx.lr = 0x82B46894;
	sub_82B13F78(ctx, base);
	// mr. r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// beq 0x82b46a34
	if (ctx.cr0.eq) goto loc_82B46A34;
loc_82B4689C:
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r14
	ctx.r7.u64 = ctx.r14.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b463c0
	ctx.lr = 0x82B468C0;
	sub_82B463C0(ctx, base);
loc_82B468C0:
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
loc_82B468C4:
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt cr6,0x82b469e8
	if (ctx.cr6.lt) goto loc_82B469E8;
	// cmpwi cr6,r23,0
	ctx.cr6.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq cr6,0x82b4697c
	if (ctx.cr6.eq) goto loc_82B4697C;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b468e4
	if (ctx.cr6.eq) goto loc_82B468E4;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B468E4;
	sub_82B0F2F0(ctx, base);
loc_82B468E4:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82b468f4
	if (ctx.cr6.eq) goto loc_82B468F4;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B468F4;
	sub_82B0F2F0(ctx, base);
loc_82B468F4:
	// mr r29,r28
	ctx.r29.u64 = ctx.r28.u64;
	// mr r26,r25
	ctx.r26.u64 = ctx.r25.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// b 0x82b469a0
	goto loc_82B469A0;
loc_82B46904:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
	// bl 0x82b14040
	ctx.lr = 0x82B46910;
	sub_82B14040(ctx, base);
	// mr. r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// beq 0x82b46a34
	if (ctx.cr0.eq) goto loc_82B46A34;
loc_82B46918:
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r21
	ctx.r9.u64 = ctx.r21.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r14
	ctx.r7.u64 = ctx.r14.u64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82b464e0
	ctx.lr = 0x82B4693C;
	sub_82B464E0(ctx, base);
	// b 0x82b468c0
	goto loc_82B468C0;
loc_82B46940:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82b13ea8
	ctx.lr = 0x82B4694C;
	sub_82B13EA8(ctx, base);
	// mr. r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne 0x82b4689c
	if (!ctx.cr0.eq) goto loc_82B4689C;
	// mr r31,r24
	ctx.r31.u64 = ctx.r24.u64;
loc_82B46958:
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt cr6,0x82b469e8
	if (ctx.cr6.lt) goto loc_82B469E8;
	// cmpwi cr6,r19,3
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 3, ctx.xer);
	// beq cr6,0x82b4689c
	if (ctx.cr6.eq) goto loc_82B4689C;
	// cmpwi cr6,r19,17
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 17, ctx.xer);
	// beq cr6,0x82b46918
	if (ctx.cr6.eq) goto loc_82B46918;
	// cmpwi cr6,r19,18
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 18, ctx.xer);
	// beq cr6,0x82b4689c
	if (ctx.cr6.eq) goto loc_82B4689C;
	// b 0x82b468c4
	goto loc_82B468C4;
loc_82B4697C:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82b46990
	if (ctx.cr6.eq) goto loc_82B46990;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B4698C;
	sub_82B0F2F0(ctx, base);
	// li r28,0
	ctx.r28.s64 = 0;
loc_82B46990:
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82b469a4
	if (ctx.cr6.eq) goto loc_82B469A4;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B469A0;
	sub_82B0F2F0(ctx, base);
loc_82B469A0:
	// li r25,0
	ctx.r25.s64 = 0;
loc_82B469A4:
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82B469A8:
	// cmplw cr6,r30,r20
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r20.u32, ctx.xer);
	// blt cr6,0x82b4686c
	if (ctx.cr6.lt) goto loc_82B4686C;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b469c4
	if (ctx.cr6.eq) goto loc_82B469C4;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B469C0;
	sub_82B0F2F0(ctx, base);
	// li r29,0
	ctx.r29.s64 = 0;
loc_82B469C4:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82b469d8
	if (ctx.cr6.eq) goto loc_82B469D8;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B469D4;
	sub_82B0F2F0(ctx, base);
	// li r26,0
	ctx.r26.s64 = 0;
loc_82B469D8:
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// cmplw cr6,r27,r22
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r22.u32, ctx.xer);
	// blt cr6,0x82b46774
	if (ctx.cr6.lt) goto loc_82B46774;
loc_82B469E4:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82B469E8:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b469f8
	if (ctx.cr6.eq) goto loc_82B469F8;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B469F8;
	sub_82B0F2F0(ctx, base);
loc_82B469F8:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82b46a08
	if (ctx.cr6.eq) goto loc_82B46A08;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B46A08;
	sub_82B0F2F0(ctx, base);
loc_82B46A08:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82b46a18
	if (ctx.cr6.eq) goto loc_82B46A18;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B46A18;
	sub_82B0F2F0(ctx, base);
loc_82B46A18:
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82b46a28
	if (ctx.cr6.eq) goto loc_82B46A28;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B46A28;
	sub_82B0F2F0(ctx, base);
loc_82B46A28:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82B46A2C:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
loc_82B46A34:
	// mr r31,r24
	ctx.r31.u64 = ctx.r24.u64;
	// b 0x82b469e8
	goto loc_82B469E8;
}

__attribute__((alias("__imp__sub_82B46A40"))) PPC_WEAK_FUNC(sub_82B46A40);
PPC_FUNC_IMPL(__imp__sub_82B46A40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82B46A48;
	__savegprlr_14(ctx, base);
	// stwu r1,-1520(r1)
	ea = -1520 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// stw r9,1588(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1588, ctx.r9.u32);
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// stw r28,1564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1564, ctx.r28.u32);
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// stw r27,1572(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1572, ctx.r27.u32);
	// stw r26,1580(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1580, ctx.r26.u32);
	// mr r25,r10
	ctx.r25.u64 = ctx.r10.u64;
	// bl 0x82b6fff8
	ctx.lr = 0x82B46A80;
	sub_82B6FFF8(ctx, base);
	// li r16,0
	ctx.r16.s64 = 0;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// mr r17,r16
	ctx.r17.u64 = ctx.r16.u64;
	// stw r16,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r16.u32);
	// bne cr6,0x82b46aac
	if (!ctx.cr6.eq) goto loc_82B46AAC;
loc_82B46A94:
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82b70310
	ctx.lr = 0x82B46A9C;
	sub_82B70310(ctx, base);
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
loc_82B46AA4:
	// addi r1,r1,1520
	ctx.r1.s64 = ctx.r1.s64 + 1520;
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
loc_82B46AAC:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b46a94
	if (ctx.cr6.eq) goto loc_82B46A94;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82b46a94
	if (ctx.cr6.eq) goto loc_82B46A94;
	// lwz r11,1668(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b46ae0
	if (!ctx.cr6.eq) goto loc_82B46AE0;
	// lis r30,-30602
	ctx.r30.s64 = -2005532672;
	// ori r30,r30,2156
	ctx.r30.u64 = ctx.r30.u64 | 2156;
loc_82B46AD0:
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82b70310
	ctx.lr = 0x82B46AD8;
	sub_82B70310(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// b 0x82b46aa4
	goto loc_82B46AA4;
loc_82B46AE0:
	// lwz r29,1644(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1644);
	// lwz r22,1660(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82b46afc
	if (!ctx.cr6.eq) goto loc_82B46AFC;
	// cmpwi cr6,r22,-1
	ctx.cr6.compare<int32_t>(ctx.r22.s32, -1, ctx.xer);
	// bne cr6,0x82b46afc
	if (!ctx.cr6.eq) goto loc_82B46AFC;
	// addi r29,r1,304
	ctx.r29.s64 = ctx.r1.s64 + 304;
loc_82B46AFC:
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82b73a00
	ctx.lr = 0x82B46B14;
	sub_82B73A00(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b46b24
	if (!ctx.cr0.lt) goto loc_82B46B24;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// b 0x82b46ad0
	goto loc_82B46AD0;
loc_82B46B24:
	// cmpwi cr6,r22,-1
	ctx.cr6.compare<int32_t>(ctx.r22.s32, -1, ctx.xer);
	// bne cr6,0x82b46b34
	if (!ctx.cr6.eq) goto loc_82B46B34;
	// lwz r22,20(r29)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// stw r22,1660(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1660, ctx.r22.u32);
loc_82B46B34:
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,236(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
	// beq cr6,0x82b46b5c
	if (ctx.cr6.eq) goto loc_82B46B5C;
loc_82B46B48:
	// lwz r11,76(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b46b48
	if (!ctx.cr0.eq) goto loc_82B46B48;
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
loc_82B46B5C:
	// li r10,1
	ctx.r10.s64 = 1;
	// cmpwi cr6,r22,18
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 18, ctx.xer);
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
	// bne cr6,0x82b46ba0
	if (!ctx.cr6.eq) goto loc_82B46BA0;
	// lwz r11,240(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b46b94
	if (ctx.cr6.eq) goto loc_82B46B94;
loc_82B46B78:
	// lwz r11,80(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b46b78
	if (!ctx.cr0.eq) goto loc_82B46B78;
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
	// cmplwi cr6,r10,6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 6, ctx.xer);
	// beq cr6,0x82b46ba0
	if (ctx.cr6.eq) goto loc_82B46BA0;
loc_82B46B94:
	// lis r30,-32768
	ctx.r30.s64 = -2147483648;
	// ori r30,r30,16389
	ctx.r30.u64 = ctx.r30.u64 | 16389;
	// b 0x82b46ad0
	goto loc_82B46AD0;
loc_82B46BA0:
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// cmpwi cr6,r28,-2
	ctx.cr6.compare<int32_t>(ctx.r28.s32, -2, ctx.xer);
	// beq cr6,0x82b46be8
	if (ctx.cr6.eq) goto loc_82B46BE8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// blt cr6,0x82b46be8
	if (ctx.cr6.lt) goto loc_82B46BE8;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82b46bc4
	if (ctx.cr6.eq) goto loc_82B46BC4;
	// cmpwi cr6,r28,-1
	ctx.cr6.compare<int32_t>(ctx.r28.s32, -1, ctx.xer);
	// bne cr6,0x82b46bec
	if (!ctx.cr6.eq) goto loc_82B46BEC;
loc_82B46BC4:
	// li r11,1
	ctx.r11.s64 = 1;
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// stw r11,1564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1564, ctx.r11.u32);
	// ble cr6,0x82b46bec
	if (!ctx.cr6.gt) goto loc_82B46BEC;
loc_82B46BD4:
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82b46bd4
	if (ctx.cr6.lt) goto loc_82B46BD4;
	// stw r11,1564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1564, ctx.r11.u32);
	// b 0x82b46bec
	goto loc_82B46BEC;
loc_82B46BE8:
	// stw r10,1564(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1564, ctx.r10.u32);
loc_82B46BEC:
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// cmpwi cr6,r27,-2
	ctx.cr6.compare<int32_t>(ctx.r27.s32, -2, ctx.xer);
	// beq cr6,0x82b46c34
	if (ctx.cr6.eq) goto loc_82B46C34;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// blt cr6,0x82b46c34
	if (ctx.cr6.lt) goto loc_82B46C34;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82b46c10
	if (ctx.cr6.eq) goto loc_82B46C10;
	// cmpwi cr6,r27,-1
	ctx.cr6.compare<int32_t>(ctx.r27.s32, -1, ctx.xer);
	// bne cr6,0x82b46c38
	if (!ctx.cr6.eq) goto loc_82B46C38;
loc_82B46C10:
	// li r11,1
	ctx.r11.s64 = 1;
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// stw r11,1572(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1572, ctx.r11.u32);
	// ble cr6,0x82b46c38
	if (!ctx.cr6.gt) goto loc_82B46C38;
loc_82B46C20:
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82b46c20
	if (ctx.cr6.lt) goto loc_82B46C20;
	// stw r11,1572(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1572, ctx.r11.u32);
	// b 0x82b46c38
	goto loc_82B46C38;
loc_82B46C34:
	// stw r10,1572(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1572, ctx.r10.u32);
loc_82B46C38:
	// lwz r10,180(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmpwi cr6,r26,-2
	ctx.cr6.compare<int32_t>(ctx.r26.s32, -2, ctx.xer);
	// beq cr6,0x82b46c80
	if (ctx.cr6.eq) goto loc_82B46C80;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// blt cr6,0x82b46c80
	if (ctx.cr6.lt) goto loc_82B46C80;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82b46c5c
	if (ctx.cr6.eq) goto loc_82B46C5C;
	// cmpwi cr6,r26,-1
	ctx.cr6.compare<int32_t>(ctx.r26.s32, -1, ctx.xer);
	// bne cr6,0x82b46c84
	if (!ctx.cr6.eq) goto loc_82B46C84;
loc_82B46C5C:
	// li r11,1
	ctx.r11.s64 = 1;
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// stw r11,1580(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1580, ctx.r11.u32);
	// ble cr6,0x82b46c84
	if (!ctx.cr6.gt) goto loc_82B46C84;
loc_82B46C6C:
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82b46c6c
	if (ctx.cr6.lt) goto loc_82B46C6C;
	// stw r11,1580(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1580, ctx.r11.u32);
	// b 0x82b46c84
	goto loc_82B46C84;
loc_82B46C80:
	// stw r10,1580(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1580, ctx.r10.u32);
loc_82B46C84:
	// lwz r19,1620(r1)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1620);
	// cmpwi cr6,r19,-1
	ctx.cr6.compare<int32_t>(ctx.r19.s32, -1, ctx.xer);
	// bne cr6,0x82b46c98
	if (!ctx.cr6.eq) goto loc_82B46C98;
	// lis r19,8
	ctx.r19.s64 = 524288;
	// ori r19,r19,4
	ctx.r19.u64 = ctx.r19.u64 | 4;
loc_82B46C98:
	// lwz r14,1628(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1628);
	// cmpwi cr6,r14,-1
	ctx.cr6.compare<int32_t>(ctx.r14.s32, -1, ctx.xer);
	// bne cr6,0x82b46ca8
	if (!ctx.cr6.eq) goto loc_82B46CA8;
	// li r14,5
	ctx.r14.s64 = 5;
loc_82B46CA8:
	// cmpwi cr6,r22,18
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 18, ctx.xer);
	// bne cr6,0x82b46cb8
	if (!ctx.cr6.eq) goto loc_82B46CB8;
	// oris r19,r19,7
	ctx.r19.u64 = ctx.r19.u64 | 458752;
	// oris r14,r14,7
	ctx.r14.u64 = ctx.r14.u64 | 458752;
loc_82B46CB8:
	// clrlwi r11,r19,24
	ctx.r11.u64 = ctx.r19.u32 & 0xFF;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82b46cdc
	if (ctx.cr6.eq) goto loc_82B46CDC;
	// clrlwi r11,r14,24
	ctx.r11.u64 = ctx.r14.u32 & 0xFF;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82b46cdc
	if (ctx.cr6.eq) goto loc_82B46CDC;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// mr r15,r16
	ctx.r15.u64 = ctx.r16.u64;
	// bne cr6,0x82b46ce0
	if (!ctx.cr6.eq) goto loc_82B46CE0;
loc_82B46CDC:
	// li r15,1
	ctx.r15.s64 = 1;
loc_82B46CE0:
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b46cf8
	if (ctx.cr6.eq) goto loc_82B46CF8;
	// lis r30,-32768
	ctx.r30.s64 = -2147483648;
	// ori r30,r30,16385
	ctx.r30.u64 = ctx.r30.u64 | 16385;
	// b 0x82b46ad0
	goto loc_82B46AD0;
loc_82B46CF8:
	// li r5,1024
	ctx.r5.s64 = 1024;
	// li r4,255
	ctx.r4.s64 = 255;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// bl 0x82e29500
	ctx.lr = 0x82B46D08;
	sub_82E29500(ctx, base);
	// lwz r11,1604(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	// lwz r21,1636(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1636);
	// rlwinm r11,r11,0,26,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFE3F;
	// cmpwi cr6,r11,-449
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -449, ctx.xer);
	// bne cr6,0x82b46dcc
	if (!ctx.cr6.eq) goto loc_82B46DCC;
	// lwz r7,160(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x82b46da0
	if (ctx.cr6.eq) goto loc_82B46DA0;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82b45088
	ctx.lr = 0x82B46D30;
	sub_82B45088(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b46d50
	if (ctx.cr0.eq) goto loc_82B46D50;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82b46d50
	if (ctx.cr6.eq) goto loc_82B46D50;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82b46da0
	if (!ctx.cr6.eq) goto loc_82B46DA0;
loc_82B46D50:
	// lwz r11,16(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b46da0
	if (!ctx.cr6.eq) goto loc_82B46DA0;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// li r5,36
	ctx.r5.s64 = 36;
	// bl 0x82e28fd0
	ctx.lr = 0x82B46D68;
	sub_82E28FD0(ctx, base);
	// li r11,-1
	ctx.r11.s64 = -1;
	// addi r6,r1,256
	ctx.r6.s64 = ctx.r1.s64 + 256;
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r11.u32);
	// bl 0x82b45100
	ctx.lr = 0x82B46D8C;
	sub_82B45100(ctx, base);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// rlwinm r11,r7,0,26,22
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFFFFFFE3F;
	// cmpwi cr6,r11,-449
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -449, ctx.xer);
	// bne cr6,0x82b46da0
	if (!ctx.cr6.eq) goto loc_82B46DA0;
	// lwz r7,160(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
loc_82B46DA0:
	// addis r11,r7,-13873
	ctx.r11.s64 = ctx.r7.s64 + -909180928;
	// addic. r11,r11,-19521
	ctx.xer.ca = ctx.r11.u32 > 19520;
	ctx.r11.s64 = ctx.r11.s64 + -19521;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b46dc0
	if (ctx.cr0.eq) goto loc_82B46DC0;
	// cmplwi cr6,r11,1503
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1503, ctx.xer);
	// bne cr6,0x82b46dc8
	if (!ctx.cr6.eq) goto loc_82B46DC8;
	// lis r7,10280
	ctx.r7.s64 = 673710080;
	// ori r7,r7,134
	ctx.r7.u64 = ctx.r7.u64 | 134;
	// b 0x82b46dc8
	goto loc_82B46DC8;
loc_82B46DC0:
	// lis r7,2048
	ctx.r7.s64 = 134217728;
	// ori r7,r7,74
	ctx.r7.u64 = ctx.r7.u64 | 74;
loc_82B46DC8:
	// stw r7,1604(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1604, ctx.r7.u32);
loc_82B46DCC:
	// lwz r23,1652(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1652);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82b46de8
	if (ctx.cr6.eq) goto loc_82B46DE8;
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// li r5,1024
	ctx.r5.s64 = 1024;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B46DE8;
	sub_82E28FD0(ctx, base);
loc_82B46DE8:
	// lwz r31,1612(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1612);
	// addi r9,r1,1604
	ctx.r9.s64 = ctx.r1.s64 + 1604;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// stw r22,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r22.u32);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// addi r7,r1,1588
	ctx.r7.s64 = ctx.r1.s64 + 1588;
	// addi r6,r1,1580
	ctx.r6.s64 = ctx.r1.s64 + 1580;
	// addi r5,r1,1572
	ctx.r5.s64 = ctx.r1.s64 + 1572;
	// addi r4,r1,1564
	ctx.r4.s64 = ctx.r1.s64 + 1564;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82b45f98
	ctx.lr = 0x82B46E14;
	sub_82B45F98(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b46ad0
	if (ctx.cr0.lt) goto loc_82B46AD0;
	// lis r11,-32761
	ctx.r11.s64 = -2147024896;
	// lwz r20,1588(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	// cmpwi cr6,r22,3
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 3, ctx.xer);
	// ori r18,r11,14
	ctx.r18.u64 = ctx.r11.u64 | 14;
	// beq cr6,0x82b46e98
	if (ctx.cr6.eq) goto loc_82B46E98;
	// cmpwi cr6,r22,17
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 17, ctx.xer);
	// beq cr6,0x82b46e84
	if (ctx.cr6.eq) goto loc_82B46E84;
	// cmpwi cr6,r22,18
	ctx.cr6.compare<int32_t>(ctx.r22.s32, 18, ctx.xer);
	// bne cr6,0x82b46ec8
	if (!ctx.cr6.eq) goto loc_82B46EC8;
	// lwz r4,1564(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	// li r10,18
	ctx.r10.s64 = 18;
	// li r5,6
	ctx.r5.s64 = 6;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
loc_82B46E50:
	// lwz r20,1588(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1588);
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// lwz r8,1604(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	// mr r6,r20
	ctx.r6.u64 = ctx.r20.u64;
	// bl 0x82b14100
	ctx.lr = 0x82B46E68;
	sub_82B14100(ctx, base);
	// mr. r17,r3
	ctx.r17.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// beq 0x82b46e78
	if (ctx.cr0.eq) goto loc_82B46E78;
loc_82B46E70:
	// mr r30,r16
	ctx.r30.u64 = ctx.r16.u64;
	// b 0x82b46ed0
	goto loc_82B46ED0;
loc_82B46E78:
	// lis r30,-32761
	ctx.r30.s64 = -2147024896;
	// ori r30,r30,14
	ctx.r30.u64 = ctx.r30.u64 | 14;
	// b 0x82b471ac
	goto loc_82B471AC;
loc_82B46E84:
	// lwz r5,1580(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1580);
	// li r10,17
	ctx.r10.s64 = 17;
	// lwz r4,1572(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	// lwz r3,1564(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	// b 0x82b46e50
	goto loc_82B46E50;
loc_82B46E98:
	// li r10,3
	ctx.r10.s64 = 3;
	// lwz r8,1604(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1604);
	// mr r9,r31
	ctx.r9.u64 = ctx.r31.u64;
	// lwz r4,1572(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1572);
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// lwz r3,1564(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1564);
	// mr r6,r20
	ctx.r6.u64 = ctx.r20.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82b14100
	ctx.lr = 0x82B46EBC;
	sub_82B14100(ctx, base);
	// mr. r17,r3
	ctx.r17.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// bne 0x82b46e70
	if (!ctx.cr0.eq) goto loc_82B46E70;
	// mr r30,r18
	ctx.r30.u64 = ctx.r18.u64;
loc_82B46EC8:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82b46ad0
	if (ctx.cr6.lt) goto loc_82B46AD0;
loc_82B46ED0:
	// lwz r11,48(r17)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r17.u32 + 48);
	// addi r22,r1,160
	ctx.r22.s64 = ctx.r1.s64 + 160;
	// lwz r29,192(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	// li r24,0
	ctx.r24.s64 = 0;
	// rlwinm r27,r11,21,31,31
	ctx.r27.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x1;
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lwz r28,196(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// lwz r25,204(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b47148
	if (ctx.cr6.eq) goto loc_82B47148;
loc_82B46EF8:
	// lwz r11,148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r26,0
	ctx.r26.s64 = 0;
	// mr r31,r22
	ctx.r31.u64 = ctx.r22.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b47074
	if (ctx.cr6.eq) goto loc_82B47074;
loc_82B46F0C:
	// cmplw cr6,r26,r20
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r20.u32, ctx.xer);
	// bge cr6,0x82b47074
	if (!ctx.cr6.lt) goto loc_82B47074;
	// lwz r11,1660(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82b47034
	if (ctx.cr6.eq) goto loc_82B47034;
	// cmpwi cr6,r11,17
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 17, ctx.xer);
	// beq cr6,0x82b46fd4
	if (ctx.cr6.eq) goto loc_82B46FD4;
	// cmpwi cr6,r11,18
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 18, ctx.xer);
	// bne cr6,0x82b4704c
	if (!ctx.cr6.eq) goto loc_82B4704C;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b13f78
	ctx.lr = 0x82B46F40;
	sub_82B13F78(ctx, base);
	// mr. r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// beq 0x82b47260
	if (ctx.cr0.eq) goto loc_82B47260;
loc_82B46F48:
	// addi r10,r31,24
	ctx.r10.s64 = ctx.r31.s64 + 24;
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r9,r1,336
	ctx.r9.s64 = ctx.r1.s64 + 336;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// stw r21,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r21.u32);
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// stw r19,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r19.u32);
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r28.u32);
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r27.u32);
	// bl 0x82b45160
	ctx.lr = 0x82B46F80;
	sub_82B45160(ctx, base);
loc_82B46F80:
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82B46F84:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82b4718c
	if (ctx.cr6.lt) goto loc_82B4718C;
	// lwz r11,144(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b46fa8
	if (ctx.cr6.eq) goto loc_82B46FA8;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// bl 0x82b0f2f0
	ctx.lr = 0x82B46FA0;
	sub_82B0F2F0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
loc_82B46FA8:
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x82b46fbc
	if (ctx.cr6.eq) goto loc_82B46FBC;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B46FB8;
	sub_82B0F2F0(ctx, base);
	// li r16,0
	ctx.r16.s64 = 0;
loc_82B46FBC:
	// lwz r11,148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82b47074
	if (!ctx.cr6.lt) goto loc_82B47074;
	// lwz r31,76(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// b 0x82b46f0c
	goto loc_82B46F0C;
loc_82B46FD4:
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b14040
	ctx.lr = 0x82B46FE0;
	sub_82B14040(ctx, base);
	// stw r3,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r3.u32);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b47260
	if (ctx.cr0.eq) goto loc_82B47260;
loc_82B46FEC:
	// addi r11,r31,24
	ctx.r11.s64 = ctx.r31.s64 + 24;
	// lwz r9,52(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// addi r10,r1,336
	ctx.r10.s64 = ctx.r1.s64 + 336;
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// stw r21,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r21.u32);
	// stw r19,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r19.u32);
	// stw r25,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r25.u32);
	// stw r28,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r28.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r29.u32);
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82b457f0
	ctx.lr = 0x82B47030;
	sub_82B457F0(ctx, base);
	// b 0x82b46f80
	goto loc_82B46F80;
loc_82B47034:
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b13ea8
	ctx.lr = 0x82B47040;
	sub_82B13EA8(ctx, base);
	// mr. r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// bne 0x82b46f48
	if (!ctx.cr0.eq) goto loc_82B46F48;
	// mr r30,r18
	ctx.r30.u64 = ctx.r18.u64;
loc_82B4704C:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82b4718c
	if (ctx.cr6.lt) goto loc_82B4718C;
	// lwz r11,1660(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82b46f48
	if (ctx.cr6.eq) goto loc_82B46F48;
	// cmpwi cr6,r11,17
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 17, ctx.xer);
	// beq cr6,0x82b46fec
	if (ctx.cr6.eq) goto loc_82B46FEC;
	// cmpwi cr6,r11,18
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 18, ctx.xer);
	// beq cr6,0x82b46f48
	if (ctx.cr6.eq) goto loc_82B46F48;
	// b 0x82b46f84
	goto loc_82B46F84;
loc_82B47074:
	// cmpwi cr6,r15,0
	ctx.cr6.compare<int32_t>(ctx.r15.s32, 0, ctx.xer);
	// bne cr6,0x82b47134
	if (!ctx.cr6.eq) goto loc_82B47134;
	// b 0x82b4712c
	goto loc_82B4712C;
loc_82B47080:
	// lwz r11,1660(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82b47220
	if (ctx.cr6.eq) goto loc_82B47220;
	// cmpwi cr6,r11,17
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 17, ctx.xer);
	// beq cr6,0x82b471c0
	if (ctx.cr6.eq) goto loc_82B471C0;
	// cmpwi cr6,r11,18
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 18, ctx.xer);
	// bne cr6,0x82b47238
	if (!ctx.cr6.eq) goto loc_82B47238;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b13f78
	ctx.lr = 0x82B470AC;
	sub_82B13F78(ctx, base);
	// mr. r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// beq 0x82b47260
	if (ctx.cr0.eq) goto loc_82B47260;
loc_82B470B4:
	// addi r10,r31,24
	ctx.r10.s64 = ctx.r31.s64 + 24;
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r9,r1,336
	ctx.r9.s64 = ctx.r1.s64 + 336;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// stw r21,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r21.u32);
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// stw r19,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r19.u32);
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r28.u32);
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r27.u32);
	// bl 0x82b45160
	ctx.lr = 0x82B470EC;
	sub_82B45160(ctx, base);
loc_82B470EC:
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82B470F0:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82b4718c
	if (ctx.cr6.lt) goto loc_82B4718C;
	// lwz r11,144(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b47114
	if (ctx.cr6.eq) goto loc_82B47114;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// bl 0x82b0f2f0
	ctx.lr = 0x82B4710C;
	sub_82B0F2F0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
loc_82B47114:
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x82b47128
	if (ctx.cr6.eq) goto loc_82B47128;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B47124;
	sub_82B0F2F0(ctx, base);
	// li r16,0
	ctx.r16.s64 = 0;
loc_82B47128:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
loc_82B4712C:
	// cmplw cr6,r26,r20
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r20.u32, ctx.xer);
	// blt cr6,0x82b47080
	if (ctx.cr6.lt) goto loc_82B47080;
loc_82B47134:
	// lwz r11,152(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// addi r24,r24,1
	ctx.r24.s64 = ctx.r24.s64 + 1;
	// lwz r22,80(r22)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r22.u32 + 80);
	// cmplw cr6,r24,r11
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b46ef8
	if (ctx.cr6.lt) goto loc_82B46EF8;
loc_82B47148:
	// cmpwi cr6,r15,0
	ctx.cr6.compare<int32_t>(ctx.r15.s32, 0, ctx.xer);
	// beq cr6,0x82b4717c
	if (ctx.cr6.eq) goto loc_82B4717C;
	// lwz r11,148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// cmplw cr6,r11,r20
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r20.u32, ctx.xer);
	// bge cr6,0x82b4717c
	if (!ctx.cr6.lt) goto loc_82B4717C;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// mr r6,r14
	ctx.r6.u64 = ctx.r14.u64;
	// addi r5,r11,-1
	ctx.r5.s64 = ctx.r11.s64 + -1;
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b46610
	ctx.lr = 0x82B47174;
	sub_82B46610(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4718c
	if (ctx.cr0.lt) goto loc_82B4718C;
loc_82B4717C:
	// lwz r11,1668(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1668);
	// li r30,0
	ctx.r30.s64 = 0;
	// stw r17,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r17.u32);
	// li r17,0
	ctx.r17.s64 = 0;
loc_82B4718C:
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82b4719c
	if (ctx.cr6.eq) goto loc_82B4719C;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B4719C;
	sub_82B0F2F0(ctx, base);
loc_82B4719C:
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x82b471ac
	if (ctx.cr6.eq) goto loc_82B471AC;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B471AC;
	sub_82B0F2F0(ctx, base);
loc_82B471AC:
	// cmplwi cr6,r17,0
	ctx.cr6.compare<uint32_t>(ctx.r17.u32, 0, ctx.xer);
	// beq cr6,0x82b46ad0
	if (ctx.cr6.eq) goto loc_82B46AD0;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b0f2f0
	ctx.lr = 0x82B471BC;
	sub_82B0F2F0(ctx, base);
	// b 0x82b46ad0
	goto loc_82B46AD0;
loc_82B471C0:
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b14040
	ctx.lr = 0x82B471CC;
	sub_82B14040(ctx, base);
	// stw r3,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r3.u32);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b47260
	if (ctx.cr0.eq) goto loc_82B47260;
loc_82B471D8:
	// addi r11,r31,24
	ctx.r11.s64 = ctx.r31.s64 + 24;
	// lwz r9,52(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// addi r10,r1,336
	ctx.r10.s64 = ctx.r1.s64 + 336;
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,144(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// stw r21,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r21.u32);
	// stw r19,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r19.u32);
	// stw r25,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r25.u32);
	// stw r28,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r28.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r29.u32);
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82b457f0
	ctx.lr = 0x82B4721C;
	sub_82B457F0(ctx, base);
	// b 0x82b470ec
	goto loc_82B470EC;
loc_82B47220:
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82b13ea8
	ctx.lr = 0x82B4722C;
	sub_82B13EA8(ctx, base);
	// mr. r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// bne 0x82b470b4
	if (!ctx.cr0.eq) goto loc_82B470B4;
	// mr r30,r18
	ctx.r30.u64 = ctx.r18.u64;
loc_82B47238:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt cr6,0x82b4718c
	if (ctx.cr6.lt) goto loc_82B4718C;
	// lwz r11,1660(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1660);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82b470b4
	if (ctx.cr6.eq) goto loc_82B470B4;
	// cmpwi cr6,r11,17
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 17, ctx.xer);
	// beq cr6,0x82b471d8
	if (ctx.cr6.eq) goto loc_82B471D8;
	// cmpwi cr6,r11,18
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 18, ctx.xer);
	// beq cr6,0x82b470b4
	if (ctx.cr6.eq) goto loc_82B470B4;
	// b 0x82b470f0
	goto loc_82B470F0;
loc_82B47260:
	// mr r30,r18
	ctx.r30.u64 = ctx.r18.u64;
	// b 0x82b4718c
	goto loc_82B4718C;
}

__attribute__((alias("__imp__sub_82B47268"))) PPC_WEAK_FUNC(sub_82B47268);
PPC_FUNC_IMPL(__imp__sub_82B47268) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// lwz r10,308(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// li r31,3
	ctx.r31.s64 = 3;
	// lwz r30,284(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// lwz r9,300(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// stw r31,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r31.u32);
	// lwz r31,268(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// stw r30,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r30.u32);
	// lwz r30,276(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// stw r9,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r9.u32);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// lwz r8,292(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// lwz r31,260(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// stw r8,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r8.u32);
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// bl 0x82b46a40
	ctx.lr = 0x82B472D4;
	sub_82B46A40(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B472F0"))) PPC_WEAK_FUNC(sub_82B472F0);
PPC_FUNC_IMPL(__imp__sub_82B472F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r8,-1
	ctx.r8.s64 = -1;
	// stw r6,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r6.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// mr r6,r8
	ctx.r6.u64 = ctx.r8.u64;
	// li r31,1
	ctx.r31.s64 = 1;
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r11.u32);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// stw r7,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// bl 0x82b47268
	ctx.lr = 0x82B4733C;
	sub_82B47268(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B47350"))) PPC_WEAK_FUNC(sub_82B47350);
PPC_FUNC_IMPL(__imp__sub_82B47350) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82b51e10
	ctx.lr = 0x82B47368;
	sub_82B51E10(ctx, base);
	// addi r3,r31,60
	ctx.r3.s64 = ctx.r31.s64 + 60;
	// bl 0x82b73ed8
	ctx.lr = 0x82B47370;
	sub_82B73ED8(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r11.u32);
	// stw r11,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r11.u32);
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// stw r11,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r11.u32);
	// stw r11,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r11.u32);
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// stw r11,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B473A8"))) PPC_WEAK_FUNC(sub_82B473A8);
PPC_FUNC_IMPL(__imp__sub_82B473A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B473B0;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B473CC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b473cc
	if (!ctx.cr6.eq) goto loc_82B473CC;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// rotlwi r28,r11,0
	ctx.r28.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// addi r30,r28,1
	ctx.r30.s64 = ctx.r28.s64 + 1;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82b83e40
	ctx.lr = 0x82B473FC;
	sub_82B83E40(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r3.u32);
	// beq 0x82b47424
	if (ctx.cr0.eq) goto loc_82B47424;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b83e40
	ctx.lr = 0x82B47418;
	sub_82B83E40(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r3.u32);
	// bne 0x82b47430
	if (!ctx.cr0.eq) goto loc_82B47430;
loc_82B47424:
	// lis r26,-32761
	ctx.r26.s64 = -2147024896;
	// ori r26,r26,14
	ctx.r26.u64 = ctx.r26.u64 | 14;
	// b 0x82b4747c
	goto loc_82B4747C;
loc_82B47430:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82e2ab28
	ctx.lr = 0x82B47440;
	sub_82E2AB28(ctx, base);
	// li r4,92
	ctx.r4.s64 = 92;
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// bl 0x82e2f240
	ctx.lr = 0x82B4744C;
	sub_82E2F240(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq 0x82b47458
	if (ctx.cr0.eq) goto loc_82B47458;
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
loc_82B47458:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// stbx r26,r11,r28
	PPC_STORE_U8(ctx.r11.u32 + ctx.r28.u32, ctx.r26.u8);
	// lwz r4,80(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r3,76(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// bl 0x82e28fd0
	ctx.lr = 0x82B47470;
	sub_82E28FD0(ctx, base);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b4747c
	if (ctx.cr6.eq) goto loc_82B4747C;
	// stb r26,0(r29)
	PPC_STORE_U8(ctx.r29.u32 + 0, ctx.r26.u8);
loc_82B4747C:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B47488"))) PPC_WEAK_FUNC(sub_82B47488);
PPC_FUNC_IMPL(__imp__sub_82B47488) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82B47490;
	__savegprlr_22(ctx, base);
	// stwu r1,-704(r1)
	ea = -704 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r25,r6
	ctx.r25.u64 = ctx.r6.u64;
	// mr r23,r7
	ctx.r23.u64 = ctx.r7.u64;
	// mr r22,r8
	ctx.r22.u64 = ctx.r8.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// stw r9,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r9.u32);
	// cmpwi cr6,r5,0
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// beq cr6,0x82b474e4
	if (ctx.cr6.eq) goto loc_82B474E4;
	// lis r3,0
	ctx.r3.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,260
	ctx.r8.s64 = 260;
	// addi r7,r1,352
	ctx.r7.s64 = ctx.r1.s64 + 352;
	// li r6,-1
	ctx.r6.s64 = -1;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// ori r3,r3,65001
	ctx.r3.u64 = ctx.r3.u64 | 65001;
	// bl 0x82b06978
	ctx.lr = 0x82B474E0;
	sub_82B06978(ctx, base);
	// addi r29,r1,352
	ctx.r29.s64 = ctx.r1.s64 + 352;
loc_82B474E4:
	// lwz r11,72(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4761c
	if (ctx.cr6.eq) goto loc_82B4761C;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B474F8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b474f8
	if (!ctx.cr6.eq) goto loc_82B474F8;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// addi r30,r11,1
	ctx.r30.s64 = ctx.r11.s64 + 1;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82b83e40
	ctx.lr = 0x82B47528;
	sub_82B83E40(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r3.u32);
	// bne 0x82b47540
	if (!ctx.cr0.eq) goto loc_82B47540;
loc_82B47534:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b4768c
	goto loc_82B4768C;
loc_82B47540:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B4754C;
	sub_82E28FD0(ctx, base);
	// li r26,0
	ctx.r26.s64 = 0;
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// addi r27,r31,88
	ctx.r27.s64 = ctx.r31.s64 + 88;
	// addi r28,r31,84
	ctx.r28.s64 = ctx.r31.s64 + 84;
	// lwz r5,76(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r6,788(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 788);
	// li r10,260
	ctx.r10.s64 = 260;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// stb r26,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r26.u8);
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B4758C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bge 0x82b475b4
	if (!ctx.cr0.lt) goto loc_82B475B4;
loc_82B47594:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// addi r6,r11,7280
	ctx.r6.s64 = ctx.r11.s64 + 7280;
	// li r5,1507
	ctx.r5.s64 = 1507;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x82b529e0
	ctx.lr = 0x82B475B0;
	sub_82B529E0(ctx, base);
	// b 0x82b47688
	goto loc_82B47688;
loc_82B475B4:
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b47664
	if (ctx.cr0.eq) goto loc_82B47664;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// stb r26,339(r1)
	PPC_STORE_U8(ctx.r1.u32 + 339, ctx.r26.u8);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B475CC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b475cc
	if (!ctx.cr6.eq) goto loc_82B475CC;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// addi r29,r11,1
	ctx.r29.s64 = ctx.r11.s64 + 1;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82b83e40
	ctx.lr = 0x82B475FC;
	sub_82B83E40(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq 0x82b47534
	if (ctx.cr0.eq) goto loc_82B47534;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B47614;
	sub_82E28FD0(ctx, base);
	// stw r30,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r30.u32);
	// b 0x82b47664
	goto loc_82B47664;
loc_82B4761C:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b473a8
	ctx.lr = 0x82B4762C;
	sub_82B473A8(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b47688
	if (ctx.cr0.lt) goto loc_82B47688;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,76(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// addi r3,r31,60
	ctx.r3.s64 = ctx.r31.s64 + 60;
	// bl 0x82b73ef0
	ctx.lr = 0x82B47644;
	sub_82B73EF0(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b47594
	if (ctx.cr0.lt) goto loc_82B47594;
	// lwz r11,64(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// addi r28,r31,84
	ctx.r28.s64 = ctx.r31.s64 + 84;
	// lwz r10,68(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// addi r27,r31,88
	ctx.r27.s64 = ctx.r31.s64 + 88;
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// stw r10,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r10.u32);
loc_82B47664:
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// lwz r6,76(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// lwz r5,0(r27)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b51e38
	ctx.lr = 0x82B47684;
	sub_82B51E38(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82B47688:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82B4768C:
	// addi r1,r1,704
	ctx.r1.s64 = ctx.r1.s64 + 704;
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B47698"))) PPC_WEAK_FUNC(sub_82B47698);
PPC_FUNC_IMPL(__imp__sub_82B47698) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B476A0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82b476d4
	if (ctx.cr6.eq) goto loc_82B476D4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b476d4
	if (!ctx.cr6.eq) goto loc_82B476D4;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82b47714
	goto loc_82B47714;
loc_82B476D4:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// stw r11,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r11.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// stw r6,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r6.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b473a8
	ctx.lr = 0x82B476EC;
	sub_82B473A8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b47714
	if (ctx.cr0.lt) goto loc_82B47714;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// lwz r4,84(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b51e38
	ctx.lr = 0x82B47714;
	sub_82B51E38(ctx, base);
loc_82B47714:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B47720"))) PPC_WEAK_FUNC(sub_82B47720);
PPC_FUNC_IMPL(__imp__sub_82B47720) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82b87d28
	ctx.lr = 0x82B4773C;
	sub_82B87D28(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b47758
	if (ctx.cr0.lt) goto loc_82B47758;
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r11.u32);
	// bl 0x82b83f08
	ctx.lr = 0x82B47754;
	sub_82B83F08(ctx, base);
	// stw r3,688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 688, ctx.r3.u32);
loc_82B47758:
	// stw r30,680(r31)
	PPC_STORE_U32(ctx.r31.u32 + 680, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B47778"))) PPC_WEAK_FUNC(sub_82B47778);
PPC_FUNC_IMPL(__imp__sub_82B47778) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,684(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 684);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b477ac
	if (ctx.cr6.eq) goto loc_82B477AC;
	// lwz r3,688(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 688);
	// bl 0x82b83f08
	ctx.lr = 0x82B477A0;
	sub_82B83F08(ctx, base);
	// bl 0x82b87e70
	ctx.lr = 0x82B477A4;
	sub_82B87E70(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r11.u32);
loc_82B477AC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B477C0"))) PPC_WEAK_FUNC(sub_82B477C0);
PPC_FUNC_IMPL(__imp__sub_82B477C0) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82b477d4
	if (ctx.cr6.eq) goto loc_82B477D4;
	// lwz r11,632(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 632);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
loc_82B477D4:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82b477e8
	if (ctx.cr6.eq) goto loc_82B477E8;
	// lwz r11,632(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 632);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
loc_82B477E8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B477F0"))) PPC_WEAK_FUNC(sub_82B477F0);
PPC_FUNC_IMPL(__imp__sub_82B477F0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,628(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 628);
	// b 0x82b477fc
	goto loc_82B477FC;
loc_82B477F8:
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
loc_82B477FC:
	// lwz r10,92(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82b477f8
	if (!ctx.cr0.eq) goto loc_82B477F8;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82b47818
	if (ctx.cr6.eq) goto loc_82B47818;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
loc_82B47818:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82b4783c
	if (ctx.cr6.eq) goto loc_82B4783C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// bge cr6,0x82b47838
	if (!ctx.cr6.lt) goto loc_82B47838;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82B47838:
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
loc_82B4783C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B47848"))) PPC_WEAK_FUNC(sub_82B47848);
PPC_FUNC_IMPL(__imp__sub_82B47848) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 632);
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// bl 0x82b53080
	ctx.lr = 0x82B47870;
	sub_82B53080(ctx, base);
	// lwz r11,92(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b47994
	if (ctx.cr6.eq) goto loc_82B47994;
	// lwz r5,632(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 632);
	// lwz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// b 0x82b478ac
	goto loc_82B478AC;
loc_82B47888:
	// lbz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,32
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 32, ctx.xer);
	// beq cr6,0x82b478a0
	if (ctx.cr6.eq) goto loc_82B478A0;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b478b4
	if (!ctx.cr6.eq) goto loc_82B478B4;
loc_82B478A0:
	// lwz r11,632(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 632);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
loc_82B478AC:
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b47888
	if (ctx.cr6.lt) goto loc_82B47888;
loc_82B478B4:
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r31,2
	ctx.r10.s64 = ctx.r31.s64 + 2;
	// addi r11,r31,1
	ctx.r11.s64 = ctx.r31.s64 + 1;
loc_82B478C0:
	// lwz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplw cr6,r31,r9
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82b47960
	if (!ctx.cr6.lt) goto loc_82B47960;
	// lbz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r6,r7
	ctx.r6.s64 = ctx.r7.s8;
	// cmpwi cr6,r6,92
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 92, ctx.xer);
	// bne cr6,0x82b47938
	if (!ctx.cr6.eq) goto loc_82B47938;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82b47900
	if (!ctx.cr6.lt) goto loc_82B47900;
	// lbz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r4,10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 10, ctx.xer);
	// bne cr6,0x82b47900
	if (!ctx.cr6.eq) goto loc_82B47900;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82b47958
	goto loc_82B47958;
loc_82B47900:
	// cmpwi cr6,r6,92
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 92, ctx.xer);
	// bne cr6,0x82b47938
	if (!ctx.cr6.eq) goto loc_82B47938;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82b47938
	if (!ctx.cr6.lt) goto loc_82B47938;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r9,13
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 13, ctx.xer);
	// bne cr6,0x82b47938
	if (!ctx.cr6.eq) goto loc_82B47938;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 10, ctx.xer);
	// bne cr6,0x82b47938
	if (!ctx.cr6.eq) goto loc_82B47938;
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82b47958
	goto loc_82B47958;
loc_82B47938:
	// cmpwi cr6,r6,13
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 13, ctx.xer);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// beq cr6,0x82b47958
	if (ctx.cr6.eq) goto loc_82B47958;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// stbx r7,r8,r9
	PPC_STORE_U8(ctx.r8.u32 + ctx.r9.u32, ctx.r7.u8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_82B47958:
	// cmplwi cr6,r8,255
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 255, ctx.xer);
	// blt cr6,0x82b478c0
	if (ctx.cr6.lt) goto loc_82B478C0;
loc_82B47960:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r6,r11,7316
	ctx.r6.s64 = ctx.r11.s64 + 7316;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r30,640
	ctx.r4.s64 = ctx.r30.s64 + 640;
	// addi r3,r30,24
	ctx.r3.s64 = ctx.r30.s64 + 24;
	// stbx r11,r8,r10
	PPC_STORE_U8(ctx.r8.u32 + ctx.r10.u32, ctx.r11.u8);
	// bl 0x82b529e0
	ctx.lr = 0x82B47988;
	sub_82B529E0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,84(r30)
	PPC_STORE_U32(ctx.r30.u32 + 84, ctx.r11.u32);
	// stw r11,80(r30)
	PPC_STORE_U32(ctx.r30.u32 + 80, ctx.r11.u32);
loc_82B47994:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B479B0"))) PPC_WEAK_FUNC(sub_82B479B0);
PPC_FUNC_IMPL(__imp__sub_82B479B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82b47a00
	if (!ctx.cr0.eq) goto loc_82B47A00;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1508
	ctx.r5.s64 = 1508;
	// addi r6,r11,7364
	ctx.r6.s64 = ctx.r11.s64 + 7364;
loc_82B479E0:
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B479EC;
	sub_82B529E0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// b 0x82b47a5c
	goto loc_82B47A5C;
loc_82B47A00:
	// lwz r11,8(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b47a1c
	if (ctx.cr6.eq) goto loc_82B47A1C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1513
	ctx.r5.s64 = 1513;
	// addi r6,r11,7328
	ctx.r6.s64 = ctx.r11.s64 + 7328;
	// b 0x82b479e0
	goto loc_82B479E0;
loc_82B47A1C:
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82b47a40
	if (ctx.cr6.eq) goto loc_82B47A40;
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b47a40
	if (!ctx.cr6.eq) goto loc_82B47A40;
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x82b47a44
	if (!ctx.cr6.eq) goto loc_82B47A44;
loc_82B47A40:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82B47A44:
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// stw r11,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r11.u32);
	// beq cr6,0x82b47a58
	if (ctx.cr6.eq) goto loc_82B47A58;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r11.u32);
loc_82B47A58:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B47A5C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B47A70"))) PPC_WEAK_FUNC(sub_82B47A70);
PPC_FUNC_IMPL(__imp__sub_82B47A70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r11,56(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b47ac0
	if (!ctx.cr0.eq) goto loc_82B47AC0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1509
	ctx.r5.s64 = 1509;
	// addi r6,r11,7420
	ctx.r6.s64 = ctx.r11.s64 + 7420;
loc_82B47AA0:
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B47AAC;
	sub_82B529E0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// b 0x82b47b10
	goto loc_82B47B10;
loc_82B47AC0:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82b47adc
	if (ctx.cr6.eq) goto loc_82B47ADC;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1514
	ctx.r5.s64 = 1514;
	// addi r6,r11,7384
	ctx.r6.s64 = ctx.r11.s64 + 7384;
	// b 0x82b47aa0
	goto loc_82B47AA0;
loc_82B47ADC:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r9,1
	ctx.r9.s64 = 1;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82b47afc
	if (!ctx.cr6.eq) goto loc_82B47AFC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// bne cr6,0x82b47b00
	if (!ctx.cr6.eq) goto loc_82B47B00;
loc_82B47AFC:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82B47B00:
	// stw r10,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
loc_82B47B10:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B47B28"))) PPC_WEAK_FUNC(sub_82B47B28);
PPC_FUNC_IMPL(__imp__sub_82B47B28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82B47B30;
	__savegprlr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r30,r28,640
	ctx.r30.s64 = ctx.r28.s64 + 640;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 672);
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B47B4C;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b47d10
	if (ctx.cr0.lt) goto loc_82B47D10;
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r27,0
	ctx.r27.s64 = 0;
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82b47cec
	if (!ctx.cr6.eq) goto loc_82B47CEC;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r31,r28,648
	ctx.r31.s64 = ctx.r28.s64 + 648;
	// addi r10,r11,-13528
	ctx.r10.s64 = ctx.r11.s64 + -13528;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82B47B74:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47b98
	if (ctx.cr0.eq) goto loc_82B47B98;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47b74
	if (ctx.cr6.eq) goto loc_82B47B74;
loc_82B47B98:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b47cec
	if (!ctx.cr0.eq) goto loc_82B47CEC;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 672);
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B47BB0;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b47d10
	if (ctx.cr0.lt) goto loc_82B47D10;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b47be4
	if (!ctx.cr6.eq) goto loc_82B47BE4;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r29,0(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r4,672(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 672);
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B47BD8;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b47d10
	if (ctx.cr0.lt) goto loc_82B47D10;
	// b 0x82b47be8
	goto loc_82B47BE8;
loc_82B47BE4:
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
loc_82B47BE8:
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82b47cec
	if (!ctx.cr6.eq) goto loc_82B47CEC;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,22356
	ctx.r10.s64 = ctx.r11.s64 + 22356;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82B47C00:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47c24
	if (ctx.cr0.eq) goto loc_82B47C24;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47c00
	if (ctx.cr6.eq) goto loc_82B47C00;
loc_82B47C24:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b47cec
	if (!ctx.cr0.eq) goto loc_82B47CEC;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 672);
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B47C3C;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b47d10
	if (ctx.cr0.lt) goto loc_82B47D10;
	// lwz r7,0(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r7,12
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 12, ctx.xer);
	// beq cr6,0x82b47c58
	if (ctx.cr6.eq) goto loc_82B47C58;
	// cmpwi cr6,r7,13
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 13, ctx.xer);
	// bne cr6,0x82b47cec
	if (!ctx.cr6.eq) goto loc_82B47CEC;
loc_82B47C58:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82b47c68
	if (!ctx.cr6.eq) goto loc_82B47C68;
	// stw r27,60(r28)
	PPC_STORE_U32(ctx.r28.u32 + 60, ctx.r27.u32);
	// b 0x82b47d0c
	goto loc_82B47D0C;
loc_82B47C68:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,7456
	ctx.r10.s64 = ctx.r11.s64 + 7456;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82B47C74:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47c98
	if (ctx.cr0.eq) goto loc_82B47C98;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47c74
	if (ctx.cr6.eq) goto loc_82B47C74;
loc_82B47C98:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b47ca8
	if (!ctx.cr0.eq) goto loc_82B47CA8;
	// li r11,1024
	ctx.r11.s64 = 1024;
	// b 0x82b47ce4
	goto loc_82B47CE4;
loc_82B47CA8:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,7440
	ctx.r10.s64 = ctx.r11.s64 + 7440;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82B47CB4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47cd8
	if (ctx.cr0.eq) goto loc_82B47CD8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47cb4
	if (ctx.cr6.eq) goto loc_82B47CB4;
loc_82B47CD8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b47cec
	if (!ctx.cr0.eq) goto loc_82B47CEC;
	// li r11,2048
	ctx.r11.s64 = 2048;
loc_82B47CE4:
	// stw r11,60(r28)
	PPC_STORE_U32(ctx.r28.u32 + 60, ctx.r11.u32);
	// b 0x82b47d0c
	goto loc_82B47D0C;
loc_82B47CEC:
	// cmpwi cr6,r7,12
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 12, ctx.xer);
	// beq cr6,0x82b47d08
	if (ctx.cr6.eq) goto loc_82B47D08;
	// cmpwi cr6,r7,13
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 13, ctx.xer);
	// beq cr6,0x82b47d08
	if (ctx.cr6.eq) goto loc_82B47D08;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// bl 0x82b53080
	ctx.lr = 0x82B47D08;
	sub_82B53080(ctx, base);
loc_82B47D08:
	// stw r27,668(r28)
	PPC_STORE_U32(ctx.r28.u32 + 668, ctx.r27.u32);
loc_82B47D0C:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
loc_82B47D10:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,76(r28)
	PPC_STORE_U32(ctx.r28.u32 + 76, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B47D20"))) PPC_WEAK_FUNC(sub_82B47D20);
PPC_FUNC_IMPL(__imp__sub_82B47D20) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e30
	ctx.lr = 0x82B47D28;
	__savegprlr_14(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r25,0
	ctx.r25.s64 = 0;
	// addi r24,r26,640
	ctx.r24.s64 = ctx.r26.s64 + 640;
	// mr r14,r25
	ctx.r14.u64 = ctx.r25.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r25.u32);
	// bl 0x82b53c98
	ctx.lr = 0x82B47D50;
	sub_82B53C98(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82b481f4
	if (ctx.cr0.lt) goto loc_82B481F4;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b481cc
	if (!ctx.cr6.eq) goto loc_82B481CC;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r27,r26,648
	ctx.r27.s64 = ctx.r26.s64 + 648;
	// addi r10,r11,-13528
	ctx.r10.s64 = ctx.r11.s64 + -13528;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
loc_82B47D74:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47d98
	if (ctx.cr0.eq) goto loc_82B47D98;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47d74
	if (ctx.cr6.eq) goto loc_82B47D74;
loc_82B47D98:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b481cc
	if (!ctx.cr0.eq) goto loc_82B481CC;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B47DB0;
	sub_82B53C98(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82b481f4
	if (ctx.cr0.lt) goto loc_82B481F4;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// li r15,-1
	ctx.r15.s64 = -1;
	// addi r22,r11,-26244
	ctx.r22.s64 = ctx.r11.s64 + -26244;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r20,r11,5272
	ctx.r20.s64 = ctx.r11.s64 + 5272;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r19,r11,7492
	ctx.r19.s64 = ctx.r11.s64 + 7492;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r18,r11,7484
	ctx.r18.s64 = ctx.r11.s64 + 7484;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r17,r11,7476
	ctx.r17.s64 = ctx.r11.s64 + 7476;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r21,r11,7468
	ctx.r21.s64 = ctx.r11.s64 + 7468;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r23,r11,22356
	ctx.r23.s64 = ctx.r11.s64 + 22356;
	// lis r11,16383
	ctx.r11.s64 = 1073676288;
	// ori r16,r11,65535
	ctx.r16.u64 = ctx.r11.u64 | 65535;
loc_82B47DFC:
	// lwz r7,0(r24)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82b47e3c
	if (!ctx.cr6.eq) goto loc_82B47E3C;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_82B47E10:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47e34
	if (ctx.cr0.eq) goto loc_82B47E34;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47e10
	if (ctx.cr6.eq) goto loc_82B47E10;
loc_82B47E34:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b48220
	if (ctx.cr0.eq) goto loc_82B48220;
loc_82B47E3C:
	// cmpwi cr6,r7,9
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 9, ctx.xer);
	// bne cr6,0x82b47f38
	if (!ctx.cr6.eq) goto loc_82B47F38;
	// lwz r7,0(r27)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r10,r21
	ctx.r10.u64 = ctx.r21.u64;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82B47E50:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47e74
	if (ctx.cr0.eq) goto loc_82B47E74;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47e50
	if (ctx.cr6.eq) goto loc_82B47E50;
loc_82B47E74:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b47e84
	if (!ctx.cr0.eq) goto loc_82B47E84;
	// li r28,16
	ctx.r28.s64 = 16;
	// b 0x82b47f68
	goto loc_82B47F68;
loc_82B47E84:
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// mr r10,r17
	ctx.r10.u64 = ctx.r17.u64;
loc_82B47E8C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47eb0
	if (ctx.cr0.eq) goto loc_82B47EB0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47e8c
	if (ctx.cr6.eq) goto loc_82B47E8C;
loc_82B47EB0:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b47ec0
	if (!ctx.cr0.eq) goto loc_82B47EC0;
	// li r28,15
	ctx.r28.s64 = 15;
	// b 0x82b47f68
	goto loc_82B47F68;
loc_82B47EC0:
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// mr r10,r18
	ctx.r10.u64 = ctx.r18.u64;
loc_82B47EC8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47eec
	if (ctx.cr0.eq) goto loc_82B47EEC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47ec8
	if (ctx.cr6.eq) goto loc_82B47EC8;
loc_82B47EEC:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b47efc
	if (!ctx.cr0.eq) goto loc_82B47EFC;
	// li r28,0
	ctx.r28.s64 = 0;
	// b 0x82b47f68
	goto loc_82B47F68;
loc_82B47EFC:
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// mr r10,r19
	ctx.r10.u64 = ctx.r19.u64;
loc_82B47F04:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47f28
	if (ctx.cr0.eq) goto loc_82B47F28;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47f04
	if (ctx.cr6.eq) goto loc_82B47F04;
loc_82B47F28:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b481cc
	if (!ctx.cr0.eq) goto loc_82B481CC;
	// li r28,255
	ctx.r28.s64 = 255;
	// b 0x82b47f68
	goto loc_82B47F68;
loc_82B47F38:
	// cmpwi cr6,r7,2
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 2, ctx.xer);
	// beq cr6,0x82b47f50
	if (ctx.cr6.eq) goto loc_82B47F50;
	// cmpwi cr6,r7,3
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 3, ctx.xer);
	// beq cr6,0x82b47f50
	if (ctx.cr6.eq) goto loc_82B47F50;
	// cmpwi cr6,r7,4
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 4, ctx.xer);
	// bne cr6,0x82b481cc
	if (!ctx.cr6.eq) goto loc_82B481CC;
loc_82B47F50:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82b481cc
	if (ctx.cr6.lt) goto loc_82B481CC;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// bgt cr6,0x82b481cc
	if (ctx.cr6.gt) goto loc_82B481CC;
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
loc_82B47F68:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B47F78;
	sub_82B53C98(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82b481f4
	if (ctx.cr0.lt) goto loc_82B481F4;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b481cc
	if (!ctx.cr6.eq) goto loc_82B481CC;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r20
	ctx.r10.u64 = ctx.r20.u64;
loc_82B47F94:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b47fb8
	if (ctx.cr0.eq) goto loc_82B47FB8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b47f94
	if (ctx.cr6.eq) goto loc_82B47F94;
loc_82B47FB8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b481cc
	if (!ctx.cr0.eq) goto loc_82B481CC;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B47FD0;
	sub_82B53C98(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82b481f4
	if (ctx.cr0.lt) goto loc_82B481F4;
loc_82B47FD8:
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82b47ff4
	if (ctx.cr6.eq) goto loc_82B47FF4;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82b47ff4
	if (ctx.cr6.eq) goto loc_82B47FF4;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82b481cc
	if (!ctx.cr6.eq) goto loc_82B481CC;
loc_82B47FF4:
	// not r11,r25
	ctx.r11.u64 = ~ctx.r25.u64;
	// lwz r29,0(r27)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// and r11,r11,r25
	ctx.r11.u64 = ctx.r11.u64 & ctx.r25.u64;
	// cmplw cr6,r25,r11
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b480a0
	if (!ctx.cr6.eq) goto loc_82B480A0;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// rlwinm r11,r25,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 1) & 0xFFFFFFFE;
	// bne cr6,0x82b4801c
	if (!ctx.cr6.eq) goto loc_82B4801C;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82B4801C:
	// cmplw cr6,r11,r16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r16.u32, ctx.xer);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// ble cr6,0x82b4802c
	if (!ctx.cr6.gt) goto loc_82B4802C;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
loc_82B4802C:
	// bl 0x82545e80
	ctx.lr = 0x82B48030;
	sub_82545E80(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq 0x82b48298
	if (ctx.cr0.eq) goto loc_82B48298;
	// rlwinm r30,r25,2,0,29
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B4804C;
	sub_82E28FD0(ctx, base);
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82545ee8
	ctx.lr = 0x82B48054;
	sub_82545EE8(ctx, base);
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r31.u32);
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// rlwinm r11,r25,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 1) & 0xFFFFFFFE;
	// bne cr6,0x82b48068
	if (!ctx.cr6.eq) goto loc_82B48068;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82B48068:
	// cmplw cr6,r11,r16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r16.u32, ctx.xer);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// ble cr6,0x82b48078
	if (!ctx.cr6.gt) goto loc_82B48078;
	// mr r3,r15
	ctx.r3.u64 = ctx.r15.u64;
loc_82B48078:
	// bl 0x82545e80
	ctx.lr = 0x82B4807C;
	sub_82545E80(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq 0x82b48298
	if (ctx.cr0.eq) goto loc_82B48298;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r14
	ctx.r4.u64 = ctx.r14.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82e28fd0
	ctx.lr = 0x82B48094;
	sub_82E28FD0(ctx, base);
	// mr r3,r14
	ctx.r3.u64 = ctx.r14.u64;
	// bl 0x82545ee8
	ctx.lr = 0x82B4809C;
	sub_82545EE8(ctx, base);
	// mr r14,r31
	ctx.r14.u64 = ctx.r31.u64;
loc_82B480A0:
	// rlwinm r11,r25,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// stwx r29,r11,r14
	PPC_STORE_U32(ctx.r11.u32 + ctx.r14.u32, ctx.r29.u32);
	// stwx r28,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r28.u32);
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B480C4;
	sub_82B53C98(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82b481f4
	if (ctx.cr0.lt) goto loc_82B481F4;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b47fd8
	if (!ctx.cr6.eq) goto loc_82B47FD8;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
loc_82B480E0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b48104
	if (ctx.cr0.eq) goto loc_82B48104;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b480e0
	if (ctx.cr6.eq) goto loc_82B480E0;
loc_82B48104:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b48140
	if (ctx.cr0.eq) goto loc_82B48140;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_82B48114:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b48138
	if (ctx.cr0.eq) goto loc_82B48138;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b48114
	if (ctx.cr6.eq) goto loc_82B48114;
loc_82B48138:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b47fd8
	if (!ctx.cr0.eq) goto loc_82B47FD8;
loc_82B48140:
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
loc_82B48148:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4816c
	if (ctx.cr0.eq) goto loc_82B4816C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b48148
	if (ctx.cr6.eq) goto loc_82B48148;
loc_82B4816C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b47dfc
	if (!ctx.cr0.eq) goto loc_82B47DFC;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B48184;
	sub_82B53C98(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82b481f4
	if (ctx.cr0.lt) goto loc_82B481F4;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b47dfc
	if (!ctx.cr6.eq) goto loc_82B47DFC;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_82B481A0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b481c4
	if (ctx.cr0.eq) goto loc_82B481C4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b481a0
	if (ctx.cr6.eq) goto loc_82B481A0;
loc_82B481C4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b47dfc
	if (!ctx.cr0.eq) goto loc_82B47DFC;
loc_82B481CC:
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b481ec
	if (ctx.cr6.eq) goto loc_82B481EC;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82b481ec
	if (ctx.cr6.eq) goto loc_82B481EC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82b53080
	ctx.lr = 0x82B481EC;
	sub_82B53080(ctx, base);
loc_82B481EC:
	// li r31,0
	ctx.r31.s64 = 0;
	// stw r31,668(r26)
	PPC_STORE_U32(ctx.r26.u32 + 668, ctx.r31.u32);
loc_82B481F4:
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82545ee8
	ctx.lr = 0x82B481FC;
	sub_82545EE8(ctx, base);
	// mr r3,r14
	ctx.r3.u64 = ctx.r14.u64;
	// bl 0x82545ee8
	ctx.lr = 0x82B48204;
	sub_82545EE8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82545ee8
	ctx.lr = 0x82B4820C;
	sub_82545EE8(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,76(r26)
	PPC_STORE_U32(ctx.r26.u32 + 76, ctx.r11.u32);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82e28e80
	__restgprlr_14(ctx, base);
	return;
loc_82B48220:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// lwz r4,672(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 672);
	// lwz r3,632(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B48230;
	sub_82B53C98(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82b481f4
	if (ctx.cr0.lt) goto loc_82B481F4;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b4824c
	if (ctx.cr6.eq) goto loc_82B4824C;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// bne cr6,0x82b481cc
	if (!ctx.cr6.eq) goto loc_82B481CC;
loc_82B4824C:
	// li r27,0
	ctx.r27.s64 = 0;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82b48290
	if (ctx.cr6.eq) goto loc_82B48290;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r29,r26,24
	ctx.r29.s64 = ctx.r26.s64 + 24;
	// mr r30,r14
	ctx.r30.u64 = ctx.r14.u64;
	// subf r28,r14,r11
	ctx.r28.s64 = ctx.r11.s64 - ctx.r14.s64;
loc_82B48268:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwzx r5,r28,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r30.u32);
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82b52930
	ctx.lr = 0x82B48278;
	sub_82B52930(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// blt 0x82b481f4
	if (ctx.cr0.lt) goto loc_82B481F4;
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r27,r25
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r25.u32, ctx.xer);
	// blt cr6,0x82b48268
	if (ctx.cr6.lt) goto loc_82B48268;
loc_82B48290:
	// li r31,0
	ctx.r31.s64 = 0;
	// b 0x82b481f4
	goto loc_82B481F4;
loc_82B48298:
	// lis r31,-32761
	ctx.r31.s64 = -2147024896;
	// ori r31,r31,14
	ctx.r31.u64 = ctx.r31.u64 | 14;
	// b 0x82b481f4
	goto loc_82B481F4;
}

__attribute__((alias("__imp__sub_82B482A8"))) PPC_WEAK_FUNC(sub_82B482A8);
PPC_FUNC_IMPL(__imp__sub_82B482A8) {
	PPC_FUNC_PROLOGUE();
	// lis r10,1586
	ctx.r10.s64 = 103940096;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// ori r10,r10,55311
	ctx.r10.u64 = ctx.r10.u64 | 55311;
	// beq cr6,0x82b482f0
	if (ctx.cr6.eq) goto loc_82B482F0;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb. r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b482f0
	if (ctx.cr0.eq) goto loc_82B482F0;
loc_82B482C4:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// mulli r10,r10,19
	ctx.r10.s64 = ctx.r10.s64 * 19;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb. r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b482c4
	if (!ctx.cr0.eq) goto loc_82B482C4;
	// li r11,127
	ctx.r11.s64 = 127;
	// divwu r11,r10,r11
	ctx.r11.u32 = ctx.r10.u32 / ctx.r11.u32;
	// mulli r11,r11,127
	ctx.r11.s64 = ctx.r11.s64 * 127;
	// subf r3,r11,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r11.s64;
	// blr 
	return;
loc_82B482F0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B482F8"))) PPC_WEAK_FUNC(sub_82B482F8);
PPC_FUNC_IMPL(__imp__sub_82B482F8) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B48300;
	__savegprlr_29(ctx, base);
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
loc_82B48308:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4832c
	if (ctx.cr0.eq) goto loc_82B4832C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b48308
	if (ctx.cr6.eq) goto loc_82B48308;
loc_82B4832C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b48430
	if (!ctx.cr0.eq) goto loc_82B48430;
	// lwz r30,4(r4)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lwz r29,4(r5)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// mr. r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b48368
	if (ctx.cr0.eq) goto loc_82B48368;
loc_82B48348:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b48360
	if (ctx.cr6.eq) goto loc_82B48360;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b48348
	if (!ctx.cr0.eq) goto loc_82B48348;
loc_82B48360:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b48430
	if (!ctx.cr6.eq) goto loc_82B48430;
loc_82B48368:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82b48430
	if (!ctx.cr6.eq) goto loc_82B48430;
	// lwz r3,8(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r31,8(r5)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// b 0x82b4858c
	goto loc_82B4858C;
loc_82B4837C:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b4841c
	if (ctx.cr6.eq) goto loc_82B4841C;
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82b4841c
	if (!ctx.cr6.eq) goto loc_82B4841C;
	// cmplwi cr6,r11,11
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 11, ctx.xer);
	// bgt cr6,0x82b48578
	if (ctx.cr6.gt) goto loc_82B48578;
	// lis r12,-32239
	ctx.r12.s64 = -2112815104;
	// addi r12,r12,7120
	ctx.r12.s64 = ctx.r12.s64 + 7120;
	// lbzx r0,r12,r11
	ctx.r0.u64 = PPC_LOAD_U8(ctx.r12.u32 + ctx.r11.u32);
	// rlwinm r0,r0,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r0.u32 | (ctx.r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-32075
	ctx.r12.s64 = -2102067200;
	// addi r12,r12,-31804
	ctx.r12.s64 = ctx.r12.s64 + -31804;
	// add r12,r12,r0
	ctx.r12.u64 = ctx.r12.u64 + ctx.r0.u64;
	// mtctr r12
	ctx.ctr.u64 = ctx.r12.u64;
	// nop 
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82B483C4;
	case 1:
		goto loc_82B483DC;
	case 2:
		goto loc_82B483C4;
	case 3:
		goto loc_82B483C4;
	case 4:
		goto loc_82B483C4;
	case 5:
		goto loc_82B48438;
	case 6:
		goto loc_82B48438;
	case 7:
		goto loc_82B48438;
	case 8:
		goto loc_82B48438;
	case 9:
		goto loc_82B48448;
	case 10:
		goto loc_82B48548;
	case 11:
		goto loc_82B48548;
	default:
		__builtin_unreachable();
	}
loc_82B483C4:
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
loc_82B483D0:
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
loc_82B483D4:
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// b 0x82b4857c
	goto loc_82B4857C;
loc_82B483DC:
	// lbz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 24);
	// lbz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 24);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b4841c
	if (!ctx.cr6.eq) goto loc_82B4841C;
	// lbz r11,25(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 25);
	// lbz r10,25(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 25);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b4841c
	if (!ctx.cr6.eq) goto loc_82B4841C;
	// lbz r11,26(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 26);
	// lbz r10,26(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 26);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b4841c
	if (!ctx.cr6.eq) goto loc_82B4841C;
	// lbz r11,27(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 27);
	// lbz r10,27(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 27);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
loc_82B48418:
	// beq cr6,0x82b48584
	if (ctx.cr6.eq) goto loc_82B48584;
loc_82B4841C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82b48430
	if (!ctx.cr6.eq) goto loc_82B48430;
loc_82B48424:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// beq cr6,0x82b48434
	if (ctx.cr6.eq) goto loc_82B48434;
loc_82B48430:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B48434:
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
loc_82B48438:
	// lfd f0,24(r3)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// lfd f13,24(r31)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// b 0x82b48418
	goto loc_82B48418;
loc_82B48448:
	// mr. r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// beq 0x82b484a8
	if (ctx.cr0.eq) goto loc_82B484A8;
	// lwz r5,24(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
loc_82B4845C:
	// lwz r10,24(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
loc_82B48464:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b48488
	if (ctx.cr0.eq) goto loc_82B48488;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b48464
	if (ctx.cr6.eq) goto loc_82B48464;
loc_82B48488:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82b484a4
	if (ctx.cr0.eq) goto loc_82B484A4;
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne 0x82b4845c
	if (!ctx.cr0.eq) goto loc_82B4845C;
	// b 0x82b484a8
	goto loc_82B484A8;
loc_82B484A4:
	// li r4,1
	ctx.r4.s64 = 1;
loc_82B484A8:
	// mr. r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r5,r6,-1
	ctx.r5.s64 = ctx.r6.s64 + -1;
	// beq 0x82b48504
	if (ctx.cr0.eq) goto loc_82B48504;
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
loc_82B484B8:
	// lwz r10,24(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
loc_82B484C0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r7,r7,r9
	ctx.r7.s64 = ctx.r9.s64 - ctx.r7.s64;
	// beq 0x82b484e4
	if (ctx.cr0.eq) goto loc_82B484E4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b484c0
	if (ctx.cr6.eq) goto loc_82B484C0;
loc_82B484E4:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82b48500
	if (ctx.cr0.eq) goto loc_82B48500;
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// cmplwi r8,0
	ctx.cr0.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne 0x82b484b8
	if (!ctx.cr0.eq) goto loc_82B484B8;
	// b 0x82b48504
	goto loc_82B48504;
loc_82B48500:
	// li r4,1
	ctx.r4.s64 = 1;
loc_82B48504:
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82b48514
	if (ctx.cr6.eq) goto loc_82B48514;
	// addi r11,r5,0
	ctx.r11.s64 = ctx.r5.s64 + 0;
	// b 0x82b483d0
	goto loc_82B483D0;
loc_82B48514:
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
loc_82B4851C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b48540
	if (ctx.cr0.eq) goto loc_82B48540;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4851c
	if (ctx.cr6.eq) goto loc_82B4851C;
loc_82B48540:
	// cntlzw r11,r8
	ctx.r11.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// b 0x82b483d4
	goto loc_82B483D4;
loc_82B48548:
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
loc_82B48550:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b48540
	if (ctx.cr0.eq) goto loc_82B48540;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b48550
	if (ctx.cr6.eq) goto loc_82B48550;
	// b 0x82b48540
	goto loc_82B48540;
loc_82B48578:
	// li r11,1
	ctx.r11.s64 = 1;
loc_82B4857C:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b4841c
	if (ctx.cr6.eq) goto loc_82B4841C;
loc_82B48584:
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
loc_82B4858C:
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne 0x82b4837c
	if (!ctx.cr0.eq) goto loc_82B4837C;
	// b 0x82b48424
	goto loc_82B48424;
}

__attribute__((alias("__imp__sub_82B48598"))) PPC_WEAK_FUNC(sub_82B48598);
PPC_FUNC_IMPL(__imp__sub_82B48598) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,632(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 632);
	// b 0x82b51ed0
	sub_82B51ED0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B485A0"))) PPC_WEAK_FUNC(sub_82B485A0);
PPC_FUNC_IMPL(__imp__sub_82B485A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B485A8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r7,r4
	ctx.r7.u64 = ctx.r4.u64;
	// bl 0x82b482a8
	ctx.lr = 0x82B485B8;
	sub_82B482A8(ctx, base);
	// addi r11,r3,30
	ctx.r11.s64 = ctx.r3.s64 + 30;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r11,r29
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// b 0x82b48608
	goto loc_82B48608;
loc_82B485C8:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82B485D0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b485f4
	if (ctx.cr0.eq) goto loc_82B485F4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b485d0
	if (ctx.cr6.eq) goto loc_82B485D0;
loc_82B485F4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// blt 0x82b48610
	if (ctx.cr0.lt) goto loc_82B48610;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b48618
	if (ctx.cr6.eq) goto loc_82B48618;
	// lwz r30,12(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
loc_82B48608:
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne 0x82b485c8
	if (!ctx.cr0.eq) goto loc_82B485C8;
loc_82B48610:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b48680
	goto loc_82B48680;
loc_82B48618:
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b4862c
	if (ctx.cr6.eq) goto loc_82B4862C;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82b48680
	goto loc_82B48680;
loc_82B4862C:
	// li r11,1
	ctx.r11.s64 = 1;
	// lwz r31,8(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// b 0x82b48660
	goto loc_82B48660;
loc_82B4863C:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b4865c
	if (!ctx.cr6.eq) goto loc_82B4865C;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// bl 0x82b485a0
	ctx.lr = 0x82B48654;
	sub_82B485A0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b48668
	if (!ctx.cr0.eq) goto loc_82B48668;
loc_82B4865C:
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
loc_82B48660:
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82b4863c
	if (!ctx.cr0.eq) goto loc_82B4863C;
loc_82B48668:
	// li r11,0
	ctx.r11.s64 = 0;
	// subf r10,r11,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r11.s64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r3,r10,1
	ctx.r3.u64 = ctx.r10.u64 ^ 1;
loc_82B48680:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B48688"))) PPC_WEAK_FUNC(sub_82B48688);
PPC_FUNC_IMPL(__imp__sub_82B48688) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82b485a0
	ctx.lr = 0x82B486A8;
	sub_82B485A0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b48714
	if (!ctx.cr0.eq) goto loc_82B48714;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b482a8
	ctx.lr = 0x82B486BC;
	sub_82B482A8(ctx, base);
	// addi r11,r3,30
	ctx.r11.s64 = ctx.r3.s64 + 30;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r11,r31
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// b 0x82b4870c
	goto loc_82B4870C;
loc_82B486CC:
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
loc_82B486D4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b486f8
	if (ctx.cr0.eq) goto loc_82B486F8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b486d4
	if (ctx.cr6.eq) goto loc_82B486D4;
loc_82B486F8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// blt 0x82b48714
	if (ctx.cr0.lt) goto loc_82B48714;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b48730
	if (ctx.cr6.eq) goto loc_82B48730;
	// lwz r7,12(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
loc_82B4870C:
	// cmplwi r7,0
	ctx.cr0.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne 0x82b486cc
	if (!ctx.cr0.eq) goto loc_82B486CC;
loc_82B48714:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B48718:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82B48730:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82b48740
	if (ctx.cr6.eq) goto loc_82B48740;
	// lwz r11,4(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
loc_82B48740:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82b48750
	if (ctx.cr6.eq) goto loc_82B48750;
	// lwz r11,8(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82B48750:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82b48718
	goto loc_82B48718;
}

__attribute__((alias("__imp__sub_82B48758"))) PPC_WEAK_FUNC(sub_82B48758);
PPC_FUNC_IMPL(__imp__sub_82B48758) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// li r9,92
	ctx.r9.s64 = 92;
loc_82B48770:
	// lbz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r8,34
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 34, ctx.xer);
	// bne cr6,0x82b487a4
	if (!ctx.cr6.eq) goto loc_82B487A4;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82b48790
	if (ctx.cr6.eq) goto loc_82B48790;
	// cmplw cr6,r3,r7
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r7.u32, ctx.xer);
	// bge cr6,0x82b48790
	if (!ctx.cr6.lt) goto loc_82B48790;
	// stbx r9,r3,r6
	PPC_STORE_U8(ctx.r3.u32 + ctx.r6.u32, ctx.r9.u8);
loc_82B48790:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b487a4
	if (!ctx.cr6.eq) goto loc_82B487A4;
	// cntlzw r11,r10
	ctx.r11.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r11,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
loc_82B487A4:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82b487d8
	if (ctx.cr6.eq) goto loc_82B487D8;
	// lbz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r8,92
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 92, ctx.xer);
	// bne cr6,0x82b487d8
	if (!ctx.cr6.eq) goto loc_82B487D8;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82b487d0
	if (ctx.cr6.eq) goto loc_82B487D0;
	// cmplw cr6,r3,r7
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r7.u32, ctx.xer);
	// bge cr6,0x82b487d0
	if (!ctx.cr6.lt) goto loc_82B487D0;
	// stbx r9,r3,r6
	PPC_STORE_U8(ctx.r3.u32 + ctx.r6.u32, ctx.r9.u8);
loc_82B487D0:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82B487D8:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82b487f0
	if (ctx.cr6.eq) goto loc_82B487F0;
	// cmplw cr6,r3,r7
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r7.u32, ctx.xer);
	// bge cr6,0x82b487f0
	if (!ctx.cr6.lt) goto loc_82B487F0;
	// lbz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// stbx r8,r3,r6
	PPC_STORE_U8(ctx.r3.u32 + ctx.r6.u32, ctx.r8.u8);
loc_82B487F0:
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// bne 0x82b48770
	if (!ctx.cr0.eq) goto loc_82B48770;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B48808"))) PPC_WEAK_FUNC(sub_82B48808);
PPC_FUNC_IMPL(__imp__sub_82B48808) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82b4882c
	if (ctx.cr6.eq) goto loc_82B4882C;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// b 0x82b4885c
	goto loc_82B4885C;
loc_82B4882C:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b48858
	if (!ctx.cr6.eq) goto loc_82B48858;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,7500
	ctx.r6.s64 = ctx.r11.s64 + 7500;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B48850;
	sub_82B529E0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
loc_82B48858:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B4885C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B48870"))) PPC_WEAK_FUNC(sub_82B48870);
PPC_FUNC_IMPL(__imp__sub_82B48870) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b488a0
	if (ctx.cr0.eq) goto loc_82B488A0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b48870
	ctx.lr = 0x82B488A0;
	sub_82B48870(ctx, base);
loc_82B488A0:
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b488b4
	if (ctx.cr0.eq) goto loc_82B488B4;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82547938
	ctx.lr = 0x82B488B4;
	sub_82547938(ctx, base);
loc_82B488B4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B488D0"))) PPC_WEAK_FUNC(sub_82B488D0);
PPC_FUNC_IMPL(__imp__sub_82B488D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,56(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b488f8
	if (ctx.cr0.eq) goto loc_82B488F8;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b48870
	ctx.lr = 0x82B488F8;
	sub_82B48870(ctx, base);
loc_82B488F8:
	// lwz r3,92(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4890c
	if (ctx.cr0.eq) goto loc_82B4890C;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b48960
	ctx.lr = 0x82B4890C;
	sub_82B48960(ctx, base);
loc_82B4890C:
	// lwz r11,72(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b48938
	if (ctx.cr6.eq) goto loc_82B48938;
	// lwz r4,84(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmplwi r4,0
	ctx.cr0.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq 0x82b48938
	if (ctx.cr0.eq) goto loc_82B48938;
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B48938;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B48938:
	// addi r3,r31,60
	ctx.r3.s64 = ctx.r31.s64 + 60;
	// bl 0x82b74050
	ctx.lr = 0x82B48940;
	sub_82B74050(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8224ad48
	ctx.lr = 0x82B48948;
	sub_8224AD48(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B48960"))) PPC_WEAK_FUNC(sub_82B48960);
PPC_FUNC_IMPL(__imp__sub_82B48960) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82b488d0
	ctx.lr = 0x82B48980;
	sub_82B488D0(ctx, base);
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b48994
	if (ctx.cr0.eq) goto loc_82B48994;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82547938
	ctx.lr = 0x82B48994;
	sub_82547938(ctx, base);
loc_82B48994:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B489B0"))) PPC_WEAK_FUNC(sub_82B489B0);
PPC_FUNC_IMPL(__imp__sub_82B489B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,40(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b489e0
	if (ctx.cr0.eq) goto loc_82B489E0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b489b0
	ctx.lr = 0x82B489E0;
	sub_82B489B0(ctx, base);
loc_82B489E0:
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b489f4
	if (ctx.cr0.eq) goto loc_82B489F4;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82547938
	ctx.lr = 0x82B489F4;
	sub_82547938(ctx, base);
loc_82B489F4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B48A10"))) PPC_WEAK_FUNC(sub_82B48A10);
PPC_FUNC_IMPL(__imp__sub_82B48A10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b48a40
	if (ctx.cr0.eq) goto loc_82B48A40;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b48a10
	ctx.lr = 0x82B48A40;
	sub_82B48A10(ctx, base);
loc_82B48A40:
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b48a54
	if (ctx.cr0.eq) goto loc_82B48A54;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82547938
	ctx.lr = 0x82B48A54;
	sub_82547938(ctx, base);
loc_82B48A54:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B48A70"))) PPC_WEAK_FUNC(sub_82B48A70);
PPC_FUNC_IMPL(__imp__sub_82B48A70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B48A78;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r5,1
	ctx.r5.s64 = 65536;
	// lis r4,16
	ctx.r4.s64 = 1048576;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82b83da8
	ctx.lr = 0x82B48A8C;
	sub_82B83DA8(ctx, base);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b51d08
	ctx.lr = 0x82B48A94;
	sub_82B51D08(ctx, base);
	// li r30,0
	ctx.r30.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r30,684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 684, ctx.r30.u32);
	// bl 0x82b47720
	ctx.lr = 0x82B48AA4;
	sub_82B47720(ctx, base);
	// li r29,1
	ctx.r29.s64 = 1;
	// stw r30,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r30.u32);
	// li r5,508
	ctx.r5.s64 = 508;
	// stw r30,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r30.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r30,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r30.u32);
	// addi r3,r31,120
	ctx.r3.s64 = ctx.r31.s64 + 120;
	// stw r30,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r30.u32);
	// stw r30,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r30.u32);
	// stw r29,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r29.u32);
	// stw r29,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r29.u32);
	// stw r29,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r29.u32);
	// stw r29,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r29.u32);
	// stw r30,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r30.u32);
	// stw r30,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r30.u32);
	// stw r30,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r30.u32);
	// stw r30,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r30.u32);
	// stw r30,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r30.u32);
	// stw r30,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r30.u32);
	// stw r30,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r30.u32);
	// stw r30,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r30.u32);
	// bl 0x82e29500
	ctx.lr = 0x82B48AFC;
	sub_82E29500(ctx, base);
	// std r30,640(r31)
	PPC_STORE_U64(ctx.r31.u32 + 640, ctx.r30.u64);
	// li r4,0
	ctx.r4.s64 = 0;
	// std r30,648(r31)
	PPC_STORE_U64(ctx.r31.u32 + 648, ctx.r30.u64);
	// li r3,4
	ctx.r3.s64 = 4;
	// std r30,656(r31)
	PPC_STORE_U64(ctx.r31.u32 + 656, ctx.r30.u64);
	// std r30,664(r31)
	PPC_STORE_U64(ctx.r31.u32 + 664, ctx.r30.u64);
	// stw r29,672(r31)
	PPC_STORE_U32(ctx.r31.u32 + 672, ctx.r29.u32);
	// bl 0x82e2f330
	ctx.lr = 0x82B48B1C;
	sub_82E2F330(ctx, base);
	// bl 0x82e2f298
	ctx.lr = 0x82B48B20;
	sub_82E2F298(ctx, base);
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,676(r31)
	PPC_STORE_U32(ctx.r31.u32 + 676, ctx.r3.u32);
	// addi r4,r11,-27336
	ctx.r4.s64 = ctx.r11.s64 + -27336;
	// beq 0x82b48b64
	if (ctx.cr0.eq) goto loc_82B48B64;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
loc_82B48B38:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// subf r9,r9,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r9.s64;
	// beq 0x82b48b5c
	if (ctx.cr0.eq) goto loc_82B48B5C;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82b48b38
	if (ctx.cr6.eq) goto loc_82B48B38;
loc_82B48B5C:
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82b48b6c
	if (ctx.cr0.eq) goto loc_82B48B6C;
loc_82B48B64:
	// li r3,4
	ctx.r3.s64 = 4;
	// bl 0x82e2f330
	ctx.lr = 0x82B48B6C;
	sub_82E2F330(ctx, base);
loc_82B48B6C:
	// stw r30,692(r31)
	PPC_STORE_U32(ctx.r31.u32 + 692, ctx.r30.u32);
	// bl 0x82b73df8
	ctx.lr = 0x82B48B74;
	sub_82B73DF8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B48B80"))) PPC_WEAK_FUNC(sub_82B48B80);
PPC_FUNC_IMPL(__imp__sub_82B48B80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B48B88;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r3,64(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 64);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b48ba4
	if (ctx.cr0.eq) goto loc_82B48BA4;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b489b0
	ctx.lr = 0x82B48BA4;
	sub_82B489B0(ctx, base);
loc_82B48BA4:
	// lwz r3,116(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 116);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b48bb8
	if (ctx.cr0.eq) goto loc_82B48BB8;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b48a10
	ctx.lr = 0x82B48BB8;
	sub_82B48A10(ctx, base);
loc_82B48BB8:
	// lwz r31,628(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 628);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82b48bd8
	if (ctx.cr0.eq) goto loc_82B48BD8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b488d0
	ctx.lr = 0x82B48BCC;
	sub_82B488D0(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82547938
	ctx.lr = 0x82B48BD8;
	sub_82547938(ctx, base);
loc_82B48BD8:
	// lwz r3,68(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 68);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b48bec
	if (ctx.cr0.eq) goto loc_82B48BEC;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b48a10
	ctx.lr = 0x82B48BEC;
	sub_82B48A10(ctx, base);
loc_82B48BEC:
	// addi r31,r30,120
	ctx.r31.s64 = ctx.r30.s64 + 120;
	// li r29,127
	ctx.r29.s64 = 127;
loc_82B48BF4:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b48c08
	if (ctx.cr0.eq) goto loc_82B48C08;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b48870
	ctx.lr = 0x82B48C08;
	sub_82B48870(ctx, base);
loc_82B48C08:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x82b48bf4
	if (!ctx.cr0.eq) goto loc_82B48BF4;
	// lwz r11,684(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 684);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b48c28
	if (ctx.cr6.eq) goto loc_82B48C28;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b47778
	ctx.lr = 0x82B48C28;
	sub_82B47778(ctx, base);
loc_82B48C28:
	// addi r3,r30,24
	ctx.r3.s64 = ctx.r30.s64 + 24;
	// bl 0x82b52588
	ctx.lr = 0x82B48C30;
	sub_82B52588(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b83df0
	ctx.lr = 0x82B48C38;
	sub_82B83DF0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B48C40"))) PPC_WEAK_FUNC(sub_82B48C40);
PPC_FUNC_IMPL(__imp__sub_82B48C40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x82547910
	ctx.lr = 0x82B48C68;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b48c8c
	if (ctx.cr0.eq) goto loc_82B48C8C;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// b 0x82b48c90
	goto loc_82B48C90;
loc_82B48C8C:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82B48C90:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b48ca4
	if (!ctx.cr6.eq) goto loc_82B48CA4;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b48cb8
	goto loc_82B48CB8;
loc_82B48CA4:
	// lwz r10,116(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// stw r11,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r11.u32);
	// stw r30,672(r31)
	PPC_STORE_U32(ctx.r31.u32 + 672, ctx.r30.u32);
loc_82B48CB8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B48CD0"))) PPC_WEAK_FUNC(sub_82B48CD0);
PPC_FUNC_IMPL(__imp__sub_82B48CD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B48CD8;
	__savegprlr_28(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r11,76(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 76);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b49490
	if (!ctx.cr6.eq) goto loc_82B49490;
	// lwz r11,84(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b49490
	if (!ctx.cr6.eq) goto loc_82B49490;
	// lwz r10,112(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 112);
	// li r30,0
	ctx.r30.s64 = 0;
	// addi r31,r28,640
	ctx.r31.s64 = ctx.r28.s64 + 640;
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82b48d40
	if (ctx.cr0.eq) goto loc_82B48D40;
	// addi r11,r10,16
	ctx.r11.s64 = ctx.r10.s64 + 16;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// std r9,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// std r9,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r11,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r11.u64);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r11,112(r28)
	PPC_STORE_U32(ctx.r28.u32 + 112, ctx.r11.u32);
	// stw r30,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r30.u32);
	// b 0x82b48d5c
	goto loc_82B48D5C;
loc_82B48D40:
	// lwz r11,672(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 672);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lwz r3,632(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 632);
	// ori r4,r11,4
	ctx.r4.u64 = ctx.r11.u64 | 4;
	// bl 0x82b53c98
	ctx.lr = 0x82B48D54;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49498
	if (ctx.cr0.lt) goto loc_82B49498;
loc_82B48D5C:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82b493ec
	if (ctx.cr6.eq) goto loc_82B493EC;
	// ble cr6,0x82b49488
	if (!ctx.cr6.gt) goto loc_82B49488;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// ble cr6,0x82b493e4
	if (!ctx.cr6.gt) goto loc_82B493E4;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// beq cr6,0x82b48da8
	if (ctx.cr6.eq) goto loc_82B48DA8;
	// cmpwi cr6,r11,10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 10, ctx.xer);
	// beq cr6,0x82b48da0
	if (ctx.cr6.eq) goto loc_82B48DA0;
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b48d94
	if (ctx.cr6.eq) goto loc_82B48D94;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// bne cr6,0x82b49488
	if (!ctx.cr6.eq) goto loc_82B49488;
loc_82B48D94:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,76(r28)
	PPC_STORE_U32(ctx.r28.u32 + 76, ctx.r11.u32);
	// b 0x82b49498
	goto loc_82B49498;
loc_82B48DA0:
	// li r3,280
	ctx.r3.s64 = 280;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B48DA8:
	// lwz r11,88(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 88);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b492a0
	if (ctx.cr6.eq) goto loc_82B492A0;
	// lwz r11,92(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 92);
	// li r29,1
	ctx.r29.s64 = 1;
	// stw r30,88(r28)
	PPC_STORE_U32(ctx.r28.u32 + 88, ctx.r30.u32);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lwz r11,648(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 648);
	// stw r30,100(r28)
	PPC_STORE_U32(ctx.r28.u32 + 100, ctx.r30.u32);
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// beq cr6,0x82b490f4
	if (ctx.cr6.eq) goto loc_82B490F4;
	// cmpwi cr6,r10,100
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 100, ctx.xer);
	// beq cr6,0x82b490b8
	if (ctx.cr6.eq) goto loc_82B490B8;
	// cmpwi cr6,r10,101
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 101, ctx.xer);
	// beq cr6,0x82b48fb8
	if (ctx.cr6.eq) goto loc_82B48FB8;
	// cmpwi cr6,r10,105
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 105, ctx.xer);
	// beq cr6,0x82b48ebc
	if (ctx.cr6.eq) goto loc_82B48EBC;
	// cmpwi cr6,r10,108
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 108, ctx.xer);
	// beq cr6,0x82b48e80
	if (ctx.cr6.eq) goto loc_82B48E80;
	// cmpwi cr6,r10,112
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 112, ctx.xer);
	// beq cr6,0x82b48e44
	if (ctx.cr6.eq) goto loc_82B48E44;
	// cmpwi cr6,r10,117
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 117, ctx.xer);
	// bne cr6,0x82b491b0
	if (!ctx.cr6.eq) goto loc_82B491B0;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,7672
	ctx.r10.s64 = ctx.r10.s64 + 7672;
loc_82B48E10:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b48e34
	if (ctx.cr0.eq) goto loc_82B48E34;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b48e10
	if (ctx.cr6.eq) goto loc_82B48E10;
loc_82B48E34:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b491b0
	if (!ctx.cr0.eq) goto loc_82B491B0;
	// li r3,258
	ctx.r3.s64 = 258;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B48E44:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,7664
	ctx.r10.s64 = ctx.r10.s64 + 7664;
loc_82B48E4C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b48e70
	if (ctx.cr0.eq) goto loc_82B48E70;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b48e4c
	if (ctx.cr6.eq) goto loc_82B48E4C;
loc_82B48E70:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b491b0
	if (!ctx.cr0.eq) goto loc_82B491B0;
	// li r3,270
	ctx.r3.s64 = 270;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B48E80:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,7656
	ctx.r10.s64 = ctx.r10.s64 + 7656;
loc_82B48E88:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b48eac
	if (ctx.cr0.eq) goto loc_82B48EAC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b48e88
	if (ctx.cr6.eq) goto loc_82B48E88;
loc_82B48EAC:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b491b0
	if (!ctx.cr0.eq) goto loc_82B491B0;
	// li r3,259
	ctx.r3.s64 = 259;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B48EBC:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,7652
	ctx.r9.s64 = ctx.r10.s64 + 7652;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B48EC8:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b48eec
	if (ctx.cr0.eq) goto loc_82B48EEC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b48ec8
	if (ctx.cr6.eq) goto loc_82B48EC8;
loc_82B48EEC:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82b48efc
	if (!ctx.cr0.eq) goto loc_82B48EFC;
	// li r3,262
	ctx.r3.s64 = 262;
	// b 0x82b48ff4
	goto loc_82B48FF4;
loc_82B48EFC:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,7644
	ctx.r9.s64 = ctx.r10.s64 + 7644;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B48F08:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b48f2c
	if (ctx.cr0.eq) goto loc_82B48F2C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b48f08
	if (ctx.cr6.eq) goto loc_82B48F08;
loc_82B48F2C:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82b48f3c
	if (!ctx.cr0.eq) goto loc_82B48F3C;
	// li r3,263
	ctx.r3.s64 = 263;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B48F3C:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,7636
	ctx.r9.s64 = ctx.r10.s64 + 7636;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B48F48:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b48f6c
	if (ctx.cr0.eq) goto loc_82B48F6C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b48f48
	if (ctx.cr6.eq) goto loc_82B48F48;
loc_82B48F6C:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82b48f7c
	if (!ctx.cr0.eq) goto loc_82B48F7C;
	// li r3,264
	ctx.r3.s64 = 264;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B48F7C:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,7628
	ctx.r10.s64 = ctx.r10.s64 + 7628;
loc_82B48F84:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b48fa8
	if (ctx.cr0.eq) goto loc_82B48FA8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b48f84
	if (ctx.cr6.eq) goto loc_82B48F84;
loc_82B48FA8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b491b0
	if (!ctx.cr0.eq) goto loc_82B491B0;
	// li r3,260
	ctx.r3.s64 = 260;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B48FB8:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,7620
	ctx.r9.s64 = ctx.r10.s64 + 7620;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B48FC4:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b48fe8
	if (ctx.cr0.eq) goto loc_82B48FE8;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b48fc4
	if (ctx.cr6.eq) goto loc_82B48FC4;
loc_82B48FE8:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82b48ffc
	if (!ctx.cr0.eq) goto loc_82B48FFC;
loc_82B48FF0:
	// li r3,265
	ctx.r3.s64 = 265;
loc_82B48FF4:
	// stw r29,100(r28)
	PPC_STORE_U32(ctx.r28.u32 + 100, ctx.r29.u32);
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B48FFC:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,7612
	ctx.r9.s64 = ctx.r10.s64 + 7612;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B49008:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b4902c
	if (ctx.cr0.eq) goto loc_82B4902C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b49008
	if (ctx.cr6.eq) goto loc_82B49008;
loc_82B4902C:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82b4903c
	if (!ctx.cr0.eq) goto loc_82B4903C;
loc_82B49034:
	// li r3,266
	ctx.r3.s64 = 266;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B4903C:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,7604
	ctx.r9.s64 = ctx.r10.s64 + 7604;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B49048:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b4906c
	if (ctx.cr0.eq) goto loc_82B4906C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b49048
	if (ctx.cr6.eq) goto loc_82B49048;
loc_82B4906C:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82b4907c
	if (!ctx.cr0.eq) goto loc_82B4907C;
loc_82B49074:
	// li r3,267
	ctx.r3.s64 = 267;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B4907C:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,7476
	ctx.r10.s64 = ctx.r10.s64 + 7476;
loc_82B49084:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b490a8
	if (ctx.cr0.eq) goto loc_82B490A8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b49084
	if (ctx.cr6.eq) goto loc_82B49084;
loc_82B490A8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b491b0
	if (!ctx.cr0.eq) goto loc_82B491B0;
	// li r3,261
	ctx.r3.s64 = 261;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B490B8:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,7596
	ctx.r10.s64 = ctx.r10.s64 + 7596;
loc_82B490C0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b490e4
	if (ctx.cr0.eq) goto loc_82B490E4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b490c0
	if (ctx.cr6.eq) goto loc_82B490C0;
loc_82B490E4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b491b0
	if (!ctx.cr0.eq) goto loc_82B491B0;
	// li r3,257
	ctx.r3.s64 = 257;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B490F4:
	// cmpwi cr6,r10,101
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 101, ctx.xer);
	// beq cr6,0x82b491bc
	if (ctx.cr6.eq) goto loc_82B491BC;
	// cmpwi cr6,r10,105
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 105, ctx.xer);
	// bne cr6,0x82b491b0
	if (!ctx.cr6.eq) goto loc_82B491B0;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,7652
	ctx.r9.s64 = ctx.r10.s64 + 7652;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B49110:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b49134
	if (ctx.cr0.eq) goto loc_82B49134;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b49110
	if (ctx.cr6.eq) goto loc_82B49110;
loc_82B49134:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// bne 0x82b49144
	if (!ctx.cr0.eq) goto loc_82B49144;
loc_82B4913C:
	// li r3,268
	ctx.r3.s64 = 268;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B49144:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,7644
	ctx.r9.s64 = ctx.r10.s64 + 7644;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B49150:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b49174
	if (ctx.cr0.eq) goto loc_82B49174;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b49150
	if (ctx.cr6.eq) goto loc_82B49150;
loc_82B49174:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82b4913c
	if (ctx.cr0.eq) goto loc_82B4913C;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,7636
	ctx.r10.s64 = ctx.r10.s64 + 7636;
loc_82B49184:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b491a8
	if (ctx.cr0.eq) goto loc_82B491A8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b49184
	if (ctx.cr6.eq) goto loc_82B49184;
loc_82B491A8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b4913c
	if (ctx.cr0.eq) goto loc_82B4913C;
loc_82B491B0:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,88(r28)
	PPC_STORE_U32(ctx.r28.u32 + 88, ctx.r11.u32);
	// b 0x82b493dc
	goto loc_82B493DC;
loc_82B491BC:
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,7612
	ctx.r9.s64 = ctx.r10.s64 + 7612;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B491C8:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b491ec
	if (ctx.cr0.eq) goto loc_82B491EC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b491c8
	if (ctx.cr6.eq) goto loc_82B491C8;
loc_82B491EC:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82b49034
	if (ctx.cr0.eq) goto loc_82B49034;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r10,7604
	ctx.r9.s64 = ctx.r10.s64 + 7604;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B49200:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b49224
	if (ctx.cr0.eq) goto loc_82B49224;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b49200
	if (ctx.cr6.eq) goto loc_82B49200;
loc_82B49224:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82b49074
	if (ctx.cr0.eq) goto loc_82B49074;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,7620
	ctx.r10.s64 = ctx.r10.s64 + 7620;
loc_82B49234:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b49258
	if (ctx.cr0.eq) goto loc_82B49258;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b49234
	if (ctx.cr6.eq) goto loc_82B49234;
loc_82B49258:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b491b0
	if (!ctx.cr0.eq) goto loc_82B491B0;
	// lwz r11,628(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 628);
	// lwz r11,56(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b49278
	if (!ctx.cr0.eq) goto loc_82B49278;
	// stw r29,92(r28)
	PPC_STORE_U32(ctx.r28.u32 + 92, ctx.r29.u32);
	// b 0x82b48ff0
	goto loc_82B48FF0;
loc_82B49278:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b49298
	if (ctx.cr0.eq) goto loc_82B49298;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b49298
	if (!ctx.cr6.eq) goto loc_82B49298;
	// stw r10,92(r28)
	PPC_STORE_U32(ctx.r28.u32 + 92, ctx.r10.u32);
	// b 0x82b48ff0
	goto loc_82B48FF0;
loc_82B49298:
	// li r3,269
	ctx.r3.s64 = 269;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B492A0:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r4,648(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 648);
	// addi r10,r11,7588
	ctx.r10.s64 = ctx.r11.s64 + 7588;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
loc_82B492B0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b492d4
	if (ctx.cr0.eq) goto loc_82B492D4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b492b0
	if (ctx.cr6.eq) goto loc_82B492B0;
loc_82B492D4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b492e8
	if (!ctx.cr0.eq) goto loc_82B492E8;
	// li r3,271
	ctx.r3.s64 = 271;
	// stw r30,100(r28)
	PPC_STORE_U32(ctx.r28.u32 + 100, ctx.r30.u32);
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B492E8:
	// lwz r11,100(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 100);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b493dc
	if (ctx.cr6.eq) goto loc_82B493DC;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b48688
	ctx.lr = 0x82B49304;
	sub_82B48688(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b493dc
	if (ctx.cr0.eq) goto loc_82B493DC;
	// lwz r10,80(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 80);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// ld r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// li r29,1
	ctx.r29.s64 = 1;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ld r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// ld r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ld r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// std r9,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r9.u64);
	// std r8,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r8.u64);
	// std r7,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r7.u64);
	// bne cr6,0x82b49360
	if (!ctx.cr6.eq) goto loc_82B49360;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x82b4be98
	ctx.lr = 0x82B49354;
	sub_82B4BE98(ctx, base);
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// beq cr6,0x82b49364
	if (ctx.cr6.eq) goto loc_82B49364;
loc_82B49360:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82B49364:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,80(r28)
	PPC_STORE_U32(ctx.r28.u32 + 80, ctx.r11.u32);
	// bne cr6,0x82b49388
	if (!ctx.cr6.eq) goto loc_82B49388;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b48cd0
	ctx.lr = 0x82B49378;
	sub_82B48CD0(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82b4938c
	if (ctx.cr6.eq) goto loc_82B4938C;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// b 0x82b49390
	goto loc_82B49390;
loc_82B49388:
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82B4938C:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
loc_82B49390:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,80(r28)
	PPC_STORE_U32(ctx.r28.u32 + 80, ctx.r11.u32);
	// beq cr6,0x82b4949c
	if (ctx.cr6.eq) goto loc_82B4949C;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// stw r29,84(r28)
	PPC_STORE_U32(ctx.r28.u32 + 84, ctx.r29.u32);
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// li r5,1518
	ctx.r5.s64 = 1518;
	// addi r6,r10,7536
	ctx.r6.s64 = ctx.r10.s64 + 7536;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// addi r3,r28,24
	ctx.r3.s64 = ctx.r28.s64 + 24;
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// ld r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r10,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r10.u64);
	// std r9,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r9.u64);
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// std r11,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r11.u64);
	// bl 0x82b529e0
	ctx.lr = 0x82B493DC;
	sub_82B529E0(ctx, base);
loc_82B493DC:
	// li r3,278
	ctx.r3.s64 = 278;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B493E4:
	// li r3,279
	ctx.r3.s64 = 279;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B493EC:
	// lbz r11,649(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 649);
	// extsb. r10,r11
	ctx.r10.s64 = ctx.r11.s8;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne 0x82b49404
	if (!ctx.cr0.eq) goto loc_82B49404;
	// lbz r11,648(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 648);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B49404:
	// lbz r11,650(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 650);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b49488
	if (!ctx.cr6.eq) goto loc_82B49488;
	// lbz r11,648(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 648);
	// cmpwi cr6,r10,61
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 61, ctx.xer);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// bne cr6,0x82b49460
	if (!ctx.cr6.eq) goto loc_82B49460;
	// cmpwi cr6,r11,33
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 33, ctx.xer);
	// beq cr6,0x82b49458
	if (ctx.cr6.eq) goto loc_82B49458;
	// cmpwi cr6,r11,60
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 60, ctx.xer);
	// beq cr6,0x82b49450
	if (ctx.cr6.eq) goto loc_82B49450;
	// cmpwi cr6,r11,61
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 61, ctx.xer);
	// beq cr6,0x82b49448
	if (ctx.cr6.eq) goto loc_82B49448;
	// cmpwi cr6,r11,62
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 62, ctx.xer);
	// bne cr6,0x82b49488
	if (!ctx.cr6.eq) goto loc_82B49488;
	// li r3,273
	ctx.r3.s64 = 273;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B49448:
	// li r3,274
	ctx.r3.s64 = 274;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B49450:
	// li r3,272
	ctx.r3.s64 = 272;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B49458:
	// li r3,275
	ctx.r3.s64 = 275;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B49460:
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82b49488
	if (!ctx.cr6.eq) goto loc_82B49488;
	// cmpwi cr6,r11,38
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 38, ctx.xer);
	// beq cr6,0x82b49480
	if (ctx.cr6.eq) goto loc_82B49480;
	// cmpwi cr6,r11,124
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 124, ctx.xer);
	// bne cr6,0x82b49488
	if (!ctx.cr6.eq) goto loc_82B49488;
	// li r3,277
	ctx.r3.s64 = 277;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B49480:
	// li r3,276
	ctx.r3.s64 = 276;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B49488:
	// li r3,281
	ctx.r3.s64 = 281;
	// b 0x82b4949c
	goto loc_82B4949C;
loc_82B49490:
	// li r11,12
	ctx.r11.s64 = 12;
	// stw r11,640(r28)
	PPC_STORE_U32(ctx.r28.u32 + 640, ctx.r11.u32);
loc_82B49498:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82B4949C:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B494A8"))) PPC_WEAK_FUNC(sub_82B494A8);
PPC_FUNC_IMPL(__imp__sub_82B494A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// bl 0x82b482a8
	ctx.lr = 0x82B494C0;
	sub_82B482A8(ctx, base);
	// addi r11,r3,30
	ctx.r11.s64 = ctx.r3.s64 + 30;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// b 0x82b49514
	goto loc_82B49514;
loc_82B494D0:
	// lwz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
loc_82B494DC:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// subf r7,r7,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r7.s64;
	// beq 0x82b49500
	if (ctx.cr0.eq) goto loc_82B49500;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b494dc
	if (ctx.cr6.eq) goto loc_82B494DC;
loc_82B49500:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// blt 0x82b49540
	if (ctx.cr0.lt) goto loc_82B49540;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b49524
	if (ctx.cr6.eq) goto loc_82B49524;
	// addi r9,r6,12
	ctx.r9.s64 = ctx.r6.s64 + 12;
loc_82B49514:
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b494d0
	if (!ctx.cr6.eq) goto loc_82B494D0;
	// b 0x82b49540
	goto loc_82B49540;
loc_82B49524:
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// li r11,0
	ctx.r11.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// bl 0x82b48870
	ctx.lr = 0x82B49540;
	sub_82B48870(ctx, base);
loc_82B49540:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B49558"))) PPC_WEAK_FUNC(sub_82B49558);
PPC_FUNC_IMPL(__imp__sub_82B49558) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,16
	ctx.r3.s64 = 16;
	// bl 0x82547910
	ctx.lr = 0x82B49580;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b495a8
	if (ctx.cr0.eq) goto loc_82B495A8;
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// b 0x82b495ac
	goto loc_82B495AC;
loc_82B495A8:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82B495AC:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b495c0
	if (!ctx.cr6.eq) goto loc_82B495C0;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b495f8
	goto loc_82B495F8;
loc_82B495C0:
	// lwz r10,628(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r10,56(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	// stw r10,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
	// lwz r10,628(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// stw r11,56(r10)
	PPC_STORE_U32(ctx.r10.u32 + 56, ctx.r11.u32);
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b495ec
	if (ctx.cr6.eq) goto loc_82B495EC;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x82b495f0
	if (!ctx.cr6.eq) goto loc_82B495F0;
loc_82B495EC:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82B495F0:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r11.u32);
loc_82B495F8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B49610"))) PPC_WEAK_FUNC(sub_82B49610);
PPC_FUNC_IMPL(__imp__sub_82B49610) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r3,56(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne 0x82b49660
	if (!ctx.cr0.eq) goto loc_82B49660;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1510
	ctx.r5.s64 = 1510;
	// addi r6,r11,7680
	ctx.r6.s64 = ctx.r11.s64 + 7680;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B4964C;
	sub_82B529E0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// b 0x82b49684
	goto loc_82B49684;
loc_82B49660:
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r10,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r10.u32);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stw r10,56(r11)
	PPC_STORE_U32(ctx.r11.u32 + 56, ctx.r10.u32);
	// stw r9,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r9.u32);
	// bl 0x82b48870
	ctx.lr = 0x82B49680;
	sub_82B48870(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B49684:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B49698"))) PPC_WEAK_FUNC(sub_82B49698);
PPC_FUNC_IMPL(__imp__sub_82B49698) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r30,r31,640
	ctx.r30.s64 = ctx.r31.s64 + 640;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B496C4;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49774
	if (ctx.cr0.lt) goto loc_82B49774;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82b496e0
	if (ctx.cr6.eq) goto loc_82B496E0;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82b49754
	if (!ctx.cr6.eq) goto loc_82B49754;
loc_82B496E0:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82547910
	ctx.lr = 0x82B496EC;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4970c
	if (ctx.cr0.eq) goto loc_82B4970C;
	// lwz r10,68(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r9,648(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// b 0x82b49710
	goto loc_82B49710;
loc_82B4970C:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82B49710:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r11.u32);
	// bne cr6,0x82b49728
	if (!ctx.cr6.eq) goto loc_82B49728;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b49774
	goto loc_82B49774;
loc_82B49728:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B49738;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49774
	if (ctx.cr0.lt) goto loc_82B49774;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b49770
	if (ctx.cr6.eq) goto loc_82B49770;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82b49770
	if (ctx.cr6.eq) goto loc_82B49770;
loc_82B49754:
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b49770
	if (ctx.cr6.eq) goto loc_82B49770;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82b49770
	if (ctx.cr6.eq) goto loc_82B49770;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53080
	ctx.lr = 0x82B49770;
	sub_82B53080(ctx, base);
loc_82B49770:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B49774:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B49798"))) PPC_WEAK_FUNC(sub_82B49798);
PPC_FUNC_IMPL(__imp__sub_82B49798) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e50
	ctx.lr = 0x82B497A0;
	__savegprlr_22(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r27,r29,640
	ctx.r27.s64 = ctx.r29.s64 + 640;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B497BC;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49b64
	if (ctx.cr0.lt) goto loc_82B49B64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b49b40
	if (!ctx.cr6.eq) goto loc_82B49B40;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r31,r29,648
	ctx.r31.s64 = ctx.r29.s64 + 648;
	// addi r10,r11,-13528
	ctx.r10.s64 = ctx.r11.s64 + -13528;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82B497E0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b49804
	if (ctx.cr0.eq) goto loc_82B49804;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b497e0
	if (ctx.cr6.eq) goto loc_82B497E0;
loc_82B49804:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b49b40
	if (!ctx.cr0.eq) goto loc_82B49B40;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B4981C;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49b64
	if (ctx.cr0.lt) goto loc_82B49B64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b49b40
	if (!ctx.cr6.eq) goto loc_82B49B40;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r22,0(r31)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B49844;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49b64
	if (ctx.cr0.lt) goto loc_82B49B64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b49b40
	if (!ctx.cr6.eq) goto loc_82B49B40;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// addi r24,r11,16868
	ctx.r24.s64 = ctx.r11.s64 + 16868;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
loc_82B49868:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4988c
	if (ctx.cr0.eq) goto loc_82B4988C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b49868
	if (ctx.cr6.eq) goto loc_82B49868;
loc_82B4988C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b49b40
	if (!ctx.cr0.eq) goto loc_82B49B40;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B498A4;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49b64
	if (ctx.cr0.lt) goto loc_82B49B64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b49b40
	if (!ctx.cr6.eq) goto loc_82B49B40;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// lwz r23,0(r31)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r26,0
	ctx.r26.s64 = 0;
	// addi r28,r1,96
	ctx.r28.s64 = ctx.r1.s64 + 96;
	// addi r25,r11,-26248
	ctx.r25.s64 = ctx.r11.s64 + -26248;
loc_82B498CC:
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// li r30,0
	ctx.r30.s64 = 0;
	// bl 0x82b53c98
	ctx.lr = 0x82B498E0;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49b64
	if (ctx.cr0.lt) goto loc_82B49B64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b49b40
	if (!ctx.cr6.eq) goto loc_82B49B40;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
loc_82B498FC:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b49920
	if (ctx.cr0.eq) goto loc_82B49920;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b498fc
	if (ctx.cr6.eq) goto loc_82B498FC;
loc_82B49920:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b49b40
	if (!ctx.cr0.eq) goto loc_82B49B40;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B49938;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49b64
	if (ctx.cr0.lt) goto loc_82B49B64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b4999c
	if (!ctx.cr6.eq) goto loc_82B4999C;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
loc_82B49954:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b49978
	if (ctx.cr0.eq) goto loc_82B49978;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b49954
	if (ctx.cr6.eq) goto loc_82B49954;
loc_82B49978:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4999c
	if (!ctx.cr0.eq) goto loc_82B4999C;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// li r30,1
	ctx.r30.s64 = 1;
	// bl 0x82b53c98
	ctx.lr = 0x82B49994;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49b64
	if (ctx.cr0.lt) goto loc_82B49B64;
loc_82B4999C:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82b499dc
	if (ctx.cr6.eq) goto loc_82B499DC;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82b499cc
	if (ctx.cr6.eq) goto loc_82B499CC;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// beq cr6,0x82b499dc
	if (ctx.cr6.eq) goto loc_82B499DC;
	// addi r11,r11,-5
	ctx.r11.s64 = ctx.r11.s64 + -5;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bgt cr6,0x82b49b40
	if (ctx.cr6.gt) goto loc_82B49B40;
	// lfd f0,0(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// b 0x82b499ec
	goto loc_82B499EC;
loc_82B499CC:
	// lwa r11,0(r31)
	ctx.r11.s64 = int32_t(PPC_LOAD_U32(ctx.r31.u32 + 0));
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// b 0x82b499e8
	goto loc_82B499E8;
loc_82B499DC:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
loc_82B499E8:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(ctx.f0.s64);
loc_82B499EC:
	// stfd f0,0(r28)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r28.u32 + 0, ctx.f0.u64);
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq cr6,0x82b49a00
	if (ctx.cr6.eq) goto loc_82B49A00;
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfd f0,0(r28)
	PPC_STORE_U64(ctx.r28.u32 + 0, ctx.f0.u64);
loc_82B49A00:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// addi r28,r28,8
	ctx.r28.s64 = ctx.r28.s64 + 8;
	// cmplwi cr6,r26,4
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 4, ctx.xer);
	// blt cr6,0x82b498cc
	if (ctx.cr6.lt) goto loc_82B498CC;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B49A20;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49b64
	if (ctx.cr0.lt) goto loc_82B49B64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b49b40
	if (!ctx.cr6.eq) goto loc_82B49B40;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,22356
	ctx.r10.s64 = ctx.r11.s64 + 22356;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_82B49A40:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b49a64
	if (ctx.cr0.eq) goto loc_82B49A64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b49a40
	if (ctx.cr6.eq) goto loc_82B49A40;
loc_82B49A64:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b49b40
	if (!ctx.cr0.eq) goto loc_82B49B40;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r4,672(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 672);
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B49A7C;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b49b64
	if (ctx.cr0.lt) goto loc_82B49B64;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b49a98
	if (ctx.cr6.eq) goto loc_82B49A98;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// bne cr6,0x82b49b40
	if (!ctx.cr6.eq) goto loc_82B49B40;
loc_82B49A98:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82547910
	ctx.lr = 0x82B49AA4;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b49abc
	if (ctx.cr0.eq) goto loc_82B49ABC;
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r11.u32);
	// b 0x82b49ac0
	goto loc_82B49AC0;
loc_82B49ABC:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82B49AC0:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82b49ad4
	if (!ctx.cr6.eq) goto loc_82B49AD4;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b49b64
	goto loc_82B49B64;
loc_82B49AD4:
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// stw r22,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r22.u32);
	// addi r30,r29,64
	ctx.r30.s64 = ctx.r29.s64 + 64;
	// stw r23,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r23.u32);
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// ld r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// std r8,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r8.u64);
	// std r11,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r11.u64);
	// b 0x82b49b24
	goto loc_82B49B24;
loc_82B49B08:
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82e2e820
	ctx.lr = 0x82B49B14;
	sub_82E2E820(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b49b30
	if (!ctx.cr0.lt) goto loc_82B49B30;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r30,r11,40
	ctx.r30.s64 = ctx.r11.s64 + 40;
loc_82B49B24:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b49b08
	if (!ctx.cr0.eq) goto loc_82B49B08;
loc_82B49B30:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r11,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r11.u32);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
	// b 0x82b49b60
	goto loc_82B49B60;
loc_82B49B40:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b49b60
	if (ctx.cr6.eq) goto loc_82B49B60;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82b49b60
	if (ctx.cr6.eq) goto loc_82B49B60;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 632);
	// bl 0x82b53080
	ctx.lr = 0x82B49B60;
	sub_82B53080(ctx, base);
loc_82B49B60:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B49B64:
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,76(r29)
	PPC_STORE_U32(ctx.r29.u32 + 76, ctx.r11.u32);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x82e28ea0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B49B78"))) PPC_WEAK_FUNC(sub_82B49B78);
PPC_FUNC_IMPL(__imp__sub_82B49B78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B49B80;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r29,0(r28)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82b482a8
	ctx.lr = 0x82B49B98;
	sub_82B482A8(ctx, base);
	// addi r11,r3,30
	ctx.r11.s64 = ctx.r3.s64 + 30;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r11,r30
	ctx.r31.u64 = ctx.r11.u64 + ctx.r30.u64;
	// b 0x82b49bec
	goto loc_82B49BEC;
loc_82B49BA8:
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
loc_82B49BB4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b49bd8
	if (ctx.cr0.eq) goto loc_82B49BD8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b49bb4
	if (ctx.cr6.eq) goto loc_82B49BB4;
loc_82B49BD8:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// blt 0x82b49c4c
	if (ctx.cr0.lt) goto loc_82B49C4C;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b49bfc
	if (ctx.cr6.eq) goto loc_82B49BFC;
	// addi r31,r7,12
	ctx.r31.s64 = ctx.r7.s64 + 12;
loc_82B49BEC:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b49ba8
	if (!ctx.cr6.eq) goto loc_82B49BA8;
	// b 0x82b49c4c
	goto loc_82B49C4C;
loc_82B49BFC:
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b482f8
	ctx.lr = 0x82B49C0C;
	sub_82B482F8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82b49c30
	if (!ctx.cr0.eq) goto loc_82B49C30;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// addi r6,r11,7700
	ctx.r6.s64 = ctx.r11.s64 + 7700;
	// li r5,1519
	ctx.r5.s64 = 1519;
	// addi r4,r30,640
	ctx.r4.s64 = ctx.r30.s64 + 640;
	// addi r3,r30,24
	ctx.r3.s64 = ctx.r30.s64 + 24;
	// bl 0x82b52c18
	ctx.lr = 0x82B49C30;
	sub_82B52C18(ctx, base);
loc_82B49C30:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r11,0
	ctx.r11.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// bl 0x82b48870
	ctx.lr = 0x82B49C4C;
	sub_82B48870(ctx, base);
loc_82B49C4C:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,12(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12, ctx.r11.u32);
	// stw r28,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r28.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B49C68"))) PPC_WEAK_FUNC(sub_82B49C68);
PPC_FUNC_IMPL(__imp__sub_82B49C68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82547910
	ctx.lr = 0x82B49C90;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b49cb8
	if (ctx.cr0.eq) goto loc_82B49CB8;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r31.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// b 0x82b49cbc
	goto loc_82B49CBC;
loc_82B49CB8:
	// li r4,0
	ctx.r4.s64 = 0;
loc_82B49CBC:
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82b49cd0
	if (!ctx.cr6.eq) goto loc_82B49CD0;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b49cd8
	goto loc_82B49CD8;
loc_82B49CD0:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b49b78
	ctx.lr = 0x82B49CD8;
	sub_82B49B78(ctx, base);
loc_82B49CD8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B49CF0"))) PPC_WEAK_FUNC(sub_82B49CF0);
PPC_FUNC_IMPL(__imp__sub_82B49CF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B49CF8;
	__savegprlr_28(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82547910
	ctx.lr = 0x82B49D14;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// li r31,0
	ctx.r31.s64 = 0;
	// beq 0x82b49d3c
	if (ctx.cr0.eq) goto loc_82B49D3C;
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// b 0x82b49d40
	goto loc_82B49D40;
loc_82B49D3C:
	// mr r30,r31
	ctx.r30.u64 = ctx.r31.u64;
loc_82B49D40:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82b49d54
	if (!ctx.cr6.eq) goto loc_82B49D54;
loc_82B49D48:
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b49da8
	goto loc_82B49DA8;
loc_82B49D54:
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r29,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r29.u32);
	// li r3,48
	ctx.r3.s64 = 48;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x82b83f88
	ctx.lr = 0x82B49D68;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b49d7c
	if (ctx.cr0.eq) goto loc_82B49D7C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82b845a8
	ctx.lr = 0x82B49D78;
	sub_82B845A8(ctx, base);
	// b 0x82b49d80
	goto loc_82B49D80;
loc_82B49D7C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82B49D80:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// bne cr6,0x82b49d9c
	if (!ctx.cr6.eq) goto loc_82B49D9C;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b48870
	ctx.lr = 0x82B49D98;
	sub_82B48870(ctx, base);
	// b 0x82b49d48
	goto loc_82B49D48;
loc_82B49D9C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b49b78
	ctx.lr = 0x82B49DA8;
	sub_82B49B78(ctx, base);
loc_82B49DA8:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B49DB0"))) PPC_WEAK_FUNC(sub_82B49DB0);
PPC_FUNC_IMPL(__imp__sub_82B49DB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,7796
	ctx.r11.s64 = ctx.r11.s64 + 7796;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82B49DD0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b49df4
	if (ctx.cr0.eq) goto loc_82B49DF4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b49dd0
	if (ctx.cr6.eq) goto loc_82B49DD0;
loc_82B49DF4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b49e04
	if (!ctx.cr0.eq) goto loc_82B49E04;
	// lwz r3,660(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 660);
	// b 0x82b49e94
	goto loc_82B49E94;
loc_82B49E04:
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b48688
	ctx.lr = 0x82B49E14;
	sub_82B48688(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b49e90
	if (ctx.cr0.eq) goto loc_82B49E90;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b49e48
	if (ctx.cr6.eq) goto loc_82B49E48;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1517
	ctx.r5.s64 = 1517;
	// addi r6,r11,7728
	ctx.r6.s64 = ctx.r11.s64 + 7728;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B49E40;
	sub_82B529E0(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82b49e94
	goto loc_82B49E94;
loc_82B49E48:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b49e78
	if (ctx.cr6.eq) goto loc_82B49E78;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82b49e78
	if (!ctx.cr6.eq) goto loc_82B49E78;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// bgt cr6,0x82b49e78
	if (ctx.cr6.gt) goto loc_82B49E78;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// b 0x82b49e94
	goto loc_82B49E94;
loc_82B49E78:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1518
	ctx.r5.s64 = 1518;
	// addi r6,r11,7536
	ctx.r6.s64 = ctx.r11.s64 + 7536;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B49E90;
	sub_82B529E0(ctx, base);
loc_82B49E90:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B49E94:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B49EA8"))) PPC_WEAK_FUNC(sub_82B49EA8);
PPC_FUNC_IMPL(__imp__sub_82B49EA8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// stw r11,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r11.u32);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82b49f7c
	if (ctx.cr6.eq) goto loc_82B49F7C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,7844
	ctx.r10.s64 = ctx.r11.s64 + 7844;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
loc_82B49EE0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b49f04
	if (ctx.cr0.eq) goto loc_82B49F04;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b49ee0
	if (ctx.cr6.eq) goto loc_82B49EE0;
loc_82B49F04:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b49f50
	if (!ctx.cr0.eq) goto loc_82B49F50;
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b49f3c
	if (ctx.cr6.eq) goto loc_82B49F3C;
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b49f3c
	if (!ctx.cr6.eq) goto loc_82B49F3C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r7,648(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	// li r5,1504
	ctx.r5.s64 = 1504;
	// addi r6,r11,7808
	ctx.r6.s64 = ctx.r11.s64 + 7808;
	// b 0x82b49f74
	goto loc_82B49F74;
loc_82B49F3C:
	// addi r5,r31,640
	ctx.r5.s64 = ctx.r31.s64 + 640;
	// li r4,1500
	ctx.r4.s64 = 1500;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b52ee8
	ctx.lr = 0x82B49F4C;
	sub_82B52EE8(ctx, base);
	// b 0x82b49f7c
	goto loc_82B49F7C;
loc_82B49F50:
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,256
	ctx.r4.s64 = 256;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82b43f08
	ctx.lr = 0x82B49F60;
	sub_82B43F08(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r11,-4536
	ctx.r6.s64 = ctx.r11.s64 + -4536;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
loc_82B49F74:
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B49F7C;
	sub_82B529E0(ctx, base);
loc_82B49F7C:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B49F90"))) PPC_WEAK_FUNC(sub_82B49F90);
PPC_FUNC_IMPL(__imp__sub_82B49F90) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82B49F98;
	__savegprlr_23(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82547910
	ctx.lr = 0x82B49FB4;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// li r24,0
	ctx.r24.s64 = 0;
	// beq 0x82b49fdc
	if (ctx.cr0.eq) goto loc_82B49FDC;
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// stw r24,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r24.u32);
	// stw r24,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r24.u32);
	// stw r24,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r24.u32);
	// stw r24,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r24.u32);
	// b 0x82b49fe0
	goto loc_82B49FE0;
loc_82B49FDC:
	// mr r23,r24
	ctx.r23.u64 = ctx.r24.u64;
loc_82B49FE0:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82b4a2b8
	if (ctx.cr6.eq) goto loc_82B4A2B8;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82b4a1cc
	if (ctx.cr6.eq) goto loc_82B4A1CC;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82b4a1cc
	if (!ctx.cr6.lt) goto loc_82B4A1CC;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,40
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 40, ctx.xer);
	// bne cr6,0x82b4a1cc
	if (!ctx.cr6.eq) goto loc_82B4A1CC;
	// addi r28,r31,640
	ctx.r28.s64 = ctx.r31.s64 + 640;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// addi r27,r23,4
	ctx.r27.s64 = ctx.r23.s64 + 4;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// bl 0x82b53c98
	ctx.lr = 0x82B4A02C;
	sub_82B53C98(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a2e8
	if (ctx.cr0.lt) goto loc_82B4A2E8;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// addi r26,r11,16868
	ctx.r26.s64 = ctx.r11.s64 + 16868;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r25,r11,7860
	ctx.r25.s64 = ctx.r11.s64 + 7860;
loc_82B4A044:
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B4A054;
	sub_82B53C98(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a2e8
	if (ctx.cr0.lt) goto loc_82B4A2E8;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b4a190
	if (!ctx.cr6.eq) goto loc_82B4A190;
	// lwz r6,0(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplwi r6,0
	ctx.cr0.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq 0x82b4a0d0
	if (ctx.cr0.eq) goto loc_82B4A0D0;
	// lwz r7,648(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
loc_82B4A078:
	// lwz r10,24(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 24);
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82B4A080:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4a0a4
	if (ctx.cr0.eq) goto loc_82B4A0A4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4a080
	if (ctx.cr6.eq) goto loc_82B4A080;
loc_82B4A0A4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b4a0bc
	if (ctx.cr0.eq) goto loc_82B4A0BC;
	// lwz r6,12(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 12);
	// cmplwi r6,0
	ctx.cr0.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne 0x82b4a078
	if (!ctx.cr0.eq) goto loc_82B4A078;
	// b 0x82b4a0d0
	goto loc_82B4A0D0;
loc_82B4A0BC:
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// li r5,1511
	ctx.r5.s64 = 1511;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B4A0D0;
	sub_82B529E0(ctx, base);
loc_82B4A0D0:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4A0D8;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a0ec
	if (ctx.cr0.eq) goto loc_82B4A0EC;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82b845a8
	ctx.lr = 0x82B4A0E8;
	sub_82B845A8(ctx, base);
	// b 0x82b4a0f0
	goto loc_82B4A0F0;
loc_82B4A0EC:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
loc_82B4A0F0:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82b4a2b8
	if (ctx.cr6.eq) goto loc_82B4A2B8;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// addi r29,r3,12
	ctx.r29.s64 = ctx.r3.s64 + 12;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B4A110;
	sub_82B53C98(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a2e8
	if (ctx.cr0.lt) goto loc_82B4A2E8;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b4a190
	if (!ctx.cr6.eq) goto loc_82B4A190;
	// addi r10,r31,648
	ctx.r10.s64 = ctx.r31.s64 + 648;
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
loc_82B4A12C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4a150
	if (ctx.cr0.eq) goto loc_82B4A150;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4a12c
	if (ctx.cr6.eq) goto loc_82B4A12C;
loc_82B4A150:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b4a044
	if (ctx.cr0.eq) goto loc_82B4A044;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r31,648
	ctx.r10.s64 = ctx.r31.s64 + 648;
	// addi r11,r11,22356
	ctx.r11.s64 = ctx.r11.s64 + 22356;
loc_82B4A164:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4a188
	if (ctx.cr0.eq) goto loc_82B4A188;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4a164
	if (ctx.cr6.eq) goto loc_82B4A164;
loc_82B4A188:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b4a1cc
	if (ctx.cr0.eq) goto loc_82B4A1CC;
loc_82B4A190:
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r29,1
	ctx.r29.s64 = 1;
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b4a1a8
	if (ctx.cr6.eq) goto loc_82B4A1A8;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// bne cr6,0x82b4a1ac
	if (!ctx.cr6.eq) goto loc_82B4A1AC;
loc_82B4A1A8:
	// stw r29,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r29.u32);
loc_82B4A1AC:
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,1500
	ctx.r4.s64 = 1500;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b52ee8
	ctx.lr = 0x82B4A1BC;
	sub_82B52EE8(ctx, base);
	// lis r30,-32768
	ctx.r30.s64 = -2147483648;
	// stw r29,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r29.u32);
	// ori r30,r30,16389
	ctx.r30.u64 = ctx.r30.u64 | 16389;
	// b 0x82b4a2e8
	goto loc_82B4A2E8;
loc_82B4A1CC:
	// addi r28,r23,8
	ctx.r28.s64 = ctx.r23.s64 + 8;
loc_82B4A1D0:
	// lwz r10,112(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// addi r29,r31,640
	ctx.r29.s64 = ctx.r31.s64 + 640;
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82b4a228
	if (ctx.cr0.eq) goto loc_82B4A228;
	// addi r11,r10,16
	ctx.r11.s64 = ctx.r10.s64 + 16;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// std r9,0(r29)
	PPC_STORE_U64(ctx.r29.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// std r9,8(r29)
	PPC_STORE_U64(ctx.r29.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// std r9,16(r29)
	PPC_STORE_U64(ctx.r29.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r11,24(r29)
	PPC_STORE_U64(ctx.r29.u32 + 24, ctx.r11.u64);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r11,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r11.u32);
	// stw r24,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r24.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// stw r10,656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 656, ctx.r10.u32);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 660, ctx.r11.u32);
	// b 0x82b4a240
	goto loc_82B4A240;
loc_82B4A228:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B4A238;
	sub_82B53C98(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a2e8
	if (ctx.cr0.lt) goto loc_82B4A2E8;
loc_82B4A240:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b4a2c4
	if (ctx.cr6.eq) goto loc_82B4A2C4;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82b4a2c4
	if (ctx.cr6.eq) goto loc_82B4A2C4;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4A25C;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a274
	if (ctx.cr0.eq) goto loc_82B4A274;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x82b845a8
	ctx.lr = 0x82B4A26C;
	sub_82B845A8(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// b 0x82b4a278
	goto loc_82B4A278;
loc_82B4A274:
	// mr r30,r24
	ctx.r30.u64 = ctx.r24.u64;
loc_82B4A278:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82b4a2b8
	if (ctx.cr6.eq) goto loc_82B4A2B8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,668(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 668);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b83e40
	ctx.lr = 0x82B4A290;
	sub_82B83E40(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq 0x82b4a2b8
	if (ctx.cr0.eq) goto loc_82B4A2B8;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r5,668(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 668);
	// lwz r4,664(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 664);
	// bl 0x82e28fd0
	ctx.lr = 0x82B4A2A8;
	sub_82E28FD0(ctx, base);
	// stw r29,40(r30)
	PPC_STORE_U32(ctx.r30.u32 + 40, ctx.r29.u32);
	// stw r30,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r30.u32);
	// addi r28,r30,12
	ctx.r28.s64 = ctx.r30.s64 + 12;
	// b 0x82b4a1d0
	goto loc_82B4A1D0;
loc_82B4A2B8:
	// lis r30,-32761
	ctx.r30.s64 = -2147024896;
	// ori r30,r30,14
	ctx.r30.u64 = ctx.r30.u64 | 14;
	// b 0x82b4a2e8
	goto loc_82B4A2E8;
loc_82B4A2C4:
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r11.u32);
	// bl 0x82b49b78
	ctx.lr = 0x82B4A2D8;
	sub_82B49B78(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a2e8
	if (ctx.cr0.lt) goto loc_82B4A2E8;
	// mr r23,r24
	ctx.r23.u64 = ctx.r24.u64;
	// mr r30,r24
	ctx.r30.u64 = ctx.r24.u64;
loc_82B4A2E8:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82b4a2fc
	if (ctx.cr6.eq) goto loc_82B4A2FC;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82b48870
	ctx.lr = 0x82B4A2FC;
	sub_82B48870(ctx, base);
loc_82B4A2FC:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4A308"))) PPC_WEAK_FUNC(sub_82B4A308);
PPC_FUNC_IMPL(__imp__sub_82B4A308) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B4A310;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r30,r31,640
	ctx.r30.s64 = ctx.r31.s64 + 640;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B4A32C;
	sub_82B53C98(ctx, base);
	// li r29,1
	ctx.r29.s64 = 1;
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4a4a0
	if (ctx.cr0.lt) goto loc_82B4A4A0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b4a47c
	if (!ctx.cr6.eq) goto loc_82B4A47C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r7,648(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	// stw r29,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r29.u32);
	// addi r10,r11,7948
	ctx.r10.s64 = ctx.r11.s64 + 7948;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82B4A358:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4a37c
	if (ctx.cr0.eq) goto loc_82B4A37C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4a358
	if (ctx.cr6.eq) goto loc_82B4A358;
loc_82B4A37C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4a390
	if (!ctx.cr0.eq) goto loc_82B4A390;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b47b28
	ctx.lr = 0x82B4A38C;
	sub_82B47B28(ctx, base);
	// b 0x82b4a4a4
	goto loc_82B4A4A4;
loc_82B4A390:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,7940
	ctx.r10.s64 = ctx.r11.s64 + 7940;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82B4A39C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4a3c0
	if (ctx.cr0.eq) goto loc_82B4A3C0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4a39c
	if (ctx.cr6.eq) goto loc_82B4A39C;
loc_82B4A3C0:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4a3d4
	if (!ctx.cr0.eq) goto loc_82B4A3D4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b47d20
	ctx.lr = 0x82B4A3D0;
	sub_82B47D20(ctx, base);
	// b 0x82b4a4a4
	goto loc_82B4A4A4;
loc_82B4A3D4:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,7936
	ctx.r10.s64 = ctx.r11.s64 + 7936;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82B4A3E0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4a404
	if (ctx.cr0.eq) goto loc_82B4A404;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4a3e0
	if (ctx.cr6.eq) goto loc_82B4A3E0;
loc_82B4A404:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4a418
	if (!ctx.cr0.eq) goto loc_82B4A418;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b49798
	ctx.lr = 0x82B4A414;
	sub_82B49798(ctx, base);
	// b 0x82b4a4a4
	goto loc_82B4A4A4;
loc_82B4A418:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r10,r11,7924
	ctx.r10.s64 = ctx.r11.s64 + 7924;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82B4A424:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4a448
	if (ctx.cr0.eq) goto loc_82B4A448;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4a424
	if (ctx.cr6.eq) goto loc_82B4A424;
loc_82B4A448:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4a45c
	if (!ctx.cr0.eq) goto loc_82B4A45C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b49698
	ctx.lr = 0x82B4A458;
	sub_82B49698(ctx, base);
	// b 0x82b4a4a4
	goto loc_82B4A4A4;
loc_82B4A45C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,3568
	ctx.r5.s64 = 3568;
	// addi r6,r11,7892
	ctx.r6.s64 = ctx.r11.s64 + 7892;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b52c18
	ctx.lr = 0x82B4A474;
	sub_82B52C18(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,668(r31)
	PPC_STORE_U32(ctx.r31.u32 + 668, ctx.r11.u32);
loc_82B4A47C:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b4a49c
	if (ctx.cr6.eq) goto loc_82B4A49C;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82b4a49c
	if (ctx.cr6.eq) goto loc_82B4A49C;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53080
	ctx.lr = 0x82B4A49C;
	sub_82B53080(ctx, base);
loc_82B4A49C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B4A4A0:
	// stw r29,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r29.u32);
loc_82B4A4A4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4A4B0"))) PPC_WEAK_FUNC(sub_82B4A4B0);
PPC_FUNC_IMPL(__imp__sub_82B4A4B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r3,3032(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 3032);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82b49ea8
	ctx.lr = 0x82B4A4EC;
	sub_82B49EA8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4A500"))) PPC_WEAK_FUNC(sub_82B4A500);
PPC_FUNC_IMPL(__imp__sub_82B4A500) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82B4A508;
	__savegprlr_25(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// li r31,0
	ctx.r31.s64 = 0;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// std r31,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r31.u64);
	// std r31,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r31.u64);
	// std r31,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r31.u64);
	// std r31,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r31.u64);
	// lwz r25,632(r27)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r27.u32 + 632);
	// bl 0x82547910
	ctx.lr = 0x82B4A53C;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a568
	if (ctx.cr0.eq) goto loc_82B4A568;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,8064
	ctx.r11.s64 = ctx.r11.s64 + 8064;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82b4a56c
	goto loc_82B4A56C;
loc_82B4A568:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82B4A56C:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b4a82c
	if (ctx.cr6.eq) goto loc_82B4A82C;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82b49b78
	ctx.lr = 0x82B4A580;
	sub_82B49B78(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a938
	if (ctx.cr0.lt) goto loc_82B4A938;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82547910
	ctx.lr = 0x82B4A594;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a5c0
	if (ctx.cr0.eq) goto loc_82B4A5C0;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,8056
	ctx.r11.s64 = ctx.r11.s64 + 8056;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82b4a5c4
	goto loc_82B4A5C4;
loc_82B4A5C0:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82B4A5C4:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b4a82c
	if (ctx.cr6.eq) goto loc_82B4A82C;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82b49b78
	ctx.lr = 0x82B4A5D8;
	sub_82B49B78(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a938
	if (ctx.cr0.lt) goto loc_82B4A938;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82547910
	ctx.lr = 0x82B4A5EC;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a618
	if (ctx.cr0.eq) goto loc_82B4A618;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,8040
	ctx.r11.s64 = ctx.r11.s64 + 8040;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82b4a61c
	goto loc_82B4A61C;
loc_82B4A618:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82B4A61C:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b4a82c
	if (ctx.cr6.eq) goto loc_82B4A82C;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82b49b78
	ctx.lr = 0x82B4A630;
	sub_82B49B78(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a938
	if (ctx.cr0.lt) goto loc_82B4A938;
	// li r28,2
	ctx.r28.s64 = 2;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r28.u32);
	// bl 0x82547910
	ctx.lr = 0x82B4A650;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a67c
	if (ctx.cr0.eq) goto loc_82B4A67C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,8024
	ctx.r11.s64 = ctx.r11.s64 + 8024;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82b4a680
	goto loc_82B4A680;
loc_82B4A67C:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82B4A680:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b4a82c
	if (ctx.cr6.eq) goto loc_82B4A82C;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4A690;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a6a4
	if (ctx.cr0.eq) goto loc_82B4A6A4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82b845a8
	ctx.lr = 0x82B4A6A0;
	sub_82B845A8(ctx, base);
	// b 0x82b4a6a8
	goto loc_82B4A6A8;
loc_82B4A6A4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82B4A6A8:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r3.u32);
	// beq cr6,0x82b4a82c
	if (ctx.cr6.eq) goto loc_82B4A82C;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82b49b78
	ctx.lr = 0x82B4A6C0;
	sub_82B49B78(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a938
	if (ctx.cr0.lt) goto loc_82B4A938;
	// li r11,2560
	ctx.r11.s64 = 2560;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x82547910
	ctx.lr = 0x82B4A6E0;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a70c
	if (ctx.cr0.eq) goto loc_82B4A70C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,8004
	ctx.r11.s64 = ctx.r11.s64 + 8004;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82b4a710
	goto loc_82B4A710;
loc_82B4A70C:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82B4A710:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b4a82c
	if (ctx.cr6.eq) goto loc_82B4A82C;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4A720;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a734
	if (ctx.cr0.eq) goto loc_82B4A734;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82b845a8
	ctx.lr = 0x82B4A730;
	sub_82B845A8(ctx, base);
	// b 0x82b4a738
	goto loc_82B4A738;
loc_82B4A734:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82B4A738:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r3.u32);
	// beq cr6,0x82b4a82c
	if (ctx.cr6.eq) goto loc_82B4A82C;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82b49b78
	ctx.lr = 0x82B4A750;
	sub_82B49B78(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a938
	if (ctx.cr0.lt) goto loc_82B4A938;
	// li r11,2589
	ctx.r11.s64 = 2589;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x82547910
	ctx.lr = 0x82B4A770;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a79c
	if (ctx.cr0.eq) goto loc_82B4A79C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,7988
	ctx.r11.s64 = ctx.r11.s64 + 7988;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82b4a7a0
	goto loc_82B4A7A0;
loc_82B4A79C:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82B4A7A0:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82b4a82c
	if (ctx.cr6.eq) goto loc_82B4A82C;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4A7B0;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a7c4
	if (ctx.cr0.eq) goto loc_82B4A7C4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82b845a8
	ctx.lr = 0x82B4A7C0;
	sub_82B845A8(ctx, base);
	// b 0x82b4a7c8
	goto loc_82B4A7C8;
loc_82B4A7C4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82B4A7C8:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r3.u32);
	// beq cr6,0x82b4a82c
	if (ctx.cr6.eq) goto loc_82B4A82C;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82b49b78
	ctx.lr = 0x82B4A7E0;
	sub_82B49B78(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a938
	if (ctx.cr0.lt) goto loc_82B4A938;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82547910
	ctx.lr = 0x82B4A7F4;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4a820
	if (ctx.cr0.eq) goto loc_82B4A820;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r31,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r31.u32);
	// addi r11,r11,7980
	ctx.r11.s64 = ctx.r11.s64 + 7980;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// b 0x82b4a824
	goto loc_82B4A824;
loc_82B4A820:
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
loc_82B4A824:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82b4a838
	if (!ctx.cr6.eq) goto loc_82B4A838;
loc_82B4A82C:
	// lis r30,-32761
	ctx.r30.s64 = -2147024896;
	// ori r30,r30,14
	ctx.r30.u64 = ctx.r30.u64 | 14;
	// b 0x82b4a938
	goto loc_82B4A938;
loc_82B4A838:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82b49b78
	ctx.lr = 0x82B4A844;
	sub_82B49B78(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a938
	if (ctx.cr0.lt) goto loc_82B4A938;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// addi r4,r11,7972
	ctx.r4.s64 = ctx.r11.s64 + 7972;
	// mr r29,r31
	ctx.r29.u64 = ctx.r31.u64;
	// bl 0x82b49c68
	ctx.lr = 0x82B4A860;
	sub_82B49C68(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a938
	if (ctx.cr0.lt) goto loc_82B4A938;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,200
	ctx.r5.s64 = 200;
	// addi r4,r11,7960
	ctx.r4.s64 = ctx.r11.s64 + 7960;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82b49cf0
	ctx.lr = 0x82B4A87C;
	sub_82B49CF0(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a938
	if (ctx.cr0.lt) goto loc_82B4A938;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82b4a934
	if (ctx.cr6.eq) goto loc_82B4A934;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b51e10
	ctx.lr = 0x82B4A894;
	sub_82B51E10(ctx, base);
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// stw r11,632(r27)
	PPC_STORE_U32(ctx.r27.u32 + 632, ctx.r11.u32);
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4a92c
	if (ctx.cr6.eq) goto loc_82B4A92C;
	// addi r28,r27,24
	ctx.r28.s64 = ctx.r27.s64 + 24;
loc_82B4A8AC:
	// lwz r4,4(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// cmplwi r4,0
	ctx.cr0.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq 0x82b4a8e0
	if (ctx.cr0.eq) goto loc_82B4A8E0;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82B4A8C0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b4a8c0
	if (!ctx.cr6.eq) goto loc_82B4A8C0;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rotlwi r5,r11,0
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// b 0x82b4a8e4
	goto loc_82B4A8E4;
loc_82B4A8E0:
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
loc_82B4A8E4:
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82b51e38
	ctx.lr = 0x82B4A8FC;
	sub_82B51E38(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a95c
	if (ctx.cr0.lt) goto loc_82B4A95C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,0(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82b49f90
	ctx.lr = 0x82B4A914;
	sub_82B49F90(ctx, base);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// blt 0x82b4a95c
	if (ctx.cr0.lt) goto loc_82B4A95C;
	// addi r26,r26,8
	ctx.r26.s64 = ctx.r26.s64 + 8;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b4a8ac
	if (!ctx.cr6.eq) goto loc_82B4A8AC;
loc_82B4A92C:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8224ad48
	ctx.lr = 0x82B4A934;
	sub_8224AD48(ctx, base);
loc_82B4A934:
	// mr r30,r31
	ctx.r30.u64 = ctx.r31.u64;
loc_82B4A938:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// stw r25,632(r27)
	PPC_STORE_U32(ctx.r27.u32 + 632, ctx.r25.u32);
	// beq cr6,0x82b4a950
	if (ctx.cr6.eq) goto loc_82B4A950;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82b48870
	ctx.lr = 0x82B4A950;
	sub_82B48870(ctx, base);
loc_82B4A950:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
loc_82B4A95C:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8224ad48
	ctx.lr = 0x82B4A964;
	sub_8224AD48(ctx, base);
	// b 0x82b4a938
	goto loc_82B4A938;
}

__attribute__((alias("__imp__sub_82B4A968"))) PPC_WEAK_FUNC(sub_82B4A968);
PPC_FUNC_IMPL(__imp__sub_82B4A968) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82b49ea8
	ctx.lr = 0x82B4A9A0;
	sub_82B49EA8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4A9B0"))) PPC_WEAK_FUNC(sub_82B4A9B0);
PPC_FUNC_IMPL(__imp__sub_82B4A9B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e5c
	ctx.lr = 0x82B4A9B8;
	__savegprlr_25(ctx, base);
	// stwu r1,-432(r1)
	ea = -432 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r27,r31,640
	ctx.r27.s64 = ctx.r31.s64 + 640;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r11,672(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// ori r4,r11,12
	ctx.r4.u64 = ctx.r11.u64 | 12;
	// bl 0x82b53c98
	ctx.lr = 0x82B4A9D8;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4abd4
	if (ctx.cr0.lt) goto loc_82B4ABD4;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r26,1
	ctx.r26.s64 = 1;
	// cmpwi cr6,r11,10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 10, ctx.xer);
	// beq cr6,0x82b4aa1c
	if (ctx.cr6.eq) goto loc_82B4AA1C;
	// cmpwi cr6,r11,11
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 11, ctx.xer);
	// beq cr6,0x82b4aa14
	if (ctx.cr6.eq) goto loc_82B4AA14;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,7844
	ctx.r4.s64 = ctx.r11.s64 + 7844;
	// bl 0x82b4a968
	ctx.lr = 0x82B4AA08;
	sub_82B4A968(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82b4abd4
	goto loc_82B4ABD4;
loc_82B4AA14:
	// mr r25,r26
	ctx.r25.u64 = ctx.r26.u64;
	// b 0x82b4aa20
	goto loc_82B4AA20;
loc_82B4AA1C:
	// li r25,0
	ctx.r25.s64 = 0;
loc_82B4AA20:
	// lwz r9,636(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	// lwz r28,648(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 648);
	// cmplwi r9,0
	ctx.cr0.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne 0x82b4aa6c
	if (!ctx.cr0.eq) goto loc_82B4AA6C;
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b4aa6c
	if (!ctx.cr6.eq) goto loc_82B4AA6C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1505
	ctx.r5.s64 = 1505;
	// addi r6,r11,8104
	ctx.r6.s64 = ctx.r11.s64 + 8104;
loc_82B4AA4C:
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B4AA58;
	sub_82B529E0(ctx, base);
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// stw r26,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r26.u32);
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// stw r26,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r26.u32);
	// b 0x82b4abd4
	goto loc_82B4ABD4;
loc_82B4AA6C:
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4aaa4
	if (ctx.cr0.eq) goto loc_82B4AAA4;
loc_82B4AA7C:
	// lwz r11,92(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b4aa7c
	if (!ctx.cr0.eq) goto loc_82B4AA7C;
	// cmplwi cr6,r10,32
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 32, ctx.xer);
	// blt cr6,0x82b4aaa4
	if (ctx.cr6.lt) goto loc_82B4AAA4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1506
	ctx.r5.s64 = 1506;
	// addi r6,r11,8076
	ctx.r6.s64 = ctx.r11.s64 + 8076;
	// b 0x82b4aa4c
	goto loc_82B4AA4C;
loc_82B4AAA4:
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82b4aae8
	if (!ctx.cr6.eq) goto loc_82B4AAE8;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82b086c0
	ctx.lr = 0x82B4AAB4;
	sub_82B086C0(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82b4aac4
	if (ctx.cr6.eq) goto loc_82B4AAC4;
	// rlwinm. r11,r3,0,27,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x10;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b4aae8
	if (ctx.cr0.eq) goto loc_82B4AAE8;
loc_82B4AAC4:
	// lwz r10,628(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// addi r5,r11,17048
	ctx.r5.s64 = ctx.r11.s64 + 17048;
	// li r4,260
	ctx.r4.s64 = 260;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r6,80(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	// bl 0x82b528d0
	ctx.lr = 0x82B4AAE4;
	sub_82B528D0(ctx, base);
	// addi r28,r1,96
	ctx.r28.s64 = ctx.r1.s64 + 96;
loc_82B4AAE8:
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4ab08
	if (ctx.cr0.eq) goto loc_82B4AB08;
	// lwz r10,72(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b4ab08
	if (ctx.cr6.eq) goto loc_82B4AB08;
	// lwz r29,84(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	// b 0x82b4ab0c
	goto loc_82B4AB0C;
loc_82B4AB08:
	// li r29,0
	ctx.r29.s64 = 0;
loc_82B4AB0C:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82547910
	ctx.lr = 0x82B4AB18;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4ab2c
	if (ctx.cr0.eq) goto loc_82B4AB2C;
	// bl 0x82b47350
	ctx.lr = 0x82B4AB24;
	sub_82B47350(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// b 0x82b4ab30
	goto loc_82B4AB30;
loc_82B4AB2C:
	// li r30,0
	ctx.r30.s64 = 0;
loc_82B4AB30:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82b4ab44
	if (!ctx.cr6.eq) goto loc_82B4AB44;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b4abd4
	goto loc_82B4ABD4;
loc_82B4AB44:
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// lwz r9,636(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 636);
	// addi r8,r31,24
	ctx.r8.s64 = ctx.r31.s64 + 24;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82b47488
	ctx.lr = 0x82B4AB6C;
	sub_82B47488(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// bge 0x82b4ab98
	if (!ctx.cr0.lt) goto loc_82B4AB98;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r26,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r26.u32);
	// stw r26,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r26.u32);
	// bl 0x82b488d0
	ctx.lr = 0x82B4AB84;
	sub_82B488D0(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82547938
	ctx.lr = 0x82B4AB90;
	sub_82547938(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// b 0x82b4abd4
	goto loc_82B4ABD4;
loc_82B4AB98:
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// stw r11,92(r30)
	PPC_STORE_U32(ctx.r30.u32 + 92, ctx.r11.u32);
	// lwz r11,692(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 692);
	// stw r30,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r30.u32);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4abd0
	if (ctx.cr0.eq) goto loc_82B4ABD0;
	// lwz r3,20(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4abd0
	if (ctx.cr0.eq) goto loc_82B4ABD0;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r4,76(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 76);
	// subf r6,r5,r11
	ctx.r6.s64 = ctx.r11.s64 - ctx.r5.s64;
	// bl 0x82e564e8
	ctx.lr = 0x82B4ABD0;
	sub_82E564E8(ctx, base);
loc_82B4ABD0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B4ABD4:
	// addi r1,r1,432
	ctx.r1.s64 = ctx.r1.s64 + 432;
	// b 0x82e28eac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4ABE0"))) PPC_WEAK_FUNC(sub_82B4ABE0);
PPC_FUNC_IMPL(__imp__sub_82B4ABE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e64
	ctx.lr = 0x82B4ABE8;
	__savegprlr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// lwz r3,680(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 680);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4acd4
	if (ctx.cr0.lt) goto loc_82B4ACD4;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82547910
	ctx.lr = 0x82B4AC18;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4ac28
	if (ctx.cr0.eq) goto loc_82B4AC28;
	// bl 0x82b47350
	ctx.lr = 0x82B4AC24;
	sub_82B47350(ctx, base);
	// b 0x82b4ac2c
	goto loc_82B4AC2C;
loc_82B4AC28:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B4AC2C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r3.u32);
	// bne cr6,0x82b4ac44
	if (!ctx.cr6.eq) goto loc_82B4AC44;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b4acd4
	goto loc_82B4ACD4;
loc_82B4AC44:
	// li r11,0
	ctx.r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// addi r8,r31,24
	ctx.r8.s64 = ctx.r31.s64 + 24;
	// addi r7,r31,640
	ctx.r7.s64 = ctx.r31.s64 + 640;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82b47488
	ctx.lr = 0x82B4AC6C;
	sub_82B47488(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4acd4
	if (ctx.cr0.lt) goto loc_82B4ACD4;
	// lwz r11,692(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 692);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4acb0
	if (ctx.cr0.eq) goto loc_82B4ACB0;
	// lwz r3,20(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4acb0
	if (ctx.cr0.eq) goto loc_82B4ACB0;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// extsw r5,r9
	ctx.r5.s64 = ctx.r9.s32;
	// lwz r4,76(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// subf r6,r9,r10
	ctx.r6.s64 = ctx.r10.s64 - ctx.r9.s64;
	// bl 0x82e564e8
	ctx.lr = 0x82B4ACA8;
	sub_82E564E8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4acd4
	if (ctx.cr0.lt) goto loc_82B4ACD4;
loc_82B4ACB0:
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b4a500
	ctx.lr = 0x82B4ACBC;
	sub_82B4A500(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4acd4
	if (ctx.cr0.lt) goto loc_82B4ACD4;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r28,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r28.u32);
	// stw r11,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r11.u32);
loc_82B4ACD4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4ACE0"))) PPC_WEAK_FUNC(sub_82B4ACE0);
PPC_FUNC_IMPL(__imp__sub_82B4ACE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B4ACE8;
	__savegprlr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// lwz r3,680(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 680);
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4add8
	if (ctx.cr0.lt) goto loc_82B4ADD8;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82b4ad20
	if (!ctx.cr6.eq) goto loc_82B4AD20;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// addi r30,r11,-29761
	ctx.r30.s64 = ctx.r11.s64 + -29761;
loc_82B4AD20:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82547910
	ctx.lr = 0x82B4AD2C;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4ad3c
	if (ctx.cr0.eq) goto loc_82B4AD3C;
	// bl 0x82b47350
	ctx.lr = 0x82B4AD38;
	sub_82B47350(ctx, base);
	// b 0x82b4ad40
	goto loc_82B4AD40;
loc_82B4AD3C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B4AD40:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r3.u32);
	// bne cr6,0x82b4ad58
	if (!ctx.cr6.eq) goto loc_82B4AD58;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b4add8
	goto loc_82B4ADD8;
loc_82B4AD58:
	// addi r8,r31,24
	ctx.r8.s64 = ctx.r31.s64 + 24;
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82b47698
	ctx.lr = 0x82B4AD70;
	sub_82B47698(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4add8
	if (ctx.cr0.lt) goto loc_82B4ADD8;
	// lwz r11,692(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 692);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4adb4
	if (ctx.cr0.eq) goto loc_82B4ADB4;
	// lwz r3,20(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4adb4
	if (ctx.cr0.eq) goto loc_82B4ADB4;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// extsw r5,r9
	ctx.r5.s64 = ctx.r9.s32;
	// lwz r4,76(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	// subf r6,r9,r10
	ctx.r6.s64 = ctx.r10.s64 - ctx.r9.s64;
	// bl 0x82e564e8
	ctx.lr = 0x82B4ADAC;
	sub_82E564E8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4add8
	if (ctx.cr0.lt) goto loc_82B4ADD8;
loc_82B4ADB4:
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b4a500
	ctx.lr = 0x82B4ADC0;
	sub_82B4A500(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4add8
	if (ctx.cr0.lt) goto loc_82B4ADD8;
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r26,636(r31)
	PPC_STORE_U32(ctx.r31.u32 + 636, ctx.r26.u32);
	// stw r11,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r11.u32);
loc_82B4ADD8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4ADE0"))) PPC_WEAK_FUNC(sub_82B4ADE0);
PPC_FUNC_IMPL(__imp__sub_82B4ADE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e60
	ctx.lr = 0x82B4ADE8;
	__savegprlr_26(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// li r26,1
	ctx.r26.s64 = 1;
	// cmplwi cr6,r30,16
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 16, ctx.xer);
	// ble cr6,0x82b4ae0c
	if (!ctx.cr6.gt) goto loc_82B4AE0C;
	// stw r26,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r26.u32);
loc_82B4AE0C:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b4b2e8
	if (!ctx.cr6.eq) goto loc_82B4B2E8;
	// rlwinm r11,r30,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// subfic r9,r30,16
	ctx.xer.ca = ctx.r30.u32 <= 16;
	ctx.r9.s64 = 16 - ctx.r30.s64;
	// add r29,r11,r10
	ctx.r29.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82e29500
	ctx.lr = 0x82B4AE38;
	sub_82E29500(ctx, base);
	// mtctr r30
	ctx.ctr.u64 = ctx.r30.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82b4ae80
	if (ctx.cr6.eq) goto loc_82B4AE80;
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
loc_82B4AE48:
	// lwz r11,104(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4aeb0
	if (ctx.cr0.eq) goto loc_82B4AEB0;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stw r9,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r9.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// lwz r9,108(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// stw r11,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r11.u32);
	// bdnz 0x82b4ae48
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B4AE48;
loc_82B4AE80:
	// cmplwi cr6,r27,46
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 46, ctx.xer);
	// bgt cr6,0x82b4b2b8
	if (ctx.cr6.gt) goto loc_82B4B2B8;
	// lis r12,-32239
	ctx.r12.s64 = -2112815104;
	// addi r12,r12,7136
	ctx.r12.s64 = ctx.r12.s64 + 7136;
	// rlwinm r0,r27,1,0,30
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U16(ctx.r12.u32 + ctx.r0.u32);
	// lis r12,-32075
	ctx.r12.s64 = -2102067200;
	// addi r12,r12,-20816
	ctx.r12.s64 = ctx.r12.s64 + -20816;
	// add r12,r12,r0
	ctx.r12.u64 = ctx.r12.u64 + ctx.r0.u64;
	// mtctr r12
	ctx.ctr.u64 = ctx.r12.u64;
	// nop 
	// bctr 
	switch (ctx.r27.u64) {
	case 0:
		goto loc_82B4AED0;
	case 1:
		goto loc_82B4AEE8;
	case 2:
		goto loc_82B4AEFC;
	case 3:
		goto loc_82B4AF2C;
	case 4:
		goto loc_82B4AF74;
	case 5:
		goto loc_82B4AF80;
	case 6:
		goto loc_82B4AF8C;
	case 7:
		goto loc_82B4AFA0;
	case 8:
		goto loc_82B4AFC0;
	case 9:
		goto loc_82B4AFE8;
	case 10:
		goto loc_82B4AFFC;
	case 11:
		goto loc_82B4B008;
	case 12:
		goto loc_82B4B014;
	case 13:
		goto loc_82B4B030;
	case 14:
		goto loc_82B4B040;
	case 15:
		goto loc_82B4B04C;
	case 16:
		goto loc_82B4B04C;
	case 17:
		goto loc_82B4B054;
	case 18:
		goto loc_82B4B078;
	case 19:
		goto loc_82B4B04C;
	case 20:
		goto loc_82B4B0A8;
	case 21:
		goto loc_82B4B0C0;
	case 22:
		goto loc_82B4B04C;
	case 23:
		goto loc_82B4B04C;
	case 24:
		goto loc_82B4B0D0;
	case 25:
		goto loc_82B4B0E8;
	case 26:
		goto loc_82B4B04C;
	case 27:
		goto loc_82B4B12C;
	case 28:
		goto loc_82B4B14C;
	case 29:
		goto loc_82B4B04C;
	case 30:
		goto loc_82B4B164;
	case 31:
		goto loc_82B4B184;
	case 32:
		goto loc_82B4B19C;
	case 33:
		goto loc_82B4B1BC;
	case 34:
		goto loc_82B4B04C;
	case 35:
		goto loc_82B4B1D4;
	case 36:
		goto loc_82B4B1EC;
	case 37:
		goto loc_82B4B04C;
	case 38:
		goto loc_82B4B210;
	case 39:
		goto loc_82B4B04C;
	case 40:
		goto loc_82B4B23C;
	case 41:
		goto loc_82B4B04C;
	case 42:
		goto loc_82B4B268;
	case 43:
		goto loc_82B4B04C;
	case 44:
		goto loc_82B4B288;
	case 45:
		goto loc_82B4B288;
	case 46:
		goto loc_82B4B288;
	default:
		__builtin_unreachable();
	}
loc_82B4AEB0:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r6,r11,8260
	ctx.r6.s64 = ctx.r11.s64 + 8260;
loc_82B4AEB8:
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B4AEC8;
	sub_82B529E0(ctx, base);
	// stw r26,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r26.u32);
	// b 0x82b4b2e8
	goto loc_82B4B2E8;
loc_82B4AED0:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82b49f90
	ctx.lr = 0x82B4AEE4;
	sub_82B49F90(ctx, base);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4AEE8:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82b494a8
	ctx.lr = 0x82B4AEF8;
	sub_82B494A8(ctx, base);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4AEFC:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// stw r10,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r10.u32);
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b4b2b8
	if (ctx.cr6.eq) goto loc_82B4B2B8;
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r10.u32);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4AF2C:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// stw r10,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r10.u32);
	// lwz r11,640(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 640);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b4af60
	if (ctx.cr6.eq) goto loc_82B4AF60;
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r10.u32);
loc_82B4AF60:
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82b4b2b8
	if (ctx.cr6.eq) goto loc_82B4B2B8;
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// stw r9,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r9.u32);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4AF74:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b4a9b0
	ctx.lr = 0x82B4AF7C;
	sub_82B4A9B0(ctx, base);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4AF80:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b47848
	ctx.lr = 0x82B4AF88;
	sub_82B47848(ctx, base);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4AF8C:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
loc_82B4AF94:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b49558
	ctx.lr = 0x82B4AF9C;
	sub_82B49558(ctx, base);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4AFA0:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82b48688
	ctx.lr = 0x82B4AFB8;
	sub_82B48688(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x82b4af94
	goto loc_82B4AF94;
loc_82B4AFC0:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82b48688
	ctx.lr = 0x82B4AFD8;
	sub_82B48688(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r4,r11,27,31,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// b 0x82b4af94
	goto loc_82B4AF94;
loc_82B4AFE8:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,24(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82b479b0
	ctx.lr = 0x82B4AFF8;
	sub_82B479B0(ctx, base);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4AFFC:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b47a70
	ctx.lr = 0x82B4B004;
	sub_82B47A70(ctx, base);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4B008:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b49610
	ctx.lr = 0x82B4B010;
	sub_82B49610(ctx, base);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4B014:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b49558
	ctx.lr = 0x82B4B020;
	sub_82B49558(ctx, base);
loc_82B4B020:
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53080
	ctx.lr = 0x82B4B02C;
	sub_82B53080(ctx, base);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4B030:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b479b0
	ctx.lr = 0x82B4B03C;
	sub_82B479B0(ctx, base);
	// b 0x82b4b020
	goto loc_82B4B020;
loc_82B4B040:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b4a308
	ctx.lr = 0x82B4B048;
	sub_82B4A308(ctx, base);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4B04C:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4B054:
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,2
	ctx.r11.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r28,r30
	ctx.r28.u64 = ctx.r30.u64;
	// lwz r4,24(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// bl 0x82b49db0
	ctx.lr = 0x82B4B070;
	sub_82B49DB0(ctx, base);
	// stw r3,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r3.u32);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4B078:
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,2
	ctx.r11.s64 = 2;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r28,r30
	ctx.r28.u64 = ctx.r30.u64;
	// lwz r4,24(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// bl 0x82b48688
	ctx.lr = 0x82B4B09C;
	sub_82B48688(ctx, base);
	// stw r3,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r3.u32);
	// stw r26,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r26.u32);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4B0A8:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
loc_82B4B0B0:
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
loc_82B4B0B8:
	// stw r11,24(r28)
	PPC_STORE_U32(ctx.r28.u32 + 24, ctx.r11.u32);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4B0C0:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// neg r11,r11
	ctx.r11.s64 = -ctx.r11.s64;
	// b 0x82b4b0b8
	goto loc_82B4B0B8;
loc_82B4B0D0:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// b 0x82b4b0b8
	goto loc_82B4B0B8;
loc_82B4B0E8:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4b10c
	if (ctx.cr0.eq) goto loc_82B4B10C;
	// lwz r10,24(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// twllei r11,0
	// divwu r11,r10,r11
	ctx.r11.u32 = ctx.r10.u32 / ctx.r11.u32;
	// b 0x82b4b0b8
	goto loc_82B4B0B8;
loc_82B4B10C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1503
	ctx.r5.s64 = 1503;
	// addi r6,r11,8216
	ctx.r6.s64 = ctx.r11.s64 + 8216;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B4B124;
	sub_82B529E0(ctx, base);
	// stw r26,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r26.u32);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4B12C:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82B4B140:
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// stw r10,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r10.u32);
	// b 0x82b4b2b8
	goto loc_82B4B2B8;
loc_82B4B14C:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// b 0x82b4b0b8
	goto loc_82B4B0B8;
loc_82B4B164:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// subfc r11,r10,r11
	ctx.xer.ca = ctx.r11.u32 >= ctx.r10.u32;
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
loc_82B4B178:
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// b 0x82b4b0b8
	goto loc_82B4B0B8;
loc_82B4B184:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// subfc r11,r11,r10
	ctx.xer.ca = ctx.r10.u32 >= ctx.r11.u32;
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// b 0x82b4b178
	goto loc_82B4B178;
loc_82B4B19C:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// subfc r10,r10,r9
	ctx.xer.ca = ctx.r9.u32 >= ctx.r10.u32;
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
loc_82B4B1B0:
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// b 0x82b4b140
	goto loc_82B4B140;
loc_82B4B1BC:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r9,24(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// subfc r10,r9,r10
	ctx.xer.ca = ctx.r10.u32 >= ctx.r9.u32;
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// b 0x82b4b1b0
	goto loc_82B4B1B0;
loc_82B4B1D4:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// b 0x82b4b0b0
	goto loc_82B4B0B0;
loc_82B4B1EC:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// lwz r10,24(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 ^ 1;
	// b 0x82b4b0b8
	goto loc_82B4B0B8;
loc_82B4B210:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4b234
	if (ctx.cr6.eq) goto loc_82B4B234;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// bne cr6,0x82b4b0b8
	if (!ctx.cr6.eq) goto loc_82B4B0B8;
loc_82B4B234:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82b4b0b8
	goto loc_82B4B0B8;
loc_82B4B23C:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b4b260
	if (!ctx.cr6.eq) goto loc_82B4B260;
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,0
	ctx.r11.s64 = 0;
	// beq cr6,0x82b4b0b8
	if (ctx.cr6.eq) goto loc_82B4B0B8;
loc_82B4B260:
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// b 0x82b4b0b8
	goto loc_82B4B0B8;
loc_82B4B268:
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bne cr6,0x82b4b280
	if (!ctx.cr6.eq) goto loc_82B4B280;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82B4B280:
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// b 0x82b4b0b8
	goto loc_82B4B0B8;
loc_82B4B288:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4B290;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4b2a8
	if (ctx.cr0.eq) goto loc_82B4B2A8;
	// addi r4,r31,640
	ctx.r4.s64 = ctx.r31.s64 + 640;
	// bl 0x82b845a8
	ctx.lr = 0x82B4B2A0;
	sub_82B845A8(ctx, base);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// b 0x82b4b2ac
	goto loc_82B4B2AC;
loc_82B4B2A8:
	// li r28,0
	ctx.r28.s64 = 0;
loc_82B4B2AC:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b48808
	ctx.lr = 0x82B4B2B8;
	sub_82B48808(ctx, base);
loc_82B4B2B8:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b4b2e8
	if (!ctx.cr6.eq) goto loc_82B4B2E8;
	// lwz r3,108(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4b2f0
	if (ctx.cr0.eq) goto loc_82B4B2F0;
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stw r11,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r11.u32);
	// stw r28,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r28.u32);
	// lwz r11,104(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
loc_82B4B2E4:
	// stw r3,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r3.u32);
loc_82B4B2E8:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82e28eb0
	__restgprlr_26(ctx, base);
	return;
loc_82B4B2F0:
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82b83f88
	ctx.lr = 0x82B4B2F8;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4b318
	if (ctx.cr0.eq) goto loc_82B4B318;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// lwz r5,104(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// addi r6,r11,8208
	ctx.r6.s64 = ctx.r11.s64 + 8208;
	// bl 0x82b84150
	ctx.lr = 0x82B4B314;
	sub_82B84150(ctx, base);
	// b 0x82b4b31c
	goto loc_82B4B31C;
loc_82B4B318:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B4B31C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82b4b2e4
	if (!ctx.cr6.eq) goto loc_82B4B2E4;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r6,r11,8176
	ctx.r6.s64 = ctx.r11.s64 + 8176;
	// b 0x82b4aeb8
	goto loc_82B4AEB8;
}

__attribute__((alias("__imp__sub_82B4B330"))) PPC_WEAK_FUNC(sub_82B4B330);
PPC_FUNC_IMPL(__imp__sub_82B4B330) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e54
	ctx.lr = 0x82B4B338;
	__savegprlr_23(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r25,0
	ctx.r25.s64 = 0;
	// addi r11,r31,1032
	ctx.r11.s64 = ctx.r31.s64 + 1032;
	// addi r23,r31,32
	ctx.r23.s64 = ctx.r31.s64 + 32;
	// li r26,-1
	ctx.r26.s64 = -1;
	// mr r30,r25
	ctx.r30.u64 = ctx.r25.u64;
	// stw r25,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r25.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r25,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r25.u32);
	// addi r27,r11,4900
	ctx.r27.s64 = ctx.r11.s64 + 4900;
	// stw r26,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r26.u32);
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// stw r23,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r23.u32);
	// sth r25,32(r31)
	PPC_STORE_U16(ctx.r31.u32 + 32, ctx.r25.u16);
	// addi r24,r11,7844
	ctx.r24.s64 = ctx.r11.s64 + 7844;
loc_82B4B37C:
	// rlwinm r29,r30,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r30.u32 | (ctx.r30.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r11,r27,220
	ctx.r11.s64 = ctx.r27.s64 + 220;
	// lhax r11,r29,r11
	ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r29.u32 + ctx.r11.u32));
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b4b478
	if (!ctx.cr0.eq) goto loc_82B4B478;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82b4b3b4
	if (!ctx.cr6.lt) goto loc_82B4B3B4;
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3032);
	// bl 0x82b48cd0
	ctx.lr = 0x82B4B3A4;
	sub_82B48CD0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// stw r3,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r3.u32);
	// bge 0x82b4b3b4
	if (!ctx.cr0.lt) goto loc_82B4B3B4;
	// stw r25,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r25.u32);
loc_82B4B3B4:
	// addi r11,r27,380
	ctx.r11.s64 = ctx.r27.s64 + 380;
	// lhax r10,r29,r11
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r29.u32 + ctx.r11.u32));
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4b43c
	if (ctx.cr0.eq) goto loc_82B4B43C;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r10,369
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 369, ctx.xer);
	// bgt cr6,0x82b4b43c
	if (ctx.cr6.gt) goto loc_82B4B43C;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r27,1476
	ctx.r10.s64 = ctx.r27.s64 + 1476;
	// lhax r10,r9,r10
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + ctx.r10.u32));
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82b4b43c
	if (!ctx.cr6.eq) goto loc_82B4B43C;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r10,r31,1030
	ctx.r10.s64 = ctx.r31.s64 + 1030;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82b4b8cc
	if (!ctx.cr6.lt) goto loc_82B4B8CC;
	// addi r8,r27,732
	ctx.r8.s64 = ctx.r27.s64 + 732;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// lhax r30,r9,r8
	ctx.r30.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + ctx.r8.u32));
	// stw r10,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r10.u32);
	// sth r30,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r30.u16);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r26,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r26.u32);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble 0x82b4b37c
	if (!ctx.cr0.gt) goto loc_82B4B37C;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// b 0x82b4b37c
	goto loc_82B4B37C;
loc_82B4B43C:
	// addi r11,r27,540
	ctx.r11.s64 = ctx.r27.s64 + 540;
	// lhax r10,r29,r11
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r29.u32 + ctx.r11.u32));
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4b7f4
	if (ctx.cr0.eq) goto loc_82B4B7F4;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r10,369
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 369, ctx.xer);
	// bgt cr6,0x82b4b7f4
	if (ctx.cr6.gt) goto loc_82B4B7F4;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r27,1476
	ctx.r9.s64 = ctx.r27.s64 + 1476;
	// lhax r9,r10,r9
	ctx.r9.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r9.u32));
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82b4b7f4
	if (!ctx.cr6.eq) goto loc_82B4B7F4;
	// addi r11,r27,732
	ctx.r11.s64 = ctx.r27.s64 + 732;
	// lhax r11,r10,r11
	ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r11.u32));
loc_82B4B478:
	// rlwinm r30,r11,1,0,30
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// addi r9,r27,124
	ctx.r9.s64 = ctx.r27.s64 + 124;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,46
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 46, ctx.xer);
	// lhax r29,r30,r9
	ctx.r29.s64 = int16_t(PPC_LOAD_U16(ctx.r30.u32 + ctx.r9.u32));
	// rlwinm r28,r29,2,0,29
	ctx.r28.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r28,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r28.s64;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r10,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r10.u32);
	// bgt cr6,0x82b4b6e0
	if (ctx.cr6.gt) goto loc_82B4B6E0;
	// lis r12,-32239
	ctx.r12.s64 = -2112815104;
	// addi r12,r12,7232
	ctx.r12.s64 = ctx.r12.s64 + 7232;
	// lbzx r0,r12,r11
	ctx.r0.u64 = PPC_LOAD_U8(ctx.r12.u32 + ctx.r11.u32);
	// rlwinm r0,r0,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r0.u32 | (ctx.r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-32075
	ctx.r12.s64 = -2102067200;
	// addi r12,r12,-19252
	ctx.r12.s64 = ctx.r12.s64 + -19252;
	// add r12,r12,r0
	ctx.r12.u64 = ctx.r12.u64 + ctx.r0.u64;
	// mtctr r12
	ctx.ctr.u64 = ctx.r12.u64;
	// nop 
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82B4B4CC;
	case 1:
		goto loc_82B4B4D8;
	case 2:
		goto loc_82B4B4E4;
	case 3:
		goto loc_82B4B4F0;
	case 4:
		goto loc_82B4B4FC;
	case 5:
		goto loc_82B4B504;
	case 6:
		goto loc_82B4B50C;
	case 7:
		goto loc_82B4B518;
	case 8:
		goto loc_82B4B524;
	case 9:
		goto loc_82B4B530;
	case 10:
		goto loc_82B4B53C;
	case 11:
		goto loc_82B4B544;
	case 12:
		goto loc_82B4B54C;
	case 13:
		goto loc_82B4B554;
	case 14:
		goto loc_82B4B55C;
	case 15:
		goto loc_82B4B564;
	case 16:
		goto loc_82B4B570;
	case 17:
		goto loc_82B4B57C;
	case 18:
		goto loc_82B4B588;
	case 19:
		goto loc_82B4B594;
	case 20:
		goto loc_82B4B5A0;
	case 21:
		goto loc_82B4B5AC;
	case 22:
		goto loc_82B4B5B8;
	case 23:
		goto loc_82B4B5C4;
	case 24:
		goto loc_82B4B5D0;
	case 25:
		goto loc_82B4B5DC;
	case 26:
		goto loc_82B4B5E8;
	case 27:
		goto loc_82B4B5F4;
	case 28:
		goto loc_82B4B600;
	case 29:
		goto loc_82B4B60C;
	case 30:
		goto loc_82B4B618;
	case 31:
		goto loc_82B4B624;
	case 32:
		goto loc_82B4B630;
	case 33:
		goto loc_82B4B63C;
	case 34:
		goto loc_82B4B648;
	case 35:
		goto loc_82B4B654;
	case 36:
		goto loc_82B4B660;
	case 37:
		goto loc_82B4B66C;
	case 38:
		goto loc_82B4B678;
	case 39:
		goto loc_82B4B684;
	case 40:
		goto loc_82B4B690;
	case 41:
		goto loc_82B4B69C;
	case 42:
		goto loc_82B4B6A8;
	case 43:
		goto loc_82B4B6B4;
	case 44:
		goto loc_82B4B6C0;
	case 45:
		goto loc_82B4B6C8;
	case 46:
		goto loc_82B4B6D0;
	default:
		__builtin_unreachable();
	}
loc_82B4B4CC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B4D8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B4E4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B4F0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,3
	ctx.r4.s64 = 3;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B4FC:
	// li r4,4
	ctx.r4.s64 = 4;
	// b 0x82b4b6d4
	goto loc_82B4B6D4;
loc_82B4B504:
	// li r4,5
	ctx.r4.s64 = 5;
	// b 0x82b4b6d4
	goto loc_82B4B6D4;
loc_82B4B50C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,6
	ctx.r4.s64 = 6;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B518:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B524:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,8
	ctx.r4.s64 = 8;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B530:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,9
	ctx.r4.s64 = 9;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B53C:
	// li r4,10
	ctx.r4.s64 = 10;
	// b 0x82b4b6d4
	goto loc_82B4B6D4;
loc_82B4B544:
	// li r4,11
	ctx.r4.s64 = 11;
	// b 0x82b4b6d4
	goto loc_82B4B6D4;
loc_82B4B54C:
	// li r4,12
	ctx.r4.s64 = 12;
	// b 0x82b4b6d4
	goto loc_82B4B6D4;
loc_82B4B554:
	// li r4,13
	ctx.r4.s64 = 13;
	// b 0x82b4b6d4
	goto loc_82B4B6D4;
loc_82B4B55C:
	// li r4,14
	ctx.r4.s64 = 14;
	// b 0x82b4b6d4
	goto loc_82B4B6D4;
loc_82B4B564:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,15
	ctx.r4.s64 = 15;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B570:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,16
	ctx.r4.s64 = 16;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B57C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,17
	ctx.r4.s64 = 17;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B588:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,18
	ctx.r4.s64 = 18;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B594:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,19
	ctx.r4.s64 = 19;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B5A0:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,20
	ctx.r4.s64 = 20;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B5AC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,21
	ctx.r4.s64 = 21;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B5B8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,22
	ctx.r4.s64 = 22;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B5C4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,23
	ctx.r4.s64 = 23;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B5D0:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,24
	ctx.r4.s64 = 24;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B5DC:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,25
	ctx.r4.s64 = 25;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B5E8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,26
	ctx.r4.s64 = 26;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B5F4:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,27
	ctx.r4.s64 = 27;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B600:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,28
	ctx.r4.s64 = 28;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B60C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,29
	ctx.r4.s64 = 29;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B618:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,30
	ctx.r4.s64 = 30;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B624:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,31
	ctx.r4.s64 = 31;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B630:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,32
	ctx.r4.s64 = 32;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B63C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,33
	ctx.r4.s64 = 33;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B648:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,34
	ctx.r4.s64 = 34;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B654:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,35
	ctx.r4.s64 = 35;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B660:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,36
	ctx.r4.s64 = 36;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B66C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,37
	ctx.r4.s64 = 37;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B678:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,38
	ctx.r4.s64 = 38;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B684:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,39
	ctx.r4.s64 = 39;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B690:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,40
	ctx.r4.s64 = 40;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B69C:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,41
	ctx.r4.s64 = 41;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B6A8:
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,42
	ctx.r4.s64 = 42;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B6B4:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,43
	ctx.r4.s64 = 43;
	// b 0x82b4b6d8
	goto loc_82B4B6D8;
loc_82B4B6C0:
	// li r4,44
	ctx.r4.s64 = 44;
	// b 0x82b4b6d4
	goto loc_82B4B6D4;
loc_82B4B6C8:
	// li r4,45
	ctx.r4.s64 = 45;
	// b 0x82b4b6d4
	goto loc_82B4B6D4;
loc_82B4B6D0:
	// li r4,46
	ctx.r4.s64 = 46;
loc_82B4B6D4:
	// li r5,0
	ctx.r5.s64 = 0;
loc_82B4B6D8:
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3032);
	// bl 0x82b4ade0
	ctx.lr = 0x82B4B6E0;
	sub_82B4ADE0(ctx, base);
loc_82B4B6E0:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// rlwinm r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r8,r27,28
	ctx.r8.s64 = ctx.r27.s64 + 28;
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// subf r10,r28,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r28.s64;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// lha r11,0(r11)
	ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r11.u32 + 0));
	// stw r10,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r10.u32);
	// lhax r10,r30,r8
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r30.u32 + ctx.r8.u32));
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne 0x82b4b77c
	if (!ctx.cr0.eq) goto loc_82B4B77C;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82b4b77c
	if (!ctx.cr6.eq) goto loc_82B4B77C;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r10,15
	ctx.r10.s64 = 15;
	// li r30,15
	ctx.r30.s64 = 15;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// sth r10,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bge cr6,0x82b4b768
	if (!ctx.cr6.lt) goto loc_82B4B768;
	// lwz r3,3032(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3032);
	// bl 0x82b48cd0
	ctx.lr = 0x82B4B758;
	sub_82B48CD0(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// stw r3,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r3.u32);
	// bge 0x82b4b768
	if (!ctx.cr0.lt) goto loc_82B4B768;
	// stw r25,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r25.u32);
loc_82B4B768:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b4b37c
	if (!ctx.cr6.eq) goto loc_82B4B37C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b4b8e0
	goto loc_82B4B8E0;
loc_82B4B77C:
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r27,700
	ctx.r10.s64 = ctx.r27.s64 + 700;
	// lhax r10,r9,r10
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + ctx.r10.u32));
	// cmpwi r10,0
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4b7bc
	if (ctx.cr0.eq) goto loc_82B4B7BC;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// cmplwi cr6,r10,369
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 369, ctx.xer);
	// bgt cr6,0x82b4b7bc
	if (ctx.cr6.gt) goto loc_82B4B7BC;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r8,r27,1476
	ctx.r8.s64 = ctx.r27.s64 + 1476;
	// lhax r8,r10,r8
	ctx.r8.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r8.u32));
	// cmpw cr6,r8,r11
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82b4b7bc
	if (!ctx.cr6.eq) goto loc_82B4B7BC;
	// addi r11,r27,732
	ctx.r11.s64 = ctx.r27.s64 + 732;
	// lhax r30,r10,r11
	ctx.r30.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r11.u32));
	// b 0x82b4b7c0
	goto loc_82B4B7C0;
loc_82B4B7BC:
	// lhax r30,r9,r27
	ctx.r30.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + ctx.r27.u32));
loc_82B4B7C0:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r10,r31,1030
	ctx.r10.s64 = ctx.r31.s64 + 1030;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82b4b8cc
	if (!ctx.cr6.lt) goto loc_82B4B8CC;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// stw r10,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r10.u32);
	// sth r30,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r30.u16);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
loc_82B4B7E0:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// b 0x82b4b37c
	goto loc_82B4B37C;
loc_82B4B7F4:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b4b818
	if (!ctx.cr6.eq) goto loc_82B4B818;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// bl 0x82b4a4b0
	ctx.lr = 0x82B4B80C;
	sub_82B4A4B0(ctx, base);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
loc_82B4B818:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82b4b8b8
	if (!ctx.cr6.lt) goto loc_82B4B8B8;
	// li r11,3
	ctx.r11.s64 = 3;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
loc_82B4B82C:
	// lwz r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r11,r27,380
	ctx.r11.s64 = ctx.r27.s64 + 380;
	// lha r10,0(r9)
	ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r9.u32 + 0));
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhax r11,r10,r11
	ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + ctx.r11.u32));
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b4b868
	if (ctx.cr0.eq) goto loc_82B4B868;
	// addi r10,r11,256
	ctx.r10.s64 = ctx.r11.s64 + 256;
	// cmplwi cr6,r10,369
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 369, ctx.xer);
	// bgt cr6,0x82b4b868
	if (ctx.cr6.gt) goto loc_82B4B868;
	// addi r11,r27,1476
	ctx.r11.s64 = ctx.r27.s64 + 1476;
	// rlwinm r8,r10,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r11,r8,r11
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + ctx.r11.u32);
	// cmplwi cr6,r11,256
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 256, ctx.xer);
	// beq cr6,0x82b4b888
	if (ctx.cr6.eq) goto loc_82B4B888;
loc_82B4B868:
	// cmplw cr6,r9,r23
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r23.u32, ctx.xer);
	// ble cr6,0x82b4b8dc
	if (!ctx.cr6.gt) goto loc_82B4B8DC;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// addi r10,r9,-2
	ctx.r10.s64 = ctx.r9.s64 + -2;
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// stw r10,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r10.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// b 0x82b4b82c
	goto loc_82B4B82C;
loc_82B4B888:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r9,r31,1030
	ctx.r9.s64 = ctx.r31.s64 + 1030;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82b4b8cc
	if (!ctx.cr6.lt) goto loc_82B4B8CC;
	// rlwinm r8,r10,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r27,732
	ctx.r9.s64 = ctx.r27.s64 + 732;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// lhax r30,r8,r9
	ctx.r30.s64 = int16_t(PPC_LOAD_U16(ctx.r8.u32 + ctx.r9.u32));
	// stw r10,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r10.u32);
	// sth r30,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r30.u16);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// b 0x82b4b7e0
	goto loc_82B4B7E0;
loc_82B4B8B8:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b4b8dc
	if (ctx.cr6.eq) goto loc_82B4B8DC;
	// stw r26,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r26.u32);
	// b 0x82b4b37c
	goto loc_82B4B37C;
loc_82B4B8CC:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,8292
	ctx.r4.s64 = ctx.r11.s64 + 8292;
	// bl 0x82b4a4b0
	ctx.lr = 0x82B4B8DC;
	sub_82B4A4B0(ctx, base);
loc_82B4B8DC:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82B4B8E0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82e28ea4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4B8E8"))) PPC_WEAK_FUNC(sub_82B4B8E8);
PPC_FUNC_IMPL(__imp__sub_82B4B8E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e4c
	ctx.lr = 0x82B4B8F0;
	__savegprlr_21(ctx, base);
	// stwu r1,-3232(r1)
	ea = -3232 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b4bcb8
	if (!ctx.cr6.eq) goto loc_82B4BCB8;
	// lis r11,-32229
	ctx.r11.s64 = -2112159744;
	// li r28,0
	ctx.r28.s64 = 0;
	// addi r22,r11,-29761
	ctx.r22.s64 = ctx.r11.s64 + -29761;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r27,1
	ctx.r27.s64 = 1;
	// addi r25,r11,7796
	ctx.r25.s64 = ctx.r11.s64 + 7796;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r21,12
	ctx.r21.s64 = 12;
	// addi r26,r11,8388
	ctx.r26.s64 = ctx.r11.s64 + 8388;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r23,r11,8336
	ctx.r23.s64 = ctx.r11.s64 + 8336;
	// lis r11,-32242
	ctx.r11.s64 = -2113011712;
	// addi r24,r11,9060
	ctx.r24.s64 = ctx.r11.s64 + 9060;
loc_82B4B93C:
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4b954
	if (ctx.cr0.eq) goto loc_82B4B954;
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4bce4
	if (ctx.cr6.eq) goto loc_82B4BCE4;
loc_82B4B954:
	// lwz r10,112(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82b4b9b4
	if (ctx.cr0.eq) goto loc_82B4B9B4;
	// addi r11,r10,16
	ctx.r11.s64 = ctx.r10.s64 + 16;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// std r9,0(r29)
	PPC_STORE_U64(ctx.r29.u32 + 0, ctx.r9.u64);
	// ld r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// std r9,8(r29)
	PPC_STORE_U64(ctx.r29.u32 + 8, ctx.r9.u64);
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// std r9,16(r29)
	PPC_STORE_U64(ctx.r29.u32 + 16, ctx.r9.u64);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r11,24(r29)
	PPC_STORE_U64(ctx.r29.u32 + 24, ctx.r11.u64);
	// lwz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r11,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r11.u32);
	// stw r28,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r28.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// stw r11,16(r29)
	PPC_STORE_U32(ctx.r29.u32 + 16, ctx.r11.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,20(r29)
	PPC_STORE_U32(ctx.r29.u32 + 20, ctx.r11.u32);
	// stw r28,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r28.u32);
	// b 0x82b4b9cc
	goto loc_82B4B9CC;
loc_82B4B9B4:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53c98
	ctx.lr = 0x82B4B9C4;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4bdec
	if (ctx.cr0.lt) goto loc_82B4BDEC;
loc_82B4B9CC:
	// lwz r7,0(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82b4bb6c
	if (!ctx.cr6.eq) goto loc_82B4BB6C;
	// addi r10,r29,8
	ctx.r10.s64 = ctx.r29.s64 + 8;
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
loc_82B4B9E0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4ba04
	if (ctx.cr0.eq) goto loc_82B4BA04;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4b9e0
	if (ctx.cr6.eq) goto loc_82B4B9E0;
loc_82B4BA04:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4bb6c
	if (!ctx.cr0.eq) goto loc_82B4BB6C;
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b4bb6c
	if (ctx.cr6.eq) goto loc_82B4BB6C;
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// li r5,3036
	ctx.r5.s64 = 3036;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r28,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r28.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r28,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r28.u32);
	// stw r27,88(r31)
	PPC_STORE_U32(ctx.r31.u32 + 88, ctx.r27.u32);
	// stw r11,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r11.u32);
	// bl 0x82e29500
	ctx.lr = 0x82B4BA3C;
	sub_82E29500(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r31,3128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 3128, ctx.r31.u32);
	// bl 0x82b4b330
	ctx.lr = 0x82B4BA48;
	sub_82B4B330(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b4ba54
	if (ctx.cr0.eq) goto loc_82B4BA54;
	// stw r27,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r27.u32);
loc_82B4BA54:
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// stw r28,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r28.u32);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b4bacc
	if (!ctx.cr6.eq) goto loc_82B4BACC;
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b4bacc
	if (!ctx.cr6.eq) goto loc_82B4BACC;
	// addi r30,r31,640
	ctx.r30.s64 = ctx.r31.s64 + 640;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82b53c98
	ctx.lr = 0x82B4BA84;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4bdec
	if (ctx.cr0.lt) goto loc_82B4BDEC;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82b4bac8
	if (ctx.cr6.eq) goto loc_82B4BAC8;
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82b4bac8
	if (ctx.cr6.eq) goto loc_82B4BAC8;
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b4bac0
	if (ctx.cr6.eq) goto loc_82B4BAC0;
	// li r5,1501
	ctx.r5.s64 = 1501;
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B4BAC0;
	sub_82B529E0(ctx, base);
loc_82B4BAC0:
	// stw r27,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r27.u32);
	// b 0x82b4bacc
	goto loc_82B4BACC;
loc_82B4BAC8:
	// stw r27,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r27.u32);
loc_82B4BACC:
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b4bb04
	if (!ctx.cr6.eq) goto loc_82B4BB04;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// bl 0x82b53080
	ctx.lr = 0x82B4BAE4;
	sub_82B53080(ctx, base);
	// addi r5,r31,640
	ctx.r5.s64 = ctx.r31.s64 + 640;
	// lwz r4,672(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 672);
	// lwz r3,632(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// stw r28,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r28.u32);
	// bl 0x82b53c98
	ctx.lr = 0x82B4BAF8;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4bdec
	if (ctx.cr0.lt) goto loc_82B4BDEC;
	// stw r27,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r27.u32);
loc_82B4BB04:
	// lwz r11,96(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r10,628(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// cmpwi r11,0
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r11,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r11.u32);
	// stw r10,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r10.u32);
	// beq 0x82b4bcac
	if (ctx.cr0.eq) goto loc_82B4BCAC;
	// addi r11,r31,640
	ctx.r11.s64 = ctx.r31.s64 + 640;
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// std r10,0(r29)
	PPC_STORE_U64(ctx.r29.u32 + 0, ctx.r10.u64);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// std r10,8(r29)
	PPC_STORE_U64(ctx.r29.u32 + 8, ctx.r10.u64);
	// ld r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// std r10,16(r29)
	PPC_STORE_U64(ctx.r29.u32 + 16, ctx.r10.u64);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r11,24(r29)
	PPC_STORE_U64(ctx.r29.u32 + 24, ctx.r11.u64);
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r11,92(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4bb54
	if (ctx.cr6.eq) goto loc_82B4BB54;
	// stw r21,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r21.u32);
loc_82B4BB54:
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b4bcec
	if (ctx.cr6.eq) goto loc_82B4BCEC;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82b4bdec
	goto loc_82B4BDEC;
loc_82B4BB6C:
	// cmpwi cr6,r7,13
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 13, ctx.xer);
	// beq cr6,0x82b4bcf4
	if (ctx.cr6.eq) goto loc_82B4BCF4;
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b4bbdc
	if (ctx.cr6.eq) goto loc_82B4BBDC;
	// cmpwi cr6,r7,9
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 9, ctx.xer);
	// bne cr6,0x82b4bbdc
	if (!ctx.cr6.eq) goto loc_82B4BBDC;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// lwz r4,8(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b48688
	ctx.lr = 0x82B4BB9C;
	sub_82B48688(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq 0x82b4bbdc
	if (ctx.cr0.eq) goto loc_82B4BBDC;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82b4be98
	ctx.lr = 0x82B4BBB8;
	sub_82B4BE98(ctx, base);
	// cmpwi cr6,r3,2
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 2, ctx.xer);
	// beq cr6,0x82b4bbdc
	if (ctx.cr6.eq) goto loc_82B4BBDC;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82b4bcac
	if (!ctx.cr6.eq) goto loc_82B4BCAC;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// stw r27,84(r31)
	PPC_STORE_U32(ctx.r31.u32 + 84, ctx.r27.u32);
	// stw r27,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r27.u32);
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82b4bdec
	goto loc_82B4BDEC;
loc_82B4BBDC:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b4bc8c
	if (!ctx.cr6.eq) goto loc_82B4BC8C;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r10,r26
	ctx.r10.u64 = ctx.r26.u64;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82B4BBF4:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4bc18
	if (ctx.cr0.eq) goto loc_82B4BC18;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4bbf4
	if (ctx.cr6.eq) goto loc_82B4BBF4;
loc_82B4BC18:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4bc44
	if (!ctx.cr0.eq) goto loc_82B4BC44;
	// li r11,10
	ctx.r11.s64 = 10;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// bne 0x82b4bc8c
	if (!ctx.cr0.eq) goto loc_82B4BC8C;
	// stw r22,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r22.u32);
	// b 0x82b4bc8c
	goto loc_82B4BC8C;
loc_82B4BC44:
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
loc_82B4BC4C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4bc70
	if (ctx.cr0.eq) goto loc_82B4BC70;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4bc4c
	if (ctx.cr6.eq) goto loc_82B4BC4C;
loc_82B4BC70:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4bc8c
	if (!ctx.cr0.eq) goto loc_82B4BC8C;
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
loc_82B4BC8C:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// subf r11,r21,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r21.s64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// stw r11,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r11.u32);
	// bne cr6,0x82b4bd60
	if (!ctx.cr6.eq) goto loc_82B4BD60;
loc_82B4BCAC:
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82b4b93c
	if (ctx.cr6.eq) goto loc_82B4B93C;
loc_82B4BCB8:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_82B4BCC0:
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// stw r11,16(r29)
	PPC_STORE_U32(ctx.r29.u32 + 16, ctx.r11.u32);
	// lwz r11,632(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 632);
	// lwz r11,28(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// stw r11,20(r29)
	PPC_STORE_U32(ctx.r29.u32 + 20, ctx.r11.u32);
	// li r11,13
	ctx.r11.s64 = 13;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
	// b 0x82b4bdec
	goto loc_82B4BDEC;
loc_82B4BCE4:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// b 0x82b4bcc0
	goto loc_82B4BCC0;
loc_82B4BCEC:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// b 0x82b4bdec
	goto loc_82B4BDEC;
loc_82B4BCF4:
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r11,56(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4bd1c
	if (ctx.cr6.eq) goto loc_82B4BD1C;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1502
	ctx.r5.s64 = 1502;
	// addi r6,r11,8312
	ctx.r6.s64 = ctx.r11.s64 + 8312;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B4BD1C;
	sub_82B529E0(ctx, base);
loc_82B4BD1C:
	// lwz r30,628(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// lwz r11,92(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4bde8
	if (ctx.cr6.eq) goto loc_82B4BDE8;
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r11,628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 628, ctx.r11.u32);
	// stw r28,92(r30)
	PPC_STORE_U32(ctx.r30.u32 + 92, ctx.r28.u32);
	// bl 0x82b488d0
	ctx.lr = 0x82B4BD40;
	sub_82B488D0(ctx, base);
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82547938
	ctx.lr = 0x82B4BD4C;
	sub_82547938(ctx, base);
	// lwz r11,628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 628);
	// stw r11,632(r31)
	PPC_STORE_U32(ctx.r31.u32 + 632, ctx.r11.u32);
	// stw r21,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r21.u32);
	// stw r27,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r27.u32);
	// b 0x82b4bde8
	goto loc_82B4BDE8;
loc_82B4BD60:
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4bde8
	if (ctx.cr0.eq) goto loc_82B4BDE8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b4bde8
	if (ctx.cr6.eq) goto loc_82B4BDE8;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82b4bdd0
	if (!ctx.cr6.eq) goto loc_82B4BDD0;
	// lbz r10,9(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 9);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82b4bdd0
	if (!ctx.cr6.eq) goto loc_82B4BDD0;
	// lbz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 8);
	// cmplwi cr6,r10,123
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 123, ctx.xer);
	// bne cr6,0x82b4bda8
	if (!ctx.cr6.eq) goto loc_82B4BDA8;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
loc_82B4BDA8:
	// lbz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 8);
	// cmplwi cr6,r11,125
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 125, ctx.xer);
	// bne cr6,0x82b4bdd0
	if (!ctx.cr6.eq) goto loc_82B4BDD0;
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b4bdd0
	if (ctx.cr6.eq) goto loc_82B4BDD0;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
loc_82B4BDD0:
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b4bde8
	if (!ctx.cr6.eq) goto loc_82B4BDE8;
	// li r11,13
	ctx.r11.s64 = 13;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
loc_82B4BDE8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B4BDEC:
	// addi r1,r1,3232
	ctx.r1.s64 = ctx.r1.s64 + 3232;
	// b 0x82e28e9c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4BDF8"))) PPC_WEAK_FUNC(sub_82B4BDF8);
PPC_FUNC_IMPL(__imp__sub_82B4BDF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b4be30
	if (!ctx.cr6.eq) goto loc_82B4BE30;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82b4be84
	goto loc_82B4BE84;
loc_82B4BE24:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82b4be48
	if (ctx.cr6.eq) goto loc_82B4BE48;
loc_82B4BE30:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b4b8e8
	ctx.lr = 0x82B4BE3C;
	sub_82B4B8E8(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bge 0x82b4be24
	if (!ctx.cr0.lt) goto loc_82B4BE24;
	// b 0x82b4be84
	goto loc_82B4BE84;
loc_82B4BE48:
	// lwz r3,116(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// li r11,0
	ctx.r11.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r10,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r10.u32);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// bl 0x82b48a10
	ctx.lr = 0x82B4BE64;
	sub_82B48A10(ctx, base);
	// lwz r11,116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4be78
	if (ctx.cr0.eq) goto loc_82B4BE78;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// b 0x82b4be7c
	goto loc_82B4BE7C;
loc_82B4BE78:
	// li r11,1
	ctx.r11.s64 = 1;
loc_82B4BE7C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,672(r31)
	PPC_STORE_U32(ctx.r31.u32 + 672, ctx.r11.u32);
loc_82B4BE84:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4BE98"))) PPC_WEAK_FUNC(sub_82B4BE98);
PPC_FUNC_IMPL(__imp__sub_82B4BE98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e40
	ctx.lr = 0x82B4BEA0;
	__savegprlr_18(ctx, base);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r18,0
	ctx.r18.s64 = 0;
	// mr r19,r5
	ctx.r19.u64 = ctx.r5.u64;
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// stw r18,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r18.u32);
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// stw r18,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r18.u32);
	// bne cr6,0x82b4bf1c
	if (!ctx.cr6.eq) goto loc_82B4BF1C;
	// addi r31,r1,80
	ctx.r31.s64 = ctx.r1.s64 + 80;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82b4bf10
	if (ctx.cr6.eq) goto loc_82B4BF10;
loc_82B4BED4:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4BEDC;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4bef0
	if (ctx.cr0.eq) goto loc_82B4BEF0;
	// addi r4,r27,16
	ctx.r4.s64 = ctx.r27.s64 + 16;
	// bl 0x82b845a8
	ctx.lr = 0x82B4BEEC;
	sub_82B845A8(ctx, base);
	// b 0x82b4bef4
	goto loc_82B4BEF4;
loc_82B4BEF0:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82B4BEF4:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82b4c794
	if (ctx.cr6.eq) goto loc_82B4C794;
	// lwz r27,12(r27)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// addi r31,r3,12
	ctx.r31.s64 = ctx.r3.s64 + 12;
	// cmplwi r27,0
	ctx.cr0.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne 0x82b4bed4
	if (!ctx.cr0.eq) goto loc_82B4BED4;
loc_82B4BF10:
	// lwz r11,112(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 112);
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// b 0x82b4c7d4
	goto loc_82B4C7D4;
loc_82B4BF1C:
	// lwz r7,112(r20)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r20.u32 + 112);
	// cmplwi r7,0
	ctx.cr0.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq 0x82b4bfa0
	if (ctx.cr0.eq) goto loc_82B4BFA0;
	// addi r11,r7,16
	ctx.r11.s64 = ctx.r7.s64 + 16;
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// std r10,640(r20)
	PPC_STORE_U64(ctx.r20.u32 + 640, ctx.r10.u64);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// lwz r9,640(r20)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r20.u32 + 640);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// std r10,648(r20)
	PPC_STORE_U64(ctx.r20.u32 + 648, ctx.r10.u64);
	// ld r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// std r10,656(r20)
	PPC_STORE_U64(ctx.r20.u32 + 656, ctx.r10.u64);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r11,664(r20)
	PPC_STORE_U64(ctx.r20.u32 + 664, ctx.r11.u64);
	// bne cr6,0x82b4c7e4
	if (!ctx.cr6.eq) goto loc_82B4C7E4;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r10,r11,-13528
	ctx.r10.s64 = ctx.r11.s64 + -13528;
	// addi r11,r20,648
	ctx.r11.s64 = ctx.r20.s64 + 648;
loc_82B4BF64:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4bf88
	if (ctx.cr0.eq) goto loc_82B4BF88;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4bf64
	if (ctx.cr6.eq) goto loc_82B4BF64;
loc_82B4BF88:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4c7e4
	if (!ctx.cr0.eq) goto loc_82B4C7E4;
	// lwz r11,12(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	// stw r11,112(r20)
	PPC_STORE_U32(ctx.r20.u32 + 112, ctx.r11.u32);
	// stw r18,12(r7)
	PPC_STORE_U32(ctx.r7.u32 + 12, ctx.r18.u32);
	// b 0x82b4c058
	goto loc_82B4C058;
loc_82B4BFA0:
	// lwz r3,632(r20)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r20.u32 + 632);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82b4bffc
	if (!ctx.cr6.lt) goto loc_82B4BFFC;
loc_82B4BFB4:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,32
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 32, ctx.xer);
	// beq cr6,0x82b4bfd4
	if (ctx.cr6.eq) goto loc_82B4BFD4;
	// cmpwi cr6,r10,9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 9, ctx.xer);
	// blt cr6,0x82b4bfe8
	if (ctx.cr6.lt) goto loc_82B4BFE8;
	// cmpwi cr6,r10,13
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 13, ctx.xer);
	// bgt cr6,0x82b4bfe8
	if (ctx.cr6.gt) goto loc_82B4BFE8;
loc_82B4BFD4:
	// lwz r10,632(r20)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r20.u32 + 632);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82b4bfb4
	if (ctx.cr6.lt) goto loc_82B4BFB4;
loc_82B4BFE8:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x82b4bffc
	if (!ctx.cr6.lt) goto loc_82B4BFFC;
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,40
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 40, ctx.xer);
	// bne cr6,0x82b4c7e4
	if (!ctx.cr6.eq) goto loc_82B4C7E4;
loc_82B4BFFC:
	// addi r31,r20,640
	ctx.r31.s64 = ctx.r20.s64 + 640;
	// lwz r4,672(r20)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r20.u32 + 672);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// bl 0x82b53c98
	ctx.lr = 0x82B4C00C;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4c7e4
	if (ctx.cr0.lt) goto loc_82B4C7E4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b4c7e4
	if (!ctx.cr6.eq) goto loc_82B4C7E4;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r10,r11,-13528
	ctx.r10.s64 = ctx.r11.s64 + -13528;
	// addi r11,r20,648
	ctx.r11.s64 = ctx.r20.s64 + 648;
loc_82B4C02C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4c050
	if (ctx.cr0.eq) goto loc_82B4C050;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4c02c
	if (ctx.cr6.eq) goto loc_82B4C02C;
loc_82B4C050:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4c7e4
	if (!ctx.cr0.eq) goto loc_82B4C7E4;
loc_82B4C058:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r29,1
	ctx.r29.s64 = 1;
	// addi r30,r1,84
	ctx.r30.s64 = ctx.r1.s64 + 84;
	// mr r31,r18
	ctx.r31.u64 = ctx.r18.u64;
	// addi r28,r11,8532
	ctx.r28.s64 = ctx.r11.s64 + 8532;
loc_82B4C06C:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82b4b8e8
	ctx.lr = 0x82B4C078;
	sub_82B4B8E8(ctx, base);
	// lwz r11,84(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 84);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82b4c794
	if (!ctx.cr6.eq) goto loc_82B4C794;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82b4c1f8
	if (ctx.cr6.eq) goto loc_82B4C1F8;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b4c0d4
	if (!ctx.cr6.eq) goto loc_82B4C0D4;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x82b83f88
	ctx.lr = 0x82B4C0A4;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4c0c0
	if (ctx.cr0.eq) goto loc_82B4C0C0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82b84150
	ctx.lr = 0x82B4C0BC;
	sub_82B84150(ctx, base);
	// b 0x82b4c0c4
	goto loc_82B4C0C4;
loc_82B4C0C0:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82B4C0C4:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82b4c794
	if (ctx.cr6.eq) goto loc_82B4C794;
	// addi r31,r3,8
	ctx.r31.s64 = ctx.r3.s64 + 8;
loc_82B4C0D4:
	// cmplwi cr6,r29,1
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 1, ctx.xer);
	// bne cr6,0x82b4c118
	if (!ctx.cr6.eq) goto loc_82B4C118;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b4c118
	if (!ctx.cr6.eq) goto loc_82B4C118;
	// lbz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 104);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,44
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 44, ctx.xer);
	// beq cr6,0x82b4c100
	if (ctx.cr6.eq) goto loc_82B4C100;
	// cmpwi cr6,r11,41
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 41, ctx.xer);
	// bne cr6,0x82b4c118
	if (!ctx.cr6.eq) goto loc_82B4C118;
loc_82B4C100:
	// lbz r11,105(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 105);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b4c118
	if (!ctx.cr0.eq) goto loc_82B4C118;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r30,r11,12
	ctx.r30.s64 = ctx.r11.s64 + 12;
	// b 0x82b4c154
	goto loc_82B4C154;
loc_82B4C118:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4C120;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4c134
	if (ctx.cr0.eq) goto loc_82B4C134;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82b845a8
	ctx.lr = 0x82B4C130;
	sub_82B845A8(ctx, base);
	// b 0x82b4c138
	goto loc_82B4C138;
loc_82B4C134:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82B4C138:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82b4c794
	if (ctx.cr6.eq) goto loc_82B4C794;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r31,r3,12
	ctx.r31.s64 = ctx.r3.s64 + 12;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82b4c1a4
	if (!ctx.cr6.eq) goto loc_82B4C1A4;
loc_82B4C154:
	// lbz r11,105(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 105);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b4c1a4
	if (!ctx.cr0.eq) goto loc_82B4C1A4;
	// lbz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 104);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,40
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 40, ctx.xer);
	// beq cr6,0x82b4c1a0
	if (ctx.cr6.eq) goto loc_82B4C1A0;
	// cmpwi cr6,r11,41
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 41, ctx.xer);
	// beq cr6,0x82b4c198
	if (ctx.cr6.eq) goto loc_82B4C198;
	// cmpwi cr6,r11,91
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 91, ctx.xer);
	// beq cr6,0x82b4c1a0
	if (ctx.cr6.eq) goto loc_82B4C1A0;
	// cmpwi cr6,r11,93
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 93, ctx.xer);
	// beq cr6,0x82b4c198
	if (ctx.cr6.eq) goto loc_82B4C198;
	// cmpwi cr6,r11,123
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 123, ctx.xer);
	// beq cr6,0x82b4c1a0
	if (ctx.cr6.eq) goto loc_82B4C1A0;
	// cmpwi cr6,r11,125
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 125, ctx.xer);
	// bne cr6,0x82b4c1a4
	if (!ctx.cr6.eq) goto loc_82B4C1A4;
loc_82B4C198:
	// addi r29,r29,-1
	ctx.r29.s64 = ctx.r29.s64 + -1;
	// b 0x82b4c1a4
	goto loc_82B4C1A4;
loc_82B4C1A0:
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
loc_82B4C1A4:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82b4c06c
	if (!ctx.cr6.eq) goto loc_82B4C06C;
	// lwz r21,84(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r10,r19
	ctx.r10.u64 = ctx.r19.u64;
	// mr r11,r21
	ctx.r11.u64 = ctx.r21.u64;
loc_82B4C1B8:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4c1dc
	if (ctx.cr6.eq) goto loc_82B4C1DC;
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82b4c1dc
	if (ctx.cr6.eq) goto loc_82B4C1DC;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne 0x82b4c1b8
	if (!ctx.cr0.eq) goto loc_82B4C1B8;
loc_82B4C1DC:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b4c238
	if (ctx.cr6.eq) goto loc_82B4C238;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b4c214
	if (!ctx.cr6.eq) goto loc_82B4C214;
	// lwz r7,8(r26)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// b 0x82b4c21c
	goto loc_82B4C21C;
loc_82B4C1F8:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r5,1515
	ctx.r5.s64 = 1515;
	// addi r6,r11,8488
	ctx.r6.s64 = ctx.r11.s64 + 8488;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// addi r3,r20,24
	ctx.r3.s64 = ctx.r20.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B4C210;
	sub_82B529E0(ctx, base);
	// b 0x82b4c794
	goto loc_82B4C794;
loc_82B4C214:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r7,r11,-4532
	ctx.r7.s64 = ctx.r11.s64 + -4532;
loc_82B4C21C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r6,r11,8444
	ctx.r6.s64 = ctx.r11.s64 + 8444;
loc_82B4C224:
	// li r5,1516
	ctx.r5.s64 = 1516;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// addi r3,r20,24
	ctx.r3.s64 = ctx.r20.s64 + 24;
	// bl 0x82b529e0
	ctx.lr = 0x82B4C234;
	sub_82B529E0(ctx, base);
	// b 0x82b4c794
	goto loc_82B4C794;
loc_82B4C238:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4c268
	if (ctx.cr6.eq) goto loc_82B4C268;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b4c254
	if (!ctx.cr6.eq) goto loc_82B4C254;
	// lwz r7,8(r26)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// b 0x82b4c25c
	goto loc_82B4C25C;
loc_82B4C254:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r7,r11,-4532
	ctx.r7.s64 = ctx.r11.s64 + -4532;
loc_82B4C25C:
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r6,r11,8408
	ctx.r6.s64 = ctx.r11.s64 + 8408;
	// b 0x82b4c224
	goto loc_82B4C224;
loc_82B4C268:
	// mr r28,r18
	ctx.r28.u64 = ctx.r18.u64;
	// mr r29,r18
	ctx.r29.u64 = ctx.r18.u64;
	// mr r25,r18
	ctx.r25.u64 = ctx.r18.u64;
	// addi r30,r1,80
	ctx.r30.s64 = ctx.r1.s64 + 80;
	// mr r24,r27
	ctx.r24.u64 = ctx.r27.u64;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82b4c5b8
	if (ctx.cr6.eq) goto loc_82B4C5B8;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r23,r11,8404
	ctx.r23.s64 = ctx.r11.s64 + 8404;
	// lis r11,-32242
	ctx.r11.s64 = -2113011712;
	// addi r22,r11,9060
	ctx.r22.s64 = ctx.r11.s64 + 9060;
loc_82B4C294:
	// addi r31,r24,16
	ctx.r31.s64 = ctx.r24.s64 + 16;
	// mr r26,r30
	ctx.r26.u64 = ctx.r30.u64;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82b4c340
	if (!ctx.cr6.eq) goto loc_82B4C340;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// bne cr6,0x82b4c340
	if (!ctx.cr6.eq) goto loc_82B4C340;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82b4c340
	if (!ctx.cr6.eq) goto loc_82B4C340;
	// addi r11,r31,8
	ctx.r11.s64 = ctx.r31.s64 + 8;
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
loc_82B4C2C0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4c2e4
	if (ctx.cr0.eq) goto loc_82B4C2E4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4c2c0
	if (ctx.cr6.eq) goto loc_82B4C2C0;
loc_82B4C2E4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4c2f8
	if (!ctx.cr0.eq) goto loc_82B4C2F8;
	// mr r25,r31
	ctx.r25.u64 = ctx.r31.u64;
	// li r28,1
	ctx.r28.s64 = 1;
	// b 0x82b4c5ac
	goto loc_82B4C5AC;
loc_82B4C2F8:
	// cmpwi cr6,r7,1
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 1, ctx.xer);
	// bne cr6,0x82b4c340
	if (!ctx.cr6.eq) goto loc_82B4C340;
	// addi r11,r31,8
	ctx.r11.s64 = ctx.r31.s64 + 8;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_82B4C308:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4c32c
	if (ctx.cr0.eq) goto loc_82B4C32C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4c308
	if (ctx.cr6.eq) goto loc_82B4C308;
loc_82B4C32C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4c340
	if (!ctx.cr0.eq) goto loc_82B4C340;
	// mr r25,r31
	ctx.r25.u64 = ctx.r31.u64;
	// li r29,1
	ctx.r29.s64 = 1;
	// b 0x82b4c5ac
	goto loc_82B4C5AC;
loc_82B4C340:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82b4c3ec
	if (!ctx.cr6.eq) goto loc_82B4C3EC;
	// lwz r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r8,r19
	ctx.r8.u64 = ctx.r19.u64;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
loc_82B4C358:
	// lwz r11,24(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
loc_82B4C360:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r7,r7,r9
	ctx.r7.s64 = ctx.r9.s64 - ctx.r7.s64;
	// beq 0x82b4c384
	if (ctx.cr0.eq) goto loc_82B4C384;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x82b4c360
	if (ctx.cr6.eq) goto loc_82B4C360;
loc_82B4C384:
	// cmpwi r7,0
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82b4c39c
	if (ctx.cr0.eq) goto loc_82B4C39C;
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// lwz r5,12(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// cmplwi r8,0
	ctx.cr0.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne 0x82b4c358
	if (!ctx.cr0.eq) goto loc_82B4C358;
loc_82B4C39C:
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82b4c3ec
	if (ctx.cr6.eq) goto loc_82B4C3EC;
	// lwz r31,8(r5)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// b 0x82b4c3e0
	goto loc_82B4C3E0;
loc_82B4C3AC:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4C3B4;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4c3c8
	if (ctx.cr0.eq) goto loc_82B4C3C8;
	// addi r4,r31,16
	ctx.r4.s64 = ctx.r31.s64 + 16;
	// bl 0x82b845a8
	ctx.lr = 0x82B4C3C4;
	sub_82B845A8(ctx, base);
	// b 0x82b4c3cc
	goto loc_82B4C3CC;
loc_82B4C3C8:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82B4C3CC:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82b4c794
	if (ctx.cr6.eq) goto loc_82B4C794;
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r30,r3,12
	ctx.r30.s64 = ctx.r3.s64 + 12;
loc_82B4C3E0:
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82b4c3ac
	if (!ctx.cr0.eq) goto loc_82B4C3AC;
	// b 0x82b4c41c
	goto loc_82B4C41C;
loc_82B4C3EC:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4C3F4;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4c408
	if (ctx.cr0.eq) goto loc_82B4C408;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82b845a8
	ctx.lr = 0x82B4C404;
	sub_82B845A8(ctx, base);
	// b 0x82b4c40c
	goto loc_82B4C40C;
loc_82B4C408:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82B4C40C:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// beq cr6,0x82b4c794
	if (ctx.cr6.eq) goto loc_82B4C794;
	// addi r30,r3,12
	ctx.r30.s64 = ctx.r3.s64 + 12;
loc_82B4C41C:
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82b4c42c
	if (!ctx.cr6.eq) goto loc_82B4C42C;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82b4c5ac
	if (ctx.cr6.eq) goto loc_82B4C5AC;
loc_82B4C42C:
	// lwz r31,0(r26)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
	// li r30,1
	ctx.r30.s64 = 1;
	// b 0x82b4c480
	goto loc_82B4C480;
loc_82B4C43C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4c454
	if (ctx.cr6.eq) goto loc_82B4C454;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b4c454
	if (ctx.cr6.eq) goto loc_82B4C454;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82B4C454:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,44(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82b48758
	ctx.lr = 0x82B4C46C;
	sub_82B48758(ctx, base);
	// lwz r11,44(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// add r30,r3,r30
	ctx.r30.u64 = ctx.r3.u64 + ctx.r30.u64;
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82B4C480:
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82b4c43c
	if (!ctx.cr0.eq) goto loc_82B4C43C;
	// addi r4,r30,1
	ctx.r4.s64 = ctx.r30.s64 + 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// bl 0x82b83e40
	ctx.lr = 0x82B4C49C;
	sub_82B83E40(ctx, base);
	// mr. r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq 0x82b4c794
	if (ctx.cr0.eq) goto loc_82B4C794;
	// subfic r10,r28,0
	ctx.xer.ca = ctx.r28.u32 <= 0;
	ctx.r10.s64 = 0 - ctx.r28.s64;
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// li r30,1
	ctx.r30.s64 = 1;
	// rlwinm r10,r10,0,30,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// addi r28,r10,39
	ctx.r28.s64 = ctx.r10.s64 + 39;
	// stb r28,0(r29)
	PPC_STORE_U8(ctx.r29.u32 + 0, ctx.r28.u8);
	// lwz r31,0(r26)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// b 0x82b4c514
	goto loc_82B4C514;
loc_82B4C4C8:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4c4e8
	if (ctx.cr6.eq) goto loc_82B4C4E8;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b4c4e8
	if (ctx.cr6.eq) goto loc_82B4C4E8;
	// li r11,32
	ctx.r11.s64 = 32;
	// stbx r11,r29,r30
	PPC_STORE_U8(ctx.r29.u32 + ctx.r30.u32, ctx.r11.u8);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82B4C4E8:
	// subf r7,r30,r27
	ctx.r7.s64 = ctx.r27.s64 - ctx.r30.s64;
	// lwz r5,44(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// add r6,r29,r30
	ctx.r6.u64 = ctx.r29.u64 + ctx.r30.u64;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x82b48758
	ctx.lr = 0x82B4C500;
	sub_82B48758(ctx, base);
	// lwz r11,44(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// add r30,r3,r30
	ctx.r30.u64 = ctx.r3.u64 + ctx.r30.u64;
	// lwz r31,12(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82B4C514:
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82b4c4c8
	if (!ctx.cr0.eq) goto loc_82B4C4C8;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stbx r28,r29,r30
	PPC_STORE_U8(ctx.r29.u32 + ctx.r30.u32, ctx.r28.u8);
	// bl 0x82b51e10
	ctx.lr = 0x82B4C528;
	sub_82B51E10(ctx, base);
	// addi r9,r20,24
	ctx.r9.s64 = ctx.r20.s64 + 24;
	// mr r8,r20
	ctx.r8.u64 = ctx.r20.u64;
	// lwz r7,20(r25)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r25.u32 + 20);
	// addi r5,r30,1
	ctx.r5.s64 = ctx.r30.s64 + 1;
	// lwz r6,16(r25)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r25.u32 + 16);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82b51e38
	ctx.lr = 0x82B4C548;
	sub_82B51E38(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// blt 0x82b4c790
	if (ctx.cr0.lt) goto loc_82B4C790;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r4,672(r20)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r20.u32 + 672);
	// bl 0x82b53c98
	ctx.lr = 0x82B4C560;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4c78c
	if (ctx.cr0.lt) goto loc_82B4C78C;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4C570;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4c588
	if (ctx.cr0.eq) goto loc_82B4C588;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82b845a8
	ctx.lr = 0x82B4C580;
	sub_82B845A8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// b 0x82b4c58c
	goto loc_82B4C58C;
loc_82B4C588:
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
loc_82B4C58C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// beq cr6,0x82b4c790
	if (ctx.cr6.eq) goto loc_82B4C790;
	// addi r30,r11,12
	ctx.r30.s64 = ctx.r11.s64 + 12;
	// mr r29,r18
	ctx.r29.u64 = ctx.r18.u64;
	// mr r28,r18
	ctx.r28.u64 = ctx.r18.u64;
	// bl 0x8224ad48
	ctx.lr = 0x82B4C5AC;
	sub_8224AD48(ctx, base);
loc_82B4C5AC:
	// lwz r24,12(r24)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r24.u32 + 12);
	// cmplwi r24,0
	ctx.cr0.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// bne 0x82b4c294
	if (!ctx.cr0.eq) goto loc_82B4C294;
loc_82B4C5B8:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4c7cc
	if (ctx.cr6.eq) goto loc_82B4C7CC;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// addi r24,r11,8400
	ctx.r24.s64 = ctx.r11.s64 + 8400;
loc_82B4C5D0:
	// lwz r26,0(r25)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmplwi r26,0
	ctx.cr0.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq 0x82b4c5e4
	if (ctx.cr0.eq) goto loc_82B4C5E4;
	// lwz r10,12(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// b 0x82b4c5e8
	goto loc_82B4C5E8;
loc_82B4C5E4:
	// mr r10,r18
	ctx.r10.u64 = ctx.r18.u64;
loc_82B4C5E8:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b4c5f8
	if (ctx.cr6.eq) goto loc_82B4C5F8;
	// lwz r27,12(r10)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// b 0x82b4c5fc
	goto loc_82B4C5FC;
loc_82B4C5F8:
	// mr r27,r18
	ctx.r27.u64 = ctx.r18.u64;
loc_82B4C5FC:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// addi r29,r26,16
	ctx.r29.s64 = ctx.r26.s64 + 16;
	// bne cr6,0x82b4c60c
	if (!ctx.cr6.eq) goto loc_82B4C60C;
	// mr r29,r18
	ctx.r29.u64 = ctx.r18.u64;
loc_82B4C60C:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r11,r10,16
	ctx.r11.s64 = ctx.r10.s64 + 16;
	// bne cr6,0x82b4c61c
	if (!ctx.cr6.eq) goto loc_82B4C61C;
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
loc_82B4C61C:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// addi r28,r27,16
	ctx.r28.s64 = ctx.r27.s64 + 16;
	// bne cr6,0x82b4c62c
	if (!ctx.cr6.eq) goto loc_82B4C62C;
	// mr r28,r18
	ctx.r28.u64 = ctx.r18.u64;
loc_82B4C62C:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82b4c7bc
	if (ctx.cr6.eq) goto loc_82B4C7BC;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82b4c7bc
	if (ctx.cr6.eq) goto loc_82B4C7BC;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82b4c7bc
	if (ctx.cr6.eq) goto loc_82B4C7BC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82b4c7bc
	if (!ctx.cr6.eq) goto loc_82B4C7BC;
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
loc_82B4C658:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi r9,0
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq 0x82b4c67c
	if (ctx.cr0.eq) goto loc_82B4C67C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82b4c658
	if (ctx.cr6.eq) goto loc_82B4C658;
loc_82B4C67C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4c7bc
	if (!ctx.cr0.eq) goto loc_82B4C7BC;
	// lwz r11,28(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r10,28(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// add r30,r11,r10
	ctx.r30.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82b83e40
	ctx.lr = 0x82B4C6A0;
	sub_82B83E40(ctx, base);
	// mr. r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq 0x82b4c794
	if (ctx.cr0.eq) goto loc_82B4C794;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,28(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// lwz r4,24(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// bl 0x82e28fd0
	ctx.lr = 0x82B4C6B8;
	sub_82E28FD0(ctx, base);
	// lwz r11,28(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// lwz r5,28(r28)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// add r3,r11,r31
	ctx.r3.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r4,24(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// bl 0x82e28fd0
	ctx.lr = 0x82B4C6CC;
	sub_82E28FD0(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82b51e10
	ctx.lr = 0x82B4C6D4;
	sub_82B51E10(ctx, base);
	// addi r9,r20,24
	ctx.r9.s64 = ctx.r20.s64 + 24;
	// mr r8,r20
	ctx.r8.u64 = ctx.r20.u64;
	// lwz r7,20(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,16(r29)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82b51e38
	ctx.lr = 0x82B4C6F4;
	sub_82B51E38(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4c78c
	if (ctx.cr0.lt) goto loc_82B4C78C;
	// lwz r30,12(r27)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// mr r31,r26
	ctx.r31.u64 = ctx.r26.u64;
loc_82B4C704:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r4,672(r20)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r20.u32 + 672);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82b53c98
	ctx.lr = 0x82B4C714;
	sub_82B53C98(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4c78c
	if (ctx.cr0.lt) goto loc_82B4C78C;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82b4c79c
	if (ctx.cr6.eq) goto loc_82B4C79C;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b4c760
	if (ctx.cr6.eq) goto loc_82B4C760;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r31,16
	ctx.r10.s64 = ctx.r31.s64 + 16;
	// mr r31,r18
	ctx.r31.u64 = ctx.r18.u64;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// ld r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// ld r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// std r8,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r8.u64);
	// std r7,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.r7.u64);
	// std r11,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r11.u64);
	// b 0x82b4c704
	goto loc_82B4C704;
loc_82B4C760:
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82b83f88
	ctx.lr = 0x82B4C768;
	sub_82B83F88(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4c77c
	if (ctx.cr0.eq) goto loc_82B4C77C;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x82b845a8
	ctx.lr = 0x82B4C778;
	sub_82B845A8(ctx, base);
	// b 0x82b4c780
	goto loc_82B4C780;
loc_82B4C77C:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
loc_82B4C780:
	// stw r3,12(r26)
	PPC_STORE_U32(ctx.r26.u32 + 12, ctx.r3.u32);
	// mr. r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r26.s32, 0, ctx.xer);
	// bne 0x82b4c704
	if (!ctx.cr0.eq) goto loc_82B4C704;
loc_82B4C78C:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
loc_82B4C790:
	// bl 0x8224ad48
	ctx.lr = 0x82B4C794;
	sub_8224AD48(ctx, base);
loc_82B4C794:
	// mr r3,r18
	ctx.r3.u64 = ctx.r18.u64;
	// b 0x82b4c7e8
	goto loc_82B4C7E8;
loc_82B4C79C:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82b4c7ac
	if (!ctx.cr6.eq) goto loc_82B4C7AC;
	// stw r30,12(r26)
	PPC_STORE_U32(ctx.r26.u32 + 12, ctx.r30.u32);
	// b 0x82b4c7b0
	goto loc_82B4C7B0;
loc_82B4C7AC:
	// stw r30,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r30.u32);
loc_82B4C7B0:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8224ad48
	ctx.lr = 0x82B4C7B8;
	sub_8224AD48(ctx, base);
	// b 0x82b4c7c0
	goto loc_82B4C7C0;
loc_82B4C7BC:
	// addi r25,r26,12
	ctx.r25.s64 = ctx.r26.s64 + 12;
loc_82B4C7C0:
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82b4c5d0
	if (!ctx.cr6.eq) goto loc_82B4C5D0;
loc_82B4C7CC:
	// lwz r11,112(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 112);
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
loc_82B4C7D4:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,112(r20)
	PPC_STORE_U32(ctx.r20.u32 + 112, ctx.r11.u32);
	// b 0x82b4c7e8
	goto loc_82B4C7E8;
loc_82B4C7E4:
	// li r3,2
	ctx.r3.s64 = 2;
loc_82B4C7E8:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x82e28e90
	__restgprlr_18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4C7F0"))) PPC_WEAK_FUNC(sub_82B4C7F0);
PPC_FUNC_IMPL(__imp__sub_82B4C7F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r31,r11,-1
	ctx.r31.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// bne cr6,0x82b4c828
	if (!ctx.cr6.eq) goto loc_82B4C828;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B4C828;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82B4C828:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4C840"))) PPC_WEAK_FUNC(sub_82B4C840);
PPC_FUNC_IMPL(__imp__sub_82B4C840) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82547910
	ctx.lr = 0x82B4C868;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r3,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r3.u32);
	// bne 0x82b4c880
	if (!ctx.cr0.eq) goto loc_82B4C880;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b4c888
	goto loc_82B4C888;
loc_82B4C880:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
loc_82B4C888:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4C8A0"))) PPC_WEAK_FUNC(sub_82B4C8A0);
PPC_FUNC_IMPL(__imp__sub_82B4C8A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,32124
	ctx.r10.s64 = ctx.r10.s64 + 32124;
	// stw r9,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r9.u32);
	// addi r9,r11,16
	ctx.r9.s64 = ctx.r11.s64 + 16;
loc_82B4C8C4:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4c8e4
	if (!ctx.cr0.eq) goto loc_82B4C8E4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82b4c8c4
	if (!ctx.cr6.eq) goto loc_82B4C8C4;
loc_82B4C8E4:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b4c924
	if (ctx.cr0.eq) goto loc_82B4C924;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r11,16
	ctx.r9.s64 = ctx.r11.s64 + 16;
	// addi r10,r10,32092
	ctx.r10.s64 = ctx.r10.s64 + 32092;
loc_82B4C8FC:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4c91c
	if (!ctx.cr0.eq) goto loc_82B4C91C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82b4c8fc
	if (!ctx.cr6.eq) goto loc_82B4C8FC;
loc_82B4C91C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4c940
	if (!ctx.cr0.eq) goto loc_82B4C940;
loc_82B4C924:
	// stw r3,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r3.u32);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B4C938;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b4c948
	goto loc_82B4C948;
loc_82B4C940:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16386
	ctx.r3.u64 = ctx.r3.u64 | 16386;
loc_82B4C948:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4C958"))) PPC_WEAK_FUNC(sub_82B4C958);
PPC_FUNC_IMPL(__imp__sub_82B4C958) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,8536
	ctx.r11.s64 = ctx.r11.s64 + 8536;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// bl 0x82547938
	ctx.lr = 0x82B4C98C;
	sub_82547938(ctx, base);
	// clrlwi. r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq 0x82b4c9a0
	if (ctx.cr0.eq) goto loc_82B4C9A0;
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82547938
	ctx.lr = 0x82B4C9A0;
	sub_82547938(ctx, base);
loc_82B4C9A0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4C9C0"))) PPC_WEAK_FUNC(sub_82B4C9C0);
PPC_FUNC_IMPL(__imp__sub_82B4C9C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B4C9C8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82b4c9e8
	if (!ctx.cr6.eq) goto loc_82B4C9E8;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82b4ca84
	goto loc_82B4CA84;
loc_82B4C9E8:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// li r3,16
	ctx.r3.s64 = 16;
	// bl 0x82547910
	ctx.lr = 0x82B4C9F4;
	sub_82547910(ctx, base);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4ca24
	if (ctx.cr0.eq) goto loc_82B4CA24;
	// lis r11,-32239
	ctx.r11.s64 = -2112815104;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,8536
	ctx.r11.s64 = ctx.r11.s64 + 8536;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// b 0x82b4ca28
	goto loc_82B4CA28;
loc_82B4CA24:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82B4CA28:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82b4ca3c
	if (!ctx.cr6.eq) goto loc_82B4CA3C;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x82b4ca84
	goto loc_82B4CA84;
loc_82B4CA3C:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B4CA54;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr. r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bge 0x82b4ca7c
	if (!ctx.cr0.lt) goto loc_82B4CA7C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B4CA74;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// b 0x82b4ca84
	goto loc_82B4CA84;
loc_82B4CA7C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r31,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r31.u32);
loc_82B4CA84:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4CA90"))) PPC_WEAK_FUNC(sub_82B4CA90);
PPC_FUNC_IMPL(__imp__sub_82B4CA90) {
	PPC_FUNC_PROLOGUE();
	// b 0x82b4c9c0
	sub_82B4C9C0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4CA98"))) PPC_WEAK_FUNC(sub_82B4CA98);
PPC_FUNC_IMPL(__imp__sub_82B4CA98) {
	PPC_FUNC_PROLOGUE();
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82b4caa8
	if (ctx.cr6.eq) goto loc_82B4CAA8;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
loc_82B4CAA8:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82b4cab4
	if (ctx.cr6.eq) goto loc_82B4CAB4;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82B4CAB4:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82b4cac8
	if (!ctx.cr6.eq) goto loc_82B4CAC8;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// blr 
	return;
loc_82B4CAC8:
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r11,4138
	ctx.r11.s64 = 271187968;
	// ori r11,r11,4352
	ctx.r11.u64 = ctx.r11.u64 | 4352;
	// rlwinm r10,r8,0,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFF00;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82b4cae8
	if (!ctx.cr6.eq) goto loc_82B4CAE8;
loc_82B4CAE0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82B4CAE8:
	// rlwinm r11,r8,0,0,15
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFF0000;
	// lis r10,18008
	ctx.r10.s64 = 1180172288;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b4cb40
	if (ctx.cr6.eq) goto loc_82B4CB40;
	// lis r10,21592
	ctx.r10.s64 = 1415053312;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b4cb40
	if (ctx.cr6.eq) goto loc_82B4CB40;
	// lis r10,32766
	ctx.r10.s64 = 2147352576;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b4cb40
	if (ctx.cr6.eq) goto loc_82B4CB40;
	// lis r10,32767
	ctx.r10.s64 = 2147418112;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b4cb40
	if (ctx.cr6.eq) goto loc_82B4CB40;
	// lis r10,-2
	ctx.r10.s64 = -131072;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b4cb40
	if (ctx.cr6.eq) goto loc_82B4CB40;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82b4cb40
	if (ctx.cr6.eq) goto loc_82B4CB40;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2905
	ctx.r3.u64 = ctx.r3.u64 | 2905;
	// blr 
	return;
loc_82B4CB40:
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
loc_82B4CB44:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// rlwinm. r9,r10,0,0,0
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne 0x82b4cba8
	if (!ctx.cr0.eq) goto loc_82B4CBA8;
	// clrlwi r9,r10,16
	ctx.r9.u64 = ctx.r10.u32 & 0xFFFF;
	// cmplwi cr6,r9,65535
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 65535, ctx.xer);
	// beq cr6,0x82b4cae0
	if (ctx.cr6.eq) goto loc_82B4CAE0;
	// cmplwi cr6,r9,65534
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 65534, ctx.xer);
	// bne cr6,0x82b4cb88
	if (!ctx.cr6.eq) goto loc_82B4CB88;
	// rlwinm r10,r10,16,17,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0x7FFF;
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// ble cr6,0x82b4cb7c
	if (!ctx.cr6.gt) goto loc_82B4CB7C;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplw cr6,r4,r9
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82b4cbb0
	if (ctx.cr6.eq) goto loc_82B4CBB0;
loc_82B4CB7C:
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_82B4CB80:
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// b 0x82b4cba8
	goto loc_82B4CBA8;
loc_82B4CB88:
	// clrlwi r7,r8,16
	ctx.r7.u64 = ctx.r8.u32 & 0xFFFF;
	// cmplwi cr6,r7,512
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 512, ctx.xer);
	// blt cr6,0x82b4cb9c
	if (ctx.cr6.lt) goto loc_82B4CB9C;
	// rlwinm r10,r10,10,26,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x3C;
	// b 0x82b4cb80
	goto loc_82B4CB80;
loc_82B4CB9C:
	// cmplwi cr6,r9,81
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 81, ctx.xer);
	// bne cr6,0x82b4cba8
	if (!ctx.cr6.eq) goto loc_82B4CBA8;
	// addi r11,r11,20
	ctx.r11.s64 = ctx.r11.s64 + 20;
loc_82B4CBA8:
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// b 0x82b4cb44
	goto loc_82B4CB44;
loc_82B4CBB0:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82b4cbc0
	if (ctx.cr6.eq) goto loc_82B4CBC0;
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
loc_82B4CBC0:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82b4cbd4
	if (ctx.cr6.eq) goto loc_82B4CBD4;
	// addi r11,r10,-1
	ctx.r11.s64 = ctx.r10.s64 + -1;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82B4CBD4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4CBE0"))) PPC_WEAK_FUNC(sub_82B4CBE0);
PPC_FUNC_IMPL(__imp__sub_82B4CBE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e58
	ctx.lr = 0x82B4CBE8;
	__savegprlr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r25,r4
	ctx.r25.u64 = ctx.r4.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r30,r7
	ctx.r30.u64 = ctx.r7.u64;
	// lhz r11,10(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// mr r24,r8
	ctx.r24.u64 = ctx.r8.u64;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4cc74
	if (ctx.cr0.eq) goto loc_82B4CC74;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r9,8(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// beq cr6,0x82b4cce4
	if (ctx.cr6.eq) goto loc_82B4CCE4;
	// addi r26,r10,4
	ctx.r26.s64 = ctx.r10.s64 + 4;
loc_82B4CC2C:
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq 0x82b4cc5c
	if (ctx.cr0.eq) goto loc_82B4CC5C;
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// add r5,r10,r11
	ctx.r5.u64 = ctx.r10.u64 + ctx.r11.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lhz r11,8(r5)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r5.u32 + 8);
	// mullw r6,r11,r28
	ctx.r6.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// bl 0x82b4cbe0
	ctx.lr = 0x82B4CC5C;
	sub_82B4CBE0(ctx, base);
loc_82B4CC5C:
	// lhz r11,10(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 10);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// addi r26,r26,8
	ctx.r26.s64 = ctx.r26.s64 + 8;
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b4cc2c
	if (ctx.cr6.lt) goto loc_82B4CC2C;
	// b 0x82b4cce4
	goto loc_82B4CCE4;
loc_82B4CC74:
	// lhz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r25.u32 + 4);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b4cc8c
	if (!ctx.cr0.eq) goto loc_82B4CC8C;
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// b 0x82b4ccb4
	goto loc_82B4CCB4;
loc_82B4CC8C:
	// lhz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// beq cr6,0x82b4cca4
	if (ctx.cr6.eq) goto loc_82B4CCA4;
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// b 0x82b4ccac
	goto loc_82B4CCAC;
loc_82B4CCA4:
	// lhz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lhz r9,6(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
loc_82B4CCAC:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// srawi r11,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 2;
loc_82B4CCB4:
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lhz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 4);
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// mullw r11,r11,r28
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r28.s32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r11,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r11.u32);
loc_82B4CCE4:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82e28ea8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4CCF0"))) PPC_WEAK_FUNC(sub_82B4CCF0);
PPC_FUNC_IMPL(__imp__sub_82B4CCF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B4CCF8;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// addi r9,r31,4
	ctx.r9.s64 = ctx.r31.s64 + 4;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// li r11,5
	ctx.r11.s64 = 5;
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_82B4CD20:
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r11.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x82b4cd20
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82B4CD20;
	// li r30,0
	ctx.r30.s64 = 0;
	// stw r7,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r7.u32);
	// addi r11,r31,44
	ctx.r11.s64 = ctx.r31.s64 + 44;
	// stw r8,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r8.u32);
	// addi r10,r31,52
	ctx.r10.s64 = ctx.r31.s64 + 52;
	// stw r29,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r29.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// stw r30,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r30.u32);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// stw r30,44(r31)
	PPC_STORE_U32(ctx.r31.u32 + 44, ctx.r30.u32);
	// stw r30,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r30.u32);
	// bl 0x82b4cbe0
	ctx.lr = 0x82B4CD6C;
	sub_82B4CBE0(ctx, base);
	// lhz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r29.u32 + 8);
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r9,52(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// stw r11,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r11.u32);
	// lhz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r29.u32 + 8);
	// stw r30,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r30.u32);
	// stw r30,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r30.u32);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// stw r30,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r30.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4CDA8"))) PPC_WEAK_FUNC(sub_82B4CDA8);
PPC_FUNC_IMPL(__imp__sub_82B4CDA8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B4CDB0;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// lwz r11,24(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// stw r29,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r29.u32);
	// lhz r11,10(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4ce3c
	if (ctx.cr0.eq) goto loc_82B4CE3C;
	// lwz r10,56(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// li r31,0
	ctx.r31.s64 = 0;
loc_82B4CDDC:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwzx r3,r31,r10
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r10.u32);
	// bl 0x82b4cda8
	ctx.lr = 0x82B4CDE8;
	sub_82B4CDA8(ctx, base);
	// lwz r10,56(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwzx r11,r31,r10
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r10.u32);
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4ce04
	if (ctx.cr0.eq) goto loc_82B4CE04;
	// li r9,4
	ctx.r9.s64 = 4;
loc_82B4CE04:
	// lwzx r11,r31,r10
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r10.u32);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lwz r8,24(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// lwz r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lhz r8,10(r8)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r8.u32 + 10);
	// lwz r11,44(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	// cmplw cr6,r28,r8
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r8.u32, ctx.xer);
	// lhz r8,8(r7)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r7.u32 + 8);
	// mullw r11,r8,r11
	ctx.r11.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// blt cr6,0x82b4cddc
	if (ctx.cr6.lt) goto loc_82B4CDDC;
loc_82B4CE3C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4CE48"))) PPC_WEAK_FUNC(sub_82B4CE48);
PPC_FUNC_IMPL(__imp__sub_82B4CE48) {
	PPC_FUNC_PROLOGUE();
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r9,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r9.u32);
	// stw r9,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r9.u32);
	// stw r9,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r9.u32);
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4ce74
	if (ctx.cr0.eq) goto loc_82B4CE74;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// b 0x82b4ce78
	goto loc_82B4CE78;
loc_82B4CE74:
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
loc_82B4CE78:
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// lhz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 8);
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r11.u32);
	// lhz r11,10(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 10);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
	// lhz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 12);
	// stw r11,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, ctx.r11.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lhz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// stw r11,16(r4)
	PPC_STORE_U32(ctx.r4.u32 + 16, ctx.r11.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lhz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 2);
	// stw r11,20(r4)
	PPC_STORE_U32(ctx.r4.u32 + 20, ctx.r11.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lhz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 4);
	// stw r11,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r11.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r10,24(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// lhz r11,6(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 6);
	// stw r11,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, ctx.r11.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r8,28(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// stw r11,32(r4)
	PPC_STORE_U32(ctx.r4.u32 + 32, ctx.r11.u32);
	// rotlwi r11,r11,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// lwz r7,24(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mullw r11,r11,r10
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// lhz r10,10(r7)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r7.u32 + 10);
	// mullw r11,r11,r8
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r8.s32);
	// stw r10,36(r4)
	PPC_STORE_U32(ctx.r4.u32 + 36, ctx.r10.u32);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,40(r4)
	PPC_STORE_U32(ctx.r4.u32 + 40, ctx.r11.u32);
	// lwz r11,20(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4cf14
	if (ctx.cr0.eq) goto loc_82B4CF14;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// b 0x82b4cf18
	goto loc_82B4CF18;
loc_82B4CF14:
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
loc_82B4CF18:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,44(r4)
	PPC_STORE_U32(ctx.r4.u32 + 44, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4CF28"))) PPC_WEAK_FUNC(sub_82B4CF28);
PPC_FUNC_IMPL(__imp__sub_82B4CF28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r31,20(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq 0x82b4cfb0
	if (ctx.cr0.eq) goto loc_82B4CFB0;
	// lhz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplwi r10,0
	ctx.cr0.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// beq 0x82b4cf60
	if (ctx.cr0.eq) goto loc_82B4CF60;
	// li r10,4
	ctx.r10.s64 = 4;
loc_82B4CF60:
	// lwz r8,28(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// cmplwi r8,0
	ctx.cr0.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne 0x82b4cf78
	if (!ctx.cr0.eq) goto loc_82B4CF78;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x82b4cfb4
	goto loc_82B4CFB4;
loc_82B4CF78:
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mullw r10,r10,r5
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r5.s32);
	// lhz r9,10(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lhz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r11.u32 + 12);
	// lwz r6,32(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// lwz r11,8(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// add r4,r9,r5
	ctx.r4.u64 = ctx.r9.u64 + ctx.r5.u64;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// add r5,r11,r31
	ctx.r5.u64 = ctx.r11.u64 + ctx.r31.u64;
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82B4CFA8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4cfb4
	if (ctx.cr0.lt) goto loc_82B4CFB4;
loc_82B4CFB0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B4CFB4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4CFC8"))) PPC_WEAK_FUNC(sub_82B4CFC8);
PPC_FUNC_IMPL(__imp__sub_82B4CFC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r10,r10,32124
	ctx.r10.s64 = ctx.r10.s64 + 32124;
	// stw r9,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r9.u32);
	// addi r9,r11,16
	ctx.r9.s64 = ctx.r11.s64 + 16;
loc_82B4CFEC:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4d00c
	if (!ctx.cr0.eq) goto loc_82B4D00C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82b4cfec
	if (!ctx.cr6.eq) goto loc_82B4CFEC;
loc_82B4D00C:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq 0x82b4d04c
	if (ctx.cr0.eq) goto loc_82B4D04C;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lis r10,-32239
	ctx.r10.s64 = -2112815104;
	// addi r9,r11,16
	ctx.r9.s64 = ctx.r11.s64 + 16;
	// addi r10,r10,32108
	ctx.r10.s64 = ctx.r10.s64 + 32108;
loc_82B4D024:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r8,r7,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r7.s64;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4d044
	if (!ctx.cr0.eq) goto loc_82B4D044;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82b4d024
	if (!ctx.cr6.eq) goto loc_82B4D024;
loc_82B4D044:
	// cmpwi r8,0
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x82b4d068
	if (!ctx.cr0.eq) goto loc_82B4D068;
loc_82B4D04C:
	// stw r3,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r3.u32);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82B4D060;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82b4d070
	goto loc_82B4D070;
loc_82B4D068:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16386
	ctx.r3.u64 = ctx.r3.u64 | 16386;
loc_82B4D070:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D080"))) PPC_WEAK_FUNC(sub_82B4D080);
PPC_FUNC_IMPL(__imp__sub_82B4D080) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82b4d094
	if (!ctx.cr6.eq) goto loc_82B4D094;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// blr 
	return;
loc_82B4D094:
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 28, ctx.xer);
	// blt cr6,0x82b4d0bc
	if (ctx.cr6.lt) goto loc_82B4D0BC;
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r10,28
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 28, ctx.xer);
	// blt cr6,0x82b4d0bc
	if (ctx.cr6.lt) goto loc_82B4D0BC;
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b4d0c8
	if (ctx.cr6.lt) goto loc_82B4D0C8;
loc_82B4D0BC:
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2905
	ctx.r3.u64 = ctx.r3.u64 | 2905;
	// blr 
	return;
loc_82B4D0C8:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// stw r10,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r10.u32);
	// stw r10,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r10.u32);
	// lwz r11,4(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4d0ec
	if (ctx.cr0.eq) goto loc_82B4D0EC;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
loc_82B4D0EC:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r11,8(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r11.u32);
	// lwz r11,12(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D108"))) PPC_WEAK_FUNC(sub_82B4D108);
PPC_FUNC_IMPL(__imp__sub_82B4D108) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e68
	ctx.lr = 0x82B4D110;
	__savegprlr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82b4d160
	if (!ctx.cr6.gt) goto loc_82B4D160;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82B4D130:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// bl 0x82b4cf28
	ctx.lr = 0x82B4D144;
	sub_82B4CF28(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4d164
	if (ctx.cr0.lt) goto loc_82B4D164;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b4d130
	if (ctx.cr6.lt) goto loc_82B4D130;
loc_82B4D160:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B4D164:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82e28eb8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4D170"))) PPC_WEAK_FUNC(sub_82B4D170);
PPC_FUNC_IMPL(__imp__sub_82B4D170) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82e28e6c
	ctx.lr = 0x82B4D178;
	__savegprlr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4d1e0
	if (ctx.cr6.eq) goto loc_82B4D1E0;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r29,0
	ctx.r29.s64 = 0;
	// lhz r11,10(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4d1d4
	if (ctx.cr0.eq) goto loc_82B4D1D4;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82B4D1A4:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// lwzx r3,r30,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4d1bc
	if (ctx.cr0.eq) goto loc_82B4D1BC;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b50558
	ctx.lr = 0x82B4D1BC;
	sub_82B50558(ctx, base);
loc_82B4D1BC:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// lhz r11,10(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b4d1a4
	if (ctx.cr6.lt) goto loc_82B4D1A4;
loc_82B4D1D4:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,56(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// bl 0x82547938
	ctx.lr = 0x82B4D1E0;
	sub_82547938(ctx, base);
loc_82B4D1E0:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82b4d240
	if (ctx.cr6.eq) goto loc_82B4D240;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r29,0
	ctx.r29.s64 = 0;
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq 0x82b4d234
	if (ctx.cr0.eq) goto loc_82B4D234;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82B4D204:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq 0x82b4d21c
	if (ctx.cr0.eq) goto loc_82B4D21C;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82b50558
	ctx.lr = 0x82B4D21C;
	sub_82B50558(ctx, base);
loc_82B4D21C:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// lhz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b4d204
	if (ctx.cr6.lt) goto loc_82B4D204;
loc_82B4D234:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,60(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// bl 0x82547938
	ctx.lr = 0x82B4D240;
	sub_82547938(ctx, base);
loc_82B4D240:
	// lis r4,9345
	ctx.r4.s64 = 612433920;
	// lwz r3,64(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// bl 0x82547938
	ctx.lr = 0x82B4D24C;
	sub_82547938(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82e28ebc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82B4D258"))) PPC_WEAK_FUNC(sub_82B4D258);
PPC_FUNC_IMPL(__imp__sub_82B4D258) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// bne cr6,0x82b4d28c
	if (!ctx.cr6.eq) goto loc_82B4D28C;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne cr6,0x82b4d28c
	if (!ctx.cr6.eq) goto loc_82B4D28C;
	// lis r3,-30602
	ctx.r3.s64 = -2005532672;
	// ori r3,r3,2156
	ctx.r3.u64 = ctx.r3.u64 | 2156;
	// b 0x82b4d31c
	goto loc_82B4D31C;
loc_82B4D28C:
	// not. r31,r11
	ctx.r31.u64 = ~ctx.r11.u64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r30,1
	ctx.r30.s64 = 1;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// beq 0x82b4d2b0
	if (ctx.cr0.eq) goto loc_82B4D2B0;
loc_82B4D2A0:
	// lwz r11,36(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi r11,0
	ctx.cr0.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne 0x82b4d2a0
	if (!ctx.cr0.eq) goto loc_82B4D2A0;
loc_82B4D2B0:
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82b4d2d8
	if (ctx.cr6.eq) goto loc_82B4D2D8;
	// lwz r30,0(r6)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplwi r30,0
	ctx.cr0.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne 0x82b4d2c8
	if (!ctx.cr0.eq) goto loc_82B4D2C8;
	// li r30,1
	ctx.r30.s64 = 1;
loc_82B4D2C8:
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82b4d2d4
	if (!ctx.cr6.gt) goto loc_82B4D2D4;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
loc_82B4D2D4:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82B4D2D8:
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82b4d318
	if (ctx.cr6.eq) goto loc_82B4D318;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82b4d318
	if (ctx.cr6.eq) goto loc_82B4D318;
loc_82B4D2E8:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82b4d318
	if (ctx.cr6.eq) goto loc_82B4D318;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82b4ce48
	ctx.lr = 0x82B4D2FC;
	sub_82B4CE48(ctx, base);
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt 0x82b4d31c
	if (ctx.cr0.lt) goto loc_82B4D31C;
	// lwz r31,36(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// addi r5,r5,48
	ctx.r5.s64 = ctx.r5.s64 + 48;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// cmplwi r31,0
	ctx.cr0.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne 0x82b4d2e8
	if (!ctx.cr0.eq) goto loc_82B4D2E8;
loc_82B4D318:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82B4D31C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D338"))) PPC_WEAK_FUNC(sub_82B4D338);
PPC_FUNC_IMPL(__imp__sub_82B4D338) {
	PPC_FUNC_PROLOGUE();
	// not r11,r4
	ctx.r11.u64 = ~ctx.r4.u64;
	// li r3,-1
	ctx.r3.s64 = -1;
	// lhz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 8);
	// cmplwi cr6,r10,3
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 3, ctx.xer);
	// bnelr cr6
	if (!ctx.cr6.eq) return;
	// lhz r3,10(r11)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r11.u32 + 10);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D358"))) PPC_WEAK_FUNC(sub_82B4D358);
PPC_FUNC_IMPL(__imp__sub_82B4D358) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82b4d384
	if (!ctx.cr6.eq) goto loc_82B4D384;
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82b4d374
	if (ctx.cr6.lt) goto loc_82B4D374;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82B4D374:
	// lwz r11,20(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// b 0x82b4d3b8
	goto loc_82B4D3B8;
loc_82B4D384:
	// not r11,r4
	ctx.r11.u64 = ~ctx.r4.u64;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lhz r10,10(r10)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + 10);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82b4d3a0
	if (ctx.cr6.lt) goto loc_82B4D3A0;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82b4d3ac
	goto loc_82B4D3AC;
loc_82B4D3A0:
	// lwz r11,56(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
loc_82B4D3AC:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82B4D3B8:
	// not r3,r11
	ctx.r3.u64 = ~ctx.r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D3C0"))) PPC_WEAK_FUNC(sub_82B4D3C0);
PPC_FUNC_IMPL(__imp__sub_82B4D3C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b16248
	ctx.lr = 0x82B4D3D4;
	sub_82B16248(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D3E8"))) PPC_WEAK_FUNC(sub_82B4D3E8);
PPC_FUNC_IMPL(__imp__sub_82B4D3E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82b4d428
	if (ctx.cr6.eq) goto loc_82B4D428;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
loc_82B4D408:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d408
	if (!ctx.cr0.eq) goto loc_82B4D408;
loc_82B4D428:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b16248
	ctx.lr = 0x82B4D430;
	sub_82B16248(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D448"))) PPC_WEAK_FUNC(sub_82B4D448);
PPC_FUNC_IMPL(__imp__sub_82B4D448) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82b4d494
	if (ctx.cr6.eq) goto loc_82B4D494;
	// lis r9,-32229
	ctx.r9.s64 = -2112159744;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - ctx.r11.s64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// lfs f0,-13892(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
loc_82B4D470:
	// lfsx f13,r8,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r11.u32);
	ctx.f13.f64 = double(temp.f32);
	// li r9,1
	ctx.r9.s64 = 1;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bne cr6,0x82b4d484
	if (!ctx.cr6.eq) goto loc_82B4D484;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82B4D484:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d470
	if (!ctx.cr0.eq) goto loc_82B4D470;
loc_82B4D494:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b16248
	ctx.lr = 0x82B4D49C;
	sub_82B16248(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D4B0"))) PPC_WEAK_FUNC(sub_82B4D4B0);
PPC_FUNC_IMPL(__imp__sub_82B4D4B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4d4ec
	if (ctx.cr0.eq) goto loc_82B4D4EC;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82B4D4CC:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d4cc
	if (!ctx.cr0.eq) goto loc_82B4D4CC;
loc_82B4D4EC:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b16308
	ctx.lr = 0x82B4D4F4;
	sub_82B16308(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D508"))) PPC_WEAK_FUNC(sub_82B4D508);
PPC_FUNC_IMPL(__imp__sub_82B4D508) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b16308
	ctx.lr = 0x82B4D51C;
	sub_82B16308(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D530"))) PPC_WEAK_FUNC(sub_82B4D530);
PPC_FUNC_IMPL(__imp__sub_82B4D530) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4d564
	if (ctx.cr0.eq) goto loc_82B4D564;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82B4D54C:
	// lfsx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d54c
	if (!ctx.cr0.eq) goto loc_82B4D54C;
loc_82B4D564:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b16308
	ctx.lr = 0x82B4D56C;
	sub_82B16308(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D580"))) PPC_WEAK_FUNC(sub_82B4D580);
PPC_FUNC_IMPL(__imp__sub_82B4D580) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4d5d0
	if (ctx.cr0.eq) goto loc_82B4D5D0;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82B4D59C:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d59c
	if (!ctx.cr0.eq) goto loc_82B4D59C;
loc_82B4D5D0:
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82b16088
	ctx.lr = 0x82B4D600;
	sub_82B16088(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D618"))) PPC_WEAK_FUNC(sub_82B4D618);
PPC_FUNC_IMPL(__imp__sub_82B4D618) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4d658
	if (ctx.cr0.eq) goto loc_82B4D658;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82B4D634:
	// lwax r8,r9,r11
	ctx.r8.s64 = int32_t(PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d634
	if (!ctx.cr0.eq) goto loc_82B4D634;
loc_82B4D658:
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82b16088
	ctx.lr = 0x82B4D688;
	sub_82B16088(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D6A0"))) PPC_WEAK_FUNC(sub_82B4D6A0);
PPC_FUNC_IMPL(__imp__sub_82B4D6A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82b16088
	ctx.lr = 0x82B4D6DC;
	sub_82B16088(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D6F0"))) PPC_WEAK_FUNC(sub_82B4D6F0);
PPC_FUNC_IMPL(__imp__sub_82B4D6F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b162a8
	ctx.lr = 0x82B4D704;
	sub_82B162A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D718"))) PPC_WEAK_FUNC(sub_82B4D718);
PPC_FUNC_IMPL(__imp__sub_82B4D718) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82b4d758
	if (ctx.cr6.eq) goto loc_82B4D758;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
loc_82B4D738:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d738
	if (!ctx.cr0.eq) goto loc_82B4D738;
loc_82B4D758:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b162a8
	ctx.lr = 0x82B4D760;
	sub_82B162A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D778"))) PPC_WEAK_FUNC(sub_82B4D778);
PPC_FUNC_IMPL(__imp__sub_82B4D778) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82b4d7c4
	if (ctx.cr6.eq) goto loc_82B4D7C4;
	// lis r9,-32229
	ctx.r9.s64 = -2112159744;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - ctx.r11.s64;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// lfs f0,-13892(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -13892);
	ctx.f0.f64 = double(temp.f32);
loc_82B4D7A0:
	// lfsx f13,r8,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r11.u32);
	ctx.f13.f64 = double(temp.f32);
	// li r9,1
	ctx.r9.s64 = 1;
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// bne cr6,0x82b4d7b4
	if (!ctx.cr6.eq) goto loc_82B4D7B4;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82B4D7B4:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d7a0
	if (!ctx.cr0.eq) goto loc_82B4D7A0;
loc_82B4D7C4:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b162a8
	ctx.lr = 0x82B4D7CC;
	sub_82B162A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D7E0"))) PPC_WEAK_FUNC(sub_82B4D7E0);
PPC_FUNC_IMPL(__imp__sub_82B4D7E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b16360
	ctx.lr = 0x82B4D7F4;
	sub_82B16360(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D808"))) PPC_WEAK_FUNC(sub_82B4D808);
PPC_FUNC_IMPL(__imp__sub_82B4D808) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4d844
	if (ctx.cr0.eq) goto loc_82B4D844;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82B4D824:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d824
	if (!ctx.cr0.eq) goto loc_82B4D824;
loc_82B4D844:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b16360
	ctx.lr = 0x82B4D84C;
	sub_82B16360(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D860"))) PPC_WEAK_FUNC(sub_82B4D860);
PPC_FUNC_IMPL(__imp__sub_82B4D860) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4d894
	if (ctx.cr0.eq) goto loc_82B4D894;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82B4D87C:
	// lfsx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d87c
	if (!ctx.cr0.eq) goto loc_82B4D87C;
loc_82B4D894:
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// bl 0x82b16360
	ctx.lr = 0x82B4D89C;
	sub_82B16360(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D8B0"))) PPC_WEAK_FUNC(sub_82B4D8B0);
PPC_FUNC_IMPL(__imp__sub_82B4D8B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4d900
	if (ctx.cr0.eq) goto loc_82B4D900;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82B4D8CC:
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r8,r8,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// xori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 ^ 1;
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d8cc
	if (!ctx.cr0.eq) goto loc_82B4D8CC;
loc_82B4D900:
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82b16168
	ctx.lr = 0x82B4D930;
	sub_82B16168(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D948"))) PPC_WEAK_FUNC(sub_82B4D948);
PPC_FUNC_IMPL(__imp__sub_82B4D948) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// rlwinm. r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq 0x82b4d988
	if (ctx.cr0.eq) goto loc_82B4D988;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r11.s64;
loc_82B4D964:
	// lwax r8,r9,r11
	ctx.r8.s64 = int32_t(PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82b4d964
	if (!ctx.cr0.eq) goto loc_82B4D964;
loc_82B4D988:
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82b16168
	ctx.lr = 0x82B4D9B8;
	sub_82B16168(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82B4D9D0"))) PPC_WEAK_FUNC(sub_82B4D9D0);
PPC_FUNC_IMPL(__imp__sub_82B4D9D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// add r10,r4,r7
	ctx.r10.u64 = ctx.r4.u64 + ctx.r7.u64;
	// rlwinm r11,r4,30,2,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rldicr r9,r9,63,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// srad r10,r9,r10
	temp.u64 = ctx.r10.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// srd r7,r10,r11
	ctx.r7.u64 = ctx.r11.u8 & 0x40 ? 0 : (ctx.r10.u64 >> (ctx.r11.u8 & 0x7F));
	// bl 0x82b16168
	ctx.lr = 0x82B4DA0C;
	sub_82B16168(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

